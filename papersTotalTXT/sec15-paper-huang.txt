SUPOR: Precise and Scalable Sensitive User Input 

Detection for Android Apps

Jianjun Huang, Purdue University; Zhichun Li, Xusheng Xiao, and Zhenyu Wu, NEC Labs 
America; Kangjie Lu, Georgia Institute of Technology; Xiangyu Zhang, Purdue University; 

Guofei Jiang, NEC Labs America

https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/huang

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXSUPOR: Precise and Scalable Sensitive User Input Detection

for Android Apps

Jianjun Huang1, Zhichun Li2, Xusheng Xiao2, Zhenyu Wu2, Kangjie Lu3, Xiangyu Zhang1, and

Guofei Jiang2

1Department of Computer Science, Purdue University

2NEC Labs America

3School of Computer Science, Georgia Institute of Technology

huang427@purdue.edu, {zhichun, xsxiao, adamwu}@nec-labs.com, kjlu@gatech.edu

xyzhang@cs.purdue.edu, gfj@nec-labs.com

Abstract

While smartphones and mobile apps have been an essen-
tial part of our lives, privacy is a serious concern. Previ-
ous mobile privacy related research efforts have largely
focused on predeﬁned known sources managed by smart-
phones. Sensitive user inputs through UI (User Inter-
face), another information source that may contain a lot
of sensitive information, have been mostly neglected.

In this paper, we examine the possibility of scalably
detecting sensitive user inputs from mobile apps. In par-
ticular, we design and implement SUPOR, a novel static
analysis tool that automatically examines the UIs to iden-
tify sensitive user inputs containing critical user data,
such as user credentials, ﬁnance, and medical data. SU-
POR enables existing privacy analysis approaches to be
applied on sensitive user inputs as well. To demonstrate
the usefulness of SUPOR, we build a system that detects
privacy disclosures of sensitive user inputs by combin-
ing SUPOR with off-the-shelf static taint analysis We
apply the system to 16,000 popular Android apps, and
conduct a measurement study on the privacy disclosures.
SUPOR achieves an average precision of 97.3% and an
average recall of 97.3% for sensitive user input identiﬁ-
cation. SUPOR ﬁnds 355 apps with privacy disclosures
and the false positive rate is 8.7%. We discover inter-
esting cases related to national ID, username/password,
credit card and health information.

1 Introduction
Smartphones have become the dominant kind of end-
user devices with more units sold than traditional PCs.
With the ever-increasing number of apps, smartphones
are becoming capable of handling all kinds of needs from
users, and gain more and more access to sensitive and
private personal data. Despite the capabilities to meet
users’ needs, data privacy in smartphones becomes a ma-
jor concern.

Figure 1: Example sensitive user inputs.

Previous research on smartphone privacy protection
primarily focuses on sensitive data managed by the
phone OS and framework APIs, such as device identi-
ﬁers (phone number, IMEI, etc.), location, contact, cal-
endar, browser state, most of which are permission pro-
tected. Although these data sources are very important,
they do not cover all sensitive data related to users’ pri-
vacy. A major type of sensitive data that has been largely
neglected are the sensitive user inputs, which refers to
the sensitive information entered by users via the User
Interface (UI). Many apps today acquire sensitive cre-
dentials, ﬁnancial, health, and medical information from
users through the UI. Therefore, to protect and respect
users’ privacy, apps must handle sensitive user inputs in
a secure manner that matches with users’ trust and ex-
pectations.

Figure 1 shows an example interface an app uses to ac-
quire users’ login credentials via input ﬁelds rendered in
the UI. When users click the button “Login”, the app use
the user ID and password to authenticate with a remote
service. As the developers may be unaware of the poten-
tial risk on the disclosures of such sensitive information,
the login credentials are sent in plain text over an inse-
cure channel (HTTP), which inadvertently compromises
users’ privacy.

In this paper, we propose SUPOR (Sensitive User
inPut detectOR), a static mobile app analysis tool for
detecting sensitive user inputs and identifying their as-

USENIX Association  

24th USENIX Security Symposium  977

sociated variables in the app code as sensitive informa-
tion sources. To the best of our knowledge, we are the
ﬁrst to study scalable detection of sensitive user inputs
on smartphone platforms.

Previously, there are many existing research efforts [9,
10, 12, 23, 24, 30, 31, 34, 40] on studying the privacy re-
lated topics on predeﬁned sensitive data sources on the
phone. Our approach enables those existing efforts to
be applied to sensitive user inputs as well. For exam-
ple, with proper static or dynamic taint analysis, one can
track the privacy disclosures of sensitive user inputs to
different sinks. With static program analysis, one can
also identify the vulnerabilities in the apps that may un-
intentionally disclosure such sensitive user inputs to pub-
lic or to the attacker controlled output. One could also
study how sensitive user inputs propagate to third-party
advertisement libraries, etc.

In this paper, to demonstrate the usefulness of our ap-
proach, we combine SUPOR with off-the-shelf static
taint analysis to detect privacy disclosures of sensitive
user inputs.

The major challenges of identifying sensitive user in-

puts are the following:

(i) How to systematically discover the input ﬁelds

from an app’s UI?

(ii) How to identify which input ﬁelds are sensitive?
(iii) How to associate the sensitive input ﬁelds to the
corresponding variables in the apps that store their
values?

In order to detect sensitive user inputs scalably, static
UI analysis is much appealing, because it is very difﬁcult
to generate test inputs to trigger all the UI screens in an
app in a scalable way. For example, an app might require
login, which is difﬁcult for tools to generate desirable in-
puts and existing approaches usually require human in-
tervention [26]. On the other hand, it is also extremely
challenging to launch static analysis to answer the afore-
mentioned three questions for general desktop applica-
tions.

To this end, we have studied major mobile OSes, such
as Android, iOS and Windows Phone systems, and made
a few important observations. Then, we implement SU-
POR for Android since it is most popular.

First, we ﬁnd all these mobile OSes provide a stan-
dard rapid UI development kit as part of the development
framework, and most apps use such a homogeneous UI
framework to develop apps. Such UI framework usually
leverages a declarative language, such as XML based
layout languages, to describe the UI layout, which en-
ables us to statically discover the input ﬁelds on the UI.
Second, in order to identify which input ﬁelds are sen-
sitive, we have to be able to render the UI, because the
rendered UI screens contain important texts as hints that

guide users to enter their inputs, which can be used to
identify whether the inputs are sensitive. For instance, in
Figure 1, the text “User ID” describes the nature of the
ﬁrst input ﬁeld. Statically rendering UI screens is gener-
ally very hard for arbitrary desktop applications. How-
ever, with help of WYSIWYG (What You See is What
You Get) layout editing feature from the rapid UI de-
velopment kits of mobile OSes, we are able to statically
render the UI for most mobile apps in order to associate
the descriptive text labels with the corresponding input
ﬁelds. Furthermore, due to the relatively small screen
size of smartphones, most text labels are concise. As
such, current NLP (Natural Language processing) tech-
niques can achieve high accuracy on identifying sensitive
terms.

Third, all mobile OSes provide APIs to load the UI
layouts made by rapid UI development kits and to bind
with the app code. Such a binding mechanism provides
us opportunities to infer the relationship between the sen-
sitive input ﬁelds from UI layouts to the variables in the
app code that store their values.

Our work makes three major contributions:
First, we devise a UI sensitiveness analysis that identi-
ﬁes the input ﬁelds that may accept sensitive information
by leveraging UI rendering, geometrical layout analysis
and NLP techniques. We modify the static rendering en-
gine from the ADT (Android Developer Tools), so that
the static rendering can be done with an APK binary in-
stead of source code, and accurately identify the coordi-
nates of text labels and input ﬁelds. Then, based on the
insight that users typically read the text label physically
close to the input ﬁeld in the screen for understanding the
purpose of the input ﬁeld, we design an algorithm to ﬁnd
the optimal descriptive text label for each input ﬁeld. We
further leverage NLP (nature language processing) tech-
niques [11, 22, 36] to select and map popular keywords
extracted from the UIs of a massive number of apps to
important sensitive categories, and use these keywords to
classify the sensitive text labels and identify sensitive in-
put ﬁelds. Our evaluation shows that SUPOR achieves
an average precision of 97.3% and an average recall of
97.3% for sensitive user inputs detection.

Second, we design a context-sensitive approach to as-
sociate sensitive UI input ﬁelds to the corresponding
variables in the app code.
Instances of sensitive input
widgets in the app code can be located using our UI anal-
ysis results in a context-insensitive fashion (i.e. based on
widget IDs). We further reduce false positives by adding
context-sensitivity, i.e. we leverage backward slicing and
identify each input widget’s residing layout by tracing
back to the closest layout loading function. Only if both
widget and layout identiﬁers match with the sensitive in-
put ﬁeld in the XML layout, we consider the widget in-
stance is associated with the sensitive input ﬁeld.

978  24th USENIX Security Symposium 

USENIX Association

Finally, we implement a privacy disclosure detec-
tion system based on SUPOR and static taint analysis,
and apply the system to 16,000 popular free Android
apps collected from the Ofﬁcial Android Market (Google
Play). The system can process 11.1 apps per minute
on an eight-server cluster. Among all these apps, 355
apps are detected with sensitive user input disclosures.
Our manual validation on these suspicious apps shows
an overall detection accuracy of 91.3%. In addition, we
conduct detailed case studies on the apps we discovered,
and show interesting cases of unsafe disclosures of users’
national IDs, credentials, credit card and health related
information.

2 Background and Motivation Example

In this section, we provide background on sensitive user
input identiﬁcation.

2.1 Necessary Support for Static Sensitive User In-

put Identiﬁcation

Modern mobile OSes, such as Android, iOS and Win-
dows Phone system, provide frameworks and tools for
rapid UI design. They usually provide a large collection
of standard UI widgets, and different layouts to compose
the widgets together. They also provide a declarative lan-
guage, such as XML, to let the developer describe their
UI designs, and further provide GUI support for WYSI-
WYG UI design tools. In order to design a static analysis
tool for sensitive user input identiﬁcation, we need four
basic supporting features. The rapid UI development de-
sign in modern mobile OSes makes it feasible to achieve
such features.
A: statically identify the input ﬁelds and text labels;
B: statically identify the attributes of input ﬁelds;
C: statically render the UI layout without launching the
app;
D: statically map the input ﬁelds deﬁned in the UI lay-
outs to the app code.

These four features are necessary to statically identify
the sensitive input ﬁelds on UIs. In order to infer the se-
mantic meaning of an input ﬁeld and decide whether it is
sensitive, we need (i) the attributes of the input ﬁeld; (ii)
the surrounding descriptive text labels on the UI. Some
attributes of the input ﬁelds can help us quickly under-
stand its semantics and sensitiveness. For example, if the
input type is password, we know this is a password-like
input ﬁeld. However, in many cases, the attributes alone
are not enough to decide the semantics and sensitiveness
of the input ﬁelds.
In those cases, we have to rely on
UI analysis. A well-designed app has to allow the user
to easily identify the relevant texts for a particular input
ﬁeld and provide appropriate inputs based on his under-
standing of the meaning of texts. Based on the above
observation, we need Feature C to render the UI and ob-

Table 1: UI features in different mobile OSes

Layout format

Android iOS
XML

NIB / XIB /
Storyboard
Xcode
Yes

Windows Phone
XAML/HTML

Visual Studio
Yes

Static UI render ADT
APIs map widgets
to code

Yes

1
2
3
4
5

6

7

<LinearLayout android:orientation="vertical">
<TextView android:text="@string/tip_uid" />
<EditText android:id="@+id/uid" />
<TextView android:text="@string/tip_pwd" />
<EditText android:id="@+id/pwd"

android:inputType="textPassword" />

<Button android:id="@+id/login"

android:text="@string/tip_login"/>

</LinearLayout>

Figure 2: Simpliﬁed layout ﬁle login_activity.xml.

tain the coordinates of input ﬁelds and text labels, so that
we can associate them and further reason about the sen-
sitiveness of input ﬁelds. Once we identify the sensitive
input ﬁelds, we have to ﬁnd the variable in the app code
used to store the values of the input ﬁeld for further anal-
ysis.

We have studied Android, iOS and Windows Phone
systems. As shown in Table 1, all mobile OSes provide
standard formats for storing app UI layouts that we can
use to achieve features A and B. All of them have IDEs
that can statically render UI layouts for the WYSIWYG
UI design. If we reuse this functionality we can achieve
static rendering (feature C). Furthermore, all of them pro-
vide APIs for developers to map the widgets in layouts
to the variables in the app code that hold the user inputs.
Combined with static program analysis to understand the
mapping, we will be able to achieve feature D.

2.2 Android UI Rendering

For proof of concept, the current SUPOR is designed for
the Android platform. An Android app usually consists
of multiple activities. Each activity provides a window
to draw a UI. A UI is deﬁned by a layout, which speci-
ﬁes the dimension, spacing, and placement of the content
within the window. The layout consists of various inter-
active UI widgets (e.g., input ﬁelds and buttons) as well
as layout models (e.g., linear or relative layout) that de-
scribe how to arrange UI widgets.

At run time, when a layout ﬁle is loaded, the Android
framework parses the layout ﬁle and determines how to
render the UI widgets in the window by checking the lay-
out models and the relevant attributes of the UI widgets.
At the mean time, all UI widgets in the layout are instan-
tiated and then can be referenced in the code.

An example layout in XML is presented in Figure 2
and the code snippet of the corresponding activity is

USENIX Association  

24th USENIX Security Symposium  979

1 public class LoginActivity extends Activity

implements View.OnClickListener {

private EditText txtUid, txtPwd;
private Button btnReset;
protected void onCreate(Bundle bundle) {

super.onCreate(bundle);
setContentView(R.layout.login_activity);
txtUid = (EditText) findViewById(R.id.uid);
txtPwd = (EditText) findViewById(R.id.pwd);
btnLogin = (Button) findViewById(R.id.login);
btnLogin.setOnClickListener(this);

}
public void onClick(View view) {

String uid = txtUid.getText().toString();
String pwd = txtPwd.getText().toString();
String url = "http://www.plxx.com/Users/" +

"login?uid=" + uid + "&pwd=" + pwd;
HttpClient c = new DefaultHttpClient();
HttpGet g = new HttpGet(url);
Object o = c.execute(g, new

BasicResponseHandler());

// following operations are omitted

2
3
4
5
6
7
8
9
10
11
12
13
14
15

16
17
18

19
20
21 }

}

Figure 3: Simpliﬁed Activity example.

shown in Figure 3. This layout includes ﬁve UI wid-
gets:
two text labels (TextView), two input ﬁelds
(EditText) and a button. They are aligned verti-
cally based on the LinearLayout at Line 1. The
ﬁrst text label shows “User ID” based on the attribute
android:text=“@string/tip_uid”, which in-
dicates a string stored as a resource with the ID
tip_uid. The type attribute of the second input ﬁeld
is android:inputType=“textPassword”, indi-
cating that it is designed for accepting a password, which
conceals the input after the users enter it. Instead of ex-
plicitly placing text labels as in Figure 2, some devel-
opers decorate an input ﬁeld with a hint attribute, which
speciﬁes a message that will be displayed when the input
is empty. For instance, developers may choose to dis-
play “User ID” and “Password” inside the corresponding
input ﬁelds using the hint attribute.

Figure 1 shows the rendered UI for the layout in Fig-
ure 2. The layout including all the inner widgets is loaded
into the screen by calling setContentView() at Line
6 in Figure 3. The argument of setContentView()
speciﬁes the reference ID of the layout resource. Simi-
larly, a runtime instance of a widget can also be located
through a findViewById() call with the appropriate
reference ID. For example, the reference ID R.id.uid
is used to obtain a runtime instance of the input ﬁeld at
Line 7 in Figure 3.

2.3 UI Sensitiveness Analysis

Existing techniques usually consider permission pro-
tected framework APIs as the predeﬁned sensitive data
sources. However, generic framework APIs, such as
getText(), can also obtain sensitive data from the
user inputs. To precisely detect these sensitive sources,

S

VP

VB

NP

PRP

NN

NN

enter

your   phone   number
your   phone   number

Figure 4: Parse tree of an example sentence.

we need to determine which GUI input widgets are sen-
sitive.

Two kinds of information are useful for this purpose.
First, certain attributes of the widgets can be a good in-
dicator about whether the input is sensitive. Using the
inputType attribute with a value “textPassword”, we
can directly identify password ﬁelds. However, not all
sensitive input ﬁelds use this attribute value. The hint
attributes also may contain useful descriptive texts that
may indicate the sensitiveness of the input ﬁelds.

Besides attributes of UI widgets, we observe that
nearby text labels rendered in the UI also provide indi-
cation about the sensitiveness of the widgets. For exam-
ple, a user can easily understand he is typing a user ID
and a password when he sees the UI in Figure 1 because
the text labels state what the input ﬁelds accept. In other
words, these text labels explain the purposes of the UI
widgets, and guide users to provide their inputs. Based
on these observations, we propose to leverage the out-
come of UI rendering to build a precise model of the UI
and analyze the text labels and hints associated with the
widgets to determine their sensitiveness.

The major task of analyzing text labels is to analyze
the text labels’ texts, which are written in natural lan-
guage. As smartphones have relatively small screens,
the texts shown in the UI are usually very concise and
straightforward to understand. For example, these texts
typically are just noun/verb phrases or short sentences
(such as the ones shown in Figure 1), and tend to directly
state the purposes for the corresponding GUI widgets.
Since there is no need to analyze paragraphs or even long
sentences, we propose a light-weight keyword-based al-
gorithm that checks whether text labels contain any sen-
sitive keyword to determine the sensitiveness of the cor-
responding GUI widgets.

2.4 Natural Language Processing

With recent research advances in the area of natural
language processing (NLP), NLP techniques have been
shown to be fairly accurate in highlighting grammatical
structure of a natural language sentence. Recent work
has also shown promising results in using NLP tech-
niques for analyzing Android descriptions [13, 30].
In
our work, we adapt NLP techniques to extract nouns and
noun phrases from the texts collected from popular apps,

980  24th USENIX Security Symposium 

USENIX Association

and identify keywords from the extracted nouns and noun
phrases. We next brieﬂy introduce the key NLP tech-
niques used in this work.

Our approach uses Parts Of Speech (POS) Tag-
ging [22,36] to identify interesting words, such as nouns,
and ﬁlter unrelated words, such as conjunctives like
“and/or”. The technique tags a word in a sentence as cor-
responding to a particular part of speech (such as iden-
tifying nouns, verbs, and adjectives), based on both its
deﬁnition and its relationship with adjacent and related
words in a phrase, sentence, or paragraph. The state-
of-the-art approaches can achieve around 97% [36] ac-
curacy in assigning POS tags for words in well-written
news articles.

Our approach uses Phrase and Clause Parsing to
identify phrases for further inspection. Phrase and clause
parsing divides a sentence into a constituent set of words
(i.e., phrases and clauses). These phrases and clauses
logically belong together, e.g., Noun Phrases and Verb
Phrases. The state-of-the-art approaches can achieve
around 90% [36] accuracy in identifying phrases and
clauses over well-written news articles.

Our approach uses Syntactic parsing [21], combined
with the above two techniques, to generate a parse-tree
structure for a sentence, and traverse the parse tree to
identify interesting phrases such as noun phrases. The
parse tree of a sentence shows the hierarchical view of
the syntax structure for the sentence. Figure 4 shows
the parse tree for an example sentence “enter your phone
number”. The root node of the tree is the sentence node
with the label S. The interior nodes of the parse tree are
labeled by non-terminal categories of the grammar (e.g.,
verb phrases VP and noun phrases NP), while the leaf
nodes are labeled by terminal categories (e.g., pronouns
PRP, nouns NN and verbs VB). The tree structure pro-
vides a basis for other tasks within NLP such as question
and answer, information extraction, and translation. The
state of the art parsers have an F1 score of 90.4% [37].

3 Design of SUPOR
In this section, we ﬁrst present our threat model, fol-
lowed by an overview of SUPOR. Then, we describe
each component of SUPOR in details.

3.1 Threat Model

We position SUPOR as a static UI analysis tool for de-
tecting sensitive user inputs. Instead of focusing on ma-
licious apps that deliberately evade detection, SUPOR
is designed for efﬁcient and scalable screening of a large
number of apps. Most of the apps in the app markets are
legitimate, whose developers try to monetize by gaining
user popularity, even though some of them might be a lit-
tle bit aggressive on exploiting user privacy for revenue.
Malware can be detected by existing works [5, 15, 39],

APK

Layout 
Parsing

UI 

Rendering
Layout 
Analysis

Keywords

UI 

Sensitiveness 

Analysis

SUPOR

Variable 
Binding

Disclosure

Vulnerability

…

Privacy 
Analysis

Figure 5: Overview of SUPOR.

which is out of scope of this paper.

Though the developers sometimes dynamically gener-
ate UI elements in the code other than deﬁning the UI
elements via layout ﬁles, we focus on identifying sensi-
tive user inputs statically deﬁned in layout ﬁles in this
work.

3.2 Overview

Figure 5 shows the workﬂow of SUPOR. SUPOR con-
sists of three major components: Layout Analysis, UI
Sensitiveness Analysis, and Variable Binding. The lay-
out analysis component accepts an APK ﬁle of an app,
parses the layout ﬁles inside the APK ﬁle, and renders
the layout ﬁles containing input ﬁelds. Based on the
outcome of UI rendering, the UI sensitiveness analysis
component associates text labels to the input ﬁelds, and
determines the sensitiveness of the input ﬁelds by check-
ing the texts in the text labels against a predeﬁned sensi-
tive keyword dataset (Section 3.6). The variable binding
component then searches the code to identify the vari-
ables that store the values of the sensitive input ﬁelds.
With variable binding, existing research efforts in study-
ing the privacy related topics on predeﬁned well-known
sensitive data sources can be applied to sensitive user in-
puts. For example, one can use taint analysis to detect
disclosures of sensitive user inputs or other privacy anal-
ysis to analyze vulnerabilities of sensitive user inputs in
the apps. Next we describe each component in detail.

3.3 Layout Analysis

The goal of the layout analysis component is to render
the UIs of an Android app, and extract the information
of input ﬁelds:
types, hints, and absolute coordinates,
which are later used for the UI sensitiveness analysis.

As we discussed in Section 2.3, if we cannot deter-
mine the sensitiveness of an input ﬁeld based on its type
and hint, we need to ﬁnd a text label that describes the
purpose of the input ﬁeld. From the user’s perspective,
the text label that describes the purpose of an input ﬁeld
must be physically close to the input ﬁeld in the screen;
otherwise the user may correlate the text label with other
input ﬁelds and provide inappropriate inputs. Based on
this insight, the layout analysis component renders the
UIs as if the UIs are rendered in production runs, mim-
icking how users look at the UIs. Based on the rendered

USENIX Association  

24th USENIX Security Symposium  981

LinearLayout @ [0, 50, 480, 752]

TextView @ [16, 16, 60, 33],  TEXT=“User ID”

EditText @ [16, 33, 464, 81],  ID=0x7f090000

TextView @ [16, 81, 79, 98],  TEXT=“Password”

EditText @ [16, 98, 464, 146],  ID=0x7f090001

Button @ [16, 146, 464, 163]
ID=0x7f090002,  TEXT=“Login”

Figure 6: UI model for Figure 1 on 480x800 screen.
Only the ID, relative coordinates and text of the widgets
are presented here.

UIs, the distances between text labels and input ﬁelds are
computed, and these distances are used later to ﬁnd the
best descriptive text labels for each input ﬁeld. We next
describe the two major steps of the layout analysis com-
ponent.

The ﬁrst step is to identify which layout ﬁles contain
input ﬁelds by parsing the layout ﬁles in the APK of an
Android app. In this work, we focus on input ﬁelds of
the type EditText and all possible sub-types, includ-
ing custom widgets in the apps. Each input ﬁeld repre-
sents a potential sensitive source. However, according to
our previous discussion, the sensitiveness cannot be eas-
ily determined by analyzing only the layout ﬁles. Thus,
all the ﬁles containing input ﬁelds are used in the second
step for UI rendering.

The second step is to obtain the coordinate information
of the input ﬁelds by rendering the layout ﬁles. Using
the rapid UI development kit provided by Android, the
layout analysis component can effectively render stan-
dard UI widgets. For custom widgets that require more
complex rendering, the layout analysis component ren-
ders them by providing the closest library superclass to
obtain the best result. After rendering a layout ﬁle, the
layout analysis component obtains a UI model, which is
a tree-structure model where the nodes are UI widgets
and the edges describe the parent-child relationship be-
tween UI widgets. Figure 6 shows the UI model obtained
by rendering the layout ﬁle in Figure 2. For each ren-
dered UI widget, the coordinates are relative to its parent
container widget. Such relative coordinates cannot be di-
rectly used for measuring the distances between two UI
widgets, and thus SUPOR converts the relative coordi-
nates to absolute coordinates with regards to the screen
size.

Coordinate Conversion. SUPOR computes the ab-
solute coordinates of each UI widget level by level, start-
ing with the root container widget. For example, in Fig-
ure 6, the root container widget is a LinearLayout,
and its coordinates are (0, 50, 480, 752), represent-
ing the left, top, right, and bottom corners. There is

Algorithm 1 UI Widget Sensitiveness Analysis
Require: I as an input ﬁeld, S as a set of text labels, KW

as a pre-deﬁned sensitive keyword dataset

Ensure: R as whether I is sensitive

1: Divide the UI plane into nine partitions based on I’s

boundary

score = 0
for all (x, y) ∈ L do

2: for all L ∈ S do
3:
4:
5:
6:
7:
8: end for
9: T = min(S)
10: R = T.text matches KW

score += distance(I, x, y) ∗ posWeight(I, x, y)

end for
L.score = score / L.numO f Pixels

no need to convert the coordinates of the root UI wid-
get, since its coordinates are relative to the top left cor-
ner of the screen, and thus are already absolute coordi-
nates. For other UI widgets, SUPOR computes their
absolute coordinates based on their relative coordinates
and their parent container’s absolute coordinates. For ex-
ample, the relative coordinates of the second UI widget,
TextView, are (16, 16, 60, 33). Since it is a child wid-
get of the root UI widget, its absolute coordinates is com-
puted as (16, 66, 60, 83). This process is repeated until
the coordinates of every UI widget are converted.

In addition to coordinate conversion, SUPOR collects
other information of the UI widgets, such as the texts in
the text labels and the attributes for input ﬁelds (e.g., ID
and inputType).

3.4 UI Sensitiveness Analysis

Based on the information collected from the layout anal-
ysis, the UI sensitiveness analysis component determines
whether a given input ﬁeld contains sensitive informa-
tion. This component consists of three major steps.

if

the

with

ﬁeld

input
certain

been
First,
like
assigned
android:inputType="textPassword",
it
is directly considered as sensitive. With such attribute,
the original inputs on the UI are concealed after users
type them. In most cases these inputs are passwords.

has
attributes

Second,

if the input ﬁeld contains any hint (i.e.,
tooltip), e.g., “Enter Password Here”, the words in the
hint are checked: if it contains any keyword in our sensi-
tive keyword dataset, the input ﬁeld is considered sensi-
tive; otherwise, the third step is required to determine its
sensitiveness.

Third, SUPOR identiﬁes the text label that describes
the purpose of the input ﬁeld, and analyzes the text in the
label to determine the sensitiveness. In order to identify
text labels that are close to a given input ﬁeld, we provide

982  24th USENIX Security Symposium 

USENIX Association

left top [4]
left [0.8]

top [2]

Input Field (Central) [6]

right top [8]
right [9]

left bottom [8]

bottom [9]

right bottom [10]

Figure 7: The partition of the UI is based on the boundary
of the input ﬁeld.

Table 2: Scores of the text labels in Figure 8.

1st input ﬁeld
2nd input ﬁeld

First Name
46.80
211.29

Last Name
218.81
46.84

Figure 8: Example for UI widget sensitiveness analysis.

an algorithm to compute correlation scores for each pair
of a text label and an input ﬁeld based on their distances
and relative positions.

The details of our algorithm is shown in Algorithm 1.
At ﬁrst, SUPOR divides the UI plane into nine parti-
tions based on the boundaries of the input ﬁeld. Fig-
ure 7 shows the nine partitions divided by an input ﬁeld.
Each text label can be placed in one or more partitions,
and the input ﬁeld itself is placed in the central partition.
For a text label, we determine how it is correlated to an
input ﬁeld by computing how each pixel in a text label
is correlated to the input ﬁeld (Line 4). The correlation
score for a pixel consists of two parts (Line 5). The ﬁrst
part is the Euclidean distance from the pixel to the input
ﬁeld, computed using the absolute coordinates. The sec-
ond part is a weight based on their relative positions, i.e.,
which of the nine partitions the widget is in. We build
the position-based weight function based on our empir-
ical observations: if the layout of the apps is top-down
and left-right arranged, the text label that describes the
input ﬁeld is usually placed at left or on top of the in-
put ﬁeld while the left one is more likely to be the one if
it exists. We assign smallest weight to the pixels in the
left partition and second smallest for the top partition.
The right-bottom partition is least possible so we give
the largest weight to it. The detailed weights for each
partition is shown in Figure 7. Based on the correlation
scores of all the pixels, our algorithm uses the average
of the correlation scores as the correlation score for the
pair of the text label and the input ﬁeld (Line 7). The
label with smaller correlation score is considered more
correlated to the input ﬁeld.

After the correlation scores for all text labels are com-
puted, SUPOR selects the text label that has the smallest
score as the descriptive text label for the input ﬁeld, and
uses the pre-deﬁned sensitive keyword dataset to deter-
mine if the label contains any sensitive keyword. If yes,
the input ﬁeld is considered as sensitive.

Example. Figure 8 shows an example UI that requires

Algorithm 1 for sensitiveness analysis. This example
shows a UI that requests a user to enter personal infor-
mation. This UI contains two input ﬁelds and two text
labels. Neither can SUPOR determine the sensitiveness
through their attributes, nor can SUPOR use any hint to
determine the sensitiveness. SUPOR then applies Algo-
rithm 1 on these two input ﬁelds to compute the corre-
lation scores for each pair of text labels and input ﬁelds.
The correlation scores are shown in Table 2. Accord-
ing to the correlation scores, SUPOR associates “First
Name” to the ﬁrst input ﬁeld and “Last Name” to the
second input ﬁeld. Since our keyword dataset contains
keywords “ﬁrst name” and “last name” for personal in-
formation, SUPOR can declare the two input ﬁelds are
sensitive.

Repeating the above steps for every input ﬁeld in the
app, SUPOR obtains a list of sensitive input ﬁelds. It
assigns an contextual ID to each sensitive input ﬁeld
in the form of <Layout_ID, Widget_ID>, where
Layout_ID is the ID of the layout that contains the in-
put ﬁeld and Widget_ID is the ID of the input ﬁeld
(i.e., the value of the attribute “android:id”).

3.5 Variable Binding

With the sensitive input ﬁelds identiﬁed in the previous
step, the variable binding component performs context-
sensitive analysis to bind the input ﬁelds to the variables
in the code. The sensitive input ﬁelds are identiﬁed using
contextual IDs, which include layout IDs and widget IDs.
These contextual IDs can be used to directly locate input
ﬁelds from the XML layout ﬁles. To ﬁnd out the vari-
ables that store the values of the input ﬁelds, SUPOR
leverages the binding mechanism provided by Android
to load the UI layout and bind the UI widgets with the
code. Such a binding mechanism enables SUPOR to as-
sociate input ﬁelds with the proper variables. We refer to
these variables the widget variables that are bound to the
input ﬁelds.

The variable binding component identiﬁes the in-
stances of the input ﬁelds in a context-insensitive fash-
ion via searching the code using the APIs provided by
the rapid UI development kit of Android. As shown in
Section 2.2, findViewById(ID) is an API that loads
a UI widget to the code. Its argument ID is the numeric
ID that speciﬁes which widget deﬁned in the XML to
load. Thus, to identify the instances of the input ﬁelds,
SUPOR searches the code for such method calls, and
compare their arguments to the widget IDs of the sensi-

USENIX Association  

24th USENIX Security Symposium  983

tive input ﬁelds. If the arguments match any widget ID of
the sensitive input ﬁelds, the return values of the corre-
sponding findViewById(ID) are considered as the
widget variables for the sensitive input ﬁelds.

One problem here is that developers may assign the
same widget ID to UI widgets in different layout ﬁles,
and thus different UI widgets are associated with the
same numeric ID in the code. Our preliminary analy-
sis on 5000 apps discovers that about 22% of the iden-
tiﬁed sensitive input ﬁelds have duplicate IDs within the
corresponding apps. Since the context-insensitive analy-
sis cannot distinguish the duplicate widget IDs between
layout ﬁles inside an app, a lot of false positives will be
presented.

To reduce false positives, SUPOR adds context-
sensitivity into the analysis, associating widget vari-
ables with their corresponding layouts. Similar to load-
ing a widget, the rapid UI development kit provides
APIs to load a UI layout into the code. For example,
setContentView(ID) with a numeric ID as the ar-
gument is used to load a UI layout to the code, as shown
at Line 6 in Figure 3. Any subsequent findViewById
with the ID WID as the argument returns the UI wid-
get identiﬁed by WID in the newly loaded UI layout,
not the UI widget identiﬁed by WID in the previous
UI layout. Thus, to ﬁnd out which layout is associ-
ated with a given widget variable, SUPOR traces back
to identify the closest method call that loads a UI lay-
out1 along the program paths that lead to the invocation
of findViewById. We next describe how SUPOR
performs context-sensitive analysis to distinguish widget
IDs between layout ﬁles. For the description below, we
use setContentView() as an example API.

Given a widget variable, SUPOR ﬁrst identiﬁes the
method call findViewById, and computes an inter-
procedural backward slice [18] of its receiver object,
i.e., the activity object. This backward slice traces back
from findViewById, and includes all statements that
may affect the state of the activity object. SUPOR
then searches the slice backward for the method call
setContentView, and uses the argument of the ﬁrst
found setContentView as the layout ID. For exam-
ple, in Figure 3, the widget variable txtUid is deﬁned
by the findViewById at Line 7, and the activity object
of this method call is an instance of LoginActivity.
From the backward slice of the activity object, the ﬁrst
method call setContentView is found at Line 6, and
thus its argument R.layout.login_activity is
associated with txtUid, whose widget ID is speciﬁed
by R.id.uid. Both R.layout.login_activity
and R.id.uid can be further resolved to identify their

1SUPOR considers both Activity.setContentView() and
LayoutInflater.inflate() as the methods to load UI layouts
due to their prevalence.

numeric IDs, and match with the contextual IDs of sensi-
tive input ﬁelds to determine whether txtUid is a wid-
get variable for a sensitive input ﬁeld.

3.6 Keyword Dataset Construction

To collect the sensitive keyword dataset, we crawl all
texts in the resource ﬁles from 54,371 apps, including
layout ﬁles and string resource ﬁles. We split the col-
lected texts based on newline character (\n) to form a
list of texts, and extract words from the texts to form a
list of words. Both of these lists are then sorted based on
the frequencies of text lines and words, respectively. We
then systematically inspect these two lists with the help
of the adapted NLP techniques. Next we describe how
we identify sensitive keywords in detail.

First, we adapt NLP techniques to extract nouns and
noun phrases from the top 5,000 frequent text lines. Our
technique ﬁrst uses Stanford parser [36] to parse each
text line into a syntactic tree as discussed in Section 2.4,
and then traverses the parse tree level by level to identify
nouns and noun phrases. For the text lines that do not
contain any noun or noun phrase, our technique ﬁlters
out these text lines, since such text lines usually con-
sist of only prepositions (e.g., to), verbs (e.g., update
please), or unrecognized symbols. From the top 5,000
frequent text lines, our technique extracts 4,795 nouns
and noun phrases. For the list of words, our technique
ﬁlters out words that are not nouns due to the similar rea-
sons. From the top 5,000 frequent words, our technique
obtains 3,624 words. We then manually inspect these two
sets of frequent nouns and noun phrases to identify sen-
sitive keywords. As phrases other than noun phrases may
indicate sensitive information, we further extract consec-
utive phrases consisting of two and three words from the
text lists and manually inspect the top 200 frequent two-
word and three-word phrases to expand our sensitive key-
word set.

Second, we expand the keyword set by searching the
list of text lines and the list of words using the identi-
ﬁed words. For example, we further ﬁnd “cvv code” for
credit card by searching the lists using the top-ranked
word “code”, and ﬁnd “national ID” by searching the
lists using the top-ranked word “id”. We also expand
the keywords using synonyms of the keywords based on
WordNet [11].

Third, we further expand the keywords by using
Google Translate to translate the keywords from English
into other languages. Currently we support Chinese and
Korean besides English.

These keywords are manually classiﬁed into 10 cate-
gories, and part of the keyword dataset is presented in
Table 3. Note that we do not use “Address” for the cate-
gory “Personal Info”. Although personal address is sen-
sitive information, our preliminary results show that this

984  24th USENIX Security Symposium 

USENIX Association

Table 3: Part of keyword dataset.

Category
Credential
Health
Identity
Credit Card
SSN
Personal Info
Financial Info
Contact
Account
Protection

Keywords
pin code, pin number, password
weight, height, blood type, calories
username, user ID, nickname
credit card number, cvv code
social security number, national ID
ﬁrst name, last name, gender, birthday
deposit amount, income, payment
phone number, e-mail, email, gmail
log in, sign in, register
security answer, identiﬁcation code

keyword also matches URL address bars in browsers,
causing many false positives. Also, we do not ﬁnd in-
teresting privacy disclosures based on this keyword in
our preliminary results, and thus “Address” is not used
in our keyword dataset. Although this keyword dataset
is not a complete dataset that covers every sensitive key-
word appearing in Android apps, our evaluation results
(in Section 5) show that it is a relatively complete dataset
for the ten categories that we focus on in this work.

4 Implementation
In this section, we provide the details of our implementa-
tion of SUPOR, including the frameworks and tools we
built upon and certain tradeoffs we make to improve the
effectiveness.

SUPOR accepts APK ﬁles as inputs, and uses a tool
built on top of Apktool [1] to extract resource ﬁles and
bytecode from the APK ﬁle. The Dalvik bytecode is
translated into an intermediate representation (IR), which
is based on dexlib in Baksmali [3]. The IR is further
converted to WALA [4] static single assignment for-
mat (SSA). WALA [4] works as the underlying analy-
sis engine of SUPOR, providing various functionalities,
e.g., call graph building, dependency graph building, and
point-to analysis.

The UI rendering engine is built on the UI render-
ing engine from the ADT Eclipse plug-ins Besides im-
proving the engine to better render custom widgets, we
also make the rendering more resilient using all avail-
able themes. Due to SDK version compatibility, not ev-
ery layout can be rendered in every theme. We try mul-
tiple themes until we ﬁnd a successful rendering. Al-
though different themes might make UI slightly differ-
ent, the effectiveness of our algorithm should not be af-
fected. The reason is that apps should not confuse users
in the successfully rendered themes, and thus our algo-
rithm designed to mimic what users see the UIs should
work accordingly.

To demonstrate the usefulness of SUPOR, we imple-
ment a privacy disclosure detection system by combining
SUPOR with static taint analysis. This system enables

us to conduct a study on the disclosures of sensitive user
inputs. We build a taint analysis engine on top of Daly-
sis [24] and make several customizations to improve the
effectiveness. The details of the customizations can be
found at Appendix A.2.

To identify sensitive user inputs, SUPOR includes to-
tally 11 source categories, including the 10 categories
listed in Section 3.6 and an additional category PwdLike
for the input ﬁelds identiﬁed as sensitive using their at-
tributes such as inputType. The PwdLike category is
prioritized if it has some overlapping with the other cat-
egories. Once the widget variables of the sensitive in-
put ﬁelds are found, we consider any subsequent method
calls on the variables that retrieve values from the input
ﬁelds as source locations, such as getText(). To iden-
tify privacy disclosures of the sensitive user inputs, SU-
POR mainly focuses on the information ﬂows that trans-
fer the sensitive data to the following two types of sinks:
(1) the sinks of output channels that send the informa-
tion out from the phone (e.g., SMS and Network) and
(2) the sinks of public places on the phone (e.g., logging
and content provider writes). More details are shown in
Appendix A.1.

Our implementation, excluding the underlying li-
braries and the core taint analysis engine, accounts for
about 4K source lines of code (SLoC) in Java.

5 Evaluations and Experiments

We conducted comprehensive evaluations on SUPOR
over a large number of apps downloaded from the of-
ﬁcial Google Play store. We ﬁrst evaluated the perfor-
mance of SUPOR and demonstrated its scalability. We
then measured the accuracy of the UI sensitiveness anal-
ysis and the accuracy of SUPOR in detecting disclosures
of sensitive user inputs. In addition, our case studies on
selected apps present practical insights of sensitive user
input disclosures, which are expected to contribute to a
community awareness.

5.1 Evaluation Setup

The evaluations of SUPOR were conducted on a clus-
ter of eight servers with an Intel Xeon CPU E5-1650 and
64/128GB of RAM. During the evaluations, we launched
concurrent SUPOR instances on 64-bit JVM with a
maximum heap space of 16GB. On each server 3 apps
were concurrently analyzed, so the cluster handled 24
apps in parallel.

In our evaluations, we used the apps collected from
the ofﬁcial Google Play store in June 2013. We applied
SUPOR to analyze 6,000 apps ranked by top downloads,
with 200 apps for each category. Based on the results of
the 6,000 apps, we further applied SUPOR on another
10,000 apps in 20 selected categories. Each of the 20
categories is found to have at least two apps with sensi-

USENIX Association  

24th USENIX Security Symposium  985

Table 4: Statistics of 16,000 apps.

Without Layout Files
Without Input Fields
Without Sensitive Input Fields
With Sensitive Input Fields
Parsing Errors
TOTAL

tive user input disclosures.

#Apps
625
5,711
4,731
4,922
11
16,000

Percentage
3.91%
35.69%
29.57%
30.76%
0.07%
100.00%

For each app, if it contains at least one input ﬁeld in
layout ﬁles, the app is analyzed by the UI sensitiveness
analysis. If SUPOR identiﬁes any sensitive input ﬁeld of
the app, the app is further analyzed by the taint analysis
to detect sensitive user input disclosures. Table 4 shows
the statistics of these apps. A small portion of the apps
do not contain any layout ﬁles and about 1/3 of the apps
do not have any input ﬁeld in layout ﬁles. This is rea-
sonable because many Game apps do not require users to
enter information. 35% of the apps without layout ﬁles
and 17% of the apps without input ﬁelds belong to dif-
ferent sub-categories of games. 11 apps (0.07%) cannot
be analyzed by SUPOR due to various parsing errors in
rendering their layout ﬁles. In total, 60.33% of the apps
contain input ﬁelds in their layout ﬁles, among which
more than half of the apps are further analyzed because
sensitive input ﬁelds are found via the UI sensitiveness
analysis.

As not every layout containing input ﬁelds is identiﬁed
with sensitive input ﬁelds, we show the statistics of the
layouts for the 4,922 apps identiﬁed with sensitive input
ﬁelds. Among these apps, 47,885 layouts contain input
ﬁelds and thus these layouts are rendered. Among the
rendered layouts, 19,265 (40.2%) are found to contain
sensitive keywords (no matter whether the keywords are
associated with any input ﬁeld). This is the upper bound
of the number of layouts that can be identiﬁed with sen-
sitive input ﬁelds. In fact, 17,332 (90.0%) of the 19,265
layouts with sensitive keywords are identiﬁed with sen-
sitive input ﬁelds.

5.2 Performance Evaluation

The whole experiment for 16,000 apps takes 1439.8 min-
utes, making a throughput of 11.1 apps per minutes on
the eight-server cluster. The following analysis is only
for the 4,922 apps identiﬁed with sensitive input ﬁelds, if
not speciﬁed.

The UI analysis in SUPOR includes decompiling
APK ﬁles, rendering layouts, and performing UI sen-
sitiveness analysis. For each app with sensitive input
ﬁelds, SUPOR needs to perform the UI analysis for at
least 1 layout and at most 190 layouts, while the median
number is 7 and the average number is 9.7. Though the
largest execution time required for this analysis is about 2

minutes. 96.3% of the apps require less than 10 seconds
to render all layouts in an app. The median analysis time
is 5.2 seconds and the average time is 5.7 seconds for one
app. Compared with the other parts of SUPOR, the UI
analysis is quite efﬁcient, accounting for only 2.5% of the
total analysis time on average. Also, the UI sensitiveness
analysis, including the correlation score computation and
keyword matching, accounts for less than 1% of the to-
tal UI analysis time, while decompiling APK ﬁles and
rendering layouts take most of the time.

To detect sensitive user input disclosures, our evalua-
tion sets a maximum analysis time of 20 minutes. 18.1%
of the apps time out in our experiments but 73.7% require
less than 10 minutes. The apps with many entry points
tend to get stuck in taint analysis, and are more likely
to timeout. Scalability of static taint analysis is a hard
problem, but we are not worse than related work. The
timeout mechanism is enforced for the whole analysis,
but the system will wait for I/O to get partial results. In
practice, we can allow a larger maximum analysis time
so that more apps can be analyzed. Among the apps ﬁn-
ished in time, the median analysis time is 1.9 minutes
and the average analysis time is 3.7 minutes.

The performance results show that SUPOR is a scal-
able solution that can statically analyze UIs of a massive
number of apps and detect sensitive user input disclo-
sures on these apps. Compared with existing static taint
analysis techniques, the static UI analysis introduced in
this work is highly efﬁcient, and its performance over-
head is negligible.

5.3 Effectiveness of UI Sensitiveness Analysis

To evaluate the accuracy of the UI sensitiveness analysis,
we randomly select 40 apps and manually inspect the UIs
of these 40 apps to measure the accuracy of the UI sen-
sitiveness analysis.

First, we randomly select 20 apps reported without
sensitive input ﬁelds, and manually inspect these apps
to measure the false negatives of SUPOR. In these apps,
the largest number of layouts SUPOR renders is 5 and
the total number of layouts containing input ﬁelds is 39
(1.95 layouts per app). SUPOR successfully renders 38
layouts and identiﬁes 57 input ﬁelds (2.85 input ﬁelds
per app). SUPOR fails to render 1 layout due to the
lack of necessary themes for a third-party library. By an-
alyzing these 57 input ﬁelds, we conﬁrm that SUPOR
has only one false negative (FN), i.e., failing to mark one
input ﬁeld as sensitive in the app com.strlabs.appdietas.
This input ﬁeld requests users to enter their weights, be-
longing to the Health category in our keyword dataset.
However, the text of the descriptive text label for the in-
put ﬁeld is “Peso de hoy”, which is “Today Weight” in
Spanish. Since our keyword dataset focuses on sensitive
keywords in English, SUPOR has a false negative. Such

986  24th USENIX Security Symposium 

USENIX Association

false negatives can be reduced by expanding our keyword
dataset to support more languages.

Second, we randomly select 20 apps reported with sen-
sitive input ﬁelds. Table 5 shows the detailed analysis re-
sults. Column “#Layouts ” counts the number of layouts
containing input ﬁelds in each app, while Column “#Lay-
outs with Sensitive Input Fields” presents the number
of layouts reported with sensitive input ﬁelds. Column
“#Input Fields” lists the total number of input ﬁelds in
each app and Column “#Reported Sensitive Input Fields”
gives the detailed information about how many input
ﬁelds are identiﬁed by checking the inputType at-
tribute, by matching the hint text, and by analyzing the
associated text labels. Sub-Column “Total” presents the
total number of sensitive input ﬁelds identiﬁed by SU-
POR in each app. Columns “FP” and “FN” show the
number of false positives and the number of false neg-
atives produced by SUPOR in classifying input ﬁelds.
Column “Duplicate ID” shows if an app contains any
duplicate widget ID for sensitive input ﬁelds. These du-
plicate IDs belong to either sensitive input ﬁelds (rep-
resented by ◦) or non-sensitive input ﬁelds (•). For all
the layouts in these 20 apps, SUPOR successfully ren-
ders the layouts except for App 18, which has 29 layouts
containing input ﬁelds but SUPOR renders only 17 lay-
outs. The reason is that Apktool fails to decompile the
app completely.

T P

T P

The results show that for these 20 apps, SUPOR iden-
tiﬁes 149 sensitive input ﬁelds with 4 FPs and 3 FNs, and
thus the achieved true positives (TP) is 145. Combined
with the 20 apps identiﬁed without sensitive input ﬁelds
(0 FP and 1 FN), SUPOR achieves an average precision
of 97.3% (precision =
T P+FP = 145/149) and an average
recall of 97.3% (recall =

T P+FN = 145/(145+(1+3)).

We next describe the reasons for the FNs and the FPs.
SUPOR has two false negatives in App 1, in which the
text label “Answer” is not identiﬁed as a sensitive key-
word. But according to the context, it means “secu-
rity answer”, which should be sensitive. Although this
phrase is modeled as a sensitive phrase in our keyword
dataset, SUPOR cannot easily associate “Answer” with
the phrase, resulting in a false negative. In App 8, SU-
POR marks an input ﬁeld as sensitive because the asso-
ciated text label containing the keyword “Height”. How-
ever, based on the context, the app actually asks the user
to enter the expected page height of a PDF ﬁle. Such
issues can be alleviated by employing context-sensitive
NLP analysis [19].

SUPOR also has two FPs in App 6 and App 8 due to
the inaccuracy of text label association. In App 6 shown
in Figure 9, the hint of the “Delivery Instructions” in-
put ﬁeld does not contain sensitive keywords, and thus
SUPOR identiﬁes the close text label for determining
its sensitiveness. However, SUPOR incorrectly asso-

Figure 9: False positive example in UI sensitiveness
analysis.

ciates a description label of “Email” to the “Delivery
Instructions” input ﬁeld based on their close distances.
Since this description contains sensitive keywords such
as email, SUPOR considers the “Delivery Instructions”
input ﬁeld as sensitive, causing a false positive. Finally,
SUPOR has both FPs and FNs for App 14, since its ar-
rangements of input ﬁelds and their text labels are not
accurately captured by our position-based weights that
give preferences for left and top positioned text labels.

To evaluate the effectiveness of resolving duplicate
IDs, We instrumented SUPOR to output detailed in-
formation when identifying the widget variables. We
did not ﬁnd any case where SUPOR incorrectly asso-
ciates the widget variables with the input ﬁelds based on
the contextual IDs, but potentially SUPOR may have
inaccurate results due to infeasible sequences of entry
points that can be executed. We next present an exam-
ple to show how backward slicing help SUPOR distin-
guish duplicate widget IDs. App 17 has two layouts with
the same hierarchy. Layout A contains a sensitive in-
put ﬁeld with the ID w1 while Layout B contains a non-
sensitive input ﬁeld with the same ID w1. Both layouts
are loaded via LayoutInflater.inflate and then
findViewById is invoked separately to obtain the en-
closed input ﬁelds. Without the backward slicing, SU-
POR considers the input ﬁeld with the ID w1 in the
Layout B as sensitive, which is a false positive. With
the backward slicing, SUPOR can distinguish the input
ﬁeld with the ID w1 in Layout B with the input ﬁeld with
the ID w1 in Layout A, and correctly ﬁlter out the non-
sensitive input ﬁeld in Layout B.

5.4 Accuracy of Detecting Sensitive User Input Dis-

closures

In our experiments, 355 apps are reported with sensitive
user input disclosures. The reported apps belong to 25
out of the 30 categories in Google Play Store and 20 cat-
egories have at least 2 apps reported. We next report the
accuracy of detecting sensitive user input disclosures.

Figure 10 shows the number of true positives and the
number of false positives by taint source and sink cat-
egories. If an app is reported with multiple disclosure
ﬂows and one of them is a false positive, the app is con-
sidered as a false positive. Through manually evaluating
the 104 apps reported cases from the ﬁrst 6,000 analyzed
apps, we ﬁnd false positives in 9 apps. Therefore, the
overall false positive rate is about 8.7%, i.e., the accu-

USENIX Association  

24th USENIX Security Symposium  987

Table 5: UI analysis details for 20 randomly chosen apps.

#Layouts

#Input
Fields

#Layouts with

Sensitive Input Fields

#Reported Sensitive Input Fields
Password Hint
Total

Label

FP

FN Duplicate

8
37
3
4
5
17
4
15
3
7
5
17
26
2
14
4
4
29
24
1
229

18
77
3
9
7
52
5
22
7
16
6
33
60
8
26
7
8
25
37
2
428

4
2
1
3
1
10
2
9
1
1
1
8
10
2
5
1
3
4
8
1
77

6
0
0
0
1
6
0
8
1
0
1
8
0
1
2
1
2
4
9
0
50

0
0
1
0
0
12
0
3
1
0
1
9
0
0
3
0
3
0
6
2
41

3
8
0
6
0
12
3
2
0
1
0
0
12
4
0
0
0
6
1
0
58

9
8
1
6
1
30
3
13
2
1
2
17
12
5
5
1
5
10
16
2
149

2

1

1

2

1

4

3

ID

◦

◦

◦

◦ •
◦ •

◦ •

•
◦
◦

App
ID
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
Total

60
50
40
30
20
10
0

70
60
50
40
30
20
10
0

False Positives
True Positives

3/54

3/42

0/1

SSN

0/2

0/4

Credit Card Account

0/5

Personal

Info

1/8

2/9

1/11

Health

Credential

Identity

PwdLike

Contact

(a) TPs and FPs by source categories.

False Positives
True Positives

5/54

5/44

0/2

SMS Send

1/4

Content Provider

Write

Network

Logging

(b) TPs and FPs by sink categories.

Figure 10: True positives and false positives by
source/sink categories for the reported apps.

racy of privacy disclosure detection is 91.3%. We in-
vestigated the false positives and found that these false
positives were mostly resulted from the limitations of the
underlying taint analysis framework, such as the lack of
accurate modeling of arrays.

5.5 Case Studies

To improve the community’s awareness and understand-
ing of sensitive user input disclosures, we conducted
cases studies on four selected apps from the source cat-
egories SSN, PwdLike, Credit Card, and Health. These
case studies present interesting facts of sensitive user in-

put disclosures, and also demonstrate the usefulness of
SUPOR. We also inform the developers of the apps men-
tioned in this section about the detected disclosures.

com.yes123.mobile is an app for job hunting. The
users are required to register with their national ID and a
password to use the service. When the users input the ID
and password, and then click log in2, the app sends both
their national IDs and passwords via Internet without any
protection (e.g., hashing or through HTTPS channel).
Since national ID is quite sensitive (similar as Social Se-
curity Number), such limited protection in transmission
may lead to serious privacy disclosure problems.

The second example app (craigs.pro.plus) shows a le-
gitimate disclosure that uses HTTPS connections to send
user sensitive inputs to its server for authentication. Even
though the password itself is not encoded (e.g., hashing),
we believe HTTPS connections provide a better protec-
tion layer to resist the disclosures during communica-
tions. Also we ﬁnd that popular apps developed by en-
terprise companies are more likely to adopt HTTPS, pro-
viding better protection for their users.

To better understand whether sensitive user inputs are
properly protected, we further inspect 104 apps, of which
44 apps send sensitive user inputs via network. Among
these 44 apps, only 10 of them adopt HTTPS connec-
tions, while the majority of apps transmit sensitive user
inputs in plain text via HTTP connections. Such study

2The UI is shown in Figure 12 in Appendix B.1.

988  24th USENIX Security Symposium 

USENIX Association

In this work, we have demonstrated that
user inputs.
SUPOR can be combined with static taint analysis to
automatically detect potential sensitive user input disclo-
sures. Such analysis can be directly employed by app
markets to raise warnings, or by developers to verify
whether their apps accidentally disclose sensitive user in-
puts. Also, SUPOR can be paired with dynamic taint
analysis to alert users before the sensitive user inputs es-
cape from the phones.

SUPOR focuses on input ﬁelds, a major type of UI
widgets to collect user inputs. Such UI widgets record
what user type and contain high entropy, unlike yes/no
buttons which contain low entropy. It is quite straight-
forward to extend our current approach to handle more
diverse widgets.

SUPOR chooses the light-weight keyword-based
technique to determine the sensitiveness of input ﬁelds
since the texts contained in the associated text labels are
usually short and straightforward to understand. Our
evaluations show that in general these keywords are
highly effective in determining the sensitiveness of in-
put ﬁelds. Certain keywords may produce false positives
since these keywords have different meanings under dif-
ferent contexts. To alleviate such issues, we may lever-
age more advanced NLP techniques that consider con-
texts [19].

7 Related Work

Many great research works [6, 8–10, 12, 14, 16, 23, 24,
34, 38] focus on privacy leakage problems on predeﬁned
sensitive data sources on the phone. SUPOR identiﬁes
sensitive user inputs, and may enable most of the ex-
isting research on privacy studies to be applied to sen-
sitive user inputs. As a result, our research compli-
ments the existing works. FlowDroid [6] also employs
a limited form of sensitive input ﬁelds—password ﬁelds.
Compared with FlowDroid, we leverage static UI ren-
dering and NLP techniques to identify different cate-
gories of sensitive input ﬁelds in an extensible manner.
Susi [33] employs a machine learning approach to de-
tect pre-deﬁned source/sinks from Android Framework.
In contrast, SUPOR focus on a totally different type of
sensitive sources–user inputs through GUI.

Moreover, a few approaches are designed for con-
trolling the known privacy leaks. AppFence [17] em-
ploys fake data or network blocking to protect privacy
leaks to Internet with user supplied policies. Nadkarni et
al.provide new OS mechanisms for proper information
sharing cross apps [28].

NLP techniques have been used to study app de-
scriptions [13, 30, 31]. WHYPER [30] and AutoCog
[31] leverages NLP techniques to understand whether
the application descriptions reﬂect the permission usage.
CHABADA [13] also applies topic modelling, an NLP

Figure 11: Case study: credit card information disclosure
example.

results indicate that most developers are still unaware of
the risks posed by sensitive user input disclosures, and
more efforts should be devoted to provide more protec-
tions on sensitive user inputs.

Our last example app (com.nitrogen.android) dis-
closes credit card information, a critical ﬁnancial infor-
mation provided by the users. Figure 11 shows the ren-
dered UI of the app. The three input ﬁelds record credit
card number, credit card security number, and the card
holder’s name. Because these ﬁelds are not decorated
with textPassword input type and they do not con-
tain any hints, SUPOR uses the UI sensitiveness analysis
to compute correlation scores for each text label. As we
can see from the UI, the text label “Credit Card Num-
ber” and the text label “Credit Card Security Number”
are equally close to the ﬁrst input ﬁeld. As our algo-
rithm considers weights based on the relative positions
between text labels and input ﬁelds, SUPOR correctly
associates the corresponding text labels for these three
input ﬁelds, and the taint analysis identiﬁes sensitive user
input disclosures for all these three input ﬁelds to log-
ging. SUPOR also identiﬁes apps that disclose personal
health information to logging, and the example app is
shown in Appendix B.2.

Although Google tries to get rid of some of the known
sinks that contribute most of the public leaks by releasing
new Android versions, many people globally may still
continue using older Android releases for a very long
time (about 14.2% of Android phones globally using ver-
sions older than Jelly Bean [2]).
If malware accesses
the logs on these devices, all the credit card information
can be exploited to malicious adversaries. Thus, certain
level of protection is necessary for older versions of apps.
Also, SUPOR ﬁnds that some apps actually sanitize the
sensitive user inputs (e.g., hashing) before these inputs
are disclosed in public places on the phone, indicating
that a portion of developers do pay attention to protect-
ing sensitive user input disclosures on the phone.

6 Discussion

SUPOR is designed as an effective and scalable solu-
tion to screening a large number of apps for sensitive

USENIX Association  

24th USENIX Security Symposium  989

technique to detecting malicious behaviors of Android
apps. It generates clusters according to the topic, which
consists of a cluster of words that frequently occur to-
gether. Then, it tries to detect the outliers as malicious
behaviors. CHABADA does not focus on detecting pri-
vacy leaks. On the other hand, SUPOR leverages NLP
techniques to identify sensitive keywords and further use
those keywords to classify the descriptive text labels and
the associated input ﬁelds.

Furthermore, there are a few important related works
using UI related information to detect different types of
vulnerabilities and attacks. AsDroid [20] checks UI text
to detect the contradiction between expected behavior in-
ferred from the UI and the program behavior represented
by APIs. Chen et al.study the GUI spooﬁng vulnerabil-
ities in IE browser [7]. Mulliner et al.discover GUI ele-
ment misuse (GEM), a type of GUI related access control
violation vulnerabilities and design GEM Miner to auto-
matically detect GEMs [27]. SUPOR focuses on sensi-
tive user input identiﬁcation which is different from the
problems studied by these existing works.

The closest related work is UIPicker [29], which also
focuses on sensitive user input identiﬁcation. UIPicker
uses supervised learning to train a classiﬁer based on the
features extracted from the texts and the layout descrip-
tions of the UI elements. It also considers the texts of the
sibling elements in the layout ﬁle. Unlike UIPicker that
uses sibling elements in the layout ﬁle as the description
text for a UI widget, which could easily include unre-
lated texts as features, SUPOR selects only the text la-
bels that are physically close to input ﬁelds in the screen,
mimicking how users look at the UI, and uses the texts
in the text labels to determine the sensitiveness of the
input ﬁelds. Also, their techniques in extracting privacy-
related texts could complement our NLP techniques to
further improve our keyword dataset construction.

In the software engineering domain, there are quite a
few efforts on GUI reverse engineering [25, 26, 32, 35]
for GUI testing. GUITAR is a well-known framework
for general GUI testing, and GUI ripper [26], a com-
ponent of GUITAR targets general desktop applications,
uses dynamic analysis to extract GUI related informa-
tion and requires human intervention when the tools can-
not ﬁll in proper information in the applications. In [25]
and [32], two different approaches have been proposed to
convert the hard-coded GUI layout to model-based lay-
out (such as XML/HTML layout). GUISurfer leverages
source code to derive the relationships between different
given UI widgets. In contract, SUPOR focuses on mo-
bile apps and in particular Android apps, and leverages
the facility from existing rapid UI development kits to
identify and render UI widgets statically.

8 Conclusions
In this paper, we study the possibility of scalably detect-
ing sensitive user inputs, an important yet mostly ne-
glected sensitive source in mobile apps. We leverage
the rapid UI development kits of modern mobile OSes
to detect sensitive input ﬁelds and correlate these input
ﬁelds to the app code, enabling various privacy analyses
on sensitive user inputs. We design and implement SU-
POR, a new static analysis tool that automatically iden-
tiﬁes sensitive input ﬁelds by analyzing both input ﬁeld
attributes and surrounding descriptive text labels through
static UI parsing and rendering. Leveraging NLP tech-
niques, we build mobile app speciﬁc sensitive word vo-
cabularies that can be used to determine the sensitiveness
of given texts. To enable various privacy analyses on sen-
sitive user inputs, we further propose a context-sensitive
approach to associate the input ﬁelds with corresponding
variables in the app code.

To demonstrate the usefulness of SUPOR, we build a
privacy disclosure discovery system by combining SU-
POR with static taint analysis to analyze the sensitive in-
formation of the variables that store the user inputs from
the identiﬁed sensitive input ﬁelds. We apply the system
to 16,000 popular Android apps, and SUPOR achieves
an average precision of 97.3% and also an average re-
call of 97.3% in detecting sensitive user inputs. SUPOR
ﬁnds 355 apps with privacy disclosures and the false pos-
itive rate is 8.7%. We also demonstrate interesting real-
world cases related to national ID, username/password,
credit card and health information.

9 Acknowledgements
The authors would like to thank the anonymous review-
ers for their insightful comments that helped improve the
presentation of this paper. Jianjun Huang and Xiangyu
Zhang are supported, in part, by National Science Foun-
dation (NSF) under grants 0845870, 1320444, 1320326
and 1409668. Any opinions, ﬁndings, and conclusions
or recommendations in this paper are those of the authors
and do not necessarily reﬂect the views of NSF.

References

[1] Android-ApkTool: A tool for reverse engineering Android
https://code.google.com/p/android-

apk ﬁle.
apktool.

[2] Android Dashboards.

https://developer.android.
com/about/dashboards/index.html. Accessed: 20
Feb 2015.

[3] Baksmali: a disassembler for Android’s dex format. https://

code.google.com/p/smali.

[4] WALA: T.J. Watson Libraries for Analysis. http://wala.

sourceforge.net.

[5] ARP, D., SPREITZENBARTH, M., HUBNER, M., GASCON, H.,
AND RIECK, K. DREBIN: Effective and explainable detection
of Android malware in your pocket. In NDSS (2014).

990  24th USENIX Security Symposium 

USENIX Association

[6] ARZT, S., RASTHOFER, S., FRITZ, C., BODDEN, E., BARTEL,
A., KLEIN, J., LE TRAON, Y., OCTEAU, D., AND MCDANIEL,
P. FlowDroid: Precise context, ﬂow, ﬁeld, object-sensitive and
lifecycle-aware taint analysis for Android apps. In PLDI (2014).
[7] CHEN, S., MESEGUER, J., SASSE, R., WANG, H. J., AND
WANG, Y.-M. A systematic approach to uncover security ﬂaws
in GUI logic. In S&P (Oakland) (2007).

[8] EGELE, M., KRUEGEL, C., KIRDA, E., AND VIGNA, G. PiOS:

Detecting privacy leaks in iOS applications. In NDSS (2011).

[9] ENCK, W., GILBERT, P., CHUN, B.-G., COX, L. P., JUNG, J.,
MCDANIEL, P., AND SHETH, A. N. TaintDroid: an information-
ﬂow tracking system for realtime privacy monitoring on smart-
phones. In OSDI (2010).

[10] ENCK, W., OCTEAU, D., MCDANIEL, P., AND CHAUDHURI,
S. A study of Android application security. In USENIX Security
(2011).

[11] FELLBAUM, C., Ed. WordNet An Electronic Lexical Database.

The MIT Press, 1998.

[12] GIBLER, C., CRUSSELL, J., ERICKSON, J., AND CHEN, H. An-
droidLeaks: Automatically detecting potential privacy leaks in
Android applications on a large scale. In TRUST (2012).

[13] GORLA, A., TAVECCHIA, I., GROSS, F., AND ZELLER, A.
Checking app behavior against app descriptions. In ICSE (2014).
[14] GRACE, M., ZHOU, Y., WANG, Z., AND JIANG, X. Systematic
In

detection of capability leaks in stock Android smartphones.
NDSS (2012).

[15] GRACE, M., ZHOU, Y., ZHANG, Q., ZOU, S., AND JIANG,
X. Riskranker: Scalable and accurate zero-day Android malware
detection. In MobiSys (2012).

Figure 12: Case study: national ID and password disclo-
sure example without protection.

[26] MEMON, A., BANERJEE, I., AND NAGARAJAN, A. GUI rip-
ping: Reverse engineering of graphical user interfaces for testing.
In WCRE (2003).

[27] MULLINER, C., ROBERTSON, W., AND KIRDA, E. Hidden
GEMs: Automated discovery of access control vulnerabilities in
graphical user interfaces. In S&P (Oakland) (2014).

[28] NADKARNI, A., AND ENCK, W. Preventing accidental data dis-

closure in modern operating systems. In CCS (2013).

[29] NAN, Y., YANG, M., YANG, Z., ZHOU, S., GU, G., AND
WANG, X. UIPicker: User-input privacy identiﬁcation in mo-
bile applications. In USENIX Security (2015).

[30] PANDITA, R., XIAO, X., YANG, W., ENCK, W., AND XIE, T.
WHYPER: Towards automating risk assessment of mobile appli-
cations. In USENIX Security (2013).

[31] QU, Z., RASTOGI, V., ZHANG, X., CHEN, Y., ZHU, T., AND
CHEN, Z. AutoCog: Measuring the description-to-permission
ﬁdelity in Android applications. In CCS (2014).

[16] HAN, J., YAN, Q., GAO, D., ZHOU, J., AND DENG, R. Com-
paring mobile privacy protection through cross-platform applica-
tions. In NDSS (2013).

[32] RAMÓN, Ó. S., CUADRADO, J. S., AND MOLINA, J. G. Model-
driven reverse engineering of legacy graphical user interfaces.
Automated Software Engineering 21, 2 (2014).

[17] HORNYACK, P., HAN, S., JUNG, J., SCHECHTER, S., AND
WETHERALL, D. These aren’t the droids you’re looking for:
Retroﬁtting Android to protect data from imperious applications.
In CCS (2011).

[18] HORWITZ, S., REPS, T., AND BINKLEY, D.

Interprocedural
slicing using dependence graphs. SIGPLAN Not. 23, 7 (June
1988).

[19] HUANG, E. H., SOCHER, R., MANNING, C. D., AND NG, A. Y.
Improving word representations via global context and multiple
word prototypes. In ACL (2012).

[20] HUANG, J., ZHANG, X., TAN, L., WANG, P., AND LIANG, B.
Asdroid: Detecting stealthy behaviors in Android applications
by user interface and program behavior contradiction.
In ICSE
(2014).

[21] JURAFSKY, D., AND MARTIN, J. H. Speech and Language Pro-
cessing: An Introduction to Natural Language Processing, Com-
putational Linguistics, and Speech Recognition, 1st ed. Prentice
Hall PTR, Upper Saddle River, NJ, USA, 2000.

[22] KLEIN, D., AND MANNING, C. D. Accurate unlexicalized pars-

ing. In ACL (2003).

[23] LU, K., LI, Z., KEMERLIS, V., WU, Z., LU, L., ZHENG, C.,
QIAN, Z., LEE, W., AND JIANG, G. Checking more and alerting
less: Detecting privacy leakages via enhanced data-ﬂow analysis
and peer voting. In NDSS (2015).

[24] LU, L., LI, Z., WU, Z., LEE, W., AND JIANG, G. CHEX:
Statically vetting Android apps for component hijacking vulner-
abilities. In CCS (2012).

[25] LUTTEROTH, C. Automated reverse engineering of hard-coded

GUI layouts. In AUIC (2008).

[33] RASTHOFER, S., ARZT, S., AND BODDEN, E. A machine-
learning approach for classifying and categorizing Android
sources and sinks. In NDSS (2014).

[34] RASTOGI, V., CHEN, Y., AND ENCK, W. AppsPlayground:
Automatic security analysis of smartphone applications. In ASI-
ACCS (2013).

[35] SILVA, J. C., SILVA, C., GONÇALO, R. D., SARAIVA, J., AND
CAMPOS, J. C. The GUISurfer tool:
towards a language in-
dependent approach to reverse engineering GUI code. In EICS
(2010).

[36] The Stanford Natural Language Processing Group, 1999.

http://nlp.stanford.edu/.

[37] SOCHER, R., BAUER, J., MANNING, C. D., AND NG, A. Y.

Parsing with compositional vector grammars. In ACL (2013).

[38] YANG, Z., YANG, M., ZHANG, Y., GU, G., NING, P., AND
WANG, X. S. AppIntent: Analyzing sensitive data transmission
in Android for privacy leakage detection. In CCS (2013).

[39] ZHOU, Y., AND JIANG, X. Dissecting Android malware: Char-

acterization and evolution. In S&P (Oakland) (2012).

[40] ZHOU, Y., AND JIANG, X. Detecting passive content leaks and

pollution in Android applications. In NDSS (2013).

Appendix

A Taint Analysis

The details of sinks and customizations of the taint
analysi engine are shown in this section.

USENIX Association  

24th USENIX Security Symposium  991

A.1 Sink Dataset

The sink dataset
includes ﬁve categories of sink
APIs, among which two categories are SMS send
and
(e.g.,SmsManager.sendTextMessage())
Network (e.g.,HttpClient.execute()).
The
other
log-
provider writes
ging
(e.g.,ContentResolver.insert()),
local
ﬁle writes (e.g.,OutputStream.write()). Totally
there are 236 APIs.

three are related to local storage:
(e.g.,Log.d()),

content

and

A.2 Customizations of Taint Analysis

Our taint analysis engine constraints the taint prop-
agation to only variables and method-call returns of
String type. Therefore, method calls that return prim-
itive types (e.g.,int) are ignored. There are two major
reasons for making this tradeoff. The ﬁrst is that the sen-
sitive information categories we focus on are passwords,
user names, emails, and so on, and these are usually not
numeric values. The second is that empirically we found
a quite number of false positives related to ﬂows of prim-
itive types due to the incompleteness of API models for
the Android framework. This observation-based reﬁne-
ment suppresses many false positives. For example, one
false warning we observed is that the length of a tainted
string (tainted.length()) is logged, and tracking
such length causes too many false positives afterwards.
Since such ﬂow does not disclose signiﬁcant information
of the user inputs, removing the tracking of such primi-
tive values reduces the sources to track and improves the
precision of the tracking.

To further suppress false warnings, we model data
structures of key-value pairs, such as Bundle and
BasicNameValuePair. Bundle is widely used
for storing an activity’s previously frozen state, and
BasicNameValuePair is usually used to encode
name-value pairs for HTTP URL parameters or other
web transmission parameters, such as JSON. For each
detected disclosure ﬂow, we record the keys when the

analysis ﬁnds method calls that insert values into the data
structures, e.g.,bundle.put("key1", tainted).
For any subsequent method call that retrieves values
from the data structures, e.g.,bundle.get("key2"),
we compare the key for retrieving values key2 with the
recorded keys. If no matches are found, we ﬁlter out the
disclosure ﬂow.

B Example Apps in Case Studies

B.1 Example App for Disclosing National IDs

The UI for the ﬁrst example app described in Section 5.5,
com.yes123.mobile, is shown in Figure 12.

Figure 13: Case study: health information disclosure.

B.2 Example App for Disclosing Health Informa-

tion

Figure 13 shows the rendered UI of the layout dpacacl
in app com.canofsleep.wwdiary, which belongs to the
category HEALTH && FITNESS. This app discloses
personal health information through the user inputs col-
lected from the UI. As we can see, even though all input
ﬁelds on the UI hold hint texts, these texts do not contain
any sensitive keywords. Therefore, SUPOR still needs
to identify the best descriptive text label for each input
ﬁeld. Based on the UI sensitiveness analysis, SUPOR
successfully marks the ﬁrst three input ﬁelds as sensi-
tive, i.e., the input ﬁelds that accept weight, height and
age. But based on the taint analysis, only the ﬁrst two in-
put ﬁelds are detected with disclosure ﬂows to logging.
Similar to ﬁnancial information, such health information
about users’ wellness is also very sensitive to the users.

992  24th USENIX Security Symposium 

USENIX Association

