iSeeYou: Disabling the MacBook  

Webcam Indicator LED

Matthew Brocker and Stephen Checkoway, Johns Hopkins University

https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/brocker

This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXUSENIX Association  

23rd USENIX Security Symposium  337

iıSeeYou:DisablingtheMacBookWebcamIndicatorLEDMatthewBrockerJohnsHopkinsUniversityStephenCheckowayJohnsHopkinsUniversityAbstractTheubiquitouswebcamindicatorLEDisanimportantprivacyfeaturewhichprovidesavisualcuethatthecam-eraisturnedon.WedescribehowtodisabletheLEDonaclassofAppleinternaliSightwebcamsusedinsomeversionsofMacBooklaptopsandiMacdesktops.Thisenablesvideotobecapturedwithoutanyvisualindicationtotheuserandcanbeaccomplishedentirelyinuserspacebyanunprivileged(non-root)application.ThesametechniquethatallowsustodisabletheLED,namelyreprogrammingtheﬁrmwarethatrunsontheiSight,enablesavirtualmachineescapewherebymalwarerunninginsideavirtualmachinereprogramsthecameratoactasaUSBHumanInterfaceDevice(HID)keyboardwhichexecutescodeinthehostoperatingsystem.Webuildtwoproofs-of-concept:(1)anOSXapplica-tion,iSeeYou,whichdemonstratescapturingvideowiththeLEDdisabled;and(2)avirtualmachineescapethatlaunchesTerminal.appandrunsshellcommands.Tode-fendagainsttheseandrelatedthreats,webuildanOSXkernelextension,iSightDefender,whichprohibitsthemodiﬁcationoftheiSight’sﬁrmwarefromuserspace.1IntroductionVideoisineffablycompelling.The(consensual)shar-ingofvideoisanactofintimacyasitallowsthevieweraglimpseintothelifeofthesharer.ItisnosurprisethenthattheInternet’sﬁrst“lifecast,”JenniferRingley’s“JenniCam”in1996[24],wasvideoandnotaudio.Simi-larly,YouTube,themostpopularwebsiteforsharinguser-createdvideos,predatesSoundCloud,awebsitewithsim-ilarfunctionalityforaudio,byseveralyearseventhoughtechnologicalconstraintswouldsuggesttheoppositeor-der.Itispreciselybecauseoftheintimacyofvideothatturningonsomeone’scamerawithouthisorherknowl-edgeorconsentisaviolationmorefundamentalthanrecordingaudio.Beyondintentionalsharing,videomakesformorecompellingevidencethataneventoccurredasclaimedthaneitheranafter-the-facteyewitnessaccountoraudiorecording.Thisistruewhetheritisavideoofasuc-cessfullyperformedfeatofskill—e.g.,insports[44]orevenvideogames[49]—videoofpolicebrutality[55],videoofviolentcrime[63],orwebcamvideousedforblackmail[15].(a)Imagesensor(front)(b)Imagesensor(back)(c)Mainboard(front)(d)Mainboard(back)Figure1:TheiSightfroma2008MacBookwestudied.ThevalueofvideoevidenceissohighthatTheWash-ingtonPostrecentlyreportedthattheUSFederalBureauofInvestigation(FBI),hasdevelopedsurveillancemal-ware,similartotheproof-of-conceptdescribedinthispaper,whichcancovertlyturnonavictim’swebcam[59].Ofcourse,thethreattoprivacyfromwebcamsvulnerabletohackingcomesnotonlyfromlawenforcement.Atthebeginningofthe2008schoolyear,theLowerMerionSchoolDistrictprovidedaMacBooklaptoptoeachenrolledstudent.Theselaptopscamepre-loadedwiththeLANrevremoteadministrationtool(RAT)whichallowedschooldistrictofﬁcialsto,amongotherthings,captureimagesfromtheMacBooks’built-iniSightweb-cam.Duringthefollowing18months,ofﬁcialscapturedmorethan30thousandimagesfromthesewebcams[5,6].Theﬁrstindicationthatimageswerebeingcapturedwaseverytimethesoftwaretookapicture,thegreenindicatorLEDwouldbrieﬂyilluminate[5,6,42].Someteachersweresoconcernedbythistheytheycoveredthelensofthewebcamsontheirownlaptops[6].Here,theindicatorLEDworkedexactlyasitwassupposedtoandalertedtheusersthattheywerebeingphotographed.Thepossibilitythatawebcamcouldbecapturingpic-tureswithouttheLEDilluminatinghasledtosuggestionsthatownersshouldtapeoverthewebcam[43]aswellasproductsdesignedtocoverthecamerastickers[10,58].1This incident illustrates the dangers of passive sensors
attached to computers like cameras, microphones, and
GPS receivers. Unlike active input devices like keyboards
and mice that require user actions to provide input, a pas-
sive sensor requires no action on the part of the user to
capture input. Indeed, a user is typically unaware that
input is being captured at all unless speciﬁc mechanisms
are built into the technology to indicate that the sensor is
currently in use. Such mechanisms include camera-use in-
dicator LEDs, shutter sounds on cell phone cameras, and
GPS-use indicator icons on mobile devices and laptops.
In the past few years, the ever-expanding set of sen-
sors present in commodity laptops and smart phones has
prompted the security and privacy community to begin
researching ways to detect and limit the undesired use of
sensors [20, 22, 26, 27, 31]. At the same time, researchers
have demonstrated attacks exploiting the presence of sen-
sors such as a clickjacking attacks against Adobe Flash
to gain access to the camera and microphone [23] from
a malicious web page and exﬁltrating audio from micro-
phones in modern automobiles [11]. (See Section 2 for
more examples.)

Our results in this paper demonstrate that, at least in
some cases, people have been correct to worry about mal-
ware covertly capturing images and video. We show a
vulnerability in the iSight webcam that affects a particu-
lar range of Apple computers — including the MacBooks
given to the students in the Lower Merion School Dis-
trict — that can be exploited to turn on the camera and
capture images and video without the indicator illuminat-
ing.

At a high level, our investigation of the iSight revealed
that it is designed around a microprocessor and a sepa-
rate image sensor with an indicator LED sitting between
them such that whenever the image sensor is transmit-
ting images to the microcontroller, a hardware interlock
illuminates the LED. We show how to reprogram the mi-
crocontroller with arbitrary, new ﬁrmware. This in turn
enables us to reconﬁgure the image sensor, allowing us to
bypass the hardware interlock and disable the LED. We
also show a new method of performing a virtual machine
escape based on our ability to reprogram the microcon-
troller.

Speciﬁcally, our technical contributions in this paper

are ﬁve-fold:

1. We describe the architecture of the Apple internal
iSight webcam found in previous generation Apple
products including the iMac G5 and early Intel-based
iMacs, MacBooks, and MacBook Pros until roughly
2008 (Section 3).

2. We demonstrate how to bypass the hardware inter-
lock that the iSight uses to turn on the indicator
LED whenever the camera is capturing images or
video (Section 4) and provide a proof-of-concept

user space application, iSeeYou, to do so (Section 6).
3. We demonstrate how to use the capability developed
to bypass the hardware interlock to achieve a virtual
machine escape (Appendix A1).

4. We develop an OS X kernel extension, iSightDe-

fender, to defend against these attacks (Section 7).
5. We sketch the design space for building a secure

camera module (Section 8).

The ability to bypass the interlock raises serious pri-
vacy concerns and the technical means by which we ac-
complish it raises additional security concerns which we
discuss in Section 9.
Threat model. To mount our main attack where we cap-
ture video without any external indication to the victim,
we assume that an attacker is able to run native code on
the victim’s computer as an unprivileged user. Further,
we assume the code is unencumbered by defenses such
as Apple’s App Sandbox [4] which is used for applica-
tions downloaded from the Mac App Store but by little
else. This assumption is quite mild and would typically
be satisﬁed by malware such as RATs.

For the virtual machine escape, we assume the attacker
has code running locally in the virtual machine and with
whatever privileges the guest OS requires to communi-
cate with USB devices. We also assume that the virtual
machine monitor has exposed the iSight device to the
virtual machine. This second assumption is quite strong
as virtual machine monitors typically do not expose USB
devices to the guest OS unless the user speciﬁcally con-
ﬁgures it to do so, for example to use video conferencing
software.
Generality of results. We stress that our main result —
disabling the iSight LED — only applies to the ﬁrst gen-
eration internal iSight webcams, found in some Apple
laptops and desktops, and we make no claims of security
or insecurity of later models, including the most recent
(renamed) FaceTime cameras. The virtual machine es-
cape described in Appendix A likely holds for other USB
devices that use the Cypress EZ-USB chip used in the
iSight, but we have not yet tested other devices.
2 Related work
General purpose computers contain a variety of proces-
sors designed for performing specialized tasks other than
general-purpose computation. Examples include graph-
ics processing units (GPUs) which produce video output;
processors in network interface controllers (NICs) which
perform network packet processing; microcontrollers in
perhipherals such as keyboards, mice, and webcams; mi-
crocontrollers in laptop batteries; and, in some systems,
baseboard management controllers (BMCs) which en-

1Although we regard this as a major contribution, we have moved

the details to an appendix to improve the paper’s ﬂow

2

338  23rd USENIX Security Symposium 

USENIX Association

ables out-of-band system management independent of the
host computer’s CPU.

Security researchers have only recently begun examin-
ing these additional processors and the ﬁrmware that runs
on them. In many cases, the designers of these systems
appear not to have appreciated the security implications
of their interfaces and implementations.

Perhaps the most well-studied processor apart from the
CPU is the GPU. Vasiliadis et al. [60] demonstrate using
the GPU to harden malware against detection by using
the GPU to implement unpacking and runtime polymor-
phism. Ladakis et al. [33] use the GPU’s direct memory
access (DMA) capability to monitor the system’s key-
board buffer to build a keylogger. Beyond GPU mal-
ware itself, researchers have used the GPU to acceler-
ate malware detection [32] and intrusion detection sys-
tems [50].

Duﬂot and Perez [17] demonstrate exploiting a NIC to
achieve arbitrary code execution. In follow up work, Du-
ﬂot et al. [18] build a NIC malware detection framework.
Miller [39] demonstrates how to communicate with
Apple laptop batteries using the System Management
Bus, authenticate to the battery to “unseal” it, and change
both conﬁguration values and ﬁrmware. This enables
overcharging the battery resulting in overheating and, po-
tentially, leading to a ﬁre.

Tereshkin and Wojtczuk [57] introduce the concept of
a “Ring −3” rootkit which runs on Intel’s Active Manage-
ment Technology (AMT) hardware which has a processor
independent of the host CPU with a separate interface to
the NIC and DMA access to main memory.

In a very similar vein, Farmer [21] discusses weak-
nesses and vulnerabilities in the Intelligent Platform Man-
agement Interface (IPMI) — the standard interface to the
baseboard management controller (BMC). Like AMT, a
BMC has direct access to the host system but its oper-
ation is completely independent making exploits both
extremely powerful and difﬁcult to detect. Moore [41]
builds on this work to produce a penetration tester’s guide
for examining IPMI and BMCs.

A webcam is just a particular type of sensor attached to
a computing device. Others include microphones, ac-
celerometers, and GPS receivers. Our work joins an
emerging line of research on the security and privacy
implications of such sensors. For example, Schlegel et al.
[54] show how to use a smartphone’s microphone to ex-
tract credit card numbers and PINs from spoken and tone-
based interfaces. Marquardt et al. [36], Owusu et al. [46]
and Miluzzo et al. [40] use smartphone accelerometers to
extract information about key presses. Checkoway et al.
[11] extract audio and GPS coordinates from automobiles.
Templeman et al. [56] use smartphone cameras to covertly
take pictures which are then used to create 3D models of
physical spaces.

Our virtual machine escape (Appendix A) is not the ﬁrst
to emulate a USB Human Interface Device (HID) such
as a mouse or keyboard. Wang and Stavrou [62] use a
compromised smart phone to act as a USB HID keyboard
and send key presses to the host system. Kennedy and
Kelley [30] use a small microcontroller to interact with the
Windows Powershell. Pisani et al. [48] similarly describe
having USB devices pose as HID keyboards to control
the computer. Elkins [19] adds a RF receiver for remote
controlling a fake HID keyboard.
3
This section describes the architecture of the internal
iSight webcam in sufﬁcient detail to understand how the
multi-step attack described in Section 4 works. Readers
who are already familiar with the iSight or the Cypress
EZ-USB or who are not interested in the low-level details
of the device are encouraged to skip directly to Section 4
and use this section and Figure 2, in particular, as a refer-
ence as needed.

Internal iSight architecture

The internal iSight consists of a Cypress CY7C68013A
EZ-USB FX2LP, a Micron MT9V112 CMOS digital im-
age sensor, a 16 byte conﬁguration EEPROM, and an
indicator LED (see Figure 1). A block diagram is given
in Figure 2.
3.1 Cypress EZ-USB
The host computer interacts with the iSight entirely
through a USB connection to the Cypress EZ-USB. The
EZ-USB is responsible for handling all USB requests and
sending replies including video data.

The EZ-USB has an internal Intel 8051-compatible mi-
crocontroller core and 16 kB of on-chip RAM accessible
as both code and data “main” memory2 but lacks persis-
tent storage [13]. In general, the ﬁrmware for the 8051
core can be located in one of three locations: (1) external
memory such as ﬂash or EPROM attached to the EZ-USB
address/data bus; (2) an I2C EEPROM; or (3) loaded from
USB. The iSight loads its ﬁrmware at boot from the host
computer over USB (see Section 4.2).
3.2 Micron digital image sensor
The Micron digital image sensor is a low-power system-
on-a-chip (SOC) capable of producing an image in several
formats. The sensor is conﬁgured by the I2C interface
which can read from and write to several hundred con-
ﬁguration registers [37]. In addition to the I2C interface,
several hardware signals inﬂuence the operation of sensor.
The most important signals from our perspective are
the active-low #RESET and active-high STANDBY sig-

2The standard 8051 is a Harvard architecture which has separate code
and data memory differentiated by hardware signals. In the conﬁguration
used by the iSight, the signals are combined effectively giving a single
main memory address space.

USENIX Association  

23rd USENIX Security Symposium  339

3

CMOS Digital Image 

MT9V112
Sensor

EEPROM

L
C
S

A
D
S

L
C
S

A
D
S

L
C
S

A
D
S

]

:

[

0
7
T
U
O
D

8

]

:

0
7
D
F

[

T
E
S
E
R
#

Y
B
D
N
A
T
S

Vcc

LED driver

circuit

0
A
P

3
D
P

USB D+
USB D-

CY7C68013A
EZ-USB FX2LP

Figure 2: Internal iSight architecture block diagram con-
sisting of a Cypress EZ-USB, a Micron digital image sen-
sor, a 16 byte conﬁguration EEPROM, and an indicator
LED. The SCL and SCA lines comprise the I2C bus.

nals. The corresponding hardware pins are connected
directly to the EZ-USB’s general purpose I/O (GPIO)
pins. As shown in Figure 2, #RESET is connected to
pin 0 of GPIO port A and STANDBY is connected to
pin 3 of GPIO port D. The other connection between
the image sensor and the EZ-USB shown in Figure 2
DOUT[7:0]→FD[7:0] is an 8 bit unidirectional bus
which transfers pixel data to the EZ-USB’s FIFO inter-
face. Other, less important, control signals are omitted
from the diagram.

The #RESET signal performs a hardware reset, reset-
ting all conﬁguration registers to their default value. The
STANDBY signal controls output enable and power down
functions. That is, when STANDBY is asserted, the im-
age sensor stops producing data on DOUT[7:0] which
enters the high impedance state as well as allowing the
image sensor to transition to a low-power state.
3.3 Conﬁguration EEPROM
The ﬁrst byte of the 16 byte EEPROM controls whether
the EZ-USB loads its ﬁrmware from USB or from the
EEPROM itself. When set to load ﬁrmware from USB, as
the iSight does, the EEPROM contains the USB vendor

Table 1: Relation between the PD3 GPIO, the STANDBY
signal, and the LED.

STANDBY

LED
PD3
High Asserted
Off
Low Deasserted On

Indicator LED

ID (VID), product ID (PID), device release number, and
a conﬁguration byte for the initial device enumeration.
Once the EZ-USB has enumerated using the VID, PID,
and release values, software on the host computer can load
the ﬁrmware. The iSight initially enumerates with vendor
ID 0x05ac (Apple, Inc.) and product ID 0x8300 (Built-
in iSight (no ﬁrmware loaded)).
3.4
Since the purpose of the indicator LED is to illuminate
whenever the camera is capturing video, a LED driver
circuit is connected directly to the STANDBY input of the
image sensor (see Figure 2). In this way, whenever PD3
is high — that is, STANDBY is asserted — the LED is off
and whenever PD3 is low — so STANDBY is deasserted
and the image sensor is producing output — the LED
is on. Since the LED is controlled by the same output
that controls STANDBY, there is no danger that ﬁrmware
on the EZ-USB could deassert STANDBY and turn the
LED off (see Table 1). However, as we demonstrate
in Section 4, we can bypass the STANDBY signal such
that changing PD3 allows us to control the LED without
affecting the operation of the image sensor.
4 Disabling the indicator LED
Disabling the indicator LED on the iSight entails two re-
quirements. First, as described in Section 3, the indicator
LED is directly connected to the STANDBY pin on the
image sensor. In order to disable the LED, we need to
keep STANDBY asserted. Since asserting STANDBY will
disable the image sensor output, we need to conﬁgure the
image sensor to ignore STANDBY before we assert this
signal. Second, we need a way to modify the ﬁrmware on
the EZ-USB to in order to conﬁgure the image sensor ap-
propriately as well as keep STANDBY asserted whenever
we want the LED to stay off.
4.1 Bypassing the STANDBY signal
The Micron image sensor has a 16 bit conﬁguration regis-
ter, RESET (which is distinct from the #RESET power-
on-reset signal). RESET is addressable from the I2C
interface at address 0x0D in register page 0 [37]. The
most signiﬁcant 8 bits control hardware clocks and how
bad frames should be handled which are of no interest to
us and can be left as 0. The least signiﬁcant 8 bits have the
following functionality as described in the image sensor

340  23rd USENIX Security Symposium 

USENIX Association

4

data sheet [37, Table 13]:

Bit 7. Prevent STANDBY from affecting entry to or

exit from the low-power state if set.

Bit 6. Prevent STANDBY from contributing to output

enable control if set.

Bit 5. Reset the SOC (but not the sensor) if set.
Bit 4. Disable pixel data output if set.
Bit 3. Chip enable. Normal operation if set, no sensor

Bit 2. Software standby if set, otherwise normal oper-

readout otherwise.

ation.

Bit 1. Restart reading an image frame.
Bit 0. Reset the sensor to its default state if set, normal

operation otherwise.

Bits 0, 1, and 5 are of no interest and can be set to 0 but
the remaining 5 bits enable us to bypass the STANDBY
signal while still maintaining normal operation. This
includes entering a (software) standby state and disabling
output when appropriate.

When the iSight is ﬁrst powered up (or, more pre-
cisely, when #RESET becomes deasserted), the RESET
register has value 0x0008; that is, normal operation and
STANDBY affects the low-power state and output enable.
If RESET is set to 0x00c8, then the camera has normal
operation but STANDBY is effectively bypassed. When
it becomes desirable for the camera to enter the standby
state, RESET can be set to 0x00d4 which disables out-
put and enters the software standby state.

With RESET set to either 0x00c8 or 0x00d4, the
hardware STANDBY signal is ignored. This enables the
use of the EZ-USB PD3 output to control the LED inde-
pendent of the standby state of the image sensor.
4.2 Programming the EZ-USB
When the iSight is ﬁrst powered, it checks the con-
ﬁguration EEPROM and then waits for programming
over USB (see Section 3.3). The AppleUSBVideo-
Support I/O Kit driver matches the vendor ID (VID)
and product
loads and the
AppleUSBCamera::start() function downloads
the camera’s ﬁrmware (stored in the gTheFirmware
array) to the EZ-USB using a series of vendor-speciﬁc
USB “Firmware Load” device requests [13, Section 3.8].
The camera will then reenumerate and function as a web-
cam.

ID (PID). The driver

One approach to change the ﬁrmware on the camera is
to modify the AppleUSBVideoSupport driver to contain
different ﬁrmware. A second approach would be to pro-
vide a new driver that matches the VID/PID and provides
a higher probe score [2]. The new driver would run at
system start up instead of Apple’s driver and download
the new ﬁrmware to the camera. These approaches have
two major drawbacks. The ﬁrst drawback is that they
rely on programming the iSight when it is in its unpro-

grammed state which only happens when the camera is
ﬁrst powered by the USB bus. The second drawback is
that root access is required in order to modify the existing
driver or load a new driver.

A third approach overcomes both drawbacks by letting
the iSight be programmed with the legitimate ﬁrmware
when it is ﬁrst powered. Once the ﬁrmware has been
loaded onto the camera, it can be reprogrammed at any
time using “Firmware Load” requests. Furthermore, it
can be reprogrammed from any user space process.
5 Finding the vulnerability
The information described in Sections 3 and 4 was dis-
covered by a combination of reverse engineering, experi-
mentation, and reading data sheets once individual com-
ponents were identiﬁed. We started by ordering camera
modules from a variety of Apple computers on eBay. Co-
incidentally, the modules were all from the original iSight
camera, although the camera boards for the MacBook and
iMac had different forms. Figure 1 shows the MacBook
board.

A cursory examination of the board reveals that the
camera microprocessor is a Cypress EZ-USB. The EZ-
USB Technical Reference Manual [13] describes the pro-
cedure to download code to EZ-USB. We reverse engi-
neered the AppleUSBVideoSupport driver using IDA [25]
to determine the format of the ﬁrmware stored in the
driver. (Section 6.1 describes the ﬁrmware in more de-
tail.) We then extracted the ﬁrmware as it would appear
in memory and analyzed it using IDA.

Our initial hypothesis was that the LED would be con-
trolled by one of the EZ-USB GPIO pins via the ﬁrmware.
To test this, we mapped out the connections on the board
using a digital multimeter with a speciﬁc focus on con-
nections from the microcontroller to the indicator LED. A
connection was found between the microcontroller, image
sensor, and the LED driver circuit. Since the microcon-
troller pin connected to the LED was set as an output,
we constructed new ﬁrmware to toggle this output and
examined the results. When the LED was turned on, the
camera functioned correctly. When the LED was turned
off, the camera ceased operating (see Table 1).

Since the output controlling the LED was also con-
nected to the image sensor, we examined it next. When
the legitimate camera ﬁrmware is downloaded to the cam-
era, it identiﬁes itself as “Apple, Inc. Built-in iSight [Mi-
cron]” suggesting that the image sensor was manufactured
by Micron Technology. There is no visible part number
that can be used to identify the model (see Figure 1).
Rather than decapping the chip, we used the Wayback
Machine3 to view the Micron website for 2005, the year
the camera board was copyrighted. Data sheets for the

3https://archive.org/web/

USENIX Association  

23rd USENIX Security Symposium  341

5

image sensors that matched the publicly known specs for
the iSight camera on Micron’s website indicate that the
image sensor communicates over an I2C bus. One of the
I2C-addressable registers identiﬁes the chip version. We
identiﬁed the I2C bus and read the register which revealed
the particular image sensor.

We examined the relevant data sheet for the image sen-
sor and noticed the STANDBY pin with functionality con-
sistent with our experiments toggling the LED-controlling
output pin. After reading the data sheet in more detail, we
discovered the I2C-addressable register which enables a
software override for the STANDBY pin. Further exper-
iments with modiﬁed ﬁrmware were performed to ver-
ify that the LED driver circuit was indeed connected to
STANDBY and that it could be bypassed.
6 Proof of concept
The discussion in Section 4 shows that, in principle, it is
possible to modify the legitimate ﬁrmware to disable the
LED. In this section, we describe the proof-of-concept
application, iSeeYou we created which reprograms the
iSight to add the capability to enable or disable the LED
using a new vendor-speciﬁc USB device request.
6.1 Modifying the ﬁrmware
Although one could reimplement the camera functionality,
we opted to create new ﬁrmware by appending new binary
code to the legitimate ﬁrmware and patching it to call
our new code. The ﬁrst step is to extract the legitimate
ﬁrmware from the AppleUSBVideoSupport device driver.4
The ﬁrmware consists of an 8 byte header followed by
a sequence of triples: a 2 byte size, a 2 byte address, and
size-bytes of data. This format corresponds exactly to the
“C2 Load” format of the EEPROM for loading ﬁrmware
directly from the EEPROM [13, Table 3-6]. Each triple
speciﬁes the data that should be written to the EZ-USB’s
main memory at a given address. By stripping off the
header and the ﬁnal triple,5 we can construct the “raw”
ﬁrmware image. The raw ﬁrmware can then be analyzed
using IDA.

The raw ﬁrmware is structured similarly to sample code
provided in the Cypress EZ-USB FX2LP Development
Kit [14] including a hardware initialization function and
USB events that are serviced by a main loop based on
state bits set by interrupt handlers.

To the legitimate ﬁrmware, we add two bits of state,
“is the sensor in software standby or running” and “is
the LED enabled or disabled,” as well as four new func-

4There are several open source tools to perform this task, e.g., iSight
Firmware Tools [7], several of which include binary patching to ﬁx bugs
in the USB interface descriptors.

5The ﬁnal triple stores a single 0x00 byte to address 0xE600
which takes the Intel 8051 core out of reset so that it can begin executing
instructions.

tions, reset_sensor, enter_standby, exit_
standby, and handle_led_control.

When the LED is enabled, the behavior of the camera
is indistinguishable from the normal behavior. That is,
when the camera is in its standby state the LED is off and
when the camera is in its running state, the LED is on.

The legitimate ﬁrmware contains a function to reset
and conﬁgure the image sensor. This is called both from
the hardware initialization function and the handler for
the USB set interface request. It begins by deasserting
the STANDBY signal and asserting the #RESET. After
a short spin loop, it deasserts #RESET and, depending
on the function argument, deasserts STANDBY. It then
proceeds to conﬁgure the image sensor. We patch the
ﬁrmware to call reset_sensor instead of this conﬁg-
uration function in both locations. The reset_sensor
function reimplements the reset functionality but adds a
call to the function which writes to the I2C bus to program
the RESET register to bypass the STANDBY signal (see
Section 4.1). At this point, if the LED has been disabled
or the argument indicates that it should enter the standby
state, the STANDBY signal is asserted to turn off the LED
which will have momentarily illuminated during the reset
sequence. Otherwise, the sensor is left running and the
LED is enabled so STANDBY remains deasserted and the
LED stays on. Finally, the reset_sensor function
jumps into the middle of the conﬁguration function, just
past the #RESET and STANDBY manipulating code, in
order to perform the rest of the conﬁguration.

The enter_standby and exit_standby func-
tions update the bit of state which records if the image
sensor is running or in standby. Then, based on whether
the LED is enabled or not, they deassert (resp. assert)
STANDBY as needed to turn the LED on (resp. off). Fi-
nally, these functions use I2C to program the RESET reg-
ister to enter or exit software standby. Each location in the
legitimate ﬁrmware which sets the state of the STANDBY
signal is patched to call its new, corresponding standby
function instead.

The ﬁnal function, handle_led_control is re-
sponsible for handling a new vendor-speciﬁc USB de-
vice request. The main loop in the legitimate ﬁrmware
which handles USB device request “setup” packets is
patched to instead call handle_led_control. If the
bRequest ﬁeld of the request does not match the new
vendor-speciﬁc value, then it jumps to the legitimate han-
dler. Otherwise, based on the wValue ﬁeld of the request,
the LED is enabled or disabled. As with the other func-
tions, the LED is then turned on if it has been enabled and
the image sensor is running. Otherwise, it is turned off.
6.2 Demonstration application: iSeeYou
iSeeYou is a simple, native OS X application; see Fig-
ure 3. When iSeeYou starts, it checks for the presence of

342  23rd USENIX Security Symposium 

USENIX Association

6

Figure 3: iSeeYou running on a white MacBook “Core 2 Duo” capturing video from the internal iSight with the LED (the
black dot to the right of the square camera at the top, center of the display bezel) unilluminated.

a built-in iSight using the appropriate vendor and product
IDs. If the iSight is found, iSeeYou initiates the repro-
gramming process using the modiﬁed ﬁrmware described
above. Once the camera has been reprogrammed and
has reenumerated, the start/stop button begins/ends cap-
turing and displaying video. The LED Enable/LED
Disable control sends USB device requests with the
new vendor-speciﬁc value to enable/disable the indicator
LED while video is being captured. Finally, when the
user quits iSeeYou, the camera is reprogrammed with the
legitimate ﬁrmware.
7 Defenses
There are several approaches one can envision to defend
the iSight against the attacks described in the previous sec-
tions. One can change (1) the hardware, (2) the ﬁrmware
on the EZ-USB (unfortunately this is not effective, see be-
low), or (3) the software on the host system. See Table 2
for an overview of possible defenses and their efﬁcacy.

The most comprehensive defense would be to change
the hardware used in the iSight. See Section 8 for sev-
eral secure hardware designs. Of course, changing the
hardware is not a deployable solution for existing de-
vices.

Table 2: Overview of possible defenses.

Defense
Change hardware No
Change ﬁrmware Yes
Yes
App Sandbox
iSightDefender
Yes

Root
Deployable User
Yes
Yes
No
No
Some No
Yes
No

A “Yes” in the Deployable column indicates that
the defense could be deployed to existing computers.
A “Yes” in the User (resp. Root) column indicates
that the defense would prevent an unprivileged (resp.
root) process from reprogramming the iSight. A
“Some” indicates that some reprogramming attempts
would be prevented but others allowed.

If the hardware must remain the same, then if the
ﬁrmware on the camera could be changed to disallow
future reprogramming, then the camera would be secure
against our attacks. Unfortunately, the “Firmware Load”
USB device request used to reprogram the 8051 core is
handled entirely by the EZ-USB device itself and cannot
be blocked or handled by the 8051 itself [13, Section 3.8].

7

USENIX Association  

23rd USENIX Security Symposium  343

Thus no matter how one programs the device’s ﬁrmware,
it can be reprogrammed by an attacker who can send basic
USB messages to the camera.

Apple deploys sandboxing technology called the App
Sandbox6 [4] which can prevent applications inside
the sandbox from accessing the iSight. Speciﬁcally,
the com.apple.security.device.camera enti-
tlement enables an application to capture still images
and video from cameras, including the internal iSight.
The com.apple.security.device.usb entitle-
ment enables applications to access USB devices.

Any App Sandbox–protected application lacking the
usb entitlement would be prohibited from reprogram-
ming the iSight and thus prohibited from disabling the
indicator LED. Although an application with the usb en-
titlement but lacking the camera entitlement would be
prohibited from using the high-level APIs for accessing
the camera, such as the QTKit API [3], it could easily
reprogram the camera to not appear as a USB video class
(UVC) device and instead transfer the frames of video
using a custom protocol.

The major drawback to using the App Sandbox to pro-
tect the camera is that applications need to opt into the
protection, something malware is unlikely to do. Worse,
the App Sandbox has, at times, been broken allowing
applications to escape from the restrictions [12, 38].

Perhaps the best way to defend against reprogramming
the iSight without changing the hardware is to modify
the operating system to prevent particular USB device
requests from being sent to the camera. We have built
such a defense structured as an OS X kernel extension
called iSightDefender.

When iSight is powered for the ﬁrst time, it enumer-
ates with vendor ID 0x05ac and product ID 0x8300
and is programmed with the legitimate ﬁrmware via the
AppleUSBVideoSupport kernel extension as described in
Sections 3.3 and 4.2. When it reenumerates with prod-
uct ID 0x8501 the kernel matches and loads the normal
drivers as well as iSightDefender.

I/O Kit kernel drivers are written in a subset of C++
and each USB device is represented by an object of class
IOUSBDevice which is responsible for communicat-
ing with the hardware by sending messages to objects in
lower layers of the USB stack. When iSightDefender is
started, it overwrites the C++ virtual method table of its
“provider” IOUSBDevice to point to the virtual method
table of a subclass of IOUSBDevice.7 The subclass
overrides the four DeviceRequest member functions.
The overridden implementations check if the device re-
quest is for the “Firmware Load” vendor-speciﬁc request

6Formerly codenamed Seatbelt.
7There seems to be no supported mechanism for interposing on USB
device requests. The authors appreciate the irony of using virtual table
hijacking — a common hacker technique — for defending against attack.

and, if so, log the attempt in the system log and block the
request.

iSightDefender is able to block all user space re-
programming attempts,8 including those mounted from
within a virtual machine. The latter requires some care as
the normal drivers that match against the IOUSBDevice
are unloaded and the virtual machine monitor’s own driver
is loaded in their place.

Using iSightDefender raises the bar for attackers by
requiring the attacker to have root privileges in order to
reprogram the iSight. In some sense, this is the strongest
possible software-based defense. Since malware running
as root would have the ability to replace or modify kernel
code, any defense implemented in the kernel can, theoret-
ically, be bypassed. Despite this limitation, we believe it
is a step in the right direction and encourage its use.

iSightDefender, and its source code, is freely avail-

able.9
8 Secure camera designs
When designing a secure camera, there are two main
considerations. First, for sensors such as cameras and
microphones, an indicator that the sensor is recording is
essential to prevent surreptitious recording. (Although
laptop microphones do not, in general, have indicators, it
is common for stand alone USB microphones; see [29]
for an example.) For the highest level of assurance that
the indicator cannot be bypassed, the indicator should be
controlled completely by hardware.

Second, as with any peripheral connected to the com-
puter, a vulnerability in the ﬁrmware running on the pe-
ripheral or the ability to reprogram the ﬁrmware enables
an attacker to leverage all of the capabilities of the periph-
eral. Section 2 contains numerous examples of this. The
virtual machine escape in Appendix A is another example
where an attacker leverages the USB connection and the
ability of the EZ-USB to mimic any USB device to the
host computer. Apple’s most recent FaceTime cameras
in its 2013 MacBook Air model eschews USB 2.0. In-
stead, the camera is connected to the host computer over
PCIe [35]. Vulnerabilities in the camera would potentially
enable an attacker to have DMA access to the host sys-
tem. This is a signiﬁcantly stronger capability than USB
access.
8.1 Secure indicators
Laptop cameras are typically constructed by pair-
the Mi-
ing a CMOS image-sensor-on-a-chip (e.g.,

8In fact, iSightDefender worked so well that one author spent more
than an hour attempting to diagnose (nonexistent) problems with iSeeYou
before noticing the tell-tale lines in the system log indicating that iSight-
Defender had been loaded by a computer restart and it was blocking
reprogramming requests.

9https://github.com/stevecheckoway/

iSightDefender

8

344  23rd USENIX Security Symposium 

USENIX Association

cron MT9V112 found in the iSight or the Toshiba
TCM8230MB(A)) with a separate microcontroller that
handles communication with the host computer (e.g., the
EZ-USB FX2LP found in the older MacBooks or the
Vimicro VC0358 [61] found in more recent MacBook
Pros [28]. There are, of course, many possible combi-
nations of image sensors and microcontrollers one could
use.

Image-sensors-on-a-chip tend to have a number of com-
mon features that can be used to build a secure indicator.
1. Separate power connection for CMOS sensor itself.
For example, VAAPIX on the MT9V112 powers
its pixel array and PVDD on the TCM8230MB(A)
powers its photo diode. A GPIO pin on the micro-
controller can be connected to both the LED driver
circuit and the CMOS sensor power supply circuit.
Whenever images are to be captured, the microcon-
troller sets its GPIO pin appropriately, power is sup-
plied to the sensor and the LED turns on.

2. #RESET pins. The LED driver circuit can be con-
nected to the #RESET pin and a GPIO pin on the
microcontroller. The microcontroller would hold the
image sensor in reset whenever it was not captur-
ing images. Compared to the power connection for
CMOS sensor, holding the entire sensor-on-a-chip
in reset means that before images could be captured,
the sensor would need to be reconﬁgured. Recon-
ﬁguring typically means sending a few dozen bytes
over an I2C or SPI bus. This introduces a slight
delay.

3. Output clocks and synchronization signals. Image
sensors typically latch outputs on one edge of an
output clock signal and image consumers are ex-
pected to read the data on the other edge of the
clock. In addition, there are signals used to indicate
which part of the image the latched data represents.
For example, the MT9V112 has FRAME_VALID
and LINE_VALID signals indicating when it’s out-
putting a frame or a line within the frame, respec-
tively, whereas the TCM8230MB(A) has VD and HD
for vertical and horizontal synchronization. These
pins can also be used to control the LED by adding
some simple hardware that drives the LED if it has
seen one of these signals change in the past few
milliseconds.

Depending on the speciﬁcs of the image sensor
output signal, a retriggerable, monostable multivi-
brator can be used to drive the LED as long as its
input changes sufﬁciently often. The multivibrator’s
output pulse width needs to be set appropriately such
that it is triggered frequently enough to continuously
drive the LED while images are being recorded.

Some care must be taken when using these output
signals. The exact meanings of the signals can fre-

quently be changed by conﬁguring the sensor. This
is analogous to the situation with the iSight where
we changed the meaning of the STANDBY signal.

An all-in-one design where the image sensor is inte-
grated with the microcontroller which communicates to
the host computer is likely to have fewer options for a
secure design. A dedicated output pin which could drive
an indicator LED would sufﬁce. However, hardware de-
signers are typically loathe to dedicate pins to speciﬁc
functions, instead a variety of functions tend to be multi-
plexed over a single pin.

It is likely that, even in this case, there would be a
separate power connection for the CMOS sensor. As with
the two-chip design above, the LED driver circuit and a
power supply circuit could be driven by a GPIO.
8.2 Secure ﬁrmware
Although using one of the secure indicator designs de-
scribed above will ensure the LED will turn on when
the camera turns on, it does nothing to protect against
reprogramming attacks.

For this, we make four concrete recommendations
which, taken together, can secure the ﬁrmware on the
camera. These apply more generally to any peripheral or
embedded system connected to a host computer.

1. Store the ﬁrmware in nonvolatile storage on the cam-
era module. Most commercial off-the-self (COTS)
microcontrollers contain some amount of nonvolatile
storage, such as ﬂash memory, to hold ﬁrmware.10
By programming the ﬁrmware at the factory, one
avoids the possibility that the legitimate ﬁrmware
will be replaced by an attacker on the host system
before being downloaded to the microcontroller.

Depending on the speciﬁc requirements of the
system, the factory programming could be the com-
plete ﬁrmware or a secure loader designed to load
cryptographically signed ﬁrmware from the host (see
below).

2. Use a microcontroller which can block unwanted
ﬁrmware reprogramming attempts. It is essential that
trusted code running on the microcontroller is able
to block reprogramming attempts for illegitimate
ﬁrmware.

3. Firmware updates, if necessary, should be crypto-
graphically signed and the signature veriﬁed before
applying the update. This requires both nonvolatile
storage for the code to verify the signature and a
microcontroller which can block reprogramming at-
tempts. Since microcontrollers are typically resource
constrained devices, choosing an appropriate signa-
ture scheme which can be implemented within the

10Microcontrollers without nonvolatile storage can be paired with
external nonvolatile storage, such as ﬂash or an EEPROM, to the same
effect.

9

USENIX Association  

23rd USENIX Security Symposium  345

constraints is important. Scheme selection is outside
the scope of this paper but we note that recent micro-
controllers have started to contain specialized crypto
instructions which can reduce code size and increase
efﬁciency. For example, Rohde et al. [53] use spe-
cialized AES instructions in some Atmel ATxmega
microcontrollers to implement the Merkle signature
scheme.

4. Require root/administrator privileges to send repro-
gramming requests. Strictly as a matter of defense
in depth, software running on the host system should
restrict reprogramming attempts. Thus, even if the
hardware and ﬁrmware defenses prove inadequate,
this added layer of protection can still defend against
some attacks.

Adding this sort of restriction typically involves a
device-speciﬁc kernel module (our iSightDefender
is an example). This may be more difﬁcult for plug
and play devices expected to conform to standard
protocols and interact with generic drivers such as
USB video class (UVC) or USB human interface
device (HID) class devices.

The inability of the EZ-USB to block reprogramming
attempts indicates that this widely-used microcontroller
is inappropriate for use in any system where security is a
consideration.

Secure physical user interface Orthogonal to secure
indicators and secure software is a secure physical user
interface. Most webcams in laptops are controlled by
software: Software tells the camera when to power up,
when to capture video, and when to power down. A
simple solution to the problem is to provide a physical
switch similar to the switches found on laptop network
adapters which controls power to the camera. A second
simple solution is to provide a lens cover which the user
must physically move aside to use the camera. This would
be similar in spirit to the original external iSight and
similar in form to the amusingly named iPatch [58].
9 Discussion
Although some webcams, such as the Logitech QuickCam
Pro 9000, come with an explicit “LED control” that can
disable the LED [64], such controls are not the norm and,
in fact, are a very bad idea from both a security and a
privacy stand point. Giving the user the ability to disable
a privacy feature is tantamount to giving malware the
same capability.

This work concerns the technical challenge of hard-
ware exploitation; however, we would be remiss if we
did not discuss the (frequently unpleasant) real-world
consequences of vulnerabilities in privacy technology.

A particularly unsavory element of the hacker culture,
“ratters,” install malware bundled with remote adminis-

tration tools (RATs) on victims’ computers. There are
several popular RATs, including Blackshades and Dark-
Comet, which come with a variety of features such as
keyloggers, the ability to install additional malware, and
the ability to record video and sound using the webcam.
Rats are often installed with the goal of spying on women.
RATs and the ratters who use them have recently come
under public scrutiny after a recent Miss Teen USA’s
webcam was used by ratter Jared Abrahams to capture
her naked images without her knowledge [15]. Abrahams
arrest and guilty plea came on the heels of an ars technica
exposé on ratters [1].

A commonly asked question on forums devoted to rat-
ting, such as the Hack Forums “Remote Administrator
Tools” forum, is how can one disable the webcam’s LED.
In one representative thread, forum user “Phisher Cat”
asks

So as all of you know, newer laptops have
a light when a laptop webcam turns on, and so
this scares the slave.

Is it theoretically possible for a RAT to dis-

able this light? [47]

disturbingly referring to his victim as “the slave,” as is
common in this subcommunity. The ﬁrst response by
“Jabaar” notes that “[p]eople have been trying to ﬁgure
this out for a very long time. The light won’t be able to
be disabled as it is built into the hardware.” Others agree:
“Capital Steez” writes that there is “no way to disable it,”
and “FBITM” concurs “there [i]s no way to do” it. Still
others suggest using social engineering in an attempt to
convince the victim that the LED is normal, for example,
“Orochimaru” writes, “You can’t physically turn it off but
you can use social engineering to fool them. Maybe send
an error or warning msgbox that says ‘Camera is now
updating, please do not disturb’ or something.” There are
many such threads on Hack Forums alone, all expressing
similar sentiments: disabling LEDs is a capability the
ratters really want to have but do not think is possible.

Unfortunately, the implications of surreptitiously cap-
turing video do not end with privacy violations like law
enforcement, school ofﬁcials, and ratters spying on peo-
ple. As part of the general trend of growing frustration
with passwords as an authentication mechanism, some
companies are moving to biometric identiﬁcation; in
particular, using facial recognition on video taken with
webcams. For example, BioID is software-as-a-service
which provides biometric identiﬁcation to online service
providers using a webcam [8]. Luxand’s FaceSDK is
a cross-platform software development kit that uses the
webcam to identify the user [34].

In principle, this sort of facial recognition is trivially
defeated by providing the expected picture or video to
the software performing the authentication. Malware that

346  23rd USENIX Security Symposium 

USENIX Association

10

can capture video of the victim can replay that video to
authenticate to the given service. This is not a new attack.
The Android Face Unlock system was defeated shortly
after being released by holding a picture of the face in
front of the camera [9]. Duc and Minh [16] describes
weaknesses of several facial recognition authentication
systems in the presence of pictures. By disabling the
indicator LED before capturing video, the victims have no
way of knowing that their accounts may be compromised.
Although the ability to disable the LED can lead to
serious privacy and security problems, there are at least
two legitimate use cases. The ﬁrst is that some people
really do not want the LED on while they are recording.
We do not ﬁnd this to be a compelling use as the beneﬁt
does not seem to outweigh the potential cost; however,
others may value this more than we do.

The second use case is signiﬁcantly more compelling:
laptop recovery. For example, the OS X version of
Adeona software captures pictures using the laptop’s in-
ternal iSight to aid in recovery of a laptop that has been
stolen by taking a picture of the thief [51, 52]. The LAN-
rev software used in the Lower Merion School District
incident discussed in the introduction had a similar “Theft
Track” feature which is how the school ofﬁcials were able
to obtain pictures of students. For this use, one does not
want the thief to know he is being observed.
10 Responsible disclosure
The authors followed responsible disclosure practices by
disclosing the LED disabling vulnerability to Apple prod-
uct security team on July 16, 2013 and the virtual machine
escape on August 1, 2013. The disclosures included the
source code for iSeeYou and the virtual machine escape
as well as directions for mounting both attacks. Apple
employees followed up several times but did not inform
us of any possible mitigation plans. The iSightDefender
code was also provided to Apple and is now publicly
available.11
11 Conclusions and future work
Engineering details of privacy technologies can have real-
world consequences. As discussed in Sections 1 and 9,
a computer user today potentially faces a variety of ad-
versaries — from law enforcement and school ofﬁcials to
criminals — who want to capture images or video clandes-
tinely. Currently, the only technological barrier standing
in their way is the camera-on indicator LED. We have
shown that, at least in some cases, the barrier can be
overcome.

In particular, we have shown that being able to repro-
gram the iSight from user space is a powerful capability.
Coupled with the hardware design ﬂaw that allows the

11See supra note 9.

indicator LED hardware interlocks to be bypassed, mal-
ware is able to covertly capture video, either for spying
purposes or as part of a broader scheme to break facial
recognition authentication. Although the iSightDefender
defense described in Section 7 raises the barrier for mal-
ware, including RATs, to take control of the camera with-
out being detected by requiring root privileges, the correct
way to prevent disabling the LED is a hardware solution.
In this paper, we have examined only a single genera-
tion of webcams produced by a single manufacturer. In
future work, we plan to expand the scope of our inves-
tigation to include newer Apple webcams (such as their
most recent high-deﬁnition FaceTime cameras) as well as
webcams installed in other popular laptop brands.

The virtual machine escape described in Appendix A
demonstrates the danger that reprogrammable peripheral
devices such as keyboards and mice pose. We plan to
undertake a much broader examination of these devices
in an attempt to understand the security implications of
connecting one device to a computer which can, under at-
tacker control, pretend to be a wide range of devices. One
particularly promising direction is to study how drivers
react to malformed or malicious responses from devices.
In the worst case, a user space program could reprogram
a peripheral device which in turn exploits a poorly written
driver to inject code into the kernel.
Acknowledgments
We thank the anonymous reviewers for their detailed com-
ments and helpful suggestions. We also thank Brian Kan-
tor, Nick Landi, Eric Rescorla, Stefan Savage, Hovav
Shacham, and Cynthia Taylor for many helpful discus-
sions throughout this work and Kevin Mantey for letting
us borrow test equipment and providing technical assis-
tance.
References
[1] Nate Anderson. Meet the men who spy on women
through their webcams. ars technica, March 2013.
Online: http://arstechnica.com/tech-
policy/2013/03/rat-breeders-meet-
the-men-who-spy-on-women-through-
their-webcams/.

[2] I/O Kit Fundamentals: Driver and Device Match-
ing. Apple Inc., May 2007. Online: https:
//developer.apple.com/library/
mac/#documentation/devicedrivers/
conceptual/IOKitFundamentals/
Matching/Matching.html.

Framework

Reference.

Apple
http://

[3] QTKit

Inc., February 2009.
developer.apple.com/library/
mac/#documentation/QuickTime/

Online:

USENIX Association  

23rd USENIX Security Symposium  347

11

Reference/QTCocoaObjCKit/_index.
html.

[4] App

Apple
http://

Sandbox Design Guide.
Online:

Inc., March 2013.
developer.apple.com/library/
mac/#documentation/Security/
Conceptual/AppSandboxDesignGuide/
AboutAppSandbox/AboutAppSandbox.
html.

[5] Ballard Spahr. Lower Merion School District foren-
sics analysis: Initial LANrev system ﬁndings, May
2010. Online: http://www.scribd.com/
doc/30891576/LMSD-Initial-LANrev-
System-findings. Redacted.

[6] Ballard Spahr. Report of independent investigation:
Regarding remote monitoring of student laptop
computers by the Lower Merion School District,
May 2010. Online: http://www.social-
engineer.org/resources/100503_
ballard_spahr_report.pdf.

[7] Étienne Bersac.

iSight Firmware Tools. Octo-
ber 2009. Online: https://launchpad.net/
isight-firmware-tools.

[8] BioID,

Inc.

The easy,

secure way to log
in and manage online identities and accounts.
2013. Online: http://mybioid.com/index.
php?id=67. Last accessed: 2013-08-06.

[9] Matt Brian. Android 4.0 Face Unlock feature
defeated using a photo. The Next Web, Novem-
ber 2011.
Online: http://thenextweb.
com/google/2011/11/11/android-4-
0-face-unlock-feature-defeated-
using-a-photo-video/.

[10] camJAMR.com.
2012.

camJAMR.com webcam
http://store.

Online:

covers.
camjamr.com/shop-now/camjamr-
webcam-covers.html.
2013-08-07.

Last

accessed:

[11] Stephen Checkoway, Damon McCoy, Danny An-
derson, Brian Kantor, Hovav Shacham, Stefan
Savage, Karl Koscher, Alexei Czeskis, Franziska
Roesner, and Tadayoshi Kohno. Comprehensive
experimental analyses of automotive attack sur-
faces.
In David Wagner, editor, Proceedings of
USENIX Security 2011. USENIX, August 2011.
Online: http://www.autosec.org/pubs/
cars-usenixsec2011.pdf.

[12] CoreLabs, Core Security Technologies. Apple OS
X Sandbox predeﬁned proﬁles bypass. November

2011. Online: http://www.coresecurity.
com/content/apple-osx-sandbox-
bypass.

[13] EZ-USB R(cid:31) Technical Reference Manual.

Cy-
press Semiconductor Corporation, 2011. On-
line: http://www.cypress.com/?docID=
27095&dlm=1.

[15] Alex Dobuzinskis.

[14] Cypress Semiconductor Corporation. CY3684 EZ-
USB FX2LP Development Kit. 2013. Online:
http://www.cypress.com/?rID=14321.
California man agrees
to plead guilty to extortion of Miss Teen
USA. Reuters, October 2013. Online: http:
//www.reuters.com/article/2013/
10/31/us-usa-missteen-extortion-
idUSBRE99U1G520131031.

[16] Nguyen Minh Duc and Bui Quang Minh. Your
face is NOT your password: Face authentica-
tion bypassing Lenovo – Asus – Toshiba. Pre-
sented at BlackHat Brieﬁngs, July 2009. On-
line: https://www.blackhat.com/html/
bh-usa-09/bh-us-09-main.html.

[17] Loïc Duﬂot and Yves-Alexis Perez.

you still trust your network card?
at CanSecWest 2010, March 2010.
http://www.ssi.gouv.fr/IMG/pdf/
csw-trustnetworkcard.pdf.

Can
Presented
Online:

[18] Loïc Duﬂot, Yves-Alexis Perez, and Benjamin
Morin. What if you can’t trust your network
card?
In Robin Sommer, Davide Balzarotti,
and Gregor Maier, editors, Proceedings of RAID
2011, pages 378–397. Springer, September 2011.
Online:
http://www.ssi.gouv.fr/IMG/
pdf/paper.pdf.

[19] Monta Elkins. Hacking with hardware: Introduc-
ing the universal RF USB keyboard emulation de-
vice: URFUKED. Presented at DefCon 18, August
2010. Online: http://www.youtube.com/
watch?v=EayD3V77dI4.

[20] William Enck, Peter Gilbert, Byung-Gon Chun,
Landon P. Cox,
Jaeyeon Jung, Patrick Mc-
Daniel, and Anmol N. Sheth. TaintDroid: An
information-ﬂow tracking system for
realtime
privacy monitoring on smartphones.
In Remzi
Arpaci-Dusseau and Brad Chen, editors, Proceed-
ings of OSDI 2010. USENIX, October 2010. Online:
http://static.usenix.org/events/
osdi10/tech/full_papers/Enck.pdf.

[21] Dan Farmer. IPMI: Freight train to hell, January

348  23rd USENIX Security Symposium 

USENIX Association

12

2013. Online: http://fish2.com/ipmi/
itrain.pdf.

[22] Clint Gibler, Jonathan Crussell, Jeremy Erickson,
and Hao Chen. AndroidLeaks: Automatically de-
tecting potential privacy leaks in Android applica-
tions on a large scale. In Stefan Katzenbeisser, Edgar
Weippl, L. Jean Camp, Melanie Volkamer, Mike Re-
iter, and Xinwen Zhang, editors, Trust and Trustwor-
thy Computing, volume 7344 of Lecture Notes in
Computer Science, pages 291–307. Springer Berlin
Heidelberg, 2012. doi: 10.1007/978-3-642-30921-
2_17.

[23] Jeremiah Grossman. Clickjacking: Web pages can
see and hear you. October 2008. Online: http:
//jeremiahgrossman.blogspot.com/
2008/10/clickjacking-web-pages-
can-see-and-hear.html.

[24] Hugh Hart. April 14, 1996: JenniCam starts lifecast-
ing. Wired Magazine, April 2010. Online: http:
//www.wired.com/thisdayintech/
2010/04/0414jennicam-launches/.

[25] Hex-Rays.

IDA: About. January 2014. Online:
https://www.hex-rays.com/products/
ida/.

[26] Peter Hornyack, Seungyeop Han, Jaeyeon Jung, Stu-
art Schechter, and David Wetherall. ‘These aren’t
the droids you’re looking for’: Retroﬁtting Android
to protect data from imperious applications.
In
George Danezis and Vitaly Shmatikov, editors, Pro-
ceedings of CCS 2011. ACM Press, October 2011.
Online:
https://research.microsoft.
com/pubs/149596/AppFence.pdf.

[27] Jon Howell and Stuart Schechter. What you see
is what they get: Protecting users from unwanted
use of microphones, cameras, and other sensors.
In Collin Jackson, editor, Proceedings of W2SP
2010. IEEE Computer Society, May 2010. Online:
https://research.microsoft.com/
pubs/131132/devices-camera-ready.
pdf.
[28] iFixit.

MacBook Pro Retina Display tear-
down. 2013. Online: http://www.ifixit.
com/Teardown/MacBook+Pro+Retina+
Display+Teardown/9493.

[29] Samson Technologies Inc. Meteor Mic - USB
Studio Microphone. 2013. Online: http://www.
samsontech.com/samson/products/
microphones/usb-microphones/
meteormic/.

[30] David Kennedy and Josh Kelley.

PowerShell
omfg. . . .
Presented at DefCon 18, August
2010. Online: http://www.youtube.com/
watch?v=eWoAGxh0a_Q.

[31] Jinyung Kim, Yongho Yoon, Kwangkeun Yi, and
Junbum Shin. ScanDal: Stack analyzer for de-
tecting privacy leaks in android applications.
In
Hao Chen and Larry Koved, editors, Proceed-
ings of MOST 2013. IEEE Computer Society, May
2013. Online: http://www.mostconf.org/
2012/papers/26.pdf.

[32] Nicholas S. Kovach. Accelerating malware detec-
tion via a graphics processing unit. Master’s thesis,
Air Force Institute of Technology, September 2010.
[33] Evangelos Ladakis, Lazaros Koromilas, Giorgos
Vasiliadis, Michalis Polychronakis, and Sotiris Ioan-
nidis. You can type, but you can’t hide: A stealthy
GPU-based keylogger.
In Thorsten Holz and
Sotiris Ioannidis, editors, Proceedings of EuroSec
2013. ACM, April 2013. Online: http://www.
cs.columbia.edu/~mikepo/papers/
gpukeylogger.eurosec13.pdf.

[34] Luxland, Inc. Detect and recognize faces with
2013. Online: http://
Luxand FaceSDK.
luxand.com/facesdk/index_c.php. Last
accessed: 2013-08-06.

[35] Mactaris. Webcam Settings 2.0 will support
FaceTime HD camera on MacBook Air 2013. July
2013. Online: http://mactaris.blogspot.
com/2013/07/webcam-settings-20-
will-support.html.

[36] Philip Marquardt, Arunabh Verma, Henry Carter,
and Patrick Traynor.
(sp)iPhone: Decoding
vibrations from nearby keyboards using mo-
bile phone accelerometers.
In George Danezis
and Vitaly Shmatikov, editors, Proceedings of
CCS 2011. ACM Press, October 2011. Online:
http://www.cc.gatech.edu/~traynor/
papers/traynor-ccs11.pdf.

[37] 1/6-Inch SOC VGA CMOS Digital Image Sensor:
MT9V11212ASTC. Micron Technology, Inc., 2005.
Online:
http://download.micron.com/
pdf/datasheets/imaging/MT9V112.
pdf.

[38] Charlie Miller. Owning the fanboys: Hacking
Mac OS X. Presented at Black Hat Japan Brief-
ings, October 2008. Online: https://www.
blackhat.com/presentations/bh-jp-
08/bh-jp-08-Miller/BlackHat-Japan-
08-Miller-Hacking-OSX.pdf.

USENIX Association  

23rd USENIX Security Symposium  349

13

[39] Charlie Miller. Battery ﬁrmware hacking:

In-
side the innards of a smart battery. Presented
at Black Hat Brieﬁngs, August 2011. Online:
http://media.blackhat.com/bh-us-
11/Miller/BH_US_11_Miller_Battery_
Firmware_Public_WP.pdf.

[40] Emiliano Miluzzo, Alexander Varshavsky, Suhrid
Balakrishnan, and Romit Roy Choudhury. Tap-
Prints: Your ﬁnger taps have ﬁngerprints.
In
Srinivasan Seshan and Lin Zhong, editors, Pro-
ceedings of MobiSys 2012. ACM Press, June
2012.
Online: http://synrg.ee.duke.
edu/papers/tapprints-final.pdf.

[41] HD Moore. A penetration tester’s guide to IPMI
July 2013. Online: https://

and BMCs.
community.rapid7.com/community/
metasploit/blog/2013/07/02/a-
penetration-testers-guide-to-ipmi.
[42] Martha T. Moore. Pa. school district’s webcam
surveillance focus of suit. USA Today, May 2010.
Online:
http://usatoday30.usatoday.
com/tech/news/surveillance/2010-
05-02-school-spy_N.htm.

[43] Andy O’Donnell. How to secure your webcam
in less than 2 seconds. March 2011. Online:
http://netsecurity.about.com/b/
2011/03/25/how-to-secure-your-
webcam-in-less-than-2-seconds.htm.
[44] Devon O’Neil. Reﬂecting on Tony Hawk’s 900.
ESPN, May 2014. Online: http://xgames.
espn.go.com/events/2014/austin/
article/10622648/twenty-years-20-
firsts-tony-hawk-900.

[45] Oracle VM VirtualBox R(cid:31). Oracle Corporation,
2013. Online: http://www.virtualbox.
org/manual/.

[46] Emmanuel Owusu, Jun Han, Sauvik Das, Adrian
Perrig, and Joy Zhang. ACCessory: Password in-
ference using accelerometers on smartphones. In
Rajesh Krishna Balan, editor, Proceedings of Hot-
Mobile 2012. ACM Press, February 2012. On-
line: http://www.hotmobile.org/2012/
papers/HotMobile12-final42.pdf.

[47] Phisher Cat. Webcam light scaring slaves. . . .
July 2013. Online: http://www.hackforums.
net/showthread.php?tid=3660650. Reg-
istration required. Last accessed 2013-08-06.

July 2010.

at BlackHat Brieﬁngs,
https://media.blackhat.com/bh-us-
10/presentations/Rushing/BlackHat-
USA-2010-Rushing-USB-HID-slides.
pdf.

Online:

[49] Sam Prell. Watch the Spelunky run that set a new
high score record. joystiq, February 2014. Online:
http://www.joystiq.com/2014/02/23/
watch-the-spelunky-run-that-set-
a-new-high-score-record/.

[50] Reinhard Riedmüller, Mark M. Seeger, Harald
Baier, Christoph Busch, and Stephen D. Wolthusen.
Constraints on autonomous use of standard GPU
components for asynchronous observations and
intrustion detection.
In Anna Brunstrom and
Svein J. Knapskog, editors, Proceedings of IWSCN
2010. IEEE Computer Society, May 2010. Online:
http://ieeexplore.ieee.org/xpl/
freeabs_all.jsp?arnumber=5497999.

[51] Thomas Ristenpart, Gabriel Maganis, Arvind
Krishnamurthy, and Tadayoshi Kohno. Privacy-
preserving location tracking of lost or stolen devices:
Cryptographic techniques and replacing trusted
third parties with DHTs.
In Paul Van Oorschot,
editor, Proceedings of USENIX Security 2008.
USENIX, July 2008. Online: http://adeona.
cs.washington.edu/papers/adeona-
usenixsecurity08.pdf.

[52] Thomas Ristenpart, Gabriel Maganis, Arvind Kr-
ishnamurthy, and Tadayoshi Kohno. Adeona.
October 2009. Online: http://adeona.cs.
washington.edu/index.html.

[53] Sebastian Rohde, Thomas Eisenbarth, Erik Dahmen,
Johannes Buchmann, and Christof Paar. Fast hash-
based signatures on constrained devices. In Gilles
Grimaud and Frano¸is Xavier Standaert, editors,
Proceedings of CARDIS 2008. Springer, September
2008. Online: https://www.hgi.rub.de/
hgi/publikationen/fast-hash-based-
signatures-constrained-devices/.

[54] Roman Schlegel, Kehuan Zhang, Xiaoyong Zhou,
Mehool Intwala, Apu Kapadia, and XiaoFeng Wang.
Soundcomber: A stealthy and context-aware sound
trojan for smartphones.
In Adrian Perrig, editor,
Proceedings of NDSS 2011. Internet Society, Febru-
ary 2011. Online: http://www.cs.indiana.
edu/~kapadia/papers/soundcomber-
ndss11.pdf.

[48] Jason Pisani, Paul Carugati, and Richard Rushing.
Presented

USB-HID hacker interface design.

[55] Stop Police Brutality. Cop breaks 84 year old’s
neck for touching him. December 2013. Online:

350  23rd USENIX Security Symposium 

USENIX Association

14

http://www.policebrutality.info/
2013/12/cop-breaks-84-year-olds-
neck-for-touching-him.html.

[56] Robert Templeman, Zahid Rahman, David Crandall,
PlaceRaider: Virtual theft
and Apu Kapadia.
in physical spaces with smartphones.
In Peng
Ning, editor, Proceedings of NDSS 2013. Internet
Society, February 2013. Online: http://www.
internetsociety.org/sites/default/
files/02_2_0.pdf.

[57] Alexander Tereshkin and Rafal Wojtczuk.

Intro-
ducing ring −3 rootkits. Presented at Black Hat
Brieﬁngs, July 2009. Online: http://www.
blackhat.com/presentations/bh-usa-
09/TERESHKIN/BHUSA09-Tereshkin-
Ring3Rootkit-SLIDES.pdf.

[58] The iPatch. The iPatch. 2011. Online: http://
www.theipatch.com. Last accessed: 2013-08-
07.

[59] Craig Timberg and Ellen Nakashima.

FBI’s
search for ‘Mo,’ suspect in bomb threats, high-
The
lights use of malware for surveillance.
Washington Post, December 2013.
Online:
http://www.washingtonpost.com/
business/technology/fbis-search-
for-mo-suspect-in-bomb-threats-
highlights-use-of-malware-for-
surveillance/2013/12/06/352ba174-
5397-11e3-9e2c-e1d01116fd98_story.
html.

[60] Giorgos Vasiliadis, Michalis Polychronakis, and
Sotiris Ioannidis. GPU-assisted malware.
In
Jean-Yves Marion, Noam Rathaus, and Cliff
Zhou, editors, Proceedings of MALWARE 2010,
IEEE Computer Society, October
pages 1–6.
2010.
Online: http://dcs.ics.forth.
gr/Activities/papers/gpumalware.
malware10.pdf.

[61] Vimicro.

VC0358 USB 2.0 Camera Proces-
sor, September 2012. Online: http://www.
vimicro.com/english/product/pdf/
Vimicro_VC0358_PB_V1.1.pdf.

[62] Zhaohui Wang and Angelos Stavrou. Exploiting
smart-phone USB connectivity for fun and proﬁt.
In Patrick Traynor and Kevin Butler, editors, Pro-
ceedings of ACSAC 2010, pages 357–366. ACM
Press, December 2010. Online: http://dl.acm.
org/citation.cfm?id=1920314.

[63] Richard Wheatsone.

Video: CCTV footage
shows the moment masked armed robber holds

terriﬁed shopkeeper’s head.

Mirror,
gun at
February 2014. Online: http://www.mirror.
co.uk/news/uk-news/urmston-armed-
robbery-cctv-footage-3149475.

[64] ZTech.

QuickCam Pro 9000 LED Control.
Post on the Logitech Forums, February 2008.
Online:
http://forums.logitech.com/
t5/Webcams/QuickCam-Pro-9000-LED-
Control/td-p/186301.
2013-08-06.

Last accessed:

A Virtual machine escape
The reprogramability of the iSight ﬁrmware can be ex-
ploited to effect a virtual machine escape whereby mal-
ware running in a guest operating system is able to escape
the conﬁnes of the virtual machine and inﬂuence the host
operating system.

One method is to reprogram the iSight from inside the
virtual machine to act as a USB Human Interface Device
(HID) such as a mouse or keyboard. Once the iSight
reenumerates, it would send mouse movements and clicks
or key presses which the host operating system would
then interpret as actions from the user.

To demonstrate the feasibility of a virtual machine es-
cape from a VirtualBox virtual machine, we implemented
a USB HID keyboard which, once loaded, performs the
following actions in order:

1. send a “host key” press;
2. send command-space to open Spotlight;
3. send the key presses for “Terminal.app” one at a

time;

4. wait a few seconds, send a return key press, and wait

a few more seconds for the Terminal to open;

5. send the key presses for a shell command followed

by a return key press;

6. disconnect from the USB bus and modify its USB
device descriptor to use the product ID 0x8300 —
the PID for the iSight in its unprogrammed state; and

7. reenumerate.
The VirtualBox host key, which defaults to the left com-
mand key on a Mac host, releases keyboard ownership,
causing the rest of the key presses to go to the host operat-
ing system rather than to the guest operating system [45,
Chapter 1].

Figure 4 shows an iSight that has been reprogrammed
from inside a VirtualBox virtual machine sending key
presses to Spotlight, instructing it to open Terminal.app.
When a new keyboard is ﬁrst plugged into the com-
puter, the Keyboard Setup Assistant asks the user to press
several keys in order to determine the keyboard layout.
This behavior appears to be controlled by the vendor ID,
product ID, and device release number. By using the ap-
propriate values for an Apple USB keyboard, the assistant

USENIX Association  

23rd USENIX Security Symposium  351

15

352  23rd USENIX Security Symposium 

USENIX Association

Figure4:Virtualmachineescape.TheiSighthasbeenreprogrammedtoactasaUSBkeyboardfrominsideaVirtualBoxvirtualmachineanditissendingkeypressestothehostoperatingsystem.Itisinthemiddleofentering“Terminal.app”intoSpotlight.doesnotappearandthereisnovisualindicationthattheoperatingsystembelievesanewkeyboardhasconnected.TheshellcommandenteredintotheTerminalisuncon-strainedandcould,forexample,usecurltodownloadarbitrary,newcodeandrunit.AftertheiSighthasﬁnishedtypingcommands,itreenu-meratesasanunprogrammediSightwhichcausestheAppleUSBVideoSupportdrivertoreprogramitwiththelegitimateiSightﬁrmware,removingevidencethattheiSightwastheinfectionvector.AlthoughweusetheiSighttoescapefromthevirtualmachine,intheory,anyEZ-USBdevicewhichisaccessi-blefrominsidethevirtualmachinecanbereprogrammedtobehaveasaHIDkeyboard.TheonemajorlimitationisthattheUSBdevicemustbeconnectedtovirtualmachinebeforetheattackispossible.Bydefault,virtualmachinemonitorsdonotprovidethisconnectionformostdevicesandthusmalwarewouldneedtocoercetheuserintoestablishingtheconnection.Evenwiththedeviceconnectedtothevirtualmachine,thereisnofeedbacktotheﬁrmwarethattheattackisproceedingasplanned.AllitcandoissendkeypressesinresponsetheUSBpolling.Iftheuserissittinginfrontofthecomputer,thekeypressessentbytheiSightmaybeapparentandtheusercaninterferebyperforminganactionsuchastypingorclickingthemouse.OnewaytopartiallycompensateistodecreasetheUSBpollingintervalbychangingtheUSBendpointdescriptorsintheﬁrmwareallowingtheiSighttosendkeypressesmorequickly.Eachoperatingsystemhasitsownpolicywhichgov-ernsaprocess’sabilitytosendUSBdevicerequests.OnLinux,thisiscontrolledbyudev.InFigure4,weusedsudoinsidethevirtualmachinetobypasstheaccesscon-trolsoftheguestoperatingsystem.Alternatively,theappropriatepermissionscouldbegrantedtotheuser.Oneofthesestepsisrequiredeventhoughthehostoperatingsystem,OSX,imposesnorestrictionsontheuseofUSBdevicerequests.Sinceeachguestoperatingsystemcon-trolsaccesstotheUSBdeviceonceithasbeenconnectedtothevirtualmachine,toperformanescape,malwaremustﬁrstacquiresufﬁcientprivilegesintheguestop-eratingsystemtoreprogramthecamera—apotentiallynontrivialfeat.16