Thwarting Cache Side-Channel Attacks Through

Dynamic Software Diversity

Stephen Crane, Andrei Homescu, Stefan Brunthaler, Per Larsen, and Michael Franz

University of California, Irvine

{sjcrane, ahomescu, s.brunthaler, perl, franz}@uci.edu

Abstract—We explore software diversity as a defense against
side-channel attacks by dynamically and systematically random-
izing the control ﬂow of programs. Existing software diversity
techniques transform each program trace identically. Our di-
versity based technique instead transforms programs to make
each program trace unique. This approach offers probabilistic
protection against both online and off-line side-channel attacks.
In particular, we create a large number of unique program
execution paths by automatically generating diversiﬁed replicas
for parts of an input program. Replicas derived from the same
original program fragment have different implementations, but
perform semantically equivalent computations. At runtime we
then randomly and frequently switch between these replicas.

We evaluate how well our approach thwarts cache-based side-
channel attacks, in which an attacker strives to recover cryp-
tographic keys by analyzing side-effects of program execution.
Our method requires no manual effort or hardware changes,
has a reasonable performance impact, and reduces side-channel
information leakage signiﬁcantly.

I. MOTIVATION

Artiﬁcial software diversity, like its biological counterpart,
is a highly ﬂexible and efﬁcient defense mechanism. Code
injection, code reuse, and reverse engineering attacks are all
signiﬁcantly harder against diversiﬁed software ([1], [2], [3],
[4], [5], [6], [7], [8]). We propose to extend software diversity
to protect against side-channel attacks, in particular cache side
channels.

Essentially, artiﬁcial software diversity denies attackers pre-
cise knowledge of their target by randomizing implementation
features of a program. Because code reuse and other related
attacks rely on static properties of a program, previous work
on software diversity predominantly focuses on randomizing
the program representation, e.g., the in-memory addresses of
code and data. Side-channel attacks, on the other hand, rely on
dynamic properties of programs, e.g., execution time, memory
latencies, or power consumption. Consequently, diversiﬁcation
against side channels must randomize a program’s execution
rather than its representation.

Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23264

Most existing diversiﬁcation approaches randomize pro-
grams before execution, e.g., during compilation, installation,
or loading. Ahead-of-time randomization is desirable because re-
diversiﬁcation during runtime impacts performance (similar to
just-in-time compilation). Some approaches interleave program
randomization and program execution ([9], [6], [10], [11]).
However, the granularity of randomization in these approaches
is quite coarse, potentially allowing an attacker to observe
the program uninterrupted for long enough to carry out a
successful side-channel attack. We avoid this problem by
extending techniques used to prevent reverse engineering such
as code replication and control-ﬂow randomization ([12], [7]).
Unlike these approaches, however, we replicate code at a
ﬁner grained level and produce a nearly unlimited number
of runtime paths by randomly switching between these replicas.
Rather than making control ﬂow difﬁcult to reverse engineer,
our technique randomly switches execution between different
copies of program fragments, which we refer to as replicas, to
randomize executed code and thus side-channel observations.
We call this new capability dynamic control-ﬂow diversity.

To vary the side-channel characteristics of replicas, we
employ diversifying transformations. Diversiﬁcation preserves
the original program semantics while ensuring that each replica
differs at the level of machine instructions. To protect against
cache side-channel attacks we use diversiﬁcations that vary
observable execution characteristics. Like other cache side-
channel mitigations, such as reloading the cache on context
switches and rewriting encryption routines to avoid optimized
lookup tables, introducing diversity has some performance
impact which we rigorously quantify in this paper.

In combination, dynamic control-ﬂow diversity and diversi-
fying transformations create binaries with randomized program
traces, without requiring hardware or developer assistance. In
this paper we explore the use of dynamic control-ﬂow diversity
against cache-based side-channel attacks on cryptographic
algorithms. Our main contributions are the following:

• We apply the new capability of dynamic control-ﬂow
diversity to the problem of side channels. To the best
of our knowledge, this is the ﬁrst use of automated
software diversity to mitigate cache side channels.

• We show how to generate machine code for efﬁcient
randomized control-ﬂow transfers and combine this
with a diversifying transformation to counter cache-
based side-channel attacks.

• We present a careful and detailed evaluation of applying
diversity to protect cache side channels and report the
following:

Input
Output : Time needed to encrypt the plaintext after

: Cache set c to probe, plaintext p, key k.

probing c.
Encrypt(k, p);
Evict cache set c;
t0 ←Time();
Encrypt(k, p);
t1 ←Time();
return t1 − t0;

Algorithm 1: EVICT+TIME attack.

Fig. 2: Example of cache structure on a modern processor.
Cache shown is 3MB in size, with 4096 (212) sets, 12-way
associativity and 64-byte cache lines. Memory addresses are
broken into a 46-bit (or less) tag, a 12-bit set number and a
6-bit line offset.

be placed into exactly one of these n sets. Each set stores at
most m lines simultaneously, in which case the cache is called
“m-way set associative”. In practice, caches are 4-, 8-, 12- and
16-way associative. Figure 2 shows the structure of a 3MB
12-way set associative cache found in our test system.

For efﬁciency, the processor shares these caches between
running processes but prevents processes from accessing
data belonging to other processes via the virtual memory
abstraction. However, since data from multiple processes is
concurrently stored in the cache, adversaries can indirectly
deduce information about which cache locations a target process
accesses by observing side-effects of cache accesses. Since
the data cache access patterns of many programs are input-
dependent and predictable, attackers can use knowledge of
some inputs and the target’s data access patterns to derive the
secret input.

To exploit cache access patterns, all cache timing attacks
rely on the same fundamental principle of cache behavior:
accessing data stored in the cache is measurably faster than
accessing the data from main memory. As a result, attacks can
exploit this principle as a side channel and observe different
cache behavior for certain segments of a program trace. In
the EVICT+TIME attack, we observe the effect of evicting an
entire cache set and forcing the encryption program to fetch
values from main memory, while in the PRIME+PROBE attack
we ﬁll a cache set and check which cache lines the encryption
evicts by observing the time to reload our data.

For convenience we summarize both AES attacks here
but refer interested readers to Tromer et al. [13] for further
details. Optimized AES implementations use four in-memory
tables (T0 through T3, each containing 256 four-byte values)
during encryption, and the access pattern of these tables varies
according to the key and plaintext inputs. Speciﬁcally, during
the ﬁrst of ten encryption rounds for plaintext p and key k,
the encryption process will access table Tl at index pi ⊕ ki

Input

: Array C of cache sets to probe, plaintext p, key
k.

Output : Array T of times needed to probe each set in
foreach c ∈ C do

C.

Read w values into cache set c from memory;

end
Encrypt(k, p);
foreach c ∈ C do
t0 ←Time();
Read w values from cache set c;
t1 ←Time();
T [c] ← t1 − t0;

end
return T;

Algorithm 2: PRIME+PROBE attack.

for all i = 0, . . . , 15 where l = i mod 4. Since we assume the
attacker knows the plaintext p, the attacker is able to derive
information about the key from information about which table
elements are loaded from memory.

Algorithm 1 shows the EVICT+TIME attack. We derive
the table access patterns by observing the total execution time
of the encryption routine. By ﬁrst running the encryption on a
chosen, random plaintext, we prime the cache with the table
entries required during the encryption of this plaintext. We
then completely evict a cache set by loading a set of memory
locations that all map into the chosen cache set. By timing
another encryption of the same plaintext, we can then, by
averaging over many runs, determine whether the encryption
used a table value from that cache set, since the encryption
routine will take longer when accessing an evicted table entry
due to the cache miss.

The PRIME+PROBE attack (shown in Algorithm 2) is very
similar to the EVICT+TIME attack, but with the timing and
eviction roles ﬂipped. In this attack we ﬁrst create a known
starting cache state by loading a set of memory locations
into each relevant cache set. We then trigger encryption of a
chosen plaintext, which will modify this cache state by caching
accessed table entries. Finally, we determine which cache sets
were modiﬁed by timing a load of each cache set again. The
cache sets corresponding to table entries that the encryption
accessed will take longer to load than those not used, since the
encryption table entry will have displaced one of the original
entries loaded by the attacker and thus incur at least one cache
miss.

By analyzing a large set of these cache observations for
randomly chosen plaintexts, we can determine the key bits that

3

TagSet#LineOﬀset6 bits12 bits46 bitsMemory AddressSet 1 line 1Set 1 line 2Set 1 line 12Set 2 line 1Set 2 line 2Set 4096 line 12Cache StructureCacheLineDataMetadata64 bytes5–25% rate reduced the average correctly recovered key bits
to 81. Adding dynamic control-ﬂow diversity on top of this
further reduced the recovered key bits to 64 and 54 for function-
level and basic block-level diversity respectively. At the 10–
50% insertion rate we observed similar trends, with CF/BB
and dynamic loads reducing the EVICT+TIME key recovery
to 20 bits. Dynamic cache loads naturally have a higher
performance variation, since they require an extra indirect
load to implement runtime dynamic randomness. This results
in a more pronounced impact on the EVICT+TIME attack.

We observed similar trends for the PRIME+PROBE attack.
While dynamic loads have some effect on the attack by
themselves,
they are most effective when combined with
function or basic-block dynamic control-ﬂow diversity. In the
best case (CF/BB + Dyn) we observed an average correct key
recovery of only 14 bits. This result is near the theoretical
limit of 8 bits where an attacker gains no information from
the side channel. Recovering 8 bits of the key is equivalent to
an adversary randomly guessing the key by nibbles without
side-channel information, since such an adversary has a 1 in
16 chance to guess each nibble correctly and each key nibble is
independent for uniform random keys. This expected number
of correctly guessed key bits with no knowledge is a lower
bound on the accuracy of any side-channel attack, and we show
this bound as a dashed line in Figure 7.

Increasing samples: To investigate whether the attacks could
feasibly overcome our defense by gathering more side-channel
observations, we increased the iteration count for both attacks.
We found that while the attack accuracy increased marginally
with 4x and 8x the number of original attack measurements,
a realistic attack is still infeasible. With the CF/BB + Static
(10–50%) setting, 4x iterations resulted in average correctness
of 70 bits for the EVICT+TIME attack and 34 bits for the
PRIME+PROBE attack. 8x iterations resulted in 42 correct
key bits on average for the PRIME+PROBE attack. These
results indicate that dynamic control-ﬂow diversity is still
effective in the presence of better resourced attackers, although
it may require a different diversifying transformation to be
more effective against the EVICT+TIME attack.

Collecting eight times more samples than in our baseline
attack required about ﬁve minutes of attack time, resulted in
a 1.5GiB data ﬁle, and analysis took about an hour on a high
end, quad-core c3.xlarge Amazon EC2 instance. In a more
realistic situation collecting many more samples than this is
likely prohibitive. It is important to remember that our attack
is simply encrypting a single block, with no inter-process
communication or application overhead. Our tests represent
a best-case scenario for an attacker. A realistic attack would
target a service which is doing more work than our test attacks,
and thus data collection would be far slower and noisier in
practice.

B. Performance Evaluation

Most existing defenses against cache side-channel attacks,
e.g., reloading sensitive tables into cache after every context
switch or rewriting encryption algorithms to not use cached
tables at all, introduce moderate overheads. Our transformations
also marginally increase the cost of AES encryption. However
we believe this overhead to be quite reasonable for an automated

Transformation

Baseline

Static Loads (5-25%)
CF/F + Static (5-25%)
CF/BB + Static (5-25%)
Dyn Loads (5-25%)
CF/F + Dyn Loads (5-25%)
CF/BB + Dyn Loads (5-25%)
Static Loads (10-50%)
CF/F + Static (10-50%)
CF/F + Static (10-50%)
CF/BB + Static (10-50%)
CF/BB + Static (25@10-50%)
Dyn Loads (10-50%)
CF/BB + Dyn Loads (10-50%)
CF/F + Dyn Loads (10-50%)

File Size (KiB)

Increase Factor

657

657
702
716
658
755
727
657
766
941
737
837
660
759
784

1.00

1.00
1.07
1.09
1.00
1.15
1.11
1.00
1.17
1.43
1.12
1.27
1.00
1.15
1.19

TABLE I: File size increase for libgcrypt, relative to a non-
diversiﬁed baseline.

and general side-channel defense. To properly quantify this
impact, we studied an AES micro-benchmark, a full-ﬂedged
service — Apache serving ﬁles over HTTPS using AES — and
the SPEC CPU2006 benchmark suite.

From this performance analysis, in conjunction with attack
success, we found that the optimal trade-off between security
and performance is the CF/F + Static Loads setting. The
CF/BB + Static Loads setting was slightly more effective,
with only a small marginal decrease in performance, and is
thus also an ideal candidate setting. Using dynamic loads, while
slightly more effective, has a signiﬁcantly larger performance
impact for comparably little marginal security beneﬁt.

AES Micro-benchmark: We ﬁrst measured the increase in
time introduced by each transformation with an AES micro-
benchmark. We generated ten random different versions of
libgcrypt for each set of parameters, ran each version of
the AES encryption function ﬁve million times on random
plaintexts for each of ten different random keys and measured
the number of cycles for each encryption. The ﬁrst column of
each group in Figure 8 shows the slowdown for the libgcrypt
micro-benchmark.

We found that using function or basic-block level dynamic
control-ﬂow diversity along with static cache noise results
in a performance slowdown of 1.76x–2.02x compared to the
baseline AES encryption when using 10–50% cache noise
insertion. Dynamic cache noise at a 5–25% rate results in
similar performance, but 10–50% insertion of dynamic loads
has signiﬁcantly more impact on performance (2.39–2.87x
slowdown).

In addition to measuring encryption time, we investigated
the impact of our transformations on the size of the encryption
library. While desktop disk space is currently plentiful, this is
not the case for embedded or mobile systems. Many programs
are also distributed over the Internet through communication
links that have either bandwidth or data limits. Table I shows
the impact of our transformations on the size of the libgcrypt
shared object.

Application Benchmark: In the previous section we mea-
sured the performance impact on AES encryption alone,
encrypting a single block. However, to get a more realistic
picture of the performance impact of our techniques, we also

8

Fig. 8: Performance slowdown factor. libgcrypt: AES micro-benchmark encryption performance slowdown, relative to a non-
diversiﬁed baseline. Apache: slowdown when serving a 4MB ﬁle over HTTPS with AES block cipher, relative to a non-diversiﬁed
baseline.

Fig. 9: Performance slowdown factor for SPEC CPU2006 with function-level dynamic control-ﬂow diversity on 25% of functions
and 10–50% static cache noise inserted in all functions. Y-axis is on a log scale.

evaluated the performance overhead of dynamic control-ﬂow
diversity and our transformations on Apache 2.4.10 serving AES
encrypted data. We used the standard apachebench (ab) tool to
evaluate performance, connecting over https to an Apache
instance using a diversiﬁed version of the OpenSSL 1.0.1
library2.

As seen in the second column of each group in Figure 8,
the overall slowdown of our techniques varies from 1.25x for
static cache noise to 2.1x for dynamic. The static noise CF/F
and CF/BB settings in fact have identical overheads in this test,
and we therefore recommend the CF/BB setting for practical
applications which consist of more than just block cipher
encryption. The overall performance impact is naturally lower
than the simple micro-benchmark, since Apache does other
processing in addition to encryption. However, this workload is

2While we have not tested the effectiveness of the side-channel attack on this
library, we believe it would take minimal effort to port the attack to OpenSSL
or other table-based AES implementations.

more representative of a real-world application of cryptography
and AES in particular.

SPEC CPU2006: To illustrate the effects of our techniques
on CPU intensive workloads, we tested with the C and C++
portions of the SPEC CPU2006 benchmark suite. We selected
one parameter setting: function-level dynamic control-ﬂow
diversity with static noise. However, since SPEC does not have
any particular targets for cache side-channel attacks, we applied
dynamic control-ﬂow diversity universally over all functions
with a 25% probability. We also applied static cache noise
over all functions with a probability to insert noise for each
instruction chosen randomly for each basic block from the
range 10–50%. These parameters represent a worst-case for
the CF/F + Dyn setting. To account for random choices, we
built and ran SPEC with four different random seeds

As we show in Figure 9, our transformations introduce a
1.82x geometric mean overhead across all benchmarks. The
xalancbmk and dealII benchmarks stand out in this test. These

9

static (5-25%)CF/F + static (5-25%)CF/BB + static (5-25%)static (10-50%)CF/F + static (10-50%)CF/BB + static (10-50%)dynamic (5-25%)CF/F + dynamic (5-25%)CF/BB + dynamic (5-25%)dynamic (10-50%)CF/F + dynamic (10-50%)CF/BB + dynamic (10-50%)1.00x1.25x1.50x1.75x2.00x2.25x2.50x2.75x3.00xPerformance Slowdown FactorlibgcryptApache400_perlbench401_bzip2403_gcc429_mcf445_gobmk456_hmmer458_sjeng462_libquantum464_h264ref471_omnetpp473_astar483_xalancbmk433_milc444_namd447_dealII450_soplex453_povray470_lbm482_sphinx3Mean slowdownGeo Mean slowdown1.00x2.00x4.00x8.00xPerformance Slowdown Factorparticular benchmarks are large, complex C++ programs with
many function calls. Since we applied function dynamic control-
ﬂow diversity across the entire program in this case, we
naturally incur a higher overhead when the program calls
many small functions. In practice users of dynamic control-
ﬂow diversity should target transformations in only the sections
of code which might be vulnerable to a side-channel attack,
instead.

V. DISCUSSION

A. Parameter Settings

In our experiments we determined that a 5–25% insertion
percentage range for cache noise instructions is too narrow.
Dynamic control-ﬂow diversity works best when replicas have
very different runtime behavior, since it relies on switching
between replicas with varying side-channel effects. In addition,
libgcrypt is mostly straight line code and thus has a relatively low
number of functions and basic blocks used for AES encryption.
We expect that more complex cryptographic algorithms such as
RSA will have more control ﬂow, and thus more opportunity
to insert dynamic control-ﬂow diversity and switch between
variants.

Cache noise, especially the dynamic variant, has an impact
on execution time and thus the EVICT+TIME attack. However,
this transformation is designed speciﬁcally to disrupt
the
PRIME+PROBE attack by polluting the cache and masking
real AES table cache accesses. A transformation targeted at
varying the running time of each replica would be more suited
to disrupting this attack. We could adapt proposed hardware
junk code insertion techniques [21], [22] to work with dynamic
control-ﬂow diversity by inserting differing code with varying
runtimes into each replica.

In the best case, CF/BB + Dyn (10–50%), our
EVICT+TIME attack can derive only 4.96 key nibbles, or
about 20 key bits. Even with a more performance conscious
alternative, CF/BB + Static (10–50%), we still prevent the
attacker from ﬁnding 80 of 128 key bits. In the PRIME+PROBE
attack our experiments show an average of 3.32 correctly
recovered key nibbles, or 13.28 key bits, for the CF/BB + Static
(10–50%) setting. The remaining approximately unknown key
bits are too much to brute-force search, since this would require
checking 2n key guesses, where n is the number of unknown
key bits. With this low correctness an attacker is unlikely
to even be able to determine which key nibbles are correct,
and thus would gain no useful information from the attack.
Thus, we conclude that our techniques effectively mitigate the
PRIME+PROBE attack, given a realistic attack scenario.

We chose example parameters of ten replicas for each
program unit along with 5–25 and 10–50 percent probability
of inserting cache noise operations at each instruction as a
starting point after initial experimentation. These parameters
are representative of a narrow and wider range of insertion.
However, these parameters may not represent an ideal trade-off
between security and performance. In fact, these parameter
settings are not mutually exclusive, e.g., some functions may
be diversiﬁed with static noise while others get dynamic noise.
Some combination of function and basic block replicas may
also be useful for some applications. For future work, we

propose to develop heuristics for automatic parameter selection
through application and attack proﬁling.

B. Disabled Cache

Disabling caching of critical memory is an often suggested
naive approach to preventing cache side-channel attacks [13].
This approach is attractive since existing commodity processors
support selectively disabling page caching, but unfortunately it
is prohibitively slow. To verify that this mitigation is impractical,
we carefully measured the performance of the AES routine
in libgcrypt with caching disabled for the AES lookup tables.
This required writing a custom Linux kernel module to map
and mark a page of memory as uncacheable using the Page
Attribute Table (PAT) available on x86 CPUs. The user mode
application, in this case libgcrypt, can then map this page into its
address space and store the lookup table into it. This interface,
while technically possible, is complex and not available in the
standard Linux kernel.

We modiﬁed libgcrypt to utilize this approach and tested the
same AES micro-benchmark described above. We found that
disabling caching on only the single AES lookup page caused
the encryption routine to be 75 times slower than normal. There-
fore disabling caching, even for a single page, is impractical
on modern hardware. We discuss other hardware based cache
protections in Section VI, however, these approaches are not
available in commodity processors.

C. Implementation Limitations

For our initial investigation of applying control-ﬂow di-
versity to side channels, we manually inspected the libgcrypt
AES implementation to select nine functions relevant to the
encryption algorithm. This simple step required no modiﬁcation
to the original sources, and could be easily automated by
supplying only an encryption entry point. We forced our
system to replicate these functions and their basic blocks to
demonstrate the effectiveness of our techniques in a controlled
environment, without the additional complication of having the
system automatically select program units for diversiﬁcation
at random. However, this small manual effort was done to
arrive at a controlled experiment and is not required to use
control-ﬂow diversity. By randomly selecting program units for
replication with some conﬁgurable probability, our system can
probabilistically protect an entire application from side-channel
attacks with no manual effort.

Instead of random or manual program unit selection, we
believe that side-channel analysis tools such as CacheAudit [23]
can guide the selection of the critical program fragments and
parameters for diversiﬁcation. This should eliminate all manual
effort while preserving a high level of security.

D. Related Attacks

Diversifying transformations, such as inserting cache noise
instructions, can also be used to perform ﬁne grained code
layout randomization. This provides probabilistic protection
against return-oriented programming and its variants which
makes it realistic to expect that our defense technique can
simultaneously defend against two or more fundamentally
different classes of attacks. We will pursue this research
direction in follow up work as well.

10

VI. RELATED WORK

This paper unites two previously unrelated strands of
research: side channels and artiﬁcial software diversity. We
discuss the related work in each of these areas separately.

A. Side Channels

After Kocher described an initial timing side-channel attack
on public-key cryptosystems [24], researchers have proposed
a multitude of side-channel attacks against cryptographic
algorithms. While researchers have proposed many different
side-channel vectors ranging from power analysis [25] to
acoustic analysis [26], we focus on applying our techniques
against timing and cache-based attacks not requiring physical
access. Cache-based attacks were ﬁrst theoretically described
by Page [27] in 2002. In 2003, Tsunoo et al. [28] demonstrated
cache-based attacks against DES in practice. Bernstein [29]
then presented a simple timing attack on AES, along with
potential causes of this timing variability, including variable
cache behavior and latency. Shortly after, Osvik, Shamir, and
Tromer [30], [13] presented their attacks on AES, including
the two example attacks used in this paper. In addition to the
two synchronous attacks we evaluated our techniques against,
Osvik et al. also described an asynchronous attack relying only
on passively observing encryptions of plaintexts from a known
but non-uniform distribution.

Recently, Hund et al. [31] used a cache-based timing side-
channel attack to de-randomize kernel space ASLR in order
to accurately perform code-reuse attacks in the kernel address
space. Since we build our system on techniques proven to be
effective against code-reuse attacks, our dynamic control-ﬂow
diversity with NOP insertion is a perfect ﬁt to defend in depth
against this attack.

As side-channel attacks have matured, researchers have
proposed numerous defenses using both hardware and software.
We will now brieﬂy describe a few of the relevant defenses.

Hardware Defenses: Several different methods of prevent-
ing side channels at the hardware level have been proposed,
with varying degrees of practicality. In the context of differential
power analysis attacks, Irwin et al [21] proposed a new stage in
the processor execution pipeline which randomly mutates the
instruction stream with the assistance of a compiler-generated
register liveness map. Among other peephole transformations,
this mutation unit adds instructions that do not affect the
correct functioning of the program, which are a super-set of
our compiler-based NOP insertion transformation. Since our
transformations in software are similar to the techniques Irwin
et al. applied to differential power analysis, we expect that
our technique will apply directly to power analysis attacks as
well. Finally, Irwin et al. proposed a new probabilistic branch
instruction, maybe, that would allow us to efﬁciently randomize
control ﬂow without the use of a random buffer. Ambrose et
al. [22] also proposed inserting random instructions but with the
added requirement that inserted instructions modify processor
state, e.g., registers, so the new instructions are indistinguishable
from legitimate program code.

an attacker. However this would require a radical change to
current cache designs. Bernstein [29] suggested the addition
of a new CPU instruction to load an entire table into L1 cache
and perform a lookup. This approach provides consistent cache
access behavior regardless of input, and as such would eliminate
cache side channels through table lookups. Wang and Lee [33]
also proposed two new hardware cache designs to mitigate
cache side channels: PLcache and RPcache. PLcache has the
new capability of locking a sensitive cache partition into cache,
while RPcache randomizes the mapping from memory locations
to cache sets. While these techniques are powerful mitigations
against cache side-channel attacks, they all require additional
hardware features which major processor vendors are unlikely
to implement. In contrast, our techniques require no special
hardware support and can be used immediately.

Intel has recently implemented a new hardware instruction
to perform encryption and decryption for AES [34]. Since this
instruction is data independent, using it instead of a software
routine should protect against side-channel attacks on AES.
However, this hardware only implements AES, and thus we
still need defensive measures to protect other cryptographic
algorithms.

Software Defenses: The ideal defense against side-channel
attacks is to modify the sensitive program so that it has no
input-dependent side-effects, however this is an extremely
labor-intensive solution and is often infeasible. Developers
generally take this approach to removing timing side channels
by creating algorithms that run in constant-time regardless
of inputs. Bernstein [29] strongly recommends this approach,
while cautioning that software which the programmer expected
to run in constant time may not do so due to hardware
complexity.

Page [35] suggested manually adding noise to encryption
to make cache side-channel attacks more difﬁcult in a manner
conceptually similar to our automatic randomizing transforma-
tions. For instance, Page manually inserted garbage instructions
and random loads into the encryption routine to combat timing
and trace based attacks respectively. Page’s work is a form
of obfuscation rather than diversiﬁcation since all users run
the same binaries with the same runtime control-ﬂow. Our
combination of control ﬂow randomization and garbage code
insertion simultaneously defends against code reuse attacks and
side channels whereas garbage code in itself does not protect
against side channels and Page’s transformations do not protect
against code reuse.

Brickell et al. [36] proposed the use of compressed and
randomized tables for AES that would alleviate cache-based
attacks. However, this implementation process requires manu-
ally rewriting the AES implementation and is speciﬁc to the
operation of AES.

Cleemput et al. [37] proposed defenses that do not require
manual program modiﬁcation. In particular, they described the
use of compiler transformations to reduce timing variability.
Our approach, while also compiler-based, seeks to mask
variability rather than remove it entirely, since opportunities to
automatically eliminate variable-time routines are limited.

To speciﬁcally target cache-based attacks, Page [32] pro-
posed partitioning the cache into disjoint conﬁgurable sets so
that a sensitive program cannot share cache resources with

In their recent paper addressing side-channel attacks in the
context of virtualized cloud computing, Zhang and Reiter [38]
proposed periodically scrubbing shared caches used by sensitive

11

processes. This scheme potentially breaks cache snooping by a
time-shared process on the same core, but will not necessarily
combat cache attacks in a Simultaneous Multithreading (SMT)
context or continuous power analysis attacks. Since our random
decision points are more ﬁne grained than the scrubbing
interval, our techniques have greater potential against these ﬁne-
grained attacks, although this would require more investigation.
In addition, control-ﬂow diversity does not depend on any
resources outside the program and is thus applicable in
situations without hypervisors, such as embedded software.

Finally, Tromer et al. [13] mention adding noise to memory
accesses with spurious accesses to decrease the signal available
to the attacker. Effectively, our technique accomplishes this goal
in a general way that could be extended to other side channels,
and we provide a concrete evaluation showing its effectiveness
in practice. Since adding replicas exponentially increases the
number of possible execution traces, we can ratchet our defense
up sufﬁciently so that an attacker cannot feasibly collect and
analyze enough samples.

B. Artiﬁcial Software Diversity

The literature on artiﬁcial software diversity is extensive;
we limit ourselves to the work most closely related to ours.
Larsen et al. provides a comprehensive systematization of
approaches to artiﬁcial software diversity [39]. Cohen initially
pioneered software diversity as a protection against reverse
engineering [1] and was ﬁrst to suggest garbage code insertion
and transformations that obscure the actual control ﬂow.
Collberg et al. [40] extended these ideas into a broader set
of obfuscating transformations against reverse engineering
attacks and introduced the notion of opaque predicates [41].
While opaque predicates usually refer to predicates that have
a known outcome at obfuscation time but are expensive to
decide afterward via static analysis, Collberg et al. also mention
“variable” opaque predicates that ﬂip-ﬂop between true and
false at runtime. These ideas were evaluated in depth by
Anckaert et al. [12] as a defense against reverse engineering,
by Collberg et al. [8] in context of client-side tampering of
networked systems, and by Coppens et al. [7] to prevent reverse
engineering of patches. Our work differs in its use of control
ﬂow randomization: we use it to switch among implementation
variants (replicas) with ﬁne-granularity—not as a randomizing
transformation in itself. Furthermore, we aim to thwart side-
channel attacks rather than reverse engineering.

Several diversiﬁed defenses against code reuse attacks have
dynamic aspects. Giuffrida et al. [6] presented a compiler-
based approach that periodically rerandomizes services in a
microkernel OS while it is running. Live rerandomization
works by periodically transferring the application state from
one process to another such that the old and new processes
run diversiﬁed variants of the same input program. While this
provides excellent protection against code reuse attacks, the
rerandomization overhead prevents the ﬁne granularity our
approach efﬁciently supports.

Hiser et al. [4] performed ﬁne-grained code layout random-
ization using a process virtual machine. The approach uses a
code cache that leads to predictable program traces and might
constitute a side channel in itself. Homescu et al. [11] diversiﬁes
just-in-time compiled code and similarly caches translated

code to improve performance. Shioji et al. [10] introduced
“code shredding” that embeds random checksums in pointers to
thwart control-ﬂow hijacking. To improve performance and add
randomness, checksums are not masked out before the pointer
values are used in control ﬂow transfers. Rather, the entire code
section is replicated in process memory to make the targets of
checksummed pointers valid. Our use of code replication is
more ﬂexible because our granularity can vary at the function
or basic block level and has a lower memory overhead as a
result. Our performance overhead is also much lower since our
compiler-based approach avoids the overheads associated with
binary rewriting; Shioji report overheads ranging from 3x to
26x on Bzip2 1.0.5.

Novark and Berger secure the heap against memory manage-
ment errors via a randomizing memory allocator [9]. Allocations
are placed randomly in memory and stay in place until their
deallocation. Freed pages are overwritten with random data.
While this can interfere with side-channel attacks, attackers
can sample the victim process arbitrarily many times between
memory allocator activations.

Summing up, our work is the ﬁrst to use software diversity
to mitigate cache side-channel attacks. Previous diversiﬁcation
approaches comprise one or more randomizing code transfor-
mations. Our approach consists of a runtime randomization
mechanism to dynamically vary execution characteristics in
addition to a set of randomizing code transformations.

VII. CONCLUSION AND OUTLOOK

We provide the ﬁrst evaluation of software diversity as a
side-channel mitigation. To that end, we developed dynamic
control-ﬂow diversity which performs ﬁne-grained program
trace randomization. Our technique does not require source code
modiﬁcation or specialized hardware so it can be automatically
applied to existing software. We have implemented a prototype
diversiﬁer atop LLVM and rigorously evaluated the performance
of our techniques using modern, realistic cache side-channel
attacks in a setting that favors attackers. Our experimental
evaluation shows that our technique mitigates cryptographic
side channels with high efﬁcacy and moderate overhead of
1.5–2x in practice, making it viable for deployment.

Beyond the cryptographic side-channel problem addressed
in this paper, we expect that control-ﬂow diversity is simul-
taneously effective against other implementation-dependent
attacks, including code reuse and reverse engineering. We plan
to explore this in future work.

ACKNOWLEDGMENTS

We thank the anonymous reviewers for their insightful
comments and suggestions. We are also grateful for helpful
feedback from Mathias Payer and Mark Murphy.

This material is based upon work partially supported by the
Defense Advanced Research Projects Agency (DARPA) under
contracts D11PC20024 and N660001-1-2-4014, and generous
gifts from Mozilla and Oracle. Any opinions, ﬁndings, and
conclusions or recommendations expressed in this material
are those of the authors and do not necessarily reﬂect the
views of the Defense Advanced Research Projects Agency
(DARPA), its Contracting Agents, or any other agency of the
U.S. Government.

12

REFERENCES

[1] F. Cohen, “Operating system protection through program evolution,”

Computers and Security, vol. 12, no. 6, pp. 565–584, Oct. 1993.

[2] S. Forrest, A. Somayaji, and D. Ackley, “Building diverse computer
systems,” in Proceedings of the 6th Workshop on Hot Topics in Operating
Systems (HOTOS ’97), 1997, pp. 67–72.

[3] V. Pappas, M. Polychronakis, and A. D. Keromytis, “Smashing the
gadgets: Hindering return-oriented programming using in-place code
randomization,” in Proceedings of the 33rd IEEE Symposium on Security
and Privacy (S&P ’12), 2012, pp. 601–615.
J. Hiser, A. Nguyen-Tuong, M. Co, M. Hall, and J. W. Davidson, “ILR:
Where’d my gadgets go?” in Proceedings of the 33rd IEEE Symposium
on Security and Privacy (S&P ’12), 2012, pp. 571–585.

[4]

[5] R. Wartell, V. Mohan, K. W. Hamlen, and Z. Lin, “Binary stirring:
self-randomizing instruction addresses of legacy x86 binary code,” in
Proceedings of the 19th ACM Conference on Computer and Communi-
cations Security (CCS ’12). ACM, 2012, pp. 157–168.

[6] C. Giuffrida, A. Kuijsten, and A. S. Tanenbaum, “Enhanced operating
system security through efﬁcient and ﬁne-grained address space random-
ization,” in Proceedings of the 21st USENIX Security Symposium, 2012,
pp. 475–490.

[7] B. Coppens, B. De Sutter, and J. Maebe, “Feedback-driven binary
code diversiﬁcation,” ACM Transactions on Architecture and Code
Optimization, vol. 9, no. 4, pp. 24:1–24:26, Jan. 2013.

[8] C. S. Collberg, S. Martin, J. Myers, and J. Nagra, “Distributed application
tamper detection via continuous software updates,” in Proceedings of the
28th Annual Computer Security Applications Conference (ACSAC ’12),
2012, pp. 319–328.

[9] G. Novark and E. D. Berger, “Dieharder: securing the heap,” in Proceed-
ings of the 17th ACM Conference on Computer and Communications
Security (CCS ’10). ACM, 2010, pp. 573–584.

[10] E. Shioji, Y. Kawakoya, M. Iwamura, and T. Hariu, “Code shredding:
byte-granular randomization of program layout for detecting code-
reuse attacks,” in Proceedings of the 28th Annual Computer Security
Applications Conference (ACSAC ’12), 2012, pp. 309–318.

[11] A. Homescu, S. Brunthaler, P. Larsen, and M. Franz, “librando: Trans-
parent code randomization for just-in-time compilers,” in Proceedings of
the 20th ACM Conference on Computer and Communications Security
(CCS ’13). ACM, 2013, pp. 993–1004.

[12] B. Anckaert, M. Jakubowski, R. Venkatesan, and K. D. Bosschere, “Run-
time randomization to mitigate tampering,” in Proceedings of the 2nd
International Workshop on Security (IWSEC ’07), 2007, pp. 153–168.
[13] E. Tromer, D. A. Osvik, and A. Shamir, “Efﬁcient cache attacks on
AES, and countermeasures,” Journal of Cryptology, vol. 23, no. 1, pp.
37–71, Jan. 2010.

[14] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart, “Cross-VM side
channels and their use to extract private keys,” in Proceedings of the 19th
ACM Conference on Computer and Communications Security (CCS ’12).
ACM, 2012, pp. 305–316.

[15] A. Homescu, S. Neisius, P. Larsen, S. Brunthaler, and M. Franz,
“Proﬁle-guided automatic software diversity,” in Proceedings of the
11th IEEE/ACM International Symposium on Code Generation and
Optimization (CGO ’13), 2013, pp. 1–11.

[16] D. Gullasch, E. Bangerter, and S. Krenn, “Cache games - bringing
access-based cache attacks on AES to practice,” in Proceedings of the
32nd IEEE Symposium on Security and Privacy (S&P ’11), 2011, pp.
490–505.

[17] Y. Yarom and K. Falkner, “Flush+reload: a high resolution, low noise, L3
cache side-channel attack,” Cryptology ePrint Archive, Report 2013/448,
2013.

[18] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage, “Hey, you, get
off of my cloud: Exploring information leakage in third-party compute
clouds,” in Proceedings of the 16th ACM Conference on Computer and
Communications Security (CCS ’09). ACM, 2009, pp. 199–212.

[19] M. Saito and M. Matsumoto, “SIMD-Oriented fast mersenne twister: a
128-bit pseudorandom number generator,” in Monte Carlo and Quasi-
Monte Carlo Methods 2006, A. Keller, S. Heinrich, and H. Niederreiter,
Eds. Springer Berlin Heidelberg, Jan. 2008, pp. 607–622.

[21]

[20] C. Lattner and V. Adve, “LLVM: A compilation framework for
lifelong program analysis & transformation,” in Proceedings of the
2nd IEEE/ACM International Symposium on Code Generation and
Optimization (CGO ’04), 2004, pp. 75–87.
J. Irwin, D. Page, and N. Smart, “Instruction stream mutation for non-
deterministic processors,” in Proceedings of the 13th IEEE International
Conference on Application-Speciﬁc Systems, Architectures and Proces-
sors (ASAP ’02), 2002, pp. 286–295.
J. A. Ambrose, R. G. Ragel, and S. Parameswaran, “RIJID: random
code injection to mask power analysis based side channel attacks,” in
Proceedings of the 44th Design Automation Conference (DAC ’07).
ACM, 2007, pp. 489–492.

[22]

[23] G. Doychev, D. Feld, B. K¨opf, L. Mauborgne, and J. Reineke,
“Cacheaudit: A tool for the static analysis of cache side channels,”
in Proceedings of the 22nd USENIX Security Symposium, 2013, pp.
431–446.

[24] P. C. Kocher, “Timing attacks on implementations of difﬁe-hellman, RSA,
DSS, and other systems,” in Advances in Cryptology (CRYPTO ’96), ser.
Lecture Notes in Computer Science, N. Koblitz, Ed. Springer Berlin
Heidelberg, Jan. 1996, no. 1109, pp. 104–113.

[25] P. Kocher, J. Jaffe, and B. Jun, “Differential power analysis,” in Advances
in Cryptology (CRYPTO ’99), ser. Lecture Notes in Computer Science,
M. Wiener, Ed. Springer Berlin Heidelberg, Jan. 1999, no. 1666, pp.
388–397.

[26] D. Genkin, A. Shamir, and E. Tromer, “RSA key extraction via
low-bandwidth acoustic cryptanalysis,” in Advances in Cryptology
(CRYPTO ’14), ser. Lecture Notes in Computer Science, J. A. Garay
and R. Gennaro, Eds. Springer Berlin Heidelberg, Jan. 2014.

[27] D. Page, “Theoretical use of cache memory as a cryptanalytic side-

channel,” Cryptology ePrint Archive, Report 2002/169, 2002.

[28] Y. Tsunoo, T. Saito, T. Suzaki, M. Shigeri, and H. Miyauchi, “Cryptanal-
ysis of DES implemented on computers with cache,” in Cryptographic
Hardware and Embedded Systems (CHES ’03), ser. Lecture Notes in
Computer Science, C. D. Walter, C¸ . K. Koc¸, and C. Paar, Eds. Springer
Berlin Heidelberg, Jan. 2003, no. 2779, pp. 62–76.

[29] D. J. Bernstein, “Cache-timing attacks on AES,” Preprint, 2005.
[30] D. A. Osvik, A. Shamir, and E. Tromer, “Cache attacks and counter-
measures: The case of AES,” in Topics in Cryptology (CT-RSA ’06),
ser. Lecture Notes in Computer Science, D. Pointcheval, Ed. Springer
Berlin Heidelberg, Jan. 2006, no. 3860, pp. 1–20.

[31] R. Hund, C. Willems, and T. Holz, “Practical timing side channel attacks
against kernel space ASLR,” in Proceedings of the 34th IEEE Symposium
on Security and Privacy (S&P ’13), 2013.

[32] D. Page, “Partitioned cache architecture as a side-channel defence

mechanism,” Cryptology ePrint Archive, Report 2005/280, 2005.

[33] Z. Wang and R. B. Lee, “New cache designs for thwarting software cache-
based side channel attacks,” in Proceedings of the 34th International
Symposium on Computer Architecture (ISCA ’07). ACM, 2007, pp.
494–505.

[34] S. Gueron, “Intel advanced encryption standard (AES) instructions set,”

Intel White Paper, 2010.

[35] D. Page, “Defending against cache-based side-channel attacks,” Infor-

mation Security Technical Report, vol. 8, no. 1, pp. 30–44, 2003.

[36] E. Brickell, G. Graunke, M. Neve, and J.-P. Seifert, “Software mitigations
to hedge AES against cache-based software side channel vulnerabilities.”
Cryptology ePrint Archive, Report 2006/052, 2006.
J. V. Cleemput, B. Coppens, and B. De Sutter, “Compiler mitigations
for time attacks on modern x86 processors,” ACM Transactions on
Architecture and Code Optimization, vol. 8, no. 4, pp. 23:1–23:20, Jan.
2012.

[37]

[38] Y. Zhang and M. K. Reiter, “D¨uppel: Retroﬁtting commodity operating
systems to mitigate cache side channels in the cloud,” in Proceedings of
the 20th ACM Conference on Computer and Communications Security
(CCS ’13). ACM, 2013, pp. 827–838.

[39] P. Larsen, A. Homescu, S. Brunthaler, and M. Franz, “SoK: automated
software diversity,” in Proceedings of the 35th IEEE Symposium on
Security and Privacy (S&P ’14), 2014, pp. 276–291.

[40] C. Collberg, C. Thomborson, and D. Low, “A taxonomy of obfuscating
transformations,” Department of Computer Science, University of
Auckland, New Zealand, Tech. Rep. 148, 1997.

13

[41] C. S. Collberg, C. D. Thomborson, and D. Low, “Manufacturing cheap,
resilient, and stealthy opaque constructs,” in Proceedings of the 25th
ACM Symposium on Principles of Programming Languages (POPL ’98),
1998, pp. 184–196.

14

