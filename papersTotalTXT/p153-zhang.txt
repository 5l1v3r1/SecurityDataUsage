DeTrust: Defeating Hardware Trust Veriﬁcation with

Stealthy Implicitly-Triggered Hardware Trojans

Jie Zhang, Feng Yuan and Qiang Xu
CUhk REliable Computing Laboratory (CURE)
Department of Computer Science & Engineering

The Chinese University of Hong Kong, Shatin, N.T., Hong Kong

{jzhang,fyuan,qxu}@cse.cuhk.edu.hk

ABSTRACT
Hardware Trojans (HTs) inserted at design time by malicious in-
siders on the design team or third-party intellectual property (IP)
providers pose a serious threat to the security of computing sys-
tems. Researchers have proposed several hardware trust veriﬁ-
cation techniques to mitigate such threats, and some of them are
shown to be able to effectively ﬂag all suspicious HTs implemented
in the Trust-Hub HT backdoor benchmark suite. No doubt to say,
adversaries would adjust their tactics of attacks accordingly and it
is hence essential to examine whether new types of HTs can be
designed to defeat these hardware trust veriﬁcation techniques.

In this paper, we present a systematic HT design methodology
to achieve the above objective, namely DeTrust. Given an HT de-
sign, DeTrust keeps its original malicious behavior while making
the HT resistant to state-of-the-art hardware trust veriﬁcation tech-
niques by manipulating its trigger designs. To be speciﬁc, DeTrust
implements stealthy implicit triggers for HTs by carefully spread-
ing the trigger logic into multiple sequential levels and combina-
tional logic blocks and combining the trigger logic with the normal
logic, so that they are not easily differentiable from normal logic.
As shown in our experimental results, adversaries can easily em-
ploy DeTrust to evade hardware trust veriﬁcation.

We close with a discussion on how to extend existing solutions to
alleviate the threat posed by DeTrust. However, they generally suf-
fer from high computational complexity, calling for more advanced
techniques to ensure hardware trust.

Categories and Subject Descriptors
B.6 [Logic Design]: Miscellaneous—Security and Trust

Keywords
hardware Trojan; hardware security; hardware Trojan design;
backdoors; implicit trigger

1.

INTRODUCTION

With the ever-increasing hardware complexity and the large num-
ber of third-parties involved in the design and fabrication process

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660289.

of integrated circuits (ICs), today’s IC products are vulnerable to
a wide range of malicious alterations, namely hardware Trojans
(HTs) [1–3]. For example, a hardware backdoor can be intro-
duced into the design by simply writing a few lines of hardware
description language (HDL) codes [4, 5], which leads to functional
deviation from design speciﬁcation and/or sensitive information
leakages. Skorobogatov and Woods [7] found a “backdoor” in a
military-grade FPGA device1, which could be exploited by attack-
ers to extract all the conﬁguration data from the chip and access/-
modify sensitive information. Liu et al. [8] demonstrated a silicon
implementation of a wireless cryptographic chip with an embedded
HT and showed it could leak secret keys. HTs thus pose a serious
threat to the security of computing systems and have called upon
the attention of several government agencies [9, 10].

HTs can be inserted into an IC product at any stage, e.g., speciﬁ-
cation, register-transfer level (RTL) design, IP integration, physical
design, and fabrication. Generally speaking, the likelihood of HTs
being inserted at design time is usually much higher than that being
inserted at manufacturing stage, because adversaries do not need to
access foundry facilities to implement HTs and it is also more ﬂex-
ible for them to implement various malicious functions.

In recent years, several techniques have been proposed to pro-
tect hardware designs against certain type of HTs inserted at de-
sign time [11–15]. Among them, some techniques [11–13] operate
at runtime and try to de-activate suspicious circuitries. These tech-
niques, however, require to modify the original design to include
runtime protections, and hence incur runtime overhead and increase
design complexity. Performing veriﬁcation for hardware trust with-
out necessarily modifying the design is therefore quite appealing.
Hicks et al. [11] made the ﬁrst attempt and formulated the HT de-
tection problem as an unused circuit identiﬁcation (UCI) problem.
However, due to the relatively simple deﬁnition of “unused circuit",
it could only cover a small set of HTs. Later, Zhang et al. [5] and
Sturton et al. [16] presented how to automatically construct HTs
that were able to evade UCI detection algorithm. Based on the
observation that HT trigger inputs are redundant to circuit normal
functions when HTs are not activated during functional veriﬁca-
tion, Zhang et al. [14] proposed a so-called VeriTrust technique,
which focused on HT trigger identiﬁcation. Recently, Waksman et
al. [15] presented a static HT detection technique based on Boolean
functional analysis, namely FANCI. Both [14] and [15] showed that
they were able to ﬂag all the suspicious HTs implemented in the
Trust-Hub hardware backdoor benchmark suite [6].

1The company responded that the hidden super key is used for failure anal-
ysis. However, it exactly matches the deﬁnition for backdoor given by the
dictionary: "Backdoor - an undocumented way to get access to a computer
system or the data it contains".

153HT design and HT identiﬁcation techniques are like arms race,
wherein designers update security measures to protect their system
while attackers respond with more tricky HTs. With state-of-the-art
hardware trust veriﬁcation techniques such as VeriTrust and FANCI
being able to effectively identify existing HTs, no doubt to say,
adversaries would adjust their tactics of attacks accordingly and
it is hence essential to examine whether new types of HTs can be
designed to defeat these hardware trust veriﬁcation techniques.
1.1 Threat Model

We follow the same threat model and assumptions used in [11,
14]. That is, a hardware design can be covertly compromised by
HTs inserted into the RTL source code or the gate-level netlist.
These HTs are introduced by one or more rogue designers in the
design team or integrated into the design with third-party IP cores.
Attackers cannot control the suite of tests used for functional veriﬁ-
cation, but they can learn arbitrary information about the test cases.
We assume that the veriﬁcation procedure is trustworthy and HTs
manifest themselves as long as they are activated.

Consequently, from the adversaries’ perspective, on the one hand,
HTs should be resistant to functional veriﬁcation with extremely
low activation probability; on the other hand, they should be re-
sistant to trust veriﬁcation by hiding as normal logic circuit. This
work aims to devise such an HT design methodology.
1.2 Contributions

In this work, we present a systematic HT design methodology
that is resistant to hardware trust veriﬁcation, namely DeTrust, by
targeting the weakness of these solutions. To be speciﬁc, to make
DeTrust evade FANCI, HT trigger logics are carefully spread among
multiple combinational logic blocks so that Boolean functional anal-
ysis would not ﬂag them as nearly-unused logics. To defeat Ver-
iTrust, we combine HT triggers with circuit original functional logic
and hide them into multiple sequential levels. Such implicit triggers
would not be seen as redundant inputs under non-trigger condi-
tion. In addition, DeTrust also borrows existing stealthy HT design
methodology (e.g., [5]) to hide from conventional functional veri-
ﬁcation and UCI techniques. With the above, HT designs can be
performed in a one-off manner to be resistant to trust veriﬁcation
solutions while still passing functional veriﬁcation.

To be speciﬁc, this work contributes to the ﬁeld of hardware trust

in the following ways:

• We show that VeriTrust [14] and FANCI [15] have limita-
tions. We design and implement an attack on a processor that
is able to evade these hardware trust veriﬁcation techniques
while still passing functional veriﬁcation.

• We present a systematic HT design methodology called De-
Trust that automatically equips HTs with stealthy implicit
triggers to be resistant to all existing hardware trust veriﬁca-
tion techniques in a one-off manner. We analyze the stealth-
iness of the proposed HT designs and present heuristic algo-
rithms to increase its stealthiness.

• We present how to extend VeriTrust and FANCI to alleviate
the threat posed by DeTrust. However, there is no easy ﬁx
to this problem. We analyze why such defenses are not sufﬁ-
cient to defend against DeTrust, even though they do increase
HT design effort.

The remainder of this paper is organized as follows. We ﬁrst
present the preliminaries related to hardware Trojan design and
identiﬁcation in Section 2. The proposed HT design methodology,

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:2)(cid:3)(cid:6)(cid:7)(cid:8)(cid:3)(cid:9)(cid:10)(cid:2)(cid:11)

(cid:12)(cid:3)(cid:13)(cid:14)(cid:11)(cid:2)(cid:15)(cid:7)(cid:16)(cid:13)(cid:3)(cid:17)(cid:18)(cid:13)(cid:19)

Figure 1: An HT-infected circuit with trigger inputs t1 and t2,
wherein the original logic function fn = d1d2 is compromised
by an HT with malicious function fm = t1t2d2 and the trigger
condition is {t1,t2} = {1,1}.
i.e., DeTrust, is then detailed in Section 3. We validate the effec-
tiveness of DeTrust by introducing practical attacks and analyzing
their stealthiness in Section 4. Next, we present some potential de-
fenses for DeTrust in Section 5. Finally, we survey related works
in Section 6 and conclude this paper in Section 7.
2. PRELIMINARIES

In this section, we ﬁrst introduce some terms used in this pa-
per. Next, we describe state-of-the-art hardware trust veriﬁcation
techniques for HTs inserted at design time. Finally, we discuss the
effectiveness of these techniques.
2.1 Deﬁnitions

Generally speaking, an HT is composed of its activation mech-
anism (referred to as trigger) and its malicious function (referred
to as payload). For the ease of discussion, we have the following
deﬁnitions:

DEFINITION 1. An HT-affected signal is a signal that the HT

targets to manipulate (e.g., f in Fig. 1).

DEFINITION 2. An HT-related signal is a signal that is driven

by any part of the HT (e.g., t1,t2,h1, f in Fig. 1).

DEFINITION 3. A functional input is an input that is used by

the circuit’s speciﬁed normal functionality (e.g., d1,d2 in Fig. 1).

DEFINITION 4. A trigger input is an input that is used in the

condition under which the HT is activated (e.g., t1,t2 in Fig. 1).

Note that, functional inputs can also serve as HT trigger in-

puts [16].
2.2 HT Classiﬁcation

In [14], the authors classiﬁed HTs into bug-based HTs and parasite-

based HTs, according to their impact on the normal functions of
the circuit. A Bug-based HT alters the circuit and causes it to lose
some of its normal functionalities while a parasite-based HT hides
along with the original circuit and does not cause it to lose any
normal functionalities. Generally speaking, when compared with
bug-based HTs, parasite-based HTs are more difﬁcult to be acti-
vated with functional veriﬁcation tests, since its malicious behav-
ior is not included in the speciﬁcation. As a result, almost all HTs
appeared in the literature belong to the parasite-based type.

Note that, as a small set of HTs are sufﬁcient for attackers to
compromise a hardware design, we do not attempt to deﬁne the
class of all possible HTs that are likely to evade hardware trust
veriﬁcation techniques in this work, which is very difﬁcult, if not
impossible. In this paper, we consider that a hardware design is in-
serted with one or more parasite-based HTs whose inputs are sepa-
rated into functional inputs and some dedicated trigger inputs. For
the convenience of presentation, HTs mentioned in the rest of the
paper means parasite-based HTs unless otherwise speciﬁed.

154(cid:10)(cid:8)(cid:11)(cid:13)(cid:19)(cid:20)(cid:10)(cid:17)(cid:21)(cid:22)(cid:7)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)
(cid:1)(cid:2) (cid:2)(cid:2)

(cid:1)

(cid:1)

(cid:2)

(cid:1)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)(cid:1)

(cid:1)(cid:2)

(cid:2)(cid:2)

(cid:2)(cid:1)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)
(cid:1)(cid:2) (cid:2)(cid:2)

(cid:1)

(cid:1)

(cid:2)

(cid:2)

(cid:2)(cid:1)

(cid:1)

(cid:1)

(cid:1)(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:1)

(cid:2)

(cid:1)

(cid:1)(cid:1)

(cid:1)(cid:2)

(cid:2)(cid:2)

(cid:2)(cid:1)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)

(cid:1)(cid:9)(cid:3)(cid:4)(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:8)(cid:11)(cid:12)(cid:13)

(cid:1)(cid:8)(cid:3)(cid:4)(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)

Figure 2: HT identiﬁcation with trust veriﬁcation techniques

2.3 Veriﬁcation for Hardware Trust

Various veriﬁcation techniques can be employed for HT identiﬁ-

cation, as detailed in the following.
2.3.1 Formal Veriﬁcation
Theoretically speaking, we can formally prove whether a hard-
ware design contains HTs or not with a given trustworthy high-level
system model (e.g., [17]). In practice, however, full formal veriﬁca-
tion of large circuits is still computationally infeasible. In addition,
the golden model itself may not be available. Consequently, we
usually have to resort to either functional veriﬁcation or dedicated
trust veriﬁcation techniques for HT detection.
2.3.2 Functional Veriﬁcation (FV)
Simulation can be used for HT detection, by activating an HT
and observing its malicious behavior.
If we were able to walk
through all possible system states, we can catch all HTs with ex-
haustive simulation. In practice, however, due to the sheer volume
of states that exist in even a simple design, FV techniques only
cover a small subset of the functional space of a hardware design.
Considering the fact that attackers have full controllability for the
location and the trigger condition of their HT designs at design
time, which are secrets to functional veriﬁcation engineers, it is
usually very difﬁcult, if not impossible, to directly activate an HT.
The above has motivated a number of dedicated hardware trust

veriﬁcation techniques, as discussed in the following.
2.3.3 Trust Veriﬁcation
Trust veriﬁcation techniques ﬂag suspicious circuitries based on
the observation that HTs are nearly always dormant (by design)
in order to pass functional veriﬁcation. Such analysis can be con-
ducted in a dynamic manner by analyzing which part of the cir-
cuit is not sensitized during functional veriﬁcation, as in UCI [11]
and VeriTrust [14]. Alternatively, static Boolean functional analy-
sis can be used to identify suspicious signals with weakly-affecting
inputs, as in FANCI [15].

In the following, we discuss these trust veriﬁcation techniques
and use the circuit shown in Fig. 1 to demonstrate how they can be
used for HT identiﬁcation.

UCI: Hicks et al. [11] ﬁrst addressed the problem of identify-
ing HTs inserted at design time, by formulating it as an unused
circuit identiﬁcation problem. They deﬁned “unused circuits” as
follows. Consider a signal pair (s,t), where t is dependent on s. If
t = s throughout the entire functional veriﬁcation procedure, the
intermediate circuit between s and t is regarded as “unused cir-
cuit”. With the above deﬁnition, the UCI algorithm in [11] traces
all signal pairs during veriﬁcation, and reports those ones for which

the property s = t holds throughout all test cases as suspicious cir-
cuitries. For our example circuit, the signal pair (h2, f ) will be al-
ways equal under non-trigger condition and hence it is guaranteed
to be ﬂagged as suspicious if the HT is not activated during func-
tional veriﬁcation. Whether the other signal pairs will be ﬂagged as
suspicious circuitries depend on the test cases applied during func-
tional veriﬁcation.

Another way to deﬁne unused circuit is based on the code cov-
erage metrics used in veriﬁcation (e.g., line coverage and branch
coverage) such that those uncovered circuitries are ﬂagged as sus-
picious malicious logic. Surprisingly, such simple analysis is able
to catch a large number of HT designs in the Trust-Hub hardware
backdoor benchmark suite, as demonstrated in [14].

One of the main limitations of UCI techniques is that they are
sensitive to the implementation style of HTs. Later, [5, 16] pre-
sented how to exploit this weakness to defeat UCI detection algo-
rithms.

VeriTrust: VeriTrust [14] ﬂags suspicious circuitries by identi-
fying potential trigger inputs used in HTs, based on the observation
that these inputs keep dormant under non-trigger condition (other-
wise HTs would have manifested themselves) and hence are redun-
dant to the normal logic function of the circuit. For our example
circuit whose K-map is shown in Fig. 2 (b), by setting all entries of
the malicious function as “don’t cares” (i.e., they can be assigned
with logic ‘0’ or logic ‘1’ freely), the trigger inputs (i.e., t1 and t2)
become redundant.

VeriTrust works as follows. Firstly, a tracer traces the activa-
tion history of the circuit in the form of simpliﬁed sum-of-products
(SOP) and product-of-sums (POS) (instead of all entries) to save
tracing overhead. Next, by setting all the un-activated entries as
don’t cares, a checker identiﬁes redundant inputs by analyzing those
unactivated SOPs and POSs. These redundant inputs are then ﬂagged
as potential HT trigger inputs for further examination. Note that,
VeriTrust may incur false positives (a false positive would mean
a ﬂagged input is not a true HT trigger input), because functional
simulation is not complete and there are some un-activated entries
belonging to normal function. However, it would not miss any true
trigger inputs.

VeriTrust is shown to be insensitive to the implementation style
of HTs (at least for existing HT designs), and it is able to identify all
HTs implemented in the Trust-Hub hardware backdoor benchmark
suite.

FANCI: FANCI [15] identiﬁes signals with weakly-affecting in-
puts by static Boolean function analysis, based on the observation
that an HT trigger input generally has a weak impact on output sig-
nals. Without running veriﬁcation tests, [15] proposed to use the

155Static/Dynamic Detection Method
Functional Veriﬁcation
dynamic
UCI by Code Coverage dynamic
UCI by [11]
dynamic
dynamic
VeriTrust [14]
FANCI [15]
static

Runtime False Negatives
good
activate the HT
good
identify uncovered parts
fair
identify equal signal pair
identify HT trigger inputs
fair
identify weakly-affecting inputs fair

False Positives

HTs with rare trigger condition none
HTs in [5]
HTs in [5, 16]
unknown
possible with low threshold

few with thorough veriﬁcation
some with thorough veriﬁcation
some with thorough veriﬁcation
many with high threshold

Table 1: HT Detection with Hardware Functional Veriﬁcation and Trust Veriﬁcation

(cid:6)(cid:7)
(cid:6)(cid:8)

(cid:6)(cid:9)

(cid:10)(cid:2)(cid:3)(cid:4)(cid:3)(cid:9)(cid:11)(cid:12)(cid:13)(cid:14)(cid:3)(cid:2)(cid:14)(cid:15)(cid:3)(cid:1)

(cid:16)(cid:11)(cid:17)(cid:12)(cid:10)(cid:11)(cid:6)

(cid:1)(cid:7)

(cid:1)(cid:8)

(cid:23)
(cid:1)(cid:18)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:4)(cid:5)(cid:2)

(cid:10)

(cid:25)

(cid:22)(cid:22)

(cid:22)(cid:22)

(cid:22)(cid:22)

(cid:22)(cid:22)

(cid:14)(cid:10)(cid:18)(cid:19)(cid:3)(cid:9)(cid:11)(cid:1)(cid:3)(cid:10)(cid:9)(cid:11)(cid:12)(cid:13)

(cid:12)(cid:10)(cid:4)(cid:3)(cid:14)

(cid:20)(cid:5)(cid:21)(cid:15)(cid:5)(cid:9)(cid:1)(cid:3)(cid:11)(cid:12)(cid:13)(cid:16)(cid:10)(cid:2)(cid:1)(cid:3)(cid:10)(cid:9)

(cid:24)

(cid:22)(cid:11)(cid:20)(cid:1)(cid:13)(cid:20)(cid:1)(cid:11)(cid:4)(cid:5)

(cid:1)(cid:7)
(cid:1)(cid:8)
(cid:1)(cid:18)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:4)(cid:7)(cid:8)(cid:9)(cid:10)(cid:6)(cid:11)(cid:12)(cid:13)(cid:14)(cid:12)(cid:15)(cid:4)(cid:13)(cid:10)(cid:16)(cid:13)(cid:17)(cid:10)(cid:14)

(cid:1)(cid:18)(cid:3)(cid:4)(cid:8)(cid:19)(cid:12)(cid:4)(cid:14)(cid:16)(cid:10)(cid:20)(cid:20)(cid:12)(cid:16)(cid:4)(cid:15)(cid:12)(cid:21)(cid:10)(cid:20)(cid:6)

Figure 3: A structural overview of existing HT designs

so-called control value (CV ) to estimate the impact between an in-
put signal and an output that is driven by it:

CV = counter
size(T )

,

(1)

where counter denotes the total number of patterns under which
ﬂipping this input signal results in the change of the output value,
while size(T ) denotes the size of the truth table. For example, as
shown in Fig. 2 (c), there are only two input patterns under which
ﬂipping t1 leads to the change of the output, and hence CV (t1) =
2/24 = 0.125. FANCI examines each state element in the circuit
and obtains a vector of control values V in its fan-in combinational
logic cone. A heuristic metric (e.g., median or mean) on V is then
calculated and compared against a cut-off threshold to determine
whether this signal is HT-related.

Consider our example circuit, as shown in Fig. 2 (c), we have
V = [0.125,0.125,0.375,0.625] and 0.3125 for f with the mean
metric. Therefore, FANCI would ﬂag f as suspicious if the cut-off
threshold is set to be larger than 0.3125. By setting a proper cut-
off threshold value in [15], FANCI is able to identify all HTs from
Trust-Hub [6].
2.4 Discussion

Table 1 summarizes the characteristics of existing solutions for
HT detection. Since dynamic trust veriﬁcation techniques (i.e.,
UCI and VeriTrust) analyze the corner cases of functional veriﬁ-
cation for HT detection, these two types of veriﬁcation techniques
somehow complement each other. Generally speaking, with more
FV tests applied, the possibility for HTs being activated is higher
while the number of suspicious circuitries reported by UCI and Ver-
iTrust would decrease. As a static solution that does not depend on
veriﬁcation, one unique advantage of FANCI over the other solu-
tions is that it does not require a trustworthy veriﬁcation team. On
the other hand, however, adversaries could also validate their HT
designs using FANCI without necessarily speculating the unknown
test cases used to catch them.

All trust veriﬁcation techniques try to eliminate false negatives
(a false negative would mean an HT that is not detected) whilst
keeping the number of false positives as few as possible in order
not to waste too much effort on examining benign circuitries that
are deemed as suspicious. However, their detection capability is re-
lated to some user-speciﬁed parameters and inputs during trust ver-

iﬁcation. For example, FANCI deﬁnes a cut-off threshold for what
is suspicious and what is not during Boolean functional analysis.
If this value is set to be quite large, it is likely to catch HT-related
wires together with a large number of benign wires. This, how-
ever, is a serious burden for security engineers because they have
to evaluate all suspicious wires by code inspection and/or extensive
simulations. If this value is set to be quite small, on the contrary,
it is likely to miss some HT-related wires. Similarly, if we apply
a small number of FV tests, UCI and VeriTrust would ﬂag a large
number of suspicious wires (all wires in the extreme case when no
FV tests are applied), which may contain HT-related signals but
the large amount of false positives make the following examination
procedure infeasible.

From the above, a successful HT design would behave similar to
normal logic, such that a large number of false positives would be
generated when HTs are detected during veriﬁcation.

3. THE DETRUST METHODOLOGY

In this section, we detail the proposed DeTrust methodology to
construct HTs that are resistant to state-of-the-art hardware trust
veriﬁcation techniques.
3.1 Overview

Fig. 3(a) presents the typical structure of an HT-infected design,
which contains its original logic, the HT payload and the HT trig-
ger. The HT payload implements certain malicious function while
the HT trigger activates it under some trigger conditions. Generally
speaking, the stealthiness of HT designs mainly depends on the HT
trigger design and it usually comprises both a combinational por-
tion and a sequential portion, as shown in Fig. 3(b).

Given an HT design, the objective of DeTrust is to revise its trig-
ger design to be resistant to known trust veriﬁcation techniques
while maintaining its malicious function. The overall ﬂow is as
follows. For a given HT that is not stealthy enough to evade func-
tional veriﬁcation and/or UCI techniques, we ﬁrst adopt the HT
design methodology proposed in [5] to defeat them. To be speciﬁc,
the trigger condition is carefully selected to be a rare value to resist
FV and the HT is implemented with the code model in [5] to evade
UCI techniques. Next, we carefully redesign the HT trigger to be
resistant to both FANCI and VeriTrust, which is the focus of this
work.

156(cid:1)(cid:2)
(cid:1)(cid:3)
(cid:1)(cid:4)
(cid:1)(cid:5)

(cid:8)(cid:2)
(cid:8)(cid:5)

(cid:8)(cid:10)
(cid:8)(cid:11)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:8)(cid:9)(cid:2)
(cid:8)(cid:9)(cid:5)

(cid:4)
(cid:4)
(cid:4)

(cid:1)(cid:2)(cid:3)

(cid:7)

(cid:1)(cid:2)
(cid:1)(cid:3)
(cid:1)(cid:4)
(cid:1)(cid:5)

(cid:1)(cid:2)(cid:3)

(cid:7)

(cid:6)(cid:2) (cid:6)(cid:3)

(cid:4)(cid:4)(cid:4)

(cid:4)(cid:4)(cid:4)

(cid:8)(cid:2)

(cid:8)(cid:9)(cid:5)

(cid:6)(cid:2)(cid:6)(cid:3)

(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:8)(cid:10)(cid:11)(cid:6)(cid:12)(cid:13)(cid:6)(cid:14)(cid:13)(cid:8)(cid:1)(cid:2)(cid:3)

(cid:5)(cid:15)(cid:7)(cid:8)(cid:9)(cid:8)(cid:16)(cid:6)(cid:17)(cid:18)(cid:19)(cid:18)(cid:20)(cid:21)(cid:10)(cid:8)(cid:1)(cid:2)(cid:3)

(cid:12)(cid:12)

(cid:12)(cid:12)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:12)(cid:12)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:1)(cid:2)
(cid:1)(cid:3)
(cid:1)(cid:4)
(cid:1)(cid:5)

(cid:12)(cid:12)

(cid:4)
(cid:4)
(cid:4)

(cid:4)
(cid:4)
(cid:4)

(cid:12)(cid:12)

(cid:1)(cid:2)(cid:3)

(cid:7)

(cid:4)(cid:4)(cid:4)

(cid:8)(cid:13)(cid:5)

(cid:8)(cid:13)(cid:2)

(cid:6)(cid:2)(cid:6)(cid:3)

cious behavior. Therefore, the number of input patterns satisfying
both requirements is bounded at:

21 ≤ counter ≤ 2n+1.

(3)
With Eq. 2 and Eq. 3, the control value of ti on the corresponding

HT-related signal is bounded at:

1

2n+m−1

≤ CV (ti) = counter
size(T )

≤ 1
2m−1

.

(4)

In order to make FANCI difﬁcult to differentiate HT-related sig-
nals and function signals, we should make control values of HT-
related signals to be comparable to those of functional signals. As
indicated by Eq. 4, reducing m has an exponential impact on the
increase of control values. Thus, we modify the implementation of
the malicious MUX by balancing these trigger inputs into multiple
sequential levels (see Fig. 4 (c)). In this way, the number of trigger
inputs is controlled to be no more than four for any combinational
block, rendering the control value of each trigger input comparable
with those of functional inputs.

Motivated by the above, our approach of defeating FANCI is
to reduce the number of trigger inputs in all the combinational
logic blocks that drive HT-related signals, and it can be achieved
by spreading HT trigger inputs among multiple sequential levels.

(cid:5)(cid:19)(cid:7)(cid:8)(cid:9)(cid:8)(cid:16)(cid:6)(cid:17)(cid:18)(cid:19)(cid:18)(cid:20)(cid:21)(cid:10)(cid:8)(cid:1)(cid:2)(cid:3)(cid:8)(cid:22)(cid:18)(cid:11)(cid:23)(cid:8)(cid:16)(cid:20)(cid:13)(cid:18)(cid:24)(cid:18)(cid:25)(cid:13)(cid:8)(cid:18)(cid:16)(cid:26)(cid:17)(cid:25)(cid:16)(cid:25)(cid:12)(cid:11)(cid:6)(cid:11)(cid:18)(cid:20)(cid:12)

Figure 4: Motivational example for defeating FANCI

3.2.2 HT Design against FANCI

Algorithm 1: The Flow to Defeat FANCI
1 NT = 2;
2 do
3
4 while (The hardware cost is larger than a given constraint.);

DefeatFANCI(NT + +);

/* One step to defeat FANCI

5 DefeatFANCI(NT )

*/

/* For combinational logic of  and 
*/
foreach The fan-in cone of the input of the ﬂip-ﬂop do

if the number of trigger inputs > NT then

Balance the trigger in the multiple sequential
levels;

end if

end foreach
/* For combinational logic of 
*/
Find out the maximum number of trigger signals, denoted
by Nmax, within a combinational logic cone;
if Nmax > NT then

Introduce multiple small FSMs until Nmax ≤ NT ;

end if

3.2 Defeating FANCI

Since FANCI identiﬁes signals with weakly-affecting inputs within

the combinational logic block, the key idea to defeat FANCI is to
make the control values of all HT-related signals comparable to
those of functional signals.
3.2.1 Motivational Case
Let us start with the case shown in Fig. 4 to illustrate the key
idea of defeating FANCI. Fig. 4 (a) and Fig. 4 (b) present a regular
multiplexer (MUX) and a malicious one with a rare trigger con-
dition, respectively. FANCI is able to differentiate the two types
of MUXes and ﬂag the malicious one since the trigger inputs, de-
noted by t0, t1, . . . , t63, have very small control values for the output
O( 1

265 ).
From this example, we can see that, the main reason for HT-
related signals (e.g., o in Fig. 4 (b)) having weakly-affecting inputs
is that it is driven by a number of trigger inputs in its fan-in com-
binational logic cone. Consider a signal driven by a combinational
logic block with m trigger inputs and n functional inputs. The size
of the truth table for this particular HT-related signal is given by:

size(T ) =2 m+n.

(2)

For any trigger input, denoted by ti, those input patterns under
which ti inﬂuences the output should meet two requirements: (i)
all trigger inputs other than ti are driven by the trigger values2;
(ii) ﬂipping ti results in the change of the output value. There are
in total 2n+1 input patterns meeting the ﬁrst requirement. Among
them, how many further satisfying the second requirement depends
on the actual difference between the malicious function and the
normal function, because they may output the same value under
certain functional inputs. At the same time, they cannot always
output the same value because otherwise there would be no mali-
2Trigger values are logic values for trigger inputs to satisfy trigger condi-
tion.

6
7
8

9
10

11

12
13
14
15 end

For the general HT design shown in Fig. 3, FANCI is likely to
catch HT-related signals in the combinational logic of ,  and .
Algorithm 1 presents the ﬂow of our defeating method for FANCI.
To reduce the number of trigger signals in a combinational logic,
we consider the combinational logic of  and  together and then
consider that of , due to the fact that we need to adopt different
methods to handle the extra signal delay of trigger inputs intro-
duced by additional sequential levels.

For the combinational logic blocks in  and , our defeating
method is similar to the one shown in Fig. 4 (c). As can be seen, the
original trigger combinational logic with a large number of trigger
inputs is spread among multiple combinational logic blocks, such

157(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:2)

(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:3)

(cid:6)(cid:7)(cid:8)(cid:9)(cid:10)(cid:4)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:5)

(cid:1)(cid:2)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:3)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:4)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:5)

(cid:25)(cid:26)(cid:27)(cid:12)(cid:28)(cid:16)(cid:17)(cid:12)(cid:14)(cid:18)(cid:20)(cid:29)(cid:5)(cid:26)(cid:30)(cid:12)(cid:31)(cid:1)(cid:32)

(cid:6)(cid:7)(cid:8)(cid:9)(cid:22)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:2)(cid:2)

(cid:6)(cid:7)(cid:8)(cid:9)(cid:22)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:2)(cid:3)

(cid:6)(cid:7)(cid:8)(cid:9)(cid:22)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:2)(cid:5)

(cid:1)(cid:2)(cid:2)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:2)(cid:3)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:2)(cid:4)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:2)(cid:5)

(cid:6)(cid:7)(cid:23)(cid:9)(cid:2)(cid:24)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:3)(cid:2)

(cid:6)(cid:7)(cid:23)(cid:9)(cid:2)(cid:24)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:3)(cid:3)

(cid:6)(cid:7)(cid:23)(cid:9)(cid:2)(cid:24)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:3)(cid:5)

(cid:1)(cid:3)(cid:2)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:3)(cid:3)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:3)(cid:4)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:3)(cid:5)

(cid:6)(cid:7)(cid:24)(cid:10)(cid:9)(cid:10)(cid:4)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:23)(cid:2)

(cid:6)(cid:7)(cid:24)(cid:10)(cid:9)(cid:10)(cid:4)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:23)(cid:3)

(cid:6)(cid:7)(cid:24)(cid:10)(cid:9)(cid:10)(cid:4)(cid:11)(cid:12)(cid:13)(cid:12)(cid:6)(cid:23)(cid:5)

(cid:1)(cid:23)(cid:2)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:23)(cid:3)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:23)(cid:4)

(cid:14)(cid:15)(cid:16)(cid:17)(cid:18)(cid:19)(cid:20)(cid:21)(cid:17)

(cid:1)(cid:23)(cid:5)

(cid:25)(cid:33)(cid:27)(cid:12)(cid:28)(cid:16)(cid:17)(cid:12)(cid:34)(cid:35)(cid:30)(cid:15)(cid:20)(cid:36)(cid:30)(cid:17)(cid:12)(cid:21)(cid:34)(cid:26)(cid:30)(cid:30)(cid:12)(cid:31)(cid:1)(cid:32)(cid:21)

Figure 5: The proposed sequential trigger design to defeat
FANCI

that the number of trigger inputs in each combinational logic block
is no more than NT (a value used to tradeoff HT stealthiness and
hardware overhead). As shown in Algorithm 1 (Lines 6− 10), we
only examine the inputs of ﬂip-ﬂops rather than all signals. This
is because, as long as the number of trigger inputs for the input of
every ﬂip-ﬂop is smaller than NT , the number of trigger inputs for
every internal signal is also smaller than NT .

The sequential part of an HT trigger can be represented by a
ﬁnite-state machine (FSM) and the trigger inputs are used to con-
trol state transitions (see Fig. 5 (a)). For the combinational logic
blocks in  that sits inside the FSM, we cannot use the above de-
feating method because the additional pipeline delay introduced
in this method would change trigger condition. Instead, we par-
tition the original FSM into multiple small FSMs, e.g., as shown in
Fig. 5 (b), the FSM with 64 trigger inputs is partitioned into eight
small FSMs. By doing so, the number of trigger inputs in each
small FSM is reduced to eight for this example, and it can be fur-
ther reduced by introducing more FSMs. The HT is triggered when
all the small FSMs reach certain states simultaneously.

Note that, the proposed defeating method against FANCI has no
impact on both circuit’s normal functionalities and HT’s malicious
behavior, because DeTrust only manipulates the HT trigger design,
which is separate from the original circuit and the HT payload.

Stealthiness Optimization

3.2.3
Until now, we have described our defeating method against FANCI.

However, as discussed in Section 2, whether an HT is able to evade
FANCI is also inﬂuenced by the cut-off threshold that is used to
trade-off false negatives and false positives.

DeTrust tries to maximize the stealthiness of the HT with respect
to FANCI subject to a given constraint in terms of hardware cost.
As the stealthiness of an HT is mainly determined by the number
of trigger inputs in each combinational logic, this is achieved by
ﬁnding the value of NT in a greedy manner. That is, as shown in
Algorithm 1, we start with NT = 2 and gradually increase it until
the cost of applying the defeating method is lower than the given
constraint.
3.3 Defeating VeriTrust

As discussed earlier, VeriTrust ﬂags suspicious HT trigger in-
puts by identifying those inputs that are redundant under veriﬁca-
tion. Consequently, the key idea to defeat VeriTrust is to make HT-
affected signals driven by non-redundant inputs only under non-
trigger condition.

3.3.1 Motivational Case
For any input that is not redundant under non-trigger condition,

we have the following lemma.

LEMMA 1. Consider an HT-affected signal whose Boolean func-
tion is f (h1,h2, . . . ,h k). Any input, hi, is not redundant under non-
trigger condition, as long as the normal function, denoted by fn,
cannot be completely represented without hi.

PROOF. Since fn cannot be completely represented without hi,
there must exist at least one pattern for all inputs except hi under
which fn(hi = 0) (cid:3)= fn(hi = 1). Therefore, hi is not redundant.

(cid:1)(cid:1)

(cid:1)

(cid:1)

(cid:2)

(cid:2)(cid:1)

(cid:1)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)
(cid:1)(cid:2) (cid:2)(cid:2)

(cid:2)

(cid:1)

(cid:2)

(cid:1)(cid:4)(cid:3)

(cid:1)(cid:2)(cid:3)

Figure 6: Motivational example for defeating VeriTrust

Inspired by Lemma 1, Fig. 6 (a) shows an HT-infected circuit
that is revised according to the circuit shown in Fig. 1, wherein the
HT is activated when {t1,t2} = {1,1}. In this implementation, the
malicious product t1t2d2 is combined with the product t1d1d2 from
the normal function and hidden in the fan-in cones of h1 and h2,
where h1 = t1d2 and h2 = d1 + t2. The K-map of f is shown in
Fig. 6 (b), where entries that cannot be activated under non-trigger
condition are marked as “don’t cares”. For this circuit, VeriTrust,
focusing on the combinational logic, would verify four signals, f ,
h1, h2 and h3. According to the K-map shown in Fig. 6 (b), it is
clear that h1, h2 and h3 are not redundant for f under non-trigger
condition. Moreover, h1, h2 and h3, which are not HT-affected
signals, have no redundant inputs as well, since all of their input
patterns can be activated under non-trigger condition. Therefore,
the HT in Fig. 6 (a) is able to evade VeriTrust.

By examining the implementation of this motivational case, we
ﬁnd that the mixed design of the trigger and the original circuit
makes trigger condition for the HT-affected signal not visible for
VeriTrust. In order to differentiate existing HTs and HTs like the
one shown in Fig. 6 (a), we deﬁne two new terms: the explicitly-
triggered HT and the implicitly-triggered HT as follows.

DEFINITION 5. We say an HT is explicitly-triggered if in the
HT-affected signal’s fan-in logic cone, there exists an input pattern
that uniquely represents the trigger condition.

DEFINITION 6. We say an HT is implicitly-triggered if in the
HT-affected signal’s fan-in logic cone, there does not exist any in-
put pattern that uniquely represents the trigger condition.

A careful examination for the HTs from Trust-Hub shows that
they are all explicitly-triggered, and this is the reason why VeriTrust
is able to ﬂag all of them as suspicious. Interested readers can refer
to the code model of HTs from Trust-Hub in [5]. On the contrary,
the HT shown in Fig. 6 (a) is implicitly-triggered, since the trigger
condition is hidden in the h1h2 which also contains certain circuit’s
normal functionalities.

The above observation motivates us to propose the following ap-
proach to implement implicitly-triggered HTs to defeat VeriTrust.

1583.3.2 HT Design against VeriTrust
For existing HT designs as shown in Fig. 3, VeriTrust is able
to detect HT trigger inputs in the combinational logic block in ,
wherein the output is the HT-affected signal. Our proposed defeat-
ing method for VeriTrust therefore focuses on this combinational
logic. According to Lemma 1, our approach to defeat VeriTrust for
DeTrust implements the implicitly-triggered HT with the following
two steps:

• Combine all malicious on-set terms3 with on-set terms from
normal function, and re-allocate sequential elements (e.g, ﬂip-
ﬂops) to hide the trigger in multiple combinational logic blocks.
• Simplify all remaining on-set terms and re-allocate sequen-

tial elements if they contain trigger inputs.

Note that, we select on-set terms only, since the circuit can be ex-
plicitly represented by the sum of all on-set terms.

Let us further illustrate our defeating method against VeriTrust
as follows. Consider a circuit with an explicitly-triggered HT, and
its Boolean function can be represented by

f = ∑
∀Cn,
cni

∑
∀Pn,
pn j

cni pn j

+ ∑
∀Cm,
cmi

∑
∀Pm
pm j

cmi pm j

,

(5)

where Pn and Pm driven by functional inputs denote the set of all
patterns that make the normal function and malicious function out-
put logic ‘1’, while Cn and Cm driven by trigger inputs denote the
set of non-trigger conditions and the trigger conditions, respec-
tively.

For the sake of simplicity, let us ﬁrst consider the case where
the malicious function contains only one malicious on-set term,
cm0 pm0. Suppose cn0 pn0 from the normal function is selected to
combine with cm0 pm0. Let f (cid:5)
n be all the on-set terms from the nor-
mal function except cn0 pn0. Then, f can be given by

(cid:5)
n + (cn0 pn0

f = f

(6)
Suppose cn0 pn0 and cm0 pm0 have the common literals, cc pc, and
then we have

+ cm0 pm0

).

f = f

where

(cid:5)
n + cc pc(cr

n0 pr
n0

+ cr

m0 pr
m0

),

cn0
cm0

= cccr
n0;
= cccr
m0;

pn0
pm0

= pc pr
n0;
= pc pr
m0

.

(7)

(8)

into different combinational logic. With the above, we ﬁnd that f ,
h1, h2 and h3 have no redundant inputs under non-trigger condition.
We detail this theoretical proof in Appendix.

When there are multiple malicious on-set terms, we can use the
above method to combine each of them with one on-set term from
the normal function and then hide the trigger in different combina-
tional logic blocks. Finally, we have

f =

(h2i+1h2i+2) +h 2k+1,

k−1∑

i=0

where

h2i+1 = cci pci
h2i+2 = crini prini
h2k+1 = f

(cid:5)
n

+ crimi primi

.

(11)

(12)

It is easy to prove that h1, h2, . . . , h2k+1 and f have no redun-
dant inputs under non-trigger condition as well with the theoretical
proof in Appendix. Note that, the HT can be spread over multiple
sequential levels by further combining the trigger logic driving h1,
h2, . . . , h2k+1 with normal logic.
3.3.3
Until now, we have presented our defeating approach against
VeriTrust. However, as discussed in Section 2, whether an HT is
able to evade VeriTrust is directly related to the functional veriﬁca-
tion test cases applied to the circuit.

Stealthiness Analysis and Optimization

According to Appendix, the HT would evade VeriTrust provided
that statement 1, statement 2, statement 3 and statement 4 (see Ap-
pendix for details) are satisﬁed during functional veriﬁcation. Let
Ps1, Ps2, Ps3 and Ps4 be the probabilities of statement 1, statement 2,
statement 3 and statement 4 to be satisﬁed during functional veriﬁ-
cation. The probability for the HT to evade VeriTrust, denoted by
PDeVeriTrust, is given as,

PDeVeriTrust = Ps1Ps2Ps3Ps4

(13)
where the dependencies between each statement are ignored. Let
P(cni pn j
) be the probability of an input pattern, cni pn j , to be acti-
vated. According to Appendix, we approximates Ps1, Ps2 and Ps3 as
follows:

,

Ps1

i (cid:3)= pc})

i (cid:3)= cc})
j ∈ Fc, pc

|cc
i ∈ Cc,cc
)×{P({cc
i cr
m0 pc pr
=P(cn0 pn0
m0
+ P({cc
i (cid:3)= cc; pc
|cc
i ∈ Cc,cc
m0 pc
i cr
j pr
m0
i (cid:3)= cc})
i ∈ Cc,cc
)|cc
+ P({cc
n0 pc pr
i cr
n0
+ P({cccr
j (cid:3)= pc})
)|pc
j ∈ Fc, pc
j pr
n0 pc
n0
i (cid:3)= cc; pc
i ∈ Cc,cc
)|cc
j ∈ Fc, pc
+ P({cc
i cr
j pr
n0 pc
n0
∈ Cr,cr
|cr
)×{P({cccr
(cid:3)= cr
mi pc pr
mi
mi
m0
m0
∈ Cr,cr
(cid:3)= cr
∈ Fr, pr
mi pc pr
m0; pr
m j
m j
mi
m j

j (cid:3)= pc})};
})+
=P(cn0 pn0
P({cccr
(cid:3)= pr
m0
=P({ci p j|ci ∈ Cn,ci (cid:3)= cn0; p j ∈ (F − Pn), p j (cid:3)= pm0
})×
P({ci p j|ci ∈ Cn,ci (cid:3)= cn0; p j ∈ Pn, p j (cid:3)= pm0

|cr
mi

}).

Ps3

})};

Ps4 can be calculated if all inputs of h1, h2 and h3 are speciﬁed.

By examining Eq. 13, we ﬁnd that PDeVeriTrust is dominated by
the probabilities of some terms, such as cn0 pn0 that is used to com-
bine with the malicious on-set term cm0 pm0. Therefore, we pro-
pose the following three methods to increase the stealthiness of HTs
against VeriTrust:
• Combine simpliﬁed malicious products (rather than malicious
on-set terms) with on-set terms from the normal function, so
that fewer terms from the normal function are required to be
activated to evade VeriTrust.

After that, we re-synthesize the circuit and re-allocate ﬂip-ﬂops,
making f become

f = h1h2 + h3,

(9)

Ps2

where

h1 = cc pc
h2 = cr
n0 pr
n0
(cid:5)
h3 = f
n

+ cr

m0 pr
m0

.

(10)

In order to keep the time sequence, we re-allocate the ﬂip-ﬂops and
h1, h2 and h3 are outputs of the new ﬂip-ﬂops.

As can be observed in Eq. 9 and Eq. 10, the key of the defeating
method is to extract common literals from the malicious on-set term
and the on-set term from the normal function and hide the trigger
3Malicious on-set term is the on-set term in the malicious function whose
adjacent terms in the normal function are off-set [14]. On-set term and off-
set term are terms that make the function output logic ‘1’ and logic ‘0’,
respectively.

159• Choose simpliﬁed products from the normal function to be
combined with simpliﬁed malicious products, so that any of
the terms in the product from the normal function being acti-
vated can make HT evade VeriTrust.
• Choose those simpliﬁed products from the normal function
with high activation probabilities to be combined with mali-
cious products. This method requires the knowledge about
the probability of products from the normal function, which
can be estimated by speculating on the test cases used in
functional veriﬁcation [5, 16].

Algorithm 2: The Flow to Defeat VeriTrust
/* For combinational logic of 

1 Simplify Boolean function of this combinational logic;
2 Conduct the simulation with tests guessed by attackers to

obtain the probability of each product;

3 foreach simpliﬁed malicious product do
4

Greedily combine it with the product from the normal
function with the largest activation probability and hide
the trigger in different combinational logic blocks;

5 end foreach
6 Re-allocate ﬂip-ﬂops for the remaining products.

The ﬂow to defeat VeriTrust is illustrated in Algorithm 2. It ﬁrst
simpliﬁes the Boolean function of the combinational logic of HT-
affected signals, and then conducts simulation with speculated test
cases to obtain the probability of each product. After that, a loop
is used to hide HT triggers whenever possible. In each iteration,
one malicious product is combined with one product from the nor-
mal function with the largest activation probability and it is hidden
in different combinational logic blocks. At last, ﬂip-ﬂops are re-
allocated for the remaining products.
3.4 Discussion

The defeating approach against FANCI and that against Ver-
iTrust in DeTrust do not interfere with each other. On the one hand,
DeTrust for FANCI focuses on reducing the number of trigger in-
puts in the combinational logic blocks used in HT triggers without
changing their logic functions; on the other hand, DeTrust for Ver-
iTrust implements the implicitly-triggered HT without increasing
the number of trigger inputs in any combinational logic.

Moreover, DeTrust for FANCI and VeriTrust would not inﬂu-
ence the stealthiness of HT designs shown in [5] against FV and
UCI techniques. Firstly, DeTrust does not change HT trigger con-
dition and hence it has no impact on functional veriﬁcation. For
UCI techniques that analyze the code coverage, DeTrust for FANCI
splits the HT trigger among multiple sequential levels, which does
not affect each part of the trigger being covered by veriﬁcation test
cases. DeTrust for VeriTrust could use basic AND, OR and NOT
operators to implement the implicit trigger, avoiding the impact
based on code coverage analysis. For the UCI technique in [11],
on the one hand, the signals introduced by DeTrust for FANCI are
within the HT trigger unit driven by different trigger inputs and
they are unlikely to be always equal during functional veriﬁcation;
on the other hand, DeTrust for VeriTrust combines parts of the nor-
mal functionalities with the HT trigger and hence is also unlikely to
create equal signal pairs during veriﬁcation. Note that, the above is
a brief discussion on the impact of DeTrust on earlier stealthy HT
design techniques, please refer to [5] for more details.

With the above, DeTrust is a one-off HT design methodology
to be resistant to all known trust veriﬁcation techniques while still
passing functional veriﬁcation.

*/

Figure 7: Supervisor transition foothold in [16] (Verilog HDL)

4. VALIDATION AND DISCUSSION

In this section, we ﬁrst design and implement a practical attack to
illustrate how to apply DeTrust to construct an HT that is resistant
to FANCI and VeriTrust. Next, we study the stealthiness of HTs
constructed with DeTrust in detail.
4.1 Practical Attack

We adopt the malicious HT used to defeat UCI technique shown
in [16] as the input to DeTrust. This HT, called supervisor tran-
sition foothold, is detailed in Fig. 7, and we implement it on the
OpenRISC processor [18]. Whenever a speciﬁc instruction repeats
twice, the HT is triggered and allows attackers to gain the full con-
trol of the system. As shown by a(cid:2) and b(cid:2) in Fig. 7, instruct_prev_t
and instruct_curr_t are two trigger inputs used to indicate whether
previous and current instructions (denoted by instruct_prev and
instruct_curr) are the trigger instructions (denoted by ‘INST RUCT ).
The trigger inputs, the payload and the original circuit are then
carefully combined to resist UCI (see c(cid:2) in Fig. 7).

FANCI is likely to catch instruct_prev_t and instruct_curr_t
considering small control values of instruct_prev and instruct_curr;
while VeriTrust guarantees to ﬂag the HT-affected signal super
(the supervisor-mode bit), since the inputs of instruct_prev_t and
instruct_curr_t are redundant under non-trigger condition.
The HT implementation shown in Fig. 7 is not stealthy enough.
DeTrust revises the HT design indicated by a(cid:2), b(cid:2) and c(cid:2) to re-
sist FANCI and VeriTrust, and the revised HT design is shown in
Fig. 8. To resist FANCI at a(cid:2) and b(cid:2), we limit the number of trig-
ger inputs in each combinational logic to be no more than four by
introducing multiple sequential levels, as shown by Fig. 8 (a). By
doing so, the control value of each trigger input is increased to a
level that is close to the control value of functional inputs. Finally,
instruct_prev_t[10] and instruct_curr_t[10] are used to indicate the
occurrence of the previous and current trigger instructions. We do
not apply DeTrust for FANCI at c(cid:2), since there are only two trigger
inputs for signal super.
To resist VeriTrust at c(cid:2), we carefully re-design the fan-in logic
cone of super whose original Boolean function is shown in Fig. 8(b)
and hide the trigger in the fan-in logic cones of three introduced
signals, h1, h2 and h3, as shown in Fig. 8(c). Note that, in order
to keep the timing of all signals unchanged, h2 and h3 are driven
by previous values of holden and in.super, denoted by holden_in
and in.super_in. We can prove that super, h1, h2 and h3 have no
redundant inputs under non-trigger condition, according to the the-
oretical proof shown in Appendix. For example, as shown in Fig. 9,
h1 can be identiﬁed as non-redundant by VeriTrust, since the pat-
terns of [0,1,0] and [1,1,0] for [h1,h2,h3] can be activated under
non-trigger condition, leading to different output values for super.

160Figure 8: Supervisor transition foothold implemented by DeTrust (Verilog HDL)

Circuit
s15850
s38417
s38584

wb_conmax
OpenRISC

10369
24370
21066
75352
143172

148
148
148
178
184

Circuit Size
(No. of gates) (No. of gates) (Ratio %)

HT Size

False Positive

Rate %
34.8
34.2
30.8
40.1
44.1

1.43
0.61
0.70
0.24
0.13

Figure 9: Patterns used to prove that h1, h2 and h3 are not re-
dundant for super, where [resetn,holdn,super] = [1,1,0]

The HT revised by DeTrust introduces about 80 code lines in the
design ﬁle, which is comparable to HTs of [11]. We use the same
environment as in the original experimental setup in FANCI [15]
and VeriTrust [14] to validate the stealthiness of this HT in the
OpenRISC processor, and we ﬁnd that it successfully evades both
HT identiﬁcation techniques, which is further discussed in the fol-
lowing subsection.
4.2 The Stealthiness of the HT

Next, we study the stealthiness of the HTs designed with DeTrust
with respect to all known veriﬁcation techniques for hardware trust,
including the static analysis with FANCI and various dynamic so-
lutions (i.e., FV, UCI and VeriTrust).

Stealthiness in terms of FANCI

4.2.1
The experimental setup to evaluate the stealthiness of HT in terms
of FANCI is set as follows. Experiments are conducted on the
benchmark circuits with diverse sizes, s15850, s38417, s38584,
wb_conmax and OpenRISC. Only one HT designed by DeTrust is
embedded in each benchmark circuit and it is similar to the one
shown in Fig. 8. All the HTs introduce fewer than 200 gates, as
shown in Table 2. For some of the benchmarks with RTL source
code provided, we insert the HT directly into the RTL source code
and then synthesize the whole design with commercial synthesis
tool; for some of the benchmarks with the netlist provided, we syn-
thesize the HT ﬁrst and then insert it into the design netlist. Similar
to the experimental setup in [15], we choose 215 = 32,768 items in
the truth table to calculate the control value for FANCI. Then, given
a cut-off threshold, FANCI ﬂags those signals with lower control
values as suspicious ones.

Table 2: The size of HTs and false positive rates under the cut-
off threshold where HTs are just detected by FANCI.

As shown in Fig. 10 (a), the values of all HT-related signals cal-
culated by the heuristic mean metric4 for the benchmark circuits
are controlled at around 0.1. Consequently, if the cut-off thresh-
old value is set as 0.001 as suggested in [15], FANCI would not
ﬂag these HTs designed with DeTrust. On the other hand, if we
raise the cut-off threshold to be 0.1, FANCI is able to catch some
HT-related signals, but it would suffer from a large number of false
positives. Column 5 in Table 2 lists the concrete false positive rate
when setting the cut-off threshold to be the lowest value with which
there is no false negative.

Even under such optimistic assumptions, FANCI would have
more than 30% false positive rates, which means that designers
need to manually examine more than 30% of signal wires in the en-
tire circuit to ﬁnally catch the HT from the candidate list. Fig. 10 (b)
presents the number of wires for further examination with different
cut-off threshold values for various benchmark circuits.

Based on the above, we conclude that DeTrust is resistant to

FANCI.

Stealthiness in terms of FV, UCI and VeriTrust
4.2.2
We adopt the same experimental environment of [14] to study
the stealthiness of the HT with respect to dynamic veriﬁcation so-
lutions for HT identiﬁcation. We conduct the experiment on the
OpenRISC processor, considering the test cases required by these
solutions. We adopt the 17 test cases bundled with the OpenRISC
design for veriﬁcation. Similar to [5], we use 5 test cases when
implementing the HT and adopt the remaining 12 test cases to val-
idate its stealthiness. The HTs used are listed in Table 3, wherein

4We obtained the similar results with other heuristic metrics used by
FANCI, such as median, both and triviality.

161t

e
a
R
e
v
i
t
i
s
o
P
e
s
a
F

l

0.7
0.65
0.6
0.55
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

s15850
s38417
s38584
wb_conmx
OpenRisc

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:2)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12)(cid:10)
(cid:13)(cid:14)(cid:15)(cid:16)(cid:17)(cid:10)(cid:18)(cid:5)(cid:18)(cid:4)(cid:3)

(cid:19)(cid:1)(cid:20)(cid:5)(cid:21)(cid:21)(cid:4)(cid:22)(cid:23)(cid:4)(cid:9)(cid:10)

(cid:6)(cid:11)(cid:24)(cid:12)(cid:5)(cid:8)(cid:6)

0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 0.11 0.12 0.13 0.14 0.15

s
e
v
i
t
i
s
o
P
e
s
a
F

l

f

o
r
e
b
m
u
n
e
h
T

3

2.7

2.4

2.1

1.8

1.5

1.2

0.9

0.6

0.3

0

x 104

s15850
s38417
s38584
wb_conmx
OpenRisc

0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1 0.11 0.12 0.13 0.14 0.15

(cid:5)(cid:6)(cid:7)(cid:4)(cid:20)(cid:17)(cid:14)(cid:21)(cid:12)(cid:8)(cid:8)(cid:4)(cid:14)(cid:6)(cid:16)(cid:7)(cid:10)(cid:6)(cid:12)(cid:9)(cid:19)

(cid:5)(cid:6)(cid:7)(cid:4)(cid:20)(cid:17)(cid:14)(cid:21)(cid:12)(cid:8)(cid:8)(cid:4)(cid:14)(cid:6)(cid:16)(cid:7)(cid:10)(cid:6)(cid:12)(cid:9)(cid:19)

(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:4)(cid:8)(cid:2)(cid:9)(cid:10)(cid:7)(cid:4)(cid:11)(cid:12)(cid:10)(cid:13)(cid:14)(cid:13)(cid:15)(cid:7)(cid:4)(cid:16)(cid:2)(cid:14)(cid:7)(cid:4)(cid:17)(cid:18)(cid:19)(cid:7)(cid:16)(cid:4)(cid:19)(cid:13)(cid:8)(cid:8)(cid:7)(cid:16)(cid:7)(cid:18)(cid:14)(cid:4)(cid:20)(cid:17)(cid:14)(cid:21)(cid:12)(cid:8)(cid:8)(cid:4)(cid:14)(cid:6)(cid:16)(cid:7)(cid:10)(cid:6)(cid:12)(cid:9)(cid:19)(cid:10)

(cid:1)(cid:22)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:4)(cid:18)(cid:17)(cid:23)(cid:22)(cid:7)(cid:16)(cid:4)(cid:12)(cid:8)(cid:4)(cid:8)(cid:2)(cid:9)(cid:10)(cid:7)(cid:4)(cid:11)(cid:12)(cid:10)(cid:13)(cid:14)(cid:13)(cid:15)(cid:7)(cid:10)(cid:4)(cid:17)(cid:18)(cid:19)(cid:7)(cid:16)(cid:4)(cid:19)(cid:13)(cid:8)(cid:8)(cid:7)(cid:16)(cid:7)(cid:18)(cid:14)(cid:4)(cid:20)(cid:17)(cid:14)(cid:21)(cid:12)(cid:8)(cid:8)(cid:4)(cid:14)(cid:6)(cid:16)(cid:7)(cid:10)(cid:6)(cid:12)(cid:9)(cid:19)(cid:10)

Figure 10: The result of FANCI

d
e

t

t
c
e
e
D
s
T
H

f

o

r
e
b
m
u
N
e
h
T

12

10

8

6

4

2

0

(cid:1)(cid:2)
UCI
VeriTrust

t

s
e
a
d
d
n
a
C

i

f

o
r
e
b
m
u
N
e
h
T

0 1 2 3 4 5 6 7 8 9 10 11 12

The Number of Test Cases

4000

3000

2000

1000

0

UCI
VeriTrust

1 2 3 4 5 6 7 8 9 10 11 12

The Number of Test Cases

(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:6)(cid:10)(cid:11)(cid:12)(cid:13)(cid:9)(cid:14)(cid:6)(cid:15)(cid:16)(cid:6)(cid:17)(cid:7)(cid:18)(cid:6)(cid:19)(cid:9)(cid:20)(cid:9)(cid:21)(cid:20)(cid:9)(cid:19)(cid:6)(cid:22)(cid:23)(cid:20)(cid:8)(cid:6)(cid:20)(cid:9)(cid:18)(cid:20)(cid:6)(cid:21)(cid:4)(cid:18)(cid:9)(cid:18)

(cid:3)(cid:13)(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)(cid:6)(cid:10)(cid:11)(cid:12)(cid:13)(cid:9)(cid:14)(cid:6)(cid:15)(cid:16)(cid:6)(cid:21)(cid:4)(cid:10)(cid:19)(cid:23)(cid:19)(cid:4)(cid:20)(cid:9)(cid:18)(cid:6)(cid:22)(cid:23)(cid:20)(cid:8)(cid:6)(cid:20)(cid:9)(cid:18)(cid:20)(cid:6)(cid:21)(cid:4)(cid:18)(cid:9)(cid:18)

Figure 11: The result of FV, UCI and VeriTrust

Payload
activate timer

Index Circuit Trigger
T1 MC8051 idle mode state
T2 MC8051 a sequence of instructions disable interrupt
T3 MC8051 a sequence of instructions compromise data
T4 MC8051 a sequence of data
T5
T6
T7
T8
T9
T10

the number of instructions compromise memory address
the number of instructions compromise the instruction
the number of instructions manipulate the address
a sequence of bus data
a sequence of instructions switch to administrator
a sequence of bus data
execute malicious codes

RISC
RISC
RISC
Leon3
Leon3
Leon3

compromise stack pointer

access any memories

Table 3: The summary of HTs used in the experiment for FV,
UCI and VeriTrust

the ﬁrst seven HTs (T1-T7) are from Trust-Hub5 [6] while the last
three HTs (T8-T10) are from some related papers [4,11,16]. All of
the HTs are carefully transplanted from the original circuit to the
OpenRISC design, keeping their trigger conditions and malicious
behavior. Then, we implement them according to DeTrust to resist
FV, UCI and VeriTrust.

The effectiveness of these dynamic veriﬁcation techniques is in-
ﬂuenced by the quantity and quality of veriﬁcation test cases. We
therefore show the number of detected HTs and the number of can-
didates reported for further examination with the increasing number
of test cases to illustrate the stealthiness of the HTs designed with
DeTrust. We consider that FV detects an HT if the trigger condition
is satisﬁed, while UCI and VeriTrust detect an HT if any part of the
HT is reported in the candidate list. Results are shown in Fig. 11.

5Trust-Hub HT benchmark suite contains various known HT triggers and
payloads contributed by researchers in the hardware trust domain. For a
detailed description of the code model, please refer to [5].

Fig. 11 (a) shows the number of HTs detected with application
of test cases. As can be observed, all HTs are able to evade FV,
UCI and VeriTrust after all veriﬁcation test cases are applied. For
FV, all HTs evade it because none of these HTs has been activated.
For UCI, all HTs evade it since all parts of the HT are treated as
“useful circuit”. Finally, all HTs evade VeriTrust because none of
trigger inputs are identiﬁed as redundant inputs.

By examining the details in Fig. 11 (a), we have the following
interesting observation. UCI and VeriTrust in fact are able to ﬂag
some HTs with fewer test cases (e.g., less than 4 test cases shown
in Fig. 11 (a)). This phenomenon, however, is not useful for HT
identiﬁcation in practice. This is because, fewer test cases would
result in much more false positives, as shown in Fig. 11 (b), which
leads to much more manual effort for further examination.

With the above, we conclude that DeTrust is also resistant to all
known dynamic veriﬁcation techniques used for HT identiﬁcation.
5. POTENTIAL DEFENSES

In this section, we discuss potential defenses against DeTrust.
We ﬁrst show that, by extending state-of-the-art HT detection tech-
niques such as FANCI and VeriTrust, we can alleviate the threat
posed by DeTrust, but it is not an easy ﬁx due to their associated
computational complexity. Next, we discuss how to defend against
DeTrust from a more practical viewpoint.
5.1 Extending FANCI and VeriTrust

One of the main reasons for DeTrust to be resistant to FANCI and
VeriTrust is that these techniques focus on analyzing the combina-
tional logics only. Thus, to evade FANCI and VeriTrust, DeTrust
spreads HT trigger logic intro multiple sequential levels and com-
bine it with normal logic to make HT become implicitly-triggered.
From this perspective, it is possible to extend FANCI to verify sig-
nals across multiple sequential levels or extend VeriTrust to trace

162and verify signals across multiple sequential levels to defend against
DeTrust, wherein the intermediate state elements can be simply
treated as logic wires. Time-frame expansion [19] can be adopted
to construct the combinational circuit that mimics the functionality
of the sequential circuit.

The extensions for FANCI and VeriTrust may facilitate to iden-
tify HTs that could not be caught previously. For example, for the
HT-infected circuit shown in Fig. 4 (c), if the extended FANCI anal-
ysis is conducted at the entire circuit level directly, the output signal
o would be reported to be suspicious with the small control value
of each trigger input as small as about 1
263 . For the example circuit
shown in Fig. 6 (b), the extension for VeriTrust would catch the HT
by verifying the entire circuit, because the implicit trigger condi-
tion is now made explicit and the corresponding logic entries keep
dormant during veriﬁcation.

The main limitation of the above extension is the associated com-
putational complexity due to the exponential increase space where
HT could be inserted. Without knowing the number of sequential
levels that HT trigger logics cover, both extensions have to enu-
merate all the possibilities (e.g., one-level, two-level, . . . ), which is
computationally-infeasible for large circuits. Speciﬁcally, for the
extension of FANCI, the total number of analyses for HT-related
signals increases dramatically, and Boolean functional analysis it-
self becomes much more difﬁcult due to the exponential increase of
the truth table size in the multi-level logics; for the extension of Ver-
iTrust, the number of products and sums to be traced and checked
increases exponentially with the size of the sequential logic. In the
worst case, the above extension becomes equivalence to verifying
all states of the circuit, which is therefore inapplicable to the large-
scaled IC design.

Moreover, the above extension would introduce a large num-
ber of false positives. On the one hand, when performing analysis
across multiple sequential levels for FANCI, the control values of
those functional inputs would be also rather small, rendering either
false negatives with small cut-off threshold or a large number of
false positives with relatively high cut-off threshold. On the other
hand, for the extension of VeriTrust, as simulation usually only cov-
ers a small functional space, with the increase of the functional
space for potential HTs to hide with DeTrust, VeriTrust would en-
counter many false positives and ﬂag many functional inputs as
suspicious HT trigger inputs.

5.2 Discussion

From the above, we can conclude that simple extensions of exist-
ing trust veriﬁcation techniques are not effective against DeTrust.
The main reason is that, with DeTrust, the problem space for trust
veriﬁcation of the entire circuit is at the same level as verifying its
entire functional space, which is prohibitive for large circuits.

Consequently, for a speciﬁc design, a more practical solution
to alleviate the threat posed by DeTrust is to reduce the problem
space by conducting security analysis and protecting its main as-
sets, based on the knowledge about the design. That is, with a given
design, we ﬁrst identify the critical components in the system, e.g.,
the cryptographic module. Next, we can adopt information ﬂow
checking techniques (e.g., [20]) to identify those circuitries that
may affect these critical components. Finally, we run the extended
trust veriﬁcation techniques as discussed earlier for HT identiﬁca-
tion. Note that, if the problem space is still too large, we can fur-
ther partition the critical components and focus on each functional
block at a time (e.g., random number generator and key generator
in a cryptographic module). However, care must be taken to verify
the interface between these blocks to ensure the completeness of
trust veriﬁcation.

The above design-aware HT identiﬁcation solution signiﬁcantly
reduces computational complexity. However, how to perform se-
curity analysis in terms of HTs is still an open question.

6. RELATED WORK

In this section, we survey related work in the ﬁeld of hardware

security and trust.
6.1 Hardware Trust Challenges

Traditionally, the hardware layer of a secure computing system
(e.g., [21–24]) is often implicitly regarded as trustworthy. This is a
rather “naive” assumption, and various hardware Trojans have been
presented in the literature.

King et al. [4] implemented two HTs in general-purpose pro-
cessor, which grants privileged access to the memory elements of
the system. Skorobogatov and Woods [7] found a backdoor in a
military-grade FPGA device. Various HT designs that are able to
compromise cryptographic device were presented in [25,26]. These
HTs are inserted at the design stage, and DeTrust can be used to en-
hance their stealthiness in terms of trust veriﬁcation techniques.

HTs can be also inserted at the manufacturing stage. Lin et
al. [27, 28] proposed the so-called Trojan side-channels for cryp-
tographic devices. In [29], Wei et al. presented three types of one-
gate HT triggers based on switching power, leakage power, and de-
lay measurements, respectively. Recently, Becker et al. [30] imple-
mented a stealthy HT by changing the dopant polarity of transistors
during the manufacturing process.
6.2 Side-Channel Analysis for HT

Identiﬁcation

Early works in hardware trust ﬁeld are mainly concerned about
HTs being inserted by a third-party foundry during the manufactur-
ing process, and they rely on side-channel analysis (SCA) for HT
identiﬁcation. The idea behind is that an HT will affect some side-
channel signatures (e.g., path delay, power consumption or sup-
ply current), even when it is not functionally activated. According
to the signatures, they can be classiﬁed into timing-based analy-
sis (e.g., [31]), current-based analysis (e.g., [32]), and power-based
analysis (e.g., [33, 34]). Process variation has a signiﬁcant impact
on the effectiveness of early works on SCA analysis. Recently,
gate-level characterization [35], multimodal analysis [36], and out-
lier analysis [37] are shown to be resistant to process variation ef-
fects and hence are quite promising.

One common assumption of the above HT detection techniques
is the existence of HT-free golden ICs used as reference, and hence
they are not applicable for identifying HTs inserted at design time.
6.3 Design for Hardware Trust

Ideally, we would like to prevent HTs from ever being inserted
into circuits or ever being triggered at runtime. Some design-for-
trust techniques tried to achieve the above objectives.
6.3.1 Design Time Prevention
Chakraborty and Bhunia [38] proposed to employ design obfus-
cation such that the circuit operates in two distinct modes, which
dramatically increases the difﬁculty of HT insertion for attackers.
Potkonjak [39] showed how to prevent untrusted CAD tool to com-
promise the design by checking at every synthesis step. For FPGA-
based design, Huffmire et al. [40] proposed to physically isolate
untrusted IP cores and trusted ones and restrict their communica-
tion, while Dutt and Li [41] adopted error correction coding (ECC)
to detect design tampers that try to change, delete or add logic into
the design.

1636.3.2 Run Time Prevention
In [11], Hicks et al. also presented the so-called BlueChip con-
cept to emulate the behavior of the suspicious circuitries at run-
time. However, BlueChip identify suspicious circuitries with UCI
algorithm only, and hence cannot detect HTs designed with De-
Trust. Waksman and Sethumadhavan [12] proposed TrustNet and
DataWatch to detect suspicious malicious behavior in the pipeline
of the processor at runtime. However, they are only effective to cer-
tain pre-deﬁned malicious behavior and their capabilities are lim-
ited by the amount of information to be checked at runtime. Later,
the same authors [13] proposed to disable HTs at runtime by scram-
bling inputs of the hardware units. While effective for computa-
tional units, this technique would fail to disable HTs by DeTrust
embedded in control logic. Dai et al. [42] proposed a speciﬁc HT
detection method for Response-Computing Authentication module,
but their approach cannot solve the general HTs designed by De-
Trust.

7. CONCLUSION

IC products are the core components of electronic systems being
used in daily life, and it is essential to ensure that they faithfully
perform their speciﬁed functionalities. Hardware Trojans imple-
mented by adversaries, being able to subvert or augment the normal
operation of infected devices, are thus serious threats.

Recently, state-of-the-art hardware trust veriﬁcation solutions such

as FANCI and VeriTrust are shown to be able to effectively defend
against existing HT designs presented in the literature. Unfortu-
nately, this is not enough because it is expected that adversaries
would adjust their tactics of attacks accordingly. Therefore, we
need to examine whether new types of HTs can be designed to de-
feat these hardware trust veriﬁcation techniques. In this paper, we
present a so-called DeTrust HT design methodology that is able
to be resistant to all known HT identiﬁcation techniques, and its
stealthiness has been validated with practical attacks performed on
an OpenRISC processor. Finally, we show that there is no easy ﬁx
to existing solutions against the threat posed by DeTrust, calling for
more advanced future works to ensure hardware trust.

8. ACKNOWLEDGMENTS

This work was supported in part by the Hong Kong SAR Re-
search Grants Council (RGC) under General Research Fund No.
CUHK418111 and CUHK Direct Grant No. 2050488.

9. REFERENCES
[1] M. Tehranipoor and F. Koushanfar. A survey of hardware

Trojan taxonomy and detection. Design and Test of Computers,
27(1):10–25, 2010.

[2] J. Markoff. Old trick threatens the newest weapons. The New

[3] S. Adee. The hunt for the kill switch. Spectrum, IEEE,

York Times, 27, 2009.

45(5):34–39, 2008.

[4] S. T. King, J. Tucek, A. Cozzie, C. Grier, W. Jiang, and Y.

Zhou. Designing and implementing malicious hardware. LEET,
8:1–8, 2008.

[5] J. Zhang and Q. Xu. On hardware Trojan design and

implementation at register-transfer level. In Proc. IEEE
International Symposium on Hardware-Oriented Security and
Trust (HOST), pp. 107–112, 2013.

[6] Trust-Hub Website.

http://www.trust-hub.org/resources/benchmarks.

[7] S. Skorobogatov and C. Woods. Breakthrough silicon scanning

discovers backdoor in military chip. In Proc. International
Conference on Cryptographic Hardware and Embedded
Systems (CHES), pp. 23–40, 2012.

[8] Y. Liu, Y. Jin, and Y. Makris. Hardware Trojans in wireless

cryptographic ICs: silicon demonstration & detection method
evaluation. In Proc. IEEE/ACM International Conference on
Computer-Aided Design (ICCAD), pp. 399–404, 2013.

[9] M. Beaumont, B. Hopkins, and T. Newby. Hardware

Trojans-prevention, detection, countermeasures (a literature
review). Technical report, 2011.

[10] U.S.A. Department of Defense. Defense science board task

force on high performance microchip supply. Washington, DC,
pp. 2005–02, 2005.

[11] M. Hicks, M. Finnicum, S. T. King, M. K. Martin, and J. M.

Smith. Overcoming an untrusted computing base: detecting and
removing malicious hardware automatically. In Proc. IEEE
Symposium on Security and Privacy (SP), pp. 159–172, 2010.

[12] A. Waksman and S. Sethumadhavan. Tamper evident

microprocessors. In Proc. IEEE Symposium on Security and
Privacy (SP), pp. 173–188, 2010.

[13] A. Waksman and S. Sethumadhavan. Silencing hardware

backdoors. In Proc. IEEE Symposium on Security and Privacy
(SP), pp. 49–63, 2011.

[14] J. Zhang, F. Yuan, L. Wei, Z. Sun, and Q. Xu. VeriTrust:

veriﬁcation for hardware trust. In Proc. IEEE/ACM Design
Automation Conference (DAC), pp. 1–8, 2013.

[15] A. Waksman, M. Suozzo, and S. Sethumadhavan. FANCI:

identiﬁcation of stealthy malicious logic using boolean
functional analysis. In Proc. ACM Conference on Computer and
Communication Security (CCS), pp. 697–708, 2013.

[16] C. Sturton, M. Hicks, D. Wagner, and S. T King. Defeating

UCI: building stealthy and malicious hardware. In Proc. IEEE
International Symposium on Security and Privacy (SP), pp.
64–77, 2011.

[17] J. Bormann, et al. Complete formal veriﬁcation of TriCore2 and
other processors. In Design and Veriﬁcation Conference, 2007.

[18] OpenCores Website. http://opencores.org/.
[19] F. Fallah. Binary time-frame expansion. In Proc. IEEE/ACM

International Conference on Computer Aided Design (ICCAD),
pp. 458–464, 2002.

[20] M. Tiwari, H. Wassel, B. Mazloom, S. Mysore, F. T. Chong,

and T. Sherwood. Complete information ﬂow tracking from the
gates up. In Proc. International Conference on Architectural
Support for Programming Languages and Operating Systems
(ASPLOS), pp. 109–120, 2009.

[21] J. Szefer and R. B. Lee. Architectural support for

hypervisor-secure virtualization. 40(1):437–450, 2012.

[22] D. Champagne and R. B. Lee. Scalable architectural support for

trusted software. In Proc. Symposium on High Performance
Computer Architecture (HPCA), pp. 1–12. IEEE, 2010.
[23] C. W. Fletcher, M. van Dijk, and S. Devadas. A secure

processor architecture for encrypted computation on untrusted
programs. In Proc. ACM workshop on Scalable Trusted
Computing (STC), pp. 3–8, 2012.

[24] TPM speciﬁcation architecture overview.
http://www.trustedcomputinggroup.org/.

[25] A. Baumgarten, M. Steffen, M. Clausman, and J. Zambreno. A

case study in hardware trojan design and implementation.
International Journal of Information Security, 10:1–14, 2011.

[26] Y. Jin, N. Kupp, and Y. Makris. Experiences in hardware Trojan

design and implementation. In Proc. IEEE International
Workshop on Hardware-Oriented Security and Trust (HOST),
pp. 50–57, 2009.

[27] L. Lin, M. Kasper, T. Güneysu, C. Paar, and W. Burleson.

Trojan side-channels: lightweight hardware Trojans through
side-channel engineering. In Proc. International Conference on
Cryptographic Hardware and Embedded Systems (CHES), pp.
382–395, 2009.

[28] L. Lin, W. Burleson, and C. Paar. MOLES: Malicious off-chip

leakage enabled by side-channels. In Proc. IEEE/ACM
International Conference on Computer-Aided Design (ICCAD),
pp. 117–122, 2009.

[29] S. Wei, K. Li, F. Koushanfar, and M. Potkonjak. Hardware

Trojan horse benchmark via optimal creation and placement of
malicious circuitry. In Proc. IEEE/ACM Design Automation
Conference (DAC), pp. 90–95, 2012.

164Symbol Meaning
T
T c/T r
D
Dc/Dr
C
Cn
Cm
Cc/Cr
F
Pn
Pm
Fc/Fr

the set of trigger inputs, T = {t1,t2, . . . ,tm}
the subset of T , T c ⊂ T , T r ⊂ T
the set of functional inputs, D = {d1,d2, . . . ,d n}
the subsets of D, Dc ⊂ D and Dr ⊂ D
the set of all conditions driven by all trigger inputs T , C = {c1,c2, . . . ,c 2m}
the set of non-trigger conditions, Cn = {cn1
the set of the trigger conditions, Cm = {cm1
the set of all conditions driven by T c/T r
the set of all input patterns driven by all functional inputs D
the subset of F that makes the normal function output logic ‘1’, Pn = {pn1
, pn2
the subset of F that makes the malicious function output logic ‘1’, Pm = {pm1
the set of all input patterns driven by Dc/Dr

, . . . ,c nx
, . . . ,c my

,cn2
,cm2

}, Cn ⊂ C
}, Cm ⊂ C, Cm ∪Cn = C Cm ∩Cn = ∅

, . . . , pny
, pm2

, . . . , pmz

}, Pn ⊂ F

}, Pm ⊂ F

Table 4: List of Notations

[30] G. T. Becker, F. Regazzoni, C. Paar, and W. P. Burleson.

Stealthy dopant-level hardware Trojans. In Proc. International
Conference on Cryptographic Hardware and Embedded
Systems (CHES), pp. 197–214, 2013.

[31] Y. Jin and Y. Makris. Hardware Trojan detection using path
delay ﬁngerprint. In Proc. IEEE International Workshop on
Hardware-Oriented Security and Trust (HOST), pp. 51–57,
2008.

[32] D. Du, S. Narasimhan, R. S. Chakraborty, and S. Bhunia.

Self-referencing: a scalable side-channel approach for hardware
trojan detection. In Proc. International Conference on
Cryptographic Hardware and Embedded Systems (CHES), pp.
173–187, 2010.

[33] D. Agrawal, S. Baktir, D. Karakoyunlu, P. Rohatgi, and B.

Sunar. Trojan detection using IC ﬁngerprinting. In Proc. IEEE
Symposium on Security and Privacy (SP), pp. 296–310, 2007.

[34] R. M. Rad, X. Wang, M. Tehranipoor, and J. Plusquellic. Power

supply signal calibration techniques for improving detection
resolution to hardware Trojans. In Proc. IEEE/ACM
International Conference on Computer-Aided Design (ICCAD),
pp. 632–639, 2008.

[35] S. Wei, S. Meguerdichian, and M. Potkonjak. Gate-level

characterization: foundations and hardware security
applications. In Proc. IEEE/ACM Design Automation
Conference (DAC), pp. 222–227, 2010.

[36] K. Hu, A. N. Nowroz, S. Reda, and F. Koushanfar.

High-sensitivity hardware trojan detection using multimodal
characterization. In Proc. IEEE/ACM Design, Automation and
Test in Europe (DATE), pp. 1271–1276, 2013.

[37] J. Zhang, H. Yu and Q. Xu. HTOutlier: hardware Trojan

detection with side-channel signature outlier identiﬁcation. In
Proc. IEEE International Symposium on Hardware-Oriented
Security and Trust (HOST), pp. 55–58, 2012.

[38] R. S. Chakraborty and S. Bhunia. Security against hardware
Trojan through a novel application of design obfuscation. In
Proc. IEEE/ACM International Conference on Computer-Aided
Design (ICCAD), pp. 113–116, 2009.

[39] M. Potkonjak. Synthesis of trustable ICs using untrusted CAD

tools. In Proc. IEEE/ACM Design Automation Conference
(DAC), pp. 633–634, 2010.

[40] T. Huffmire, B. Brotherton, G. Wang, T. Sherwood, R. Kastner,
T. Levin, T. Nguyen, and C. Irvine. Moats and drawbridges: an
isolation primitive for reconﬁgurable hardware based systems.
In Proc. IEEE Symposium on Security and Privacy (SP), pp.
281–295, 2007.

[41] S. Dutt and L. Li. Trust-based design and check of FPGA

circuits using two-level randomized ECC structures.
Transcations on Reconﬁgurable Technology and System,
2(1):1–36, 2009.

[42] S. Dai, T. Wei, C. Zhang, T. Wang, Y. Ding, Z. Liang, and W.

Zou. A framework to eliminate backdoors from
response-computable authentication. In Proc. IEEE Symposium
on Security and Privacy (SP), pp. 3–17, 2012.

APPENDIX
In this appendix, we prove that HT designed with DeTrust is able
to evade VeriTrust under non-trigger conditions. All symbols used
in the following are listed in Table 4.

Let us ﬁrst consider the Boolean function of the HT-affected sig-
nal without DeTrust, wherein there is only one malicious on-set
term cm0 pm0, given by Eq. 6 (see Section 3.3.2):

f = f
= f

where

(cid:5)
n + (cn0 pn0
(cid:5)
n + cc pc(cr

+ cm0 pm0
n0 pr
+ cr
n0

)
m0 pr
m0

),

cn0
cm0
cn0
cm0

= pc pr
,
n0
= pc pr
m0

= cccr
n0
= cccr
m0
∈ Cn, pn0
∈ Cm, pm0

, pn0
, pm0
∈ Pn,
∈ Pm,

,

and cm0 pm0 denotes a malicious on-set term/product, cn0 pn0 de-
notes a on-set term/product from the normal function, cc pc denotes
the common literals of cn0 pn0 and cm0 pm0, and f (cid:5)
n denotes all on-
set terms/products from the normal function except cn0 pn0. With
DeTrust, we have

where

f = h1h2 + h3,

h1 = cc pc
h2 = cr
n0 pr
n0
(cid:5)
h3 = f
n

+ cr

m0 pr
m0

.

To prove that the above HT implementation is able to evade Ver-
iTrust, we need to prove that f , h1, h2 and h3 have no redundant
inputs under non-trigger conditions. To be speciﬁc, we ﬁrst prove
that h1, h2 and h3 are not redundant for f under non-trigger condi-
tions in Statement 1, Statement 2 and Statement 3, and then prove
that h1, h2 and h3 have no redundant inputs under non-trigger con-
ditions in Statement 4.

To prove that an input is not redundant under non-trigger con-
ditions, our idea is to ﬁnd one pair of input patterns that meet the
following three requirements:

• they are different only at the value of this input;
• they would generate different output values;
• they can be activated under non-trigger conditions.

Next, let us present proofs of Statement 1, Statement 2, Statement
3 and Statement 4 in the following, respectively.

165tions.

Statement 1: h1 is not redundant for f under non-trigger condi-
PROOF. We use input patterns, {1,1,0} and {0,1,0} for {h1,h2,h3},

|cc

n0 pr

m0 pc pr
m0

∈ Cc,cc

to prove statement 1. Obviously, these two input patterns meet the
ﬁrst two requirements, and next we prove that they can be activated
under non-trigger conditions as follows.
The input pattern, {1,1,0}, can be generated by activating cn0 pn0
that belongs to the normal function. With cn0 pn0, h1 = 1, as cc pc
n0 is activated; h3 = 0, as h3 = f (cid:5)
is activated; h2 = 1, as cr
n does
not include cn0 pn0. Note that only cn0 pn0 can generate {1,1,0}.
The input pattern, {0,1,0}, can be generated by activating a set
(cid:3)= cc} which are con-
of input patterns, {cc
i cr
trolled by non-trigger conditions. With such input patterns, h1 = 0,
(cid:3)= cc is activated; h2 = 1, as cr
i pc where cc
as cc
m0 is activated;
h3 = 0, as {cc
(cid:3)= cc}, that is the neighbor of
i
i cr
m0 pc pr
m0
m0 pc pr
the malicious on-set term/product of cccr
m0, must be equal to
∈ Cc,cc
(cid:3)=
|cc
logic ‘0’, according to [14]. Note that {cc
i cr
m0 pc
j pr
m0
i
(cid:3)= cc}, {cccr
|pc
∈
|cc
∈Cc,cc
j pr
n0 pc
cc; pc
n0
i
j
(cid:3)= cc; pc
∈ Fc, pc
∈ Cc,cc
(cid:3)= pc}
Fc, pc
j
j
are another four sets whose elements are possible to generate {0,1,0},
as long as they are not included into f (cid:5)
n.
Since f = h1h2 +h3, only the pair of input patterns, {1,1,0} and
{0,1,0}, can be used to prove Statement 1.

(cid:3)= pc}, {cc
∈ Fc, pc
i cr
(cid:3)= pc}, and {cc
i cr
n0 pc

n0 pc pr
n0
|cc
j pr
n0
i

∈ Cc,cc

m0 pr

|cc

i

i

i

i

i

i

j

j

i

j

tions.

Statement 2: h2 is not redundant for f under non-trigger condi-
PROOF. We use input patterns, {1,1,0} and {1,0,0} for {h1,h2,h3},

mi pc pr
m0

to prove statement 2. Obviously, these two input patterns meet the
ﬁrst two requirements, and next we prove that they can be activated
under non-trigger conditions as follows.
The input pattern, {1,1,0}, can be generated by cn0 pn0, which
has been proved in the statement 1.
The input pattern, {1,0,0}, can be generated by activating a set
∈ Cr,cr
(cid:3)= cr
} which are con-
|cr
of input patterns, {cccr
mi
m0
mi
trolled by non-trigger conditions. With such input patterns, h1 = 1,
n0 pr
m0 pr
m0 and cr
as cc pc is activated; h2 = 0, as both cr
n0 are not ac-
∈ Cr,cr
tivated; h3 = 0, as the activated {cccr
},
(cid:3)= cr
|cr
mi pc pr
mi
m0
m0
mi
that is the neighbor of malicious on-set term/product of cccr
m0 pc pr
m0,
|cr
(cid:3)=
∈ Cr,cr
must be equal to logic ‘0’. Note that {cccr
mi pc pr
mi
mi
m j
} is another set of input patterns to possi-
m0; pr
cr
m j
bly generate {1,0,0} as long as cr
= 0 and f (cid:5)
Since f = h1h2 +h3, only the pair of input patterns, {1,1,0} and
{1,0,0}, can be used to prove Statement 2.

∈ Fr, pr
m j

(cid:3)= pr
m0

n = 0.

n0 pr
n0

tions.

Statement 3: h3 is not redundant for f under non-trigger condi-
PROOF. We use input patterns, {0,0,0} and {0,0,1} for {h1,h2,h3},

n0 pr

n0 and cr

to prove statement 3. Obviously, these two input patterns meet the
ﬁrst two requirements, and next we prove that they can be activated
under non-trigger conditions as follows.
The input pattern, {0,0,0}, can be generated by activating a set
}
of input patterns, {ci pi|ci ∈ Cn,ci (cid:3)= cn0; pi ∈ (F − Pn), pi (cid:3)= pm0
controlled by non-trigger conditions. With such input patterns,
h1 = 0 and h2 = 0, as cc pc, cr
m0 are not activated;
}.
n outputs logic ‘0’ due to {pi|pi ∈ (F − Pn), pi (cid:3)= pm0
h3 = 0, as f (cid:5)
The input pattern, {0,0,1}, can be generated by activating a set
} which are
of patterns, {ci pi|ci ∈ Cn,ci (cid:3)= cn0; pi ∈ Pn, pi (cid:3)= pm0
controlled by non-trigger conditions. With such input patterns,
h1 = 0 and h2 = 0, as it is easy to ﬁnd an element in this set where
cc pc, cr
n outputs
}.
logic ‘1’ due to {ci|ci ∈ Cn,ci (cid:3)= cn0
Moreover, Statement 3 can be proven by the {0,1,0} and {0,1,1},
and {1,0,0} and {1,0,1} as well. We do not list all those input pat-
terns, since above is enough to prove Statement 3.

m0 are not activated; h3 = 1, as f (cid:5)

} and {pi|pi ∈ Pn, pi (cid:3)= pm0

n0 and cr

m0 pr

m0 pr

n0 pr

Statement 1, Statement 2 and Statement 3 together prove that f

has no redundant inputs under non-trigger conditions.

Statement 4: h1, h2 and h3 have no redundant inputs under non-

trigger conditions.

PROOF. All input patterns of h1, h2 and h3 could be activated
without triggering the HT, since the complete trigger conditions
does not exist in their fan-in cones. Therefore, all their inputs are
not redundant under non-trigger conditions.

If the malicious function contains more than one on-set terms,

with DeTrust, we have

k−1∑

f =

(h2i+1h2i+2) +h 2k+1,

where

i=0

h2i+1 = cci pci
h2i+2 = crini prini
h2k+1 = f

(cid:5)
n

+ crimi primi

,

as shown in Eq. 11 (see Section 3.3.2). We are able to follow the
above procedure to prove that h1, h2, . . . , h2k+1 are not redundant
for f , and meanwhile h1, h2, . . . , h2k+1 have no redundant inputs.
Consequently, DeTrust is able to successfully evade VeriTrust.

166