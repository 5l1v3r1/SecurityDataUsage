Chucky: Exposing Missing Checks in Source Code

for Vulnerability Discovery

Fabian Yamaguchi
University of Göttingen
Göttingen, Germany

Christian Wressnegger

idalab GmbH

Berlin, Germany
Konrad Rieck

University of Göttingen
Göttingen, Germany

Hugo Gascon

University of Göttingen
Göttingen, Germany

Abstract
Uncovering security vulnerabilities in software is a key for
operating secure systems. Unfortunately, only some secu-
rity ﬂaws can be detected automatically and the vast ma-
jority of vulnerabilities is still identiﬁed by tedious auditing
of source code. In this paper, we strive to improve this sit-
uation by accelerating the process of manual auditing. We
introduce Chucky, a method to expose missing checks in
source code. Many vulnerabilities result from insuﬃcient in-
put validation and thus omitted or false checks provide valu-
able clues for ﬁnding security ﬂaws. Our method proceeds by
statically tainting source code and identifying anomalous or
missing conditions linked to security-critical objects. In an
empirical evaluation with ﬁve popular open-source projects,
Chucky is able to accurately identify artiﬁcial and real miss-
ing checks, which ultimately enables us to uncover 12 previ-
ously unknown vulnerabilities in two of the projects (Pidgin
and LibTIFF).

Categories and Subject Descriptors
D.2.4 [Software Engineering]: Software/Program Veriﬁ-
cation; K.6.5 [Management of Computing and Infor-
mation Systems]: Security and Protection

Keywords
Vulnerabilities; Static Analysis; Anomaly Detection

1.

INTRODUCTION

Detecting and eliminating vulnerabilities in software is a
key for operating secure computer systems. The slightest
ﬂaw in the design or implementation of software can severely
undermine its security and make it an easy victim for attack-
ers. Several security incidents of the last years are actually
the result of critical vulnerabilities in software, for example,

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516665.

the attacks conducted by Stuxnet [8], the drive-by download
attacks exploiting Java ﬂaws [24] and the recently discovered
UPNP ﬂaws in millions of home routers [21].

Finding vulnerabilities in software is a classic problem of
computer security. Unfortunately, an automatic approach
for ﬁnding arbitrary vulnerabilities cannot exist. Accord-
ing to Rice’s theorem, checking whether a program contains
vulnerable code using another program is undecidable in the
general case [12].

As a result of this limitation, security research has focused
on discovering speciﬁc types of vulnerabilities. For example,
the usage of potentially dangerous functions, such as strcpy
and strcat, can be easily detected by scanning for these func-
tions [e.g., 3, 36, 39]. Similarly, analysis techniques such as
fuzzing [e.g., 22, 33] and taint analysis [e.g., 23, 26] can help
in spotting insecure ﬂows of data in software. Sophisticated
methods using symbolic execution can even discover ﬂaws
in unusual code branches [e.g., 1, 9, 37]. Many of these ap-
proaches, however, are hard to operate eﬀectively in practice
and opaque to a security analyst [see 11, 14]. Consequently,
the vast majority of security ﬂaws is still discovered by te-
dious and time-consuming manual analysis.

In this paper, we strive to improve this situation by ac-
celerating the process of manual auditing. To this end, we
introduce Chucky, a method for automatically identifying
missing checks in source code. Many types of vulnerabilities
result from insuﬃcient validation of input and thus omitted
checks provide valuable clues for ﬁnding security ﬂaws. For
example, if the length of data copied to a buﬀer is checked
in 9 out of 10 functions in a program, it is evident that the
function missing the check is a prime candidate for secu-
rity auditing. To identify such functions, Chucky statically
taints the source code and detects anomalous or missing
conditions linked to security-critical objects, such as mem-
ory buﬀers. By comparing regular checks with missing ones,
Chucky is able to suggest correct conditions and potential
ﬁxes to the analyst.

Our method operates independent of external information
and additional annotations, as for example used by the static
security checker Splint [7]. Instead we build on the assump-
tion that missing or faulty checks are rare events and the
majority of conditions imposed on security-critical objects
in a software project are correct. While this assumption is
satisﬁed for mature software projects, it does not hold true
in all cases. We discuss limitations of our approach in Sec-
tion 5 speciﬁcally.

499We demonstrate the eﬃcacy of our approach in a quali-
tative and quantitative evaluation, where we analyze miss-
ing checks in the code of the following popular open-source
projects: Firefox, Linux, LibPNG, LibTIFF and Pidgin. For
all projects, Chucky is able to identify artiﬁcial and real
missing checks accurately with few false positives. This ac-
curacy ultimately enables us to identify 12 diﬀerent previ-
ously unknown vulnerabilities in two of the projects, namely
Pidgin and LibTIFF.

In summary, we make the following contributions:
• Identiﬁcation of missing checks. We introduce a
novel method for static analysis of source code that is
able to automatically identify missing checks for vul-
nerability discovery.

• Anomaly detection on conditions. Our method
embeds functions in a vector space, such that miss-
ing and unusual expressions in their conditions can be
identiﬁed automatically.

• Top-down and bottom-up analysis. Taint analysis
enables us to spot missing checks on untrusted input
sources (top-down) as well as when accessing security-
critical sinks (bottom-up).

• Suggestion of corrections. During auditing our
method is able to suggest potential ﬁxes to an analyst
by highlighting diﬀerences between a missing check
and regular ones.

The rest of this paper is structured as follows: we re-
view missing-check vulnerabilities in Section 2 and introduce
Chucky in Section 3 along with technical details. We eval-
uate its ability to expose missing checks on real source code
in Section 4. Limitations and related work are discussed in
Section 5 and 6, respectively. Section 7 concludes the paper.

2. MISSING-CHECK VULNERABILITIES
Many critical classes of vulnerabilities in software are a
direct consequence of missing checks. This includes ﬂaws in
access control, such as missing checks of user permissions,
as well as purely technical defects, such as buﬀer and in-
teger overﬂows resulting from missing range checks. The
consequences of these classes of vulnerabilities can be dra-
matic. For example, in January 2013 a vulnerability in the
Java 7 runtime caused by a missing check in an access control
component allowed attackers to install malware on millions
of hosts (CVE-2013-0422). Thus, ﬁnding missing checks is
crucial for securing software and computer systems.

Throughout this paper, we adopt the terminology estab-
lished in the ﬁeld of taint analysis for discussing missing
checks [see 29]. In taint analysis, data entering a program
via a source is monitored as it propagates to a sink, possibly
undergoing validation in the process. Using this terminology
we can discriminate two types of security checks in source
code, both of which Chucky is designed to analyze.

• Checks implementing security logic. Programs
implementing access control, such as Web applications
or operating system kernels, perform security checks
to restrict access to resources. Methods to detect spe-
ciﬁc types of these ﬂaws have been proposed for Web
applications [31] as well as Linux kernel code [34]. In
this setting, parameters or global variables act as input

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

int foo(char *user, char *str, size_t n)
{

char buf[BUF_SIZE], *ar;
size_t len = strlen(str);

if(!is_privileged(user))

return ERROR;

if(len >= BUF_SIZE) return ERROR;
memcpy(buf, str, len);

ar = malloc(n);
if(!ar) return ERROR;

return process(ar, buf, len);

}

Figure 1: Exemplary security checks in a C function:
a check implementing security logic (line 6) and two
checks ensuring secure API usage (line 9 and 13).

sources, which need to be validated. As an example,
consider the ﬁrst check in Figure 1, where the parame-
ter user is validated before allowing the remaining code
of the function to be executed.

• Checks ensuring secure API usage. Regardless of
security logic, checks to ensure secure operation of in-
ternal and external APIs are required. As an example,
consider the last two checks shown in Figure 1. To pro-
tect from buﬀer overﬂows, the ﬁrst check validates the
variable len derived from the source strlen before it is
propagated to the sink memcpy. Moreover, the second
check validates the return value of the source malloc to
ensure that subsequent code does not cause a denial of
service condition by dereferencing a NULL-pointer.

Chucky is based on the key observation that sources
and sinks are usually employed many times within a code
base, each time requiring similar security checks to be im-
plemented. As a consequence, there often exist typical pat-
terns for checking data retrieved from sources or propagated
to sinks. If such patterns can be automatically inferred from
the code, it is possible to detect deviations from these pat-
terns and thereby spot potential vulnerabilities.

3.

IDENTIFYING MISSING CHECKS

Exposing missing checks in source code poses two main
challenges: First, typical checks must be determined au-
tomatically by leveraging information scattered throughout
the code base. Second, any deviations from these checks
need to be detected and presented to the analyst while brows-
ing the code. Moreover, the analyst must be able to easily
comprehend how the method arrives at its results.

To address these problems, our method implements a ﬁve-
step procedure, which can be executed for each source and
sink referenced by a selected function. This procedure com-
bines techniques from static analysis and machine learning
to determine missing checks and provide supporting evi-
dence. The ﬁve steps are illustrated in Figure 2 and outlined
in the following:

1. Robust Parsing. Conditions, assignments and API
symbols are ﬁrst extracted from a function’s source
code using a robust parser [20].
In particular, the

500Figure 2: Overview of Chucky: (1) sources and sinks are identiﬁed, (2) functions with similar context are
grouped, (3) variables depending on the sources/sinks are tainted, (4) functions are embedded in a vector
space using tainted conditions, and (5) functions with anomalous or missing conditions are detected.

sources and sinks used in each of the functions are de-
termined. The remaining four steps are then executed
for each source or sink independently.

2. Neighborhood discovery. The necessity of a check
highly depends on the context code operates in. Our
method thus identiﬁes functions in the code base oper-
ating in a similar context to that of the selected func-
tion using techniques inspired by natural language pro-
cessing (Section 3.2).

3. Lightweight tainting. To determine only those checks
associated with a given source or sink, lightweight taint-
ing is performed for the function under examination
and all its neighbors in top-down and bottom-up di-
rection (Section 3.3).

4. Embedding of functions. The selected function and
its neighbors are then embedded in a vector space using
the tainted conditions such that they can be analyzed
using machine learning techniques (Section 3.4).

5. Anomaly Detection. The embedding of functions
enables us to geometrically search for missing checks.
In particular, we compute a model of normality over
the functions, such that anomalous checks can be iden-
tiﬁed by large distances from this model (Section 3.5).

In the following sections, we describe these steps in more
detail and provide the necessary technical as well as theo-
retical background.
3.1 Robust Parsing

Reasoning about missing checks requires a deep under-
standing of program syntax. Chucky therefore begins by
parsing code using a robust parser for C/C++ developed
during our research. The parser is based on an island gram-
mar [see 20] for the parser generator ANTLR [25] and pro-
vides abstract syntax trees (ASTs) for all functions of a code
base even when declarations can only be resolved partially.
This allows Chucky to be directly employed without requir-
ing code to be compiled or a build environment to be conﬁg-
ured. To encourage more research in the area, we have made
our parser available as open-source software1. Chucky em-
ploys this parser to extract the following information from
each function.

1https://github.com/fabsx00/joern

• Sources and sinks. All function parameters, func-
tion calls as well as global and local variables are poten-
tial sources or sinks of information, each of which may
be tied to a unique set of conditions required for secure
operation. Chucky therefore begins by extracting all
sources and sinks from each function. The granularity
of the analysis is further increased by taking ﬁelds of
structures into account. As an example, consider Fig-
ure 3 where all sources and sinks of the function foo
are marked.

• API symbols. Additionally, we extract API symbols
as a prerequisite for neighborhood discovery (see Sec-
tion 3.2). All types used in parameter and local vari-
able declarations as well as the names of all functions
called are considered as API symbols.

• Assignments. Assignments describe the ﬂow of in-
formation between variables, which we exploit to de-
termine conditions related to a sink by performing
lightweight tainting (see Section 3.3). For each assign-
ment, we store the subtree of the AST referring to the
left- and right-value of the assignment.

• Conditions. Ultimately, functions are compared in
terms of the conditions they impose when using a source
or sink (see Sections 3.4 and 3.5). As conditions, we
consider all expressions of control statements such as
those introduced by the keywords if, for or while as
well as those found in conditional expressions. To pro-
vide access to partial expressions, we store conditions
as references to corresponding subtrees of the AST
rather than as ﬂat strings.

Upon completion of this step, patterns can be determined
for each of the extracted sources and sinks and analyzed for
missing checks, as explained in the following sections.
3.2 Neighborhood Discovery

Security checks are often highly context dependent. For
example, omitting checks on string operations may be per-
fectly acceptable when parsing conﬁguration ﬁles, while pos-
ing a serious threat when processing network data. Chucky
accounts for this diﬀerence by only comparing the function
under examination to functions sharing a similar context.
This is achieved by identifying the neighborhood of the func-
tion, that is, related functions using similar API symbols.
The rationale behind this choice is that the combination of
interfaces used by a function is characteristic for the subsys-
tem it operates in as well as the functionality it implements.

(1) Identiﬁcation of sinks and sources(2) Neighborhood discoveryvoid foo(int n) {    ...    x = malloc(n);    if (x && n > 0)        process(x, n);    ...}void woo(int n) {    ...    malloc(...);    ...    process(...);    ...}void boo(int n) {    ...    malloc(...);    ...    process(...);    ...}void bar(int n) {    ...    malloc(...);    ...    process(...);    ...}(4) Embedding of functions(n > 0)(x)bar()foo()woo()boo()(5) Anomaly detection(n > 0)(x)Missing checkNormalityInput sourcevoid foo(int n) {    ...    x = malloc(n);    if (x && n > 0)        process(x, n);    ...}(3) Lightweighttainting5011

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

int foo(char *user, char *str, size_t n)
{

char buf[BUF_SIZE], *ar;
size_t len = strlen(str);

if(!is_privileged(user))

return ERROR;

if(len >= BUF_SIZE) return ERROR;
memcpy(buf, str, len);

ar = malloc(n);
if(!ar) return ERROR;

return process(ar, buf, len);

}

Figure 3: C function with sources and sinks: All
parameters (line 1), global and local variables (lines
3,4 and 9) and function calls (line 4, 6, 10, 12 and
15) are marked for analysis.

For discovering these neighboring functions, we adapt the
classic bag-of-words model from natural language process-
ing that is commonly used to compare text documents [28].
Similar to the words in these documents, we represent each
function in the code base by the API symbols it contains. We
then map the functions to a vector space, whose dimensions
are associated with the frequencies of these symbols [see 41].
Functions using a similar API lie close to each other in this
vector space, whereas functions with diﬀerent context are
separated by large distances.
Formally, we deﬁne a mapping φ from the set of all func-
tions X = {x1, . . . , xm} to R|A| where A is the set of all API
symbols contained in X. This mapping is given by

, φ(x) (cid:55)→(cid:0)I(x, a) · TFIDF(x, a, X)(cid:1)
(cid:40)

1 if x contains API symbol a
0 otherwise

a∈A

where I is an indicator function deﬁned as

φ : X → R|A|

I(x, a) =

and TFIDF(x, a, X) a standard weighting term from infor-
mation retrieval [28]. The rationale behind the use of this
term is to lower the impact of very frequently used API
symbols on the similarity of functions.
This geometric representation enables us to identify the
k-nearest neighbors N ⊂ X of the selected function x with
respect to the source or sink s. We determine this set N by
ﬁrst extracting all functions of the code base that reference s.
We then calculate the cosine distance of their corresponding
vectors to φ(x) and ﬁnally select those k functions with the
smallest distance.

Note, that Chucky is not very sensitive to the choice
of the parameter k, as we demonstrate in Section 4, where
values between 10 and 30 provide good performance. As
a result of the neighborhood discovery, only the function
under examination and its neighbors need to be processed
in the following steps of the analysis.
3.3 Lightweight Tainting

Among the many checks present in a regular function,
only a subset is relevant for a chosen source or sink. An-
alyzing the function in terms of its use of a speciﬁc source
or sink therefore requires unrelated checks to be discarded
automatically. However, this selection of relevant checks is

Figure 4: Dependency graph for function foo. Nodes
reachable from memcpy are shaded, where the taint
propagation stops at function boundaries. Isolated
nodes are omitted.

not trivial, as it requires the ﬂow of data between variables
to be taken into account.

To address this problem, Chucky performs lightweight
tainting of the code of the target function and all its neigh-
bors for each source or sink in two stages:

1. Dependency modelling. A directed graph is cre-
ated to model the dependencies between variables. The
nodes of the graph correspond to the identiﬁers used in
the function (i.e., sources and sinks), while the edges
reﬂect assignments between identiﬁers. Edges are also
added if identiﬁers are parameters of functions.

2. Taint propagation. Starting from the identiﬁer cor-
responding to a selected source or sink, the graph is
traversed in top-down as well as bottom-up direction to
discover all related identiﬁers. The propagation stops
at function boundaries, that is, edges from parameters
to functions are not followed.

An example of a dependency graph for the function foo
from Figure 3 is shown in Figure 4. The identiﬁer memcpy has
been picked as source/sink for the analysis. Three identi-
ﬁers are tainted (gray shading) including directly connected
nodes, such as len and buf, as well as indirectly linked nodes,
such as strlen.

Once the tainted identiﬁers for a function are known, we
examine its conditions (see Section 3.1) and remove a con-
dition if it does not reference at least one of the tainted
identiﬁers. We thus restrict the conditions analyzed in sub-
sequent steps only to those conditions related to the source
or sink under examination.
3.4 Embedding of Functions

In the last two steps, we leverage the information dis-
tributed across the function neighborhood to determine typ-
ical checks and deviations thereof using anomaly detection.
Similar to the technique for neighborhood discovery (Sec-
tion 3.2), this method for anomaly detection operates on
numerical vectors and thus the functions need to be again
embedded in a suitable vector space. We implement this
embedding as follows.

useris_privilegedstrstrlenlenbufmemcpyarmallocnprocessargargargargargassignargargargargassign502Figure 5: Schematic depiction of embedding. Conditions related to the speciﬁed source/sink are extracted
from the abstract syntax tree and mapped to a vector space using their expressions.

Upon completion of the previous step, conditions related
to the source or sink s are known for each function. We pro-
ceed to extract all expressions (including sub-expressions)
contained in each of these conditions. The expressions then
undergo a simple normalization to account for small syntac-
tical diﬀerences in the formulation of checks. In detail, the
normalization consists of two transformations.

to determine checks that are present in most neighbors but
are missing in the examined function. This enables Chucky
to pinpoint the exact missing check and report its absence
to the analyst. Moreover, an anomaly score can be calcu-
lated, allowing particularly interesting code to be returned
to the analyst for immediate inspection. Mathematically,
this process is implemented as follows.

1. Removal of negations. Since Chucky does not ac-
count for the actions taken upon evaluation of an ex-
pression, negations are removed as the ﬁrst step of
normalization. For the same reason, relational oper-
ators are replaced by the symbol $CMP. Furthermore,
numbers are replaced by $NUM since for example, the
expression x < 10 is equivalent to x < 1 + 9.

2. Normalization of arguments and return values
If the source or sink of interest is a function, its return
value is renamed to $RET while any variables directly
inﬂuencing its arguments are renamed to $ARG. This
allows return values and arguments of functions to be
compared regardless of the names of variables chosen.

Finally, the functions can be embedded in a vector space
by applying a mapping ϕ, which transforms functions into
numerical vectors. To represent each function by all normal-
ized expressions contained in its conditions, we deﬁne E to
be the set of all normalized expressions and ϕ as

, ϕ(x) (cid:55)→(cid:0)I(x, e)(cid:1)

e∈E

where I is an indicator function deﬁned as

ϕ : X → R|E|

(cid:40)

I(x, e) =

1 if x contains e in a condition
0 otherwise.

Note that while the total number of expressions contained
in the code base may be very large, the vast majority of
functions contains only few of these expressions. In practice,
this allows for memory eﬃcient implementations using hash
maps or sorted arrays [27].

Figure 5 illustrates this process for the function foo from
Figure 1. The single condition related to the sink memcpy is
ﬁrst determined and all sub-expressions are extracted and
normalized. Finally, the vectorial representation is obtained
by applying the mapping ϕ.
3.5 Anomaly Detection

Based on the embedding of functions, we are ﬁnally able
to determine missing checks geometrically. To this end, a
model of normality quantifying the importance of each ex-
pression contained in a check is derived from the embedded
neighbors. Measuring the distance to this model allows us

For each source or sink s used in a function x under
consideration, a model of normality is calculated based on
its neighbors N . Recalling that in the previous step, each
neighbor is mapped to a vector in the space spanned by the
expressions contained in its conditions, a natural choice for
this model is the center of mass of all embedded neighbor
vectors. The model µ ∈ R|E| is thus computed over all k
embedded neighbour functions as

(cid:88)

n∈N

µ =

1
|N|

ϕ(n)

Each coordinate of µ represents the fraction of the neighbors,
that contain a particular Boolean expression in its conditions
as a number between 0 and 1. For example, a score of 0.9
in the coordinate associated with the expression $RET $CMP
$NUM indicates that 90% the function’s neighbors check the
return value against a literal number while only 10% do not.
Identifying missing checks is now easy as it merely requires
assessing the diﬀerence between the embedded function vec-
tor ϕ(x) and the model of normality µ. To this end, we
calculate the distance vector d ∈ R|E| given by

d = µ − ϕ(x).

Each coordinate of the vector d is a value between -1 and
+1. Positive numbers denote Boolean expressions that are
checked by a fraction of neighbors but missing in the func-
tion under consideration x, i.e., missing checks. In contrast,
negative numbers denote expressions checked in x but not
present in any of its neighbors.

Finally, from the distance vector we compute an anomaly
score suitable to rank functions according to the likelihood
that it is omitting a check. We deﬁne this anomaly score for
a function x as

(cid:0)µe − I(x, e)(cid:1)

f (x) = ||µ − ϕ(x)||∞ = max
e∈E

that is, the anomaly score is given by the largest coeﬃcient of
the vector d. Recalling that positive numbers denote missing
expressions, the rationale behind this choice is to rank func-
tions high if many neighbors contain an expression, which
is not present in the function of interest. Furthermore, the
maximum norm is chosen, because functions deviating from
its neighbors in a single concrete expression—while contain-
ing all other expressions—are usually more interesting than
functions diﬀering from their neighbors entirely.

len >= BUF_SIZE>=fooBUF_SIZElen!is_privileged (user)! ar!aris_privileged (user)!user$ARG $CMP BUF_SIZEBUF_SIZE$ARG0BBBB@···111···1CCCCA$ARG$CMPBUFSIZE$ARGBUFSIZE5034. EMPIRICAL EVALUATION

We proceed to evaluate our method on the source code
of ﬁve popular software projects: Firefox, Linux, LibPNG,
LibTIFF and Pidgin.
In particular, we are interested in
Chucky’s detection performance when tasked to identify
missing checks as well as its practical value in real source
code audits. We begin by conducting a controlled experi-
ment (Section 4.1) involving artiﬁcial as well as real missing
checks leading to vulnerabilities discovered in the past. Fi-
nally, we study our method’s ability to assist in the discov-
ery of previously unknown vulnerabilities by providing case
studies (Section 4.2).
4.1 Missing Check Detection

To evaluate the detection performance of Chucky, the
security history of each of the ﬁve projects is reviewed. In
each code base, we uncover cases where a security check
is present in many functions but omitted in others, thus
causing vulnerabilities.

In all but one case, these vulnerabilities are critical, al-
lowing an attacker to fully compromise the software. Addi-
tionally, we take care to choose samples involving diﬀerent
cases of vulnerabilities, e.g., missing checks for security logic,
function arguments, function return values. In the following
we provide a detailed description of our dataset. Table 1
summarizes this information.

• Firefox. The JavaScript engine of the popular Web
browser Firefox (version 4.0) contains 5,649 functions
and 372,450 lines of code. A failure to check the num-
ber of arguments passed to native code implementa-
tions of JavaScript functions (i.e., the parameter argc)
leads to a use-after-free vulnerability (CVE-2010-3183).
Ten utility functions implementing array operations
perform the same security check to avoid this.

• Linux. The ﬁlesystem code of the Linux operating
system kernel (version 2.6.34.13) contains 19,178 func-
tions and 955,943 lines of code. A missing check before
setting an ACL allows to bypass ﬁle system permis-
sions (CVE-2010-2071). The check involves the pa-
rameter dentry and its structure ﬁeld dentry->d_inode.
Eight functions of diﬀerent ﬁlesystems implement a
corresponding security check correctly.

• LibPNG. The image processing library LibPNG (ver-
sion 1.2.44) contains 437 functions and 40,255 lines of
code. A missing check of the PNG chunk’s size (i.e.,
the parameter length) results in a memory corruption
(CVE-2011-2692). Nineteen functions processing PNG
chunks perform the same critical check to avoid this.
• LibTIFF. The image processing library LibTIFF (ver-
sion 3.9.4) contains 609 functions and 33,335 lines of
code. Missing checks of the length ﬁeld of TIFF di-
rectory entries (i.e., the parameter dir and its ﬁeld
dir->tdir_count) lead to two independent stack-based
buﬀer-overﬂows (CVE-2006-3459 and CVE-2010-2067).
Nine functions processing TIFF directory entries per-
form a security check to avoid this problem.

• Pidgin. The instant messaging library of the popular
instant messenger Pidgin (version 2.7.3) contains 7,390
functions and 332,762 lines of code. A missing check of

(a) Averaged ROC curve

(b) AUC (Minimal Detection Rate)

Figure 6: Detection performance for the ﬁve
projects with neighborhoods of diﬀerent size.

the return value of the internal base64-decoding rou-
tine purple_base64_decode leads to a denial-of-service
vulnerability (CVE-2010-3711). Eighteen functions pars-
ing network data in Pidgin perform a corresponding
security check correctly to avoid this.

For each code base we begin our evaluation by patching
the known vulnerabilities. We then proceed to create sev-
eral experiments in a round-robin fashion for each security
check, where we remove the check from one function while
leaving all other functions untouched. Vulnerabilities are
thus deliberately introduced in order to allow us to measure
our methods ability to identify them.

Chucky is then employed to rank functions by analyzing
their use of the source or sink requiring validation. Note
that while only those functions known to be vulnerable or
non-vulnerable are included in the ranking, the entire code
base is considered for neighborhood selection. The experi-
ment thus reﬂects the situation encountered in practice and
performs no simpliﬁcations.

These experiments allow us to assess our method’s ability
to rediscover those vulnerabilities reported to the projects
in the past but go one step further by exploring Chucky’s
capability to discover artiﬁcially introduced vulnerabilities.
In total, the dataset allows us to perform 64 experiments
independently (see last column of Table 1).

0.00.20.40.60.81.0FalsePositiveRate0.00.20.40.60.81.0TruePositiveRatek=5k=10k=20k=50020406080100NumberofNeighbors(k)0.00.20.40.60.81.0MinimalDetectionRateFirefoxLinuxlibPNGlibTIFFPidginAverage504Project
Firefox 4.0
Linux 2.6.34.13 Filesystem code
LibPNG 1.2.44 Entire library
Entire library
LibTIFF 3.9.4
Pidgin 2.7.3
Messaging

Component
Vulnerability
JavaScript engine CVE-2010-3183
CVE-2010-2071
CVE-2011-2692
CVE-2010-2067
CVE-2010-3711

LOC # functions # with check
10
8
19
9
18

5649
19178
473
609
7390

372450
955943
40255
33335
332762

Table 1: Overview of our dataset. For each project the missing-check vulnerability, the lines of code (LOC),
the number of functions and the number of functions involving the check is listed.

Figure 6(a) shows the ROC curves of our method averaged
over all projects for neigborhoods of diﬀerent size k, where
the detection rate is plotted against the false-positive rate
for diﬀerent thresholds. For low values of k, such as k =
5, already 50% of the missing checks can be detected with
few false positives. With increasing k, Chucky is able to
identify more missing conditions, where ﬁnally almost all
missing checks in the ﬁve code bases are detected with k =
20 at a detection rate of 96%.

We further investigate the eﬀect of the number of neigh-
bors on the detection performance by generating individual
ROC curves for values of k between 1 and 100 using the Area
Under Curve (AUC) as a performance measure [2]. Fig-
ure 6(b) shows the results of this experiment. For k = 25
we attain perfect results across all code bases allowing all
vulnerabilities to be detected with no false positives. While
we do not assume that an optimal choice of k exists for ar-
bitrary code bases, for the projects under consideration, the
average number of functions operating in a similar context
thus seems to be around 25. For all further evaluations we
thus ﬁx k to 25.

Moreover, we can observe that for those code bases where
APIs have been insecurely used (Firefox, LibPNG, LibTIFF
and Pidgin), the maximum performance is achieved when k
is chosen above a certain threshold. This conﬁrms that in
these cases, the majority of functions employing the source
or sink perform the security check, thus making neighbor-
hood discovery rather dispensable.
In the case of Linux,
where missing checks in security logic need to be identiﬁed,
the performance drops when k becomes too large. We ex-
amine this case in detail and ﬁnd that the source dentry is
used many times across the code base while a security check
is only required in few cases. Neighborhood discovery thus
becomes essential in order to create a model of normality
only from functions that operate in a similar context.

This quantitative evaluation demonstrates the potential of
Chucky. All of the considered vulnerabilities are success-
fully identiﬁed by our method and would have been spot-
ted if Chucky had been applied to the respective software
projects in the past.
4.2 Discovery of Vulnerabilities

First and foremost, Chucky is designed to assist an an-
alyst in day-to-day auditing. In the following, we therefore
study our method’s ability to assist in the discovery of previ-
ously unknown vulnerabilities in practice. In particular, we
describe how 7 previously unknown vulnerabilities have been
discovered by applying Chucky on two real-world projects,
namely, LibTIFF and Pidgin. We have conducted further
studies uncovering 5 more unknown vulnerabilities. For the
sake of brevity however, we omit these and details of the
vulnerabilities here.

To ensure that all vulnerabilities found by Chucky are
previously unknown, we update the code of both software
projects to the most recent version. At the time of writing,
these are version 4.0.3 for LibTIFF and 2.10.6 for Pidgin.
4.2.1 LibTIFF Case Study
In the ﬁrst case study, we employ Chucky to uncover
vulnerabilities in LibTIFF, an image processing library and
suite of tools for the Tagged Image File Format (TIFF). Im-
age processing libraries are a popular target for attackers as
parsing images securely is a challenging task.
In particu-
lar, integer overﬂow vulnerabilities when dealing with image
dimensions (i.e., image width and height) are a common
problem. We therefore use Chucky to rank all functions of
the code base according to anomalous use of any parameters
or local variables named width, height, w or h.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

static int
tiffcvt(TIFF* in, TIFF* out)
{

uint32 width, height; /* image width & height */
uint16 shortv;
float floatv;
char *stringv;
uint32 longv;
uint16 v[1];

TIFFGetField(in, TIFFTAG_IMAGEWIDTH, &width);
TIFFGetField(in, TIFFTAG_IMAGELENGTH, &height);

CopyField(TIFFTAG_SUBFILETYPE, longv);
[...]
if( process_by_block && TIFFIsTiled( in ) )

return( cvt_by_tile( in, out ) );

else if( process_by_block )

return( cvt_by_strip( in, out ) );

else

return( cvt_whole_image( in, out ) );

}

Figure 7: Missing checks of the variables width and
height in the function tiffcvt.

From the 74 functions dealing with these variables, Chucky

reports only a single function with an anomaly score of
100%. We examine the reported function tiffcvt (Figure 7)
to ﬁnd that the width and height ﬁelds are obtained directly
from the image ﬁle at lines 11 and 12 and are not checked.
Chucky reports that all neighbors of the function perform a
check on the variable height while 79% additionally perform
a check on the variable width.

Indeed, this missing check leads to an integer overﬂow
when calling the function cvt_by_strip shown in Figure 8,
for which 50% of its neighbors suggest an additional check
for the width ﬁeld. Triggering this overﬂow, a buﬀer smaller
than expected can be allocated at line 11, resulting in a
heap-based buﬀer overﬂow when calling TIFFReadRGBAStrip

505Score
0.92
0.88,
0.88
0.88
0.84
0.84
0.80
0.80
0.76
0.76

Source File
tools/thumbnail.c
tools/rgb2ycbcr.c
tools/rgb2ycbcr.c
tools/ycbcr.c
tools/pal2rgb.c
tools/tiﬀ2bw.c
libtiﬀ/tif print.c
tools/raw2tiﬀ.c
tools/sgisv.c
tools/sgisv.c

Function Name
initScale
cvtRaster
setupLuma
setupLuma
main
main
TIFFPrintDirectory
guessSize
svRGBContig
svRGBSeparate

Table 2: Top ten functions returned for the sink
TIFFmalloc. All 10 functions fail to check the re-
turn value of the sink. Vulnerabilities are indicated
by dark shading.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

static int
cvt_by_strip( TIFF *in, TIFF *out )

{

}

uint32* raster; /* retrieve RGBA image */
uint32 width, height; /* image width & height */
[...]
TIFFGetField(in, TIFFTAG_IMAGEWIDTH, &width);
TIFFGetField(in, TIFFTAG_IMAGELENGTH, &height);
/* Allocate strip buffer */
raster = (uint32*)

_TIFFmalloc(width*rowsperstrip*sizeof (uint32));

if (raster == 0) {

TIFFError(TIFFFileName(in),

"No space for raster buffer");

return (0);

} [...]
for(row=0;ok&&row<height;row+=rowsperstrip )

{ [...]

/* Read the strip into an RGBA array */
if (!TIFFReadRGBAStrip(in,row,raster)) {

[...]
} [...]

}

_TIFFfree( raster ); [...]
return ok;

Integer overﬂow in the

Figure 8:
function
cvt_by_strip caused by the missing check in the caller
tiffcvt. In eﬀect, a buﬀer overﬂow results when call-
ing TIFFReadRGBAStrip.

on line 21.Chucky thus leads us almost directly to a possibly
exploitable memory corruption vulnerability.

In a second example, our method is used to uncover NULL
pointer dereferenciations. To this end, all functions of the
code base are analyzed for missing or unusual checks for
_TIFFMalloc, a simple wrapper around malloc.

In total 237 functions call _TIFFMalloc. Table 2 shows the
top ten of these functions ranked by our method according
to anomalous use of _TIFFMalloc. In each of the ten cases,
Chucky reports that a check for the return value (expres-
sion $RET) is performed by the vast majority of neighbors,
while it is missing in the identiﬁed functions. Note, that
at no point, the checks required for the use of _TIFFMalloc
have been speciﬁed explicitly; instead Chucky leverages the
information distributed across the code base to determine
these security checks automatically. We conﬁrm the missing
checks in all ten cases. In four of these, the omitted check
allows attackers to cause a denial-of-service condition by pro-

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

cvtRaster(TIFF* tif, uint32* raster,

uint32 width, uint32 height)

{

}

uint32 y;
tstrip_t strip = 0;
tsize_t cc, acc;
unsigned char* buf;
uint32 rwidth = roundup(width, horizSubSampling);
uint32 rheight = roundup(height, vertSubSampling);
uint32 nrows = (rowsperstrip > rheight ?
rheight : rowsperstrip);

uint32 rnrows = roundup(nrows,vertSubSampling);

cc = rnrows*rwidth + 2*((rnrows*rwidth) /
(horizSubSampling*vertSubSampling));

buf = (unsigned char*)_TIFFmalloc(cc);
// FIXME unchecked malloc
for (y = height; (int32) y > 0; y -= nrows){

uint32 nr = (y > nrows ? nrows : y);
cvtStrip(buf, raster + (y-1)*width, nr, width);
nr = roundup(nr, vertSubSampling);
acc = nr*rwidth + 2*((nr*rwidth)/

(horizSubSampling*vertSubSampling));

if(!TIFFWriteEncodedStrip(tif,strip++,

buf,acc)){

_TIFFfree(buf); return (0);

}

}
_TIFFfree(buf); return (1);

Figure 9: A missing check detected in the function
cvtRaster of the library LibTIFF.

viding speciﬁcally crafted input, whereas in other cases, only
a software defect is identiﬁed.

As an example,

let us consider the function cvtRaster
shown in Figure 9. This function provides an illustrative
example because the programmer conﬁrms that the return
value of _TIFFMalloc requires validation in the comment on
line 17. In this particular case, the method reports that 85%
of the function’s neighbors validate the return value and 40%
compare it to the constant NULL. No other Boolean expres-
sion is found to consistently occur across all neighbors in
more than 30% of the cases. Furthermore, from all symbols
used in the function, the deviation in its use of _TIFFMalloc
is most pronounced. The function is thus among the top
15% in the global ranking and thus Chucky points the ana-
lyst to vulnerability even if an interest in _TIFFMalloc is not
expressed explicitly.

4.2.2 Pidgin Case Study
In the second case study, we employ Chucky to uncover
two denial-of-service vulnerabilities in Pidgin’s implementa-
tion of the Microsoft Instant Messaging Protocol. In partic-
ular, we ﬁnd that a vulnerability exists allowing users to re-
motely crash the instant messengers without requiring coop-
eration from the victims side. As starting point for our anal-
ysis, we review the C standard library for commonly used
functions, which crash upon reception of a NULL pointer
as an argument. As an example, the sinks atoi and strchr
are chosen and Chucky is employed to rank all functions
according to missing or faulty checks for these sinks.

Table 3 shows all functions with an anomaly score of over
50%, that is, cases where more than half of the neighbors
suggest a check to be introduced. Furthermore, in all cases,
Chucky indicates that the arguments passed to the sinks
need to be checked. With this information, we are able to

506Score
0.84
0.76
0.72
0.72
0.64
0.64
0.60
0.60
0.60
0.60
0.56

Function Name
msn normalize
msn oim report to user
msn parse oim xml
msn import html

Source File
msn.c
oim.c
oim.c
msnutils.c
switchboard.c msn switchboard add user
slpcall.c
msnutils.c
contact.c
contact.c
command.c
msg.c

msn slp sip recv
msn parse socket
msn parse addr... contacts
msn parse each member
msn command from string
msn message parse payload

Table 3: Top ten functions returned for the sinks
atoi and strchr in Pidgin’s implementation of the Mi-
crosoft Instant Messenger Protocol. Vulnerabilities
are indicated by dark shading.

discover two cases among the top ten missing checks allowing
attackers to remotely crash Pidgin.

First Example.

For the function msn_parse_oim_xml shown in Figure 10,
Chucky reports that 72% of its neighbors validate argu-
ments passed to atoi while this function does not. Indeed,
this is the case on line 19 where the variable unread is passed
to atoi unchecked. Moreover, Chucky reports that 75%
of the function neighbors check the return value of xmln-
ode_get_data while this function does not. Combined, these
two missing checks allow Pidgin to be crashed by sending
an XML-message with an empty “E/UI” node. This causes
xmlnode_get_data to return a NULL pointer on line 13, which
is then propagated to atoi resulting in a crash.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

static void
msn_parse_oim_xml(MsnOim *oim, xmlnode *node)
{

xmlnode *mNode;
xmlnode *iu_node;
MsnSession *session = oim->session;
[...]
iu_node = xmlnode_get_child(node, "E/IU");

{

char *unread = xmlnode_get_data(iu_node);
const char *passports[2] =

{ msn_user_get_passport(session->user) };

const char *urls[2] =

{ session->passport_info.mail_url };

int count = atoi(unread);

/* XXX/khc: pretty sure this is wrong */
if (count > 0)

purple_notify_emails(session->account->gc,

count, FALSE, NULL,
NULL, passports,
urls, NULL, NULL);

g_free(unread);

}

[...]

}

Second Example.

For the function msn_message_parse_payload shown in Fig-
ure 11, Chucky reports a failure to check the argument
passed to strchr with an anomaly score of 56%. The vul-
nerable call can be seen on line 15 and can be triggered
by sending a message containing the string “Content-Type”
immediately followed by two successive carriage return line
feed sequences. This causes the variable value to be set to
NULL on line 10. This value propagates to strchr on line
15 causing the crash of Pidgin. This vulnerability is partic-
ularly interesting as it can be triggered by other users of the
MSN service.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

void
msn_message_parse_payload(MsnMessage *msg, [...])
{

[...]
for (cur = elems; *cur != NULL; cur++)

{

}

const char *key, *value; [...]
tokens = g_strsplit(*cur, ": ", 2);
key = tokens[0];
value = tokens[1];
[...]
if (!strcmp(key, "Content-Type"))

{

char *charset, *c;
if ((c = strchr(value, ’;’)) != NULL)

{

}

[...]

msn_message_set_content_type(msg, value);

}

else

{

}

msn_message_set_attr(msg, key, value);

g_strfreev(tokens);

g_strfreev(elems);
/* Proceed to the end of the "\r\n\r\n" */
tmp = end + strlen(body_dem);
[...]
g_free(tmp_base);

}

Figure 11: Missing check in the function msn_message
_parse_payload of the instant messenger Pidgin.

Similar to other methods for the discovery of security
ﬂaws, Chucky cannot overcome the inherent limitations of
vulnerability identiﬁcation. While our method is able to
expose missing security checks eﬀectively, it cannot verify
whether these truly lead to vulnerabilities in practice. This
limitation, however, can be alleviated by the analyst, as he
can guide the search for vulnerabilities by only inspecting
security-critical sources and sinks, such as common memory,
network and parsing functions. As our experiments demon-
strate, this often enables Chucky to pinpoint missing checks
related to vulnerabilities with little manual eﬀort.

In contrast to other methods, Chucky does not require
external information or code annotations to identify missing
checks. The method is capable of operating on the code
base of a software project alone. This advantage comes at
price: our approach is based on the assumption that the
majority of checks in a code base are correct and missing
checks are rare. While this assumption holds true for mature
software projects, it is not necessary satisﬁed by software at

if(iu_node != NULL &&

purple_account_get_check_mail(session->account))

5. LIMITATIONS

Figure 10: Missing check in the function msn_parse
_oim_xml of the instant messenger Pidgin.

507an early stage of development. Consequently, Chucky is
better suited for ﬁnding vulnerabilities in stable code.

It is also important to note that Chucky makes no at-

tempts to evaluate expressions. Semantically equivalent checks
thus cannot be detected, which may lead to false positives in
practice. Moreover, our method is only able to detect checks
if they are missing entirely and cannot detect checks per-
formed too late. Combining our method with existing tech-
niques from data ﬂow analysis and symbolic execution there-
fore seems to be an interesting direction for future work.

Finally, there exist many types of vulnerabilities that have
no relation to missing checks and thus cannot be exposed by
Chucky. Nonetheless, it is a common practice of developers
to add checks before potential vulnerabilities and security-
critical code, for example for protecting buﬀers, limiting ac-
cess to resources or changing the program ﬂow. All these
checks can be exposed by Chucky and hence our method
addresses a wide range of possible security ﬂaws.
6. RELATED WORK

The theory and practice of ﬁnding vulnerabilities in soft-
ware is a classic ﬁeld of computer security. Due to their
generic nature, missing-check vulnerabilities border on a
wide range of previous research. In the following, we point
out relations to this work and related approaches.

Static Code Analysis.

In practice, checking tools such as Microsoft PREfast [15]
or PScan [5] are used to statically ﬁnd vulnerabilities in
source code. These tools possess built-in information about
correct API usage and common programming mistakes, which
severely limits the kind of vulnerabilities these tools can
detect. An alternative route is taken by scanners such as
Splint [7], which allow code annotations to be supplied by
analysts. However, creating these annotations and rules re-
garding API usage is both time consuming and challenging
as it requires an intimate understanding of both internal and
external APIs of a target program.

Several approaches seize the idea of inspecting the tempo-
ral properties of API usage [e.g., 6, 16, 38] and attempt to
provide this information across projects [e.g., 10, 43]. Such
properties would, for instance, indicate that a lock function
call usually is followed by a call to the unlock function. Soft-
ware defects can thus be detected by identifying anomalies,
which do not comply with the derived set of rules. Con-
ditions, however, are not analyzed and therefore, these ap-
proaches are not suited for ﬁnding missing checks.

Tan et al. [34] analyze API call sequences to identify nec-
essary security checks whereas the mapping between a spe-
ciﬁc check and the event that is required to be checked is
speciﬁed in advance. Similarly, Livshits et al. [18] focus on
inferring information ﬂow speciﬁcations by modelling prop-
agation graphs. In contrast, Chucky attempts to ﬁnd miss-
ing checks in a more general scope and without additional
speciﬁcation of the sensitive code regions or functions.

Other work goes one step further and makes use of ad-
ditional auxiliary information like software revision histo-
ries [19, 40] or diﬀerent API implementations [32]. Similar
to Chucky, Son et al. [31] intend not to make use of anno-
tations or any external speciﬁcations. Instead they rely on
software engineering patterns commonly used in web appli-
cations and SQL queries that alter the database as security-
sensitive events. Therefore, this approach is tightly bound

to web applications while Chucky can be applied in any
programming environment if a suitable parser is available.

In many approaches, infrequent but correct patterns might
cause false positives due to a biased notion of normality.
Thummalapenta and Xie [35] address this by introducing al-
ternative patterns. We discussed this limitation with respect
to Chucky in Section 5. Another more general method
coined as vulnerability extrapolation [41, 42] learns from
known security ﬂaws and ﬁnds locations that might exhibit
a similar vulnerability. We build on this method for the
neighborhood discovery described in Section 3.2.

Taint Analysis and Symbolic Execution.

Taint analysis or taint tracking is a method for perform-
ing information ﬂow analysis. Data of interest is “tainted”
and tracked from a source through the system to a speciﬁed
sink. In principle one diﬀerentiates between static and dy-
namic taint analysis. Dynamic taint tracking has been used
for the discovery of vulnerabilities [e.g., 23, 37]. However,
since Chucky is strictly operating on source code, we do
not discuss dynamic approaches at this point. Static taint
tracking has been eﬀectively used for detecting vulnerabili-
ties such as format string vulnerabilities in C programs [30]
or SQL injections and cross-site scripting [13, 17].

Nevertheless, taint analysis implies some limitations that
come down to its passive view on the data ﬂow. Symbolic ex-
ecution can overcome these by actively exploring the code’s
state space and execution paths [1, 4, 9, 37]. Due to this
state exploration, symbolic execution becomes intractable
without heuristics to reduce the number of branches that
need to be analyzed. As a result it hardly can be used for
code auditing in practice [11].

7. CONCLUSIONS

Vulnerabilities in software are a persistent problem and
one of the root causes of many security incidents. Discover-
ing security ﬂaws is a challenging and often daunting task,
as automatic approaches are inherently limited in spotting
vulnerable code. As a remedy, we introduce Chucky in
this paper, a method that can automatically detect missing
checks in software and thereby help to accelerate the manual
auditing of source code. Instead of struggling with the lim-
its of automatic approaches, our method aims at assisting a
human analyst by providing information about missing secu-
rity checks and potential ﬁxes. Our evaluation demonstrates
the potential of this approach, since we are able to uncover
12 previously unknown vulnerabilities in popular software
projects among the ﬁrst missing checks.

Finally, Chucky can interface with many other techniques
for ﬁnding vulnerabilities. For example, exposed missing
checks might be further analyzed using techniques for fuzzing
or symbolic execution. These techniques could allow to nar-
row down the actual consequences of a missing check and
might help to rank detected ﬂaws according to their sever-
ity. Moreover, we currently plan to integrate Chucky in
a visual development environment and analyze its capabil-
ities to expose missing security checks directly during the
development of software.

Acknowledgments
The authors acknowledge funding from BMBF under the
project PROSEC (FKZ 01BY1145).

508References
[1] T. Avgerinos, S. K. Cha, B. L. T. Hao, and D. Brum-
ley. AEG: Automatic Exploit Generation. In Proc. of
Network and Distributed System Security Symposium
(NDSS), 2011.

[2] A. Bradley. The use of the area under the ROC curve in
the evaluation of machine learning algorithms. Pattern
Recognition, 30(7):1145–1159, 1997.

[3] B. Chess and M. Gerschefske. Rough auditing tool for
security. Google Code, http://code.google.com/p/
rough-auditing-tool-for-security/, visited Febru-
ary, 2013.

[4] M. Cova, V. Felmetsger, G. Banks, and G. Vigna. Static
detection of vulnerabilities in x86 executables. In Proc.
of Annual Computer Security Applications Conference
(ACSAC), pages 269–278, 2006.

[5] A. DeKok. Pscan: A limited problem scanner for
c source ﬁles. http://deployingradius.com/pscan/,
visited February, 2013.

[6] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and
B. Chelf. Bugs as deviant behavior: A general approach
to inferring errors in systems code. In Proc. of ACM
Symposium on Operating Systems Principles (SOSP),
pages 57–72, 2001.

[7] D. Evans and D. Larochelle. Improving security using
extensible lightweight static analysis. IEEE Software,
19(1):42–51, 2002.

[8] N. Falliere, L. O. Murchu, , and E. Chien. W32.stuxnet

dossier. Symantec Corporation, 2011.

[9] P. Godefroid, M. Y. Levin, and D. Molnar. SAGE:
whitebox fuzzing for security testing. Communications
of the ACM, 55(3):40–44, 2012.

[10] N. Gruska, A. Wasylkowski, and A. Zeller. Learning
from 6,000 projects: lightweight cross-project anomaly
detection. In Proc. of the International Symposium on
Software Testing and Analysis (ISSTA), pages 119–130,
2010.

[11] S. Heelan. Vulnerability detection systems: Think cy-
borg, not robot. IEEE Security & Privacy, 9(3):74–77,
2011.

[12] J. Hopcroft and J. Motwani, R. Ullmann.

Introduc-
tion to Automata Theory, Languages, and Computa-
tion. Addison-Wesley, 2 edition, 2001.

[13] N. Jovanovic, C. Kruegel, and E. Kirda. Pixy: A static
analysis tool for detecting web application vulnerabil-
ities.
In Proc. of IEEE Symposium on Security and
Privacy, pages 6–263, 2006.

[14] J. A. Kupsch and B. P. Miller. Manual vs. auto-
mated vulnerability assessment: A case study. In Proc.
of Workshop on Managing Insider Security Threats
(MIST), pages 83–97, 2009.

[15] J. R. Larus, T. Ball, M. Das, R. DeLine, M. F¨ahndrich,
J. Pincus, S. K. Rajamani, and R. Venkatapathy. Right-
ing software. IEEE Software, 21(3):92–100, 2004.

[16] Z. Li and Y. Zhou. PR-Miner: automatically extract-
ing implicit programming rules and detecting violations
in large software code. In Proc. of European Software
Engineering Conference (ESEC), pages 306–315, 2005.

[18] B. Livshits, A. V. Nori, S. K. Rajamani, and A. Baner-
jee. Merlin: speciﬁcation inference for explicit infor-
mation ﬂow problems. In Proc. of ACM SIGPLAN In-
ternational Conference on Programming Languages De-
sign and Implementation (PLDI), 2009.

[19] B. Livshits and T. Zimmermann. Dynamine: ﬁnding
common error patterns by mining software revision his-
tories. In Proc. of European Software Engineering Con-
ference (ESEC), pages 296–305, 2005.

[20] L. Moonen. Generating robust parsers using island
grammars. In Proc. of Working Conference on Reverse
Engineering (WCRE), pages 13–22, 2001.

[21] H. Moore. Security ﬂaws in universal plug and play:

Unplug. don’t play. Technical report, Rapid 7, 2013.

[22] C. Mulliner, N. Golde, and J.-P. Seifert. Sms of death:
From analyzing to attacking mobile phones on a large
scale. In Proc. of USENIX Security Symposium, 2011.

[23] J. Newsome and D. Song. Dynamic taint analysis for
automatic detection, analysis, and signature generation
of exploits on commodity software. In Proc. of Network
and Distributed System Security Symposium (NDSS),
2005.

[24] J. W. Oh. Recent Java exploitation trends and malware.

Presentation at Black Hat Las Vegas, 2012.

[25] T. Parr and R. Quong. ANTLR: A predicated-LL(k)
parser generator. Software Practice and Experience,
25:789–810, 1995.

[26] G. Portokalidis, A. Slowinska, and H. Bos. Argos: an
emulator for ﬁngerprinting zero-day attacks for adver-
tised honeypots with automatic signature generation.
ACM SIGOPS Operating Systems Review, 40(4):15–27,
Apr. 2006.

[27] K. Rieck and P. Laskov. Linear-time computation of
similarity measures for sequential data. Journal of Ma-
chine Learning Research (JMLR), 9(Jan):23–48, Jan.
2008.

[28] G. Salton and M. J. McGill. Introduction to Modern

Information Retrieval. McGraw-Hill, 1986.

[29] E. Schwartz, T. Avgerinos, and D. Brumley. All you
ever wanted to know about dynamic taint analysis and
forward symbolic execution (but might have been afraid
to ask). In Proc. of IEEE Symposium on Security and
Privacy, pages 317–331, 2010.

[30] U. Shankar, K. Talwar, J. S. Foster, and D. Wagner.
Detecting format string vulnerabilities with type qual-
iﬁers. In Proc. of USENIX Security Symposium, pages
201–218, 2001.

[31] S. Son, K. S. McKinley, and V. Shmatikov. Rolecast:
ﬁnding missing security checks when you do not know
what checks are. In Proc. of ACM International Con-
ference on Object Oriented Programming Systems Lan-
guages and Applications (SPLASH), 2011.

[32] V. Srivastava, M. D. Bond, K. S. Mckinley, and
V. Shmatikov. A security policy oracle: Detecting se-
curity holes using multiple API implementations.
In
Proc. of ACM SIGPLAN International Conference on
Programming Languages Design and Implementation
(PLDI), 2011.

[17] B. Livshits and M. S. Lam. Finding security vulnerabil-
ities in java applications with static analysis. In Proc.
of USENIX Security Symposium, 2005.

[33] M. Sutton, A. Greene, and P. Amini. Fuzzing: Brute
Force Vulnerability Discovery. Addison-Wesley Profes-
sional, 2007.

509[34] L. Tan, X. Zhang, X. Ma, W. Xiong, and Y. Zhou.
Autoises: automatically inferring security speciﬁcations
and detecting violations. In Proc. of USENIX Security
Symposium, 2008.

[35] S. Thummalapenta and T. Xie. Alattin: Mining al-
ternative patterns for detecting neglected conditions.
In Proc. of the International Conference on Automated
Software Engineering (ASE), pages 283–294, 2009.

[36] J. Viega, J. Bloch, Y. Kohno, and G. McGraw. ITS4:
A static vulnerability scanner for C and C++ code. In
Proc. of Annual Computer Security Applications Con-
ference (ACSAC), pages 257–267, 2000.

[37] T. Wang, T. Wei, Z. Lin, and W. Zou. IntScope: Auto-
matically detecting integer overﬂow vulnerability in x86
binary using symbolic execution. In Proc. of Network
and Distributed System Security Symposium (NDSS),
2009.

[38] A. Wasylkowski, A. Zeller, and C. Lindig. Detecting
object usage anomalies. In Proc. of European Software
Engineering Conference (ESEC), pages 35–44, 2007.

[39] D. A. Wheeler. Flawﬁnder. http://www.dwheeler.

com/flawfinder/, visited February, 2013.

[40] C. C. Williams and J. K. Hollingsworth. Automatic
mining of source code repositories to improve bug ﬁnd-
ing techniques. IEEE Transactions on Software Engi-
neering, 31:466–480, 2005.

[41] F. Yamaguchi, F. Lindner, and K. Rieck. Vulnerability
extrapolation: Assisted discovery of vulnerabilities us-
ing machine learning. In Proc. of 5th USENIX Work-
shop on Oﬀensive Technologies (WOOT), pages 118–
127, Aug. 2011.

[42] F. Yamaguchi, M. Lottmann, and K. Rieck. General-
ized vulnerability extrapolation using abstract syntax
trees. In Proc. of 28th Annual Computer Security Ap-
plications Conference (ACSAC), pages 359–368, Dec.
2012.

[43] H. Zhong, T. Xie, L. Zhang, J. Pei, and H. Mei. Mapo:
Mining and recommending API usage patterns. In Proc.
of the European Conference on Object-Oriented Pro-
gramming(ECOOP), pages 318–343, 2009.

510