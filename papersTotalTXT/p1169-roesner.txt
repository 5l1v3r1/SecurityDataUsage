World-Driven Access Control for Continuous Sensing

Franziska Roesner
University of Washington

David Molnar

Microsoft Research

Alexander Moshchuk

Microsoft Research

Tadayoshi Kohno
Microsoft Research and
University of Washington

Helen J. Wang
Microsoft Research

ABSTRACT
Modern applications increasingly rely on continuous moni-
toring of video, audio, or other sensor data to provide their
functionality, particularly in platforms such as the Microsoft
Kinect and Google Glass. Continuous sensing by untrusted
applications poses signiﬁcant privacy challenges for both de-
vice users and bystanders. Even honest users will struggle to
manage application permissions using existing approaches.
We propose a general, extensible framework for controlling
access to sensor data on multi-application continuous sens-
ing platforms. Our approach, world-driven access control,
allows real-world objects to explicitly specify access policies.
This approach relieves the user’s permission management
burden while mediating access at the granularity of objects
rather than full sensor streams. A trusted policy module on
the platform senses policies in the world and modiﬁes appli-
cations’ “views” accordingly. For example, world-driven ac-
cess control allows the system to automatically stop record-
ing in bathrooms or remove bystanders from video frames,
without the user prompted to specify or activate such poli-
cies. To convey and authenticate policies, we introduce pass-
ports, a new kind of certiﬁcate that includes both a policy
and optionally the code for recognizing a real-world object.
We implement a prototype system and use it to study the
feasibility of world-driven access control in practice. Our
evaluation suggests that world-driven access control can ef-
fectively reduce the user’s permission management burden
in emerging continuous sensing systems. Our investigation
also surfaces key challenges for future access control mecha-
nisms for continuous sensing applications.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—Ac-
cess controls; H.5.1 [Information Interfaces and Pre-
sentation]: Multimedia Information Systems
Keywords
Access control; permissions; continuous sensing; wearable;
augmented reality
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660319.

Figure 1: Sensor Privacy Concerns. Camera restrictions
are common in sensitive locations like locker rooms, where both
device users’ and bystanders’ privacy are at risk from untrusted
applications. Continuous sensing platforms like Google Glass will
make it harder for honest users to mitigate such risks by manag-
ing applications’ permissions. World-driven access control allows
real-world objects to push policies to devices.

1.

INTRODUCTION

Continuous sensing is an emerging technology that en-
ables new classes of applications. New platforms, such as
Microsoft Kinect [37], Google Glass [14], and Meta Space-
Glasses [26], fundamentally rely on continuous video and
depth cameras to support natural user input via gestures
and continuous audio sensing for voice commands. Applica-
tions on these platforms leverage these capabilities to deliver
new functionality to users. For example, WordLens [34] is a
Google Glass and iPhone application that uses the camera to
continuously scan for words in the real world. It then shows
translations of these words overlaid on the user’s vision.

These new capabilities raise serious privacy concerns. Con-
sider a user who enters a locker room while wearing a Google
Glass. We identify four classes of privacy concerns in this
scenario. First, Word Lens or other untrusted applications
running on the Glass may see sensitive video data, both
about the user and about bystanders. Second, the user may
accidentally record bystanders by forgetting to turn oﬀ the
camera while entering the locker room. Third, the user may
record herself in a locker room mirror and accidentally share
the recording on social media. Finally, malicious users could
use the Glass to record others without their knowledge.

The ﬁrst three classes of privacy concerns have honest
users who want to protect against untrusted applications
and user error. While protecting against malicious users is
also important, current approaches for addressing these pri-
vacy concerns do not work well even for honest users. In
this paper we thus assume that users are honest, but that

1169they may run untrusted applications. Our threat model is
similar to the smartphone model, where users are trusted
but applications are not.

Sensitive locations like locker rooms and bars commonly
handle these concerns today by posting explicit policies that
prohibit recording or the presence of recording devices (in-
cluding Google Glass [15]), as in Figure 1. This approach,
however, is hard to enforce and does little to protect a user
from untrusted applications or user error. Users must notice
the sign, then remember to turn oﬀ their device.

A new access control challenge. A natural way to ad-
dress these privacy concerns is with application permissions
in the operating system. However, continuous sensing and
natural user input pose new challenges to access control de-
sign. Today, platforms like Android, iOS, and Windows 8
deny untrusted applications default access to sensitive re-
sources like the camera and GPS. To determine which per-
missions to grant, these OSes put the user in the loop: with
manifests at application installation time (Android, Win-
dows 8) or prompts at the time of sensitive data access (iOS).
Previous work [12, 35], however, has shown that these
permission models are ﬂawed. Manifests are out of context
with applications’ use of sensitive data, making it hard for
users to understand what permissions applications need and
why. Prompts are disruptive and cause “prompt fatigue,”
conditioning users to simply click yes.

User-driven access control [35] addresses these ﬂaws by
coupling permission granting with user actions within an ap-
plication (e.g., clicking a special embedded camera button).
Unfortunately, this approach is not well-suited for contin-
uous sensing because it relies on explicit user interactions
with the device. By contrast, continuous sensing applica-
tions are, almost by deﬁnition, designed to automatically
“do things for you” without any such explicit actions.

Further, for applications with natural user input, like ges-
ture or voice, the input method itself relies on the camera or
microphone being always accessible. In these settings, per-
mission granting models that allow or deny access to entire
sensor streams are too coarse-grained.

The fundamental new challenge in permission system de-
sign for continuous sensing is thus enabling ﬁne-grained, au-
tomatic permission granting. For example, how should the
OS determine which objects in a video frame are accessi-
ble to an application? We pursued multiple unsuccessful at-
tempts to design access control for continuous sensing, which
we discuss in Section 3.1. From them, we learned that ac-
cess control decisions should depend on objects and people
around the user, and that these objects should specify their
own access policies in a distributed, context-sensitive way.

World-driven access control. Our solution is world-
driven access control. Using this approach, objects, places,
and people would present passports to the operating system.
A passport speciﬁes how to handle access control decisions
about an object, along with, optionally, code stating how
the object should be recognized. For example, in Figure 1,
the locker room might present a passport suggesting that
video or audio recording is prohibited. Passports provide a
distributed, context-sensitive approach to access control.

In our design (Section 3), a trusted policy module in the
OS detects passports, extracts policies, and applies those
policies dynamically to control applications’ access to sen-
sor data. In other words, users themselves do not specify

or activate policies, but can instead rely on their device to
automatically detect and enforce policies broadcast by real-
world objects. For example, a world-driven access control
enabled version of Google Glass would enable a locker room
to broadcast a policy stating “no recording” via Bluetooth or
other means. The Glass would detect this policy, then auto-
matically stop recording based on the locker room’s policy.
Our design thus protects the user from untrusted applica-
tions while relieving the user of explicit permission manage-
ment. While users can override policies communicated by
passports, applications cannot.

Passports are intended to help users avoid accidentally
sharing or allowing applications to access sensitive data. For
example, a workplace can publish a passport stating that
whiteboards are sensitive, helping the user avoid recording
(and later accidentally sharing on social media) photos of
conﬁdential information on the whiteboard.
In the locker
room, a “no-record” policy helps the user avoid accidentally
allowing an untrusted application to access the video feed of
herself undressing in the mirror.

Passports can also help users respect others’ wishes with-
out requiring onerous manual conﬁguration. At the Ada-
Camp conference, for example, attendees wear red lanyards
to opt out of photography [3]. A world-driven access control
policy can tell the policy module to remove those attendees
from video streams and photos before applications see them.
The user does not need to manually check lanyards or re-
move the device entirely. Our approach allows dynamically
changing application permissions based on context, such as
being at a conference, without explicit user actions.

Making world-driven access control work requires over-
coming multiple challenges. First, there are many diﬀer-
ent policy communication mechanisms, ranging from QR
codes and Bluetooth to object recognition, each with dif-
ferent tradeoﬀs. Second, recognizing passports and comput-
ing policy decisions induces latency for applications. Third,
policy decisions may have false positives and false negatives.
Finally, our approach creates a new problem of policy au-
thenticity as adversaries may attempt to move, modify, or
remove markers that communicate policies. We describe
these and other challenges, as well as our approaches for
addressing them, in the context of our implementation in
Section 5 and our evaluation in Section 6.

Contributions. We introduce world-driven access control,
whereby application access to sensor data depends on poli-
cies speciﬁed by real-world objects. Our approach allows
the system to automatically manage application permissions
without explicit user interaction, and supports permissions
at the granularity of real-world objects rather than complete
sensor streams. We contribute:

1. World-driven access control, a permission model for
continuous sensing that allows real-world objects to
communicate policies using special passports. Our de-
sign enables a distributed, context-sensitive approach
for objects to control how sensitive data about them
is accessed and for the system to validate the authen-
ticity of these policies.

2. An extensible system design and implementation in
which a trusted policy module protects users from un-
trusted applications without requiring the user to ex-
plicitly manage permissions. We evaluate our proto-
type in ﬁve diﬀerent settings (Section 6) with represen-

1170tative policies from prior work and real-world policies.
Our design’s modularity allows us to implement each
policy in under 150 lines of C# code.

3. Empowering objects with the ability to inﬂuence ac-
cess control decisions on users’ devices introduces nu-
merous challenges. We crystallize these challenges and
explore methods for addressing them. For example,
we introduce techniques for mitigating latency and ac-
curacy challenges in detecting and enforcing policies
(Sections 3-6), such as by combining multiple means
of communicating a policy.

In summary, world-driven access control is intended to
to relieve the user’s permission management burden while
preserving functionality and protecting privacy in emerg-
ing continuous sensing applications. This work presents a
new design point in the space of access control solutions for
continuous sensing applications. We believe that the foun-
dations laid herein will facilitate further work in the ﬁeld.

Previous work in this area focused on bystander privacy
(e.g., visual or electronic opt-outs [7, 16, 36]), or is speciﬁc to
one type of object alone. We discuss related work in detail in
Section 8. Finally, while our focus is on continuous sensing,
our policies can also apply to discrete sensing applications,
e.g., a cell phone camera taking a photo, as well as to output
permissions, e.g., permission for a camera to ﬂash or a phone
to ring. We reﬂect on challenges and discuss other extensions
in Section 7, then conclude in Section 9.

2. GOALS AND THREAT MODEL

We consider ﬁne-grained access control for sensor data on
platforms where multiple isolated applications desire contin-
uous access to system sensors, such as camera, microphone,
and GPS. In our model, the system is trustworthy and un-
compromised, but applications are untrusted.

Goals. Our goal is to help honest users manage applica-
tions’ permissions. A user may do so to (1) protect his/her
own privacy by minimizing exposure of sensor information
to untrusted applications, and/or (2) respect bystanders’ pri-
vacy wishes. We seek to help the user achieve these goals
with minimal burden; users should not need to continuously
manage permissions for each long-running application.

Constraints. We constrain our model in three ways:
(1) We consider only access control policies that are applied
at data collection time, not at data distribution time. These
policies aﬀect whether or not an application may receive a
data item — such as a camera frame or audio event — but
do not provide additional data ﬂow guarantees after an ap-
plication has already accessed the data.
(2) Policies apply to applications, not to the system itself.
For example, if a policy restricts camera access, the (trusted)
system still receives camera data but prevents it from reach-
ing applications. We observe that any system designed to
apply policies embedded in real-world sensor data must, by
deﬁnition, be able to receive and process sensor inputs.
(3) Users can always use another device that does not run
our system, and hence can, if they desire, violate real-world
policies with non-compliant devices. Our solution therefore
does not force user or device compliance and, indeed, ex-
plicitly allows users to override access control policies. We
consider techniques for verifying device compliance, which
have been studied elsewhere [24], out of scope.

Figure 2: World-Driven Access Control
in Action.
World-driven access control helps a user manage application per-
mission to both protect her own privacy and to honor a by-
stander’s privacy wishes. Here, a person asks not to be recorded;
our prototype detects and applies the policy, allowing applications
to see only the modiﬁed image. In this case, the person wears a
QR code to communicate her policy, and a depth camera is used
to ﬁnd the person, but a variety of other methods can be used.

Novel threat model. Our approach empowers real-world
objects with the ability to broadcast data collection policies.
Unlike conventional approaches to access control, like mani-
fests and prompts, we therefore transfer the primary policy
controls away from the user and onto objects in the real
world. Thus, in addition to untrusted applications, we must
consider the threat of adversarially-inﬂuenced real-world ob-
jects. For example, we must consider malicious policies de-
signed to prevent recording (e.g., criminals might appreciate
the ability to turn oﬀ all nearby cameras) or override poli-
cies that prohibit recording (e.g., someone seeking to embar-
rass users in the bathroom by causing them to accidentally
record). These threats guide several design decisions, which
we will return to later, like the ability for users to override
policy suggestions and our design of passports.

3. WORLD-DRIVEN ACCESS CONTROL

World-driven access control is based on three principles
derived from our initial attempts to build an access control
mechanism for continuous sensing, which we summarize. We
then describe our solution, key challenges we encountered,
and how our design addresses these challenges. Figure 2
shows world-driven access control in action, and Figure 3
shows a block diagram of our system.
3.1 Principles from Initial Approaches

Object-driven policies. In user-driven access control [35],
applications are granted access to sensitive resources as a
result of explicit in-application user interactions with special
UI elements (e.g., clicking on an embedded camera button).
This technique eﬀectively manages application permissions
without the drawbacks of prompts or install-time manifests,
and so we attempted to adapt it to continuous sensing.

In some cases, user-driven access control worked well —
photos and video chat on Google Glass, for example, are
triggered by explicit user actions like winking or using the
touchpad. However, many promising continuous sensing ap-
plications do not involve explicit user input. For example,
the WordLens translation application is object-driven, rather
than user-driven: it reacts to all words it “sees” and trans-
lates them without explicit user input. In future systems,
such applications that “do things for you” may run continu-
ously for long periods of time; they are uniquely enabled by
continuous sensing and raise the greatest privacy risks. At-
tempting to inject user actions into such applications — such

1171Figure 3: System Overview. We build on the recognizer abstraction [18], in which applications subscribe to high-level events
generated by object recognition algorithms. Our contribution is the policy module (Section 3.4), which sees all events, detects policies,
and blocks or modiﬁes events accordingly before releasing them to untrusted applications.

as allowing users to use a drag-and-drop gesture to grant ap-
plications one-time access to information about real-world
objects — felt disruptive and artiﬁcial.

From this, we learned that access control decisions can-
not depend (only) on user actions but should instead be
object-driven: real-world objects around the user must help
determine access control policies.

Distributed organization. The next problem was how
to map from objects to access control policies. We ﬁrst at-
tempted to build a taxonomy of which objects are sensitive
(e.g., whiteboards) or not sensitive (e.g., chairs). Unfor-
tunately, a static taxonomy is not rich enough to capture
the complexities of real-world objects — for example, not all
whiteboards contain sensitive content.

We then attempted to deﬁne a hierarchical naming scheme
for real-world objects. For example, we might name an ob-
ject by referring to the room it is in, then the building,
and ﬁnally the building’s owner. We hoped to build a sys-
tem analogous to the Web’s Domain Name System, where
objects could be recognized in the real world, mapped to
names, and ﬁnally mapped to policies. Unfortunately, be-
cause objects can move from one location to another, poli-
cies may not nest hierarchically, and hierarchies not based
on location quickly become complex.

Though there may be value in further attempting to tax-
onomize the world and its moving objects, we chose to pur-
sue an approach in which policy decisions are not central-
ized. Instead, our design’s access control decisions are dis-
tributed : each object is able to set its own policy and com-
municate it to devices.

Context sensitivity. Finally, we faced the challenge of
specifying an object’s policy. A ﬁrst approach here is to
have static “all-or-nothing” policies. For example, a person
or a whiteboard could have a policy saying to never include
it in a picture, and certain sensitive words might always
mark a conversation as not for recording.

While static policies cover many scenarios, others are more
complex. For example, AdaCamp attendees can opt out of
photos by wearing a red lanyard [3]. At the conference, the
lanyard communicates a policy, but outside it does not. Poli-
cies may also depend on applications (e.g., only company-
approved apps may record a whiteboard). From this, we
learned that policies must be context-sensitive and arbitrar-
ily complex. Thus, in addition to static policies, we support
policies that are (appropriately sandboxed) executable code
objects, allowing them to evaluate all necessary context.
3.2 Background: Recognizers & Events

A key enabler for world-driven access control is the rec-
ognizer operating system abstraction [18]. A recognizer is
an OS component that processes a sensor stream, such as
video or audio, to “recognize” objects or other triggers. Upon

recognition, the recognizer creates an event, which is dis-
patched by the OS to all registered and authorized appli-
cations. These events expose higher-level objects to appli-
cations, such as a recognized skeleton, face, or QR code.
Applications may also register for lower-level events, like
RGB/depth frames or location updates.

The recognizer abstraction restricts applications’ access to
raw sensor data, limiting the sensitive information an appli-
cation receives with each event. Further, this event-driven
model allows application developers to write code agnostic to
the application’s current permissions [18]. For example, if an
application does not receive camera events, it cannot distin-
guish whether the hardware camera is turned oﬀ or whether
it is currently not authorized to receive camera events.

Previous work on recognizers, however, did not study how
to determine which permissions applications should have [18].
While the authors discuss visualization techniques to inform
users what information is shared, the burden is on users to
manage permissions through prompts or manifests. World-
driven access control removes this burden by dynamically
adjusting permissions based on world-expressed policies.

3.3 Policies and Policy Communication

We now dive more deeply into our design. We seek a gen-
eral, extensible framework for communicating policies from
real-world objects. Our prototype focuses primarily on poli-
cies communicated explicitly by the environment (e.g., by
QR code or ultrasound), not inferred by the system. How-
ever, our system can be extended to support implicit or in-
ferred policies as computer vision and other techniques im-
prove. For example, the recent PlaceAvoider approach [39] —
which can recognize privacy-sensitive locations with train-
ing — can be integrated into our system.

Designed to be a broad framework, world-driven access
control can support a wide range of policy communication
mechanisms on a single platform, including QR codes or
other visual markers, ultrasound, audio (e.g., embedded in
music), location, Bluetooth, or other wireless technologies.
Additionally, world-driven access control supports both poli-
cies that completely block events (e.g., block RGB frames
in the bathroom) and that selectively modify events (e.g.,
remove bystanders from RGB frames).

Appendix A summarizes existing real-world policies (e.g.,
recording bans) that can be supported by this approach and
which motivate the incentives of establishments (e.g., bars
and conferences) to deploy world-driven policies. We em-
phasize that each establishment need not necessarily con-
struct and implement its own policy; rather, we expect that
a suite of standard policies will suﬃce to cover many scenar-
ios. For example, “do not record in this location” might be
a standard policy.

Stepping back, a world-driven policy speciﬁes (1) when
and for how long it should be active, (2) to which real-world

1172objects or locations it applies, (3) how the system should
enforce it, and (4) to which applications it applies, if appli-
cable. Elaborating on the latter, policies can be application-
speciﬁc, such as by whitelisting known trusted applications.
For example, a corporate building’s policy might block au-
dio input for any application not signed with the company’s
private key.

While conceptually simple, there are numerous challenges
for communicating policies in practice.
In our design, we
aim to quickly recognize a policy, quickly recognize the spe-
ciﬁc objects or locations to which it applies, and accurately
enforce it. A challenge in achieving these goals is that policy
communication technologies diﬀer in range, accuracy, infor-
mation density, and the ability to locate speciﬁc real-world
objects. For example, Bluetooth or WiFi can be detected
accurately across a wide area but cannot easily refer to spe-
ciﬁc objects (without relying on computer vision or other
object detection techniques). By contrast, QR codes can
help the system locate objects relative to their own location
(e.g., the person to whom the QR code is attached), but
their range and detection accuracy is limited (Section 6).
Similarly, a QR code can communicate thousands of bytes
of information, while a speciﬁc color (e.g., a colored shirt or
lanyard [3, 36]) can communicate much less.

We begin to tackle these challenges with several approaches,

and return to additional challenges (like recognition latency
and policy authenticity) in later sections:

Extending policy range. The range of a technology should
not limit the range of a policy. We thus allow a policy to
specify whether it is active (1) while the policy signal itself
is in range, (2) for some speciﬁed time or location, or (3)
until an explicit “end policy” signal is sensed. For example,
a WiFi-based policy for a building might use the ﬁrst op-
tion, and a QR-code-based policy for a bathroom might use
the third option (with “start” and “end” policy QR codes on
either side of the bathroom door). There are challenges even
with these approaches; e.g., the “end policy” signal may be
missed. To overcome missed signals, the QR-code-based pol-
icy can fall back to a timeout (perhaps after ﬁrst notifying
the user) to avoid indeﬁnitely applying the policy.

Increasing information density. Policies need not be
speciﬁed entirely in a real-world signal. Instead, that signal
can contain a pointer (such as a URL) to a more detailed
remote policy. Based in part on this idea, we introduce
passports as a method for dynamically extending the system
with new policy code in Section 4.

Combining technologies. Observing that diﬀerent com-
munications methods have diﬀerent tradeoﬀs, we propose
the use of hybrid techniques: allowing multiple mechanisms
to work together to express a policy. For example, to re-
move bystanders wearing a speciﬁc color from RGB frames, a
wide-range high-density technology like Bluetooth can boot-
strap the policy by informing the system of the opt-out color;
the color helps locate the area to remove from a frame.

3.4 Policy Detection and Enforcement

There is considerable diversity in the types of policies ob-
jects may wish to convey, and hence our solution must be
able to accommodate such diversity. As surfaced in this and
later sections, not all policies are trivial to handle.

World-driven policies are enforced by a trusted policy mod-
ule on the platform (Figure 3). The policy module sub-
scribes to all (or many) of the system recognizers. Any
of these recognizers may produce events that carry policies
(e.g., detected QR codes, WiFi access points, or Bluetooth
signals). The policy module ﬁlters events before they are
delivered to applications. The result of event ﬁltering may
be to block an event or to selectively modify it (e.g., remove
a person from an RGB frame).

In more detail, the policy module keeps the following
state: (1) default permissions for each application (e.g., from
a manifest or other user-set defaults), specifying whether it
may receive events from each recognizer, (2) currently active
policies, and (3) a buﬀer of events from each recognizer.

Before dispatching a recognizer event to an application,
the policy module consults the default permission map and
all active policies. Depending on the result, the policy mod-
ule may block or modify the event.

Event modiﬁcation is complicated by the fact that it may
rely on information in multiple events. For example, if some-
one wearing a QR code should be removed from an RGB
frame, the modiﬁcation relies on (1) the person event, to
isolate the pixels corresponding to a person, and (2) the QR
code event, to pinpoint the person nearest the QR code’s
bounding box (to whom the policy applies).

The policy module thus uses the buﬀer of recognizer events
to identify those needed to enforce a policy. Because corre-
sponding events (those with the same frame number or sim-
ilar timestamps) may arrive at diﬀerent times from diﬀerent
recognizers, the policy module faces a tradeoﬀ between pol-
icy accuracy and event dispatch performance. For example,
consider a QR code that begins an RGB blocking policy. If
the QR code recognizer is slow and the policy module does
not wait for it, an RGB frame containing the QR code may
be mistakenly dispatched before the policy is detected.

Thus, for maximum policy accuracy, the policy module
should wait to dispatch events until all other events on which
a policy may depend have arrived. However, waiting too
long to dispatch an event may be unacceptable, as in an
augmented reality system providing real-time feedback in a
heads-up display. We discuss our implementation choice,
which favors performance, in Section 5.

3.5 Policy Interface

Each world-expressed policy has a ﬁxed interface (Fig-
ure 4), which allows policy writers to extend the system’s
policy module without dictating implementation. We ex-
pect that policies are typically short (those we describe in
Sections 5 and 6 all require under 150 lines of C#) and rely
on events from existing object recognizers, so policy writers
need not implement new recognizers.

The key method is ApplyPolicyToEvent, which is called
once for each event dispatched to each application. This
method takes as input the new event and a buﬀer of previous
events (up to some bound), as well as metadata such as
the application in question and the system’s conﬁguration
(e.g., current permissions). The policy implementation uses
this information to decide whether and how to modify or
block the event for this application. The resulting event is
returned, with a ﬂag indicating whether it was modiﬁed.

The resulting event is then passed to the next policy,
which may further modify or block it.
In this way, poli-
cies can be composed. Although later modiﬁcations are lay-

1173public interface IPolicy {

string PolicyName();
void Init();
void ApplyPolicyToEvent(

RecognizerEvent inEv, EventBuffer prevEvents,
out RecognizerEvent outEv, out bool modified);

void Destroy();

}

Figure 4: Policy Interface. Policies implement this interface
to block or modify events before they are passed to applications.

ered atop earlier ones, each policy also receives unmodiﬁed
events in the event buﬀer used to make and enforce policy
decisions. Thus, poorly written or malicious policies cannot
confuse the decisions of other policies.

Policy code isolation. Policy code can only use this re-
stricted API to obtain and modify sensor events. Policies
must be written in managed code and may not invoke native
code, call OS methods, or access the ﬁle system, network,
or GPU. (Isolating managed code in .NET is common with
AppDomains [27].) Our restrictions protect the user and
the OS from malicious policy code, but they do impose a
performance penalty and limit policies to making local deci-
sions. Our evaluation shows that we can still express many
realistic policies eﬃciently.

Policy conﬂicts. In the case of policy conﬂicts, the system
must determine an eﬀective global policy. If multiple world-
driven policies conﬂict, the system takes the most restrictive
intersection of these policies. In the case of a conﬂict due to
a user’s policy or explicit action, recall that we cannot force
users or their devices to comply with world-driven policies,
since users can always use hardware not running our sys-
tem. The system can thus let the user override the policy
(e.g., by incorporating access control gadgets [35] to ver-
ify that the action genuinely came from the user, not from
an application) and/or use a conﬁrmation dialog to ensure
that the violation of the world-driven policy is intentional,
not accidental, on the user’s part. This approach also gives
users the ability to override malicious or questionable poli-
cies (e.g., policies that block too much or too little).

4. PASSPORTS: POLICY AUTHENTICITY

AND RUNTIME EXTENSIONS

In this section, we simultaneously address two issues: pol-
icy authenticity and system extensibility. First, an attacker
may attempt to forge, move, or remove an explicit world-
driven policy, requiring a method to verify policy authen-
ticity. Second, new policy communication technologies or
computer vision approaches may become available, and our
system should be easily extensible.

To address both issues, we introduce a new kind of digital
certiﬁcate called a passport.
Inspired by real-world travel
passports, our policy passport is designed to support policy
authenticity by verifying that a passport (1) is issued by a
trusted entity, and (2) is intended to apply to the object
or location where it is observed. To support extensibility, a
passport may additionally contain sandboxed object recog-
nition and/or policy code to dynamically extend the system.
4.1 On the Need for Policy Authenticity

We elaborate here on the need to address attackers who
might wish to make unauthorized modiﬁcations to existing

policies. Attacker modiﬁcations may make policies less re-
strictive (e.g., to trick employees of a company into acci-
dentally taking and distributing photos of conﬁdential in-
formation in conference rooms) or more restrictive (e.g., to
prevent the cameras of surrounding users from recording the
attacker breaking a law). In particular, attackers attempting
to change policies may employ the following methods:

1. Creating a forged policy.
2. Moving a legitimate policy from one object to another

(eﬀectively forging a policy on the second object).

3. Removing an existing policy.
The diﬃculty of mounting such attacks depends on the
policy communication technology. For example, it may be
easy for an attacker to replace, move, or remove a QR code,
but more diﬃcult to do so for an ultrasound or WiFi signal.
Thus, these risks should be taken into account by object or
location owners deploying explicit policies.

The threat of policy inauthenticity also varies by object.
For example, it is likely more diﬃcult for an attacker to forge
a policy (like a QR code) aﬃxed to a person than one aﬃxed
to a wall. Thus, for certain types of objects, such as humans,
the system may trust policies (e.g., colored lanyards as opt-
outs [3]) without requiring additional veriﬁcation, under the
assumption that it is diﬃcult to physically manipulate them.
4.2 Signing Passports

The contents and origin of passports must be crypto-
graphically veriﬁable. There are numerous approaches for
such veriﬁability, ranging from crowd-sourced approaches
like Perspectives [43] and Convergence [25] to social-based
approaches like PGP [44]. While the certiﬁcate authority
(CA) model for the Web has known limitations [9], because
of its (current) wide acceptance, we choose to build on the
CA model for world-driven access control. However, we
stress that the underlying mechanism is interchangeable.

Building on the CA model, we introduce a policy authority
(PA), which is trusted to (1) verify that the entity request-
ing a passport for an object or location is the real owner
(i.e., has the authority to provide the policy), and (2) sign
and issue the requested passport. Multiple policy author-
ities may exist. Thus, object or location owners wishing
to post policies must submit them to be signed by one of
these trusted authorities. For this approach to be eﬀective,
it must be diﬃcult for an attacker to obtain a legitimately
signed policy for an object or location for which he or she
cannot demonstrate ownership.
4.3 Describing Objects via Passports

In addition to containing a policy speciﬁcation, each signed
passport contains a description of the associated object or
location. For a ﬁxed location (e.g., on a corporate campus),
the description may specify GPS coordinates bounding the
targeted area. For a mobile object, the description should
be as uniquely-identifying as possible (e.g., containing the
license plate of the associated car). Thus, after verifying
a passport’s signature, the system also veriﬁes that the en-
closed description matches the associated object or location.
Having a description in the passport helps prevent an at-
tacker from moving a legitimately signed passport from one
object or location to another. Preventing such an attack
may be diﬃcult to achieve in general, as it depends on the
false positive rates of the object recognition algorithm and
what is actually captured by the device’s sensors (e.g., the

1174car’s license plate may not be in view). The key point is that
passports give object owners control over the description, so
an object owner can pick the best available description.

We observe that object descriptions may create privacy
risks for objects if not designed carefully. We return to the
tension between description clarity and privacy in Section 7.
We further support active object descriptions contained
in the passport. Rather than being simply static (e.g., “car
with license plate 123456”), the object description may con-
sist of code (or of a pointer to code) that directly extends the
system’s recognizers (e.g., with a car recognizer). Beyond
aiding policy veriﬁcation, active descriptions can extend the
system’s basic object recognition abilities without requiring
changes to the system itself. Certiﬁcates including code and
policy are similar in spirit to the permission objects in .NET
Code Access Security [28], the delegation authorization code
in Active Certiﬁcates [6], the self-describing packets in Ac-
tive Networks [40], or objects in Active DHTs [13], but we
are not aware of previous approaches that dynamically add
object recognition algorithms. In our initial design, the ac-
tive object descriptions are trusted by virtue of the PA’s
signature, and could be further sandboxed to limit their ca-
pabilities (as in Active DHTs [13]). For example, object de-
scription code may be forbidden to access the network. To-
day, for example, the Kinect’s skeleton detection and face
detection do not need network access. Diﬀerent levels of
sandboxing may be allowed by the user.

If the description contained in the passport does not match
the associated object, the passport is ignored — i.e., the sys-
tem applies a sensible default. For a real-world travel pass-
port, the default is to deny access; in our case, requiring
explicit allow-access policies on all objects would likely re-
quire an unacceptable infrastructure and adoption overhead.
Thus, in practice, the system’s default may depend on the
current context (e.g., a public or private setting), the type
of object, or the type of recognizer. For example, a default
may deny face recognition but allow QR code events.

We believe the idea of active object descriptions is of in-
terest independent from world-driven policies. By allowing
real-world objects to specify their own descriptions, the sys-
tem’s object recognition capabilities can be easily extended
in a distributed, bottom-up manner.
4.4 Monitoring Passports

Passport signatures and objects descriptions help prevent
attackers from forging or moving passports. We must also
consider the threat of removing passports entirely. Again,
because a deny-access default may create high adoption over-
head, a missing passport allows access in the common case.
As an initial approach, we suggest mitigating this threat
by monitoring passports. In particular, a policy owner can
monitor a passport directly — by installing a device to ac-
tively monitor the policy, e.g., to ensure that the expected
QR code or ultrasound signal is still present — or can in-
clude in the policy itself a request that devices occasionally
report back policy observations. While an attacker may also
try to manipulate the monitoring device, its presence raises
the bar for an attack: disabling the monitor will alert the
policy owner, and fooling it while simultaneously removing
the policy from the environment may be diﬃcult for some
policy communication technologies (e.g., WiFi).

Stepping back, we have explored the problem space for pol-
icy passports. The proposed designs are an initial approach,

and we welcome future work on alternative approaches sup-
porting our core concept that real-world objects can specify
their own policies and prove their authenticity.

5.

IMPLEMENTATION

While world-driven access control may intuitively appear
straightforward, it is not obvious that it can actually work
in practice. We explore the challenges — and methods for
overcoming them — in more detail with our implementation
and evaluation. Our prototype runs on a Windows lap-
top or tablet and relies on sensors including the Kinect’s
RGB/depth cameras and its microphone, the built-in WiFi
adapter, and a Bluetooth low energy (BLE) sensor. Though
this platform is more powerful than some early-generation
continuous sensing devices, we expect these devices to im-
prove, such as with specialized computer vision hardware [10,
30]. Some continuous sensing platforms — such as Xbox
with Kinect — are already powerful enough today.

Sensor input is processed by recognizers [18], many of
which simply wrap the raw sensor data. We also imple-
mented a QR code recognizer using an existing barcode li-
brary [1], a speech keyword recognizer using the Microsoft
Speech Platform, a WiFi access point recognizer, and one
that computes the dominant audio frequency.
5.1 Policy Module

As described in Section 3.4, the policy module subscribes
to events from all of the system’s recognizers and uses them
to detect and enforce policies. Before dispatching an event to
an application, the system calls the policy module’s Filter-
Event() method, which blocks or modiﬁes the event based
on currently active policies. To modify an event, it uses
recently buﬀered events from other recognizers if necessary.
Recall from Section 3.4 the policy accuracy versus perfor-
mance tradeoﬀ: policies can be detected and applied more
accurately if all relevant events have arrived, but waiting too
long impacts event dispatch latency. In our implementation
we favor performance: to avoid delays in event dispatch,
we do not match up events precisely using frame numbers
or timestamps, but simply use the most recent events, at
the possible expense of policy accuracy. Alternatively, this
choice could be made per application or by user preference.
We quantify the eﬀects of this tradeoﬀ in Section 6.
5.2 Passports

In addition to static policies (e.g., a simple QR code that
activates a pre-installed “block RGB events” policy), our
prototype supports passports by transforming certain recog-
nizer events into passport lookups. The system appends the
text in a QR code or a Bluetooth MAC address to the base
URL at www.wdac-passport-authority.com/passportlookup/. If
a corresponding passport exists, the server provides its URL.
The passport contains a policy DLL that implements our
policy interface (Figure 4). The system downloads, veriﬁes,
and installs the new policy (if not previously installed).

The process of loading a passport could be optimized by
caching server responses. If the system cannot make a net-
work connection, it misses the passport; a future implemen-
tation could buﬀer the network request until connectivity
is available, in case the policy is still applicable then. Note
that the system does not need a network connection to parse
static (non-passport) policies; passports communicated via
certain communication technologies (e.g., Bluetooth) could

1175Name

Detection

Enforcement

Lines of Code (C#)

Respectful Cameras [36] Visual indicator Blur faces
Brassil [7]
Blur faces
Bluetooth
Blur faces
TagMeNot [8]
QR Code
Ultrasound
Iceberg Systems [20]
Disable camera
Parachuri et al. [31]
Visual indicator Remove person

84 (QR code) – 104 (color)
69 (remove person)
84 (remove person)
35 (audible sound)
84

Figure 5: Policies in Prior Work. Our architecture generalizes policies from prior work; this table details those we implemented.

also encode their policy code directly rather than pointing
to a server. As noted in Section 4, code in a passport could
be signed by a policy authority and sandboxed. Since signa-
ture and sandboxing approaches have been well studied else-
where, we do not include them in our prototype but rather
focus on world-driven access control functionality.

5.3 Prototype Policies

We implemented prototype policies representative of those

in the real world (Appendix A) or in related work.

Block RGB in sensitive area. We implemented several
policies blocking RGB events in sensitive areas, based on
QR codes, BLE, WiFi, and audio. For example, a QR code
on a bathroom door can specify a policy that blocks RGB
until the corresponding “end policy” QR code is detected.
We can similarly use a BLE emitter to specify such a policy;
BLE has a range of roughly 50 meters, making it suitable
for detecting a sensitive area like a bathroom. Similarly, we
use the access point (AP) name of our oﬃce’s WiFi network
to trigger a policy that blocks RGB events. (Future APs
might broadcast more complete, authenticated policies.)

We also use our audio frequency recognizer to block RGB
events: if a trigger frequency is heard three 32 ms timeslots
in a row, the corresponding policy is engaged (and disen-
gaged when the trigger has not been heard for three consec-
utive timeslots). In our experiments, we used a frequency
of 900 Hz; in a real setting, ultrasound may be preferable.
Ultrasound is already used in real settings to communicate
with smartphones [42]. More complex audio communication
is also possible, e.g., encoding a policy in the signal [33].

Remove person from RGB. We support several policies
to remove bystanders from RGB frames. First, we support
bystanders wearing opt-out QR codes — though our imple-
mentation could easily support an opt-in instead — and ﬁlter
RGB events to remove the pixels associated with the person
nearest such a QR code’s bounding box. To do so, we use
the per-pixel playerIndex feature of Kinect depth frames.
Figure 2 shows a modiﬁed RGB frame based on this policy.
As a simpler, more eﬃcient policy to remove people from
RGB frames, and inspired by practices at AdaCamp, we also
implemented a color-based policy, using a certain shirt color
to indicate an opt-out. This policy (1) detects a 10x10 pixel
square of the target color, (2) calculates its average depth,
and (3) removes RGB pixels near that depth. Thus, this
policy applies to anything displaying the target color, and
it avoids the latency of the Kinect’s player detection. Using
a hybrid approach, we also implemented a BLE policy to
bootstrap the color policy (discussed more in Section 6).

Block sensitive audio. We implemented a policy that
blocks sensitive audio based on our speech keyword recog-
nizer. We use a hard-coded grammar that includes words

Figure 6: Example Policy Evaluation. We evaluate start
lag (false negatives before a policy is correctly applied), ﬁnish
lag (false positives after a policy should have been stopped), and
additional false positives and negatives outside of these lags.

that may signal a sensitive conversation, such as project
codenames like “Natal,” as well as explicit user commands
such as “stop audio.” The policy blocks audio events once
such a keyword is detected, and resumes audio events upon
command (i.e., when the user explicitly says “begin audio”).

6. EVALUATION

We evaluate along two axes:

1. Policy Expressiveness and Implementation Eﬀort. We
show that our architecture can incorporate a wide va-
riety of policies desired by users and proposed in prior
work with low developer eﬀort (Section 6.1).

2. Policy Eﬀectiveness. We explore the eﬀectiveness of
policy communication technologies and world-driven
policies implemented in our prototype (Section 6.2).

6.1 Policy Expressiveness & Effort

We validate that our policy interface (Figure 4) is expres-
sive enough to capture realistic policies. We implemented
a representatives set of policies proposed in prior work rele-
vant to continuous sensing [7, 8, 20, 31, 36], summarized in
Figure 5. In some cases, we implemented a slightly diﬀer-
ent enforcement than the one speciﬁed in prior work (e.g.,
removing people from the frame instead of blurring faces),
and we note these diﬀerences where applicable. Each policy
could be implemented in our prototype with only a modest
number of lines of C# code (between 35 and 104, measured
using Visual Studio’s Code Metrics), indicating that our ar-
chitecture supports new and diverse policies with modest
additional developer eﬀort.

Other policies exist in prior work, such as a policy to en-
crypt recordings with a shared key derived with a distributed
prototol [16]. We determined that our system could support
this policy, but for our purposes here we chose not to spend
eﬀort reimplementing its protocol. Our prototype can also
handle existing real-world policies (Appendix A).

We conclude that our architecture’s policy abstraction is
suﬃciently expressive and that policies can be implemented
with modest developer eﬀort.

1176Trace Name Policy Trigger

Intended Policy for Targeted Event Type

LOC Total Events

Length

Bathroom
Bathroom
Bathroom

Block RGB events in bathroom.
QR Code
Block RGB events in bathroom.
Bluetooth
Audio Frequency (900 Hz) Block RGB events in bathroom.

Person
Person
Person
Person

QR Code
QR Code with memory
Bluetooth + Person
Color

Remove person from RGB events.
Remove person from RGB events.
Remove person from RGB events.
Remove person from RGB events.

Speaking

Speech Keyword

Block audio events after sensitive keyword.

Corporate

WiFi

Commute

Location

Block RGB events in corporate building.

Blur location events in sensitive area.

24
23
35

84
89
69
104

23

23

29

10435
10435
10435

7132
7132
7132
7132

4529

21064

475

83 sec.
83 sec.
83 sec.

60 sec.
60 sec.
60 sec.
60 sec.

42 sec.

191 sec.

482 sec.

Figure 7: Evaluated Policies. We constructed scenarios, took traces using our prototype, and evaluated the eﬀectiveness of various
policies. In the third column, the type of event targeted by the policy is bolded; the fourth column reports total events in the trace.

Trace Name Policy Trigger

# Target Events

Start Lag

Finish Lag

Additional FN Additional FP

Bathroom
Bathroom
Bathroom

QR Code
Bluetooth
Audio Frequency (900 Hz)

Person
Person
Person
Person

QR Code
QR Code with memory
Bluetooth + Person
Color

Speaking

Speech Keyword

Corporate

WiFi

Commute

Location

1946
1946
1946

1244
1244
1244
1244

375

2823

475

0 (0 sec)
-50 (-2.1 sec)
0 (0 sec)

0 (0 sec)
183 (7.8 sec)
0 (0 sec)

279 (13.5 sec)
279 (13.5 sec)
210 (10.1 sec)
147 (6.1 sec)

0 (0 sec)
0 (0 sec)
8 (0.4 sec)
0 (0 sec)

16 (1.8 sec)

27 (3.0 sec)

21 (1.4 sec)

0 (0 sec)

14 (14.2 sec)

4 (4.1 sec)

0
0
81

88
20
0
23

0

171

0

0
0
0

0
0
30
23

0

417

0

Figure 8: Evaluation Results. This table shows the results from running each policy against the corresponding trace. The ﬁrst two
columns match those in Figure 7. Figure 6 explains how start/ﬁnish lag and additional false positives/negatives are calculated.

6.2 Policy Effectiveness

We evaluate policy eﬀectiveness in representative scenar-
ios. We aim not to maximize eﬀectiveness but to explore
policy communication technologies and demonstrate the fea-
sibility of world-driven access control. We also view our
evaluation methodology itself as a contribution for others
studying access control for continuous sensing.

6.2.1 Evaluation Methodology
We designed and evaluated representative scenarios, each
with one or more environmental policy triggers (Figure 7).
For example, in the Bathroom scenario, we aﬃxed QR codes
on and near the bathroom door, and we placed a BLE emit-
ter and a smartphone producing a 900 Hz tone inside. In the
Person scenario, a person carried a BLE emitter and wore a
QR code and a red color.

We used our prototype to record a trace of raw recognizer
events for each scenario. We constructed scenarios so that
a policy was applicable in one continuous segment (e.g., a
person is only seen once in the Person trace) and that the
trace was realistic (e.g., we turned on a faucet in the bath-
room). We then replayed every trace once for each policy
present. Pre-recorded traces let us compare multiple policies
on the same trace. Since our goal is to evaluate feasibility,
we consider only one representative trace of each scenario.
We then annotated each trace with ground truth for each
policy of interest: whether the ideal enforcement of that
policy would modify or block each event. We compared
the results of the replay for each policy with our ground
truth annotations. In particular, we introduce the follow-

ing methodology for evaluating the eﬀectiveness of a policy.
Considering only those events that may be aﬀected by the
given policy, such as RGB in the Bathroom trace or audio
in the Speech trace, we evaluate the policy as follows.

Speciﬁcally, we consider four values: (1) start lag (false
negatives before the policy is correctly applied), (2) ﬁnish
lag (false positives before the policy is correctly removed),
(3) additional false positives, and (4) additional false nega-
tives. Conceptually, start and ﬁnish lag measure the time
it takes to recognize the policy. Additional false positives
occur outside of this region and additional false negatives
occur within this region; neither include the start or ﬁnish
lag. Figure 6 shows each value visually. These values rely, of
course, on speciﬁc characteristics of a trace; we attempted to
construct realistic evaluation scenarios to get a conceptual
idea of how well these policies work in practice.

We ran our traces with an outward-facing Kinect attached
to a Lenovo W520 laptop (Core i7, 16 GB RAM, 160 GB
SSD). This setup let us log traces without aﬀecting events
rates, relying on a large memory to buﬀer all events un-
til trace completion. Without logging, we achieved similar
event rates on a less powerful Samsung tablet (Core i5, 2
GB RAM). We expect that continuous sensing devices will
approach the capabilities of these more powerful machines.

6.2.2 Evaluation Results
We describe lessons learned from our experience, sup-

ported by policy-speciﬁc evaluations (Figures 8–9).

Adding policy memory reduces jitter. We ﬁnd that
certain policy technologies show high variability in detec-

1177(a) Bathroom Scenario: RGB-Blocking Policies

(b) Person Scenario: RGB-Modifying Policies

(c) Speech Scenario: Audio-Blocking Policy

(d) Corporate Scenario: RGB-Blocking Policy

Figure 9: Policy Evaluation. The grey regions were annotated as “depends” in the ground truth, i.e., the human annotator believed
that either blocking or not blocking the event would be acceptable; these events are not counted in Figure 8. Figure 6 shows an example.

tion. For example, QR codes are detected only about every
third RGB frame when present, WiFi signals are unreliable
at a building’s perimeter (presumably far from an access
point), and audio frequency is sensitive to other ambient
audio (e.g., running water in the bathroom).

We ﬁnd that we can minimize this detection jitter by
adding memory to the policy. For example, in the origi-
nal QR code policy, we consult the most recent QR code
event for each RGB event to determine if the policy should
be applied. In the “QR code with memory” policy, we look
farther into the past, consulting up to ﬁve recent QR code
events and applying the most recent policy it ﬁnds (if any).
(One QR code event, or null if no QR code is found, is gen-
erated per RGB frame.) This change makes the QR code
policy more robust:
if at least one of ﬁve RGB frames re-
sults in a correctly detected QR code, the policy will not
jitter in the interim. The tradeoﬀ is that too much memory
may lead to a longer ﬁnish lag or more false positives.

Hybrid techniques can improve performance. Diﬀer-
ent technologies can be combined to exploit their respec-
tive strengths. For example, in the Person trace, we used
Bluetooth (which has a wider range) to bootstrap person
removal using color or the Kinect’s person detection (which
can localize the object to be modiﬁed in a frame). This re-
sult challenged our initial intuition that policies should be
detectable via the same sensor as the events to which the
policy applies. We reasoned that if the system is in a state
where it misses a policy trigger (e.g., the camera is oﬀ), then
it should also be in a state to miss the events to which the
policy applies (e.g., RGB events). However, this proposal
fails due to diﬀerences in the characteristics of diﬀerent pol-
icy technologies.

Additionally, the latency incurred by loading policy code can
be hidden by bootstrapping it as early as possible. It took
on average 227.6 ms (10 trials) to load and install a passport
(197.9 ms of which is network latency), increasing the start
lag by 5-6 RGB frames if the policy is to be used immedi-
ately. Communicating a person’s opt-out via BLE, rather
than in a QR code on the person, would thus allow enough
time to load the policy before the person is encountered.

Accuracy and latency may conﬂict. Recall that we
trade oﬀ policy accuracy with performance in our imple-
mentation (Section 5). Rather than waiting to dispatch an
RGB event until the corresponding QR event arrives, we
dispatch all RGB events immediately, relying on the most
recent (possibly out of date) QR code event to detect a pol-
icy. We observe that start lag consists of two components:
(1) the time it takes to be in range of the policy (e.g., close
enough to the QR code), and (2) the number of unmodi-
ﬁed events after the policy comes into range but the trigger
is not yet recognized. Our choice to trade oﬀ accuracy for
performance potentially aﬀects the second component.

We measured the eﬀect of this implementation choice for
QR codes. We ﬁnd that the accuracy impact is negligible: in
the Bathroom trace, the diﬀerence is just one frame (40 ms).
That is, one RGB event contained a QR code and was let
through, but the policy was applied by the next RGB event.
In the Person trace, the lag is four frames (160 ms); these
accuracy diﬀerences are not discernible in Figure 9. How-
ever, the same performance lag may noticeably impact the
user in some cases: to avoid distracting lag between the real
and virtual objects in augmented reality, for example, sensor
input events must be dispatched in as close to real-time as
possible [2]. Systems may diﬀer in their requirements.

Bootstrap remote policies early with passports. We
experimented with passports in the Person trace, using Blue-
tooth and QR codes to load person removal policies. Pass-
ports let us easily extend our system without rebuilding it.

Better technology will improve accuracy. Because the
Kinect has a relatively low RGB resolution (640x480, up
to 30 frames per second), in two traces we simultaneously
collected additional video using a GoPro camera (1280x1080,

1178up to 60 frames per second) aﬃxed to the Kinect (included in
Figures 9a–b.) We synchronized Kinect and GoPro frames
by hand, downsampling the GoPro points and marking the
policy as enforced if any collapsed frames were blocked or
modiﬁed. The barcode library could decode QR codes up
to one second earlier in the GoPro traces, with fewer false
negatives. The GoPro’s wide-angle lens also allowed it to
decode QR codes in the periphery (e.g., near but not on the
bathroom door) that the Kinect did not see. Thus, as mobile
cameras improve, so will their ability to detect world-driven
policies.

We expect that other cases in which our system failed to
match ground truth will also be improved by better tech-
nology. For example, the speech keyword recognizer is slow,
resulting in large start and ﬁnish lags. Similarly, the start
lag is long for all person removal policies (Figure 9b) because
the trace involves approaching the person down a hall, and
no method is eﬀective until the camera is close enough.

World-driven access control is practical. Our expe-
riences suggest that world-driven policies can be expressed
with modest developer eﬀort, that the system can be seam-
lessly extended with passports, and that policies can be de-
tected and enforced with reasonable accuracy given the right
choice of technology. Even without advances in computer
vision or other technologies, world-driven access control al-
ready signiﬁcantly raises the bar in some scenarios — e.g.,
the accuracy of our system in the bathroom setting.

7. REFLECTIONS AND FUTURE WORK

Continuous sensing applications will become increasingly
prevalent as technologies like Google Glass and Microsoft
Kinect become more ubiquitous and capable. World-driven
access control provides a new alternative to controlling ac-
cess to sensor streams. As our work uncovers, important
challenges arise when attempting to instantiate this approach
in a real system. One key challenge is the tradeoﬀ between
policy detection accuracy and enforcement latency. A sec-
ond key challenge is the need to verify the authenticity of
signals communicated from real-world objects. Though we
designed and evaluated speciﬁc approaches for overcoming
both challenges, future insights may lead to alternate solu-
tions. We highlight these challenges in this section, with
the hope of providing targets for and beneﬁting future re-
searchers focused on access control for continuous sensing.

We also highlight a separate challenge: the tension be-
tween the speciﬁcity of the information broadcast in a pol-
icy and an object’s privacy. While speciﬁc object descrip-
tions (e.g., “no pictures of car with license plate 123456”) are
valuable both for policy veriﬁcation and for extending the
system’s object recognition capabilities, they reveal informa-
tion to anyone receiving the broadcast. We view this issue
as separate from our study of how to eﬀectively communi-
cate and manage world-driven policies, our primary goal,
but we believe it is important to consider if world-driven
access control systems are deployed with highly expressive
policies. Currently, policy creators must balance policy ac-
curacy and description privacy, considering evolving social
norms in the process. Since speciﬁc object descriptions in
passports are nevertheless valuable for verifying that a pol-
icy has not been moved by an adversary, we encourage fu-
ture work on privacy-preserving, expressive policies (e.g., en-
crypted policies accessible only by trusted policy modules).

A separate privacy issue arises with the use of crypto-
graphic signatures on policies: if the signatures on each ob-
ject are unique, then they can be used to track objects; we
observe, however, that there are many other methods to
track objects today (e.g., RFIDs, Bluetooth IDs, MAC ad-
dresses), and hence consider the issue out of scope.

Finally, as described, world-driven access control can use
diverse mechanisms to communicate policies. We imple-
mented and evaluated several approaches for explicitly com-
municating policies, and we encourage further study of other
approaches. For example, our design is general enough to
encompass implicitly communicated policies. Implicit poli-
cies may rely on improved computer vision (e.g., to recog-
nize sensitive locations, as in PlaceAvoider [39]) or be in-
ferred from natural human behavior (e.g., closing a door or
whispering). Other examples of work in this area are Le-
gion:AR [21], which uses a panel of humans to recognize ac-
tivities, and work on predicting the cost of interruption from
sensors [17]. Additionally, to improve policy detection accu-
racy, systems may include additional policy-speciﬁc sensors,
such as cameras, whose sole purpose is to sense policies, al-
lowing them to be lower-power than user-facing sensors [23].

8. ADDITIONAL RELATED WORK

We have discussed inline prior works that consider by-
stander privacy, allowing them to opt out with visual (e.g.,
[36]) or digital markers (e.g., [7, 16]). TagMeNot [8] pro-
poses QR codes for opting out of photo tagging. Our work
can support all of these prior special-purpose policies, but
moves beyond them in (1) providing a dynamically extensi-
ble framework that can support any policy, (2) allowing any
real-world object to specify its policy by a variety (or com-
bination) of technological mechanisms, and (3) tackling the
challenge of policy authenticity by introducing passports.
The above-mentioned designs, like ours, rely on compliant
recording devices or vendors; other systems aim to prevent
recording by uncooperative devices, e.g., by ﬂashing directed
light at cameras [32]. Recent work studied bystander reac-
tions to augmented reality devices and surveyed design axes
for privacy-mediation approaches [11].

Others have considered the privacy of device users.

In-
deed, Starner considered it a primary challenge for wearable
computing [38]. Though wearable devices can improve secu-
rity (e.g., with location-based or device-based access control,
as in Grey [5]), data collected or sent by the device can re-
veal sensitive information. Such concerns motivate privacy-
preserving location-based access control (e.g., [4]). Here, we
assume that the device and system are trustworthy.

Others have also restricted applications’ access to percep-
tual data. Darkly [19] integrates privacy protection into
OpenCV, and the “recognizer” abstraction [18] helps limit
applications’ access to objects in a sensor feed. World-
driven access control builds on the recognizer abstraction,
but moves beyond it by addressing the challenge of determin-
ing which access control policies should be applied. In par-
ticular, previous work did not specify when to grant appli-
cations permissions to access recognizers. PlaceAvoider [39]
identiﬁes images captured in sensitive locations and with-
holds them from applications. PiBox [22] restricts applica-
tions from secretly leaking private data, but provides weak
guarantees when users explicitly share it. Our approach
helps users avoid accidentally sharing sensitive content with
untrusted applications.

11799. CONCLUSION

Continuous sensing applications on platforms like smart-
phones, Google Glass, and XBox Kinect raise serious access
control challenges not solved by current techniques. We in-
troduced world-driven access control, by which real-world
objects specify per-application privacy policies. This ap-
proach aims to enable permission management at the gran-
ularity of objects rather than complete sensor streams, and
without explicitly involving the user. A trusted platform
detects these policies in the environment and automatically
adjusts each application’s “view” accordingly.

We built an end-to-end world-driven access control pro-
totype, surfacing key challenges. We introduced passports
to address policy authenticity and to allow our system to
be dynamically extended. We mitigated detection inaccura-
cies by combining multiple policy communication techniques
and introducing memory into policies. Finally, we explored
the tradeoﬀs between policy accuracy and performance, and
between broadcast policies and privacy.

Our prototype enforces many policies, each expressed with
modest developer eﬀort, with reasonable accuracy even with
today’s technologies and oﬀ-the-shelf algorithms. Our expe-
riences suggest that world-driven access control can relieve
the user’s permission management burden while preserving
functionality and protecting privacy. Beyond exploring a
new design point for access control in continuous sensing,
this work represents a step toward integrating physical ob-
jects into a virtual world ; we believe our explorations lay the
groundwork for future work in this space.

Acknowledgements
We thank Greg Akselrod, Raymond Cheng, Lydia Chilton,
Jon Howell, Jaeyeon Jung, Benjamin Livshits, Eyal Ofek,
Matthai Philipose, Stuart Schechter, Will Scott, Alex Taka-
kuwa, and Margus Veanes for valuable discussions and feed-
back on earlier drafts; we thank Weidong Cui for his help
with evaluation traces. This work was done while the ﬁrst
and fourth authors were visiting Microsoft Research. This
work was supported in part by a National Science Foun-
dation Graduate Research Fellowship under Grant DGE-
0718124 and a Microsoft Research PhD Fellowship.

References
[1] ZXing.Net. http://zxingnet.codeplex.com/.
[2] Abrash, M. Latency – the sine qua non of AR and

VR, 2012. http://bit.ly/UbrBL0.

[3] Ada Initiative. Another way to attract women to

conferences: photography policies, 2013.
http://bit.ly/1bc3x3O.

[4] Ardagna, C. A., Cremonini, M., di Vimercati, S.

D. C., and Samarati, P. Privacy-enhanced
Location-based Access Control. In Handbook of
Database Security. 2008, pp. 531–552.

[5] Bauer, L., Garriss, S., McCune, J. M., Reiter,

M. K., Rouse, J., and Rutenbar, P.
Device-enabled authorization in the Grey system. In
International Conference on Information Security
(2005).

[7] Brassil, J. Technical Challenges in Location-Aware
Video Surveillance Privacy. In Protecting Privacy in
Video Surveillance, A. Senior, Ed. 2009, pp. 91–113.

[8] Cammozzo, A. TagMeNot. http://tagmenot.info/.

[9] Clark, J., and van Oorschot, P. C. SoK: SSL and

HTTPS: Revisiting past challenges and evaluating
certiﬁcate trust model enhancements. IEEE
Symposium on Security & Privacy (2013).

[10] CNXSoft. Qualcomm fast computer vision sdk, 2011.

http://bit.ly/rUY7Pa.

[11] Denning, T., Dehlawi, Z., and Kohno, T. In situ

with bystanders of augmented reality glasses:
Perspectives on recording and privacy-mediating
technologies. In ACM CHI (2014).

[12] Felt, A. P., Ha, E., Egelman, S., Haney, A.,
Chin, E., and Wagner, D. Android permissions:
User attention, comprehension, and behavior. In
Symposium on Usable Privacy and Security (SOUPS)
(2012).

[13] Geambasu, R., Levy, A. A., Kohno, T.,

Krishnamurthy, A., and Levy, H. M. Comet: An
active distributed key-value store. In USENIX OSDI
(2010).

[14] Google. Google Glass. http://glass.google.com/.

[15] Gray, R. The places where Google Glass is banned,

Dec. 2013. http://www.telegraph.co.uk/
technology/google/10494231/The-places-where-
Google-Glass-is-banned.html.

[16] Halderman, J. A., Waters, B., and Felten,

E. W. Privacy Management for Portable Recording
Devices. In Workshop on Privacy in Electronic Society
(2004).

[17] Hudson, S., Fogarty, J., Atkeson, C., Avrahami,

D., Forlizzi, J., Kiesler, S., Lee, J., and Yang,
J. Predicting human interruptibility with sensors: a
wizard of oz feasibility study. In ACM CHI (2003).

[18] Jana, S., Molnar, D., Moshchuk, A., Dunn, A.,
Livshits, B., Wang, H. J., and Ofek, E. Enabling
Fine-Grained Permissions for Augmented Reality
Applications with Recognizers. In USENIX Security
Symposium (2013).

[19] Jana, S., Narayanan, A., and Shmatikov, V. A

Scanner Darkly: Protecting User Privacy from
Perceptual Applications. In IEEE Symposium on
Security and Privacy (2013).

[20] Kotadia, M. Jamming device aims at camera

phones, 2003. http://cnet.co/HEvS8b.

[21] Lasecki, W., Song, Y. C., Kautz, H., and

Bigham, J. Real-time crowd labeling for deployable
activity recognition. In Computer Supported
Cooperative Work (CSCW) (2013).

[22] Lee, S., Wong, E., Goel, D., Dahlin, M., and

Shmatikov, V. PiBox: A platform for privacy
preserving apps. In USENIX Symposium on
Networked Systems Design and Implementation
(NSDI) (2013).

[6] Borisov, N., and Brewer, E. A. Active certiﬁcates:

A framework for delegation. In Network and
Distributed System Security Symposium (NDSS)
(2002).

[23] LiKamWa, R., Priyantha, B., Philipose, M.,

Zhong, L., and Bahl, P. Energy characterization &
optimization of image sensing toward continuous
mobile vision. In MobiSys (2013).

1180[24] Lioy, A., and Ramunno, G. Trusted computing. In

Place

Policy

Handbook of Information and Communication
Security, Stavroulakis and Stamp, Eds. 2010,
pp. 697–717.

[25] Marlinspike, M. Convergence.

http://convergence.io/.

[26] Meta. Spaceglasses. http://spaceglasses.com.
[27] Microsoft. App. Domains.

http://msdn.microsoft.com/en-
us/library/2bh4z9hs(v=vs.110).aspx.

[28] Microsoft. Creating your own code access
permissions, 2013. http://bit.ly/HFzDKD.

[29] O’Brien, K. Swiss Court Orders Modiﬁcations to

Google Street View, 2012. http://nyti.ms/L3cdNZ.

[30] Panzarino, M. Inside the revolutionary 3d vision

chip at the heart of google’s project tango phone, Feb.
2014. http://tcrn.ch/1fkCuWK.

[31] Paruchuri, J. K., Cheung, S.-C. S., and Hail,

M. W. Video data hiding for managing privacy
information in surveillance systems. EURASIP
Journal on Info. Security (Jan. 2009), 7:1–7:18.

[32] Patel, S. N., Summet, J. W., and Truong, K. N.

BlindSpot: Creating Capture-Resistant Spaces. In
Protecting Privacy in Video Surveillance, A. Senior,
Ed. 2009.

[33] Priyantha, N. B., Miu, A. K. L., Balakrishnan,

H., and Teller, S. J. The cricket compass for
context-aware mobile applications. In Mobile
Computing and Networking (2001).

[34] Quest Visual. WordLens: See the world in your

language. http://questvisual.com/.

[35] Roesner, F., Kohno, T., Moshchuk, A., Parno,

B., Wang, H. J., and Cowan, C. User-driven access
control: Rethinking permission granting in modern
operating systems. In IEEE Symposium on Security
and Privacy (2011).

[36] Schiff, J., Meingast, M., Mulligan, D. K.,
Sastry, S., and Goldberg, K. Y. Respectful
Cameras: Detecting Visual Markers in Real-Time to
Address Privacy Concerns. In International
Conference on Intelligent Robots and Systems (2007).

[37] Shotton, J., Fitzgibbon, A., Cook, M., Sharp,
T., Finocchio, M., Moore, R., Kipman, A., and
Blake, A. Real-time human pose recognition in parts
from a single depth image. In Computer Vision &
Pattern Recognition (2011).

[38] Starner, T. The Challenges of Wearable Computing:

Part 2. IEEE Micro 21, 4 (2001), 54—67.

[39] Templeman, R., Korayem, M., Crandall, D., and

Kapadia, A. PlaceAvoider: Steering ﬁrst-person
cameras away from sensitive spaces. In Network and
Distributed System Security Symposium (NDSS)
(2014).

[40] Tennenhouse, D. L., Smith, J. M., Sincoskie,

W. D., Wetherall, D. J., and Minden, G. J. A
Survey of Active Network Research. IEEE
Communications 35 (1997), 80–86.

[41] The 5 Point Cafe. Google Glasses Banned, Mar.

2013. http://the5pointcafe.com/google-glasses-
banned/.

Ask before photo.
Avoid people in background of photo.
No photos, no Google Glass.
No recording w/in 15 ft. of dressing room.
No cell phone in locker room.
Lanyard color indicates photo preference.

Mercury
Mercury
5Point Cafe
Goodwill
Local Gym
AdaCamp SF
Open Source Bridge Provide notice before taking photo.
Sirens
Sirens
WisCon
Street View

Ask before photo.
No photos during sessions.
Ask before photo.
Blur sensitive areas, no photos over fences.

Figure 10: Existing Real-World Policies. Today, multiple
places request that people follow photo and video policies. We
report a sample set of places, along with the policy they request.
These policies can be captured by our framework.

[42] Tom Simonite. Bringing cell-phone location-sensing

indoors. http://bit.ly/TVyMEx.

[43] Wendlandt, D., Andersen, D. G., and Perrig,

A. Perspectives: Improving SSH-style host
authentication with multi-path probing. In USENIX
Security Symposium (2008).

[44] Zimmermann, P. R. The Oﬃcial PGP User’s Guide.

MIT Press, Cambridge, MA, USA, 1995.

APPENDIX
A. REAL-WORLD POLICIES

We summarize a sample set of real-world locations with
sensor privacy policies (Figure 10) that would beneﬁt from
world-driven access control. These scenarios motivate the
incentive of establishments to install world-driven policies.
The ﬁrst two settings are bars that request patrons refrain
from taking recordings of others without permission. For
example, the 5 Point Cafe recently banned Google’s Glass
device due to privacy concerns [41] and other Glass bans
have followed [15]. Similarly, the “local gym” and “Goodwill”
settings both prohibit recording devices near dressing rooms.
All of these places could specify an explicit “no pictures”
policy for a world-driven access control device.

The next four settings are conventions that set explicit
policies around photography [3], generally requiring asking
before taking a photo or prohibiting recording in certain
times or locations (e.g., during a conference session). One
policy is more ﬁne-grained, based on explicit communication
from attendees using colored lanyards (where a red lanyard
means “no photos,” a yellow lanyard means “ask ﬁrst,” and a
green lanyard means “photos OK”). These colors could serve
as the foundation for a world-driven access control policy. As
suggested in prior work, such individual policies could also
be communicated using a marker on a shirt [36] or via a
communication from the bystander’s phone (e.g., [7, 16]).

Finally, Google’s Street View product, which is powered
by cars that regularly drive through the world and capture
panoramic views, has raised signiﬁcant privacy concerns.
Switzerland only recently allowed Google to collect Street
View data, but it required Google to blur sensitive areas
and refrain from taking pictures across fences and garden
hedges [29]. These policies could also be enforced by world-
driven access control, based on the locations of sensitive ar-
eas or presence of fences.

1181