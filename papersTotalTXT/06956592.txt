2014 IEEE Symposium on Security and Privacy

Dynamic Searchable Encryption via Blind Storage

Muhammad Naveed, Manoj Prabhakaran, Carl A. Gunter

University of Illinois at Urbana-Champaign

Abstract—Dynamic Searchable Symmetric Encryption allows
a client to store a dynamic collection of encrypted documents with
a server, and later quickly carry out keyword searches on these
encrypted documents, while revealing minimal information to the
server. In this paper we present a new dynamic SSE scheme that is
simpler and more efﬁcient than existing schemes while revealing
less information to the server than prior schemes, achieving fully
adaptive security against honest-but-curious servers.

We implemented a prototype of our scheme and demonstrated
its efﬁciency on datasets from prior work. Apart from its concrete
efﬁciency, our scheme is also simpler: in particular, it does not
require the server to support any operation other than upload and
download of data. Thus the server in our scheme can be based
solely on a cloud storage service, rather than a cloud computation
service as well, as in prior work.

In building our dynamic SSE scheme, we introduce a new
primitive called Blind Storage, which allows a client to store a set
of ﬁles on a remote server in such a way that the server does not
learn how many ﬁles are stored, or the lengths of the individual
ﬁles; as each ﬁle is retrieved, the server learns about its existence
(and can notice the same ﬁle being downloaded subsequently), but
the ﬁle’s name and contents are not revealed. This is a primitive
with several applications other than SSE, and is of independent
interest.

I.

INTRODUCTION

In recent years, searchable symmetric encryption (SSE)
has emerged as an important problem at the intersection of
cryptography, cloud storage, and cloud computing. SSE allows
a client to store a large collection of encrypted documents with
a server, and later quickly carry out keyword searches on these
encrypted documents. The server is required to not learn any
more information from this interaction, beyond certain patterns
(if two searches involve the same keyword, and if the same
document appears in the result of multiple searches, but not
the actual keywords or the contents of the documents).

A long line of recent work has investigated SSE with
improved security, more ﬂexible functionality and better ef-
ﬁciency [23], [10], [18], [17], [6]. The techniques in all
these works build on the early work of [10], [9]. In this
work we present a radically different approach that achieves
stronger security guarantees and ﬂexibility, with signiﬁcant
performance improvements. In particular, our construction
enjoys the following features:
• Dynamic SSE, which supports adding and removing docu-
• The server is “computation free”. Indeed, the only opera-
tions that need to be supported by the server are uploading
and downloading blocks of data, if possible, parallelly. This
makes our system highly scalable, and any optimizations in
these operations (e.g., using a content delivery network) will
be directly reﬂected in the performance of the system.

ments at any point during the life-time of the system.

• The information revealed to the server (“leakage functions”)
is strictly lesser than in all prior Dynamic SSE schemes
except [24]. Scheme of [24] reveals less information to the
server at the expense of poly-logarithmic overhead on top of
Dynamic SSE overhead of other schemes (including ours).
• Satisﬁes a fully adaptive security deﬁnition, allowing for
the possibility that the search queries can be adversarially
inﬂuenced based on the information revealed to the server
by prior searches.
• Security is in the standard model, rather than the heuristic
Random Oracle Model; relies only on the security of block
ciphers and collision resistant hash functions.
• Optional document-set privacy. The number of documents
in the system and their lengths can be kept secret, revealing
the existence of a document only when it is accessed by
the client (typically after learning that a keyword appears
in that document). This allows one, for instance, to archive
e-mail with support for keyword searching, while keeping
the number and lengths of e-mails hidden from the server
(until each one is retrieved).

A simple prototype has been implemented to demonstrate the
efﬁciency of the system.

Blind Storage. An important contribution of this work is to
identify a more basic primitive that we call Blind Storage, on
which our Dynamic SSE scheme is based. A Blind Storage
scheme allows a client to store a set of ﬁles on a remote
server in such a way that the server does not learn how many
ﬁles are stored, or the lengths of the individual ﬁles; as each
ﬁle is retrieved, the server learns about its existence (and can
notice the same ﬁle being downloaded subsequently), but the
ﬁle’s name and contents are not revealed. Our Blind Storage
scheme also supports adding new ﬁles and updating or deleting
existing ﬁles. Further, though not needed for the Dynamic SSE
construction, our Blind Storage scheme can be used so that the
actual operation — whether it is reading, writing, deleting or
updating — is hidden from the server.

Though not

the focus of this work, we remark that a
Blind Storage system would have direct applications in itself,
rather than as a tool
in constructing ﬂexible and efﬁcient
Dynamic SSE schemes. As our Blind Storage scheme does
not make requirements on the server other than storage, it can
be used with commodity storage systems such as Dropbox.
This enables a wide range of simple applications that can
take advantage of modular privacy protections to operate at a
large scale and low expense but with strong privacy guarantees.
Applications can range from backing up a laptop to archiving
patient records at a hospital. Further, in our dynamic SSE
scheme, document set privacy with relatively low overhead is
made possible because we can simply store all the documents
in the same Blind Storage system that is used to implement
the SSE scheme.

© 2014, Muhammad Naveed. Under license to IEEE.
DOI 10.1109/SP.2014.47

639

II. RELATED WORK

The problem of searching on encrypted data has received
increasing attention from the security and cryptography com-
munity, with the growing importance of cloud storage and
cloud computation. One of the major hurdles in outsourcing
data storage and management for businesses has been security
and privacy concerns [15], [21], [3]. Theoretical cryptography
literature offers an extremely powerful and highly secure
solution in the form of Oblivious Random Access Memory
(ORAM) [20], [13], which addresses almost all of the security
concerns related to storing data in an untrusted server. How-
ever, this solution remains very inefﬁcient for several important
applications, despite signiﬁcant recent
improvements [22],
[26], [25]. The notion of Symmetric Searchable Encryption
(SSE) — investigated in a long line of works including [23],
[11], [7], [10], [27], [8], [19], [18], [17], [24], among others
— attempts to strike a different balance between efﬁciency
and security, by letting the server learn just the pattern of
data access (and ideally, nothing more), in return for a simpler
and faster construction; further, one often settles for security
against passively corrupt (honest-but-curious) servers. The
scheme of [24] also provides a notion of forward privacy,
which prevents leaking whether a newly added document
contains the keywords the user has already searched for.

The approach in [10] formed the basis for many subsequent
works. The basic idea is to use an index that maps each search
keyword to the list of documents that contains it. This list is
kept as an encrypted linked list, with each node containing the
key to decrypt next node. The nodes of all the linked lists are
kept together, randomly sorted. Until the head of a linked list is
decrypted, it is virtually invisible to the server; in particular, the
number of linked lists and their lengths remain hidden from
the server. This construction provided non-adaptive security
(which assumes that all the search queries are generated at
once); efﬁciently achieving adaptive security has been the
subject of much research starting with [10].

An important aspect of SSE is whether it is dynamic or not:
i.e., whether the client can update the document collection after
starting to search on it. Dynamic SSE schemes were presented
in [11], [27], [18], [17], [5], [24].

Finally, we mention a few variants of the SSE problem that
are not considered in this work. One could require security
against actively corrupt servers, rather than just honest-but-
curious servers. Another variant requires more expressive
searches, involving multiple keywords (e.g., [14], [6], [5]).
One could also require that many clients can perform searches
on a document collection created by a single data-owner
[16]. While we do not consider these problems in this work,
the main new tool we build — namely, a Blind Storage
system — is a general-purpose tool and is likely to be useful
for expressive search queries. Indeed, it could be used to
implement components like the “T-sets” of [6] more efﬁciently.
These and other extensions are subject of on going work.

III. TECHNICAL OVERVIEW

Fig. 1: Contrasting the architecture of existing SSE Schemes (on the
left) with that of the proposed scheme.

our scheme, and in particular, as depicted in Figure 1, from
the fact that our server is computation free.

Techniques. Our main construction is that of a versatile tool
called Blind Storage, which is then used to build a full-ﬂedged
SSE scheme. A Blind Storage scheme lets the client keep all
information — including the number and size — about ﬁles
secret from the server storing them, until they are accessed. In
building the SSE scheme, the search index entries for all the
keywords are stored as individual ﬁles in the Blind Storage
scheme (with care taken to facilitate updates).

Our Blind Storage scheme, called SCATTERSTORE,

is
constructed using a simple, yet powerful technique: each ﬁle is
stored as a collection of blocks that are kept in pseudorandom
locations; the server sees only a super-set of the locations
where the ﬁle’s blocks are kept, and not the exact set of
locations.1 The key security property this yields us is that, from
the point of view of the server, each ﬁle is associated with a
set of locations independent of the other ﬁles in the system.
(Indeed, the sets of locations for two ﬁles can overlap.)

A rigorous probabilistic analysis shows that for appropriate
the probability that any information
choice of parameters,
about ﬁles not yet accessed is leaked to the server can be
made negligible (say, 2−40 or 2−80), with a modest blow-up
in the storage and communication costs (e.g., by a factor of 4)
over unprotected storage.

The only cryptographic tools used in our scheme are block
ciphers (used for standard symmetric key encryption as well as
for generating pseudorandom locations where the data blocks
are kept) and collision resistant hash functions. The security
parameters for these tools are chosen independently of the
other parameters in the scheme.

Architecture. Most of the previous SSE schemes were pre-
sented as using a dedicated server, that performed both storage
and computation. (See Figure 1.) The computation typically
involved an (unparallelizable) sequence of decryptions. To
deploy such a scheme using commodity services, one would
need to rely not only on cloud storage services, but also
cloud computation services. This presents several limitations.
Firstly, this limits the choice of service providers available to a
user: one could use Amazon EC2 for computation, combined
with Amazon S3 for storage; however, it is not viable to
use Dropbox for persistent storage and Amazon EC2 for
computation, as this would incur high costs for communication
between these two services. Storage and compute clusters are
physically separated in modern data centers. This would add
additional latency in all dynamic SSE schemes except ours, as
data needs to be transmitted from storage nodes to compute
nodes over the data center network. In contrast, our system

In this section, we brieﬂy discuss our techniques and the
advantages of our scheme compared to prior SSE construc-
tions. Most of the advantages follow from the simplicity of

1To the extent that extra blocks are read, our scheme is similar to existing
Oblivious RAM constructions. However, in our case, the overhead of extra
blocks is bounded by a constant factor.

640

StorageProcessingcommand/dataresponseStorageuploaddownloadStorageProcessingcommand/dataresponseStorageuploaddownloadcan be easily implemented using Dropbox or other similar
services which provide only storage. Secondly, relying on
cloud computation makes the deployment less ﬂexible, as it
is harder to change choices like that of the operating system
(due to pricing changes or technical support, for instance).

Another important issue in existing schemes is that one
relies on availability and trust assumptions (e.g., honest-but-
curious) for both computation and storage. Clearly, it is desir-
able to trust storage alone, as is the case in our scheme. Fur-
ther, in ongoing work, we consider obtaining security against
actively corrupt (rather than honest-but-curious) servers; this is
easier and more efﬁcient to achieve starting from our scheme,
since we need to enforce honest behavior on part of a server
that provides storage alone.

Finally, it is signiﬁcantly cheaper to rely on a cloud-storage
service alone than on cloud computation (plus persistent stor-
age).

Security deﬁnition. An important feature of our schemes
is the stronger and easier to understand security guarantees.
All
the information leaked to the server is fully captured
in relatively simple functionalities. For the Blind Storage
scheme, as shown in Figure 2, each time a ﬁle is accessed,
the functionality FSTORE reveals just a triple (op, j, size) to the
server, where op speciﬁes what the access operation is (read,
write, update or delete), j speciﬁes the last time, if any, the
same ﬁle was accessed, and size speciﬁes the size of the ﬁle.
The functionality FSSE (shown in Figure 7) speciﬁes all the
information revealed by our SSE scheme. It is slightly more
complex, partly because it allows the client to reuse document
IDs. Further, it offers a higher level of secrecy for documents
that are originally in the system, compared to those added later
during the operation of the system.

Fully Adaptive Security. As mentioned in Section I, we
achieve fully adaptive security, without relying on heuristics
like the random oracle model. Technically, this is a conse-
quence of the fact that the server does not carry out any
decryptions. We point out that achieving adaptive security by
making the client do decryptions for the server would not be
viable in existing SSE schemes because a long sequence of
decryptions (that cannot be parallelized) need to be carried
out; several rounds of communication (with attendant network
delays) would be necessary if the client carries out
these
decryptions for the server. Nevertheless, a similar approach
was mentioned in [6] as a theoretical solution to avoid the
Random Oracle Model and retain adaptive security.

The price we pay for the improved security, greater com-
putational efﬁciency, parallelizability and simpler architecture
is that the server storage and communication costs are possibly
higher than that of some of the existing schemes (e.g., a factor
of 2 to 4 over unprotected storage, which is in fact, comparable
to overheads incurred in some other schemes like that of
[6]). Also our SSE scheme could, in principle, involve up to
three rounds of communication for retrieving the documents
(this happens if the keyword has a large number of matching
documents). In contrast, many existing schemes involve only
two rounds (one to retrieve encrypted list of documents, and
one to retrieve the documents themselves).

641

Comparative Performance. The most natural prior work
for us to compare against is [18] (though, unlike this work,
it uses the Random Oracle Model). We remark that
the
more recent work of [6] augments the functionality of [18]
(but without support for dynamic updates), and provides a
highly streamlined implementation over very large scale data;
however, for the task of simple keyword searches, its algorithm
remains comparable to [18]. Since [18] reports performance of
a prototype implemented in a comparable environment as ours
(conservative comparison: we use a laptop and they used a
server), we compare with it. Asymptotically, the client-side
storage and computation in our system is same as [18], but
the constants for our scheme are much better, and is reﬂected
in the performance measured. Our scheme completely avoids
server-side computation (which is quite signiﬁcant in [18]).

IV. BLIND STORAGE

As mentioned in Section I, an important contribution of this
paper is to identify a versatile primitive called Blind Storage.
It allows a client to store a set of ﬁles with a remote server,
revealing to the server neither the number nor the sizes of the
ﬁles. The server would learn about the existence of a ﬁle (and
its size, but not the name used by the client to refer to the
ﬁle, or its contents) only when the client retrieves it later. We
also allow the client to add new ﬁles, and to update or delete
existing ﬁles. The client’s local storage should be independent
of the total amount of data stored in the system.

In this section, ﬁrst we present

the deﬁnition of a
Blind Storage system, followed by an efﬁcient construction
SCATTERSTORE, and a proof of security. Later,
in Sec-
tion V-B, we show how to build a Dynamic SSE scheme using
a Blind Storage system.

A. Deﬁnition

Below, ﬁrst we deﬁne the syntax of a Blind Storage system
(and the infrastructure it needs), followed by the security
requirements on it.

The Syntax. A blind storage system consists of a client and a
“dumb” storage server. The server is expected to provide only
two operations, download and upload. The data is represented
as an array of blocks; the download operation is allowed to
specify a list of indices of blocks to be downloaded; similarly,
the upload operation is allowed to specify a list of data blocks
and indices for those blocks.

A blind storage system is deﬁned by three polynomial-time
algorithms on the client-side: BSTORE.Keygen, BSTORE.Build
and BSTORE.Access. Of these, BSTORE.Access is an interactive
protocol.
• BSTORE.Keygen takes security parameter as an input and
outputs a key KBSTORE (typically a collection of keys for the
various cryptographic primitives used). Note that KBSTORE,
which the client is required to retain throughout the lifetime
of the system, is required to be independent of the data to
be stored.

• BSTORE.Build takes as input (KBSTORE, d0,{idi, datai}t

i=1,
where KBSTORE is a key, d0 is an upperbound on the total
number of data blocks to be stored in the system, (idi, datai)
are the id and data of the ﬁles that the system to be initialized

• On receiving the command FSTORE.Build from the client:

• On receiving the command FSTORE.Access(id, op) from the client:

i=1) from the client (where d0 is an upperbound on the total number of data blocks to be stored

in the system at any time, and the rest specify ﬁles to be stored in the system initially); it internally stores the speciﬁed ﬁles.

◦ FSTORE accepts input (d0,{idi, datai}t
◦ Build Leakage: In addition, FSTORE sends d0 to the server.
◦ If no ﬁle matching the identiﬁer id exists, and the operation op ∈ {read, delete}, FSTORE returns a status message to the client indicating
so. Else, if op = read, FSTORE returns the ﬁle with identiﬁer id; if op = delete, it is removed. If op = write, the content data for the
ﬁle is also accepted from the client, and the ﬁle is created or its content replaced with data. If op = update, FSTORE interacts with
the client as follows:
FSTORE returns the current size of the ﬁle (in blocks – possibly 0, if the ﬁle does not exist) to the client.
FSTORE accepts the size of the updated ﬁle from the client.
FSTORE returns the current contents of the ﬁle to the client.
FSTORE accepts the updated contents of the ﬁle from the client. The ﬁle stored internally is updated with this.

◦ Access Leakage: In addition, FSTORE sends the tuple (op, j, size) to the server where:

op speciﬁes what the current access operation is,a
j is the last instance when the same ﬁle was accessed (j = 0 means that this ﬁle was not accessed before)
size is the size (in number of blocks) of the ﬁle being accessed. For the update operation, size is the larger of the sizes before and
after the update.

aA reﬁned version of Blind-Storage would require the operation to be not revealed. See Section IV-B3.

Fig. 2: The FSTORE functionality: all the information leaked to the server in our Blind Storage scheme is speciﬁed here.

with; it outputs an array of blocks D to be uploaded to the
server.
• BSTORE.Access takes as input a key KBSTORE, a ﬁle id id,
an operation speciﬁer op ∈ {read, write, update, delete},
and optionally data data (if op is write or update). Then
it interacts with the server (through the upload/download
interface) and returns a status message and optionally ﬁle
data (for the read and update operations). For the update
operation, BSTORE.Access allows more ﬂexibility:2 ﬁrst it
requires only id as input, and outputs the current size of the
ﬁle with that ID; then it accepts as input (an upperbound
on) what the size of the ﬁle will be after update; then it
outputs the current ﬁle data, and only then requires the new
data with which the ﬁle will be updated.

Security Requirement. We specify the security requirement
of a blind-storage system following the “real/ideal” paradigm
that is standard for secure multi-party computation (as opposed
to using speciﬁc game-based security deﬁnitions used in some
of the earlier literature on SSE). This includes specifying
an adversary model and an “ideal functionality,” as detailed
below. The formal security requirement we shall require is
that of Universally Composable security [4] (but restricted to
our adversary model).3

In the adversary model we consider,

the adversary is
allowed to corrupt only the server passively — i.e., as an
honest-but-curious adversary. (If the client is corrupt, we need
not provide any security guarantees.)

The ideal functionality is speciﬁed as a virtual trusted
third party FSTORE
that mediates between the client and
the server (modeling the information leaked to the server).
FSTORE accepts two commands from the client: FSTORE.Build
and FSTORE.Access, along with inputs to these commands
2One can always use a read followed by a write to get the effect of an

update, but this is less efﬁcient and potentially reveals more information.

3We remark that for our setting of passive adversaries, UC security is
a conceptually simpler notion than for the setting of active adversaries.
Nevertheless, for the sake of concreteness, we use the UC security model,
which automatically ensures security even when the inputs to the client are
adaptively chosen under adversarial inﬂuence.

(which are identical
to the inputs to BSTORE.Build and
BSTORE.Access as described above, except
the key
KBSTORE). In this ideal model, it is FSTORE which maintains the
collection of ﬁles, and performs all the operations speciﬁed by
the FSTORE.Build and FSTORE.Access commands. In addition,
it reveals limited information to the server as speciﬁed in
Figure 2.

for

We stress that all the information revealed to the server by
our blind-storage scheme is captured by the FSTORE functional-
ity. Note that the information leaked (during FSTORE.Build and
FSTORE.Access) is limited and simple to specify. This simplicity
is one of the important contributions of this work.
Remark. Even when using the ideal FSTORE functionality, an
adversary can learn some statistics about the ﬁles and accesses
by analyzing the patterns in the information revealed to it.
Such information could indeed be sensitive, and it is up to
the higher-level application that uses a blind-storage system to
ensure that this is not the case. The cryptographic construction
seeks to only match the guarantees given by FSTORE.

B. Our Construction

a

shall

present

version,

simpliﬁed

Our Blind Storage construction is called SCATTERSTORE.
First, we
called
SCATTERSTORE-LITE, which already involves most of
the critical components in the full construction. The only
drawback of the simpliﬁed construction is that the client is
required to maintain a data structure to map each ﬁle-name to
a small piece of information. This solution is well-suited for
a scenario when the system consists of a moderate number
of large ﬁles. In our ﬁnal construction, we show how to
avoid this local data structure, so that the client’s storage is
of constant size, independent of the number of ﬁles in the
system.

1) Simpliﬁed Construction: SCATTERSTORE-LITE: In this
section, we present a sketch of SCATTERSTORE-LITE, our
simpliﬁed Blind-Storage construction. We defer a formal
description to the next section where we present
the full
construction.

642

The construction relies on the following primitives:
– a full-domain collision resistant hash function (CRHF), H,
– a pseudorandom function (PRF), Φ,
– a full-domain pseudorandom function (FD-PRF), Ψ (implemented by applying Φ to the output of H),
– a pseudorandom generator (PRG), Γ.
(In our prototype, as described in Section VI, the implementation of Φ, Ψ and Γ all rely on the AES block-cipher; H is implemented using
SHA-256.) The security parameter k is an implicit input to all the cryptographic primitives used in the construction. The other parameters
in the construction are the size parameters nD, mD, an expansion parameter α > 1, and the minimum number of blocks communicated in
each transaction, κ.
• BSTORE.Keygen: A key KΦ for the PRF Φ, and a key KID for the FD-PRF Ψ are generated; KBSTORE is set to be the pair (KΦ, KID).
• BSTORE.Build(F, KBSTORE): F is a list of ﬁles f = (idf , dataf ). Below sizef denotes the number of blocks in an encoding of dataf; each
block has two short header ﬁelds containing a version number initialized to 0, and H(idf ); the latter is not allowed to be all 0s, which
is reserved to indicate a free block. In addition, the ﬁrst block has a header ﬁeld that records sizef. (It will be convenient to keep the
version number ﬁeld at an extreme end of the block, as it needs to kept unencrypted, whereas the rest of the block will be encrypted at
the end of this phase.)
◦ Let D be an array of nD blocks of mD bits each.
◦ Initialize every block in D with all 0s (to be encrypted later).
◦ For each ﬁle f in F,

1) Generate a pseudorandom subset Sf ⊆ [nD], of size |Sf| = max((cid:100)α · sizef(cid:101), κ) as follows.

a) Generate a seed σf = ΨKID (idf ) for the PRG Γ.
b) Let Sf be the set of integers in the sequence Λ[σf ,|Sf|]. Here Λ[σ, (cid:96)] denotes a sequence of (cid:96) integers obtained as follows.
Generate a (sufﬁciently long) output from the PRG Γ, with seed σ, and parse it as a sequence of integers in the range [nD].
Λ[σ, (cid:96)] is the ﬁrst (cid:96) distinct integers in this sequence.

2) Check if the following two conditions hold:

at least sizef blocks in D that are indexed by the numbers in Sf are free;
at least one block in D that is indexed by the numbers in S0
f

is free.

If either condition does not hold, abort. By the choice of our parameters, this will happen only with negligible probability.

3) Pick a pseudorandom subset (cid:98)Sf ⊆ Sf of size |(cid:98)Sf| = sizef, such that the blocks in D that are indexed by the numbers in (cid:98)Sf are
order; we pick the shortest preﬁx of this sequence that contains sizef numbers indexing free blocks, and let (cid:98)Sf be the set of these
4) Write the sizef blocks of dataf onto the blocks in D that are indexed by the numbers in (cid:98)Sf (in increasing order). These blocks get

all free. For convenience, we shall rely on the fact that the numbers in the sequence used to generate Sf are in a pseudorandom

sizef numbers.

marked as not free.

◦ Encrypt each block of D using the PRF Φ and the key KΦ. The version number ﬁeld is left unencrypted, while the rest is encrypted
using the version number (initialized to 0) and the index number of the block as IV. More precisely, for the ith block D[i], we split it
as vi||B[i] (vi being the version number), and then update B[i] to B[i] ⊕ ΦKΦ (vi||i).
(If the block-size of the PRF is less than the size of the block B[i], then a few lower-order bits of the IV are reserved for use as a
counter, to obtain multiple blocks from the PRF for a single block in D.)

Fig. 3: SCATTERSTORE: A Blind-Storage Scheme (continued on next page)

In our construction, each ﬁle in the blind storage system
is kept in a large array D of encrypted blocks, at positions
indexed by a pseudorandom set. This set is deﬁned by a
short seed and the size of the set: the seed can be used to
generate a (virtually inﬁnite) pseudorandom sequence, and the
size speciﬁes the length of the preﬁx of this sequence that
deﬁnes Sf. In our simpliﬁed construction, the client stores this
information in a data-structure that maps the ﬁle-names to the
descriptor of the pseudorandom set.4

The main security property that we need to ensure is that
the location of the blocks of one ﬁle does not reveal any
information about the blocks of the other ﬁles, or even the
proportion of occupied and free blocks in D.5 However, clearly,
we cannot choose the positions to store blocks of one ﬁle
independent of the blocks of the other ﬁles, since two ﬁles
must not occupy the same block. A naïve solution would be to

4Only the size of the pseudorandom set needs to be stored. The seed for
the set can be derived by applying a (full-domain) pseudorandom function to
the ﬁle-name. See next section.

5This property manifests itself in the simulation based proof of security,
since the simulator will pick the locations of blocks of a ﬁle being accessed
independent of the number and size of ﬁles that are not yet accessed.

use a large D, to reduce the probability that the blocks chosen
for one ﬁle do not overlap with that for any other ﬁle. But
this is problematic, because to reduce the probability of such
a collision to a small quantity (say, negligible in the security
parameter), size of D needs to be enormously larger (i.e., a
super-polynomial factor larger) than the actual amount of data
stored.

We overcome this inherent tension between collision proba-
bility and wasted space as follows. To store a ﬁle f of n blocks,
we choose a pseudorandom subset Sf of not n blocks, but say
(for a typical setting of parameters), 2n blocks. This subset of
2n blocks will be chosen independent of the other ﬁles in the
system (and it is this subset that the server sees when the client

accesses this ﬁle). Within this set we choose a subset (cid:98)Sf ⊆ Sf
of n blocks, where the actual data is stored. The set (cid:98)Sf is of
about (cid:98)Sf (except its size).

course, selected depending on the other blocks used by other
ﬁles, to avoid collisions. However, since the contents of the
blocks are kept encrypted, the server does not learn anything

This, it turns out, allows D to be only a small constant
factor larger than the total data to be stored in the system.

643

as well.

8) Accept as input new contents data(cid:48) encoded as size(cid:48)

empty, combine these blocks together (in increasing order of their indices) to recover the entire contents of the ﬁle, and output it.

6) Some of the blocks indexed by Sf would have already been decrypted in Step 2 above. Decrypt the remaining blocks indexed by Sf,

7) Identify (cid:98)Sf as the set of indices of blocks belonging to the ﬁle being accessed (by checking if their headers match idf). If (cid:98)Sf is not
9) Identify a subset (cid:98)S(cid:48)
are either marked as belonging to idf (i.e., in (cid:98)Sf) or are free.
f ⊆ Sf.

If no such preﬁx exists, or if the ﬁrst of the size(cid:48)
abort; again, by the choice of our parameters, this will happen only with negligible probability.
Note that if size(cid:48)

f as follows. Find the shortest preﬁx of the sequence Λ[σf , (cid:96)] which contains size(cid:48)

f ⊆ Sf of size size(cid:48)
f < sizef, then (cid:98)S(cid:48)

f blocks identiﬁed is not within Λ[σf , κ] (this can happen only when sizef = 0), then

f ⊆ (cid:98)Sf; else, (cid:98)Sf ⊆ (cid:98)S(cid:48)

f < sizef mark as free the blocks indexed by (cid:98)Sf \(cid:98)S(cid:48)

10) Then update the blocks indexed by (cid:98)S(cid:48)

11) Encrypt all the blocks indexed by Sf using the IV vi||i as described in the BSTORE.Build step, but after incrementing vi for each

f with the blocks of data(cid:48). If size(cid:48)

f blocks that

f blocks.

f .

block.

• BSTORE.Access(idf , op, KBSTORE): We describe the case when op = update, and mention how the other operations differ from it.

f from D.

blocks indexed by S0

2) Decrypt the blocks of D[S0

1) First, compute σf = ΨKID (idf ), and deﬁne the set S0

f of size κ, to consist of the numbers in the sequence Λ[σf , κ]. Retrieve the
f ] (where D[i] = (vi||B[i]) is decrypted as B[i]⊕ ΦKΦ (vi||i)), in the order in which they appear in Λ[σf , κ],
until a block which is marked as belonging to idf is encountered. If no such block is encountered the ﬁle is not present in the system.
In this case, set sizef = 0.

the ﬁle sizef from the header of this block.

3) Otherwise (if a block marked as belonging to idf is found), this is the ﬁrst block of the ﬁle with identiﬁer idf: recover the size of
4) Output sizef to the client and accept as input size(cid:48)
5) Let (cid:96) = (cid:100)α · max(sizef , size(cid:48)

f . Else, let Sf be the set of numbers in Λ[σf , (cid:96)]. In this case, retrieve the blocks

f )(cid:101). If (cid:96) ≤ κ, let Sf = S0

f, the size of the ﬁle after update.

indexed by Sf \ S0

f from the server.

back, with their version numbers incremented by 1, and reencrypted.

12) Upload the newly reencrypted blocks back to the server. Note that all the blocks that were downloaded, i.e., D[Sf ], are uploaded
• When op = read, the Steps 1 through 7 from above are carried out, but setting size(cid:48)
• When op = write, the behavior is the same as when op = update, except that the new ﬁle data is taken as input upfront, and no data
• When op = delete, the behavior is the same as when op = write, except that it takes size(cid:48)

is returned.

f = 0.

f = 0.

Fig. 4: SCATTERSTORE: A Blind-Storage Scheme (continued from Figure 3)

A typical parameter setting would be to let D have 4 times
as many blocks as total data blocks to be stored. Then, we
can drive the information leaked to the server to a negligible
quantity with only small constant factor overheads in the
storage and communication.6

An important feature of our pseudorandom set construction,
compared to linked-list based construction of related work
in the literature, is that the server need not carry out any
decryptions. In linked-list based constructions, each node in
the list is progressively revealed; even if the server were to
take the help of the client in decrypting each node, several
rounds of communication will be required.7 In contrast, our
construction allows the server to be “crypto-free” and still have
only constant number of rounds of interaction.

This simplicity leads to another advantage: our construction
meets a fully adaptive security deﬁnition for blind storage (and
for searchable encryption) against honest-but-curious servers.
Here, adaptive security refers to the fact that the choice of
which ﬁles the client needs to access can be adversarially
inﬂuenced, after the system has been deployed. Prior work re-
quired less efﬁcient and more complicated schemes to achieve
adaptive security, and often employed the Random Oracle

6We note that the pseudorandom set Sf would have to be at least a minimum
size κ (say, κ = 80 blocks); when accessing small ﬁles which are just a few
blocks long (i.e., n is small), 2n will be less than this minimum. For such
ﬁles, the communication involves an additive overhead equal to this minimum.

However, the number of blocks occupied in D, i.e., size of (cid:98)Sf, is always n,

irrespective of n being small or large.

7In our full construction, the server does take the help of the client to carry
out a decryption and to recover the description of the pseudorandom set; but
this involves only one round of communication.

heuristics [18], [10]. We use only standard primitives (PRFs
and collision-resistant hash functions) and obtain security in
the standard model (i.e., not in the Random Oracle model).

Finally, our pseudorandom set construction easily supports
a dynamic blind-storage scheme. We sketch the update opera-
tion (creating and deleting a ﬁle are essentially special cases
of the update operation). To update a ﬁle, the client retrieves
the encrypted blocks corresponding to the ﬁle’s pseudorandom

set Sf, decrypts them, updates the subset of blocks (cid:98)Sf where

the ﬁle’s blocks are present, reencrypts all of the downloaded
blocks (i.e., all of Sf), and uploads them back to the server.
There are two details worth highlighting:
• Encryption of each block is carried out by XOR-ing the
contents of the block with the output of a PRF, which keyed
using a ﬁxed secret key, but whose inputs depend on the
block: this input consists of the block’s index in D and its
current version number. (The version number is speciﬁc to
each block, and it is kept unencrypted in the block.) Initially,
all blocks have version number 0, and when reencrypting a
block, its version number is incremented.
• In the above process, the updated ﬁle may need fewer or
more blocks than the original ﬁle. We let the size of the
set Sf that is retrieved to correspond to the longer of the
two versions of the ﬁle. If the updated version needs fewer
blocks than the original ﬁle (in which case Sf corresponds
to the original ﬁle), the extra blocks are marked as free. If
the updated ﬁle needs more blocks, then the subset Sf that is
retrieved corresponds to the size of the ﬁle after the update;

then, additional empty blocks are located in Sf to extend (cid:98)Sf

to be large enough for the updated ﬁle. In either case, the

644

server sees the size of the larger of the two versions.

2) Full Construction: SCATTERSTORE: We present

the
details of our ﬁnal Blind Storage scheme in Figure 3 and
Figure 4. Here we give a brief sketch of the main ideas.

In the simpler scheme above, we allowed the client to
maintain a data-structure mapping a ﬁle-identiﬁer idf
to a
descriptor of the pseudorandom set Sf. This is not desirable
if the system would store a large number of small ﬁles; then
the size of this data structure is comparable to that of the
entire collection of ﬁles. We would like our client to store only
a constant number of cryptographic keys, so that its storage
requirement does not grow with the size of the entire set of
ﬁles stored in the system.

For this, recall that the two pieces of information needed to
deﬁne a pseudorandom set Sf are a seed and the size of the set.
The seed itself can be obtained by applying a full-domain PRF
to the ﬁle-identiﬁer. (A full-domain PRF can be implemented
using a full-domain collision resistant function (CRHF) and a
normal PRF: an arbitrary-length ﬁle-identiﬁer is ﬁrst hashed
to a ﬁxed-length input for the PRF using the CRHF.) If the
client knew the size of Sf as well, there will be no need to
store this map at all. We exploit this to use a two-level access
to a ﬁle, as follows.

For each ﬁle, the ﬁrst block consists of a header that stores
the size (number of blocks) of the ﬁle. To retrieve a ﬁle
idf, the client assumes that the ﬁle is “small” and retrieves
a pseudorandom set S0
f with the smallest possible number of
blocks, i.e., κ. After recovering the ﬁrst block of the ﬁle from
the blocks in S0
f , the client computes the actual size of Sf
and if it is larger than κ, then retrieves the rest of Sf from
the server. (Note that Sf is simply a superset of S0
f , obtained
from a longer pseudorandom sequence.) We remark that it is
important for security that when |Sf| > κ the client performs
this second access, even if the entire ﬁle happened to ﬁt within
the blocks in S0
f .

The update functionality as we have deﬁned, ﬁts well into
this two-level access. To update a ﬁle idf, ﬁrst the client is
allowed to learn the current size of the ﬁle before providing any
information about the update; this size information is retrieved
after the ﬁrst level of access and returned to the client. (Note
that we could have in fact provided the client with the ﬁrst few
blocks of the current ﬁle too, but for simplicity we omit this
from the speciﬁcation of the functionality.) Next, before the
second level of access, the larger of the current ﬁle size and
updated ﬁle size needs to be known. So at this point, we require
the client to submit the size of the updated ﬁle. Then the size
of the set Sf to be retrieved is deﬁned by the larger of the
current and updated sizes. If this set has more than κ blocks,
the second level of access retrieves the remaining blocks; then,
as in the simpler construction, all the retrieved blocks will be
reencrypted (with a subset of them having updated contents)
and uploaded back on the server.

3) Variations and Enhancements: There are several opti-
mizations and variations to this construction that would be of
interest. We mention a few.
• The time taken for the read operation can be signiﬁcantly
improved as follows. As presented above, in reading ﬁle, the
client retrieves a pseudorandom subset of blocks from the

server, and decrypts all of them. Of these, the blocks that
actually contain data from this ﬁle are identiﬁed from each
block’s header. Since decryption is the most computationally
intensive operation, if we can avoid decrypting the blocks
not belonging to the ﬁle being read, we can speed up
the operation by a constant factor (namely, α, a parameter
discussed later). This is indeed possible by storing the
relevant information in the ﬁrst block of the ﬁle. Note that
we still need to sequentially decrypt a few blocks (for our
choice of parameters, up to four blocks, in expectation)
before the ﬁrst block of the ﬁle is encountered.
• Almost all our operations — especially the computationally
intensive parts involving encryption and decryption — are
“embarrassingly parallel.” For instance, a set of blocks
received from the server can be decrypted in parallel and
assembled together using an array pre-allocated to hold all
the blocks in the ﬁle.
• Our construction can be easily extended to meet a stronger
security requirement, that the server does not learn the kind
of operation (read, write or update) performed by the client
(beyond what it can infer from the access pattern). For
this, we shall use the update operation in place of every
operation, since it offers the facility of reading and writing.
(If this is used for actual updates — which allow read and
write in the same operation — and if the data being written
depends on the date being read, then care should be taken
to avoid observable delays that can lead to a timing attack.)

C. Security Analysis

We sketch a proof of security that our construction is a se-
cure realization of the deal blind storage functionality FSTORE,
for the adversary model in which the server is corrupted only
passively. The proof follows the standard real/ideal paradigm
in cryptography (see [12], for instance), and uses some of the
standard conventions and terminology.

Roughly, the proof involves demonstrating a simulator S
which interacts with a client only via the ideal functionality
FSTORE (the ideal experiment), yet can simulate the view of the
server in an actual interaction with the client in an instance of
our scheme (the real experiment). The simulated view would
be indistinguishable from the real view of the server, even
when combined with the inputs to the client. Further — and
this is the adaptive nature of our security guarantee — the
inputs to the client at any point in either experiment can be
arbitrarily inﬂuenced by the view of the server till then.

Before describing our simulator, we describe the main
reason for security. Suppose the client makes a read access to a
ﬁle f for the ﬁrst time. In the ideal experiment, the server learns
this ﬁle’s size from FSTORE, and nothing about the other ﬁles.
In the real experiment, the server sees one or two downloads
f and a set of blocks Sf \ S0
from D— a set of κ blocks S0
f
(with the possibility that Sf = S0
f , in which case there is only
one download). Thanks to the encryption, it is easy to enforce
that the contents of these downloaded blocks give virtually
no information to the server (beyond the size of f). But we
need to ensure that the location of these blocks also do not
reveal anything more. For instance, it should not reveal how
many other ﬁles are present in the system. In our construction,
this is ensured by the fact that the pseudorandom subsets S0
f
and Sf are determined by a process that is independent of the

645

The simulator S interacts with the functionality FSTORE on the one hand, and interacts with the server on the other, translating each message
it receives from FSTORE into a set of simulated messages in the interaction between the client and the server in our scheme.
1) When it receives the initial message from FSTORE with the system parameters, S can calculate the size of D; it simulates the contents
2) S initializes a map with entries of the form (j; Λj, sizej), which maps an integer j (indicating the sequence number of accesses) to a

of the blocks in D by picking uniformly random bit strings, with the version number in each block set to 0.

sequence of blocks in D and the size of the ﬁle accessed (in blocks).
The maps are initialized to be empty, and is ﬁlled up as FSTORE reports ﬁle accesses to S.
3) For access number j∗, ﬁrst the table entry (j∗; Λj∗ , sizej∗ ) is created as described below.
Let the triple reported by FSTORE to S for access number j∗ be (op, j, size). Recall that if j > 0, then the ﬁle being accessed has already
been accessed (as the jth access).
a) If op = delete, then let sizej∗ = 0. Else, set sizej∗ = size. Let (cid:96) = max((cid:100)α · sizej∗(cid:101), κ).
b) If j = 0, then S samples a random sequence of (cid:96) distinct integers in the range [nD], uniformly randomly, and sets Λj∗ to be this
c) Else (j > 0), if |Λj| ≥ (cid:96), set Λj∗ = Λj; else (j > 0, and |Λj| < (cid:96)), extend Λj to a sequence of length (cid:96) uniformly at random
4) Next, S creates the simulated view in which ﬁrst the server gets a request to download κ blocks indexed by the ﬁrst κ entries of Λj∗;
if (cid:96) > κ, this is followed by a request to download blocks indexed by the next (cid:96) − κ entries of Λj∗. For operations other than read,
this is followed by an upload consisting of new versions (with the blocks’ version numbers incremented, and with fresh random strings
as contents) of the blocks indexed by the ﬁrst (cid:96) entries of Λj∗.

(without duplicates). Set Λj∗ to be this extended sequence.

sequence.

Fig. 5: Description of the simulator S used in the proof of Theorem 1.

other ﬁles in the system – they are chosen randomly (or rather,
pseudorandomly) for each ﬁle independently. The other ﬁles in

the system inﬂuence the subset (cid:98)Sf ⊆ Sf of blocks that actually
the encryption, the server does not learn anything about (cid:98)Sf

carries the data (because these blocks must not be shared with
the data-carrying blocks of any other ﬁle). However, due to

(beyond the fact that it must be a subset of Sf).

Formally, a simulator can simulate the view of the adver-
sary randomly, based only on the size of the ﬁle f being
accessed. The only difference between this simulation and
the real execution (beyond what is hidden by the encryption
and the security of pseudorandomness) is the following: in
the real execution, there is a small probability that an update
could fail, if there are not enough free blocks within the
pseudorandom subset S0
f or Sf. In the simulation, no failure
occurs. Thus the crucial argument in proving security is to
show that it is only with negligible probability that the client
would be left without adequate number of free blocks in such
a pseudorandom set, forcing it to abort the protocol. We will
give a standard probabilistic argument to prove that this is
indeed the case.

In the proof below we describe our simulator S more
formally, and then discuss the main combinatorial argument
used to show that the simulation is indistinguishable from the
real execution. For the sake of clarity, we leave out some of
the routine details of this proof, and focus on aspects speciﬁc
to our construction.

The following theorem statement is in terms of the “storage
slack ratio” in a Blind Storage system, which is the ratio of the
number of blocks nD in the system to the number of blocks
of (formatted) data in the ﬁles stored in the system. Note
that the storage slack ratio decreases as ﬁles are added (or
updated to become longer) and increases as ﬁles are deleted
(or updated to become shorter). The security guarantee below
uses the standard security deﬁnition in cryptography literature
(see, for instance, [12]), which assures that the security “error”
(statistical distance between the simulated execution and the

646

real execution) is negligible,8 as a function of the security
parameter. Later, we discuss the choice of concrete parameters.
Theorem 1: Protocol SCATTERSTORE securely realizes the
functionality FSTORE against honest-but-curious adversaries,
provided the storage slack ratio at all times is at least
1−1/α
and nD ≥ κ = ω(log k).

2

Proof: The non-trivial case is when the server is corrupt
(honest-but-curious) and the client is honest. We describe a
simulator for this setting in Figure 5. The simulator essentially
maintains the indices of the sets of blocks seen by the server.
It need not maintain the subsets within these sets that carry
actual data for the ﬁle being accessed. The maps are used to
maintain consistency in terms of the pattern (same subsets are
used if the same ﬁle is accessed) and the size of the ﬁles.

There are two differences between this simulation and
the real execution. Firstly, the simulated execution uses truly
random strings instead of the outputs from Φ, Φ and Γ. To
handle this we can consider a “hybrid experiment” in which
the real execution is modiﬁed so that instead of Φ, Ψ and Γ,
truly random functions are used. By the security guarantees
of the PRF, the FD-PRF and the PRG (applied one after the
other), this causes only an indistinguishable difference.

The second difference is in aborting: in the real protocol,
the client aborts when it cannot ﬁnd enough free blocks in
a pseudorandom subset, whereas the simulation never aborts.
Conditioned on the protocol never aborting in the hybrid
execution, the server’s view in that execution is identical to
that in the simulated execution.

To complete our proof, therefore it remains to show that
the probability of the client aborting in the hybrid (or real)
protocol
is negligible. We denote this probability by perr.
Before proceeding, we remark that our goal here is to give an
asymptotic proof of security (showing that perr goes down as
a negligible function of the security parameter). The concrete
8A function ν : N → R+ is said to be negligible if, for every c > 0,
there exists a sufﬁciently large k0 ∈ N such that for all k ≥ k0, ν(k) < 1
kc .
That is, ν(k) becomes smaller than 1/poly(k) eventually, for any polynomial
poly.

parameters from this analysis are overly pessimistic and an
actual implementation can use less conservative parameters.
The key message is that perr provides a bound on the extent
of insecurity, and this probability can be quickly driven down
by modestly large parameters that scale linearly with the size
of the data stored.

To analyze perr, recall that we are analyzing a modiﬁed
execution in which the output of the PRG Γ on pseudorandom
seeds (used to deﬁne the pseudorandom subsets) have been
replaced with truly random strings. Suppose there has been no
abort so far, and a new ﬁle f of sizef blocks is to be inserted into
the system (either during the BSTORE.Build stage of during an
update or write operation). Let d out of the nD blocks in D
be ﬁlled. These blocks were ﬁlled by picking random subsets,
and then within these subsets, choosing random subsets with
free blocks. The net effect is of choosing a random subset
of d blocks out of the nD blocks. Now, when f is being
inserted, we pick a random subset S0
f of size κ and a random
set Sf ⊇ S0
f of size |Sf| = max((cid:100)α · sizef(cid:101), κ). The expected
· |Sf|. By a
number of occupied blocks within this set is d
nD
standard application of Chernoff bound,9 the probability that
|Sf| blocks are occupied is 2−Ω(|Sf|), provided
more than 2 d
nD
is upperbounded by a constant less than 1. Since |Sf| ≥ κ,
d
nD
this probability is 2−Ω(κ), and since κ is super-logarithmic
in k (for e.g., log2 k), this probability is 2−ω(log k) which is
negligible in k. Thus except with negligible probability, of the
|Sf| blocks chosen, at least |Sf|(1− 2 d
) ≥ α· sizef · (1− 2 d
)
are free.

nD

nD

nD

nD

≥ 1

d ≥ 2

By the hypothesis in the theorem statement, the storage
1−1/α, or equivalently, 1 − 2 d
slack ratio nD
α. Thus,
except with negligible probability, of the |Sf| blocks chosen
) ≥ sizef blocks are free. The same analysis
α· sizef · (1− 2 d
shows that S0
f will have at least one free block (in fact, at
least (cid:98)κ/α(cid:99) free blocks), except with negligible probability.
If both these conditions hold, the client will not abort when
adding this ﬁle. By a union bound, the probability that it aborts
remains negligible as long as it adds only polynomially many
ﬁles.

On the choice of parameters. There are a few parameters that
one can set in an implementation of our blind storage scheme
to optimize security levels and performance. For simplicity we
treat perr (which measures the probability that any illegitimate
information is revealed to the server) as ﬁxed at either 2−40
or 2−80. The other important parameters are the following:
• γ, an upperbound on the storage slack ratio — i.e., nD
,
d0
where d0 is an upperbound on the total number of blocks
of all the ﬁles (formatted correctly);

the ratio between the number of blocks in a (large
enough) ﬁle and the number of blocks in the pseudorandom

• α,

9In choosing a random subset of blocks,

the blocks are not chosen
independent of each other. So in order to apply Chernoff bound, we ﬁrst
consider the experiment in which the blocks are selected independent of each
other with the same ﬁxed probability, so that the expected number of blocks
chosen is, say 3/2d. Then, by an application of Chernoff bound, except with
2−Ω(nD) probability, at least d blocks are occupied. Now, in this experiment,
|Sf| blocks in Sf, again using
we bound the probability that more than 2 d
nD
Chernoff bound. This probability is an upperbound on the corresponding
probability in the original experiment.

647

subset which is downloaded/uploaded when that ﬁle is
accessed; and

the minimum number of blocks in a pseudorandom

• κ,

subset.

The higher these parameters, the better the security level would
be. However, they also reﬂect higher storage and communica-
tion costs. One can ﬁnd different combinations of (γ, α, κ)
to meet a security level (probability of “error” in simulation)
using the following explicit upperbound, which is tighter than
the Chernoff bound used for asymptotic analysis above.10

(cid:18)(cid:100)αn(cid:101)

(cid:19)(cid:18) γ − 1

(cid:19)i(cid:18) 1

(cid:19)(cid:100)αn(cid:101)−i

n−1(cid:88)

perr(γ, α, κ) ≤ max
n≥ κ

α

i

γ

γ

i=0

Figure 6 plots various possible combinations of α and κ for
various choices of perr and γ. A few suggested choices of
(γ, α, κ) which achieve perr ≤ 2−40 are (4, 4, 45), (2, 8, 60)
and (4, 8, 25). Thus, for instance, one could use the parameter
setting of (γ, α, κ) = (4, 4, 45) which means that the amortized
storage requirement for each ﬁle and the communication
requirement for reading large ﬁles is roughly 4 times the size
of the ﬁle; however, for small ﬁles – any ﬁle with at most
11 blocks, including empty or non-existent ﬁles – 45 blocks
would be downloaded, decrypted, reencrypted and uploaded
back.

While a very large value of κ would require a large amount
of communication and extra computation on part of the client
(for updates), we recommend moderately large values for κ.
This is because, ﬁrstly, increasing κ does not have any effect on
the storage needed (because only as many blocks are occupied
in D as the actual data consists of), and secondly it actually
provides a higher security guarantee and may slightly increase
the overall efﬁciency too! Apart from lowering perr, another
reason for a higher security guarantee (not captured in FSTORE,
for simplicity) is that the server does not
learn the exact
number of blocks in every ﬁle that is accessed; for “small”
ﬁles, it learns only that the ﬁle is small (at most 11 blocks,
in the above example). The higher the value of κ, the less
the information that the server learns. The potential (slightly)
higher efﬁciency is due to the fact that when a “small” ﬁle
is retrieved, a single round of interaction sufﬁces, and again,
the higher the value of κ, the more the ﬁles that fall into the
“small” category. This does not increase the computational cost
during read operations.

We point out that while α, κ (and nD) are parameters built
into the system speciﬁcation, it is not necessary to have a hard
bound d0 on the number of blocks of D that can be ﬁlled.
In other words, γ and perr exhibit graceful degradation: as the
array D ﬁlls up and γ decreases, perr increases.

Another parameter that affects the choice of these pa-
rameters is the size of the blocks in D. As the block size
decreases, on the one hand, the number of blocks in ﬁles
grows and the effect of the communication overhead due to the
minimum number of blocks used for small ﬁles (the parameter

10The error probability when adding a ﬁle of n ≥ κ

α blocks is up-
perbounded by the probability that when (cid:100)αn(cid:101) blocks are picked (with
replacements) from a set of nD blocks of which at most d0 would be occupied,
i < n distinct blocks that are picked are free. The actual experiment involves
picking blocks without replacement, but for our range of parameters, this gives
a valid upperbound.

κ) decreases; on the other hand, the overhead due to the header
size in each block increases.

An implementation can choose a default standard setting
of the above parameters, or seek to optimize performance by
tuning them to suit the proﬁle of the ﬁles to be stored in
the system. For instance, the set of parameters appropriate
for an application like our SSE construction in the sequel
(in which the keyword index ﬁles are stored in a Blind
Storage system) may be different from those appropriate for
an application storing a relatively small number of large ﬁles.
But it is important that any such optimization is based on a
public proﬁle of the set of ﬁles to be stored in the system.
This is because, conservatively, we should assume that the
server would know all the system parameters (and exact sizes
of the ﬁles accessed). It is true that, heuristically, slightly
better guarantees may be available, since the server learns
only max((cid:100)α · size(cid:101), κ), and need not exactly know α and κ
(except as revealed by the former, combined with any auxiliary
information it may have about the sizes of the ﬁles being
accessed). Further heuristics could be employed to make this
information noisy, so that it remains hard to decipher the
parameters even from a large number of correlated accesses.
Nevertheless, we recommend that the system parameters are
optimized only using information that can be made known to
the server.

Fig. 6: Finding the right parameters. Each line on the graph cor-
responds to trade-offs between α and κ for a choice of perr ∈
{2−40, 2−80} and γ ∈ {4, 8, 16}.

V. SEARCHABLE SYMMETRIC ENCRYPTION

In this section we formally deﬁne the syntax and security
requirements of a dynamic SSE scheme, and also present
an efﬁcient construction. As we shall see, our syntax for a
dynamic SSE scheme is simpler than in [18], since all non-
trivial operations are carried out by the client, and hence, there
are no server side algorithms to be speciﬁed. Our construction

A. Deﬁnitions

A dynamic searchable symmetric encryption scheme (or
simply, SSE) consists of ﬁve probabilistic polynomial time
procedures (run by the client), SSE.keygen, SSE.indexgen,
SSE.search, SSE.add and SSE.remove. These procedures inter-
act with a “dumb” server which provides download and upload
facilities to access blocks in an array (see Section IV-A),
and also a simple ﬁle-system to lookup documents by identi-
ﬁers. Looking ahead, in our implementation, the upload and
download facilities are used to implement a blind-storage
scheme which is used to store the keyword indices, and the

648

ﬁle lookup facility is used to store the actual (encrypted)
documents.11
• SSE.keygen: Takes the security parameter as input, and
outputs a key KSSE. All of the following procedures take
KSSE as an input.
• SSE.indexgen: Takes as input the collection of all the doc-
uments (labeled using document IDs), a dictionary of all
the keywords, and for each keyword, an index ﬁle listing
the document IDs in which that keyword is present.12 It
interacts with the server to create a representation of this
data on the server side.13
• SSE.search: Takes as input a keyword w, interacts with the
• SSE.add: Takes as input a new document (labeled by a
document ID that is currently not in the document collec-
tion), interacts with the server, and incorporates it into the
document collection.
• SSE.remove: Takes as input a document ID, interacts with
the server, and if a document with that ID is present in the
server, removes it from the document collection.

server, and returns all the documents containing w.

Security Requirement. As in the case of blind-storage, we
specify an ideal functionality, FSSE (Figure 7) to capture the
security requirements of a dynamic SSE scheme. We note that
the standard simulation-based security (with an environment)
applied to the functionality FSSE automatically ensures what
has been called security against adaptive chosen keyword
attacks (CKA2-security) for searchable encryption.

The functionality FSSE is described in detail in Figure 7.
If document-set privacy is required,
then the functionality
behaves slightly differently: the original set of documents are
not added to the list of documents ∆ upfront, but each one
is added only at the ﬁrst instance when it is accessed using
FSSE.search or FSSE.remove.

We highlight a few aspects of our security deﬁnition,
compared to that in [18] and prior work. In all forms of
SSE, keyword access pattern and document access pattern are
revealed: i.e., if the same keyword is searched for multiple
times or if the same document appears in multiple keyword
searches, the server learns about that; techniques for hiding
this information incur signiﬁcant costs. The goal of an SSE
scheme is to reveal as little information as possible, beyond this
information. In our scheme we reveal very little information
beyond this, for the original set of documents. For newly added
documents, a little more information is revealed, as they are
added (see Addition leakage in Figure 7). This has the effect
that for every subset of newly added documents, the server
learns only the number of keywords that are common to all
the documents in that subset.

Existing schemes reveal signiﬁcantly more information. For
example, in [18], when a document is removed, the scheme
reveals the number of keywords in the document and further,

11In our scheme, if we opt to have document-set security, then the ﬁle
lookup facility is not used, as the documents will also be stored in the blind-
storage.

12The index ﬁles can be created by SSE.indexgen, if it is not given as input.
13Typically, this would consist of a collection of (encrypted) documents, la-
beled by document indices (different from document IDs), and a representation
of the index, which in our constructions will be stored using a blind-storage
system.

• Initialization. On receiving the command FSSE.indexgen from the client, FSSE accepts a set of ∂0 documents — refered to as the original
documents (as opposed to newly added documents) — and stores them internally in an array ∆. For 1 ≤ ∂ ≤ ∂0, the array stores
∆[∂] = (id∂, contents∂, W∂) — a unique document ID, the document contents and a set of keywords in the document. It also accepts
from the client a number N, which is a (possibly liberal) upperbound on the total number of (keyword, document) pairs that will be
present in the system at any one time. FSSE also maintains a set called Removed initialized to ∅.
◦ Initialization Leakage. FSSE reveals to the server the (N, s1,··· , s∂0 ) where s∂ = |contents∂| (in number of bits).
• Addition. On receiving the command FSSE.add to add a document (id, contents, W) (with a new or existing document ID), FSSE appends
it to the array ∆: i.e., if there are ∂ − 1 entries currently, let ∆[∂] = (id, contents, W). If there exists ∂(cid:48) < ∂ with id∂(cid:48) = id and
∂(cid:48) (cid:54)∈ Removed, then add ∂(cid:48) to Removed.
◦ Addition Leakage. FSSE reveals to the server the updated set Removed and {M new
w = {∂(cid:48)|∂(cid:48) > ∂0 and w ∈
w is the set of newly added documents (i.e., not the original documents) that have the keyword w. Note that only the
• Removal. On receiving the command FSSE.remove, FSSE accepts a document ID id and identiﬁes ∂ (if any) such that id∂ = id and

w , and not their labels w, are shared with the server.
∂ (cid:54)∈ Removed. If such an index ∂ exists, it adds ∂ to Removed.
◦ Removal Leakage. FSSE reveals to the server the updated set Removed.
• Search. On receiving the command FSSE.search, it accepts a keyword w from the client and returns {(id∂, contents∂)|w ∈ W∂ and ∂ (cid:54)∈
Removed} to the client.
◦ Search Leakage. FSSE reveals to the server the last instance the same keyword was searched on (or that it is being searched for the

w |w ∈ W}, where M new

W∂(cid:48)}. i.e., M new
sets M new

ﬁrst time) and also Mw = {∂|w ∈ W∂}.

Fig. 7: The FSSE functionality: all the information leaked to the server in our SSE scheme is speciﬁed here.

for each keyword in it, up to two other documents that share
the same keyword. This is the case even if that keyword is
never searched on. In contrast, by our security requirement, if
an original document is removed, only the number of keywords
in it that are searched can be revealed. Further, it is not
revealed that a removed document shared a keyword with
another document, unless such a keyword is explicitly searched
for.

We remark that our functionality reveals “removed” ver-
sions of the documents in search results, but this information
was revealed (implicitly) by the leakage functions in [18]
as well, as the identiﬁers for each keyword in a removed
document is revealed and this information links the removed
documents to future searches on the same keyword (when the
same identiﬁer for the keyword is revealed).

Finally, our scheme allows the client to refer to a doc-
ument using an arbitrary document ID rather than a serial
number (which is useful when removing documents from the
collection). We also allow the client to reuse document IDs.
The server does learn when a document ID is reused (though
not the actual identiﬁer of the document ID itself); further, in
the pattern information revealed to the server, the different
versions that use the same document ID are differentiated.
Other dynamic SSE schemes often avoid this aspect simply
by not using document IDs. This sufﬁces if the only time
a document
is removed is immediately after retrieving it
from a search (or if the client is willing to maintain a map
from document IDs to serial numbers); however, realistically,
in many applications of a dynamic SSE scheme, it will be
important to efﬁciently remove documents referenced by their
document IDs.

B. Searchable Encryption from Blind Storage

In this section, we describe an efﬁcient dynamic searchable
encryption scheme, BSTORE-SSE, built on top of a blind-
storage scheme. The full details are given in Figure 8. Here
we sketch the main ideas.

First, note that we can implement a static searchable
encryption scheme simply by storing the index ﬁle for each

keyword (which lists all the documents containing that key-
word) in a blind storage system. The guarantees of blind stor-
age readily translate to the security guarantees of searchable
encryption: the server learns only the pattern of index ﬁles
(i.e., keywords) accessed by the client.

In a dynamic searchable encryption scheme, we need to
support adding and removing documents, which in turn results
in changing the index ﬁles. We seek to do this without reveal-
ing much information about the keywords in a document being
added or removed, if those keywords have not been searched
on before. To support dynamic searchable encryption (with
much better security guarantees than previous constructions),
we rely on the following observation. The access pattern that
server would be allowed to learn tells the server if two newly
added documents share a keyword or not, as soon as they
are added and before such a keyword is searched for (but
not whether they share keywords with the original set of
documents that were added when initializing the system). This
means we can treat the set of newly added documents virtu-
ally as a different system, with signiﬁcantly weaker security
requirements.

Thus, for each keyword, we use two index ﬁles: one listing
the original documents that include that keyword, and another
listing the newly added documents that include it. The ﬁrst
index ﬁle is stored with the server using a blind storage
scheme, where as the second can be stored in a “clear storage”
system (see below). Searching for keywords now involves
retrieving both these index ﬁles. Adding documents involves
updating only the second kind of index ﬁles (using an append
operation of the clear storage). Also, removing a newly added
document involves updating only the second kind of index
ﬁles, which is straightforward (except for efﬁciency concerns,
addressed below). But in removing an original document, we
need to ensure that the information on keywords in it that
are not searched for (for e.g., the number of such keywords)
remains secret. This is achieved by a lazy deletion strategy. The
index ﬁle of a keyword (for the original set of documents) is
not updated until that keyword is searched for. At that point, if
the client learns that a document listed in that index has been
deleted, the index is updated accordingly. This update can be

649

The construction uses a blind-storage system BSTORE, and a pseudorandom permutation Ψ(cid:48) for mapping document IDs (with versioning)
to pseudorandom document indices. It also uses a clear-storage system CLEARSTORE (see text).
• SSE.keygen: Let KSSE = (KBSTORE, K∂ID) where KBSTORE is generated by BSTORE.Keygen and K∂ID is a key for the PRP Ψ(cid:48).
• SSE.indexgen:

1) Firstly, for each document ∂, assign a pseudorandom ID η∂ = Ψ(cid:48)
2) For each keyword w that appears in at least one document, construct an index ﬁle with ﬁle-ID indexw that contains η∂ for each
document ∂ that contains the keyword w. No speciﬁc format is required for the data in this ﬁle; in particular, it could contain a
“thumbnail” (of ﬁxed size) about each document in the list.

K∂ID (id∂), where id∂ is the document ID.

3) Next, initialize a blind-storage system with the collection of all these index ﬁles (using BSTORE.Build).
4) Also, (outside of the blind-storage system) upload encryptions of all the documents labeled with their pseudorandom document index

• SSE.remove: To minimize the amount of information leaked, and for efﬁciency purposes, we rely on a lazy delete strategy.

1) Given a document ID id∂, check if a document with index η∂ = Ψ(cid:48)

K∂ID (id∂) exists, and if so remove it, using the ﬁle system interface
of the server. The index ﬁles (in the blind storage or the clear storage) are not updated for the keywords in this document right away,
but only during a subsequent search operation (see below).
• SSE.add: To add a document ∂ to the document collection, ﬁrst call SSE.remove to remove any earlier copy of a document with the

same document ID. Then proceed as follows:
1) Compute a pseudorandom document index η∂ = Ψ(cid:48)
2) Generate a random tag tag and add it to the document (say, as a preﬁx, before or after encrypting the document). Encrypt the

K∂ID (id∂).

η∂.

document and upload it, as in the SSE.indexgen phase, using the label η∂.

3) Then, for each keyword w that appears in this document, use the append facility of the clear-storage scheme to append a record
consisting of (η∂, tag) to the ﬁle with ﬁle-ID indexw to include η∂. Note that the append operation will create a ﬁle in the clear
storage system, if it does not already exist.

• SSE.search: Given a keyword w, retrieve and update the index ﬁles with ﬁle-ID indexw and indexw as follows:

1) Retrieve the index ﬁle indexw from the blind storage system using the ﬁrst stage of update operation of the blind storage scheme.
Also, retrieve the index ﬁle indexw from the clear storage system, using the ﬁrst stage of its update operation. All the documents
containing the keyword w have their document indices listed in these two index ﬁles. Attempt to retrieve all these documents listed
from the server.

2) Some of the documents listed in the index ﬁle indexw could have been removed. Complete the blind storage update operation on

the ﬁle indexw to erase the removed ﬁles from its list, without changing the size of the ﬁle.

3) Some of the documents listed in the index ﬁle indexw may have been removed or replaced with newer versions. Complete the clear
storage update operation on the ﬁle indexw to remove from its list any document that could not be retrieved, or for which the listed
tag did not match the one in the retrieved document. (Both the update operations are completed in the same round).
One could add an extra round to ﬁrst check just the tags of the documents before retrieving the documents themselves.

Fig. 8: Searchable Encryption Scheme BSTORE-SSE

carried out in a single update operation of the blind storage
scheme, with little overhead.

In fact, for removing newly added documents too, we
follow a similar lazy delete strategy, for efﬁciency purposes.
(Otherwise, during a delete operation, the client will need
to fetch the index ﬁles for all the keywords in the deleted
document in order to update them, unless the server is willing
to carry out a small amount of computation.) However, we
need to account for the possibility that a document ID could
be reused and that a later version may not have a keyword
present in an earlier version. We associate a random tag with
a document to check if the version listed in an index is the
same as the current version.

Properly instantiated, this simple idea yields strictly better
security than prior dynamic searchable encryption schemes
[18], [10] which revealed more information about keywords
not searched for, especially when removing documents.

Clear Storage. To store the index ﬁles for newly added
documents, our SSE scheme uses a “clear storage” scheme
CLEARSTORE that supports the following operations:
• Files labeled with ﬁle-IDs can be stored (in the clear, without
any encryption). A two-stage update operation can be used
to read this ﬁle and then write back an updated version
(which could be shorter).

• In addition,

there is an efﬁcient append operation,

that
allows appending a record (of ﬁxed size) to the ﬁle in
constant time (without having to retrieve the entire ﬁle and
update it).

Note that a standard ﬁle-system interface provided by the
server can support all these operations. But the append op-
eration may not be supported by a cloud storage provider. In
this case, it can be implemented by the client, as we consider
in our evaluation.

We consider a simpliﬁed version of the SCATTERSTORE to
implement CLEARSTORE with efﬁcient append. In this imple-
mentation, to store a ﬁle f = (idf , dataf ), the ﬁle data dataf is
stored (unencrypted) in a subset of blocks of a pseudorandom

set (cid:98)Sf ⊆ Sf. We use a separate ﬁle-system interface (without
shortest preﬁx of Sf that contains (cid:98)Sf

append) to store ﬁxed-size header ﬁles labeled with the ﬁle-
name idf; This header ﬁle stores an index indicating the last
block of Sf that is occupied by the ﬁle (i.e., the length of the
14 To append a record to
a ﬁle, the client retrieves the header block via the ﬁle-system
interface, using the ﬁle-name idf. Then it generates Sf, and
recovers the ith block in Sf, where i is the index stored in the
header block. Then it checks if there is enough space in this

14The ﬁrst block of the data could also be stored in the header ﬁle. Note
that then it is possible that the header block itself contains all the data of the
ﬁle; in this case the index indicating the last block is set to 0.

650

last block, and if so adds the record there. Else, it generates κ
more entries in Sf, fetches those blocks from the clear storage,
adds the record to the ﬁrst empty block in this sequence,15
and updates the index of the last block stored in the header
ﬁle accordingly. Note that the number of blocks fetched is a
constant on average provided a block is large enough to contain
(say) κ records; the number of blocks written back is at most
two (and on the average, close to 1).

Choice of parameters. We instantiate BSTORE-SSE with
our SCATTERSTORE constructions. By choosing the parameter
κ for SCATTERSTORE, we can ensure that a single search
operation can typically be completed in one and half rounds
of interaction. This is because the typical size of an index ﬁle
could ﬁt into a few blocks, and by choosing κ = 80 as we
do in our experiments, the index ﬁle can often be retrieved
without having to fetch more blocks. However, in the worst
case (e.g., searching for the keyword “the,” as we report), two
and half rounds of interaction will be needed.
Theorem 2: Protocol BSTORE-SSE securely realizes FSSE
against honest-but-curious adversaries.

Proof Sketch: The security of this scheme is fairly straight-
forward to establish, since it uses the blind storage scheme as
a blackbox, and involves no other cryptographic primitive. All
the information available to the server from the blind storage
scheme as used in this construction (i.e., the access patterns of
the index ﬁles) is easily derived from the information that the
server is allowed to have in the searchable encryption scheme.
In other words, a simulator can simulate to the server all the
messages in the protocol using the information it obtains in
the ideal world. The details are straightforward, and hence
omitted.

VI.

IMPLEMENTATION DETAILS

We implemented prototypes of our blind storage and
searchable encryption schemes. The code was written in
C++ using open-source libraries. We used Crypto++ [1] for
the block cipher (AES) and collision-resistant hash function
(SHA256) implementations.

As our schemes only require upload and download interface
and do not require any computation to be performed on the
server, they can be implemented on commercially available
cloud storage services. As a proof of concept, we further
implemented a C++ API to interface with Dropbox’s Python
API. This enables a Dropbox user to use a C++ implementation
of BSTORE-SSE (using SCATTERSTORE) with Dropbox as
the server. In our Dropbox implementation, each block in the
SCATTERSTORE scheme is kept as a ﬁle in Dropbox. We
recommend using SCATTERSTORE with a block size that is
a multiple of the block size in the cloud storage provider’s
storage (typically, 4KB).

VII. SEARCHABLE ENCRYPTION EVALUATION

For concreteness, we will compare the performance of our
SSE scheme with that of the recent scheme in [18], as one

15Unlike in the case of blind-storage, if no empty block is found among
the blocks fetched, the client can go on to fetch more blocks. This also allows
one to optimistically fetch a smaller number of blocks, without a signiﬁcant
penalty.

of the most efﬁcient dynamic SSE schemes in the literature,
implemented in a comparable setting. The more recent work
of [6] offers a possibly more optimized version of this protocol
(without dynamic functionality), but
is harder to compare
against experimentally, as the reported implementation was in
a high performance computing environment. We remark that
for the case of simple keyword searches (which is not the focus
of [6]), the construction of [6] is similar to that of [10], [18],
and is expected to show similar performance.

We focus on computational costs; space and communica-
tion overheads in the prior constructions are often not reported
making a direct comparison hard.
• The computation times reported are for the client. In our
case the server is devoid of any computation (beyond simple
storage tasks) and hence this constitutes all the computation
in the system. In contrast, in previous SSE schemes, the
server’s computation is often much more than that of the
client. Thus it would already be a signiﬁcant improvement
if our client computation costs are comparable to the client
computation costs in prior work. As we shall see, this is
indeed the case.
• There are several possible engineering optimizations in the
Blind-Storage scheme which can signiﬁcantly improve the
performance of the SSE scheme (for instance, the ﬁrst one
listed in Section IV-B3 cuts down the time taken for the
search operation by a factor of α or more). None of these
optimizations have been implemented in the prototype used
for evaluation.

Datasets. We use two datasets to evaluate our searchable
encryption scheme, emails and documents.
1) For emails we use the Enron dataset [2] which was also
used by [18] and several other works. From the Enron e-
mail dataset, we selected a 256MB subset, consisting of about
383,000 unique keywords and 20,695,000 unique (document,
keyword) pairs. In the experiments involving smaller amounts
of data, subsets of appropriate sizes were derived from these
datasets.
2) For documents, we created a dataset with 1GB of four types
of documents, namely PDF, Microsoft PowerPoint, Microsoft
Word and Microsoft Excel. The documents were obtained by
searching for English language documents with ﬁletypes pdf,
ppt, doc and xls, using Google search. The resulting collection
consists of 1556 documents (roughly evenly distributed among
the four ﬁletypes), with over 214,000 unique keywords and
about 1,372,000 unique (document, keyword) pairs.

Experiments. The code was compiled without any optimiza-
tions on Apple Mac OS X. We used a well provisioned laptop
– with Intel Core i7 3615QM processor, 8GB memory, running
Mac OS X 10.9 – for the experiments, keeping in mind that
the typical user of our system will use searchable encryption
on a cloud via her personal computer, just the same way a
cloud storage service like Dropbox is used. This is in contrast
with prior research which typically evaluated their work on
large servers with large amounts of memory.

As we shall see below, our scheme is highly scalable
and practically efﬁcient. We cannot offer a direct comparison
between our performance speeds and that of [18], because of

651

different hardware conﬁguration and limited test equipment
information presented in [18]. Nevertheless, our evaluation
shows that our scheme should be signiﬁcantly more efﬁcient
than that of [18].

A. Micro-benchmarks – File-keyword pair analysis

In [18], micro-benchmarks were used to evaluate the SSE
operations. We do the same for the SSE.indexgen algorithm.
(For our search, add and delete operations, the performance
is essentially independent of the total number of ﬁle-keyword
pairs already stored in the system, and this micro-benchmark
does not provide a meaningful evaluation of these operations.
These operations are evaluated differently, as explained below.)

Figure 9 shows micro-benchmarks for our scheme. The
parameters used in the scheme are held constant, and are the
same as detailed in the next section. Each data point is an
average of 5 runs of SSE.indexgen. Note that the amortized
per-pair time falls as the number of pairs increases, before
tending to 1.58µs; this is because our SSE.indexgen operation
involves encrypting the whole array D (which has the same
size in all the experiments), and this overhead does not increase
with the number of pairs.

Compared to the time for index generation operation re-
ported in [18], our performance is signiﬁcantly better. [18]
reports a per-pair time of 35µs for the same operation. Thus
our index generation operation is an order of magnitude faster.

2) Index Generation: Index generation is computationally
the most expensive phase of any searchable encryption scheme.
Our index generation performance measurements include en-
cryption of documents and all other operations except the
cost of plaintext index generation. Plaintext index generation
performance is orthogonal to our contributions, doesn’t reﬂect
the performance of our system and is ignored by all prior work.
Figure 10 shows our index generation performance on the
email dataset. Our performance is much better when compared
to that of [18], which takes 52 seconds to process 16MB of
data. Our scheme can process 256MB (16 times more data)
in about 35s. [18] extrapolates this to to 16GB of text e-
mails without any attachments and, since the time for index
generation scales roughly linearly with data, estimates that
their index generation would take 15 hours; in contrast, it
would take only 41 minutes in our scheme.

This matches our conclusion from the micro-benchmarks
evaluation, that our index generation operation is at least an
order of magnitude faster than that of [18].

Figure 11 shows the performance of our scheme on the

document dataset.

Fig. 10: SSE.indexgen performance on email dataset with 99%
conﬁdence intervals: SKE stands for Symmetric Key Encryption and
is the time required to encrypt the documents. All SKE costs are
non-zero but some are very small.

Fig. 9: File/Keyword pair versus amortized time for SSE.indexgen.
Time per ﬁle/keyword pair tends to 1.58µs, much better than the 35µs
reported in [18] in a similar dataset.

B. Full evaluation

Each data point for Index Generation is the average of 5
runs of SSE.indexgen. Each data point for the Search is the
average of 5 runs using the most frequent English word "the".
Each data point for addition is the average of at least 5 runs.

1) Parameters Used: The parameters used for the experi-
ments guarantee perr ≤ 2−80 (recall that perr is the probability
of the scheme aborting and measures the security “error”) if
less than 1/8 of the total blocks in D are ﬁlled and guarantee
perr ≤ 2−40 if less than 1/4 of the total blocks in D are ﬁlled.
We set κ = 80 and α = 4, block size of D to 256 bytes, the
total number of blocks in D to nD = 224.

Fig. 11: SSE.indexgen on the document dataset with 99% conﬁdence
intervals

Communication costs. The communication cost of initial index
upload depends upon the parameters used for Blind-Storage,
and speciﬁcally, the size of the array D. As mentioned above,
in Section VII-B1, the size of D was set to 1GB (224 blocks of
256 bytes each) in our experiments. In comparison, the actual
amount of index data for the 256MB subset of the email dataset
consisted of 20,694,991 ﬁle-keyword pairs, which, using 4-
byte ﬁelds for document IDs, translates to about 78MB of data.
Given the small size of some of the index ﬁles, on formatting
this data into 256-byte blocks for the Blind-Storage scheme,
this resulted in about 178MB data. For our choice of κ and α,
γ = 4 is sufﬁcient to bring perr below 2−40. That is, it would

652

be sufﬁcient to use about 712MB as the size of D. Hence
the choice of 1GB as the size of D in our experiments leaves
abundant room to add more documents later.

For the document dataset, there are only 1,371,656 ﬁle-
keyword pairs, which translates to a plaintext index size of
5MB (with 4-byte document IDs). Thus the size of D could be
as low as 20MB. Note that the document collection itself is of
size 1GB in this case. For rich data formats, it will typically be
the case that the communication overhead due to SSE.indexgen
would be only a fraction of the communication requirement for
the documents themselves.

3) Search: Figure 12 shows the search performance of
our scheme excluding the ﬁnal decryption of the documents.
Figure 12 does include overhead incurred at search time to
handle lazy delete. We searched for the most frequent English
word “the” and it was present in almost all the documents.
(The exact query word is not mentioned in the previous work
we are comparing against, so we chose a worst-case scenario
for our experiments.) Our scheme performed better than [18]
for all data sizes. Their scheme needs 17 ms, 34 ms and
53 ms for 4MB, 11MB and 16MB subsets of the Enron
dataset respectively. Our scheme consumed 5 ms, 11 ms and
25 ms for 4MB, 8MB and 16MB subsets of the Enron dataset
respectively. The search time grows proportionately to the size
of the response. Figure 13 shows the search performance on
the document dataset.

Fig. 12: Search performance on the email dataset with 99% conﬁ-
dence intervals

Fig. 14: Communication needed for searching on the email dataset.
The graph shows the size of the retrieved documents themselves
alongside the extra communication incurred by our scheme.

As it turns out (and as was experimentally conﬁrmed), the
overhead for searches does not signiﬁcantly vary depending on
whether the search operation involved a lazy deletion or not.
This is because all search operations use the update mechanism
of the underlying Blind-Storage scheme and the clear storage
scheme. The efﬁciency of the update mechanism itself does not
depend signiﬁcantly on whether the ﬁle was modiﬁed or not.
Indeed, in the case of Blind-Storage updates, it is important
for the security that it must not be revealed to the server if a
lazy deletion was involved or not.16

Communication costs. As our scheme does not
involve
any server-side computation, we download slightly more data
compared to [18]. But as shown in Figure 14, for the email
dataset, the communication overhead is negligible compared
to the size of the documents retrieved. The document dataset
is much richer and contains much fewer keywords compared
to the email dataset of the same size (1GB of documents in
our dataset contains only 70MB of text), and therefore the
overhead would be even lower for it.

4) Add: As opposed to [18] and other prior work, per-
formance of our add operation does not depend upon the
amount of data (i.e. the number of ﬁle-keyword pairs) already
present in the searchable encryption system. Figure 15 shows
the performance of addition of ﬁles of speciﬁed size when
256MB of data was initially indexed into the system.

Fig. 13: Search performance on the document dataset with 99%
conﬁdence intervals

Note that our scheme uses a lazy deletion strategy to
handle removals. This lazy delete mechanism allows us to
obtain vastly improved security guarantees by limiting the
information leaked to the server (only for ﬁles uploaded during
initial index generation). One might ask if this leads to any
efﬁciency degradation during subsequent searches, since the
actual updates to the index take place when a keyword that
was contained in a deleted document is searched for later.

Fig. 15: Add performance on email dataset with 99% conﬁdence
intervals. SKE costs are non-zero but very small.
Communication costs. We only need, on average, to download
three blocks and upload two blocks per unique keyword in
the document that is being added. (If the server supports an

16We remark that our security model does not consider timing attacks.
Depending on the implementation, we do not rule out a small dependence
between the time taken and the extent of lazy delete computations involved. A
serious implementation should take this into account. Since our SSE scheme is
a relatively thin wrapper around the Blind-Storage mechanism, timing attacks
can be effectively mitigated with relative ease.

653

(SHARPS), and NSF CNS 09-64392 (EBAM). The views
expressed are those of the authors only.

REFERENCES
“Crypto++,” http://www.cryptopp.com/.
“Enron dataset,” https://www.cs.cmu.edu/~enron/.

[1]
[2]
[3] P. Brudenall, B. Treacy, and P. Castle, “Outsourcing to the cloud:
data security and privacy risks,” Financier Worldwide and Hunton &
Williams, 2010.

[4] R. Canetti, “Universally composable security: A new paradigm for
cryptographic protocols,” Electronic Colloquium on Computational
Complexity (ECCC) TR01-016, 2001, previous version “A uniﬁed
framework for analyzing security of protocols” available at the ECCC
archive TR01-016. Extended abstract in FOCS 2001.

[5] D. Cash, J. Jaeger, S. Jarecki, C. Jutla, H. Krawczyk, M. Ro¸su, and
M. Steiner, “Dynamic searchable encryption in very large databases:
Data structures and implementation,” 2014.

[6] D. Cash, S. Jarecki, C. Jutla, H. Krawczyk, M. Rosu, and M. Steiner,
“Highly-scalable searchable symmetric encryption with support for
boolean queries,” in CRYPTO, 2013.

[7] Y.-C. Chang and M. Mitzenmacher, “Privacy preserving keyword

searches on remote encrypted data.” in ACNS, 2005, pp. 442–455.

[8] M. Chase and S. Kamara, “Structured encryption and controlled disclo-

sure,” in ASIACRYPT, 2010, pp. 577–594.

[9] R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky, “Searchable
symmetric encryption: Improved deﬁnitions and efﬁcient constructions,”
Journal of Computer Security, vol. 19, no. 5, pp. 895–934, 2011.

[10] R. Curtmola, J. A. Garay, S. Kamara, and R. Ostrovsky, “Searchable
symmetric encryption: improved deﬁnitions and efﬁcient constructions,”
in CCS, 2006, pp. 79–88.

[11] E.-J. Goh, “Secure indexes,” Cryptology ePrint Archive, Report

2003/216, 2003, http://eprint.iacr.org/2003/216/.

[12] O. Goldreich, Foundations of Cryptography: Basic Applications. Cam-

bridge University Press, 2004.

[13] O. Goldreich and R. Ostrovsky, “Software protection and simulation on

oblivious RAMs,” J. ACM, vol. 43, no. 3, pp. 431–473, 1996.

[14] P. Golle, J. Staddon, and B. R. Waters, “Secure conjunctive keyword

search over encrypted data.” in ACNS, 2004, pp. 31–45.

[15] W. Jansen and T. Grance, “Guidelines on security and privacy in public

cloud computing,” NIST special publication, pp. 800–144, 2011.

[16] S. Jarecki, C. Jutla, H. Krawczyk, M. Rosu, and M. Steiner, “Outsourced
symmetric private information retrieval,” in CCS. ACM, 2013, pp.
875–888.

[17] S. Kamara and C. Papamanthou, “Parallel and dynamic searchable
symmetric encryption,” in Financial Cryptography and Data Security,
FC (2013), 2013.

[18] S. Kamara, C. Papamanthou, and T. Roeder, “Dynamic searchable

symmetric encryption,” in CCS, 2012, pp. 965–976.

[19] K. Kurosawa and Y. Ohtaki, “UC-secure searchable symmetric encryp-

tion,” in Financial Cryptography and Data Security (FC), 2012.

[20] R. Ostrovsky, “Efﬁcient computation on oblivious RAMs,” in STOC,

1990, pp. 514–523.

[21] S. Paquette, P. T. Jaeger, and S. C. Wilson, “Identifying the security risks
associated with governmental use of cloud computing,” Government
Information Quarterly, vol. 27, no. 3, pp. 245 – 253, 2010.

[22] B. Pinkas and T. Reinman, “Oblivious RAM revisited,” in CRYPTO,

2010, pp. 502–519.

[23] D. X. Song, D. Wagner, and A. Perrig, “Practical techniques for searches

on encrypted data.” in IEEE S&P, 2000, pp. 44–55.

[24] E. Stefanov, C. Papamanthou, and E. Shi, “Practical dynamic searchable

encryption with small leakage,” 2014.

[25] E. Stefanov and E. Shi, “Oblivistore: High performance oblivious cloud

storage,” in IEEE S&P, 2013, pp. 253–267.

[26] E. Stefanov, E. Shi, and D. Song, “Towards practical oblivious RAM,”

in NDSS, 2012.

[27] P. van Liesdonk, S. Sedghi, J. Doumen, P. H. Hartel, and W. Jonker,
“Computationally efﬁcient searchable symmetric encryption,” in Work-
shop on Secure Data Management (SDM), 2010, pp. 87–100.

Fig. 16: Add performance on document dataset with 99% conﬁdence
intervals: SKE costs are non-zero but very small.

append operation that allows to append data to existing ﬁles
on the server, we do not need to download any data during
Add.)

5) Remove: The communication and computation cost of
removing a document is virtually negligible, since it uses a
lazy deletion strategy. Removal of a document in our scheme
only requires the client to send a command to the server to
delete the document from its ﬁle-system, and does not need
any update to the searchable encryption index.

C. Summary

Evaluation of our scheme shows that it is more efﬁcient,
scalable and practical than prior schemes. Index generation in
our scheme is more than 20 times faster than that of [18].
Search operations are 2-3 times faster, in our experiments.
Further, unlike [18], our addition and removal
times are
independent of the total number of ﬁle-keyword pairs, and
is much more scalable. Removal in our scheme has virtually
zero cost. We stress that several possible optimizations have
not been implemented in this prototype.

VIII. CONCLUSION

In this work, we introduced a new cryptographic construct
called Blind Storage, and implemented it using a novel, yet
light-weight protocol SCATTERSTORE. We also showed how a
dynamic SSE scheme can be constructed using Blind Storage,
in a relatively simple manner. The resulting scheme is more
computationally efﬁcient, require simpler infrastructure, and is
more secure than the existing schemes.

Important future directions include making the scheme
secure against actively corrupt servers, and allowing secure
searches involving multiple keywords. The core idea of using
pseudorandom subsets in SCATTERSTORE is amenable to these
extensions, as is being explored in on going work.

ACKNOWLEDGMENT

We thank Igors Svecs for collaboration in the early stages
of the project. We are grateful to Seny Kamara for helping us
with evaluation datasets and Elaine Shi for useful discussions.
We also thank Ravinder Shankesi for help in debugging the
code and Fahad Ullah for help in collecting documents for the
document dataset.

This work was supported by NSF 07-47027, NSF 12-
28856, NSF CNS 13-30491 (ThaW), HHS 90TR0003-01

654

