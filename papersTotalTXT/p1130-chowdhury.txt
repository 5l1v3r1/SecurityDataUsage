Equivalence-based Security for Querying Encrypted
Databases: Theory and Application to Privacy Policy

Audits

Omar Chowdhury

Purdue University

West Lafayette, Indiana

Deepak Garg

MPI-SWS
Germany

Limin Jia, Anupam Datta
Carnegie Mellon University

Pittsburgh, Pennsylvania

ochowdhu@purdue.edu

dg@mpi-sws.org

{liminjia,danupam}@cmu.edu

ABSTRACT
To reduce costs, organizations may outsource data storage
and data processing to third-party clouds. This raises conﬁ-
dentiality concerns, since the outsourced data may have sen-
sitive information. Although semantically secure encryption
of the data prior to outsourcing alleviates these concerns,
it also renders the outsourced data useless for any rela-
tional processing. Motivated by this problem, we present
two database encryption schemes that reveal just enough
information about structured data to support a wide-range
of relational queries. Our main contribution is a deﬁnition
and proof of security for the two schemes. This deﬁnition
captures conﬁdentiality oﬀered by the schemes using a novel
notion of equivalence of databases from the adversary’s per-
spective. As a speciﬁc application, we adapt an existing
algorithm for ﬁnding violations of a rich class of privacy
policies to run on logs encrypted under our schemes and
observe low to moderate overheads.

Categories and Subject Descriptors
H.2.0 [DATABASE MANAGEMENT]: General—Secu-
rity, integrity, and protection; K.4.1 [Computers and So-
ciety]: Public Policy Issues—Privacy, Regulation

Keywords
Privacy Policy Audit; HIPAA; GLBA; Querying Encrypted
Databases

1.

INTRODUCTION

To reduce infrastructure costs, small- and medium-sized
businesses may outsource their databases and database ap-
plications to third-party clouds. However, such data is of-
ten private, so storing it in a cloud raises conﬁdentiality
concerns. Semantically secure encryption of databases prior
to outsourcing alleviates conﬁdentiality concerns, but it also
makes it impossible to run any relational queries on the cloud

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. Copyrights for third-
party components of this work must be honored. For all other uses, contact
the Owner/Author.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s).
ACM 978-1-4503-3832-5/15/10.
http://dx.doi.org/10.1145/2810103.2813638.

without client interaction. Several prior research projects
have investigated encryption schemes that trade-oﬀ perfect
data conﬁdentiality for the ability to run relational queries
[39, 6, 21]. However, these schemes either require client-side
processing [21], or require additional hardware support [6],
or support a very restrictive set of queries [39]. Our long-
term goal is to develop database encryption schemes that can
(1) be readily deployed on commercial oﬀ-the-shelf (COTS)
cloud infrastructure without any special hardware or any
kernel modiﬁcations, (2) support a broad range of (non-
update) relational queries on the encrypted database with-
out interaction with the client, (3) be implemented with low
or moderate overhead, and (4) provide provable end-to-end
security and a precise characterization of what information
encryption leaks in exchange for supporting a given set of
queries. Both in objective and in method, our goal is similar
to that of CryptDB [34], which attains properties (1)–(3),
but not (4).

As a step towards our goal, in this paper, we design two
database encryption schemes, EunomiaDET and EunomiaKH,
with properties (1)–(4). Our design is guided by, and partly
speciﬁc to, a single application, namely, audit of data-use
logs for violations of privacy policies. This application rep-
resents a real-world problem. Organizations are subject to
privacy legislation. For example, in the US, the healthcare
and ﬁnance industry must handle client data in accordance
with the federal acts HIPAA [1] and GLBA [2] respectively.
To remain compliant with privacy legislation, organizations
record logs of privacy-relevant day-to-day operations such as
data access/use and employee role changes, and audit these
logs for violations of privacy policies, either routinely or on
a case-by-case basis. Logs can be fairly large and are often
organized in commodity databases. Audit consists of a se-
quence of policy-guided queries. Audit is computationally
expensive but highly parallelizable, so there is signiﬁcant
merit in outsourcing the storage of logs and the execution
of audit algorithms to third-party clouds.

Security. We characterize formally what information about
an encrypted log (database) our schemes may leak to an ad-
versary with direct access to the encrypted store (modeling a
completely adversarial cloud). We prove that by looking at
a log encrypted with either of our schemes, an adversary can
learn (with non-negligible probability) only that the plain-
text log lies within a certain, precisely deﬁned equivalence
class of logs. This class of logs characterizes the uncertainty
of the adversary and, therefore, the conﬁdentiality of the

1130encrypted log [5]. Prior work like CryptDB lacks such a
theorem. CryptDB uses a trusted proxy server to dynam-
ically choose the most secure encryption scheme for every
database column (from a pre-determined set of schemes),
based on the queries being run on that column. While each
scheme is known to be secure in isolation and it is shown
that at any time, a column is encrypted with the weakest
scheme that supports all past queries on the column [32,
Theorem 2], there is no end-to-end characterization of in-
formation leaked after a sequence of queries.
(In return,
CryptDB supports all SQL queries, including aggregation
queries, which we do not support.)

Functionality. To demonstrate that our proposed encryp-
tion schemes support nontrivial applications, we adapt an
audit algorithm called reduce from our prior work [19] to
execute on logs encrypted with either EunomiaDET scheme or
EunomiaKH scheme. We implement and test the adapted al-
gorithm, ereduce, on both schemes and show formally that
the algorithm runs correctly on both schemes (except with
negligible probability). The algorithm ereduce can audit
all policies that reduce can, including most clauses of the
HIPAA and GLBA Privacy Rules [19].

Audit with ereduce is a challenging application for en-
cryption schemes because it requires almost all standard re-
lational query operations on logs. These operations include
selection, projection, join, comparison of ﬁelds, and what
we call displaced comparison (is the diﬀerence between two
timestamps less than a given constant?). Both our encryp-
tion schemes support all these query operations. The only
standard query operation not commonly required by privacy
audit (and not supported by our schemes) is aggregation
(sums and averages; counting queries are supported). Any
application that requires only the query operations listed
above can be adapted to run on EunomiaDET or EunomiaKH,
even though this paper focuses on the audit application only.
EunomiaDET and EunomiaKH trade eﬃciency and ﬂexibil-
ity diﬀerently. EunomiaDET uses deterministic encryption
and has very low overhead (3% to 9% over a no-encryption
baseline in our audit application), but requires anticipat-
ing which pairs of columns will be join-ed in audit queries
prior to encryption. EunomiaKH uses Popa et al.’s adjustable
key hash scheme [35, 34] for equality tests and has higher
overhead (63% to 406% in our audit application), but the
columns that will be join-ed during audit do not have to
be determined prior to encryption. To determine which
columns will be join-ed during audit for violations of a given
policy, we develop a new static analysis of policies, which we
call the EQ mode check.

To support displaced comparisons, which privacy audit
often requires, we design and prove the security of a new
cryptographic sub-scheme dubbed mOPED (short for, mu-
table order-preserving encoding with displacement). This
scheme extends the mOPE scheme of Popa et al. [33], which
does not support displacements, and may be of independent
interest.

Deployability. Both EunomiaDET and EunomiaKH can be
deployed on commodity database systems with some addi-
tional metadata.
In both schemes, a client encrypts the
individual data cells locally and store the ciphertexts in a
commodity database system in the cloud (possibly incre-

mentally). Audit (ereduce) runs on the cloud without in-
teraction with the client and returns encrypted results to
the client, who decrypts them to recover policy violations.
Both EunomiaDET and EunomiaKH use basic, widely-available
cryptographic operations only.

Contributions. We make the following technical contribu-
tions:

• We introduce two database encryption schemes, namely
EunomiaDET and EunomiaKH, that support selection,
projection, join, comparison of ﬁelds, and displaced
comparison queries. The schemes trade eﬃciency for
the need to predict expected pairs of join-ed columns
before encryption. As a building block, we develop the
sub-scheme mOPED, that allows displaced compari-
son of encrypted values.

• We characterize the conﬁdentiality attained by our
schemes as equivalence classes of plaintext logs and
prove that both our schemes are secure.

• We adapt an existing privacy policy audit algorithm
to execute on our schemes. We prove the functional
correctness of the execution of the algorithm on both
our schemes.

• We implement both our schemes and the adapted audit
algorithm, observing low overheads on EunomiaDET and
moderate overheads on EunomiaKH.

Proofs of theorems omitted from this paper can be found

in an accompanying technical report [15].

Notation. This paper is written in the context of the pri-
vacy audit application and our encryption schemes are pre-
sented within this context. We sometimes use the term “log”
or “audit log” when the more general term “database” could
have been used and, similarly, use the term “policy” or “pri-
vacy policy” when the more general term “query” would ﬁt
as well.

2. OVERVIEW OF EUNOMIA

We ﬁrst present the architecture of Eunomia. Then, we
motivate our choice of encryption schemes through examples
and discuss policy audit in Eunomia in more detail. Finally,
we discuss our goals, assumptions, and adversary model.

2.1 Architecture of Eunomia

We consider the scenario where an organization, called
the client or Cl, with sensitive data and audit requirements
wishes to outsource its log (organized as a relational database)
and audit process (implemented as a sequence of policy-
dependent queries) to a potentially compromisable third-
party cloud server, denoted CS. Cl generates the log from its
day-to-day operations. Cl then encrypts the log and trans-
fers the encrypted log to the CS. Cl initiates the audit pro-
cess by choosing a policy. The auditing algorithm runs on
the CS infrastructure and the audit result containing en-
crypted values is sent to Cl, which can decrypt the values in
the result.

The mechanism of log generation is irrelevant for us. From
our perspective, a log is a pre-generated database with a
public schema, where each table deﬁnes a certain privacy-
relevant predicate. For example, the table Roles may con-
tain columns Name and Role, and may deﬁne the mapping of

1131Cl’s employees to Cl’s organizational roles. Similarly, the ta-
ble Sensitive accesses may contain columns Name, File name,
and Time, recording who accessed which sensitive ﬁle at
what time. Several tables like Sensitive accesses may con-
tain columns with timestamps, which are integers.

2.2 Encryption Schemes

An organization may na¨ıvely encrypt the entire log with
a strong encryption scheme before transferring it to a cloud,
but this renders the stored log ineﬀective for audit, as audit
(like most other database computations) must relate diﬀer-
ent parts of the log. For example, suppose the log contains
two tables T1 and T2. T1 lists the names of individuals who
accessed patients’ prescriptions. T2 lists the roles of all in-
dividuals in the organization. Consider the privacy policy:

Policy 1: Every individual accessing patients’ prescriptions
must be in the role of Doctor.

The audit process of the above policy must read names
from T1 and test them for equality against the list of names
under the role Doctor in T2. This forces the use of an en-
cryption method that allows equality tests (or equi-joins).
Unsurprisingly, this compromises the conﬁdentiality of the
log, as an adversary (e.g., the cloud host, which observes the
audit process) can detect equality between encrypted ﬁelds
(e.g., equality of names in T1 and T2). However, not all is
lost: for instance, if per-cell deterministic encryption is used,
the adversary cannot learn the concrete names themselves.
A second form of data correlation necessary for audit is the

order between time points. Consider the following policy:

Policy 2: If an outpatient’s medical record is accessed by
an employee of the Billing Department, then the outpatient
must have visited the medical facility in the last one month.
Auditing this policy requires checking whether the dis-
tance between the timestamps in an access table and the
timestamps in a patient visit table is shorter than a month.
In this case, the encryption scheme must reveal not just
the relative order of two timestamps but also the order be-
tween a timestamp and another timestamp displaced by one
month. Similar to Policy 1, the encryption scheme must
reveal equality between patient names in the two tables.

To strike a balance between functional (audit) and con-
ﬁdentiality requirements, we investigate two cryptographic
schemes, namely EunomiaDET and EunomiaKH, to encrypt
logs. Each cell in the database tables is encrypted indi-
vidually. All cells in a column are encrypted using the same
key. EunomiaDET uses deterministic encryption to support
equality tests; two columns that might be tested for equal-
ity by subsequent queries are encrypted with the same key.
EunomiaDET requires that log columns that might be tested
for equality during audit are known prior to the encryption.
Audit under EunomiaDET is quite eﬃcient. However, adapt-
ing encrypted logs to audit diﬀerent policies that require
diﬀerent column equality tests requires log re-encryption,
which is costly. Our second scheme EunomiaKH handles fre-
quent policy updates eﬃciently. EunomiaKH relies on the ad-
justable key hash scheme [35, 34] for equality tests. A trans-
fer token is generated for each pair of columns needed to be
tested for equality prior to audit. EunomiaKH additionally
stores keyed hashes of all cells. Audit under EunomiaKH re-
quires the audit algorithm to track the provenance of the ci-
phertext (i.e., from which table, which column the ciphertext
originated) and is less eﬃcient than audit under EunomiaDET.

Displaced comparison (needed for Policy 2) is supported
using a new sub-scheme mOPED, which is described in
Section 4. Both EunomiaDET and EunomiaKH use mOPED.
Like its predecessor, mOPE [33], the scheme adds a addi-
tional search tree (additional metadata) to the encrypted
database on CS.
(Supporting displacements is necessary
for a practical audit system because privacy regulations use
displacements to express obligation deadlines. Out of 84
HIPAA privacy clauses, 7 use displacements. Cignet Health
of Prince George’s County, Maryland was ﬁned $1.3 million
for violating one of these clauses, §164.524 [29].

The encrypted database has a schema derived from the
schema of the plaintext database and may be stored on CS
using any standard database management systems (DBMS).
The DBMS may be used to index the encrypted cells. As
shown in [19], database indexing plays a key role in improv-
ing the eﬃciency of the audit process. Hence, we develop
our encryption scheme in such a way that it is possible to
leverage database indexing supported by commodity DBMS.

2.3 Policies and audit

Privacy policies may be extracted from privacy legisla-
tion like HIPAA [1] and GLBA [2], or from internal com-
pany requirements. Technically, a privacy policy speciﬁes a
constraint on the log. For example, Policy 1 of Section 1
requires that any name appearing in table T1 appears in ta-
ble T2 with role Doctor. Generally, policies can be complex
and may mention various entities, roles, time, and subjec-
tive beliefs. For instance, DeYoung et al.’s formalization of
the HIPAA and GLBA Privacy Rules span over 80 and 10
pages, respectively [18]. We represent policies as formulas of
ﬁrst-order logic (FOL) because we ﬁnd it technically conve-
nient and because FOL has been demonstrated in prior work
to be adequate for representing policies derived from exist-
ing privacy legislation (DeYoung et al., mentioned above,
use the same representation). We describe this logic-based
representation of policies in Section 3.

Our audit algorithm adapts our prior algorithm, reduce
[19], that works on policies represented in FOL. This algo-
rithm takes as input a policy and a log and reduces the pol-
icy by checking the policy constraints on the log. It outputs
constraints that cannot be checked due to lack of informa-
tion (missing log tables, references to future time points, or
need for human intervention) in the form of a residual policy.
Similar to reduce, our adapted algorithm, ereduce, uses
database queries as the basic building block. Our encryption
schemes permit queries with selection, projection, join, com-
parison and displaced comparison operations. Our schemes
do not support queries like aggregation (which would re-
quire an underlying homomorphic encryption scheme and
completely new security proofs).

To run reduce on EunomiaDET, we need to identify columns
that are tested for equality. This information is needed
prior to encryption for EunomiaDET and prior to audit for
EunomiaKH, as explained in Section 4. We develop a static
analysis of policies represented in FOL, which we call the
EQ mode check, deﬁned in Section 7, to determine which
columns may need to be compared for equality when the
policy is audited.

2.4 Adversary model and Security Goals

Assumptions and threat model. In our threat model, Cl
is trusted but CS is an honest but curious adversary with the

1132following capability: CS can run any polynomial time algo-
rithm on the stored (encrypted) log, including the audit over
any policy. We assume that Cl generates keys and encrypts
the log with our encryption schemes before uploading it to
CS. Audit runs on the CS infrastructure but (by design) it
does not perform decryption. Hence, CS never sees plaintext
data or the keys, but CS can glean some information about
the log, e.g., the order of two ﬁelds or the equality of two
ﬁelds. The output of audit may contain encrypted values
indicating policy violations, but these values are decrypted
only at Cl.

We assume that privacy policies are known to the adver-
sary. This assumption may not be true for an organization’s
internal policies, but relaxing this assumption only simpli-
ﬁes our formal development. To audit over logs encrypted
with EunomiaDET, any constants appearing in the policy (like
“Doctor” in Policy 1 of Section 1) must be encrypted be-
fore the audit process starts, so CS can recover the associ-
ation between ciphertext and plaintexts of constants that
appear in the (publicly known) privacy policy. Similarly,
in EunomiaKH, the hashes of constants in policies must be
revealed to the adversary. in a set

Security and functionality goals. (Conﬁdentiality) Our
primary goal is to protect the conﬁdentiality of the log’s
content, despite any compromise of CS, including its infras-
tructure, employees, and the audit process running on it.
(Expressiveness) Our system should be expressive enough to
represent and audit privacy policies derived from real legis-
lation. In our evaluation, we work with privacy rules derived
from HIPAA and GLBA.

Log equivalence. Central to the deﬁnition of the end-to-
end security property that we prove of our EunomiaDET and
EunomiaKH is the notion of log equivalence. It characterizes
what information about the database remains conﬁdential
despite a complete compromise of CS. Our security deﬁ-
nition states that the adversary can only learn that the log
belongs to a stipulated equivalence class of logs. The coarser
our equivalence, the stronger our security theorem.

For semantically secure encryption, we could say that two
logs are equivalent if they are the same length. When the
encryption permits join, selection, comparison and displaced
comparison queries, this deﬁnition is too strong. For exam-
ple, the attacker must be allowed to learn that two constants
on the log (e.g., Doctor and Nurse) are not equal if they lie
in diﬀerent columns that the attacker can try to join. Hence,
we need a reﬁned notion of log equivalence, which we for-
malize in Section 5.2.

3. POLICY AND LOG SPECIFICATIONS

We review the logic that we use to represent privacy poli-
cies and give a formal deﬁnition of logs (databases). These
deﬁnitions are later used in the deﬁnition and analysis of
our encryption schemes and the ereduce audit algorithm.

Policy logic. We use the guarded-fragment of ﬁrst-order
logic introduced in [3] to represent privacy policies. The
syntax of the logic is shown in Figure 1. Policies or formulas
are denoted ϕ. Terms t are either constants c, d drawn from
a domain D or variables x drawn from a set Var. (Func-
tion symbols are disallowed.) ~t denotes a list of terms. The
basic building block of formulas is atoms, which represent
relations between terms. We allow three kinds of atoms.

Atoms P ::= p(t1, . . . , tn) | timeOrder(t1, d1, t2, d2) |

t1 = t2

Guard
Formula ϕ ::= P | ⊤ | ⊥ | ϕ1 ∧ ϕ2 | ϕ1 ∨ ϕ2 |

::= P | ⊤ | ⊥ | g1 ∧ g2 | g1 ∨ g2 | ∃x.g

g

∀~x.(g → ϕ) | ∃~x.(g ∧ ϕ)

Figure 1: Policy speciﬁcation logic syntax

First, p(t1, . . . , tn) represents a relation which is established
through a table named p in the audit log. The symbol p
is called a predicate (or, interchangeably, a table). The set
of all predicate symbols is denoted by P. An arity function
α : P → N speciﬁes how many arguments each predicate
takes (i.e., how many columns each table has). Second, for
numerical terms, we allow comparison after displacement
with constants, written timeOrder(t1, d1, t2, d2). This rela-
tion means that t1 + d1 ≤ t2 + d2. Here, d1, d2 must be
constants. Third, we allow term equality, written t1 = t2.
Although we restrict atoms of the logic to these three cat-
egories only, the resulting fragment is still very expressive.
All the HIPAA- and GLBA-based policies tested in prior
work [19] and all but one clause of the entire HIPAA and
GLBA privacy rules formalized by DeYoung et al. [18] lie
within this fragment.

Formulas or policies, denoted ϕ, contain standard logical
connectives ⊤ (“true”), ⊥ (“false”), ∧ (“and”), ∨ (“or”), ∀x
(“for every x”) and ∃x (“for some x”). Saliently, the form of
quantiﬁers ∀x and ∃x is restricted: Each quantiﬁer must in-
clude a guard, g. As shown in [19], this restriction, together
with the mode check described in Section 7, ensures that au-
dit terminates (in general, the domain D may be inﬁnite).
Intuitively, one may think of a policy ϕ as enforcing a con-
straint on the predicates it mentions, i.e., on the tables of
the log. A guard g may be thought of as a query on the log
(indeed, the syntax of guards generalizes Datalog, a well-
known database query language). The policy ∀~x.(g → ϕ)
may be read as “for every result ~x of the query g, the con-
straint ϕ must hold.” Dually, ∃~x.(g ∧ ϕ) may be read as
“some result ~x of the query g must satisfy the constraint ϕ.”

Example 1. Consider the following policy, based on §6802(a)
of the GLBA privacy law:

(send(p1, p2, m, t)∧

∀p1, p2, m, q, a, t.
tagged(m, q, a) ∧ activeRole(p1, institution)∧
notAﬃliateOf(p2, p1, t) ∧ customerOf(q, p1, t) ∧ attr(a, npi))

→(cid:18)(∃t1, m1.send(p1, q, m1, t1) ∧ timeOrder(t1, 0, t, 0)∧

timeOrder(t, 0, t1, 30) ∧ discNotice(m1, p1, p2, q, a, t))

W

(∃t2, m2.send(p1, q, m2, t2) ∧ timeOrder(t, 0, t2, 0)∧

timeOrder(t2, 0, t, 30) ∧ discNotice(m2, p1, p2, q, a, t))(cid:19)

The policy states that principal p1 can send a message m to
principal p2 at time t where the message m contains principal
q’s attribute a (e.g., account number) and (i) p1 is in the
role of a ﬁnancial institution, (ii) p2 is not a third-party
aﬃliate of p1 at time t, (iii) q is a customer of p1 at time
t, (iv) the attribute a is non-public personal information
(npi, e.g., a social security number) only if any one of the
two conditions separated by ∨ holds. The ﬁrst condition
says that the institution has already sent a notiﬁcation of
this disclosure in the past 30 days to the customer q (i.e.,

11330 ≤ (t − t1) ≤ 30). The second condition says that the
institution will send a notiﬁcation of this disclosure within
the next 30 days (i.e., 0 ≤ (t2 − t) ≤ 30).

key property of δ is that if, during audit, column a1 of table
p1 is tested for equality against column a2 of table p2, then
hp1.a1, p2.a2i ∈ δ.

Logs and schemas. An audit log or log, denoted L, is a
database with a given schema. A schema S is a set of pairs
of the form htableName, columnNamesi where columnNames
is an ordered list of all the column names in the table (pred-
icate) tableName. A schema S corresponds to a policy ϕ if
S contains all predicates mentioned in the policies ϕ, and
the number of columns in predicate p is α(p).

Semantically, we may view a log L as a function that given
as argument a variable-free atom p(~t) returns either ⊤ (the
entry ~t exists in table p in L) or ⊥ (the entry does not exist).
To model the possibility that a log table may be incomplete,
we allow for a third possible response uu (unknown). In our
implementation, the diﬀerence between uu and ⊥ arises from
an additional bit on the table p indicating whether or not
the table may be extended in future. Formally, we say that
log L1 extends log L2, written L1 ≥ L2 when for every p
and ~t, if L2(p(~t)) 6= uu, then L1(p(~t)) = L2(p(~t)). Thus,
the extended log L1 may determinize some unknown entries
from L2, but cannot change existing entries in L2.

Our logic uses standard semantics of ﬁrst-order logic, treat-
ing logs as models. The semantics, written L |= ϕ, take into
account the possibility of unknown relations; we refer the
reader to [19] for details (these details are not important for
understanding this paper). Intuitively, if L |= ϕ, then the
policy ϕ is satisﬁed on the log L; if L 6|= ϕ, then the policy
is violated; and if neither holds then the log does not have
enough information to determine whether or not the policy
has been violated.

Example 2. The policy in Example 1 can be checked for vi-
olations on a log whose schema contains tables send, tagged,
activeRole, notAﬃliateOf, customerOf, attr and discNotice
with 4, 3, 2, 3, 3, 2 and 6 columns respectively.
In this
audit, values in several columns may have to be compared
for equality. For example, the values in the ﬁrst columns
of tables send and activeRole must be compared because,
in the policy, they contain the same variable p1. Similarly,
timestamps must be compared after displacement with con-
stants 0 and 30. The log encryption schemes we deﬁne next
support these operations.

4. ENCRYPTION SCHEMES

We present our two log encryption schemes, EunomiaDET
and EunomiaKH in Section 4.2 and Section 4.3 respectively.
Both schemes use (as a black-box) a new sub-scheme called
mOPED, for comparing timestamps after displacement,
which we present in Section 4.4.

4.1 Preliminaries

We introduce common constructs used through out the

rest of this section.

Equality scheme. To support policy audit, we determine,
through a static analysis of the policies to be audited, which
pairs of columns in the log schema may be tested for equality
or joined. We defer the details of this policy analysis to
Section 7. For now, we just assume that the result of this
analysis is available. This result, called an equality scheme,
denoted δ, is a set of pairs of the form hp1.a1, p2.a2i. The

Policy constants. Policies may contain constants. For in-
stance, the policy of Example 1 contains the constants npi,
institution, 0 and 30. Before running our audit algorithm
over encrypted logs, a new version of the policy contain-
ing these constants in either encrypted (for EunomiaDET) or
keyed hash (for EunomiaKH) form must be created. Conse-
quently, the adversary, who observes the audit and knows
the plaintext policy, can learn the encryption or hash of
these constants. Hence, these constants play an important
role in our security deﬁnitions. The set of all these policy
constants is denoted C.

Displacement constants. Constants which feature in the
2nd and 4th argument positions of the predicate timeOrder()
play a signiﬁcant role in construction of the mOPED en-
coding and our security deﬁnition. These constants are
called displacements, denoted D. For instance, in Example
1, D = {0, 30}. For any policy, D ⊆ C.

Encrypting timestamps. We assume (conservatively) that
all timestamps in the plaintext log may be compared to each
other, so all timestamps are encrypted (in EunomiaDET) or
hashed (in EunomiaKH) with the same key Ktime. This key is
also used to protect values in the mOPED sub-scheme. The
assumption of all timestamps may be compared with each
other, can be restricted substantially (for both schemes) if
the audit policy is ﬁxed ahead of time.

4.2 EunomiaDET

The log encryption scheme EunomiaDET encrypts each cell
individually using deterministic encryption. All cells in a
column are encrypted with the same key.
Importantly, if
cells in two columns may be compared during audit (as de-
termined by the equality scheme δ), then the two columns
also share the same key. Hence, cells can be tested for equal-
ity simply by comparing their ciphertexts. To allow times-
tamp comparison after displacement, the encrypted log is
paired with a mOPED encoding of timestamps that we ex-
plain later. Note that it is possible to replace deterministic
encryption with a cryptographically secure keyed hash and
a semantically secure ciphertext to achieve the same func-
tionality (the keyed hash value could be used to check for
equality). However, this design incurs higher space overhead
than our design with deterministic encryption.

Technically, EunomiaDET contains the following three al-
gorithms: KeyGenDET(1κ, S, δ), EncryptLogDET(L, S, K), and
EncryptPolicyConstantsDET(ϕ, K).

Key generation. The probabilistic algorithm KeyGenDET(·,
·, ·) takes as input the security parameter κ, the plaintext
log schema S, and an equality scheme δ. It returns a key set
K. The key set K is a set of triples of the form hp, a, ki. The
triple means that all cells in column a of table p must be en-
crypted (deterministically) with key k. The constraints on K
are that (a) if p.a contains timestamps, then k = Ktime, and
(b) if hp1.a1, p2.a2i ∈ δ, hp1, a1, k1i ∈ K and hp2, a2, k2i ∈ K,
then k1 = k2.

Encrypting the log. The algorithm EncryptLogDET(·, ·, ·)
takes as input a plaintext log L, its schema S, and the key set
K generated by KeyGen(). It returns a pair eL = heDB, eT i

1134where, eDB is the cell-wise encryption of L with appropriate
keys from K and eT is the mOPED encoding.

Encrypting constants in the policy. To audit over logs
encrypted with EunomiaDET, constants in the policy must
be encrypted too (else, we cannot check whether or not an
atom mentioning the constant appears in the encrypted log).
The algorithm EncryptPolicyConstantsDET(·, ·) takes as input
a plaintext policy ϕ, and a key set K, and returns a policy
ϕ′ in which constants have been encrypted with appropriate
keys. The function works as follows: If, in ϕ, the constant c
appears in the ith position of predicate p, then in ϕ′, the ith
position of p is c deterministically encrypted with the key of
the ith column of p (as obtained from K). Other than this,
ϕ and ϕ′ are identical.

Remarks. The process of audit on a log encrypted with
EunomiaDET requires no cryptographic operations. Com-
pared to an unencrypted log, we only pay the overhead
of having to compare longer ciphertexts and some cost for
looking up the mOPED encoding to compare timestamps.
However, auditing for a policy that requires equality tests
beyond those prescribed by an equality scheme δ is impos-
sible on a log encrypted for δ. To do so, we would have
to re-encrypt parts of the log, which is a slow operation.
Our second log encryption scheme, EunomiaKH, represents a
diﬀerent trade-oﬀ.

4.3 EunomiaKH

EunomiaKH relies on the adjustable keyed hash (AKH)
scheme [35, 34] to support equality tests. We review AKH
and then describe how we build EunomiaKH on it.

1

Abstractly, AKH provides three functions: Hash(k, v) =
P × DET(kmaster, v) × k (P is a point on an elliptic curve,
DET(·, ·) is the deterministic encryption function, and kmaster
is a master encryption key), Token(k1, k2) = k2 × k−1
and
Adjust(w, ∆) = w × ∆. Hash(k, v) returns a keyed hash of
v with key k on a pre-determined elliptic curve with public
parameters. Token(k1, k2) returns a token ∆k1 7→k2 , which
allows transforming hashes created with key k1 to corre-
sponding hashes created with k2. The function Adjust(w, ∆)
performs this transformation: If w = Hash(k1, v) and ∆ =
∆k1 7→k2 , then Adjust(w, ∆) returns the value Hash(k2, v).
The AKH scheme allows the adversary to compare two val-
ues hashed with keys k1 and k2 for equality only when it
knows either ∆k1 7→k2 or ∆k2 7→k1 . Popa et al. prove this
security property, reducing it to the elliptic-curve decisional
Diﬃe-Hellman assumption [35].

To encrypt a log in EunomiaKH, we generate two keys
kh, ke for each column. These are called the hash key and
the encryption key, respectively. Each cell v in the col-
umn is transformed into a pair hHash(kh, v), Encrypt(ke, v)i.
Here, Hash(kh, v) is the AKH hash of v with key kh and
Encrypt(ke, v) is a standard probabilistic encryption of v
with key ke.1 Columns do not share any keys. If audit on
a policy requires testing columns t1.a1 and t2.a2 for equality
and these columns have hash keys kh1 and kh2 , then the
audit algorithm is given one of the tokens ∆kh1
and
∆kh2
. The algorithm can then transform hashes to
test for equality. Each execution of the audit process can be

7→kh2

7→kh1

1The Encrypt(ke, v) component of the ciphertext is returned
to the client Cl as part of the audit output. Cl then decrypts
it to obtain concrete policy violations.

given a diﬀerent set of tokens depending on the policy being
audited and, hence, unlike EunomiaDET, the same encrypted
log supports audit over any policy. However, equality test-
ing is more expensive now as it invokes the Adjust() function.
This increases the runtime overhead of audit.

Formally, EunomiaKH contains the following four algorithms:
KeyGenKH(1κ, S), EncryptLogKH(L, S, K), EncryptPolicyConsta
ntsKH(ϕ, K), and GenerateToken(S, δ, K).

Key generation. The probabilistic key generation algo-
rithm KeyGenKH(·, ·) takes as input a security parameter and
a log schema S and returns a key set K. K contains tuples
of the form hp, a, kh, kei, meaning that column p.a has hash
key kh and encryption key ke. The only constraint is that if
p.a contains timestamps, then kh = Ktime.

Encrypting the log. The algorithm EncryptLogKH(·, ·, ·)
takes as arguments a plaintext log L, its schema S and a
key set K. It returns a pair eL = heDB, eT i where, eDB is
the cell-wise encryption of L with appropriate keys from K
and eT is the mOPED encoding. Because each cell maps
to a pair, each table has twice as many columns in eDB as
in L.

Encrypting policy constants. To audit over EunomiaKH
encrypted logs, constants in the policy must be encrypted.
The algorithm EncryptPolicyConstantsKH(·, ·) takes as input
a plaintext policy ϕ, and a key set K, and returns a policy
ϕ′ in which constants have been encrypted with appropriate
keys taken from K: If constant c appears in the ith position
of predicate p in ϕ and the hash and encryption keys of the
ith column of p in K are kh and ke, respectively, then the
constant c is replaced by hHash(kh, v), Encrypt(ke, v)i in ϕ′.

Generating tokens. GenerateToken(·, ·, ·) is used to gen-
erate tokens that are given to the audit algorithm to enable
it to test for equality on the encrypted log. For each tu-
ple hp.a1, q.a2i in δ, the algorithm GenerateToken(S, δ, K) re-
turns the tuple hp.a1, q.a2, ∆k1 7→k2 i, where hp, a1, k1, i ∈ K
and hq, a2, k2, i ∈ K.

7→kh1

7→kh2

or ∆kh2

Remarks. From the perspective of conﬁdentiality, the same
amount of information is revealed irrespective of whether the
audit algorithm (which may be compromised by the adver-
sary) is given ∆kh1
, because each token
can be computed from the other. However, the actual token
used for comparison by the audit algorithm can have a sig-
niﬁcant impact on its performance. Consider Policy 1 from
Section 1, which stipulates that each name appearing in ta-
ble T1 appears in T2 with the role Doctor. The audit process
will iterate over the names in T1 and look up those names in
T2. Consequently, for performance, it makes sense to index
the hashes of the names in T2 and for the audit algorithm to
use the token ∆k1 7→k2 , where k1 and k2 are the hash keys of
names in T1 and T2, respectively. If, instead, the algorithm
uses ∆k2 7→k1 , then indexing is ineﬀective and performance
suﬀers. The bottom line is that directionality of information
ﬂow during equality testing matters for EunomiaKH. Our
policy analysis, which determines the columns that may be
tested for equality during audit (Section 7) takes this di-
rectionality into account. The equality scheme δ returned

1135by this analysis is directional (even though the use of δ in
EunomiaDET ignored this directionality): if hp1.a1, p2.a2i ∈ δ,
and p1.a1 and p2.a2 have hash keys k1 and k2, then the audit
algorithm uses the token ∆k1 7→k2 , not ∆k2 7→k1 .

4.4 Mutable Order Preserving Encoding with

Displacements (mOPED)

We now discuss the mOPED scheme which produces a
data structure, eT , that allows computation of the boolean
value t1 + d1 ≤ t2 + d2 on the cloud, given only Enc(t1),
Enc(t2), Enc(d1) and Enc(d2). Here, Enc(t) denotes the de-
terministic encryption of t (in the case of EunomiaDET) or
the AHK hash of t (in the case of EunomiaKH) with the ﬁxed
key Ktime. The scheme mOPED extends a prior scheme
mOPE [33], which is a special case d1 = d2 = 0 of our
scheme.

Consider ﬁrst the simple case where the log L and the
policy ϕ are ﬁxed. This means that the set T of values of
the form t + d that the audit process may compare to each
other is also ﬁxed and ﬁnite (because t is a timestamp on
the ﬁnite log L and d ∈ D is a displacement occurring in
the ﬁnite policy ϕ). Suppose that the set T has size N
(note that N ∈ O(|D| · |L|). Then, the client can store on
the cloud a map eT : EncTimeStamp × EncD → {1, . . . , N },
which maps each encrypted timestamp Enc(t) and each en-
crypted displacement Enc(d) to the relative order of t + d
among the elements of T . To compute t1 + d1 ≤ t2 + d2, the
audit process can instead compute eT (Enc(t1), Enc(d1)) ≤
eT (Enc(t2), Enc(d2)). The map eT can be represented in
many diﬀerent ways. In our implementation, we use nested
hash tables, where the outer table maps Enc(t) to an inner
hash table and the inner table maps Enc(d) to the relative
order of t+d. For audit applications where the log and policy
are ﬁxed upfront, this simple data structure eT suﬃces.

The scheme mOPED is more general and allows the
client to incrementally update eT on the cloud. This is
relevant when either the policy or the log changes often. A
single addition or deletion of t or d can cause the map eT to
change for potentially all other elements and, hence, a naive
implementation of eT may incur cost linear in the current
size of T for single updates. Popa et al. show how this cost
can be made logarithmic by interactively maintaining a bal-
anced binary search tree over encrypted values Enc(t) and
using paths in this search tree as the co-domain of eT . We
extend this approach by maintaining a binary search tree
over pairs (Enc(t), Enc(d)), where the search order reﬂects
the natural order over t + d. Since the cloud never sees
plaintext data, the update of this binary search tree and the
map eT must be interactive with the client. We omit the
details of this interactive update and refer the reader to [33]
for details. As the cloud may be compromised, the security
property we prove of mOPED (Section 5.1) holds despite
the adversary observing every interaction with the client.
We note that an audit algorithm never updates eT , so its
execution remains non-interactive.

5. SECURITY ANALYSIS

We now prove that our schemes EunomiaDET, EunomiaKH
and mOPED are secure. We start with mOPED, because
EunomiaDET and EunomiaKH rely on it.

5.1 Security of mOPED

We formalize the security of mOPED as an indistin-
guishability game in which the adversary provides two se-
quences of timestamps and a set of displacements D, then
observes the client and server construct the mOPED data
structure eT on one of these sequences chosen randomly and
then tries to guess which sequence it is. We call this game
IND-CDDA (indistinguishability under chosen distances with
displacement attack). This deﬁnition is directly based on the
IND-OCPA (indistinguishability under ordered chosen plain-
text attack) deﬁnition by Boldyreva et al. [10] and the LoR
security deﬁnition by Pandey and Rouselakis [31]. Because
eT intentionally reveals the relative order of all timestamps
after displacement with constants in D, we need to impose
a constraint on the two sequences chosen by the adversary.
Let ~u[i] denote the ith element of the sequence ~u. We say
that two sequences of timestamps ~u and ~v are equal up
to distances with displacements D, written EDD(~u, ~v, D) iﬀ
|~u| = |~v| and ∀d, d′ ∈ D, i, j. (~u[i]+d ≥ ~u[j]+d′) ⇔ (~v[i]+d ≥
~v[j] + d′). We describe here the IND-CDDA game and the
security proof for mOPED with deterministic encryption;
the case of mOPED with AKH hashes is similar.

IND-CDDA game. The IND-CDDA security game between
a client or challenger Cl (i.e., owner of the audit log) and
an adaptive, probabilistic polynomial time (ppt) adversary
Adv for the security parameter κ proceeds as follows:

1. Cl generates a secret key Ktime using the probabilistic
$← KeyGen(1κ).

key generation algorithm KeyGen. Ktime
$← {0, 1}.
3. Cl creates an empty eT on the cloud.

2. Cl chooses a random bit b. b

4. Adv chooses a set of distances D = {d1, . . . , dn} and

sends it to Cl.

5. Cl and Adv engage in a polynomial of κ number of

rounds of interactions. In each round j:
(a) Adv selects two values v0

j and v1

j and sends them

to Cl.

j , vb

values vb

j + d1, vb

j + d2, . . . , vb

(b) Cl deterministically encrypts the following n + 1
j + dn using Ktime.
(c) Cl interacts with the cloud to insert DET(Ktime, vb
j )
and {DET(Ktime, vb
i=1 into eT . The ad-
versary observes this interaction and the cloud’s
complete state, but not Cl’s local computation.

j + di)}n

6. Adv outputs his guess b′ of b.

Adv wins the IND-CDDA security game iﬀ:
1. Adv guesses b correctly (i.e., b = b′);
2. EDD([v0

0, . . . , v0

0, . . . , v1

m], [v1

m], D) holds, where m is the

number of rounds played in the game.

Let winAdv,κ be a random variable which is 1 if the Adv
wins and 0 if Adv loses. Recall that a function f : N → R is
negligible with respect to its argument κ, if for every c ∈ N
there exists another integer K such that for all κ > K,
f (κ) < x−c. We write negl(κ) to denote some negligible
function of κ.

Theorem 1 (Security of mOPED with deterministic
encryption) Assuming that deterministic encryption is a

1136pseudorandom function, our mOPED scheme is IND-CDDA
secure, i.e., Pr[winAdv,κ = 1] ≤ 1
2 + negl(κ) where the proba-
bility is taken over the random coins used by Adv as well as
the random coins used in choosing the key and the bit b.

Proof. By a hybrid argument. We augment a similar
proof of security for the mOPE scheme [33] to also take
displacements D into account.

mOPED’s security degrades with the size of the con-
stants’ set D occurring in the audited policies. If a system’s
policies do not use constants, mOPED is as secure as its
predecessor mOPE.

Security of mOPED with AKH hash. The security
game for mOPED with AKH hashes is very similar to
IND-CDDA. We replace DET(·, ·) with Hash(·, ·) in the game.
The proof is in the standard model and reduces to the secu-
rity of AKH [35, Deﬁnition 4] and ﬁnally to the elliptic-curve
decisional Diﬃe-Hellman (ECDDH) assumption.

5.2 Security of EunomiaDET

We prove security for EunomiaDET, formalized as an in-
distinguishability game. We ﬁrst deﬁne a notion of log
equivalence that characterizes the conﬁdentiality achieved
by EunomiaDET (and, as we explain later, by EunomiaKH).
This notion is a central contribution of our work. The
security theorem in this section shows that by looking at
the EunomiaDET encryption of a log, an adversary can learn
only that the log belongs to its equivalence class (with non-
negligible probability). Hence, the equivalence class of the
log represents the uncertainty of the adversary about the
log’s contents and, therefore, characterizes what conﬁden-
tiality the scheme provides.

Deﬁnition 1 (Plaintext log equivalence) Given any two
plaintext audit logs L1 and L2, an equality scheme δ, a set
of constants C and a set of displacements D ⊆ C, L1 and
L2 are equivalent, denoted by L1 ≡(δ,C,D) L2, if and only if
all of the followings hold:

1. L1 and L2 have the same schema and tables of the
same name in L1 and L2 have the same number of
records (rows).

2. For each equivalence class of columns deﬁned by δ,
there is a bijection from values of L1 to values of L2.
(By equivalence class of columns deﬁned by δ, we mean
an equivalence class of columns deﬁned by the reﬂexive,
symmetric, transitive closure of δ.) For a table t and a
column a, let Mt,a denote the bijection corresponding
to the equivalence class of δ in which (t, a) lies. Let v
be the value in some row i of the table t, column a in
L1. Then,
(a) The value in the ith row of table t, column a in

L2 is Mt,a(v).

(b) If v ∈ C, then Mt,a(c) = c.
(c) |v| = |Mt,a(v)|.

3. Let timeStamps(L1) be the sequence of timestamps in
L1 obtained by traversing the tables of L1 in any or-
der and the timestamps within each table in row order.
Let timeStamps(L2) be the timestamps in L2 obtained
similarly, traversing tables in the same order. Then,
EDD(timeStamps(L1), timeStamps(L2), D) holds.

Intuitively, each clause of the above deﬁnition speciﬁes
a property of logs that a log’s encryption under either of
our schemes may reveal to an adversary. Everything else
about the encrypted log remains hidden. We list below the
revealed properties to which each clause of the above deﬁni-
tion corresponds:

1. Schema of the log and the number of records in each

of its tables.

2a. If two columns can be joined (according to δ) then for
two values, one from each column, whether the values
are equal.

2b. The encryption(s) of any constant that appears in the

policy.

2c. The length of each value in the log.

3. The relative order of all timestamps in the log, dis-

placed by constants in D and by 0.

No other information about the log can be recovered by
an adversary looking at the log’s encryption. In particular,
a log’s encryption reveals neither the actual values on the
log (other than constants occurring in the policy), nor the
equality between values in non-joinable columns. Note that
all revealed information is either necessary to execute audit
queries or it cannot be hidden even with (cell-granularity)
semantically-secure encryption.

We now deﬁne the IND-CPLADET game, which formalizes
when an adversary Adv breaks the security of EunomiaDET.
IND-CPLADET stands for indistinguishability under the cho-
sen plaintext log attack.

IND-CPLADET game. The IND-CPLADET game is played be-
tween a client or challenger Cl and an adversary Adv for all
large enough security parameters κ.

1. Adv picks a log schema S, the sets C, D and an equality

scheme δ and gives these to Cl.

2. Cl probabilistically generates a set of secret keys K
based on the suﬃciently large security parameter κ,
the log schema S, and the equality scheme δ. K $←
KeyGenDET(1κ, S, δ).

3. Cl randomly selects a bit b. b
4. Adv chooses two plaintext audit logs L0 and L1 such
that both L0, L1 have schema S, L0 ≡(δ,C,D) L1, L0 6=
L1, and sends L0, L1 to Cl.

$← {0, 1}.

5. Following the scheme EunomiaDET, Cl deterministically
encrypts Lb according to the key set K to obtain the
encrypted audit log eDBb.
heDBb, eTbi ← EncryptLogDET(Lb, S, K).
It then constructs the mOPED data structure eTb.
Adv may observe the construction of the mOPED
data-structure eTb passively. Cl then sends heDBb, eTbi
to Adv.

6. For any constant c ∈ C, if c appears in table t, column
a of Lb, then Cl gives Adv the encryption of c with the
encryption key of column a.

7. Adv runs a probabilistic algorithm that may invoke the
encryption oracle on keys from K but never asks for the
encryption of any value in L0 or L1.

8. Adv outputs its guess b′ of b.

1137Adv wins the IND-CPLADET game iﬀ b = b′. Let the ran-
DET be 1 if the Adv wins and 0 otherwise.

dom variable winAdv

Theorem 2 (Security of EunomiaDET) If deterministic en-
cryption is a pseudorandom function, then the encryption
scheme EunomiaDET is IND-CPLADET secure, i.e., for any
ppt adversary Adv and suﬃciently large κ, Pr[winAdv
DET = 1] ≤
1
2 + negl(κ) where the probability is taken over the random
coins used by Adv as well as the random coins used in choos-
ing keys and the random bit b.

Proof. By hybrid argument. We successively replace
If
uses of deterministic encryption with a random oracle.
the Adv can distinguish two consecutive hybrids with non-
negligible probability, it can also distinguish a random oracle
from a pseudorandom function, which is a contradiction.

Intuitively, this theorem says that any adversary cannot
distinguish two equivalent logs if they are encrypted with
EunomiaDET, except with negligible probability. An imme-
diate corollary of this theorem is that a passive cloud that
observes the execution of our audit algorithm ereduce on
a log encrypted with EunomiaDET learns only the ≡(δ,C,D)
class of the log and, hence, only the log properties listed
earlier in this section. This follows because ereduce can be
simulated by the adversary.

5.3 Security of EunomiaKH

We now deﬁne and prove security for the log encryption
scheme EunomiaKH. The security game, IND-CPLAKH, is sim-
ilar IND-CPLADET and uses the same deﬁnition of log equiva-
lence. The proof of security for EunomiaKH is in the standard
model and reduces to the ECDDH assumption.

IND-CPLAKH game. The IND-CPLAKH game is played be-
tween a challenger Cl and a PPT adversary Adv for all
large enough security parameters κ.
It is very similar to
the IND-CPLADET security game but has the following dif-
ferences. All the encryption is done using the EunomiaKH
scheme. Additionally, after step 5, Cl generates the token
list ~∆ according to δ and send its to Adv. Adv wins the
IND-CPLAKH game iﬀ b = b′. Let the random variable winAdv
KH
be 1 if the Adv wins and 0 otherwise.

Theorem 3 (Security of EunomiaKH) If the ECDDH as-
sumption holds and the encryption scheme used in EunomiaKH
is IND-CPA secure, then EunomiaKH is IND-CPLAKH secure,
i.e., for any ppt adversary Adv and suﬃciently large κ, the
following holds: Pr[winAdv
2 + negl(κ), where the
probability is taken over the random coins used by Adv as
well as the random coins used in choosing keys and the ran-
dom bit b.

KH = 1] ≤ 1

Proof. By hybrid argument, we reduce to the IND-CPA
security of encryption and the security of AKH [35, Deﬁni-
tion 4]. The latter relies on the ECDDH assumption.

IND-CPLADET
Generalizing the security deﬁnitions.
and IND-CPLAKH security games cover only a single round
of interaction between the adversary and the challenger. It
is possible to extend the games to a polynomial number of
interactions and maintain the security theorems. However,
we must assume that the adversary chooses more precise
logs in each interaction, i.e., if the adversary chooses logs
Li
in the (i + 1)-th

1 in the ith interaction and Li+1

, Li+1

0, Li

0

1

0 ≥ Li

interaction, then Li+1
1. Recall that,
L1 ≥ L2 means the log L1 extends the log L2 with additional
information, possibly, replacing unknown values in L1 with
either true or false.

0 and Li+1

1 ≥ Li

Attacks using frequency analysis. Similar to prior work
based on deterministic encryption, our security games (i.e.,
IND-CPLADET and IND-CPLAKH) and security theorems (i.e.,
Theorems 2 and 3) implicitly assume that all plaintext logs
within an equivalence class are equally likely a priori. This
is because in both games, the value b is chosen without
bias.
If the plaintexts are not uniformly distributed and
some auxiliary information about this distribution is known
to the adversary, then the security theorems may not apply.
In fact, concurrent work by Naveed et al. [28] shows that
the association between ciphertexts and plaintexts for de-
terministically encrypted databases can be recovered using
frequency analysis, when the adversary knows the distribu-
tion of the frequencies of data values in the columns of the
plaintext database. However, guessing such distributions
for columns containing sensitive information (e.g., SSNs,
names) is usually very diﬃcult for an adversary. Naveed et
al.’s evaluation is based on publicly available plaintext pa-
tient record databases containing only non-personally iden-
tiﬁable columns like race, gender, and duration of stay at a
hospital.

6. AUDITING ALGORITHM

We now present our auditing algorithm ereduce, which
adapts the prior algorithm reduce [19] to run on logs en-
crypted with EunomiaDET and EunomiaKH. Our choice of
reduce as the basis is motivated by the fact that reduce is
general enough to capture rich policies, including most pri-
vacy clauses of HIPAA and GLBA. The algorithm ereduce
has two very similar versions that execute on logs encrypted
with EunomiaDET and EunomiaKH. We call these versions
ereduceDET and ereduceKH, respectively. The principal
diﬀerence between reduce and ereduceKH/DET is that the
ereduceKH/DET uses the special mOPED data structure to
evaluate displaced comparisons. In the following we ﬁrst de-
scribe ereduceKH in detail and then describe how to simplify
it to obtain ereduceDET.

6.1 Auxiliary Deﬁnitions

A substitution σ is a ﬁnite map from variables to value,
provenance pairs. Each element in the range of a substi-
tution is of the form hv, ℓi, where v is the value that the
variable is mapped to and ℓ is called the provenance of v.
The provenance ℓ indicates which table and which column
the value v originated from. ℓ has the form p.a. We often
write a substitution σ as a ﬁnite list of elements, each of the
form hx, vh, ve, ℓi. For any variable x in σ’s domain, we use
σ(x).hash, σ(x).cipher, and σ(x).ℓ to select the hash value
(i.e., vh), the ciphertext value (i.e., ve), and the provenance
(i.e., ℓ), respectively.

We say substitution σ1 extends σ2 (denoted σ1 ≥ σ2) if
σ1’s domain contains σ2’s domain and σ1 agrees with σ2
on all variables in σ2’s domain. Given a substitution σ, we
deﬁne [σ] = {hx, p.ai | ∃v.σ(x) = hv, p.ai}. We use σ ↓ X,
where X ⊆ domain(σ), to denote the substitution σ′ such
that σ ≥ σ′ and the domain of σ′ contains variables from the
set X only. We lift the ↓ operation to a set of substitutions

1138Σ pointwise. We use • to denote the identity substitution.
We say that a substitution σ satisﬁes a formula g on the
(EunomiaKH-)encrypted log eL if replacing each free variable
x in g with the concrete value σ(x).hash results in a formula
that is true on eL.

6.2 Algorithm ereduceKH

KH

KH

and esat

and esat

Like its basis reduce, the algorithm ereduceKH is deﬁned
as a recursive function that operates on the logical represen-
tation of the policy being audited.
It uses two auxiliary
KH. We describe these functions
below. To simplify notation, we drop the superscript KH
KH in the rest of this sec-

functions, desat
from ereduceKH, desat
tion and write ereduce, desat and esat instead.

ereduce(eL, ϕ, ~∆, σ) is the top-level function that takes as
input a EunomiaKH encrypted audit log eL, a constant en-
crypted policy ϕ, a set of tokens ~∆, and an input substitu-
tion σ, and returns a residual policy ψ. ψ represents a part
of the original policy ϕ that cannot be evaluated due to lack
of information in eL. We use • as the input substitution to
the initial call to ereduce.

desat(eL, g, ~∆, σ) is an auxiliary function used by ereduce

while evaluating quantiﬁers to get all ﬁnite substitutions
that satisfy the quantiﬁer’s guard formula. It takes as input
a EunomiaKH encrypted audit log eL, a constant encrypted
formula g, a set of tokens ~∆, and an input substitution σ,
and returns all ﬁnite substitutions for free variables of g that
extend σ and satisfy g with respect to eL.

esat(eL, p(~t), ~∆, σ) is an auxiliary function used by desat for

evaluating all ﬁnite substitutions that satisfy a given pred-
icate (with an input substitution applied). The inputs eL,
~∆, and σ have their usual meaning. p(~t) is a constant en-
crypted predicate. This function returns all ﬁnite substitu-
tions for free variables of p(~t) that extend the input substi-
tution σ and satisfy p(~t) on eL. The implementation of esat
is log-representation dependent. Evaluation of the predicate
timeOrder uses the mOPED data structure.

ereduce eagerly evaluates as much of the input policy
ϕ as it can; in case it cannot evaluate a portion of ϕ due
to eL’s incompleteness, it returns that portion of ϕ as part
of the result. The return value of ereduce is thus a logi-
cal formula ψ (called the residual formula). Auditing with
ereduce is an iterative process. When the current log eL is
extended with additional information (thus removing some
incompleteness) resulting in the new log eL1 (eL1 ≥ eL),
we can invoke ereduce again with the residual formula ψ
as the input policy and eL1 as the input log.

We present selected cases of ereduce in Figure 2. We
use the notation f(~a) ⇓ ψ to mean that function f returns ψ
when applied to arguments ~a. When the formula input to
ereduce is a predicate p(~t) (rule R-P), ereduce uses σ and
~∆ to replace all variables in p(~t) with concrete values (with
proper hash adjustments) to obtain a new ground predi-
cate p(~t′). (A ground predicate only has constants as argu-
ments.) Then it consults eL to check whether p(~t′) exists.
If eL(p(~t′)) = uu, indicating the log doesn’t have enough
information, then ereduce returns p(~t′). Otherwise, it re-
turns either true or false depending on whether there is a
row in table p with hash values matching ~t′. For exam-

p(~t′) ← ∀ti ∈ Var. p(~t)[ti 7→ hAdjust(σ(ti).hash,

∆σ(ti).ℓ→p.i), σ(ti).cipheri]

P ← eL(p(~t′))

ereduce(eL, p(~t), ~∆, σ) ⇓ P

ereduce(eL, ϕ1, ~∆, σ) ⇓ ϕ′
1

ereduce(eL, ϕ2, ~∆, σ) ⇓ ϕ′

2 ψ ← ϕ′
ereduce(eL, ϕ1 ∨ ϕ2, ~∆, σ) ⇓ ψ

1 ∨ ϕ′
2

desat(eL, g, ~∆, σ) ⇓ Σ′

∀σi ∈ Σ′. ereduce(eL, ϕ, ~∆, σi) ⇓ ϕi

ϕ′ ← ∀~x. (g ∧ ~x /∈ [Σ′ ↓ ~x] → ϕ)

ψ ← ^

ϕi ∧ ϕ′

R-P

R-W

ereduce(eL, ∀~x.(g → ϕ), ~∆, σ) ⇓ ψ

i

R-∀

Figure 2: ereduce description

k1 to vh

ple, let us assume that ereduce is called with the input
substitution σ = [hp1, vh
k1 , ∗, t.cli, . . .] and the input predi-
cate activeRole(p1, hdoctorh
k3 , ∗i) (p1 is a variable and doctor
is a constant). ∗ represents a ciphertext that is not im-
portant for this example. Let us assume that column 1 of
the activeRole table uses the keys (k2, ) whereas in σ, the
hash value mapped to p1 is generated using k1. Hence, we
have to change the value vh
k2 using the adjustment
key ∆k1 7→k2 ∈ ~∆. Then, using the following SQL query we
check whether a row with the appropriate hash values ex-
ists: “select * from activeRole where column1Hash=vh
k2 and
column2Hash=doctorh
k3 ”. If such a row exists, then ⊤ is re-
turned; otherwise, ⊥ is returned. When ereduce is called
for timeOrder, the same hash adjustment applies before the
mOPED data structure is consulted.

In rule R-W, ereduce is recursively called for the two sub-

formulas of the disjunction. The returned residual formula
is the disjunction of the residual formulas returned from the
two recursive calls.

When the input formula is of the form ∀~x. (g → ϕ) (rule

R-∀), we ﬁrst use the function desat (described below) to get

all substitutions Σ′ for ~x that extend σ and satisfy g on
eL. Our EQ mode check (described later), ensures there are
only a ﬁnite number of such substitutions. For each of these
substitutions σi ∈ Σ′, we recursively call ereduce for ϕ to
obtain a residual formula ϕi. Then the returned residual

tutions σi for ~x are not checked again when eL is extended.

formula isVi ϕi ∧ ϕ′ where ϕ′ ensures that the same substi-
Next, we explain selected rules for desat (presented below)

with an example.

S-P

Σ ← esat(eL, p(~t), ~∆, σ)
desat(eL, p(~t), ~∆, σ) ⇓ Σ
desat(eL, g1, ~∆, σ) ⇓ Σ′
∀σi ∈ Σ′. desat(eL, g2, ~∆, σi) ⇓ Σi
desat(eL, g1 ∧ g2, ~∆, σ) ⇓ [

Σi

i

S-V

q(x, y) and substitution σ = ∅ (empty) as input. The S-

Let us assume desat is called with the formula g ≡ p(x) ∧
∧ rule applies and ﬁrst desat is recursive called on p(x) and

σ = ∅. Now, the rule S-P applies. Here, x is not in the
domain of σ, so the esat function consults eL (i.e., using
SQL query like: “select * from p”) to ﬁnd concrete values of x
to make p(x) true. Let us assume that we get hvh
k1 , ∗i (i.e., k1
is used to hash the column 1 of table p). Then, esat returns

1139the substitution σ1 = [hx, vh

k1 , ∗, p.1i] as output. Going back

to the S-∧ rule, now the second premise of S-∧ calls desat

for q(x, y) with each substitution obtained after evaluating
p(x), in our case, σ1. Let us assume that columns 1 and
2 of table q are hashed with keys k2 and k3, respectively.
While evaluating, q(x, y) with σ1, S-P rule is used. σ1 maps
variable x with key k1, so esat converts vh
k2 using
the token ∆p.1→q.1. It then tries to get concrete values for
y (with respect to given value of x) by consulting table q
in eL using the following SQL query: “select column2Hash,
column2Cipher from q where column1Hash=vh
k2 ”. Assuming
that the SQL query returns hwh
k3 , ∗i for column 2 (i.e., y),
esat returns the substitution [hx, vh
k3 , ∗, q.2i].

k1 , ∗, p.1i, hy, wh

k1 to vh

Obtaining ereduceDET from ereduceKH. As described
above, ereduceKH tracks the provenance of the encrypted
data value required for audit. This is not required when
logs are encrypted using EunomiaDET in place of EunomiaKH.
Therefore, ereduceDET is a simpliﬁcation of ereduceKH. In
ereduceDET, the substitution σ maps variables to determin-
istic ciphertexts. Further, in the rules R-P and S-P, no
adjustment is needed.

6.3 Properties

We have proved the functional correctness of both algo-
rithms, ereduceDET and ereduceKH. We show the correct-
ness theorem for ereduceKH below. The theorem states
that the result of decrypting the output (residual policy)
of ereduce on a EunomiaKH-encrypted log and the output
of reduce on the corresponding plaintext log are equal with
high probability. A low probability exception exists because
hash collisions are possible in EunomiaKH (but very unlikely).
The function EncryptSubstitutionKH encrypts a plaintext sub-
stitution with provenance.
It is very similar to the func-
tion EncryptPolicyConstantsKH (Section 4.3). The notation
χI ⊢ ϕP : δ refers to the EQ mode check, which is described
in Section 7.

Theorem 4 (Correctness of ereduceKH) For all plain-
text policies ϕP and ψP, for all constant encrypted policies ϕE
and ψE, for all database schema S, for all plaintext audit logs
L = hDB, T i, for all encrypted audit logs eL = heDB, eT i,
for all plaintext substitutions σP, for all encrypted substitu-
tions σE, for all χI , for all equality schemes δ, for all security
parameters κ, for all encryption keys K, for all token lists ~∆,
if all of the following hold: (1) χI ⊢ ϕP : δ, (2) [σP] ⊇ χI , (3)
K = KeyGenKH(κ, S), ~∆ = GenerateToken(S, δ, K), (4) eL =
EncryptLogKH(L, S, K), (5) ϕE = EncryptPolicyConstantsKH(
ϕP, K), (6) AKH key adjustment is correct, (7) σE = Encrypt
SubstitutionKH(σP, K), (8) ψP = reduce(L, σP, ϕP), (9) ψE =
ereduceKH(eL, ϕE, ~∆, σE), and (10) ψ′
P = DecryptPolicyCons
tantsKH(ψE, K), then ψp = ψ′

P with high probability.

The correctness theorem for ereduceDET is similar.

7. EQ MODE CHECK

We now present the EQ mode check, which is a static anal-
ysis of policies that serves two purposes: (i) It ensures that
ereduce terminates for any policy that passes the check and
(ii) It outputs the equality scheme δ of the policy, which is
needed for both EunomiaDET and EunomiaKH (see Section 4).
The EQ mode check runs time linear in the size of the

∀k ∈ I(p). tk ∈ Var → tk ∈ FE(χI )

htj , p.ji


χO = χI ∪


[

j∈O(p)∧tj ∈Var∧tj /∈FE(χI )

δ = {hp′.i, p.li | 0 < l ≤ α(p) ∧ tl ∈ Var

∧htl, p′.ii ∈ χI }

χI ⊢g p(t1, . . . , tn) : hχO, δi

g-Pred

χI ⊢g g1 : hχ, δ1i

χ ⊢g g2 : hχO, δ2i

χI ⊢g g1 ∧ g2 : hχO, δ1 ∪ δ2i

χI ⊢g g1 : hχ1, δ1i

χI ⊢g g2 : hχ2, δ2i

χI ⊢g g1 ∨ g2 : hχ1 ⋓ χ2, δ1 ∪ δ2i

g-Conj

g-Disj

Figure 3: Selected χI ⊢g g : hχO, δi judgements

policy. The EQ mode check extends the mode check de-
scribed in [19] by additionally carrying provenance and key-
adjustment information, which are necessary for ereduceKH.

Mode speciﬁcation. The concept of “modes” comes from
logic programming [4]. Consider the following example: Pred-
icate tagged(m, q, a) is true when the message m is tagged
with principal q’s attribute a. Assuming that the number of
possible messages in English language is inﬁnite, the num-
ber of concrete values for variables m, q, and a for which
tagged holds is also inﬁnite. However, if we are given a
concrete message (i.e., concrete value for the variable m),
then the number of concrete values for q and a for which
tagged holds is ﬁnite. Hence, we say the predicate tagged’s
argument position 1 is the input position (denoted by “+”)
whereas the argument positions 2 and 3 are output argu-
ment positions (denoted by “−”). We call such a description
of inputs and outputs of a predicate its mode speciﬁcation.
The mode speciﬁcation of a predicate means that given con-
crete values for variables in the input positions, the number
of concrete values for variables in the output position that
satisfy the predicate is ﬁnite. Hence, tagged(m+, q−, a−) is a
valid mode speciﬁcation whereas tagged(m−, q−, a+) is not.

EQ mode checking. EQ mode check uses the mode spec-
iﬁcation of predicates to check whether a formula is well-
moded. EQ mode check has two types of judgements: χI ⊢g
g : hχO, δi for guards, and χI ⊢ ϕ : δ for policy formulas.
Each element of the sets χI , χO is a pair of form hx, p.ai
which signiﬁes that when g or ϕ is evaluated, a concrete
value for the variable x will exist with provenance p.a.

The top level judgement χI ⊢ ϕ : δ states that given
ground values for variables in set χI , the formula ϕ is well-
moded and that audit ϕ would require the equality checking
for column pairs given by δ. We call a given policy ϕ well-
moded if there exists a δ for which we can prove {} ⊢ ϕ :
δ. The judgement ⊢ uses ⊢g as a sub-judgement in the
quantiﬁer case. We explain ⊢g ﬁrst. The judgement χI ⊢g
g : hχO, δi states that given concrete values for variables in
the set χI , the number of concrete values for variables in
the set χO (χO is a subset of the free variables of g) for
which the formula g holds true is ﬁnite. It also outputs the
column pairs which may be checked for equality during the
evaluation of g.

Selected mode checking rules for guards are listed in Fig-
ure 3. We explain these rules using an example. We show
how to check the formula g = (p(x−)∨q(x−, z−))∧r(x+, y−)
with χI = {}. The function I (resp., O) takes as input a

1140predicate p and returns all input (resp., output) argument
positions of p. For instance, I(r) = {1} and O(r) = {2}.

1 = p(x−) and gd

First, the rule G-CONJ applies. The ﬁrst premise of
G-CONJ requires that gc
1 = (p(x−) ∨ q(x−, z−)) is well-
moded with χI = {}. The rule G-DISJ can be used to
check the well-modedness of gc
1 with χI = {}. The ﬁrst
and second premise require gd
2 = q(x−, z−)
to be independently well-moded with the input χI = {}.
While checking p(x−) with χI = {} we see that the rule
G-PRED applies. The ﬁrst premise of G-PRED checks
whether all input variables of p, none in this case, are in-
cluded in χI ; this is trivially satisﬁed here. We use an
auxiliary function FE for checking this, deﬁned as follows:
FE(χI ) = {x | ∃p, i.hx, p.ii ∈ χI }. When p is evaluated,
we will get concrete values for variable(s) in output posi-
tions of p (i.e., x in this case with provenance p.1), hence
χO = {hx, p.1i}. This is formalized in premise 2. Finally,
because χI = {}, so we will not need any equality compar-
isons in evaluating p, so δ = {} (premise 3). Similarly, we
can derive, {} ⊢g q(x−, z−) : h{hx, q.1i, hz, q.2i}, {}i. Once
we have established that both gd
2 are well-moded, we
see that we are only guaranteed to have a concrete value
for variable x after gd
1 is true we
will not get any concrete value for z, which appears only in
gd
2 ), but x can have provenance p.1 or q.1. We have to keep
track of both, which is captured using the ⋓ operator de-
ﬁned as follows: χ1 ⋓ χ2 = {hx, p1.a1i | ∃p2, a2.((hx, p1.a1i ∈

χ1 ∧ hx, p2.a2i ∈ χ2)W(hx, p1.a1i ∈ χ2 ∧ hx, p2.a2i ∈ χ1)).}.

1 : h{hx, p.1i, hx, q.1i}, {}i.

1 ∨ gd

2 has evaluated (if gd

1 and gd

So we have, {} ⊢g gc

Next, we return to the second premise of G-CONJ, which
requires that r(x+, y−) be well-moded with respect to χ =
{hx, p.1i, hx, q.1i}. The rule G-PRED applies again.
Its
ﬁrst premise, which requires that variables in input argu-
ment position (x in this case) be included in χI , is satisﬁed.
According to the second premise, we will get concrete values
for y with provenance r.2 when the predicate is evaluated,
so χO = {hx, p.1i, hx, q.1i, hy, r.2i}. Finally, a concrete value
for x (with provenance p.1 or q.1) is needed while evaluat-
ing r (x an input argument of r), hence we need to check
for equality between the following column pairs, p.1, r.1 and
q.1, r.1. Therefore, δ = {hp.1, r.1i, hq.1, r.1i}.

Top-level mode checking rules for policy formulas are very
similar to those for guards, except that formulas do not
ground variables. We show the rule for universal quantiﬁca-
tion below. Recall that the audit algorithm ereduce checks
formulas of the form ∀~x. (g → ϕ) by ﬁrst obtaining all sub-
stitutions for ~x that satisfy g and then checking whether ϕ
holds for each of these substitution.

χI ⊢g g : hχO, δgi

~x ⊆ FE(χO)

f v(g) ⊆ FE(χI ) ∪ {~x}

χO ⊢ ϕ : δc

χI ⊢ ∀~x. (g → ϕ) : δg ∪ δc

Univ

The ﬁrst premise of UNIV checks that we have only a ﬁnite
number of substitutions for ~x that satisfy g with respect
to χI and with equality scheme δg. This is necessary for
termination of ereduce. The second and third premises
check that g yields concrete substitutions for all quantiﬁed
variables ~x and its own free variables. The last premise
checks that ϕ is well-moded.

8.

IMPLEMENTATION AND EVALUATION
We have implemented EunomiaDET, EunomiaKH, ereduceDET

and ereduceKH using OpenSSL version 1.0.1e. For deter-

Figure 4: Experimental results on HIPAA policies

ministic encryption, we use AES with a variation of the
CMC mode [22] with a ﬁxed IV and a 16-byte block size.
We use 256-bit keys. For the AKH scheme, we use the li-
brary by Popa et al. [34]. The underlying elliptic curve is
the NIST-approved NID X9 62 prime192v1.

We report our empirical evaluation of ereduceDET and
ereduceKH. We run experiments on a 2.67GHz Intel Xeon
X5650 CPU with Debian Linux 7.6 and 50GB of RAM,
of which no more than 3.0 GB is used in any experiment.
SQLite version 3.8.7.1 is used to store the plaintext and en-
crypted logs. We aggressively index all database columns in
input argument positions. In EunomiaDET, the index is built
over deterministically encrypted values; in EunomiaKH, the
index is built over hashed values. We use privacy policies
derived from the GLBA and HIPAA privacy rules and cover
4 and 13 representative clauses of these rules, respectively.
We use synthetically generated plaintext audit logs. Given
an input policy and a desired number of privacy sensitive ac-
tions, our audit log generation algorithm randomly decides
whether each action will be policy compliant or not. To gen-
erate log entries for a compliant action, the algorithm tra-
verses the abstract syntax tree of the policy and generates
instances of atoms that together satisfy the policy. For the
non-compliant actions, we randomly choose atoms to falsify
a necessary condition. Our synthetic log generator also out-
puts the mOPED data structure but with plaintext values
for timestamps. We generate logs containing between 2000
and 14000 privacy-sensitive actions. Each plaintext log is
separately encrypted with the EunomiaDET and EunomiaKH
schemes. The maximum plaintext audit log size we consid-
ered is 17 MB. The corresponding maximum encrypted log
sizes in EunomiaDET and EunomiaKH are 67.3MB and 267MB,
respectively. Most of the size overhead of the EunomiaKH-
encrypted log comes from the keyed hashes.

We measure the relative overhead of running ereduce on
logs encrypted with EunomiaDET and EunomiaKH, choosing
reduce on plaintext audit log as the baseline. We exper-
iment with both RAM-backed and disk-backed versions of
SQLite. We report here only the memory-backed results (the
disk-backed results are similar). Figure 4 shows the average

1141execution time per privacy-sensitive action for the HIPAA
policy in all three conﬁgurations (GLBA results are similar).
The number of privacy-sensitive actions (and, hence, the log
size) varies on the x-axis. The overhead of EunomiaDET is
very low, between 3% and 9%. This is unsurprising, because
no cryptographic operations are needed during audit. The
overhead comes from the need to read and compare longer
(encrypted) ﬁelds in the log and from having to use the
mOPED data structure. With EunomiaKH, overheads are
much higher, ranging from 63% to 406%. These overheads
come entirely from two sources: the cost of reading a much
larger database and the cost of performing hash adjustments
to check equality of values in diﬀerent columns. We observe
that the overhead due to the increased database size is more
than that due to hash adjustment. For the policies we exper-
imented with, the per-action overhead due to database size
grows linearly, but the overhead due to hash adjustments is
relatively constant. About 30% of ereduce’s overhead when
running on EunomiaKH comes from key-adjustments. Hence,
there is room for substantial improvement by caching previ-
ous key-adjustments, which we do not do currently.

9. RELATED WORK
Functional and predicate encryption. Functional en-
cryption [13, 20, 27, 30] allows the declassiﬁcation of any
stipulated function of data, given only the ciphertext of the
data and a decryption key. Functional encryption can be
used to implement audit over encrypted logs: The declas-
siﬁcation function can perform the audit and return the
outcome. However, existing functional encryption schemes
are not eﬃcient enough to be practically usable for audit.
Property-preserving encryption [31] and predicate encryp-
tion [38, 14, 24] are a special case of functional encryption
where the function returns a boolean value. Predicate en-
cryption can also be used to implement audit when the goal
is only to ﬁnd whether or not there is a violation (which is
a boolean outcome). However, this is usually insuﬃcient for
audit in practice. Pandey and Rouselakis [31] describe sev-
eral notions of security for symmetric predicate encryption.
Our security deﬁnition IND-CPLADET (resp., IND-CPLAKH)
is inspired by their LoR security deﬁnition.

Searchable audit log. Waters et al. [41] present a frame-
work for log conﬁdentiality and integrity with the ability
to search based on keywords. They use hash chains for
integrity and identity-based encryption [12] with extracted
keywords to provide conﬁdentiality and search [11]. In our
work, we consider conﬁdentiality of the data, but not in-
tegrity. Complementary techniques can ensure integrity of
the audit log [36, 37, 25, 23]. Our framework supports more
expressive policies than that of Waters et al. Additionally,
audit requires timestamp comparison, which their frame-
work does not support.

Order-preserving encryption. A symmetric encryption
scheme that maintains the order of the plaintext data is pro-
posed by Boldyreva et al. [10]. This scheme does not satisfy
the ideal IND-OCPA security deﬁnition. Popa et al. present
the mOPE scheme, which we enhance to support timestamp
comparison with displacements [33]. Recently, Kerschbaum
and Schr¨opfer present a keyless order-preserving encryption
scheme for outsourced data [26].
In their approach, the

owner of the plaintext data must keep a dictionary map-
ping plaintexts to ciphertexts, which would be undesirable
in our setting, where the objective is to outsource storage to
a cloud.

Querying outsourced database. Hacig¨um¨u¸s et al. [21]
develop a system that allows querying over encrypted data
by asking the client to decrypt data. In contrast, our schemes
require no interaction with the client for read-only queries.
Tu et al. [40] introduce split client/server query execution
for processing analytical queries on encrypted databases.
Our schemes do not require any query processing on the
client-side. Damiani et al.
[17] develop a secure indexing
approach for querying an encrypted database. In contrast,
we do not require modiﬁcation to the indexing algorithm of
the DBMS.

CryptDB [34] uses a trusted proxy to dynamically choose
an encryption scheme for each database column, based on
the query operations being performed on the column. More-
over, CryptDB does not provide a complete, rigorous char-
acterization of its conﬁdentiality properties, which we do.
However, CryptDB supports all SQL queries, whereas we
cannot support aggregation queries.

Privacy policy compliance checking. Prior work on
logic-based compliance checking algorithms focuses on plain-
text logs [8, 7, 9, 16, 19]. In particular, this paper adapts
our prior work [19] to execute on encrypted logs. The key
addition is the EQ mode check, which provides additional
information about predicate arguments that may be com-
pared for equality during the audit of a policy.

10. SUMMARY

In this paper, we have presented two database encryp-
tion schemes, EunomiaDET and EunomiaKH, that reveal just
enough information to allow projection, selection, join, com-
parison and displaced comparison queries. We present a
novel deﬁnition of database equivalence, which character-
izes the conﬁdentiality properties provided by our schemes.
We prove that our schemes are secure. As a concrete ap-
plication, we show how to execute audit for privacy policy
violations over logs that have been encrypted using either of
our schemes. This requires a new static analysis of policies,
which tracks pairs of columns that may be joined during
audit.

Acknowledgements. This work was partially supported
by the NSF grants CNS 1064688, CNS 1116991, CNS 1314688,
and CCF 042442 and the AFOSR MURI grant FA9550-11-1-
0137. The authors thank the anonymous reviewers for their
helpful comments.

11. REFERENCES

[1] Health Insurance Portability and Accountability Act,

1996. U.S. Public Law 104-191.

[2] Gramm-Leach-Bliley Act, 1999. U.S. Public Law

106-102.

[3] H. Andr´eka, I. N´emeti, and J. van Benthem. Modal
languages and bounded fragments of predicate logic.
Journal of Philosophical Logic, 27(3):217–274, 1998.

1142[4] K. Apt and E. Marchiori. Reasoning about prolog

programs: From modes through types to assertions.
Formal Aspects of Computing, 1994.

[5] A. Askarov and A. Sabelfeld. Gradual release:

Unifying declassiﬁcation, encryption, and key release
policies. In IEEE S&P, 2007.

[6] S. Bajaj and R. Sion. Trusteddb: A trusted hardware
based database with privacy and data conﬁdentiality.
In SIGMOD, 2011.

[7] D. Basin, F. Klaedtke, S. Marinovic, and E. Zalinescu.

Monitoring of temporal ﬁrst-order properties with
aggregations. In RV, 2013.

equations, and inner products. In EUROCRYPT,
2008.

[25] J. Kelsey and B. Schneier. Minimizing bandwidth for

remote access to cryptographically protected audit
logs. In Recent Advances in Intrusion Detection, 1999.

[26] F. Kerschbaum and A. Schroepfer. Optimal

average-complexity ideal-security order-preserving
encryption. In CCS, 2014.

[27] A. Lewko, T. Okamoto, A. Sahai, K. Takashima, and

B. Waters. Fully secure functional encryption:
Attribute-based encryption and (hierarchical) inner
product encryption. In EUROCRYPT, 2010.

[8] D. Basin, F. Klaedtke, S. Marinovic, and E. Z˘alinescu.

[28] M. Naveed, S. Kamara, and C. V. Wright. Inference

Monitoring compliance policies over incomplete and
disagreeing logs. In RV, 2012.

[9] A. Bauer, J.-C. K¨uster, and G. Vegliach. From

propositional to ﬁrst-order monitoring. In RV. 2013.
[10] A. Boldyreva, N. Chenette, Y. Lee, and A. O’Neill.

Order-preserving symmetric encryption. In
EUROCRYPT, 2009.

[11] D. Boneh, G. D. Crescenzo, R. Ostrovsky, and

G. Persiano. Public key encryption with keyword
search. Cryptology ePrint Archive, Report 2003/195.
[12] D. Boneh and M. Franklin. Identity-based encryption

from the Weil pairing. In CRYPTO, 2001.

[13] D. Boneh, A. Sahai, and B. Waters. Functional

encryption: Deﬁnitions and challenges. In TCC, 2011.

[14] D. Boneh and B. Waters. Conjunctive, subset, and

range queries on encrypted data. In TCC, 2007.

[15] O. Chowdhury, D. Garg, L. Jia, and A. Datta.

Equivalence-based Security for Querying Encrypted
Databases: Theory and Application to Privacy Policy
Audits. Technical Report CMU-CyLab-15-003, Cylab,
Carnegie Mellon University, 2015. Available at
http://arxiv.org/abs/1508.02448.

[16] O. Chowdhury, L. Jia, D. Garg, and A. Datta.

Temporal mode-checking for runtime monitoring of
privacy policies. In CAV, 2014.

[17] E. Damiani, S. D. C. Vimercati, S. Jajodia,

S. Paraboschi, and P. Samarati. Balancing
conﬁdentiality and eﬃciency in untrusted relational
dbmss. In CCS, 2003.

attacks against property-preserving encrypted
databases. In CCS, 2015.

[29] U. D. of Health & Human Services. Cignet Health

Fined a $4.3M Civil Money Penalty for HIPAA
Privacy Rule Violations. Available at
http://www.hhs.gov/ocr/privacy/hipaa/
enforcement/examples/cignetcmp.html.

[30] A. O’Neill. Deﬁnitional issues in functional

encryption. Cryptology ePrint Archive, Report
2010/556, 2010. http://eprint.iacr.org/2010/556.

[31] O. Pandey and Y. Rouselakis. Property preserving

symmetric encryption. In EUROCRYPT, 2012.

[32] R. A. Popa. Building practical systems that compute

on encrypted data. PhD thesis, MIT, 2014.
[33] R. A. Popa, F. H. Li, and N. Zeldovich. An

ideal-security protocol for order-preserving encoding.
In IEEE S&P, 2013.

[34] R. A. Popa, C. M. S. Redﬁeld, N. Zeldovich, and

H. Balakrishnan. CryptDB: Protecting conﬁdentiality
with encrypted query processing. In SOSP, 2011.

[35] R. A. Popa and N. Zeldovich. Cryptographic

treatment of CryptDB’s adjustable join. Technical
Report MIT-CSAIL-TR-2012-006, 2012.

[36] B. Schneier and J. Kelsey. Cryptographic support for

secure logs on untrusted machines. In USENIX
Security Symposium, 1998.

[37] B. Schneier and J. Kelsey. Secure audit logs to

support computer forensics. ACM TISSEC,
2(2):159–176, 1999.

[18] H. DeYoung, D. Garg, L. Jia, D. Kaynar, and

[38] E. Shen, E. Shi, and B. Waters. Predicate privacy in

A. Datta. Experiences in the logical speciﬁcation of
the HIPAA and GLBA privacy laws. In WPES, 2010.

[19] D. Garg, L. Jia, and A. Datta. Policy auditing over

incomplete logs: Theory, implementation and
applications. In CCS, 2011.

[20] V. Goyal, O. Pandey, A. Sahai, and B. Waters.

Attribute-based encryption for ﬁne-grained access
control of encrypted data. In CCS, 2006.

[21] H. Hacig¨um¨u¸s, B. Iyer, C. Li, and S. Mehrotra.

Executing SQL over encrypted data in the
database-service-provider model. In SIGMOD, 2002.
[22] S. Halevi and P. Rogaway. A tweakable enciphering

mode. In CRYPTO, 2003.

[23] J. E. Holt. Logcrypt: Forward security and public

veriﬁcation for secure audit logs. In ACSW Frontiers,
2006.

[24] J. Katz, A. Sahai, and B. Waters. Predicate

encryption supporting disjunctions, polynomial

encryption systems. In TCC, 2009.

[39] D. X. Song, D. Wagner, and A. Perrig. Practical

techniques for searches on encrypted data. In IEEE S
& P, 2000.

[40] S. Tu, M. F. Kaashoek, S. Madden, and N. Zeldovich.
Processing analytical queries over encrypted data. In
PVLDB, 2013.

[41] B. R. Waters, D. Balfanz, G. Durfee, and D. K.

Smetters. Building an encrypted and searchable audit
log. In NDSS, 2004.

1143