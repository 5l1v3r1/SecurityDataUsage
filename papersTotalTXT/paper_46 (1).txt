Private and Secure Public-Key Distance Bounding

Application to NFC Payment — Short Paper

Serge Vaudenay

EPFL

CH-1015 Lausanne, Switzerland

http://lasec.epfl.ch

Abstract. Distance-Bounding is used to defeat relay attacks. For wireless pay-
ment systems, the payment terminal is not always online. So, the protocol must
rely on a public key for the prover (payer). We propose a generic transformation
of a (weakly secure) symmetric distance bounding protocol which has no post-
veriﬁcation into wide-strong-private and secure public-key distance bounding.

1

Introduction

Several wireless payment systems have recently been spread: automatic toll payment
systems for vehicles, NFC-equipped credit cards, and NFC-equipped smartphones ap-
plications. These methods allow to pay small amounts without any action from the
holder other than approaching their device to the payment terminal. I.e., no conﬁrma-
tion is required on the credit card/smartphone and no PIN code or other credential is
requested on the payment terminal. The credit card/smartphone is typically passive.

In relay attacks, a man-in-the-middle A passively relays messages between two
participants: a prover P and a veriﬁer V [9,10]. The prover P is a credit card/smartphone
(of the payer) and the veriﬁer V is a payment terminal (of the vendor). A can be run
by two players: a malicious customer A1 mimicking a payment in a shop to buy some
service to V , and a malicious neighbor A2 to the victim P. A1 and A2 relay messages
between P and V . The payer (the victim) may not even be aware that their P is activated
and communicating. So, relay attacks can be an important threat.

So far, the most promising technique to defeat relay attacks is distance-bounding
(DB) [5]. A DB protocol includes several fast challenge/response rounds during which
the veriﬁer/vendor sends a challenge bit and expects to receive a response bit within a
very short time from the prover/payer. The protocol fails if some response arrives too
late or some response is incorrect. Due to the time of ﬂight, if P is too far from V , his
time to compute the response is already over when the challenge reaches him.

Here are the traditional threat models for distance-bounding.

– Honest-prover security: man-in-the-middle attacks (MiM) (including impersonation

fraud [1] and the so-called maﬁa fraud [8] which includes relay attacks).

– Malicious-prover security: distance fraud (DF) [5], in which a malicious prover
pretends that he is close although it is not the case; distance hijacking (DH) [7], in
which the malicious prover relies on honest close-by participants; collusion frauds
(CF) [3] (including the so-called terrorist fraud [8]), in which a malicious prover
colludes with close-by participants (but without leaking his credentials).

– Privacy, where we want that no man-in-the-middle adversary can learn the identity
of the prover. Wide/narrow privacy refers to whether the adversary can see if a
protocol succeeds on the veriﬁer side. Strong/weak privacy refers to whether the
adversary can corrupt provers and get their secret.

For payment systems, we cannot assume an online connection to a trusted server
nor a shared secret between the payer and the vendor: we must have a public-key based
protocol. We can further wonder which threat models are relevant. Clearly, the man-
in-the-middle attacks are the main concern: we must eliminate relay attacks and their
possible active extensions. Privacy is also important as payers want to remain anony-
mous to observers. Since liability is important in payment systems, the payment must
be undeniable, so it must be impossible for a malicious payer to claim having not made
a payment because he was too far. We also want to be able to catch red handed people
who pay with a stolen credit card. So, distance fraud is also a concern.

Table 1. Existing Public-Key Distance Bounding Protocols

DH

CF

Privacy Strong privacy

MiM DF

protocol
Brands-Chaum [5] secure secure insecure insecure insecure
insecure insecure
DBPK-Log [6]
insecure
secure secure
HPO [13]
insecure secure
secure secure insecure insecure insecure
GOR [11]
ProProx [18]
secure secure
secure insecure
secure insecure secure
secure secure
privDB

insecure
insecure
insecure
insecure
insecure
secure
(Missing entries correspond to absence of proof in either direction.)

So far, only ﬁve public-key distance bounding protocols exist: the original protocol
by Brands and Chaum [5], the DBPK-Log protocol by Bussard and Bagga [6], the
protocol by Hermans, Peeters, and Onete [13] (herein called the HPO protocol), its
recent extension by Gambs, Onete, and Robert [11] (the GOR protocol, herein)1, and
ProProx [18] (see Table 1). None of them (except ProProx) resist to collusion frauds.
The Brands-Chaum protocol does not resist to distance hijacking [7]. In [2], Bay et
al. have broken DBPK-Log. Neither the Brands-Chaum protocol nor ProProx protect
privacy but the HPO and GOR protocols were designed for this. However, HPO does
not offer strong privacy and privacy in GOR can be broken.2

We show how to transform a symmetric distance bounding protocol symDB into
a public-key distance bounding privDB. We prove that privDB is DF-secure, MiM-
secure, DH-secure, and strong-private by assuming some weak form of DF, MiM, and
DH security for the underlying symDB and that symDB belongs to the class of protocols
with no post-veriﬁcation. We propose a suitable symDB protocol called OTDB.

1 The GOR protocol is a bit different from others as it provides anonymous authentication. The
veriﬁer does not identify the prover in the protocol, but only gets the insurance that he holds a
valid key pair. Furthermore, the protocol is deniable: anybody can forge a valid transcript.

2 This statement will be proven in a subsequent paper.

2

2 Deﬁnitions

We recall and adapt the framework of [4,18]. We assume a multiparty setting in which
participants have a location and information travels at the speed of light. Participants
receive inputs and produce outputs. Honest participants run their purported algorithm.
Malicious participants may run an arbitrary probabilistic polynomial-time (PPT) al-
gorithm. The deﬁnition below is adapted from [4,18] to accommodate identiﬁcation
protocols and also to bridge public-key and symmetric distance bounding.
Deﬁnition 1. A distance-bounding protocol (DB) is a tuple consisting of: 1. PPT key
generation algorithms KP and KV depending on a security parameter l and produc-
ing a key pair (skP; pkP) and (skV ; pkV ), respectively; 2. a two-party PPT protocol
(P(skP; pkV );V (skV )), where P(skP; pkV ) is the proving algorithm and V (skV ) is the
verifying algorithm; 3. a distance bound B. At the end of the protocol, V (skV ) has
a private output and sends a ﬁnal message OutV . He accepts (OutV = 1) or rejects
(OutV = 0). The protocol must be complete. I.e., such that “setting up the keys” for
(P;V ) then making P(skP; pkV ) and V (skV ) interact together, at locations within a dis-
tance up to B always makes V (skV ) accept (OutV = 1) and output pkP.
For a public-key distance-bounding identiﬁcation protocol, “setting up the keys”
for P and V means running KP ! (skP; pkP) and KV ! (skV ; pkV ). For Symmetric
distance bounding protocols, provers/veriﬁers are paired and “setting up the keys” for
a pair (P;V ) means running KP ! skP then setting skV = skP and pkP = pkV = ?.
Moving to noisy settings [16] follows standard techniques which are omitted herein.

Veriﬁers are assumed to be able to validate pkP (e.g., by means of a PKI). In what

follows, Validate(pkP) denotes this operation.

Security of DB. Like in [4,18], all security notions are formalized by a game with three
types of participants: provers, veriﬁers, and actors. Each participant can have several
instances (as they may run several sessions of the protocol at different locations or
time). Without loss of generality, actors are malicious. The purported algorithm is P for
provers and V for veriﬁers. There is a distinguished instance of the veriﬁer denoted by
V . Instances of participants within a distance to V up to B are called close-by. Others
are called far-away. We say that the adversary wins if V accepts.

In security models, we only consider without loss of generality one veriﬁer (possibly
with several instances) who is further assumed to be honest. In Def. 2–3, we consider
without loss of generality only one prover (possibly with several instances) with an
identity corresponding to the key pkP.
Deﬁnition 2 ([18]). We consider the following honest-prover security notion. At the
beginning of the game, we set up the keys (following Def. 1) and give pkV as input to
all participants, skP as input to the prover instances, and pkP as input to all malicious
participants. The prover is honest. The DB protocol is MiM-secure (man-in-the-middle)
if for all such settings in which there is no close-by prover, the probability that V accepts
and outputs pkP is negligible.3
3 The key generation algorithms accepts as input a security parameter l which is omitted for
simplicity reasons. Hence, Pr[V accepts] is a function of l. We say that f (l) is negligible if
for every integer d we have f (l) = O(l(cid:0)d) for l ! +¥.

3

The DB protocol is one-time MiM-secure if the above is satisﬁed in settings where

there is a single veriﬁer instance and a single prover instance.
Deﬁnition 3 ([18]). We consider the following malicious-prover security notion. At the
beginning of the game, we use an arbitrary PPT algorithm K(pkV ) instead of KP in the
key setup. The DB protocol is DF-secure (distance fraud) if for all such settings where
there is no close-by participant except V , the probability that V accepts and outputs
pkP is negligible.
Note that the key of the malicious prover is set up maliciously (even depending on pkV )
using an algorithm K which can differ from KP.

Privacy. So far, the most general and prominent model for privacy is the simulation-
based privacy notion in [17] which was enriched in [15]. Hermans et al. [14] presented
a simpler privacy model which we call the HPVP model.
Deﬁnition 4 (HPVP Privacy [14]). We consider an adversary playing with the fol-
lowing oracles: 1. Create ! (i; pkP) runs KP and sets pkP as a valid key for a new
prover whose number is i; 2. Corrupt(i) ! state returns the current state (in perma-
nent memory) of the ith prover; 3. Draw(i; j) ! vtag draws either the ith prover (if in
the left game) or the jth prover (if in the right game) and returns a pseudonym vtag
(if the prover is already drawn, ? is returned); 4. Free(vtag) releases vtag so that
it can be drawn again; 5. SendP(vtag;m) ! m′ sends a message m to a drawn tag
vtag and gets a response m′; 6. Launch ! k runs a new veriﬁer whose number is k;
7. SendV(k;m) ! m′ sends a message m to the kth veriﬁer and gets a response m′;
8. Result(k) ! OutV gives the ﬁnal result (whether the protocol succeeded or not) of
the protocol on the kth veriﬁer side. In the privacy game, the adversary interacts with
these oracles and guesses if it is left or right. The game is formalized as follows: 1. run
KV ! (skV ; pkV ) and initialize all veriﬁers with skV and all provers and A with pkV ;
2. pick b 2 f0;1g; 3. let A interact with the oracles (in the left game for b = 0 or the
right game for b = 1) and make a guess b; 4. A wins if b = b. We have privacy if for
every PPT adversary A, Pr[A wins](cid:0) 1
2 is negligible. For narrow privacy, the adversary
does not use the Result oracle. For weak privacy, he does not use the Corrupt oracle.
Otherwise, the adversary is wide, respectively strong.

Distance Hijacking. In distance hijacking [7], the prover is malicious, running an algo-
rithm A. But we add a honest prover P(skP′; pkV ) with another identity P′ associated to
the key pair (skP′; pkP′). The malicious prover runs A(skP; pkP; pkP′; pkV ). We formal-
ize distance hijacking for DB protocols consisting of a regular (i.e., time-insensitive)
initialization phase, a time-critical challenge phase, and a regular veriﬁcation phase.
A is playing a man-in-the-middle between P(skP′; pkV ) and V (skV ) except during the
challenge phase when he remains passive. (See Fig. 1.)
Deﬁnition 5. A DB protocol (KP;KV ;P;V;B) is DH-secure if for all PPT algorithms K
and A, the following game makes V output pkP with negligible probability:
1: for public-key DB: KP ! (skP′; pkP′), KV ! (skV ; pkV ), K(pkP′; pkV )! (skP; pkP);

if pkP = pkP′, the game aborts
for symmetric DB: KP ! skP′, K ! skP, set skV = skP, pkP = pkP′ = pkV = ?;

4

;P′
1;P′

P(skP′; pkV )

phase ends for V

2: let A run A(skP; pkP; pkP′; pkV ), let V , V1;V2; : : : run V (skV ), let P′, P′
3: let A interact with P′
2 : : : and V ;V1;V2; : : : concurrently until the initialization
4: let P′ and V continue interacting with each other until the challenge phase ends
5: let A continue interacting with P′
A DB protocol is one-time DH-secure if the above holds when there are no P′

for V ; A receives the exchanged messages but remains passive

2 : : : and V ;V1;V2; : : : concurrently during

the veriﬁcation phase

1;P′

2; : : : run

;P′
1;P′

i and Vi.

V1;V2; : : :

initialization
P′
1;P′

@@I@@R

(cid:0)(cid:0)(cid:18)(cid:0)(cid:0)(cid:9)

A

challenge

A

-(cid:27) 6

2; : : :

V1;V2; : : :

@@I@@R

P′
1;P′

2; : : :

(cid:0)(cid:0)(cid:18)(cid:0)(cid:0)(cid:9)

V1;V2; : : :

veriﬁcation
P′
1;P′

@@I@@R

(cid:0)(cid:0)(cid:18)(cid:0)(cid:0)(cid:9)

2; : : :

A

(cid:0)(cid:0)(cid:18)(cid:0)(cid:0)(cid:9)

V

@@R@@I

P′

V

P′

(cid:0)(cid:0)(cid:18)(cid:0)(cid:0)(cid:9)

V

@@R@@I

P′

Fig. 1. Distance Hijacking

3 From Symmetric to Asymmetric Distance Bounding

3.1 The OTDB Protocol

We propose a one-time DB protocol OTDB based on the Hancke-Kuhn protocol [12].
It is represented on Fig. 2. We use a 2n-bit secret s. It is XORed to a random mask m
selected by the veriﬁer. The answer to a challenge in iteration i is just the bit of s(cid:8) m at
position 2i(cid:0) 1 or 2i, depending on the challenge.

We deﬁne a sub-category of simple DB protocols.

Deﬁnition 6. A symmetric DB protocol (K;P;V;B) follows the canonical structure if
there exist 5 PPT algorithms Pinit, Pchall, Vinit, Vchall, Vver such that P(s) and V (s) are
deﬁned as follows:

1. P(s) and V (s) run the initialization phase by running Pinit and Vinit, respectively.
These algorithms do not use s. They produce a ﬁnal state sP and sV , respectively.
2. P(s) and V (s) run the challenge phase by running Pchall(s;sP) and Vchall(sV ),
where Vchall does not depend on s and produces a ﬁnal state s′
V .
3. V (s) computes OutV = Vver(s;s′
The canonical point is that there is no interactive veriﬁcation and the secret is only used
by P in the challenge phase and by V in the ﬁnal veriﬁcation.

V ).

5

Veriﬁer

secret key: s

Prover

secret key: s

pick m 2 f0;1g2n

initialization phase
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)! a = s(cid:8) m

m

pick ci 2 f0;1g, start timeri
stop timeri

a = s(cid:8) m, check timeri (cid:20) 2B, ri = a2i+ci(cid:0)1

challenge phase

for i = 1 to n

ri

ci

(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)!
 (cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) ri = a2i+ci(cid:0)1
veriﬁcation phase
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)!

OutV

Fig. 2. The OTDB Protocol.

Theorem 7. OTDB follows the canonical structure. It is DF-secure, one-time MiM-
secure, and one-time DH-secure.

n
w

3
4

w=0

(

)

Proof. The canonical structure of OTDB is clear.
For DF-security, we observe that whatever the adversary is doing, the distribution
of a on the veriﬁer side is uniform in f0;1g2n. Since there is no close-by partici-
pant, a response can be received on time only if it was sent before the challenge was
known. If a2i(cid:0)1 = a2i, this can be done with probability 1. Otherwise, this can only
be done with probability 1
2. So, the optimal probability that all responses are correct is
(cid:229)n

)n which is negligible.

2(cid:0)n(cid:0)w =

(

(

4 . So, the probability of success is also

)n, which is negligible.

For one-time MiM-security, we consider a distant V = V (s) and P(s) with several
actors. By playing with P(s), the adversary can deduce for each i either s2i(cid:0)1 or s2i but
not both. To answer to V , he must know precisely which of these two bits is needed but
when he learns it, it is too late to play with P(s) to get it. So, the probability to pass one
round is limited to 3
For one-time DH-security, we consider P′ who is set up with a random s and V
who is maliciously set up with an independent s′. In the initialization part (which can
be corrupted), we let m be the value sent by V and m′ be the value received by P′.
When they start the challenge phase, V uses a = s′ (cid:8) m and P′ uses a′
= s(cid:8) m′, where
m′ only depends on m and s′. So, a′ is uniformly distributed and independent from a.
The challenge part between P′ and V cannot be corrupted, by deﬁnition of the one-time
⊓⊔
DH-security. Hence, V accepts with probability 2(cid:0)n, which is negligible.
As concrete parameters, we can use n = 49 for a 2(cid:0)20 security. (Since attacks must

3
4

be online, these levels of security are sufﬁcient in practice.)

3.2 The privDB Protocol

We adapt the RFID protocol from [15,17] for DB. We assume that KV generates a key
pair for a public-key cryptosystem Enc/Dec and that KP generates a key pair for a digital
signature scheme Sign/Verify. The protocol runs as follows (see Fig. 3): 1. V sends a
nonce N to P; 2. P picks a random s and sends EncpkV (s∥pkP∥N∥SignskP (N)) to V ; 3. V

6

decrypts, checks that N is the same, veriﬁes the signature on N, and validates pkP (if
this step fails, V sends OutV = 0 and aborts); 4. P and V run a symmetric DB symDB
based on the secret s (if this step fails, V sends OutV = 0 and aborts); 5. the private
output of V is set to pkP and the public one is set to OutV = 1. Compared to HPO [13],
the encrypted channel can also be used to transmit a certiﬁcate in a private way.

Veriﬁer

secret key: skV
public key: pkV

pick N
s∥pk∥N∥s = DecskV (e)
check N, Verifypk(s;N), and Validate(pk)

private output: pk

Prover

secret key: skP
public key: pkP

N

e

(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)! pick s, s = SignskP (N)
 (cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0) e = EncpkV (s∥pkP∥N∥s)
 (cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)!
(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)!

symDB(s)

OutV

Fig. 3. privDB: Strong Private Public-Key DB from Symmetric DB.

Theorem 8. If symDB is DF-secure then privDB is DF-secure.

The reduction is quite trivial.
Theorem 9. If 1. symDB is one-time MiM-secure, 2. the signature scheme resists to
chosen-message universal forgery attacks (UF-CMA secure), 3. the cryptosystem resists
chosen-ciphertext attacks (IND-CCA secure), then privDB is MiM-secure.
Proof. We let G0 denote the MiM security game. In what follows, Gi is a game and
pi denotes the probability that Gi succeeds. We want to show that p0 is negligible. We
ﬁrst reduce G0 to a game G1 in which no two veriﬁers select the same nonce. Clearly,
p1 (cid:0) p0 is negligible. Let N be the value chosen by V . We call the instances of P
who are given N the “matching instances”. We reduce G1 to a game G2 in which no
two matching instances select the same s value. Clearly, p2 (cid:0) p1 is negligible. So, two
matching instances cannot produce the same e value in G2.
We reduce G2 to a game G3 in which we simulate all veriﬁers other than V who
receive an e produced by a matching instance. The simulation is made by making these
veriﬁers abort, as this would be the normal behavior due to N mismatch. So, p3 = p2.
We ﬁrst consider the case where V is not given any e coming from a matching
instance and show this can only succeed in negligible cases. In this case, no e coming
from a matching instance needs to be decrypted. So, we can use the IND-CCA security
and replace (with hybrid arguments) each such e by the encryption of a random string
and get a similar advantage. We obtain a new game G4 such that p4 (cid:0) p3 is negligible.
Hence, we can now modify the simulation of matching instances by not computing any
signature of N: the signature s will not be used anyway. We obtain a new game G5 such
that p5 = p4. Now, in G5 we can simulate other prover instances with a signing oracle
and use the UF-CMA security with N as the challenge message. Clearly, if V accepts,
there was some forgery. So, due to UF-CMA security, p5 is negligible.

7

Now, we are left with the remaining case where V is given some e coming from a
unique matching instance P. We make some further change in the simulation of V and
deﬁne G6: we make V skip the decryption of e and continue with the values encrypted
by P. Due to the correctness of the cryptosystem, we have p6 = p3. Next, we deﬁne G7
in which we replace e by the encryption of a random string. Due to IND-CCA security,
we have that p7 (cid:0) p6 is negligible. We obtain a game G7 in which P selects a random s
and runs with V a single instance of symDB. Note that this s is not used anywhere else,
but in symDB, and that s is random. Since P is far away, we are now in the conﬁguration
of a one-time MiM attack against symDB. So, we can now invoke the one-time MiM-
⊓⊔
security of symDB and conclude that p7 must be negligible.
Theorem 10. If symDB is one-time MiM-secure, one-time DH-secure, and follows the
canonical structure, and if the cryptosystem resists chosen-ciphertext attacks (IND-CCA
secure), then privDB is DH-secure.
Proof. We let G0 denote the DH security game. In what follows, Gi is a game and pi
denotes the probability that Gi succeeds. We want to show that p0 is negligible.
Since symDB has no interactive veriﬁcation, G0 consists of two phases after the
key set up: the initialization phase and the challenge phase. The last phase matches the
challenge phase of symDB between V and P′ alone: we can assume without loss of
generality that A, the Vi’s and P′
i ’s play no longer role in this phase. The main point is
to realize that for V to identify pkP, the V and P′ must start with two independent keys
s′ and s, and use the one-time DH-security of symDB.

i ’s but assume that A gets skP′.

Without loss of generality, we replace A by the simulation of A and all P′

i in the
DH game. (So, our new adversary is knowing skP′. But this secret plays no role in
DH-security.) So, we can ignore the P′
We ﬁrst reduce G0 to a game G1 in which no two veriﬁers select the same nonce.
Clearly, p1 (cid:0) p0 is negligible. In what follows, we let N, s, and e denote the values in
the protocol as seen by P′. We note that if V is given e, it will decrypt to pkP′ which is
different from pkP. So, the game cannot succeed. So, we reduce G1 to a game G2 which
aborts if e is given to V . We have p2 = p1.
Next, we reduce G2 to a game G3 in which we simulate as follows the Vi’s who
receive e. If Vi receives e but did not select N before, we simulate Vi by rejecting the
protocol (we know this is his normal behavior in G2). If Vi receives e and did select
N before (there can’t be several such Vi’s), instead of decrypting e, we simulate Vi by
directly using the values used by P′ during the encryption into e. Clearly, p3 = p2. We
obtain a game in which e is never decrypted.
We reduce G3 into a new game G4 in which the value e is replaced by the encryption
of a random string. Since pkV can be externally set up and that we can outsource all
decryption operations in G3 and G4 to a decryption oracle who is never invoked with e,
we deduce from the IND-CCA security that p4 (cid:0) p3 is negligible.
If no Vi selected N and received e, only P′ is set up with a random s to run symDB
and no other algorithm receives s in the game. Due to the canonical structure of symDB,
the P′ run in the initialization phase does not depend on s, so the symDB key by V is
independent from s. So, the challenge phase in G4 is between P′ and V who are set up
with independent keys, the one for P′ being uniform. By using the one-time DH-security
of symDB, this succeeds with negligible probability. So, p4 is negligible.

8

If now one Vi selected a and received e (we know that there is no more than one
such Vi) we assume this is V1 without loss of generality. If V1 does not compute his
OutV before the challenge phase of the game, none of his message depend on s due to
the canonical structure of symDB, so we can proceed as in the previous case.

Now, if V1 sends out his OutV before the challenge phase of the game, we deﬁne a
new game G5 in which OutV is replaced by 0. In G5, we can conclude as in the previous
case. So, what is left to be shown is that OutV = 1 with negligible probability in G4. For
that, we observe that P′ is only running the initialization of OutV (so do not depend on s
by assumption on OutV ). Since V1 is set up with a random s and that no other algorithm
depends on s during the execution of symDB by V1, we are in an impersonation attack
⊓⊔
case. Due to the one-time MiM security of OutV , we conclude.
Theorem 11. If the cryptosystem resists chosen-ciphertext attacks (IND-CCA secure),
privDB is wide-strong private in the HPVP model.
Proof. We let G0 denote the wide-strong HPVP privacy game. In what follows, Gi is a
game and pi denotes the probability that Gi succeeds. We want to show that p0 (cid:0) 1
2 is
negligible. We deﬁne a game G1 in which we simulate the veriﬁers who receive some
e which was released by any prover by skipping the decryption process and continuing
with the correct values which were encrypted by the prover. More precisely, we only
take s and N and verify that N is correct. (We know the signature is correct since it was
correctly produced by a prover.) Note that the actual value of pkP which is used as a
private output of the veriﬁer is never used in the game. So, only s and N are important
for this simulation with a matching e. Due to correctness of the cryptosystem and of the
signature scheme, we have p1 = p0.

Next, we construct G2 in which we replace each e released by a prover by the en-
cryption of a random string using hybrids. Thanks to IND-CCA security, we obtain that
p2 (cid:0) p1 is negligible.
We observe that in G2, the public keys pkP and signatures of the prover are never
used. So, we deﬁne a game G3 in which the simulation of the prover is changed by not
computing the signature. Clearly, p3 = p2.

We now have a game in which provers never use their identity. It does not matter
which provers are drawn (the left or the right), the simulation of the prover is the same.
⊓⊔
So the probability of correctly winning b = b must be exactly p3 = 1
2 .

4 Conclusion

We have constructed a public-key DB protocol which is the ﬁrst to be provably DH-
secure and the ﬁrst to be strong private.

References

1. G. Avoine, A. Tchamkerten. An Efﬁcient Distance Bounding RFID Authentication Proto-
col: Balancing False-Acceptance Rate and Memory Requirement. In Information Security
ISC’09, Pisa, Italy, Lecture Notes in Computer Science 5735, pp. 250–261, Springer-Verlag,
2009.

9

2. A. Bay, I. Boureanu, A. Mitrokotsa, I. Spulber, S. Vaudenay. The Bussard-Bagga and
Other Distance-Bounding Protocols under Attacks. In INSCRYPT’12, Beijing, China, Lec-
ture Notes in Computer Science 7763, pp. 371–391, Springer-Verlag, 2012.

3. I. Boureanu, A. Mitrokotsa, S. Vaudenay. Towards Secure Distance Bounding. In Fast
Software Encryption’13, Singapore, Lecture Notes in Computer Science 8424, pp. 55–67,
Springer-Verlag, 2013.

4. I. Boureanu, S. Vaudenay. Optimal Proximity Proofs. IACR Eprint 2014/693 report, 2014.

To appear in the proceedings of INSRYPT’14.

5. S. Brands, D. Chaum. Distance-Bounding Protocols (Extended Abstract). In Advances in
Cryptology EUROCRYPT’93, Lofthus, Norway, Lecture Notes in Computer Science 765,
pp. 344–359, Springer-Verlag, 1994.

6. L. Bussard, W. Bagga. Distance-Bounding Proof of Knowledge to Avoid Real-Time Attacks.
In IFIP TC11 International Conference on Information Security SEC’05, Chiba, Japan, pp.
223–238, Springer, 2005.

7. C.J. F. Cremers, K.B. Rasmussen, B. Schmidt, S. ˇCapkun. Distance Hijacking Attacks on
Distance Bounding Protocols. In IEEE Symposium on Security and Privacy S&P’12, San
Francisco, California, USA, pp. 113–127, IEEE Computer Society, 2012.

8. Y. Desmedt. Major Security Problems with the “Unforgeable” (Feige-)Fiat-Shamir Proofs
of Identity and How to Overcome Them. In Congress on Computer and Communication
Security and Protection Securicom’88, Paris, France, pp. 147–159, SEDEP Paris France,
1988.

9. A. Francillon, B. Danev, S. ˇCapkun. Relay Attacks on Passive Keyless Entry and Start Sys-
tems in Modern Cars. In Network and Distributed System Security Symposium (NDSS’11),
San Diego, CA, USA, The Internet Society, 2011.

10. L. Francis, G. Hancke, K. Mayes, K. Markantonakis. On the Security Issues of NFC En-
abled Mobile Phones. International Journal of Internet Technology and Secured Transac-
tions (IJITST), vol. 2, pp. 336–356, 2010.

11. S. Gambs, C. Onete, J.-M. Robert. Prover Anonymous and Deniable Distance-Bounding Au-
thentication. In ACM Symposium on Information, Computer and Communications Security
(ASIACCS’14), Kyoto, Japan, pp. 501–506, ACM Press, 2014.

12. G.P. Hancke, M.G. Kuhn. An RFID Distance Bounding Protocol. In Conference on Security
and Privacy for Emerging Areas in Communications Networks SecureComm’05, Athens,
Greece, pp. 67–73, IEEE, 2005.

13. J. Hermans, R. Peeters, C. Onete. Efﬁcient, Secure, Private Distance Bounding without Key
Updates. In ACM Conference on Security and Privacy in Wireless and Mobile Networks
WISEC’13, Budapest, Hungary, pp. 195–206, ACM, 2013.

14. J Hermans, A. Pashalidis, F. Vercauteren, B. Preneel. A New RFID Privacy Model. In Com-
puter Security - ESORICS’11, Leuven, Belgium, Lecture Notes in Computer Science 6879,
pp. 568–587, Springer-Verlag, 2011.

15. K. Ouaﬁ, S. Vaudenay. Strong Privacy for RFID Systems from Plaintext-Aware Encryption.
In Cryptology and Network Security, 8th International Conference CANS’12, Darmstadt,
Germany, Lecture Notes in Computer Science 7712, pp. 247–262, Springer-Verlag, 2012.

16. D. Singel´ee, B. Preneel. Distance Bounding in Noisy Environments. In Security and Privacy
in Ad-hoc and Sensor Networks ESAS 2007, Cambridge, UK, Lecture Notes in Computer
Science 4572, pp. 101–115, Springer-Verlag, 2007.

17. S. Vaudenay. On Privacy Models for RFID. In Advances in Cryptology ASIACRYPT’07,
Kuching, Malaysia, Lecture Notes in Computer Science 4833, pp. 68–87, Springer-Verlag,
2007.

18. S. Vaudenay. Proof of Proximity of Knowledge. IACR Eprint 2014/695 report, 2014.

10

