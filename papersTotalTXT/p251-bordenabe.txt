Optimal Geo-Indistinguishable Mechanisms for

Location Privacy

Nicolás E. Bordenabe

INRIA and École Polytechnique
nbordenabe@lix.polytechnique.fr

Konstantinos Chatzikokolakis
CNRS and École Polytechnique

kostas@lix.polytechnique.fr

Catuscia Palamidessi

INRIA and École Polytechnique
catuscia@lix.polytechnique.fr

ABSTRACT
We consider the geo-indistinguishability approach to loca-
tion privacy, and the trade-oﬀ with respect to utility. We
show that, given a desired degree of geo-indistinguishability,
it is possible to construct a mechanism that minimizes the
service quality loss, using linear programming techniques. In
addition we show that, under certain conditions, such mech-
anism also provides optimal privacy in the sense of Shokri
et al. Furthermore, we propose a method to reduce the
number of constraints of the linear program from cubic to
quadratic, maintaining the privacy guarantees and without
aﬀecting signiﬁcantly the utility of the generated mecha-
nism. This reduces considerably the time required to solve
the linear program, thus enlarging signiﬁcantly the location
sets for which the optimal mechanisms can be computed.

Categories and Subject Descriptors
C.2.0 [Computer–Communication Networks]: General—
Security and protection; K.4.1 [Computers and Society]:
Public Policy Issues—Privacy

Keywords
Location privacy; Location obfuscation; Geo-indistinguisha-
bility; Diﬀerential privacy; Linear optimization

1.

INTRODUCTION

While location-based systems (LBSs) have demonstrated
to provide enormous beneﬁts to individuals and society, these
beneﬁts come at the cost of users’ privacy: as discussed in
[1, 2, 3], location data can be easily linked to a variety of
other information about an individual, and expose sensitive
aspects of her private life such as her home address, her polit-
ical views, her religious practices, etc.. There is, therefore, a
growing interest in the development of location-privacy pro-
tection mechanisms (LPPMs), that allow to use LBSs while

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11˙..$15.00.
http://dx.doi.org/10.1145/2660267.2660345.

providing suﬃcient privacy guarantees for the user. Most of
the approaches in the literature are based on perturbing the
information reported to the LBS provider, so to prevent the
disclosure of the user’s location [4, 5, 6, 7, 8, 9].

Clearly, the perturbation of the information sent to the
LBS provider leads to a degradation of the quality of ser-
vice, and consequently there is a trade-oﬀ between the level
of privacy that the user wishes to guarantee and the service
quality loss (QL) that she will have to accept. The study
of this trade-oﬀ, and the design of mechanisms which opti-
mize it, is an important research direction started with the
seminal paper of Shroki et al. [10].

Obviously, any such study must be based on meaningful
notions of privacy and of quality loss. The authors of [10]
consider the privacy threats deriving from a Bayesian ad-
versary. More speciﬁcally, they assume that the adversary
knows the prior probability distribution on the user’s pos-
sible locations, and they quantify privacy as the expected
error, namely the expected distance between the true loca-
tion and the best guess of the adversary once she knows the
location reported to the LBS. We refer to this quantity as
AdvError. The adversary’s guess takes into account the
information already in her possession (the prior probabil-
ity), and it is by deﬁnition more accurate, in average, than
the reported location. We also say that the adversary may
remap the reported location.

The notion of quality loss adopted in [8] is also deﬁned in
terms of the expected distance between the real location and
the reported location, with the important diﬀerence that the
LBS is not assumed to know the user’s prior distribution (the
LBS is not tuned for any speciﬁc user), and consequently it
does not apply any remapping. Note that the notion of dis-
tance used for expressing QL does not need to be the same
as the one used to measure location privacy. When these two
notions coincide, then QL is always greater than or equal to
the location privacy, due to the fact that the adversary can
make use of the prior information to her advantage. The op-
timal mechanism of [8] is deﬁned as the one which maximizes
privacy for a given QL threshold, and since these measures
are linear functions of the noise (characterized by the con-
ditional probabilities of each reported location given a true
location), such mechanism can be computed by solving a
linear optimization problem.

In this paper, we consider the geo-indistinguishability fra-
mework of [9], a notion of location privacy based on dif-
ferential privacy [11], and more precisely, on its extension
to arbitrary metrics proposed in [12]. Intuitively, a mecha-

251nism provides geo-indistinguishability if two locations that
are geographically close have similar probabilities to gener-
ate a certain reported location. Equivalently, the reported
location will not increase by much the adversary’s chance to
distinguish the true location among the nearby ones. Note
that this notion protects the accuracy of the location: the
adversary is allowed to distinguish locations which are far
away.
It is important to note that the property of geo-
indistinguishability does not depend on the prior. This is a
feature inherited from diﬀerential privacy, which makes the
mechanism robust with respect to composition of attacks in
the same sense as diﬀerential privacy.

We study the problem of optimizing the trade-oﬀ between
geo-indistinguishability and quality of service. More pre-
cisely, given a certain threshold on the degree of geo-indistin-
guishability, and a prior, we aim at obtaining the mechanism
K which minimizes QL. Thanks to the fact that the prop-
erty of respecting the geo-indistinguishability threshold can
be expressed by linear constraints, we can reduce the prob-
lem of producing such a K to a linear optimization problem,
which can then be solved by using standard techniques of
linear programming.

It should be remarked that our approach is, in a sense,
dual wrt the one of [8]. The latter ﬁxes a bound on QL and
optimizes the location privacy. Here, on the contrary, we ﬁx
a bound on the location privacy and then optimize QL. An-
other important diﬀerence is that in [8] the privacy degree of
the optimal mechanism, measured by AdvError, is guar-
anteed for a speciﬁc prior only, while in our approach the
privacy guarantee of the optimal mechanism is in terms of
geo-indistinguihability, which does not depend on the prior.
In our opinion, this is an important feature of the present
approach, as it is diﬃcult to control the prior knowledge of
the adversary. Consider, for instance, a user for which the
optimal mechanism has been computed with respect to his
average day (and consequent prior π), and who has very dif-
ferent habits in the morning and in the afternoon. By simply
taking into account the time of the day, the adversary gains
some additional knowledge that determines a diﬀerent prior,
and the privacy guarantees of the optimal mechanism of [8]
can be severely violated when the adversary uses a prior
diﬀerent from π.

However, when the notion of distance used to measure
the QL coincides with that used for expressing the degree
of privacy according to AdvError, then, somewhat sur-
prisingly, our optimal mechanism K turns out to be also
optimal in terms of AdvError, in a sense getting the best
of both approaches. Intuitively, this is due to the fact that
the property of geo-indistinguishability is not aﬀected by
remapping. Hence, the expected error of the adversary must
coincide with QL, i.e., the adversary cannot gain anything
by any remapping H, or otherwise KH would be still geo-
indistinguishable and provide a better QL. Since privacy co-
incides with the QL, it must also be optimal. In conclusion,
we obtain a geo-indistinguishable K with minimum QL and
maximum degree of privacy (for that QL).

Note that the optimal mechanisms are not unique, and
ours does not usually coincide with the one produced by the
algorithm of [8]. In particular the one of [8] in general does
not provide geo-indistinguishability, while ours does, by de-
sign. The robustness of the geo-indistinguishability property
seems to aﬀect favorably also other notions of privacy: We
have evaluated the two mechanisms with the privacy deﬁni-

tion of [8] on two real datasets, and we have observed that,
while the mechanism of [8] by deﬁnition oﬀers the best pri-
vacy on the prior for which it is computed, ours can perform
signiﬁcantly better when we consider diﬀerent priors.

We now turn our attention to eﬃciency concerns. Since
the optimal mechanism is obtained by solving a linear op-
timization problem, the eﬃciency depends crucially on the
number of constraints used to express geo-indistinguishability.
We note that this number is, in general, cubic with respect
to the amount of locations considered. We show that we are
able to reduce this number from cubic to quadratic, using
an approximation technique based on constructing a suitable
spanning graph of the set of locations. The idea is that, in-
stead of considering the geo-indistinguishability constraints
for every pair of locations, we only consider those for every
edge in the spanning graph. We also show, based on exper-
imental results, that for a reasonably good approximation
our approach oﬀers an improvement in running time with
respect to method of Shokri et al. We must note however
that the mechanism obtained this way is no longer optimal
with respect to the original metric, but only with respect to
the metric induced by the graph, and therefore the QL of
the mechanism might be higher, although our experiments
also show that this increase is not signiﬁcant.

Note that in this paper we focus on the case of sporadic
location disclosure, that is, we assume that there is enough
time between consecutive locations reported by the user,
and therefore they can be considered independent. Geo-
indistinguishability can be applied also in case of correla-
tion between consecutive points, but additional care must
be taken to avoid the degradation of privacy, that could be
signiﬁcant when the number of consecutive locations is high.
The problem of correlation is orthogonal to to the goals of
this paper. We refer to [13] for a study of this problem.

Contribution.

The main contributions of this paper are the following:
• We present a method based on linear optimization
to generate a mechanism that is geo-indistinguishable
and achieves optimal utility. Furthermore when the
notions of distance used for QL coincide with that used
for geo-indistinguishability, then the mechanism is also
optimal with respect to the expected error of the ad-
versary.

• We evaluate our approach under diﬀerent priors (gen-
erated from real traces of two widely used datasets),
and show that it outperforms the other mechanisms
considered.

• We propose an approximation technique, based on span-
ning graphs, that can be used to reduce the number of
constraints of the optimization problem and still ob-
tain a geo-indistinguishable mechanism.

• We measure the impact of the approximation on the
utility and the number of constraints, and analyze the
running time of the whole method, obtaining favorable
results.

Plan of the paper.

The rest of the paper is organized as follows. Next section
recalls some preliminary notions. In Section 3 we illustrate

252our method to produce a geo-indistinguishable and optimal
mechanism as the solution of a linear optimization prob-
lem, and we propose a technique to reduce the number of
constraints used in the problem. In Section 4 we evaluate
our mechanism with respect to other ones in the literature.
Finally, in Section 5, we discuss related work and conclude.

The missing proofs can be found in the report version of

this paper [14].

2. PRELIMINARIES
2.1 Location obfuscation, quality loss and ad-

versary’s error

A common way of achieving location privacy is to apply a
location obfuscation mechanism, that is a probabilistic func-
tion K : X → P(X ) where X is the set of possible locations,
and P(X ) denotes the set of probability distributions over
X . K takes a location x as input, and produces a reported
location z which is communicated to the service provider.
In this paper we generally consider X to be ﬁnite, in which
case K can be represented by a stochastic matrix, where kxz
is the probability to report z from location x.
A prior distribution π ∈ P(X ) on the set of locations can
be viewed either as modelling the behaviour of the user (the
user proﬁle), or as capturing the adversary’s side informa-
tion about the user. Given a prior π and a metric d on
X , the expected distance between the real and the reported
location is:

ExpDist(K, π, d) =(cid:80)

x,z πxkxzd(x, z)

From the user’s point of view, we want to quantify the
service quality loss (QL) produced by the mechanism K.
Given a quality metric dQ on locations, such that dQ(x, z)
measures how much the quality decreases by reporting z
when the real location is x (the Euclidean metric d2 being
a typical choice), we can naturally deﬁne the quality loss
as the expected distance between the real and the reported
location, that is QL(K, π, dQ) = ExpDist(K, π, dQ). The
QL can also be viewed as the (inverse of the) utility of the
mechanism.

Similarly, we want to quantify the privacy provided by
K. A natural approach, introduced in [10] is to consider a
Bayesian adversary with some prior information π, trying to
remap z back to a guessed location ˆx. A remapping strategy
can be modelled by a stochastic matrix H, where hz ˆx is the
probability to map z to ˆx. Then the privacy of the mech-
anism can be deﬁned as the expected error of an adversary
under the best possible remapping:

AdvError(K, π, dA) = min
H

ExpDist(KH, π, dA)

Note that the composition KH of K and H is itself a mech-
anism. Similarly to dQ, the metric dA(x, ˆx) captures the
adversary’s loss when he guesses ˆx while the real location is
x. Note that dQ and dA can be diﬀerent, but the canonical
choice is to use the Euclidean distance for both.

A natural question, then, is to construct a mechanism that

achieves optimal privacy, given a QL constraint.

Definition 1. Given a prior π, a quality metric dQ, a
quality bound q and an adversary metric dA, a mechanism
K is q-OptPriv(π, dA, dQ) iﬀ

1. QL(K, π, dQ) ≤ q, and

2. for all mechanisms K(cid:48), QL(K(cid:48), π, dQ) ≤ q implies

AdvError(K(cid:48), π, dA) ≤ AdvError(K, π, dA)

In other words, a q-OptPriv mechanism provides the best
privacy (expressed in terms of AdvError) among all mech-
anisms with QL at most q. This problem was studied in [8],
providing a method to construct such a mechanism for any
q, π, dA, dQ, by solving a properly constructed linear pro-
gram.
2.2 Differential privacy

Diﬀerential privacy was originally introduced in the con-
text of statistical databases, requiring that a query should
produce similar results when applied to adjacent databases,
i.e. those diﬀering by a single row. The notion of adjacency
is related to the Hamming metric dh(x, x(cid:48)) deﬁned as the
number of rows in which x, x(cid:48) diﬀer. Diﬀerential privacy re-
quires that the greater the hamming distance between x, x(cid:48)
is, the more distinguishable they are allowed to be.
This concept can be naturally extended to any set of se-
crets X , equipped with a metric dX [15, 12]. The distance
dX (x, x(cid:48)) expresses the distinguishability level between x and
x(cid:48):
if the distance is small then the secrets should remain
indistinguishable, while secrets far away from each other are
allowed to be distinguished by the adversary. The metric
should be chosen depending on the application at hand and
the semantics of the privacy notion that we try to achieve.
Following the notation of [12], a mechanism is a proba-
bilistic function K : X → P(Z), where Z is a set of re-
ported values (assumed ﬁnite for the purposes of this pa-
per). The similarity between probability distributions can
be measured by the multiplicative distance dP deﬁned as
µ2(z)| = 0 if both
dP (µ1, µ2) = supz∈Z | ln µ1(z)
µ1(z), µ2(z) are zero and ∞ if only one of them is zero.
In other words, dP (µ1, µ2) is small iﬀ µ1, µ2 assign similar
probabilities to each value z.

µ2(z)| with | ln µ1(z)

The generalized variant of diﬀerential privacy under the

metric dX , called dX -privacy, is deﬁned as follows:

Definition 2. A mechanism K : X → P(Z) satisﬁes

dX -privacy iﬀ:

(cid:48)
dP (K(x), K(x

)) ≤ dX (x, x

(cid:48)

)

∀x, x

(cid:48) ∈ X

or equivalently K(x)(z) ≤ edX (x,x(cid:48))K(x(cid:48))(z) for all x, x(cid:48) ∈
X , z ∈ Z. A privacy parameter  can also be introduced by
scaling the metric dX (note that dX is itself a metric).

Diﬀerential privacy can then be expressed as dh-privacy.
Moreover, diﬀerent metrics give rise to various privacy no-
tions of interest; several examples are given in [12].
2.3 Geo-indistinguishability

In the context of location based systems the secrets X are
locations, and we can obtain a useful notion of location pri-
vacy by naturally using the Euclidean distance d2, scaled by
a security parameter . The resulting notion of d2-privacy,
called -geo-indistinguishability in [9], requires that a loca-
tion obfuscation mechanism should produce similar results
when applied to locations that are geographically close. This
prevents the service provider from inferring the user’s loca-
tion with accuracy, while allowing him to get approximate
information required to provide the service. Following the
spirit of diﬀerential privacy, this deﬁnition is independent
from the prior information of the adversary.

253A characterization of geo-indistinguishability from [9] pro-
vides further intuition about this notion. The character-
ization compares the adversary’s conclusions (a posterior
distribution) to his initial knowledge (a prior distribution).
Since some information is supposed to be revealed (i.e. the
provider will learn that the user is somewhere around Paris),
we cannot expect the two distributions to coincide. How-
ever, geo-indistinguishability implies that an informed ad-
versary who already knows that the user is located within
a small area N , cannot improve his initial knowledge and
locate the user with higher accuracy. More details, together
with a second characterization can be found in [9].

Note that geo-indistinguishability does not guarantee a
small leakage under any prior; in fact no obfuscation mech-
anism can ensure this while oﬀering some utility. Consider,
for instance, an adversary who knows that the user is lo-
cated at some airport, but not which one. Unless the noise
is huge, reporting an obfuscated location will allow the exact
location to be inferred, but this is unavoidable.1.

Considering the mechanism, [9] shows that geo-indistingui-
shability can be achieved by adding noise to the user’s loca-
tion drawn from a 2-dimensional Laplace distribution. This
can be easily done in polar coordinates by selecting and an-
gle uniformly and a radius from a Gamma distribution. If
a restricted set of reported locations is allowed, then the lo-
cation produced by the mechanism can be mapped back to
the closest among the allowed ones.

Although the Laplace mechanism provides an easy and
practical way of achieving geo-indistinguishability, indepen-
dently from any user proﬁle, its utility is not always optimal.
In the next section we show that by tailoring a mechanism
to a prior corresponding to a speciﬁc user proﬁle, we can
achieve better utility for that prior, while still satisfying
geo-indistinguishability, i.e. a privacy guarantee indepen-
dent from the prior. The evaluation results in Section 4
show that the optimal mechanism can provide substantial
improvements compared to the Laplace mechanism.

3. GEO-INDISTINGUISHABLE

MECHANISMS OF OPTIMAL UTILITY
As discussed in the introduction, we aim at obtaining a
mechanism that optimizes the tradeoﬀ between privacy (in
terms of geo-indistinguishability) and quality loss (in terms
the metric QL). Our main goal is, given a set of locations X
with a privacy metric dX (typically the Euclidean distance),
a privacy level , a user proﬁle π and a quality metric dQ, to
ﬁnd an dX -private mechanism such that its QL is as small
as possible.

We start by describing a set of linear constraints that en-
force dX -privacy, which allows to obtain an optimal mecha-
nism as a linear optimization problem. However, the number
of constraints can be large, making the approach computa-
tionally demanding as the number of locations increases. As
a consequence, we propose an approximate solution that re-
places dX with the metric induced by a spanning graph.
We discuss a greedy algorithm to calculate the spanning
graph and analyze its running time. We also show that, if
the quality and adversary metrics coincide, then the con-
structed (exact or approximate) mechanisms also provide

1This example is the counterpart of the well-known Terry
Gross example from [11]

optimal privacy in terms of AdvError. Finally, we discuss
some practical considerations of our approach.
3.1 Constructing an optimal mechanism
The constructed mechanism is assumed to have as both
input and output a predetermined ﬁnite set of locations X .
For instance, X can be constructed by dividing the map in
a ﬁnite number of regions (of arbitrary size and shape), and
selecting in X a representative location for each region. We
also assume a prior π over X , representing the probability
of the user being at each location at any given time.

Given a privacy metric dX (typically the Euclidean dis-
tance) and a privacy parameter , the goal is to construct
a dX -private mechanism K such that the service quality
loss with respect to a quality metric dQ is minimum. This
property is formally deﬁned below:

Definition 3. Given a prior π, a privacy metric dX , a
privacy parameter  and a quality metric dQ, a mechanism
K is dX -OptQL(π, dQ) iﬀ:

1. K is dX -private, and
2. for all mechanisms K(cid:48), if K(cid:48) is dX -private then

QL(K, π, dQ) ≤ QL(K(cid:48), π, dQ)

Note that dX -OptQL optimizes QL given a privacy con-
straint, while q-OptPriv (Deﬁnition 1) optimizes privacy,
given an QL constraint.

In order for K to be dX -private it should satisfy the fol-

lowing constraints:

kxz ≤ edX (x,x(cid:48))kx(cid:48)z

x, x(cid:48), z ∈ X

Hence, we can construct an optimal mechanism by solving a
linear optimization problem, minimizing QL(K, π, dQ) while
satisfying dX -privacy:

Minimize:

πxkxzdQ(x, z)

Subject to: kxz ≤ edX (x,x(cid:48))kx(cid:48)z

(cid:88)
(cid:88)

x,z∈X

kxz = 1

z∈X
kxz ≥ 0

x, x

(cid:48)

, z ∈ X
x ∈ X

x, z ∈ X

It is easy to see that the mechanism K generated by the

previous optimization problem is dX -OptQL(π, dQ).
3.2 A more efﬁcient method using spanners
In the optimization problem of the previous section, the
dX -privacy deﬁnition introduces |X|3 constraints in the lin-
ear program. However, in order to be able to manage a large
number of locations, we would like to reduce this amount to
a number in the order of O(|X|2). One possible way to
achieve this is to use the dual form of the linear program
(shown in the appendix). The dual program has as many
constraints as the variables of the primal program (in this
case |X|2) and one variable for each constraint in the pri-
mal program (in this case O(|X|3)). Since the primal linear
program ﬁnds the optimal solution in a ﬁnite number of
steps, it is guaranteed by the strong duality theorem that
dual program will also do so. However, as shown in Section
4.3, in practice the dual program does not oﬀer a substan-
tial improvement with respect to the primal one (a possible

254explanation being that, although fewer in number, the con-
strains in the dual program are more complex, in the sense
that each one of them involves a larger number of variables).
An alternative approach is to exploit the structure of the
metric dX . So far we are not making any assumption about
dX , and therefore we need to specify |X| constraints for each
pair of locations x and x(cid:48). However, it is worth noting that
if the distance dX is induced by a weighted graph (i.e. the
distance between each pair of locations is the weight of a
minimum path in a graph), then we only need to consider
|X| constraints for each pair of locations that are adjacent
in the graph. An example of this is the usual deﬁnition of
diﬀerential privacy: since the adjacency relation between
databases induces the Hamming distance dh, we only need
to require the diﬀerential privacy constraint for each pair
of databases that are adjacent in the Hamming graph (i.e.
that diﬀer in one individual).

It might be the case, though, that the metric dX is not
induced by any graph (other than the complete graph), and
consequently the amount of constraints remains the same.
In fact, this is generally the case for the Euclidean metric.
Therefore, we consider the case in which dX can be approx-
imated by some graph-induced metric.
If G is an undirected weighted graph, we denote with dG
the distance function induced by G, i.e. dG(x, x(cid:48)) denotes
the weight of a minimum path between the nodes x and x(cid:48)
in G. Then, if the set of nodes of G is X and the weight of
its edges is given by the metric dX , we can approximate dX
with dG. In this case, we say that G is a spanning graph, or
a spanner [16, 17], of X .

Definition 4

(Spanner). A weighted graph G = (X , E),

with E ⊆ X ×X and weight function w : E → R is a spanner
of X if

(cid:48)

(cid:48)

w(x, x

) = dX (x, x

) ∀(x, x
(cid:48)
Note that if G is a spanner of X , then
) ∀x, x

) ≥ dX (x, x

dG(x, x

(cid:48)

(cid:48)

) ∈ E

(cid:48) ∈ X

A main concept in the theory of spanners is that of dilation,
also known as stretch factor:

Definition 5

ner of X . The dilation of G is calculated as:

(Dilation). Let G = (X , E) be a span-

δ = max
x(cid:54)=x(cid:48)∈X

dG(x, x(cid:48))
dX (x, x(cid:48))

A spanner of X with dilation δ is called a δ-spanner of X .
Informally, a δ-spanner of X can be considered an approx-
imation of the metric dX in which distances between nodes
are “stretched” by a factor of at most δ. Spanners are gener-
ally used to approximate distances in a geographic network
without considering the individual distances between each
pair of nodes. An example of a spanner for a grid in the
map can be seen in Figure 1.

If G is a δ-spanner of X , then it holds that
(cid:48) ∈ X

) ∀x, x
which leads to the following proposition:

) ≤ δdX (x, x

dG(x, x

(cid:48)

(cid:48)

Proposition 1. Let X be a set of locations with metric
dX , and let G be a δ-spanner of X . If a mechanism K for
X is 

δ dG-private, then K is dX -private.

Figure 1: (a) a division of the map of Paris into a
7 × 5 square grid. The set of locations X contains
the centers of the regions. (b) A spanner of X with
dilation δ = 1.08.

We can then propose a new optimization problem to ob-
tain a dX -private mechanism. If G = (X , E) is a δ-spanner
of X , we require not the constraints corresponding to dX -
privacy, but those corresponding to 
δ dG-privacy instead,
that is, |X| constraints for each edge of G:

Minimize:

πxkxzdQ(x, z)

x,z∈X
Subject to: kxz ≤ e



δ dG(x,x(cid:48))kx(cid:48)z

z ∈ X , (x, x

(cid:88)
(cid:88)

kxz = 1

x∈X
kxz ≥ 0

) ∈ E
(cid:48)
x ∈ X

x, z ∈ X

Since the resulting mechanism is 

δ dG-private, by Propo-
sition 1 it must also be dX -private. However, the number of
δ dG-privacy is now |E||X|. More-
constraints in induced by 
over, as discussed in the next section, for any δ > 1 there is
|X|
an algorithm that generates a δ-spanner with O(
δ−1 ) edges,
which means that, ﬁxing δ, the total number of constraints
of the linear program is O(|X|2).

It is worth noting that although dX -privacy is guaran-
teed, optimality is lost: the obtained mechanism is 
δ dG-
OptQL(π, dQ) but not necessarily dX -OptQL(π, dQ), since
the set of 
δ dG-private mechanisms is a subset of the set of
dX -private mechanisms. The QL of the obtained mecha-
nism will now depend on the dilation δ of the spanner: the
smaller δ is, the closer the QL of the mechanism will be from
the optimal one. However, if δ is too small then the num-
ber of edges of the spanner will be large, and therefore the
number of constraints in the linear program will increase.
In fact, when δ = 1 the mechanism obtained is also dX -
OptQL(π, dQ) (since dG and dX coincide), but the amount
of constraints is in general O(|X|3). In consequence, there
is a tradeoﬀ between the accuracy of the approximation and
the number of constraints in linear program.

3.3 An algorithm to construct a δ-spanner
The previous approach requires to compute a spanner for
X . Moreover, given a dilation factor δ, we are interested in
generating a δ-spanner with a reasonably small number of
edges. In this section we describe a simple greedy algorithm
to get a δ-spanner of X , presented in [16]. This procedure
(described in Algorithm 1) is a generalization of Kruskal’s
minimum spanning tree algorithm.

(a)(b)255Algorithm 1 Algorithm to get a δ-spanner of X
1: procedure GetSpanner(X , dX , δ)
2:
3:
4:

E := ∅
G := (X , E)
for all (x, x(cid:48)) ∈ (X × X ) do

(cid:46) taken in increasing

if dG(x, x(cid:48)) > δdX (x, x(cid:48)) then

E := E ∪ {(x, x(cid:48))}

order wrt dX

5:
6:
7:
8:
9:
10: end procedure

end for
return G

end if

The idea of the algorithm is the following: we start with
a spanner with an empty set of edges (lines 2-3).
In the
main loop we consider all possible edges (that is, all pairs of
locations) in increasing order with respect to the distance
function dX (lines 4-8), and if the weight of a minimum
path between the two corresponding locations in the current
graph is bigger than δ times the distance between them, we
add the edge to the spanner. By construction, at the end of
the procedure, graph G is a δ-spanner of X .
A crucial result presented in [16] is that, in the case where
X is a set of points in the Euclidean plane, the degree of each
node in the generated spanner only depends on the dilation
factor:

Theorem 1. Let δ > 1. If G is a δ-spanner for X ⊆ R2,
with the Euclidean distance d2 as metric, then the degree
of each node in the spanner constructed by Algorithm 1 is
O( 1

δ−1 ).

This result is useful to estimate the total number of edges
in the spanner, since our goal is to generate a sparse spanner,
i.e. a spanner with O(|X|) edges.

Considering the running time of the algorithm, since the
main loop requires all pair of regions to be sorted increas-
ingly by distance, we need to perform this sorting before the
loop. This step takes O(|X|2 log |X|). The main loop per-
forms a minimum-path calculation in each step, with |X|2
If we use, for instance, Dijkstra’s algorithm,
total steps.
each of these operations can be done in O(|E| +|X| log |X|).
If we select δ so that the ﬁnal amount of edges in the span-
|E| = O(|X|), we can conclude that the
ner is linear, i.e.
total running time of the main loop is O(|X|3 log |X|). This
turns out to be also the complexity of the whole algorithm.
A common problem in the theory of spanners is the follow-
ing: given a set of points X ⊆ R2 and a maximum amount
of edges m, the goal is to ﬁnd the spanner with minimum
dilation with at most m edges. This has been proven to be
NP-Hard ([18]). In our case, we are interested in the analog
of this problem: given a maximum tolerable dilation factor
δ, we want to ﬁnd a δ-spanner with minimum amount of
edges. However, we can see that the ﬁrst problem can be
expressed in terms of the second (for instance, with a binary
search on the dilation factor), which means that the second
problems must be at least NP-Hard as well.
3.4 AdvError of the obtained mechanism

As discussed in 2.1, the privacy of a location obfusca-
tion mechanism can be expressed in terms of AdvError
for an adversary metric dA. In [8], the problem of optimiz-
ing privacy for a given QL constraint is studied, providing

a method to obtain a q-OptPriv(π, dA, dQ) mechanism for
any q, π, dQ, dA.

In our case, we optimize QL for a given privacy con-
straint, constructing a dX -OptQL(π, dQ) mechanism. We
now show that, if dQ and dA coincide, the mechanism gener-
ated by any of the two optimization problems of the previous
sections is also q-OptPriv(π, dQ, dQ).

AdvError corresponds to an adversary’s remapping H
that minimizes his expected error with respect to the metric
dA and his prior knowledge π. A crucial observation is that
dX -privacy is closed under remapping.

Lemma 1. Let K be a dX -private mechanism, and let H

be a remapping. Then KH is dX -private.

Now let K be a dX -OptQL(π, dQ) mechanism and H a
remapping. Since KH is dX -private (Lemma 1) and K is
optimal among all such mechanisms, we have that:

QL(K, π, dQ) ≤ QL(KH, π, dQ) ∀H

As a consequence, assuming that dQ and dA coincide, the ad-
versary minimizes his expected error by applying no remap-
ping at all (i.e. the identity remapping), which means that
AdvError(K, π, dQ) = QL(K, π, dQ) and therefore K must
be q-OptPriv(π, dQ, dQ).

Theorem 2. If a mechanism K is dX -OptQL(π, dQ) then

it is also q-OptPriv(π, dQ, dQ) for q = QL(K, π, dQ).

It is important to note that Theorem 2 holds for any
metric dX . This means that both mechanisms obtained as
result of the optimization problems presented in Sections
3.1 and 3.2 are q-OptPriv(π, dQ, dQ) – since they are dX -
δ dG-OptQL(π, dQ) respectively – how-
OptQL(π, dQ) and 
ever for a diﬀerent value of q.
In fact, in contrast to the
method of [8] in which the quality bound q is given as
a parameter, our method optimizes the QL given a pri-
vacy bound. Hence, the resulting mechanism will be q-
OptPriv(π, dQ, dQ), but for a q that is not known in ad-
vance and will depend on the privacy constraint  and the
dilation factor δ. The greater the  is (i.e. the higher the
privacy), or the lower the δ is (i.e. the better the approxima-
tion), the lower the quality loss q of the obtained mechanism
will be.

Finally, we must remark that this result only holds in the
case where the metrics dQ, dA coincide. If the metrics diﬀer,
e.g. the quality is measured in terms of the Euclidean dis-
tance (the user is interested in accuracy) but the adversary
uses the binary distance (he is only interested in the exact
location), then this property will no longer be true.
3.5 Practical considerations

We conclude this section with a discussion on the prac-
tical applicability of location obfuscation. First, it should
be noted that, although constructing an optimal mechanism
is computationally demanding, once the matrix K is com-
puted, obfuscating a location x only involves drawing a re-
ported location from the distribution K(x) which is compu-
tationally trivial. Moreover, although obfuscation is meant
to happen on the user’s smartphone, computing the mech-
anism can be oﬄoaded to an external server and even par-
allelized. The user only needs to transmit π, dX , dQ (which
are considered public) and receive K, and the computation

256Figure 2: (a) Division of the map of Beijing into
regions of size 0.658 x 0.712 km. The density of each
region represents its “score”, that is, how frequently
users visit it. (b) The 50 selected regions. These
regions are the ones with highest density between
the whole set of regions.

only needs to be performed occasionally, to adapt to changes
in the user proﬁle.

Second, an important feature of obfuscation mechanisms
is that they require no cooperation from the service provider,
who simply receives a location and has no way of knowing
whether it is real or not. Obfuscation can happen on the
user’s device, at the operating system or browser level, which
is crucial since the user has strong incentives to apply it
while the service provider does not. The user’s device could
also perform ﬁltering of the results, as described in [9].

Finally, we argue that the common idea that users of LBSs
are willing to give up their privacy is misleading: the only
alternative oﬀered is not to use the service. The usage of
browser extensions such as “Location Guard” [19] shows that
users do care about their privacy and that obfuscation can be
a practical approach for using existing services in a privacy
friendly way.

4. EVALUATION

In this section we evaluate the technique for constructing
optimal mechanisms described in the previous sections. We
perform two kinds of evaluation: ﬁrst, a comparison with
other mechanisms, namely the one of Shokri et al. and the
Planar Laplace mechanism. Second, a performance evalua-
tion of the spanner approximation technique.

The comparison with other mechanisms is performed with
respect to both privacy and quality loss. For privacy, the
main motivation is to evaluate the mechanisms’ privacy un-
der diﬀerent priors, and in particular under priors diﬀerent
than the one they were constructed with. Following the
motivating scenario of the introduction, we consider that a
user’s proﬁle can vary substantially between diﬀerent time
periods of the day, and simply by taking into account the
time of a query, the adversary can obtain a much more infor-
mative prior which leads to a lower privacy. For the purposes
of the evaluation, we consider priors corresponding to four
diﬀerent time periods: the full day, the morning (7am to
noon), afternoon (noon to 7pm) and night (7pm to 7am).
Then we construct the mechanisms using the full day prior
and compare their privacy for all time periods.

We perform our evaluation on two widely used datasets:
GeoLife [20, 21, 22] and T-Drive [23, 24]. The results of Ge-
oLife are presented in detail in the following sections, while,

Figure 3: Boxplot of the location privacy provided
by the three diﬀerent mechanisms under considered
priors. The OptQL mechanism was constructed with
 = 1.07 and δ = 1.05.

due to space restrictions, those of T-Drive (which are in gen-
eral similar) are summarized in Section 4.4.
4.1 The GeoLife dataset

The GeoLife GPS Trajectories dataset contains 17621 traces

from 182 users, moving mainly in the north-west of Beijing,
China, in a period of over ﬁve years (from April 2007 to
August 2012). The traces show users performing routinary
tasks (like going to and from work), and also traveling, shop-
ping, and doing other kinds of entertainment or unusual ac-
tivities. Besides, the traces were logged by users using diﬀer-
ent means of transportation, like walking, public transport
or bike. More than 90% of the traces were logged in a dense
representation, meaning that the individual points in the
trace were reported every 1-5 seconds or every 5-10 meters.
Since user behaviour changes over time, and the mechanism
should be occasionally reconstructed, we restrict each user’s
traces to a 90 days period, and in particular to the one with
the greatest number of recorded traces, so that the prior is
as informative as possible.
4.2 Mechanism comparison wrt privacy and

quality loss

For the evaluation, we divide the map of Beijing into a
grid of regions 0.658 km wide and 0.712 km high, displayed
in Figure 2a. To avoid users for which little information is
available, we only keep those having at least 20 recorded
points within the grid area for each one of the time periods.
Whenever we count points, those falling within the same
grid region during the same hour are counted only once, to
prevent traces with a huge number of points in the same
region (e.g. the user’s home) from completely skewing the
results. After this ﬁltering, we end up with 116 users (64%
of the total 182).

We then proceed to calculate the 50 “most popular” re-
gions of the grid as follows: for each user, we select the 30
regions in which he spends the greatest amount of time. A
region’s “score” is the number of users that have it in their
30 highest ranked ones. Then we select the 50 regions with
the highest score.

Figure 2a shows the division of the map into regions, with
the opacity representing the score of each of them, while
Figure 2b shows the 50 regions with highest score. We can

(a)(b)All dayMorningAfternoonNight0.20.30.40.50.60.70.80.91.01.11.2Location privacy (km)OptQLOptPrivPL257a privacy constraint (cid:48) (in general diﬀerent from ) such that
the QL of this mechanism is also q. We call this mechanism
PL. Note that at the end of this process, by construction,
the QL of the three mechanisms is q.

We begin the evaluation comparing the location privacy
of each mechanism for each of the selected users, under the
four constructed priors. We ﬁx  = 1.07 (which intuitively
corresponds to a ratio of 2 between the probability for two
regions adjacent in the grid to report the same observed
location) and δ = 1.05. Figure 3 shows a boxplot of the
location privacy (in km) oﬀered by the diﬀerent mechanisms
under each prior. In all four cases, the general performance
of our mechanism is better than that of the others, with the
only exception being the all-day prior (which is the one used
in the construction of the mechanisms) since, as explained in
Section 3.4, OptQL and OptPriv are q-OptPriv(π, d2, d2)
and therefore oﬀer the same privacy.

Finally, to show the beneﬁts of using a mechanism with
optimal utility, we compare now the QL of the mechanisms
OptQL and PL when both mechanisms are generated with
the same privacy level . We can see the results in Fig-
ure 4. The OptQL mechanism clearly oﬀers a better util-
ity to the user, while guaranteeing the same level of geo-
indistinguishability.
4.3 Performance of the approximation

algorithm

We recall from Section 3.2 that if we consider a large
number of locations in X , then the number of constraints
in the linear program might be large. Hence, we intro-
duced a method based on a spanning graph G to reduce
the total number of constraints of the linear program. How-
ever, in general the obtained mechanism is no longer dX -
OptQL(π, dQ), and therefore it has a higher QL than the
optimal one.

In this section we study the tradeoﬀ between the increase
in the QL of the mechanism and the reduction in the num-
ber of constraints of the optimization problem, as a conse-
quence of using our approximation technique. We also show
how this reduction aﬀects the running time of the whole ap-
proach. We start by constructing the OptQL mechanism
for all selected users and for diﬀerent dilations in the range
from 1.05 to 2.0, in all cases considering  = 1.07 as before.
We then measure the QL of each mechanism under the user
proﬁle. We can see the results in Figure 5a. It is clear that
the QL increases slowly with respect to the dilation: the me-
dian value is 0.946 km for δ = 1.05, is 0.972 km for δ = 1.1,
and 1.018 km for δ = 1.2. Therefore we can deduce that,
for a reasonable approximation, the increase in the quality
loss is not really signiﬁcant. It is worth noting that we do
not show the QL for δ = 1 in the plot (corresponding to the
case where dX and dG are the same). The reason is that
in that case the number of constraints is really high, and
therefore it takes a lot of time to generate one instance of
the mechanism (and much more time to generate it for the
86 users considered).

The relation between the dilation and the number of con-
straints is shown in Figure 5b. Note that this number is
independent from the user, and therefore it is enough to cal-
culate it for just one of them. It is clear that the number of
constraints decreases exponentially with respect to the di-
lation, and therefore even for small dilations (which in turn
mean good approximations) the number of constraints is

Figure 4: Quality loss of the OptQL and PL mecha-
nisms for diﬀerent values of . The mechanisms were
calculated for all users. Here, points represent the
utility for every user, while the two lines join the
medians for each mechanism and each value of .

see that most of the selected regions are located in the south-
east of the Haidian district, and all of them are located in
the north-west of Beijing. We consider the set of locations
X to be the centers of the selected regions, and the metric
dX to be the Euclidean distance between these centers, i.e.
dX = d2.

Finally, a second ﬁltering is performed, again keeping users
with at least 20 points in each time period, but this time con-
sidering only the 50 selected regions. After this, we end up
with a ﬁnal set of 86 users (46% of the total 182).

In this section, we evaluate the location privacy and the
utility of three diﬀerent mechanisms under the several prior
distributions for each user. These priors correspond to diﬀer-
ent parts of the day (all day, morning, afternoon and night),
and are computed by counting the number of points, logged
in the corresponding time period, that fall in each of the se-
lected regions (again, counting only once those points logged
within the same hour), and then by normalizing these num-
bers to obtain a probability distribution.

We start by evaluating the location privacy provided by
the diﬀerent mechanisms. However, we must note that in
general location privacy mechanisms do not satisfy dX -
privacy unless they are speciﬁcally designed to do so. There-
fore, for this evaluation, we measure location privacy with
the metric AdvError, proposed in [8] and described in Sec-
tion 2.1, which measures the expected error of the attacker
under a given prior distribution. In order to perform a fair
comparison, we construct the mechanisms in such a way that
their QL coincide. The ﬁrst step is to select a privacy level
 and a dilation δ, and then to construct the mechanism de-
scribed in Section 3.2. We will call this mechanism OptQL.
This mechanism has a QL of q = QL(OptQL, π, d2). We
then continue by constructing the optimal mechanism of
Shokri et al [8], and setting the QL as q. We call this mech-
anism OptPriv. Finally, we compute a discretized version
of the Planar Laplace mechanism of Andr´es et al [9]. under

0.00.51.01.52.02.53.03.54.04.55.05.56.00.20.40.60.81.01.21.41.61.82.0EpsilonQuality Loss (km)OptQLPL258Figure 5: (a) Boxplot of the relation between QL and dilation for the mechanism OptQL with privacy
constraint  = 1.07. The spanner is calculated with the greedy algorithm presented in Section 3.3.
(b)
Relation between the approximation ratio and the number of constraints in the linear program. This number
is independent from the user and form the value of .

signiﬁcantly reduced with the proposed approximation tech-
nique. For instance, we have 87250 constraints for δ = 1 (the
optimal case), and 25551 constraints for δ = 1.05. This rep-
resents a decrease of 71% with respect to the optimal case,
with only 1.05 approximation ratio.

It is also worth noting that, between δ = 1.4 and δ = 1.45
there is a pronounced decrease in the number of constraints
(Figure 5b) and also a decrease in the QL (Figure 5a). This
might seem counterintuitive at ﬁrst, since one would expect
that a worse approximation should always imply a higher
loss of quality. However, there is a simple explanation: al-
though the spanner with δ = 1.45 has a higher worst-case
approximation ratio, the average-case ratio is actually better
that the one of the spanner with δ = 1.4. This phenomenon
is a consequence of the particular topology of the set of lo-
cations and to the algorithm used to get the spanner.

Finally, we measure the running time of the method used
to generate the OptQL mechanism, under diﬀerent methods
to solve the linear optimization problem. The experiments
were performed in a 2.8 GHz Intel Core i7 MacBook Pro
with 8 GB of RAM running Mac OS X 10.9.1, and the source
code for the method was written in C++, using the routines
in the GLPK library for the linear program. We compare
the performance of three diﬀerent methods included in the
library: the simplex method in both its primal and dual
form, and the primal-dual interior-point method. Besides,
we run these methods on both the primal linear program
presented in Section 3.2 and its dual form, presented in Ap-
pendix 6. Since the running time depends mainly on the
number of locations being considered, in the experiments
we focus on just one user of the dataset, and we ﬁx the pri-
vacy level as  = 1.07. The results can be seen in Table 1.
Some ﬁelds are marked with “1h+”, meaning that the exe-
cution took more than one hour, after which it was stopped.
Others are marked with “Error”, meaning that the execution
stopped before one hour with an error2. A particular case of
error happened when running the interior-point method on
the dual linear program, where all executions ended with a

2The actual error message in this case was: “Error: unable
to factorize the basis matrix (1). Sorry, basis recovery pro-
cedure not implemented yet”

|X|

50

75

Primal simplex

Dual simplex

Pr. LP Du. LP

Pr. LP Du. LP

57s
46.4s
4m 37s

2s

Error
1h+
1h+
1h+
1h+
1h+

1h+
5.2
2s
1s
1s
1h+
Error
Error
5m 55s
21.8s

40s
5.9s
4s
2s
2s

29m 26s
1m 12s

42s
19.2s
27.2s

45s
15.5s
1h+
3s
2s
1h+

2m 19s
48.4s
1h+
15.5s

Interior
Pr. LP
49m 20s

7.5s
2.7s
0.5s
0.5s
1h+
55s
11.7s
2.2s
1.7s

δ
1.0
1.1
1.2
1.5
2.0
1.0
1.1
1.2
1.5
2.0

Table 1: Execution times of our approach for 50
and 75 locations, for diﬀerent values of δ, and using
diﬀerent methods to solve the linear program.

“numerical instability” error (and therefore this case is not
included in the table). From the results we can observe that:
• The only two methods that behave consistently (that
never ﬁnish with error, and the running time increases
when the dilation decreases) are the dual simplex and
the interior-point methods, both when applied to the
primal program.

• From these, the interior-point method performs better
in the case of bigger dilation, while it does it much
worse for very small ones.

• Somewhat surprisingly, the dual linear program does
not oﬀer a signiﬁcant performance improvement, spe-
cially when compared with the interior-point method.

In the case of OptPriv, the mechanism is generated using
Matlab’s linear program solver (source code kindly provided
by the authors of [8]). We generated the mechanism for
the same cases, and observed that the running time mainly
depends on the number of regions: for 50 regions, the mech-
anism is generated in approximately 1 minute, while for 75
regions it takes about 11 minutes.
4.4 The T-Drive dataset

In order to reaﬃrm the validity of the proposed approach,
we performed the same evaluation in a diﬀerent dataset: the
T-Drive trajectories dataset. This dataset contains traces

0.60.70.80.91.01.11.21.31.41.51.61.71.051.11.151.21.251.31.351.41.451.51.551.61.651.71.751.81.851.91.952DilationQualityLoss(km)(a)(b)01000020000300004000050000600007000080000900001.01.11.21.31.41.51.61.71.81.92.0DilationConstraints259other mechanisms (again, with the exception of the all day
prior, for which we know that these values coincide). We
can also see in Figure 7 the comparison in terms of utility
of the mechanisms OptQL and PL. Again, the quality loss
of OptQL is, in all cases, better than the one of PL. This
is to be expected, since, from all mechanisms providing a
certain geo-indistinguishability, OptQL is the one with op-
timal utility (or really close to the optimal utility when the
approximation is used).

5. CONCLUSION AND RELATED WORK
Related work
In the last years, a large number of location-privacy protec-
tion techniques, diverse both in nature and goals, have been
proposed and studied. Many of these aim at allowing the
user of an LBS to hide his identity from the service provider.
Several approaches are based in the notion of k-anonymity
[25, 26, 27], requiring that the attacker cannot identify a user
from at least other k− 1 diﬀerent users. Others are based on
the idea of letting the users use pseudonyms to interact with
the system, and on having regions (mix zones, [4, 6]), where
the users can change their pseudonyms without being traced
by the system. All these approaches are incomparable with
ours, since ours aims at hiding the location of the user and
not his identity.

Many approaches to location privacy are based on obfus-
cating the position of the user. A common technique for this
purpose is cloaking [28, 29, 30, 26], which consists in blur-
ring the user’s location by reporting a region to the service
provider. Another technique is based on adding dummy lo-
cations[31, 32, 5] to the request sent to the service provider.
In order to preserve privacy, these dummy locations should
be generated in such a way that they look equally likely
to be the user’s real position. A diﬀerent approach is to
construct mechanisms that provide optimal privacy under
certain quality constraints [8] (an approach dual to ours, as
discussed in the introduction), while [33] additionally takes
into account bandwidth constraints. Finally, collaborative
models have been proposed [34], where privacy is achieved
with a peer-to-peer scheme where users avoid querying the
service provider whenever they can ﬁnd the requested infor-
mation among their peers.

Diﬀerential Privacy has also been used in the context of
location privacy; however, it is in general used to protect
aggregate location information. For instance, [35] presents
a way to statistically simulate the location data from a
database while providing privacy guarantees. In [36], a quad
tree spatial decomposition technique is used to achieve dif-
ferential privacy in a database with location patter min-
ing capabilities. On the other hand, Dewri [37] proposes a
combination of diﬀerential privacy and k-anonymity for the
purposes of hiding the location of a single individual. The
proposed deﬁnition requires that the distances between the
probability distributions corresponding to k ﬁxed locations
(deﬁned as the anonymity set) should not be greater than
the privacy parameter .

The work closest to ours is [38], which independently pro-
poses a linear programming technique to construct opti-
mal obfuscation mechanisms wrt either AdvError or geo-
indistinguishability. Although there is an overlap in the
main construction (the optimization problem of Section 3.1),
most of the results are substantially diﬀerent. The approx-

Figure 6: Boxplot of the location privacy for the
T-Drive dataset. The median value of the location
privacy for OptQL is always as good as the one of
the other mechanisms.

of 10357 taxis in Beijing, China, during the period of one
week. The total distance of the traces in this dataset is about
9 million kilometres, with more than 15 million reported
points. The average time between consecutive points in a
trace is 177 seconds, and the average distance is 623 meters.
Due to the huge amount of users in this dataset, we started
the evaluation process by blindly selecting (using a standard
random function) 5% of the total number users (about 532
users out of 10357). We then perform the same steps as de-
scribed in the previous sections, particularly those described
in Section 4.2. In Figure 6 we can see the comparison of the
location privacy for the diﬀerent mechanisms. We can see
that, also for this dataset, the privacy level of OptQL is,
in general, as good as the one of OptPriv, and always bet-
ter than the one of PL. In particular, the median value for
OptQL is always higher than the corresponding one for the

Figure 7: Quality loss of the OptQL and PL mecha-
nisms for diﬀerent values of , using the data in the
T-Drive dataset. The loss of quality of OptQL is
always smaller than the one of PL.

All dayMorningAfternoonNight0.20.30.40.50.60.70.80.91.01.11.21.31.4Location privacy (km)OptQLOptPrivPL0.00.51.01.52.02.53.03.54.04.55.05.56.00.20.40.60.81.01.21.41.61.82.0EpsilonQuality Loss (km)OptQLPL260imation technique of [38] consists of discarding some of the
geo-indistinguishability constraints when the distance in-
volved is larger than a certain lower bound. This aﬀects
the geo-indistinguishability guarantees of the mechanism,
although the eﬀect can be tuned by properly selecting the
bound for discarding constraints. On the other hand, our
approximation technique, based on spanning graphs, can
be used to reduce the number of constraints from cubic
to quadratic without jeopardizing the privacy guarantees,
by accepting a small decrease on the utility. Moreover, we
show that the mechanism obtained from this optimization
problem is also optimal wrt AdvError (Theorem 2), which
is an important property of the proposed method. Finally,
the evaluation methods are substantially diﬀerent:
in [38]
the employed set of prior distributions diﬀer in their level of
entropy (priors with low entropy are considered more infor-
mative). In our work, we obtain the diﬀerent priors by com-
bining the distribution of the user (assumed to be known by
the adversary) with some public available information (for
instance, the time of the day).

Finally, dX -privacy has been used in [39] to capture fair-
ness, instead of privacy. The goal is to construct a fair
mechanism that produces similar reported values for “simi-
lar” users, the similarity being captured by the metric. As in
our work, the construction involves solving an optimization
problem, however no technique is used to reduce the number
of constraints.
Conclusion
In this paper we have developed a method to generate a
mechanism for location privacy that combines the advan-
tages of the geo-indistinguishability privacy guarantee of [9]
and the optimal mechanism of [8]. Since linear optimization
is computationally demanding, we have provided a technique
to reduce the total number of constraints in the linear pro-
gram, based on the use of a spanning graph to approximate
distances between locations, which allows a huge reduction
on the number of constraints with only a small decrease
in the utility. Finally, we have evaluated the proposed ap-
proach using traces from real users, and we have compared
both the privacy and the running time of our mechanism
with that of [8].
It turns out that our mechanism oﬀers
better privacy guarantees when the side knowledge of the
attacker is diﬀerent from the distribution used to construct
the mechanisms. Besides, for a reasonably good approxi-
mation factor, we have showed that our approach performs
much better in terms of running time.

6. ACKNOWLEDGEMENTS

This work was partially supported by the MSR-INRIA
joint lab, by the European Union 7th FP project MEALS,
by the project ANR-12-IS02-001 PACE, and by the INRIA
Large Scale Initiative CAPPRIS. The work of Nicol´as E.
Bordenabe was partially funded by the DGA.

7. REFERENCES
[1] Freudiger, J., Shokri, R., Hubaux, J.P.: Evaluating

the privacy risk of location-based services. In: Proc. of
FC’11. Volume 7035 of LNCS., Springer (2011) 31–46

[2] Golle, P., Partridge, K.: On the anonymity of

home/work location pairs. In: Proc. of PerCom’09.
Volume 5538 of LNCS. Springer-Verlag (2009) 390–397

[3] Krumm, J.: Inference attacks on location tracks. In:

Proc. of PERVASIVE. Volume 4480 of LNCS.,
Springer (2007) 127–143

[4] Beresford, A.R., Stajano, F.: Location privacy in

pervasive computing. IEEE Pervasive Computing 2(1)
(2003) 46–55

[5] Chow, R., Golle, P.: Faking contextual data for fun,
proﬁt, and privacy. In: Proc. of WPES, ACM (2009)
105–108

[6] Freudiger, J., Shokri, R., Hubaux, J.P.: On the

optimal placement of mix zones. In: Proc. of PETS
2009. Volume 5672 of LNCS., Springer (2009) 216–234

[7] Hoh, B., Gruteser, M., Xiong, H., Alrabady, A.:

Preserving privacy in gps traces via uncertainty-aware
path cloaking. In: Proc. of CCS, ACM (2007) 161–171

[8] Shokri, R., Theodorakopoulos, G., Troncoso, C.,

Hubaux, J.P., Boudec, J.Y.L.: Protecting location
privacy: optimal strategy against localization attacks.
In: Proc. of CCS, ACM (2012) 617–627

[9] Andr´es, M.E., Bordenabe, N.E., Chatzikokolakis, K.,
Palamidessi, C.: Geo-indistinguishability: diﬀerential
privacy for location-based systems. In: Proc. of CCS,
ACM (2013) 901–914

[10] Shokri, R., Theodorakopoulos, G., Boudec, J.Y.L.,

Hubaux, J.P.: Quantifying location privacy. In: Proc.
of S&P, IEEE (2011) 247–262

[11] Dwork, C., Mcsherry, F., Nissim, K., Smith, A.:

Calibrating noise to sensitivity in private data
analysis. In: Proc. of TCC. Volume 3876 of LNCS.,
Springer (2006) 265–284

[12] Chatzikokolakis, K., Andr´es, M.E., Bordenabe, N.E.,
Palamidessi, C.: Broadening the scope of Diﬀerential
Privacy using metrics. In: Proc. of PETS. Volume
7981 of LNCS., Springer (2013) 82–102

[13] Chatzikokolakis, K., Palamidessi, C., Stronati, M.: A

predictive diﬀerentially-private mechanism for
mobility traces. In: Proc. of PETS. Volume 8555 of
LNCS., Springer (2014) 21–41

[14] Bordenabe, N.E., Chatzikokolakis, K., Palamidessi, C.:
Optimal geo-indistinguishable mechanisms for location
privacy. Tech. rep., INRIA (2013) arXiv:1402.5029.

[15] Reed, J., Pierce, B.C.: Distance makes the types grow

stronger: a calculus for diﬀerential privacy. In: Proc.
of ICFP, ACM (2010) 157–168

[16] Narasimhan, G., Smid, M.: Geometric spanner

networks. CUP (2007)

[17] Sack, J., Urrutia, J.: Handbook of Computational

Geometry. Elsevier Science (1999)

[18] Klein, R., Kutz, M.: Computing Geometric

Minimum-Dilation Graphs is NP-Hard. In: Proc. of
the GD. Volume 4372., Springer (2006) 196–207

[19] Location Guard.

https://github.com/chatziko/location-guard.

[20] Zheng, Y., Li, Q., Chen, Y., Xie, X., Ma, W.Y.:
Understanding Mobility Based on GPS Data. In:
Proc. of UbiComp 2008. (2008)

261[21] Zheng, Y., Zhang, L., Xie, X., Ma, W.Y.: Mining

[36] Ho, S.S., Ruan, S.: Diﬀerential privacy for location

interesting locations and travel sequences from GPS
trajectories. In: Proc. of WWW 2009. (2009)

pattern mining. In: Proc. of SPRINGL, ACM (2011)
17–24

[22] Zheng, Y., Xie, X., Ma, W.Y.: Geolife: A collaborative

[37] Dewri, R.: Local diﬀerential perturbations: Location

social networking service among user, location and
trajectory. IEEE Data Eng. Bull. 33(2) (2010) 32–39

privacy under approximate knowledge attackers. IEEE
Trans. on Mobile Computing 99(PrePrints) (2012) 1

[23] Yuan, J., Zheng, Y., Xie, X., Sun, G.: Driving with

[38] Shokri, R.: Optimal user-centric data obfuscation.

knowledge from the physical world. In: The 17th
ACM SIGKDD international conference on Knowledge
Discovery and Data mining, KDD ’11. (2011)

[24] Yuan, J., Zheng, Y., Zhang, C., Xie, W., Xie, X., Sun,

G., Huang, Y.: T-drive: driving directions based on
taxi trajectories. In: GIS. (2010) 99–108

[25] Gruteser, M., Grunwald, D.: Anonymous usage of

location-based services through spatial and temporal
cloaking. In: Proc. of MobiSys, USENIX (2003)

[26] Gedik, B., Liu, L.: Location privacy in mobile

systems: A personalized anonymization model. In:
Proc. of ICDCS, IEEE (2005) 620–629

[27] Mokbel, M.F., Chow, C.Y., Aref, W.G.: The new

casper: Query processing for location services without
compromising privacy. In: Proc. of VLDB, ACM
(2006) 763–774

[28] Bamba, B., Liu, L., Pesti, P., Wang, T.: Supporting
anonymous location queries in mobile environments
with privacygrid. In: Proc. of WWW, ACM (2008)
237–246

[29] Duckham, M., Kulik, L.: A formal model of

obfuscation and negotiation for location privacy. In:
Proc. of PERVASIVE. Volume 3468 of LNCS.,
Springer (2005) 152–170

[30] Xue, M., Kalnis, P., Pung, H.: Location diversity:

Enhanced privacy protection in location based
services. In: Proc. of LoCA. Volume 5561 of LNCS.,
Springer (2009) 70–87

[31] Kido, H., Yanagisawa, Y., Satoh, T.: Protection of
location privacy using dummies for location-based
services. In: Proc. of ICDE Workshops. (2005) 1248

[32] Shankar, P., Ganapathy, V., Iftode, L.: Privately

querying location-based services with SybilQuery. In:
Proc. of UbiComp, ACM (2009) 31–40

[33] Herrmann, M., Troncoso, C., Diaz, C., Preneel, B.:

Optimal sporadic location privacy preserving systems
in presence of bandwidth constraints. In: Proc. of
WPES. (2013)

Kazemi, E., Hubaux, J.P.: Hiding in the mobile
crowd: Location privacy through collaboration. In:
Proc. of the TDSC, IEEE (2014)

[35] Machanavajjhala, A., Kifer, D., Abowd, J.M., Gehrke,

J., Vilhuber, L.: Privacy: Theory meets practice on
the map. In: Proc. of ICDE, IEEE (2008) 277–286

[34] Shokri, R., Theodorakopoulos, G., Papadimitratos, P.,

Maximize:

bx

bx +

(x,x(cid:48))∈E

axx(cid:48)z ≥ 0,



δ dG(x,x(cid:48))ax(cid:48)xz − axx(cid:48)z) ≤ πxdQ(x, z),

(e

x, z ∈ X

z ∈ X , (x, x

(cid:48)

) ∈ E

Technical report, ETH Zurich (2014)
http://arxiv.org/abs/1402.3426.

[39] Dwork, C., Hardt, M., Pitassi, T., Reingold, O.,

Zemel, R.S.: Fairness through awareness. In: Proc. of
ITCS, ACM (2012) 214–226

APPENDIX
In this section we show the dual form of the optimization
problem presented in Section 3.2. We recall that the original
linear program is as follows:

Minimize:

πxkxzdQ(x, z)

(cid:88)

x,z∈X

kxz ≤ e



δ dG(x,x(cid:48))kx(cid:48)z

z ∈ X , (x, x

Subject to:

(cid:88)

kxz = 1

x∈X
kxz ≥ 0

) ∈ E
(cid:48)
x ∈ X

(1)

(2)

x, z ∈ X

To obtain the dual form, we apply the standard technique
of linear programming. First, for the dual program we need
to consider one variable for each of the constraints in the
original linear program that are not constraints on single
variables. Therefore we have two sets of variables:

• The variables of the form axx(cid:48)z, with z ∈ X , (x, x(cid:48)) ∈ E,
• The variables of the form bx, with x ∈ X , corresponding

corresponding to the constraints in (1).

to the constraints in (2).

Applying the standard technique, we obtain the following
system of constraints and objective function, that constitute
the dual linear program:

(cid:88)

x∈X

Subject to:

(cid:88)

262