Towards Better Internet Citizenship:

Reducing the Footprint of Internet-wide Scans by

Topology Aware Preﬁx Selection

Johannes Klick

Freie Universität Berlin
johannes.klick@fu-

berlin.de

Stephan Lau

Freie Universität Berlin

stephan.lau@fu-berlin.de

Matthias Wählisch
Freie Universität Berlin

m.waehlisch@fu-

berlin.de

Volker Roth

Freie Universität Berlin

volker.roth@fu-berlin.de

ABSTRACT
Internet service discovery is an emerging topic to study
the deployment of protocols. Towards this end, our
community periodically scans the entire advertised IPv4
address space. In this paper, we question this princi-
ple. Being good Internet citizens means that we should
limit scan traﬃc to what is necessary. We conducted a
study of scan data, which shows that several preﬁxes do
not accommodate any host of interest and the network
topology is fairly stable. We argue that this allows us
to collect representative data by scanning less. In our
paper, we explore the idea to scan all preﬁxes once and
then identify preﬁxes of interest for future scanning.

Based on our analysis of the censys.io data set (4.1

TB data encompassing 28 full IPv4 scans within 6 months)
we found that we can reduce scan traﬃc between 25-
90% and miss only 1-10% of the hosts, depending on
desired trade-oﬀs and protocols.

1.

INTRODUCTION

Fast Internet-wide scanning is growing in popularity
among researchers. At the time of writing, researchers
regularly scan the Internet for vulnerable SSL certiﬁ-
cates [6, 12], SSH public keys [10], and for the banners
of plain text protocols such as SMTP, HTTP, FTP,
and Telnet [5]. The majority of researchers scan at
Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than the author(s) must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
IMC 2016, November 14 - 16, 2016, Santa Monica, CA, USA
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to
ACM. ISBN 978-1-4503-4526-2/16/11. . . $15.00
DOI: http://dx.doi.org/10.1145/2987443.2987457

least 2.8 billion addresses advertised in the IPv4 ad-
dress space [5–8, 10–12, 15, 16, 19]. Hitrates, the frac-
tion of probed addresses from which a response is re-
ceived, are very often under two percent [7]. This means
that most scan traﬃc is overhead. Most of these scans
are done periodically for trend analyses, which exacer-
bates the amount of unnecessary scan traﬃc. For ex-
ample, the ongoing Internet-wide research project cen-
sys.io [5,7] probes the IANA allocated address space for
19 protocols on a continuous basis. This results in 72.2
billion generated IP-packets per week. which causes
several hostile responses ranging from threatening le-
gal actions to conducted denial-of-service attacks [7].
Whereas scanning the IPv4 address space is feasible this
is not any more the case for IPv6. When IPv6 becomes
more popular, we need scanning strategies that limit
scans to parts of the address space that are in use.

Many measurement scenarios require only partial scans

instead of exploring the full IP address space. However,
we currently lack a systematic understanding of the de-
ployment of Internet services with respect to IP address
ranges.

In this paper, we want to start the discussion how
we can reduce scan traﬃc systematically. We present
the Topology Aware Scanning Strategy (TASS), a new
IP preﬁx based and topology aware scanning strategy
for periodic scanning. TASS enables researchers to col-
lect responses from 90-99% of the available hosts for six
months by scanning only 10-75% of the announced IPv4
address space in each scan cycle (protocol dependent).
TASS is seeded with the results of a full advertised IPv4
address scan for a given protocol and time period. The
preﬁxes for all responses will be selected for periodic
scans of the given protocol.

Periodic scanning of only selected preﬁxes reduces
scan traﬃc signiﬁcantly while hitting most of the hosts
of interest. For instance, our analysis reveals that re-
sponsive preﬁxes obtained from a full FTP scan cover

421IANA /0

Addresses: ∼4.3 billion

IANA allocated

Publications:
[5–8, 11, 12]
Addresses: ∼3.7 billion

Announced addresses (BGP)

Publications:

[10, 15, 16, 19]

Addresses: ∼2.8 billion
IP hitlists and samples

Publications:

[1, 2, 4, 9, 11, 13, 14, 18, 20]

Addresses: 1-20 million

Figure 1: Current scanning strategies and their
scoping of the IPv4 address space.

98% of all FTP hosts 6 months later, at the cost of
scanning only 57.4% of the advertised addresses. The
scanning overhead can be optimized further by omitting
preﬁxes with a low density. Here, density denotes the
fraction of hosts per address space size. For example,
if we limit preﬁx selection to a 95% coverage of the re-
sponsive addresses then we can still ﬁnd 92.3% of the
FTP hosts after six months while scanning only 20.6%
of the announced address space. Moving forward we
plan to investigate whether the distributions of found
and missed hosts are the same.

For our evaluation of TASS we use 4.1 TB of data de-
rived from 28 full IPv4 scans obtained from censys.io [5].
For common protocols we show that, following an ini-
tial scan of the full IPv4 address space, the hitrate for
responsive preﬁxes decreases by about 0.3 percent per
month compared to what a full scan would ﬁnd.

Consequently, periodical TASS scans are 1.25 to 10
times more eﬃcient for a period of at least 6 months
if researchers accept a single-digit percentage reduction
in host coverage.

2. STATE OF THE ART

TASS represents a trade-oﬀ between scanning over-
head and results accuracy. In what follows, we review
the kinds of trade-oﬀs other researchers have made pre-
viously. We identiﬁed three kinds of approaches in the
literature: (i) full scans of IANA allocated addresses,
(ii) scans of routable addresses and (iii) scans of ad-
dress space samples.
IANA allocated address space. The most basic
approach is to scan all IP addresses covered by the /0
preﬁx. Scans of this type seek to explore the reacha-
bility of all potential hosts. However, some (unicast)
addresses do not oﬀer public services per deﬁnition, for
example, private networks addresses and the loopback
addresses. Excluding these unallocated or reserved ad-
dresses is the ﬁrst obvious step towards a reduction

of scanning noise. This has been a common practice
from the beginning [6, 8, 11, 12] and is still being prac-
ticed [5, 7].
Announced IP addresses (BGP). The second type
of trade-oﬀ involves only addresses that are covered in
global BGP tables [10, 15, 16, 19].
IP hitlists and samples. Several researchers sampled
parts of the IPv4 address space in order to extrapolate
from their data. For example, Alt et al. [1] scanned for
honeypots by probing at least one host in all /24 blocks
of the Internet. Rossow [18] used a random sample of 1
million IP addresses in his research on traﬃc ampli-
ﬁcation threats. Heidemann et al. [11] probed 1% of
the address space repeatedly, which consisted of 24,000
/24 blocks. These blocks were compiled based on three
diﬀerent selection strategies: (i) 50% were selected ran-
domly, (ii) 25% were selected if a host in this block was
responsive before, and (iii) 25% were selected by other
policies. This approach does not discriminate between
preﬁxes of diﬀerent sizes and therefore it does not utilize
potentially important topology information.

Sampling leads to a reduction of scan traﬃc, but
is less suited for research that requires precise statis-
tics. Whereas samples tend to be probabilistic, hitlists
are compiled based on predetermined characteristics.
Fan and Heidemann [9] generated IP address hitlists
by scanning the IPv4 address space repeatedly and by
ﬁltering out addresses that were consistently respon-
sive. Their approach was applicable to only a third of
the Internet, though, and exhibited 40-50% ﬂuctuation
after three months, probably caused by dynamic IP ad-
dresses. By comparison, TASS compiles preﬁx hitlists
and exhibits only 1-10% ﬂuctuation after six months.
Dynamic IP addresses ﬂuctuate within a particular pre-
ﬁx, which may explain why TASS is signiﬁcantly more
stable.

Cai and Heidemann [2] investigated the responsive-
ness of /24 blocks (note the diﬀerence from /24 network
preﬁxes). They probed 1% of the Internet address space
by selecting /24 blocks that were responsive to ICMP
probes, as shown by a prior census of all allocated ad-
dresses. They clustered blocks with adjacent addresses
and similar network behavior, and found that a ﬁfth of
the /24 blocks had a utilization less than 10%.

Plonka et al. [17] used passive IPv6 measurements of
WWW clients for identiﬁcation of stable and dense IPv6
preﬁxes. We use active scan data and focus on hosts,
but we are aware that a combination of both approaches
might lead to a more comprehensive solution.
Summary. The objectives of most of the measurement
studies do not require a priori scanning of unreachable
address space. The state of the art in Internet scanning
appears to base trade-oﬀs primarily on IP blocks and
individual IP addresses. We are not aware of attempts
other than ours to leverage network preﬁx responsive-
ness for scan traﬃc reduction.

4223. TOPOLOGY-AWARE SCANNING

In this section, we give a high-level overview over
TASS, followed by an empirical motivation why TASS
is a promising trade-oﬀ between scanning overhead and
accuracy. An evaluation of TASS performance over time
is given in Section 4. We used the FTP, HTTP, HTTPS,
and CPE WAN Management Protocol (CWMP). For
brevity, we provide graphs primarily for FTP and HTTPS.

l-preﬁx /8

l-preﬁx /8

/12

/8

m-preﬁx

/12

/12

/11

/10

/9

3.1 TASS in a Nutshell

TASS amortizes the overhead of an initial scan of
the full routable address space over repeated scans that
cover only a subset of all preﬁxes. The core idea of
TASS is to identify preﬁxes which are of primary inter-
est when scanning the Internet repeatedly. The goal of
TASS is to be eﬃcient. Eﬃciency is measured as the
number of successful protocol handshakes per number
of connection attempts. TASS is parameterized by an
adjustable target ratio φ that speciﬁes the proportion
of hosts that TASS shall cover in repeated scans. For
this reason, we refer to φ as the host coverage. TASS
works as follows:

1. At time t0, perform a full scan and output all re-
sponsive addresses. Let N be their number. Count
the number of responsive addresses ci in each re-
sponsive preﬁx i. The sum of all ci is N .

2. Calculate the density ρi = ci/232−preﬁx length of all
responsive preﬁxes and their relative host coverage
φi = ci/N of responsive addresses.

3. Sort the preﬁxes in the descending order of density.

Relabel preﬁxes so that i < j ⇔ ρi > ρj.

4. Find the smallest k so that(cid:80)k

i=1 φi > φ.

5. Scan preﬁxes 1, . . . , k repeatedly until time t0+∆t,

then start over at step 1.

Within each time interval [t0, t0 + ∆t] there will be
a gradual loss of results accuracy as hosts leave or en-
ter preﬁxes other than preﬁxes 1, . . . , k. On each full
scan, full accuracy is recovered. We motivate in the
remainder of this section why we expect this strategy
to yield high accuracy with signiﬁcantly reduced scan
overhead. We evaluate the strategy in Section 4 and
quantify the expected loss of accuracy over time, which
yields an adjustable time period ∆t.
3.2 Preﬁx derivation

TASS requires that addresses are mapped to preﬁxes.
The censys.io dataset already contains preﬁx informa-
tion that Durumeric et al. [5] apparently obtained from
their outgoing AS. However, closer inspection reveals
that the included information is often coarse-grained
or even missing. For this reason, we chose to use the
Routeviews Preﬁx-to-AS mappings (pfx2as) provided

(a) Announced preﬁxes.

(b) Resulting m-preﬁxes.

Figure 2: The less speciﬁc l-preﬁx /8 contains
the more speciﬁc m-preﬁx /12. The l-preﬁx is
then decomposed into the more speciﬁc one and
the remaining smallest preﬁxes.

by CAIDA [3] instead. Said mappings reﬂect a topo-
logical view of the Internet, are ﬁne-grained, and are
used routinely for research.

It is worth noting that preﬁxes in BGP may be loosely
aggregated.
In particular, more speciﬁc preﬁxes (m-
preﬁxes, e.g. 100.0.0.0/12) may be announced in paral-
lel to less speciﬁc preﬁxes (l-preﬁxes, e.g. 100.0.0.0/8).
The CAIDA data includes a large fraction of more spe-
ciﬁc preﬁxes in addition to less speciﬁc preﬁxes. For
example, the dataset of 2015/09/07 contains 595,644
preﬁxes of which 54% are m-preﬁxes. The m-preﬁxes
account for 34.4% of the advertised IP space.

To reﬂect potential network characteristics, we deag-
gregate the l-preﬁx of each m-preﬁx into the minimal
set of preﬁxes that contains the m-preﬁx. This ap-
proach allows us to take all routing information into
account while maintaining a proper partition of the ad-
dress space for scanning purposes. See Figure 2 for an
illustration of this process.
In the following two sec-
tions we show that this approach potentially reduces
the number of scanned addresses.
3.3 Host stability versus preﬁx length

We expect that TASS performs well if hosts do not
ﬂuctuate signiﬁcantly in between preﬁxes.
In a ﬁrst
step, we analyzed the distribution of host numbers across
preﬁxes of diﬀerent lengths over a period of six months
with 7 measurements. If the distribution variance was
high then this would already indicate that TASS may
miss hosts. Figures 3(a) and 3(b) show the results for
the case of l-preﬁxes, and Figures 3(c) and 3(d) show the
results for the case of m-preﬁxes. The host numbers ap-
pear to be stable and therefore the results do not contra-
dict our expectation. Of course, this result is necessary
but not suﬃcient by itself. We still need to investigate
the ﬂuctuation in between preﬁxes of the same length.
This is future work that we intend to do with a larger
dataset and for a full paper. The graphs also indicate a
right-shift towards longer preﬁxes without a pronounced
loss of stability. This lends support to our hypothesis

423(a) FTP for less speciﬁc preﬁxes.

(b) HTTPS for less speciﬁc preﬁxes.

(c) FTP for more speciﬁc preﬁxes.

(d) HTTPS for more speciﬁc preﬁxes.

Figure 3: Shows the host distribution over preﬁx lengths based on seven diﬀerent measurements from
09/2015 to 03/2016. Preﬁxes longer than /24 are negligible and have been omitted.

that m-preﬁxes are a better choice than l-preﬁxes be-
cause their density is potentially higher. For example,
if all hosts in an l-preﬁx cluster in an m-preﬁx then the
l-preﬁx minus the m-preﬁx need not be scanned.

3.4 Preﬁx density

TASS yields a favorable trade-oﬀ if small reductions
in coverage lead to large reductions in scan overhead.
Towards an evaluation of the potential trade-oﬀ, we an-
alyzed the density of preﬁxes in relation to the adver-
tised address space. Recall that the density of a preﬁx
is the number of responsive hosts in the preﬁx divided
by the number of addresses in the preﬁx. Figures 4(a)
and 4(b) show the results for the case of l-preﬁxes, and
Figures 4(c) and 4(d) show the results for the case of
m-preﬁxes. The graphs are sorted in the order of de-
creasing preﬁx density ρ, the red curve. Preﬁxes with
zero density are not included. The green curve is the cu-
mulative relative host coverage φ. The blue curve is the
cumulative relative address space coverage. The graphs
show a sharp decrease of preﬁx density combined with
a sharp increase in host coverage and a modest increase
of address space coverage over the range of preﬁxes.
This clearly indicates that preﬁx selection based on pre-
ﬁx density is well suited to maximize the eﬃciency of
scans. Based on the data we analyzed we can report
the following statistics for the case of l-preﬁxes:

• 100% (φ = 1) of all FTP hosts are found in ∼134 K
preﬁxes representing 76.2% of the routed address
space.

• 95% (φ = 0.95) of all FTP hosts are found in
∼105 K preﬁxes representing 27.3% of the routed
address space.

• 23.8% of the addresses were unresponsive.
• The ﬁrst 20 K preﬁxes with a density of ρ > 0.04
contain 64% (φ = 0.64) of all FTP servers but
represent only 2% of the advertised address space.

For m-preﬁxes, an address space coverage of 57.4%
suﬃces to achieve full host coverage (φ = 1), which is
a reduction of 18.8 percentage points compared to l-
preﬁxes. At the same time, preﬁx selection based on
density is roughly twice as eﬃcient as a full scan, for
the FTP protocol. If one tolerates a 5% loss of FTP
hosts then scanning 20.6% of the address space suﬃces
to ﬁnd 95% of the FTP hosts that a full scan would
ﬁnd. For detailed information, see Table 1.

4. ACCURACY OVER TIME

The ﬁndings we summarized in previous sections sug-
gest that TASS can be an eﬃcient scanning strategy.
However, the beneﬁts manifest only if the distribution
of hosts across preﬁxes remains reasonably stable over

●●●/8/10/12/14/16/18/20/22/24Prefix length [bits]FTP hosts [#]0 1M 2M 3M ●●●●●●●/8/10/12/14/16/18/20/22/24Prefix length [bits]HTTPS hosts [#]0 2M 4M 6M 8M ●/8/10/12/14/16/18/20/22/24Prefix length [bits]FTP hosts [#]0 1M 2M 3M ●●●●●●/8/10/12/14/16/18/20/22/24Prefix length [bits]HTTPS hosts [#]0 2M 4M 6M 8M 424(a) FTP: Less speciﬁc preﬁxes.

(b) HTTP: Less speciﬁc preﬁxes.

(c) FTP: More speciﬁc preﬁxes.

(d) HTTP: More speciﬁc preﬁxes.

Figure 4: Shows responsive preﬁxes ranked by their density (dotted), the cumulative relative host
coverage (solid), and the cumulative relative address space coverage (dashed) with density ρ > 0.

time. As a ﬁrst step to quantify the accuracy of TASS
over time we simulated TASS and an address-based
hitlist approach using monthly snapshots of full IPv4
scans from censys.io [5] for the time period from 09/2015
to 03/2016 (7 snapshots). Then we determined the frac-
tion of hosts that TASS and the hitlist approach would
have uncovered in each scan cycle compared to a peri-
odic full scan. We used the aforementioned datasets as
our ground truth, again. We focused our analysis on
four protocols, which were FTP, HTTP, HTTPS and
TR-069 also known as the CPE WAN Management Pro-
tocol (CWMP), a 4.1 TB dataset in total. CWMP is
used for remote management of residential gateways.
We chose CWMP for contrast because its purpose dif-
fers markedly from the other two protocols.

4.1 Hitlist accuracy over time

The hitlist approach we simulated takes all addresses
that are responsive in an initial full scan and subse-
quently scans only those addresses. This strategy ex-
hibits maximal eﬃciency and accuracy for stable (un-
changing) host distributions. Figure 5 show the results
of our simulation. They indicate that the accuracy of
the hitlist approach quickly drops to 80% within one
month and continues to decrease over time for FTP,
HTTP and HTTPS. The drop is much more pronounced
for the CWMP protocol. A likely explanation is that
residential gateways are connected to the Internet via
dynamic IP addresses more often. Over the course of

e
g
a
r
e
v
o
C
e
c
a
p
S

s
s
e
r
d
d
A

s
s
e
l

e
r
o
m

φ

1
0.99
0.95
0.7
0.5

1
0.99
0.95
0.7
0.5

FTP HTTP HTTPS CWMP

0.762
0.470
0.273
0.031
0.008

0.574
0.371
0.206
0.023
0.006

0.828
0.548
0.362
0.064
0.021

0.648
0.440
0.279
0.048
0.017

0.832
0.542
0.343
0.065
0.024

0.645
0.427
0.262
0.052
0.020

0.477
0.142
0.099
0.043
0.024

0.332
0.113
0.085
0.037
0.021

Table 1: IPv4 address space coverage of the pro-
tocols using less and more speciﬁc preﬁxes.

Figure 5: Hitrate using IP hitlists.

 0 0.2 0.4 0.6 0.8 1 0 20000 40000 60000 80000 100000 120000 0 0.2 0.4 0.6 0.8 1DensityCoverageRankdensityhost coverageIPv4 space coverage 0 0.2 0.4 0.6 0.8 1 0 20000 40000 60000 80000 100000 120000 140000 160000 180000 0 0.2 0.4 0.6 0.8 1DensityCoverageRank 0 0.2 0.4 0.6 0.8 1 0 50000 100000 150000 200000 250000 300000 0 0.2 0.4 0.6 0.8 1DensityCoverageRank 0 0.2 0.4 0.6 0.8 1 0 50000 100000 150000 200000 250000 300000 350000 400000 450000 0 0.2 0.4 0.6 0.8 1DensityCoverageRank 0.4 0.5 0.6 0.7 0.8 0.9 109/1510/1511/1512/1501/1602/1603/16HitrateTime [month/year]CWMPFTPHTTPHTTPS425(a) Hitrate with φ = 1.

(b) Hitrate with φ = 0.95.

Figure 6: Hitrate of TASS compared to a full scan.

six months, the accuracy drops to 71% for HTTP and
to 43% for CWMP. From these results we conclude that
the hitlist approach is not recommendable for periodic
scanning over time periods of several months.
4.2 TASS accuracy over time

We simulated TASS with l-preﬁxes and m-preﬁxes
as described prior over the same six months time pe-
riod. Figure 6(a) shows the results for a coverage set-
ting of φ = 1, that is, full host coverage. Recall that
this selects all preﬁxes with a non-zero density, that is,
ρ > 0. We found that accuracy decreases at a rate of
0.3% per month for l-preﬁxes. For m-preﬁxes, accuracy
decreases at a rate of up to 0.7% per month or about
4.2% over the course of six months. The greater ef-
ﬁciency of m-preﬁxes is thus paid for by an accuracy
reduction twice as much as for l-preﬁxes. We repeated
our analysis for a host coverage setting of 95%, that is,
φ = 0.95. This reduced the accuracy further to 90-94%,
depending on the protocol. Figure 6(b) summarizes the
outcomes. We started a similar investigation of SSH
and selected SCADA protocols but to our surprise we
found that accuracy and densities increased over time.
Further scrutiny of the ground truth datasets revealed
that the snapshots for these protocols likely included
data from prior scans. We have notiﬁed the main con-
tributor of censys.io [5] who acknowledged the problem.

5. DISCUSSION AND FUTURE WORK
Our results indicate that less speciﬁc preﬁxes yield
greater scanning accuracy over time than more speciﬁc
preﬁxes. A likely cause is that l-preﬁxes reduce the over-
all number of preﬁxes, which renders it less likely that a
host ﬂuctuates in between preﬁxes. On the other hand,
l-preﬁxes have a higher scanning overhead compared to
m-preﬁxes. For a full host coverage setting (φ = 1),
the overhead diﬀered by about 15-20 percentage points
according to our analysis in Section 3.4. Consequently,
we must consider this trade-oﬀ when deciding between
l-preﬁxes and m-preﬁxes.

Likewise, the host coverage setting φ has a signiﬁ-
cant inﬂuence on the scanning overhead. Even a small
reduction of host coverage, say from φ = 1 to φ = 0.99,
results in a reduction of scan overhead by 20-30%. As
part of our future work we intend to investigate more
closely how the 1% of missed hosts are distributed in
comparison to the other hosts.

Furthermore, in the context of the analysis of secu-
rity incidents (e.g., Heartbleed ) it is important to anal-
yse whether vulnerable servers are distributed equally
across both selected preﬁxes and omitted preﬁxes, for
φ < 1. If the distribution was fairly equal then regular
estimates of vulnerable populations could be obtained
with good eﬃciency and accuracy, for example, with
φ = 0.5 and a small address space coverage of 0.6-0.8%
per scan cycle.

Finally, we suspect that more ﬁne-grained preﬁxes
may help to reduce the scanning overhead even further.
Towards this end, it may be worthwhile to apply the
clustering approach of Cai and Heidemann [2] to net-
work preﬁxes. At any rate we are eager to investigate
other data sets, additional protocols and distribution
patterns for longer periods of time.

6. CONCLUSION

Fast Internet-wide scanning is an emerging topic for

investigators who wish to conduct network research based
on up-to-date real world data. This will likely lead to
a proliferation of scanning activities. Projects such as
censys.io already help to curtail the resulting scan traf-
ﬁc by making current datasets available to the Internet
community for research purposes. However, there will
always be objectives that call for individual data col-
lection. The activities of corporations and individuals
must be factored in as well because tools for fast In-
ternet scanning are widely available. It is desirable to
research and develop tools that tax the address space
and the patience of scan targets more sparingly than
brute force. With TASS, we hope to make progress to-
wards the right direction: a scanning strategy that is

 0.9 0.92 0.94 0.96 0.98 109/1510/1511/1512/1501/1602/1603/16HitrateTime [month/year]  Less specific     More specificCWMPFTPHTTPHTTPSCWMPFTPHTTPHTTPS 0.9 0.92 0.94 0.96 0.98 109/1510/1511/1512/1501/1602/1603/16HitrateTime [month/year]  Less specific     More specificCWMPFTPHTTPHTTPSCWMPFTPHTTPHTTPS426more eﬃcient, without loosing signiﬁcant accuracy of
the results.

Our initial investigations are promising. By select-
ing preﬁxes for periodic scanning according to density
and by adjusting host coverage, it is feasible to address
a wide range of trade-oﬀs. Particularly, small com-
promises with regard to host coverage can reduce scan
overhead substantially, for four protocols that we inves-
tigated thus far (FTP, HTTP, HTTPS, and CWMP).
TASS opens up a variety of options for further research.
When IPv6 becomes popular, brute forcing the address
space becomes infeasible. By then we ought to have
better approaches for network scanning. Perhaps TASS
can oﬀer a blueprint for tackling that challenge as well.
Acknowledgements
We thank the anonymous reviewers, our shepherd, Roya
Ensaﬁ, and Dave Plonka for their helpful comments. We
would also like to thank the censys.io team for having
provided the measurement infrastructure and for their
timely replies to our inquiries. Furthermore, we thank
Carsten Sch¨auble and Christian Salzmann from the IT
service of the CS department of our university for the
compute power they provided for our analysis eﬀort.
This work was partly funded by grants from the German
Federal Ministry of Education and Research (BMBF
Grants No. 16KIS0254, 16KIS0528K).
7. REFERENCES
[1] L. Alt, R. Beverly, and A. Dainotti. Uncovering

Network Tarpits with Degreaser. In Proc. of ACM
ACSAC, 2014.

[2] X. Cai and J. Heidemann. Understanding

Block-level Address Usage in the Visible Internet.
Proc. of ACM SIGCOMM, 2011.

[3] Center for Applied Internet Data Analysis.

Routeviews Preﬁx to AS mappings Dataset for
IPv4 and IPv6. https://www.caida.org/data/
routing/routeviews-preﬁx2as.xml.

[4] D. Cicalese, J. Aug´e, D. Joumblatt, T. Friedman,

and D. Rossi. Characterizing IPv4 Anycast
Adoption and Deployment. In Proc. of ACM
CoNEXT, 2015.

[5] Z. Durumeric, D. Adrian, A. Mirian, M. Bailey,

and J. A. Halderman. A Search Engine Backed by
Internet-Wide Scanning. In Proc. of ACM CCS,
2015.

[6] Z. Durumeric, J. Kasten, M. Bailey, and J. A.
Halderman. Analysis of the HTTPS Certiﬁcate
Ecosystem. In Proc. of ACM IMC, 2013.

[7] Z. Durumeric, E. Wustrow, and J. A. Halderman.

ZMap: Fast Internet-wide Scanning and Its

Security Applications. In Proc. of USENIX
Security, 2013.

[8] P. Eckersley and J. Burns. An Observatory for the

SSLiverse.
https://www.eﬀ.org/ﬁles/defconssliverse.pdf,
2010.

[9] X. Fan and J. Heidemann. Selecting

Representative IP Addresses for Internet
Topology Studies. In Proc. of ACM IMC, 2010.

[10] O. Gasser, R. Holz, and G. Carle. A deeper

understanding of SSH: results from Internet-wide
scans. In Proc. of IEEE NOMS, 2014.

[11] J. Heidemann, Y. Pradkin, R. Govindan,

C. Papadopoulos, G. Bartlett, and J. Bannister.
Census and Survey of the Visible Internet. In
Proc. of ACM IMC, 2008.

[12] N. Heninger, Z. Durumeric, E. Wustrow, and

J. A. Halderman. Mining Your Ps and Qs:
Detection of Widespread Weak Keys in Network
Devices. In Proc. of USENIX Security, 2012.

[13] R. Holz, L. Braun, N. Kammenhuber, and

G. Carle. The SSL Landscape – A Thorough
Analysis of the X.509 PKI Using Active and
Passive Measurements. In Proc. of ACM IMC,
2011.

[14] H. K. Lee, T. Malkin, and E. Nahum.

Cryptographic Strength of SSL/TLS Servers:
Current and Recent Practices. In Proc. of ACM
IMC, 2007.

[15] D. Leonard and D. Loguinov. Demystifying

Service Discovery: Implementing an
Internet-Wide Scanner. In Proc. of ACM IMC,
2010.

[16] A. Nappa, Z. Xu, M. Z. Raﬁque, J. Caballero, and

G. Gu. CyberProbe: Towards Internet-Scale
Active Detection of Malicious Servers. In Proc. of
ISOC NDSS, 2014.

[17] D. Plonka and A. Berger. Temporal and Spatial
Classiﬁcation of Active IPv6 Addresses. In Proc.
of ACM IMC, 2015.

[18] C. Rossow. Ampliﬁcation Hell: Revisiting

Network Protocols for DDoS Abuse. In Proc. of
ISOC NDSS, 2014.

[19] The Shadowserver Foundation. Open Resolver

Scanning Project.
https://dnsscan.shadowserver.org/.

[20] S. Yilek, E. Rescorla, H. Shacham, B. Enright,
and S. Savage. When Private Keys are Public:
Results from the 2008 Debian OpenSSL
Vulnerability. In Proc. of ACM IMC, 2009.

427