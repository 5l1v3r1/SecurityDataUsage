DEMOS-2: Scalable E2E Veriﬁable Elections without

Random Oracles

∗
Aggelos Kiayias
Dept. of Informatics &
Telecommunications

National and Kapodistrian U.
of Athens, Athens, Greece

aggelos@di.uoa.gr

†
Thomas Zacharias
Dept. of Informatics &
Telecommunications

National and Kapodistrian U.
of Athens, Athens, Greece
thzacharias@di.uoa.gr

Bingsheng Zhang

Security Lancaster Research

Centre

‡

Lancaster University,

Lancaster, UK

b.zhang2009@gmail.com

ABSTRACT
Recently, Kiayias, Zacharias and Zhang proposed a new E2E
veriﬁable e-voting system called ‘DEMOS’ that for the ﬁrst
time provides E2E veriﬁability without relying on external
sources of randomness or the random oracle model; the main
advantage of such system is in the fact that election auditors
need only the election transcript and the feedback from the
voters to pronounce the election process unequivocally valid.
Unfortunately, DEMOS comes with a huge performance and
storage penalty for the election authority (EA) compared
to other e-voting systems such as Helios. The main rea-
son is that due to the way the EA forms the proof of the
tally result, it is required to precompute a number of cipher-
texts for each voter and each possible choice of the voter.
This approach clearly does not scale to elections that have
a complex ballot and voters have an exponential number of
ways to vote in the number of candidates. The performance
penalty on the EA appears to be intrinsic to the approach:
voters cannot compute an enciphered ballot themselves be-
cause there seems to be no way for them to prove that it is
a valid ciphertext.

In contrast to the above, in this work, we construct a new
e-voting system that retains the strong E2E characteristics
of DEMOS (but against computational adversaries) while
completely eliminating the performance and storage penalty
of the EA. We achieve this via a new cryptographic con-
struction that has the EA produce and prove, using voters’
coins, the security of a common reference string (CRS) that

∗Supported by ERC project CODAMODA.
†Supported by project FINER, Greek Secretariat of Re-
‡Research was performed while Zhang was a post-doc at

search and Technology funded under action “ARISTEIA 1.”.

National and Kapodistrian University of Athens, Greece.
Supported by project FINER, Greek Secretariat of Research
and Technology funded under action “ARISTEIA 1.”.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS'15, October 12–16, 2015, Denver, Colorado, USA. 
© 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813727.

CCS ’15 Denver, Colorado, US

voters subsequently can use to aﬃx non-interactive zero-
knowledge (NIZK) proofs to their ciphertexts. The EA itself
uses the CRS to prove via a NIZK the tally correctness at
the end. Our construction has similar performance to Helios
and is practical. The privacy of our construction relies on
the SXDH assumption over bilinear groups via complexity
leveraging.

Categories and Subject Descriptors
K.6 [Management of Computing and Information
Systems]: Security and Protection; C.2.4 [Computer-
communication Networks]: Distributed Systems

Keywords
End-2-End Veriﬁability; e-voting systems; Internet voting

1.

INTRODUCTION

End-to-end (E2E) veriﬁability has been widely identiﬁed
as a critical property for the adoption of e-voting systems in
real world election procedures (see e.g., [RG15] for a recent
high level account).
In an E2E veriﬁable election system,
it is possible for an auditor to verify the correctness of the
election tally utilizing feedback from the participants and
examining the public election transcript. Naturally, E2E
veriﬁability should be achieved without violating the privacy
of the voters and any other desirable property of the election
system.

Helios, [Adi08], proposed by Adida, is a widely used e-
voting system that can achieve E2E veriﬁability and pri-
[BCP+11,
vacy (assuming it is suitably instantiated, cf.
BPW12]). To achieve veriﬁability, an important design el-
ement is the incorporation of an “audit or cast” procedure
in the voting booth application that prepares the encrypted
voter’s choice [Ben06]. This process enables the voter to
challenge her device that assists her in the preparation of
her ballot. Once the voter is convinced that the device is
not cheating her she can submit the enciphered vote together
with a cryptographic proof (called a Non-interactive Zero-
Knowledge proof or NIZK, cf.
[BFM88, GS08]) that the
ciphertext properly encodes the voter’s choice. The inclu-
sion of the NIZK is critical for veriﬁability: without it, it
is possible for a malicious client to violate the encoding of
the candidate choice and “stuﬀ” the virtual ballot box with
additional votes for a certain candidate of her choice (or in
general invalidate the election tally).

352In Helios, an auditor can verify the election tally by uti-
lizing some feedback from the voters (speciﬁcally hashes of
submitted ciphertexts that are called “smart ballot track-
ers”) and the election transcript. The auditor will verify
that ciphertexts included in the transcript match the hashes
given by the voters and furthermore that all the NIZK’s in
the transcript are valid.
If all appear to be in order the
election tally can be accepted to be correct.

The above argumentation has a caveat: the veriﬁcation of
the NIZK’s relies on the random oracle model (RO) [BR93]
which basically posits that a given hash function is a ran-
dom function from the perspective of the adversary. It fol-
lows that the auditor should believe the election tally as long
as she believes the Election Authority (EA) has no essential
understanding of the hash function1 that gives her an advan-
tage in breaking soundness of the underlying NIZK’s. While
it will be surprising to obtain a soundness attack against
SHA256 based NIZK such an attack cannot be ruled out as
forging SHA256-NIZK’s is not a problem that has been suﬃ-
ciently studied. Further, in the case of e-voting, even a single
bad NIZK on a single voter ciphertext would be enough to
completely corrupt the election tally and if e-voting is de-
ployed in the large scale the EA could be subverted by a
truly mighty adversary (e.g., it is believed by many that the
US Government/NSA has an understanding of hash function
vulnerabilities that surpasses what is publicly known).

To resolve the above concern, a system called DEMOS
was put forth in [KZZ15] where it is possible to prove E2E
veriﬁability in the “standard model”, which in the termi-
nology of that paper, means without access to an external
source of randomness or the random oracle model. The main
idea is to remove the task of calculating the encrypted vote
from the voter client and have the EA precompute for each
voter a ciphertext for each potential voter choice. The voter
then casts a vote by pointing to a speciﬁc ciphertext and the
EA terminates the procedure by proving all the encryptions
were done correctly (actually they use commitments instead
of encryptions). The system meets its objective as the EA
is the sole entity that performs a Σ proof (cf. [CDS94]) with
the veriﬁer’s challenge formed collectively by the voters who
submit coins (that may be biased) to the election transcript.
At ﬁrst it may seem that this precomputation step is nec-
essary to obtain this level of strong E2E veriﬁability. The
only way to avoid precomputation from the EA, is to have
the voter clients perform the encryption of the voters’ choices
and in such case a proof that the encryption is done correctly
is needed. Such proof has to be non-interactive since the au-
ditor will be active only after the end of the election (and
in fact there may be many independent auditors that wish
to check that the election was executed properly). Unfor-
tunately NIZK’s require either a “common reference string”
(CRS) or the RO. In the former case, the only entity to pro-
duce the CRS is the EA and because the EA is malicious
from the perspective of E2E veriﬁability, if she chooses the
CRS, she can choose it so that the NIZK is “simulatable”
and hence she may be able to produce valid looking NIZKs
for an incorrect statement.
1.1 Our Results

We construct a new e-voting scheme that retains the
[KZZ15] (but

strong E2E veriﬁability characteristics of

1The current Helios implementation uses the SHA256 hash
function for implementing NIZKs.

against computational adversaries) while completely obvi-
ating the need for a precomputation step by the EA. In the
asymptotic sense our system has the same characteristics as
Helios (while entirely removing the reliance to the RO model
for security).

We achieve this via a new technique for proving the va-
lidity of ciphertexts that are submitted by the voters during
ballot casting. Our proof technique may have applications
beyond the e-voting domain - more comments on this below.
As mentioned above, the way to remove the precompu-
tation is to have the voter clients produce the encrypted
choices of the voter; the main technical challenge is how to
prove the validity of those ciphertexts. For simplicity let us
assume for now that the ciphertext ψ that is to be produced
by each voter encrypts a plaintext in {0, 1}. Our construc-
tion strategy is as follows.

We will use a type of NIZK where there are two possi-
ble ways to generate the CRS, one that makes every NIZK
perfectly sound and another that makes every NIZK sim-
ulatable using the trapdoor information associated to the
CRS. The EA will use this dual mode CRS and will pub-
lish a CRS that is of the ﬁrst type, i.e., one that makes all
NIZK’s perfectly sound. This is reasonable in the sense that
if the EA is honest, NIZK statements produced by the vot-
ers over this CRS will be guaranteed to be valid. However,
a danger comes from the fact that nobody can distinguish
such CRS from the other type of CRS that is simulatable
and will enable any collaborator of the EA to fake a NIZK
and stuﬀ the virtual ballot box with fake votes.

To mediate this problem we will have the EA prove that
the CRS she publishes is of the ﬁrst type following the same
general Σ proof structure suggested in [KZZ15] (in contrast
to this latter paper though, the EA will be only proving her
CRS is of the ﬁrst type — not that the whole election tally
is valid). Subsequently any other entity (such as a voter or a
trustee) can utilize the CRS of the EA (we call it the master
CRS) to produce a “second layer” CRS that she can use for
proving a certain statement using NIZK.

In more details our technique is as follows. The master
CRS published by the EA can be seen as a public-key of
an additively homomorphic encryption scheme. When the
prover gets to know the statement to be shown, for instance
when the voter wishes to show that a ciphertext ψ is an
encryption of {0, 1} she performs the following. She cre-
ates two strings crs0, crs1 that are homomorphic ciphertexts
based on the master CRS of the EA. The crs0, crs1 strings
also can be used as dual CRS’s and have the property that
if they are multiplied they provide an encryption of 1. The
dual property of crs0, crs1 is by design as follows: if crs0 is
an encryption of 0 then one can produce simulatable fake
NIZK’s with respect to crs0 while if crs0 is an encryption
of 1 then one can produce only perfectly sound proofs with
respect to crs0. The same properties hold true for crs1.

The product of the two crs0, crs1 is denoted by crs0/1 and
we call it the second layer CRS. The prover will now show
that crs0/1 is an encryption of 1 via a NIZK w.r.t. the master
CRS. Then, the prover will show ψ to be an encryption of 0
with respect to crs0 and an encryption of 1 with respect to
crs1 via two independent NIZK’s on the individual CRS’s.
Observe that in order for the prover to accomplish this she
will have to cheat in one of these two proofs; this is possible
due to the fact that she has chosen the strings crs0, crs1
herself and she is only subject to the constraint that their

353product, crs0/1, is an encryption of 1 (as she has to give
a NIZK proof with respect to the master CRS about this
fact). This ﬂexibility enables her to choose crs0 or crs1 to be
an encryption of 0 and hence simulate one of the two proofs
that show ψ to be an encryption of 0 or an encryption 1 (she
knows the plaintext inside ψ so she has to choose crs0 and
crs1 accordingly).

Using the above strategy, all voters can provide cipher-
texts and prove them to be valid encodings of a candidate
choice.
It is easy to see that as long as the master CRS
is of the perfectly sound type, the proofs that crs0/1 is an
encryption of 1 will be perfect and hence the voters cannot
stuﬀ invalid ciphertexts in the virtual ballot box. However,
as mentioned above, the EA might attempt to use a master
CRS of the second type (simulatable) and then collaborate
with a voter to violate integrity. To prevent that we require
the EA to start a Σ proof showing that the master CRS is
of the perfectly sound type. As in [KZZ15] we collect coins
from the voters to form a weak random source and ﬁnally
at the end have the EA publish together with the result the
ﬁnal move of the Σ protocol using the coins of the voters as
the challenge. The auditor now is tasked with checking all
the NIZK’s w.r.t. the CRS’s generated by the voters as well
as the NIZK’s provided w.r.t. the master CRS. Finally, she
is also tasked with checking the Σ proof provided by the EA
showing that the master CRS is of the perfectly sound type.
Given the above, one may wonder how we will be able
to prove privacy. Naturally, if we are to prove privacy, we
should be able to construct a type of simulation argument
that enables us to plug in some instance of a hard problem
into the honest voters’ ciphertexts. This requires faking at
least one of the NIZK’s which by nature of perfect sound-
ness we will be unable to perform. To circumvent this we
utilize complexity-leveraging:
in the privacy proof, our re-
duction will take super-polynomial time to ﬁnd an execution
of the adversary where the reduction can cheat the Σ proto-
col proof and fake it so that the master CRS is of the second
type (simulatable NIZK’s). In this execution our reduction
will be able to fake all proofs and thus plug in any given
hard problem instance. While this cannot happen in the
real world (as the EA needs to run in real time so she is not
expected to ﬁnd such an execution) our reduction will still
yield an algorithm that breaks a hard problem (it will be the
symmetric external Diﬃe-Hellman (SXDH) problem over bi-
linear groups). Assuming this problem is subexponentially
hard we get a contradiction and hence privacy holds.

Note that in our system we can have trustees participate
(exactly as in the case of Helios) and produce the master
CRS on behalf of the EA; hence we can achieve the same
distribution of trust with respect to privacy as in the Helios
system (this was left open in [KZZ15]). An interesting side
note is that our strategy above provides an eﬃcient way
to perform a Lapidot-Shamir [LS90] type of Σ protocol: the
prover performs a Σ-proof for the CRS that, by nature, does
not have to depend on the statement to be shown which can
become known to the prover only in the third move of the
protocol (where in our case the prover will show using a
NIZK). This proof technique can be generalized and may
have applications beyond e-voting.

1.2 Related Work

Our technique for structuring our proof argument is in-
spired by [GOS06] where correlated random strings are cho-

sen by the prover in such a way that a veriﬁer can check that
at least one of them will yield a perfectly sound proof but
she cannot distinguish which one. The prover then proceeds
to issue NIZK’s for each random string thus ensuring that
one of them will be valid. Our NIZK proof is a modiﬁed and
simpliﬁed version of the NIZK given in [GS08].

In terms of modeling privacy and veriﬁability we fol-
low previous works in the area [KTV10, KTV11, BCP+11,
BPW12, KZZ15] mostly using the latter reference as a basis
for our formulation. Importantly, due to the virtues of our
construction, we can achieve a stronger level of privacy com-
pared to [KZZ15] that is in the simulation based sense, akin
to [BPW12], as opposed to the indistinguishability-type of
privacy shown in [KZZ15].

We also argue that our deﬁnition captures a level of
receipt-freeness in the sense of [KZZ15]. On the other hand,
we do not deal with coercion resistance; however techniques
such as those of [JCJ02] are in principle compatible with our
approach and our system may be augmented to incorporate
them. We leave this for future work.

2. PRELIMINARIES
2.1 Notations

1 , Ax

Throughout this paper, we use λ as the security parame-
ter. Calligraphic letters are used for sets and algorithms. A
shorthand x ← X denotes that x is drawn uniformly from
a set X . For algorithms and distributions, the same nota-
tion x ← A means that the element x is sampled according
to the (output) distribution. When A is a probabilistic al-
gorithm, we use A(x; r) to denote running A on input x
with explicate random coin r. Let A = (A1, A2) ∈ G2
and B = (B1, B2) ∈ G2 be two ElGamal ciphertexts. By
A · B, we mean (A1 · B1, A2 · B2); similarly, by Ax we mean
(Ax
2 ). We denote Dlogg(h) as the discrete logarithm of
h with respect to base g.
2.2 Bilinear Groups and SXDH Assumptions
Let Genbp(1λ) be a probabilistic polynomial time (PPT)
bilinear group generator that takes input as the security
parameter, λ ∈ N and outputs the group parameters,
σbp := (p, G1, G2, GT , e, g1, g2), where (i) G1, G2, GT are
cyclic multiplicative groups with prime order p; (ii) g1 ∈
G1 and g2 ∈ G2 generate G1 and G2 respectively; (iii)
e : G1 × G2 (cid:55)→ GT is a non-degenerate bilinear pairing such
2) = e(g1, g2)ab. We assume the decisional Diﬃe-
that e(ga
Hellman problem is hard in both groups, a.k.a., the symmet-
ric external Diﬃe-Hellman (SXDH) assumption holds.

1 , gb

Deﬁnition 1 (SXDH) We say SXDH assumption holds for
Genbp(1λ) if for any PPT adversary A we have ∀i ∈ {1, 2}
the distinguishing advantage Advsxdh(A) is negligible in λ:

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Pr

 σbp ← Genbp(1λ);

a, b ← Z∗
p :
A(σbp, ga
i , gb

i , gab

 − Pr

 σbp ← Genbp(1λ);

a, b, c ← Z∗
p :
A(σbp, ga
i , gc
i , gb

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

i ) = 1

i ) = 1
2.3 Sigma Protocols
Let R be an eﬃciently computable binary relation. For
all (x, w) ∈ R, we call x the statement and w the witness,
and L is the language consisting of the statements in R.
In a Sigma protocol, the prover P wants to convince the
veriﬁer V a statement x ∈ L in a zero knowledge fashion.

354More speciﬁcally, Sigma protocols are 3-move public coin
special honest-veriﬁer zero knowledge proofs of knowledge
with special soundness. In the ﬁrst step, the prover publishes
a commitment message, denoted as Σ(1). In the second step,
the veriﬁer gives a challenge message, denoted as ch. In the
third step, the prover outputs a response message, denoted
as Σ(2). At the end, the transcript (Σ(1), ch, Σ(2)) is publicly
veriﬁable with respect to (x,L).

In this work, we employ the Schnorr’s identity proto-
col [Sch89] to show the knowledge of discrete logarithm.
For instance, Σdlog {(s) : h = gs} stands for a Sigma pro-
tocol for the knowledge of secret s satisfying the equation
h = gs. We also use the DDH tuple proof [Cha90] to show
the correctness of election parameters.
In particular, by
Σddh {(x) : C = Ax ∧ D = Bx}, we mean a Sigma protocol
showing the DDH tuple relation of (A, B, C, D).
2.4 Non-interactive Zero Knowledge Proofs.
An non-interactive proof system Γ = (Gencrs, Simcrs, Prov,

Vrfy, Sim) consists of the following PPT algorithms:

• Gencrs(σbp) is a CRS generation algorithm that takes
input as the bilinear group parameter σbp ← Genbp(1λ)
and outputs a common reference string crs.

• Simcrs(σbp) is a CRS simulator that takes input as the
bilinear group parameter σbp ← Genbp(1λ) and outputs
a simulated common reference string crs∗ together with
a simulation trapdoor td.

• Prov(crs; x; w) is the prover algorithm that takes inputs
as the common reference string crs, the statement x
and the witness w, and outputs a proof π.

• Vrfy(crs; x; π) is the veriﬁer algorithm that takes inputs
as the common reference string crs, the statement x
and the proof π, and outputs 1 if the proof is accept-
able and 0 otherwise.

• Sim(crs∗; x; td) is the proof simulator that takes inputs
as the simulated crs∗, the statement x and the simula-
tion trapdoor td, and outputs a simulated proof π∗.

We call Γ a non-interactive zero knowledge (NIZK) proof
system if it has completeness, soundness, and zero knowl-
edge properties described below.

Deﬁnition 2 (Perfect completeness) We say the NIZK sys-
tem Γ for R is perfectly complete if for all adversaries A:

(cid:20) σbp ← Genbp(1λ); crs ← Gencrs(σbp); (x, w) ← A(crs);

π ← Prov(crs; x; w) : Vrfy(crs; x; π) = 1 ∨ (x, w) (cid:54)∈ R

(cid:21)

Pr

Where Sim∗(crs∗, td, x, w) = Sim(crs∗, x, td) for (x, w) ∈ R
and both oracles outputs ⊥ if (x, w) (cid:54)∈ R.

3. E-VOTING SECURITY FRAMEWORK
3.1 Syntax

An e-voting system is an interactive protocol Π among an
election authority EA, a bulletin board BB, a set of voters
V = {V1, . . . , Vn} (who may utilize a voter supporting device
(VSD) to vote), and a set of trustees T = {T1, . . . , Tt}. Let
O = {opt1, ..., optm} be the set of election options. We
denote by U ⊆ 2O the collection of subsets of options that
the voters are allowed to choose to vote. We denote the
option selection of voter V(cid:96) as U(cid:96) ∈ U, which is a subset of
the options. Let (cid:126)U be the set of vectors of option selections
of arbitrary length. Let F : (cid:126)U (cid:55)→ (Z+)m be the election
evaluation function such that F (U1, . . . ,Un) is equal to an
m-vector whose i-th location is equal to the number of times
opti was chosen in the option selections U1, . . . ,Un.

Similar as [KZZ15], we consider an e-voting system Π as
a quintuple of algorithms and protocols that are denoted by
(Setup, Cast, Tally, Result, Verify) as follows:

• Setup is a protocol executed among the trustees T ,
the election authority EA, and the bulletin board BB.
During the protocol, the election public parameters
including V,O,U are generated and published on BB.
The voters’ credentials (s1, . . . , sn) are generated and
distributed to the voters. After the protocol execution,
each trustee Ti obtains a private state sti.

• Cast is a protocol executed between the voter V(cid:96) (who
operates a VSD) and BB. In the protocol, V(cid:96) posts her
ballot blt(cid:96) to BB and obtains a receipt rec(cid:96).

• Tally is a protocol executed among T1, . . . , Tt, EA and
BB.
In the protocol, each Ti sends her partial tally
data tai to the EA, and the EA will post the received
data to BB after all Ti complete their Tally protocols.
• Result is an algorithm that takes input as the election
transcript info on BB, and outputs the election result
or returns ⊥ in case such result is undeﬁned.

• Verify is an algorithm that takes input as the election
transcript info on BB, and an auxiliary information
aux, and outputs 0 or 1. aux can be either a voter’s
receipt, rec(cid:96) or a trustee’s private state sti.

= 1

Deﬁnition 3 (Perfect soundness) We say the NIZK system
Γ for R is perfectly sound if for all adversaries A, we have:

(cid:20) σbp ← Genbp(1λ); crs ← Gencrs(σbp);

(x, π) ← A(crs) : Vrfy(crs; x; π) = 1 ∧ x (cid:54)∈ L

(cid:21)

= 0

Pr

Deﬁnition 4 (Computational zero-knowledge) We say the
NIZK system Γ for R is computationally zero-knowledge if
there exists a pair of probabilistic polynomial time simulators
(Simcrs, Sim) such that for all non-uniform polynomial time
adversaries A, the following is negligible in λ:

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)Pr

 σbp ← Genbp(1λ);

crs ← Gencrs(σbp) :
AProv(crs;·;·)(crs) = 1

 − Pr

 σbp ← Genbp(1λ);

(crs∗, td) ← Simcrs(σbp) :
ASim∗(crs∗,td,·,·)(crs∗) = 1

3.2 Simulation-based Privacy

We model privacy as indistinguishability between a real-
world experiment and an ideal world experiment.
In the
experiment, the adversary is allowed to corrupt a number of
voters and all but one of the trustees.
In Figure 1, we deﬁne an ideal process denoted as F m,n,t
k-priv
that captures the essential aspects of the election function-
ality from a privacy perspective (we stress that this is not a
full ideal functionality as it is not intended to capture cor-
rectness or veriﬁability which we model separately).

In the ideal experiment all the entities, i.e., T1, . . . , Tt,
V1, . . . , Vn and EA, are modeled as dummy parties that sim-
ply forward the input they receive from the environment Z
to the ideal process F m,n,t
k-priv . Note that the environment Z

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

355• Upon receiving (sid, init, O, V, T , U ) from EA, it parses
O as options {opt1, ..., optm}, V as voters {V1, ..., Vn},
T as trustees {T1, ..., Tt}, and U voting option selections
U ⊆ 2O it sets the election status to ‘init’ and creates
an empty set Tstart. It sends (sid, init, O, V, T , U ) to the
adversary S.

• Upon receiving (sid, start) from Ti, if the election status
is ‘init’ and Ti (cid:54)∈ Tstart, then it sends (sid, start, Ti) to S.
• Upon receiving (sid, start, Ti) from S and provided Ti has
sent (sid, start) before, it adds Ti to Tstart.
• Once |Tstart| = t, it sets the election status to ‘vote’ and
creates an empty set Vvoted and an empty string records.
It then sends (sid, vote) to S.
• Upon receiving (sid, cast, U(cid:96)) from V(cid:96), if the election sta-
tus is ‘vote’ and U(cid:96) ∈ U, then it sends (sid, cast, V(cid:96)) to
S.
• Upon receiving (sid, cast, V(cid:96)) from S, if the election sta-
tus is ‘vote’ and (sid, cast, U(cid:96)) was sent before by V(cid:96), it
adds/updates (V(cid:96), U(cid:96)) to records and adds V(cid:96) to Vvoted.
• Upon receiving (sid, tally) from EA, if the election status
is ‘vote’, it sets the election status to ‘tally’ and creates
an empty set Ttally. It then sends (sid, tally) to S.
• Upon receiving (sid, proceed) from Ti, if the election sta-
tus is ‘tally’ and Ti (cid:54)∈ Ttally, it sends (sid, proceed, Ti) to
the adversary S.
• Upon receiving (sid, proceed, Ti) from S, provided that Ti
sent (sid, proceed) before and election status is ‘tally’, it
adds Ti to Ttally.
• Once |Ttally| = t, it computes and sends the election re-
sults τ ← F (Uvoted) to S, where Uvoted = (cid:104)U(cid:96)|(V(cid:96), U(cid:96)) ∈
records ∧ V(cid:96) ∈ Vvoted(cid:105).

Figure 1: The interaction between the ideal process
F m,n,t
k-priv and the ideal world adversary S.

can schedule all the election entities arbitrarily. The ideal
world adversary S that is active in the experiment inter-
acts with the ideal process F m,n,t
k-priv and provides output to Z
which makes a ﬁnal decision outputing a bit. The adversary
is also allowed to control the corrupted parties, i.e. up to
k voters and up to t − 1 trustees. Note that the interac-
tion between Z and S is restricted in this way (in the spirit
of [Can98]) since in our setting it is impossible to achieve
stronger notions of simulation-based security (such as uni-
versal composition, [Can01]). We denote the output of the
environment in the ideal experiment by IDEALFm,n,t
k-priv ,S,Z (λ).
In the real world experiment, the entities T1, . . . , Tt,
V1, . . . , Vn, EA, BB are executing the protocol Π in the pres-
ence of an adversary A who has corrupted up to k voters
and t − 1 trustees. The voters and the trustees run the
protocol on command by the environment. We denote the
output of the environment in the real world experiment by
REALΠ,A,Z (λ). The objective of the adversary is to obtain
suﬃcient information about the honest voters’ option selec-
tion so that, in collaboration with the environment, is able
to distinguish the real from the ideal world execution.
We say that the protocol is private if for all real-world
adversaries A there is a simulator S so that it is impossible
for any environment Z to distinguish between the real and
ideal world experiment. Formally, we deﬁne it as follows.

Deﬁnition 5 Let n, m, t, k ∈ N with k ≤ n and Π an e-
voting protocol with t trustees and n voters. We say that Π
is k-private if for any PPT adversary A controlling up to k
voters and up to t − 1 trustees, there is an adversary S in
the ideal world experiment, such that for any environment
Z the following two random variables are computationally
indistinguishable,

IDEALFm,n,t

k-priv

,S,Z (λ)

c≡ REALΠ,A,Z (λ)

3.3 E2E Veriﬁability

We would like to extend the E2E veriﬁability deﬁnition
in [KZZ15] to adding VSD and trustees. Similarly, we use
the metric d1(·,·) derived by the 1-norm, (cid:107)·(cid:107)1 scaled to half2
to measure the adversarial success rate with respect to the
amount of tally deviation d and the number of voters that
perform audit θ. The adversary starts by selecting the voter,
options and trustee identities for given parameters n, m, k.
It also speciﬁes the set U of the allowed ways to vote. The
adversary now fully controls all the trustees and the EA. The
adversary manages the Cast protocol executions, playing
the role of the VSD. For each voter, the adversary may
choose to corrupt it or to allow the challenger to play on
its behalf. In the second case, the adversary provides the
option selection that the honest voter will use in the Cast
protocol. The adversary ﬁnally posts the election transcript
to the BB.
As in [KZZ15], we consider a vote extractor algorithm E
(not necessarily running in polynomial-time) that explains
the election transcript from the dishonest voters’ aspect.
The adversary will win the game provided that there is a
subset of θ honest voters that audit the result successfully
but the deviation of the tally is bigger than d; the adver-
sary will also win in case the vote extractor fails to produce
the option selection of the dishonest voters but still, θ hon-
est voters verify correctly. The attack game is speciﬁed in
detail in Figure 2.

Deﬁnition 6 (E2E-Veriﬁability) Let 0 <  < 1 and
m, n, t, d, θ ∈ N with θ ≤ n and Π an e-voting protocol with
n voters and t trustees. Π achieves E2E veriﬁability with
error , w.r.t. the election function F a number of θ honest
voters and tally deviation d if there exists a (not necessarily
polynomial-time) vote extractor E such that for any PPT ad-
versary A that controls all t trustees, less than n − θ voters,
the EA and all VSD’s it holds:

Pr[G

A,E,d,θ
e2e-ver (1λ, m, n, t) = 1] < 

In plain words, Deﬁnition 6 implies that in an E2E veriﬁ-
able e-voting system, if the number of voters that verify the
result is θ then any adversary that attempts to manipulate
the result by a shift of d according to the metric d1(·,·) will
get caught with probability more than 1 − .

4. BUILDING BLOCKS

In this section, we construct a few cryptographic building

blocks for our DEMOS-2 system.
2I.e., d1 : Zm

+ × Zm
+ −→ R with d1(w, w(cid:48)) = 1
i=1 |wi − w(cid:48)
i|.

2 · (cid:107)w − w(cid:48)(cid:107)1 =

2 ·(cid:80)n

1

356E2E Veriﬁability Game G

A,E,d,θ
e2e-ver (1λ, m, n, t)

1. A chooses O = {opt1, ..., optm}, V = {V1, ..., Vn}, T =
{T1, ..., Tt}, and U ⊆ 2O.
It sends them to C along
with some public election parameters and voter creden-
tials {s(cid:96)}(cid:96)∈[n] parameterized by security parameter λ.
Throughout the game, C plays the role of the BB.
2. A and C engages in an interaction where A schedules the
Cast protocols of all voters. For each voter V(cid:96), A can
either completely control the voter or allow C operate on
V(cid:96)’s behalf, in which case A provides a option selection
U(cid:96) to C. Then, C engages in the Cast protocol with the
adversary A, so that A plays the roles of EA and VSD.
Provided the protocol terminates successfully, C obtains
the receipt α(cid:96) on behalf of V(cid:96).
Let ˜V be the set of honest voters (i.e., those controlled by
C) that terminated successfully.

3. Finally, A posts the election transcript info to the BB..

The game returns a bit which is 1 if and only if the following
conditions hold true:

1. | ˜V| ≥ θ (i.e., at least θ honest voters terminated).
2. ∀(cid:96) ∈ [n] : if V(cid:96) ∈ ˜V then Verify(info, rec(cid:96)) = 1.

and either one of the following two :

3.a. if ⊥ (cid:54)= (cid:104)U(cid:96)(cid:105)V(cid:96)∈V\ ˜V ← E(info, {rec(cid:96)}V(cid:96)∈ ˜V ) then

(cid:0)Result(info), F (U1, . . . , Un)(cid:1) ≥ d,

d1

3.b. ⊥ ← E(info, {rec(cid:96)}V(cid:96)∈ ˜V ).

Figure 2: The E2E Veriﬁability Game between the
challenger C and the adversary A using the vote ex-
tractor E.

4.1 A NIZK for DDH Tuple
In this section, we construct a NIZK proof that allows
the prover to convince the veriﬁer (A, B, C, D) ∈ (G1)4 is a
DDH tuple, i.e. the prover shows that he knows s ∈ Zp such
that C = As ∧ D = Bs. The same proof works analogously
for DDH tuple in G2, and such a NIZK proof with respect
to crs is denoted as NIZK{crs; (s) : C = As ∧ D = Bs}. Our
proof is modiﬁed and simpliﬁed from the well-known Groth-
Sahai (GS) proof system [GS08]. Similar to [GOS06], we
use additively homomorphic public key cryptosystem, lifted
ElGamal, for the commitment scheme. Given an lifted El-
Gamal ciphertext u ∈ (G2)2, the commitment of m ∈ Zp
with randomness r ∈ Zp is deﬁned as um · Encpk(0; r). It is
easy to see that when u = Encpk(x), x (cid:54)= 0, the commitment
is perfectly binding and when u = Encpk(0) the commitment
is perfectly hiding.

The CRS of our NIZK consists of the bilinear group pa-
rameter, σbp and the commitment key, ck := (pk, u). The
CRS is perfectly sound when the perfectly binding commit-
ment key is used, while it is perfectly simulatable when the
perfectly hiding commitment key is used. Formally, the
NIZK proof system Γddh consists of the following PPT al-
gorithms:

• Genddh

crs (σbp):
– Pick α1, α2 ← Z∗
p.
– Set h2 = gα1
– Output crs := (σbp, ck := (h2, u)).

2 and u = (u1, u2) := (gα2

2 , g2hα2

2 ).

• Simddh

crs (σbp):
– Pick α1, α2 ← Z∗
p.
– Set h2 = gα1
– Output crs∗ := (σbp, ck := (h2, u)) and td := α2.

2 and u = (u1, u2) := (gα2

2 , hα2

2 ).

• Provddh(crs; (A, B, C, D); s):

– Pick r ← Zp.
– Set c = (c1, c2) = Comck(s; r) := (us

1gr

2, us

2hr

2),

π1 = Ar, and π2 = Br.
– Output π := (c, π1, π2).
• Vrfyddh(crs; (A, B, C, D); π):

– Output 1 if and only if the following holds.

∗ e(C, u1) · e(π1, g2) = e(A, c1).
∗ e(C, u2) · e(π1, h2) = e(A, c2).
∗ e(D, u1) · e(π2, g2) = e(B, c1).
∗ e(D, u2) · e(π2, h2) = e(B, c2).

• Simddh(crs∗; (A, B, C, D); td):

– Pick r ← Zp.
– Set c∗ = (c1, c2) := (gr

π∗
2 = BrD−α2 .

– Output π∗ := (c∗, π∗

1 , π∗
2 ).

2, hr

2), π∗

1 = ArC−α2 , and

Clearly, the simulated CRS is computationally indistin-
guishable from the real CRS based on the IND-CPA security
of the underlying public key cryptosystem.

Theorem 1 The protocol Γddh is a NIZK proof system for
(A, B, C, D) ∈ (G1)4 is a DDH tuple. The NIZK proof has
perfect completeness, perfect soundness and computational
zero-knowledge under the SXDH assumption.

Due to space limitation, we omit the proof of Thm. 1 here.
Note that the proof can be derived from the generic GS proof
in instantiation 3 [GS08].
4.2 NIZK OR Composition

In our work, OR composition of the NIZK proofs is of-
ten needed, e.g., to show a lifted ElGamal ciphertext in
(G1)2 (resp. (G2)2) is an encryption of 0 or 1. To achieve
this, we adopt the correlated key generation technique from
[GOS06]3. The intuition is to use two tiers of NIZK proofs,
and the CRS for the ﬁrst tier NIZK is given as the master
CRS. To prove an OR composition of statements such as
x1 ∨ . . . ∨ xn, the prover ﬁrst generates n second tier CRS’s,
crs1, . . . , crsn and uses the master CRS to show that at least
one of them is a perfectly sound CRS; the prover then uses
the second tier CRS crsi prove the statement xi for i ∈ [n].
Since the prover is able to generate n − 1 perfectly simu-
latable CRS’s with trapdoors, he can simulate any n − 1
statements. On the other hand, at least one of the crsi is
perfectly sound, so at least one of the statement xi is valid.
The ZK property directly follows the fact that it is compu-
tationally hard to distinguish which CRS is perfectly sound.
More speciﬁcally, the prover gives n lifted ElGamal ci-
phertexts as the n second tier CRS, and shows the product

3We refer interested readers to [R`af15] for more general
NIZK composition via correlated key generation.

357of them is an encryption of 1 using the DDH tuple NIZK de-
scribed in Section 4.1. Therefore, we can ensure that at least
one of the CRS encrypts an non-zero value. In the following,
we describe the NIZK proof system Γ0/1 for the ciphertext
c = Encpk(b; r) ∈ (G1)2 encrypts 0 or 1, i.e., b ∈ {0, 1}.

• Gen0/1

crs (σbp):
– Use G1 variant of Genddh

CRS crsm in G1.

crs (σbp) to produce a master

• Sim0/1

crs (σbp):
– Use G1 variant of Simddh

lated CRS crs∗

m in G1 and a trapdoor td.

crs (σbp) to produce a simu-

• Prov0/1(crsm; (pk := (g1, f1), c); (b, r)):

– Pick α1, α2, α3 ← Zp.
– Set h2 = gα1

and u(1−b) = (u(1−b)

2 , u(b) = (u(b)
, u(1−b)
1
:= (σbp, ck(b)

2

– Deﬁne crs(b)

1 , u(b)

2 , g2hα2
2 ) = (gα2
2 , hα3
2 ).

) = (gα3

2 ),

:= (h2, u(b))) and

crs(1−b) := (σbp, ck(1−b) := (h2, u(1−b))).

– Set (u1, u2) = u(b) · u(1−b) ∈ (G2)2 and compute
πcrs ← Provddh(crsm; (g2, h2, u1, u2/g2); α2 + α3).
1); r) and
); α3).

– Set π(b) ← Provddh(crs(b); (g1, f1, c1, c2/gb

π(1−b) ← Simddh(crs(1−b); (g1, f1, c1, c2/g1−b
1
– Output π := (crs(0), crs(1), πcrs, π(0), π(1)).

• Vrfy0/1(crsm; (pk := (g1, f1), c); π):

– Output 1 if and only if the following veriﬁes.

∗ Vrfyddh(crsm; (g2, h2, u1, u2/g2); πcrs)=1.
∗ Vrfyddh(crs(0); (g1, f1, c1, c2); π(0)) = 1.
∗ Vrfyddh(crs(1); (g1, f1, c1, c2/g2); π(1)) = 1.

• Sim0/1(crs∗

m; (pk := (g1, f1), c); td):

– Pick α1, α2, α3 ← Zp.
– Set h2 = gα1
u(1) = (u(1)
– Deﬁne crs(0)

1 , u(0)
2 , u(0) = (u(0)
2 ) = (gα2
1 , u(1)
2 ) = (gα3
2 , hα3
2 ).
:= (σbp, ck(0)

2 , hα2

2 ), and

:= (h2, u(0))) and

crs(1) := (σbp, ck(1) := (h2, u(1))).

– Set (u1, u2) = u(0) · u(1) ∈ (G2)2 and compute

πcrs ← Simddh(crsm; (g2, h2, u1, u2/g2); td).

– Set π(0) ← Simddh(crs(0); (g1, f1, c1, c2); α2) and

π(1) ← Simddh(crs(1); (g1, f1, c1, c2/g1); α3).
– Output π∗ := (crs(0), crs(1), πcrs, π(0), π(1)).

Theorem 2 The protocol Γ0/1 is a NIZK proof system for
c encrypts 0 or 1. The NIZK proof has perfect completeness,
perfect soundness and computational zero-knowledge under
the SXDH assumption.

Proof. Perfect completeness. It directly follows the
completeness and simulatability of the underlying Γddh.
Perfect soundness. The prover generates two CRS’s,
crs(0) and crs(1), and uses Γddh to show that the product
of them is lifted ElGamal encryption of 1. Since Γddh is
perfect sound, it is sure that at least one CRS encrypts to

a non-zero value. By simultaneously showing the given ci-
phertext c is encryption of 0 and 1 with respect to crs(0) and
crs(1), we guarantee that c encrypts either 0 or 1. Compu-
tational zero-knowledge. First of all, crs(0) and crs(1) are
computationally indistinguishable if the SXDH assumption
holds. Analogously, the simulated CRS is computationally
indistinguishable from the real one. Moreover, the Γddh is
computationally zero-knowledge, so all the simulated sub-
proofs are indistinguishable from a real ones. Therefore, π∗
(cid:4)
is computationally indistinguishable from π.

4.3 Lapidot-Shamir Revisited

Kiayias, Zacharias and Zhang [KZZ15] proposed a tech-
nique that allows the EA to prove the validity of some cryp-
tographic elements on the BB using Sigma protocols.
In
particular, the EA posts the commitment messages of Sigma
protocols on the BB before the election starts; During the
election, the veriﬁer’s challenge is jointly contributed by all
the voters (1 bit per voter); After the election ends, the EA
then completes the Sigma protocols by posting the corre-
sponding response messages on the BB. However, this tech-
nique has its limitations, namely, the statement to be proven
must be ﬁxed before the election starts. In order to prove a
statement that is generated during or after the election, we
need a generic 3-move ZK protocol whose commitment mes-
sage is independent of the statement, such as the Lapidot-
Shamir protocol4 [LS90]. Unfortunately, one has to convert
the original language to Hamiltonian cycle in order to use
the Lapidot-Shamir protocol, so it is very ineﬃcient in prac-
tice.

To resolve this issue, we propose a new Lapidot-Shamir
like 3-move ZK framework where the prover’s ﬁrst move does
not depend on the statement to be proven. The idea is to
combine a 3-move public coin honest-veriﬁer zero-knowledge
protocol with a perfectly sound NIZK proof. For notation
simplicity, we will use Sigma protocol notation for such 3-
move public coin honest-veriﬁer zero-knowledge protocols,
but we emphasize that the special soundness and special ZK
properties are not necessary for our composition. Let ΓL be
a perfectly sound NIZK proof system for some NP language

crs(σbp; r) = crsL(cid:9) be a Sigma proto-

L, and let Σcrs(cid:8)(r) : GenL

col to show the given crsL is a perfectly sound CRS. The mes-
sage structure of the composed 3-move ZK protocol between
the prover P and the veriﬁer V is depicted in Figure 3. In
the ﬁrst move, the prover P generates a NIZK CRS crsL and
sends it to the veriﬁer V together with the commitment mes-
the veriﬁer V gives the challenge message ch. In the third
move, the prover V ﬁxes the statement x ∈ L and computes
then sends to V the statement x, the NIZK proof π, and the

crs(σbp; r) = crsL(cid:9).In the second move
sage of Σcrs(cid:8)(r) : GenL
the NIZK proof for x, π ← NIZK(cid:8)crsL; (w) : (x, w) ∈ R(cid:9). P
response message of Σcrs(cid:8)(r) : GenL
crs(σbp; r) = crsL(cid:9). V ac-
crs(σbp; r) = crsL(cid:9) , ch,
(cid:8)(r) : GenL
(cid:8)(r) : GenL
crs(σbp; r) = crsL(cid:9)) is a valid Sigma protocol

cepts the proof if (i) (Σcrs
(1)
Σcrs
(2)
transcript and (ii) VrfyL(crsL; x; π) = 1.

Theorem 3 Let ΓL be a perfectly complete, perfectly sound,
and computationally zero-knowledge NIZK proof system for

4NB: Technically, the size of the commitment message of the
Lapidot-Shamir protocol still depends on the statement.

358• P → V: crsL and Σcrs
• V → P: ch

• P → V: x, π ← NIZK(cid:8)crsL; (w) : (x, w) ∈ R(cid:9) and

(1)

(cid:8)(r) : GenL
crs(σbp; r) = crsL(cid:9)

crs(σbp; r) = crsL(cid:9)

(cid:8)(r) : GenL

Σcrs
(2)

Figure 3: The message structure of the composed
3-move ZK for L.

language L, and let Σcrs(cid:8)(r) : GenL

crs(σbp; r) = crsL(cid:9) be a 3-

move public coin honest veriﬁer zero-knowledge protocol with
perfectly completeness, statistical soundness, and computa-
tional zero-knowledge. The above composed 3-move public
coin honest veriﬁer zero-knowledge protocol for language L
is perfectly complete, statistically sound, and computation-
ally zero-knowledge.

Proof. Perfect completeness.

Σcrs(cid:8)(r) : GenL
Since Σcrs(cid:8)(r) : GenL

It directly follows
from the perfect completeness properties of both ΓL and

crs(σbp; r) = crsL(cid:9). Statistical soundness.
crs(1λ; r) = crsL(cid:9) is statistically sound,

crsL is a perfectly sound CRS with over-whelming proba-
bility. When crsL is a perfectly sound CRS, no adversary
can produce a fake π∗ to make the veriﬁer accept an in-
valid x∗ (cid:54)∈ L such that VrfyL(crsL; x∗; π∗) = 1. Hence,
the composed ZK is statistically sound. Computational
zero-knowledge. The simulatable CRS crs∗ generated by
SimL
crs(σbp) is computationally indistinguishable from a per-
fectly sound CRS. From the computationally zero-knowledge

properties of both ΓL and Σcrs(cid:8)(r) : GenL

crs(σbp; r) = crsL(cid:9),

it is easy to see that the simulated composed ZK proof is
(cid:4)
computationally indistinguishable from a real one.

5. SYSTEM DESIGN
5.1 System Overview

Our system is a single-server web-based system.

In an
election, the election server mainly plays roles as EA and
BB but may aid the other parties. All the other parties are
realized by Javascripts running at the client side. We as-
sume there is a secure channel between the election server
and each trustee, say, realized by HTTPS. The system uses
homomorphic tally and currently supports x-out-of-m type
of option selection. Let mmin (resp. mmax) be the mini-
mum (resp. maximum) number of options that is allowed to
choose to vote.

Setup. To create an election, the EA needs to login
to the election server and provides the election deﬁnition.
An election deﬁnition consists of question, options, (mmin,
mmax), start/end time, trustee list (including their email
addresses), and voter list (including their voter ID’s and
email addresses). The election server then creates a unique
election ID, eid and selects a bilinear group parameter for
the election, σbp := (p, G1, G2, GT , e, g1, g2) ← Genbp(1λ),
and posts σbp on BB. (Note that σbp is hard-coded in our
prototype.) The election server then generates and sends a
random 128-bit credential to each trustee by email, inviting
them to setup the election parameters. Upon receiving the
credential, each trustee authenticates himself to the server
and executes the election parameters setup process (cf. Sec-
tion 5.2, below). Once all the trustees jointly setup the

election parameters, the EA triggers the server to send an
invitation email (with the voter ID, vid(cid:96) ∈ G2 and a freshly
generated random 128-bit credential s(cid:96)) to each voter V(cid:96),
where vid(cid:96) is a random group element in G2 generated by
the election server.

Cast. After the election starts, each voter V(cid:96) uses
(vidi, s(cid:96)) to authenticate itself to the election server and then
prepares and casts its vote using the voter supporting de-
vice VSD. The voters’ ballots are prepared locally in the
VSD and are posted to the election server, which will be
displayed on the BB. (cf. Section 5.3, below).

Tally. When the election is ﬁnished, the server com-
putes the tally ciphertexts by multiplying all the submit-
ted valid ciphertexts for each option on the BB, denoted
as (E1, . . . , Em)5. The voters’ coins are used to produce
the Sigma protocol challenge (cf. Section 5.4, below). The
trustees are then invited to complete their Sigma protocols
and decrypt the tally ciphertexts (cf. Section 5.5, below).
Note that each trustee should send the above message to the
election server (EA) using a secure channel such as HTTPS.
The election server checks the validity of all the Σ proofs and
NIZK proofs upon receiving such a message from a trustee,
and rejects it in case some of the proofs are invalid. The
election server only posts all the received trustees’ messages
to the BB after all the trustees have successfully completed
their Tally protocols.
Result. After all the trustees sends their partial decryp-
tion of the tally ciphertexts, the election server, for j ∈ [m],
√
computes τj = Dlogg1
i=1 Dj,(i)). Here the discrete
n steps, given
logarithm can be solved in approximately
the knowledge that τj ∈ [0, n], as there are maximum n pos-
sible votes for each option in total. It then posts the ﬁnal
tally τ = (τ1, . . . , τm) on the BB and informs all the voters
by email.

(Ej,2/(cid:81)k

Verify. After the Setup protocol, each trustee Ti is able
to check the consistency between the posted election param-
eters on the BB and its private state sti. After the election,
each voter V(cid:96) is able to fetch the election transcript, info from
BB and verify the integrity of the election with its receipt
rec(cid:96). More speciﬁcally, the voter checks the following:

• There is a unique ballot blt(cid:96) indexed by vid(cid:96) in the

election transcript info.

• There is no duplicated ciphertexts and NIZK proofs

across the entire election transcript info.

• All the NIZK proofs in each ballot blt(cid:96) uses vid(cid:96) as a

part of the second layer CRS’s.

• All the Sigma and NIZK proofs are valid.

The voter checks if the data in blt(cid:96) hashes to the rec(cid:96) and

the validity of all the Sigma proofs and NIZK proofs.
5.2 Generating Election Parameters

The election parameters generation does not require the
interaction between the trustees, and each trustee Ti only
needs to interact with the election server. The protocol con-
sists of two rounds. In particular, each trustee Ti performs
the following:
• Round 1:

5Note that, during this step, any invalid ciphertexts and
duplicated ciphertexts are removed.

3591 and u0,(i) = gβi
1 ;

– Pick random αi, βi ← Zq;
– Set h1,(i) = gαi
– Post/Append h1,(i), u0,(i) to the public election
parameters on the BB together with the following
Σ commitment messages:
∗ Σdlog
∗ Σdlog

(cid:8)(αi) : h1,(i) = gαi
(cid:110)

1
(βi) : u0,(i) = gβi
1

(cid:9)
(cid:111)

(1)

(1)

• The election server computes and posts on BB:

– pk := (g1, h1 :=(cid:81)k
– u0 :=(cid:81)k

i=1 u0,(i)

i=1 h1,(i))

• Round 2:

1 and u2,(i) = uγi
0 ;

– Pick random γi ← Zq;
– Set u1,(i) = gγi
– Post/Append u1,(i), u2,(i) to the public election
parameters on the BB together with the following
Σ commitment messages:
∗ Σddh

(cid:8)(γi) : u1,(i) = gγi

1 ∧ u2,(i) = uγi

(cid:9)

(1)

0

Upon termination, each trustee Ti keep its working tape as
its private state sti. After all the trustees have participated
in Setup, the election sever computes and posts the election
parameters on the BB:

• crsm := (σbp, ck := (u0, ((cid:81)k

i=1 u1,(i), g1 ·(cid:81)k

i=1 u2,(i))))

5.3 Casting a Vote

The VSD fetches election parameters from the BB and
works as a “voting booth”. The VSD shows the election
question and a list of options to the voter V(cid:96). The voter V(cid:96)
can select x ∈ [mmin, mmax] options and let the VSD prepare
the ballots. Let (cid:126)e = (e1, e2 . . . , em) be the characteristic
vector corresponding to the voter’s selection, where ej = 1
if the option optj is selected and ej = 0 otherwise. The VSD
prepares two versions of the ballot that encrypts the same
option selection as follows
• For j ∈ {1, 2, . . . , m}:

– Pick random rj,(a), rj,(b) ← Zp;
– Compute c(a)
j,2 ) = (g

j = (c(a)
j = (c(b)

j,1 , c(a)
j,1, c(b)

j,2) = (g

– Compute c(b)

• Compute two receipts:

1 h

rj,(a)
1
rj,(b)
1

, gej
, gej

1 h

rj,(a)
1
rj,(b)
1

);

);

– rec(a) = hash(eid, vid(cid:96), ‘A’, c(a)
– rec(b) = hash(eid, vid(cid:96), ‘B’, c(b)

1 , . . . , c(a)
1 , . . . , c(b)
m );

m );

The VSD presents to the voter the receipts for both A
and B versions of the ballot, rec(a) and rec(b); meanwhile,
it displays two big buttons labeled as ‘A’ and ‘B’ respec-
tively. The voter should keep the receipts and then ran-
domly choose one of the buttons to proceed. Suppose the
voter chooses ‘A’ (resp.
‘B’), the system opens the ver-
sion B (resp. A) of the ballot by revealing the random-
ness used to create all the ciphertexts in version B (resp.
A), r1,(b), . . . , rm,(b). The voter can export the data and
use any third-party auditing software to perform the check.
The VSD then computes the NIZK proofs for the version

A of the ballot. For j ∈ {1, 2, . . . , m}, the VSD computes
j ← NIZK{crsm; (ej, rj,(a)) : c(a)
j = Encpk(ej; rj,(a)) ∧ ej ∈
π(a)
{0, 1}}. Note that in above NIZK proofs, Prov0/1 uses the
It then sets c(a) = (cid:81)m
vid(cid:96) as the h2 in the description of Section 4.2 instead of
(cid:80)m
generating a fresh h2 = gα1
for crs(0) and crs(1) every time.
2
j=1 ej, and r(a) =
j=1 rj,(a), and computes π(a) ← NIZK{crsm; (e, r(a)) :
c(a) = Encpk(e; r(a)) ∧ e ∈ [mmin, mmax]}. The VSD posts
the ballot blt(cid:96) :=
to the

, e = (cid:80)m
(cid:111)

j=1 c(a)

vid(cid:96), ‘A’,

(cid:29)

(cid:28)

, π(a)

(cid:110)

, π(a)

j

c(a)
j

j

j∈[m]

BB.

The voter’s receipt is deﬁned as rec(cid:96) := (vid(cid:96), ‘A’, rec(a))
assuming version A of the ballot was selected during the
Cast protocol.
5.4 Producing the Sigma Protocols Challenge
After the election is ﬁnished, the voters’ coins are collected
to produce the Sigma protocol challenge. On the BB, every-
one can identify the version of each submitted ballot. We
interpret ‘A’ as 0, ‘B’ and 1, and if the voter did not submit
a ballot, his coin is ﬁxed as 0. Denote ρj as the voter Vj’s
coin and ρ = (ρ1, ρ2, . . . , ρn). As studied in [KZZ15], the
voters’ coins can be modeled an adaptive non-oblivious bit
ﬁxing source. Nevertheless, we still want to produce a single
challenge if only computationally bounded adversaries are
considered. Assume hash be a cryptographic collision resis-
tant hash function such that there is no known algorithm
can ﬁnd a collision with 22κ expected steps. We compute
the challenge ch ← hash(ρ) and claim that if H∞(ρ) ≥ κ
then H∞(hash(ρ)) ≥ κ by Theorem 4.

Theorem 4 Let X be an n-bit eﬃciently sampleable dis-
tribution with H∞(X) ≥ κ. Let hash : {0, 1}∗ (cid:55)→ {0, 1}λ
be a cryptographic hash function, where λ > 2κ is a security
parameter. If H∞(hash(X)) < κ then we have an explicit al-
gorithm that can ﬁnd a collision for hash within 22κ expected
number of steps.

Proof. First of all, when H∞(hash(X)) < H∞(X), there
must be a collision for hash among all x in X.
Since
H∞(hash(X)) < κ, there exists a hash image σ such that
Pr[hash(X) = σ] ≥ 2−κ. Moreover, it is obvious that σ
must be one of the images that has collisions. Consider the
algorithm A that repetitively samples x from X at random
and stores hash(x), trying to ﬁnd a collision. Given that
Pr[hash(X) = σ] ≥ 2−κ, the expected running time to ﬁnd
(cid:4)
a collision at the hash image σ is less than 22κ.
5.5 Finalizing the Election

Each trustee Ti fetches all the posted information from

BB and checks its consistency. After that, Ti does:

• Compute and send the following response messages to

the election server (EA):

(cid:8)(αi) : h1,(i) = gαi
(cid:110)
(cid:8)(γi) : u1,(i) = gγi

(βi) : u0,(i) = gβi
1

(cid:9)
(cid:111)
1 ∧ u2,(i) = uγi

0

1

(cid:9)

– Σdlog
(2)

– Σdlog
(2)

– Σddh
(2)

• For j ∈ {1, . . . , m}:

360– Compute and send to the the election server (EA)
j,1 together with

the partial decryption Dj,(i) = Eγi

NIZK(cid:8)crsm; (γi) : h1,(i) = gγi

(cid:9) .

1 ∧ Dj,(i) = Eγi

j,1

6. SECURITY
6.1 On Non-malleability of the NIZK Proofs
It is well-known that GS proofs are malleable with respect
to the same CRS. More speciﬁcally, given a GS proof, π, for
the statement x with respect to crs, anyone can re-randomize
the proof to produce a distinct proof π∗ for x respect to
crs. To prevent replay attacks, all the duplicated ciphertexts
shall be removed. However, the adversary can still copy and
re-randomize some honest voters’ ciphertexts as well as their
attached NIZK proofs if the same CRS is used among all the
voters. To address this issue, each voter is required to use a
distinct vid(cid:96) as a part of her second layer CRS’s.

Regarding privacy, recall we assume the election servers
(EA and BB) are honest; in particular, all the voter ID’s
{vid(cid:96)}(cid:96)∈[n] should be generated honestly such that no one
(vid(cid:96)) for all (cid:96) ∈ [n]
knows the discrete logarithms: Dlogg2
(vid(cid:96)2 ) for all (cid:96)1 (cid:54)= (cid:96)2 ∈ [n]. We now show that,
and Dlogvid(cid:96)1
given c = Encpk(b) for an unknown b ∈ {0, 1} together with
a proof π generated by the NIZK proof system Γ0/1 using
vid1, no PPT adversary can produce ˆc = Encpk(b) and ˆπ
that includes vid2 as a part of its second layer CRS’s with
non-negligible probability.

Recall that in the NIZK proof system Γ0/1 described in
Section 4.2 the prover generates crs(0) and crs(1) and shows,
via a DDH tuple NIZK proof, that the ciphertext c encrypts
0 using crs(0) and c encrypts 1 using crs(1). Since the DDH
tuple NIZK proof is perfectly sound, crs(b) and crs(1−b) must
be encryption of 1 and 0 respectively under the “public key”,
vid1. Similarly, due to perfect soundness, in ˆπ, ˆcrs(b) and
ˆcrs(1−b) must be encryption of 1 and 0 respectively under
the “public key”, vid2. Hence, the non-malleability problem
is reduced to Theorem 5.

Theorem 5 Given randomly chosen pk1, pk2 and c0 =
Encpk1 (m), c1 = Encpk1 (1 − m) for unknown m ∈ {0, 1},
for all PPT adversary A, the probability to produce ˆc0 =
Encpk2 (m), ˆc1 = Encpk2 (1− m) is negligible if the underlying
encryption scheme is IND-CPA secure.

Proof. The proof is done via reduction. Assume there
is a PPT adversary A who can produce ˆc0 = Encpk2 (m),
ˆc1 = Encpk2 (1 − m), we can contruct an adversary B who
can win the IND-CPA game of the underlying encryption
scheme. In the IND-CPA game, B is given pk1 and it sends
m0 = 0, m1 = 1 to the challenger C. B will receive c0 =
Encpk1 (mb) from C and B needs to guess b. B then computes
c1 = Encpk1 (1)/c0 and generates (sk2, pk2). After that she
sends c0, c1, pk1 and pk2 to A. Upon receiving ˆc0 and ˆc1
from A, B decrypts them; she sends b(cid:48) to C if ˆc0 and ˆc1
are indeed encryption of b(cid:48) and 1 − b(cid:48), otherwise, she sends
random b(cid:48) ← {0, 1} to C. Clearly, B wins when A wins. (cid:4)
6.2 Privacy

Our system achieves the simulation-based privacy deﬁned
in Section 3.2. Similarly to [KZZ15], we utilize complexity
leveraging. Speciﬁcally, we choose the security parameters

such that breaking the SXDH assumption of Genbp and ﬁnd-
ing a collision for hash is much harder than guessing the
challenge of the Sigma protocols.

Theorem 6 Assume there exists a constant c, 0 < c < 1
-time adversary A the advantage of
such that for any 2λc
breaking the SXDH assumption of Genbp is negl(λ). Let k =
λc(cid:48)
for any constant c(cid:48) < c. For any m, n, t = poly(λ), the
e-voting system Π described in Section 5 is k-private unless
there is an explicit algorithm that can ﬁnd a collision for
hash : {0, 1}∗ (cid:55)→ {0, 1}λ in 2λc

time.

k-priv ,S,Z (λ)

It sets u2,(w) = uγw

Proof. (Sketch) Given an adversary A, we construct
c≡ REALΠ,A,Z (λ).
a simulator S s.t.
IDEALFm,n,t
Without loss of generality, let Tw be the honest trustee. The
simulator S operates as follows.
At the beginning of the experiment, S selects all the vot-
ers’ coins (including both honest and corrupted voters) at
random, denoted as ρ = (ρ1, . . . , ρn) ∈ {0, 1}n. It then pro-
duces the challenge of the Sigma protocols using ρ. When
S receives (sid, init,O,V,T ,U) from F, it simulates EA in
the Setup protocol playing roles as EA and BB, and in-
teracting with all the corrupted trustees. Meanwhile, S
sends (sid, start, Ti) to F if the corrupted trustee Ti(cid:54)=w suc-
cessfully terminates the Setup protocol. Upon receiving
(sid, start, Tw) from F, the simulator S plays a role as Tw
and the EA to execute the Setup protocol with the follow-
ing modiﬁcations.
0 /g1 and simulates
a proof for the fake DDH relation of (g1, u0, u1,(w), u2,(w)).
Once all the trustees have completed their Setup, S gener-
vid(cid:96) is known. It then sends
ates vid(cid:96) such that d(cid:96) = Dlogg2
credentials to all the voters.
S then plays roles as EA and BB in the Cast protocol.
Upon receiving (sid, cast, V(cid:96)) from F for an honest V(cid:96), S exe-
cutes a Cast protocol on behalf of V(cid:96) with a random U(cid:96) ∈ U .
After all the voters cast their ballots, S plays the role of the
EA interacting with the corrupted trustees in the Tally pro-
Importantly, upon receiving (sid, proceed, Tw) from
tocol.
F, S sends suitably long messages to EA to fake the Tally
interaction for Tw. Due to the secure channel between Tw
and the EA, the adversary cannot tell Tw’s Tally protocol
is fake.
After all the corrupted trustees ﬁnish the Tally protocol,
S does not post their tally messages to the BB; instead, it
stores the set of the transcripts of all the Sigma protocols
and rewinds the state of the experiment to the Cast protocol
of the last honest voter, VL. In the second run, S executes
the Cast protocol for VL again but this time it chooses a
diﬀerent ballot version to submit. Namely, S ﬂips the voter’s
coin of VL. S then completes the rest of the protocol in the
second run until all the corrupted trustees ﬁnish the Tally
protocol. If there is no collision for hash, the challenge of
the Σ protocols must be distinct from that of the ﬁrst run
(otherwise we obtain a collision ﬁnding algorithm for hash).
Hence, S obtains another set of the transcripts of all the Σ
protocols with a diﬀerent challenge. Subsequently, S utilizes
the knowledge extractor to extract all the witnesses αi, βi, γi
i=1 γi. Note that now
the master CRS crsm is an encryption of 0 and thus it is a
perfectly simulatable CRS and γ is the trapdoor.
After that, S rewinds the state of the experiment to the
beginning of the Cast protocol and starts a third run. In
the Cast protocol, S uses the pre-generated coin ρ(cid:96) for each

for all i (cid:54)= w. S then computes γ =(cid:80)k

361(cid:80)

j,1

i(cid:54)=w αi

1 · E

j,(w) = Ej,2/(gτj

(cid:96) (cid:54)∈ U
honest voter V(cid:96). In addition, it encrypts an invalid U∗
and simulates the NIZK proofs using the trapdoor γ. In case
the corrupted voters’ coins do not match the pre-generated
(guessed) coins, S resets back to the beginning of the exper-
iment and starts over.
S repeats the above procedure until it has three runs of
the execution and the voters’ coins of the third run exe-
cution is guessed correctly. The expected running time to
make this happen is 2k · poly(λ). Subsequently, for each cor-
rupted voter V(cid:96), S uses d(cid:96) to decrypt all the second layer
CRS’s in its ballot blt(cid:96) on the BB, and thus determine U(cid:96).
If U(cid:96) (cid:54)∈ U , S abort. Otherwise, S sends (sid, cast, V(cid:96),U(cid:96))
to F. After sending all the corrupted voters’ option selec-
tions, S sends (sid, tally) to F on behalf of the EA. S then
sends (sid, proceed, Ti) to F if the corrupted trustee Ti(cid:54)=w
successfully terminates the Tally protocol. Upon receiving
the election result τ := (τ1, . . . , τm) from F, for j ∈ [m], S
computes D∗
) and simulates the
NIZK corresponding proofs. S then posts D∗
j,(w) to the BB.
We ﬁrst show that the probability that the above simula-
tor S aborts is negligible. When the extracted U(cid:96) (cid:54)∈ U for
some corrupted voter V(cid:96), the adversary A must managed
to either break the soundness of the underlying NIZK proof
system or ‘copy’ one of the honest voter’s ciphertexts by re-
randomizing them. According to Theorem 2, 3 and 5, either
events happen with negligible probability.
Suppose S does not abort, we now show that if the lifted
ElGamal is IND-CPA secure, then the protocol view cre-
ated by S is indistinguishable from the real execution. Note
that IND-CPA security of the ElGamal implies that SXDH
assumption holds. Given an adversary A who can distin-
guish the protocol view simulated by S, we can construct
an adversary B who can break the IND-CPA game. Indeed,
in the reduction, when B receives the public key, we will
post it as hi,(w) in the Setup protocol, simulating the Dlog
Sigma protocol. B then sends m0 = 0, m1 = 1 to the IND-
CPA challenger. When receiving a ciphertext c = (c1, c2), B
can transfer the ciphertext under public key h1,(w) to be a
ciphertext under the public key h1 and use it in the honest
voters’ ballots. The transformation: c(cid:48) = (c1, c2 · g
i(cid:54)=w αi
).
Clearly, c and c(cid:48) encrypts the same message under diﬀerent
public keys. If the adversary A can distinguish the honest
voters’ ballots, then the adversary B distinguish the IND-
CPA challenge with running time 2k · poly(λ) < 2λc
(cid:4)

(cid:80)

1

.

Remark. As in [KZZ15], we use complexity leveraging to
argue privacy which means k < λ. But for any desired k we
can always choose a suitable security parameter λ such that
the system is k-private. In most real world elections (e.g.,
national elections) privacy is only guaranteed between hun-
dreds or a few thousands voters that belong to a precinct.
If one wants to achieve privacy nation-wide as well, it is still
possible to use our scheme eﬃciently with the following mod-
iﬁcation: the trustees, each one individually, will perform a
Sigma OR proof that either their published parameter is
properly generated or that they know a preimage of a one-
way hash function of the coins of the voters (this should be
done using a Lapidot-Shamir like proof since the statement
is not determined fully before the ﬁrst move of the proto-
col). In the privacy proof the simulator can use complexity
leveraging to ﬁnd such preimage in time independent of the
number of corrupted voters and thus complete the simula-
tion in time proportional to breaking the one-way function.

6.3 E2E Veriﬁability

For simplicity, our analysis is for 1-out-of-m type voting,
and our analysis can be easily extended to x-out-of-m cases.

Theorem 7 The e-voting system described in Section 5
achieves E2E veriﬁability against all PPT adversaries with
error (1/2)d + (1/2)θ unless there is an explicit algorithm
that can ﬁnd a collision for hash : {0, 1}∗ (cid:55)→ {0, 1}λ in 22θ
time, where θ is the lower bound of the number of honest
successful voters, d is the tally deviation that the adversary
wants to achieve.

Proof. (Sketch) We emphasize that in the E2E veriﬁ-
ability proof, only BB is assumed to be honest. The rest
components of the election server are controlled by the ad-
versary. Hence, the voter ID, vid(cid:96), may not necessarily be
unique, and the adversary is allowed to change the content
on the BB arbitrarily before the Tally protocol starts. Nev-
ertheless, we can assume all the Sigma protocols and the
NIZK proofs on the BB are valid if there is at least one
honest voter that performs veriﬁcation. We ﬁrst construct
a vote extractor E for our system as follows.
Construction of the vote extractor. E takes input as
the election transcript, info and a set of receipts {rec(cid:96)}V(cid:96)∈ ˜V .
If Result(info) = ⊥, then E outputs ⊥. Otherwise, for all
the corrupted voters V(cid:96) ∈ V \ ˜V, E extracts U(cid:96) by exhaustive
search over the ElGamal ciphertexts in the ballot blt(cid:96). It
then outputs (cid:104)U(cid:96)(cid:105)V(cid:96)∈V\ ˜V .
Based on the above vote extractor, we now prove the E2E
veriﬁability of our scheme. Assume an adversary A that
e2e-ver (1λ, n, m, t). Namely, A breaks E2E
A,E,d,θ
wins the game G
veriﬁability by allowing at least θ honest successful voters
and achieving tally deviation d. Let E be the event that
there exists one tallied ciphertext that encrypts e∗ (cid:54)∈ U . By
Theorems 1 and 2, all the NIZK proofs are perfectly sound.
Hence, the adversary needs to cheat on at least one Sigma
protocol to make event E occur. Since the voters’ coins have
min entropy θ, by Theorem 4, the Sigma protocols challenge
hash(ρ) should have the same entropy, θ; otherwise, we have
found an explicit algorithm that ﬁnds the collision of hash
with 22θ time. Hence, each Sigma protocol has soundness
error at least (1/2)θ. Therefore,

Pr[G

e2e-ver (1λ, n, m, t) = 1 | E] ≤ (1/2)θ.
A,E,d,θ

(1)

Assume that E does not occur. In this case, the deviation
from the intended result that A achieves, derives only by
miscounting the honest votes. This may be achieved by A
in two diﬀerent possible ways:

Modiﬁcation attacks. Modify one of the versions of the
honest voters’ ballots when it was produced on the VSD.
If the voter chooses to submit the modiﬁed version, then
achieved deviation is 1.
Clash attacks. Assign the same vid to q honest voters so
that the adversary can inject q − 1 ballots. All the q voters
verify the same ballot on the BB and hence miss the in-
jected votes that produce the tally deviation. The deviation
achieved by this attack is q − 1.

Recall that each honest voter should select one of the two
versions of the ballot at random, and the other version will
be opened for auditing. Hence, the success rate of x devi-
ation via the modiﬁcation attack is (1/2)x. With regard to
the clash attacks, similarly, it is easy to see that the success
probability to clash y honest voters without being detected

362is (1/2)y−1 (all y honest voters choose the same version to
vote). Overall, the upper bound of the success probability
of A when E does not occur is

Pr[G

e2e-ver (1λ, n, m, t) = 1 | ¬E] ≤ (1/2)d.
A,E,d,θ

By Eq. (1), (2), we have the overall probability

Pr[G

e2e-ver (1λ, n, m, t) = 1] ≤ (1/2)d + (1/2)θ .
A,E,d,θ

(2)

(cid:4)

7.

IMPLEMENTATION

Our prototype is written in Django framework. We also
adopt Twitter Bootstrap [Boo15] for better user interface.
All the cryptographic elements are Base64 encoded and in-
terchanged in JSON format. We use SHA3 to implement
hash and adopt CryptoJS [Mot15] as its JavaScript imple-
mentation. We use Type F pairing groups [BN06] as the
asymmetric bilinear group candidates.
Its JavaScript im-
plementation employs SJCL [SJC15] for basic big number
arithmetic. On top of SJCL, we ported the Type F pair-
ing arithmetic of jPBC [DI11] to JavaScript. Unlike DE-
MOS [KZZ15], the election setup step of DEMOS-2 is very
eﬃcient and independent of m, n. This is because all the
votes are encrypted at the client side during the cast phase
on demand. The benchmark results in Tbl. 1 shows the time
that a VSD (client) takes to encrypt a vote and produce a
ballot (using Javascript). The benchmark is produced on a
Mac Mini with 2.5 GHz Intel Core i5, 4GB RAM. For in-
stance, when m = 2, it takes 0.4s to prepare both A and B
versions of the ballot; afterwards, it takes 2.2s to complete
the NIZK proofs.

Table 1: Client-side Vote Encryption Eﬃciency

m Security Version A&B NIZK proof Ballot Size
2
10

2239.2 ms
8210.4 ms

399.4 ms
1913.5 ms

2.5 KB
9.3 KB

80 bits
80 bits

8. REFERENCES
[Adi08]

Ben Adida. Helios: Web-based open-audit
voting. In USENIX, 2008.

[BCP+11] David Bernhard, V´eronique Cortier, Olivier
Pereira, Ben Smyth, and Bogdan Warinschi.
Adapting helios for provable ballot privacy. In
ESORICS, 2011.
Josh Benaloh. Simple veriﬁable elections.
USENIX, 2006.

[Ben06]

[BFM88] Manuel Blum, Paul Feldman, and Silvio Micali.

[BN06]

[Boo15]

Non-interactive zero-knowledge and its
applications. In STOC, 1988.
Paulo S. L. M. Barreto and Michael Naehrig.
Pairing-friendly elliptic curves of prime order.
In SAC, pages 319–331. Springer, 2006.
Bootstrap. Twitter Bootstrap.
http://getbootstrap.com/, 2015.

[BPW12] David Bernhard, Olivier Pereira, and Bogdan

Warinschi. How not to prove yourself: Pitfalls of
the Fiat-Shamir heuristic and applications to
Helios. In ASIACRYPT, 2012.

[BR93] Mihir Bellare and Phillip Rogaway. Random

[Can98]

[Can01]

oracles are practical: A paradigm for designing
eﬃcient protocols. In CCS, pages 62–73, 1993.
Ran Canetti. Security and composition of
multi-party cryptographic protocols. J. of
CRYPTOLOGY, 13:2000, 1998.
Ran Canetti. Universally composable security:
A new paradigm for cryptographic protocols. In
FOCS, pages 136–145, 2001.

[CDS94] Ronald Cramer, Ivan Damg˚ard, and Berry

Schoenmakers. Proofs of partial knowledge and
simpliﬁed design of witness hiding protocols. In
CRYPTO, 1994.

[Cha90] David Chaum. Zero-knowledge undeniable

[DI11]

[GOS06]

[GS08]

[JCJ02]

signatures (extended abstract). In
EUROCRYPT, pages 458–464. Springer, 1990.
Angelo De Caro and Vincenzo Iovino. jpbc:
Java pairing based cryptography. In ISCC 2011,
pages 850–855, 2011.
Jens Groth, Rafail Ostrovsky, and Amit Sahai.
Non-interactive zaps and new techniques for
nizk. In CRYPTO, pages 97–111, 2006.
Jens Groth and Amit Sahai. Eﬃcient
non-interactive proof systems for bilinear
groups. In EUROCRYPT, 2008.
Ari Juels, Dario Catalano, and Markus
Jakobsson. Coercion-resistant electronic
elections. ePrint, 2002:165, 2002.

[KTV10] Ralf K¨usters, Tomasz Truderung, and Andreas

Vogt. Accountability: Deﬁnition and
relationship to veriﬁability. ePrint, 2010:236,
2010.

[KTV11] Ralf K¨usters, Tomasz Truderung, and Andreas

Vogt. Veriﬁability, privacy, and
coercion-resistance: New insights from a case
study. In S & P, pages 538–553, 2011.

[LS90]

[Sch89]

[R`af15]

[Mot15]

[KZZ15] Aggelos Kiayias, Thomas Zacharias, and
Bingsheng Zhang. End-to-end veriﬁable
elections in the standard model. In
EUROCRYPT, pages 468–498. Springer, 2015.
Dror Lapidot and Adi Shamir. Publicly
veriﬁable non-interactive zero-knowledge proofs.
In CRYPTO. Springer, 1990.
Jeﬀ Mott. Crypto-JS.
http://code.google.com/p/crypto-js/, 2015.
Carla R`afols. Stretching groth-sahai: NIZK
proofs of partial satisﬁability. In TCC, 2015.
[RG15] Mark Ryan and Gurchetan S. Grewal. Online
voting is convenient, but if the results aren’t
veriﬁable it’s not worth the risk. The
Conversation, https://theconversation.com/
online-voting-is-convenient-but-if-the
-results-arent-verifiable-its-not-
worth-the-risk-41277, May 2015.
Claus-Peter Schnorr. Eﬃcient identiﬁcation and
signatures for smart cards. In EUROCRYPT,
volume 434, pages 688–689. Springer, 1989.
SJCL. Stanford Javascript Crypto Library.
http://crypto.stanford.edu/sjcl/, 2015.

[SJC15]

363