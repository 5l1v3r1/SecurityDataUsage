System-level Non-interference for Constant-time

Cryptography

Gilles Barthe

IMDEA Software Institute,

Spain

Gustavo Betarte

Universidad de la República,

Uruguay

Juan Diego Campo

Universidad de la República,

Uruguay

Carlos Luna

Universidad de la República,

Uruguay

David Pichardie

ENS Rennes/IRISA/INRIA,

France

ABSTRACT
Cache-based attacks are a class of side-channel attacks that
are particularly eﬀective in virtualized or cloud-based en-
vironments, where they have been used to recover secret
keys from cryptographic implementations. One common ap-
proach to thwart cache-based attacks is to use constant-time
implementations, i.e. which do not branch on secrets and do
not perform memory accesses that depend on secrets. How-
ever, there is no rigorous proof that constant-time implemen-
tations are protected against concurrent cache-attacks in
virtualization platforms with shared cache; moreover, many
prominent implementations are not constant-time. An alter-
native approach is to rely on system-level mechanisms. One
recent such mechanism is stealth memory, which provisions
a small amount of private cache for programs to carry po-
tentially leaking computations securely. Stealth memory in-
duces a weak form of constant-time, called S-constant-time,
which encompasses some widely used cryptographic imple-
mentations. However, there is no rigorous analysis of stealth
memory and S-constant-time, and no tool support for check-
ing if applications are S-constant-time.

We propose a new information-ﬂow analysis that checks
if an x86 application executes in constant-time, or in S-
constant-time. Moreover, we prove that constant-time (resp.
S-constant-time) programs do not leak conﬁdential infor-
mation through the cache to other operating systems exe-
cuting concurrently on virtualization platforms (resp. plat-
forms supporting stealth memory). The soundness proofs
are based on new theorems of independent interest, includ-
ing isolation theorems for virtualization platforms (resp. plat-
forms supporting stealth memory), and proofs that constant-
time implementations (resp. S-constant-time implementa-
tions) are non-interfering with respect to a strict information
ﬂow policy which disallows that control ﬂow and memory ac-
cesses depend on secrets. We formalize our results using the
Coq proof assistant and we demonstrate the eﬀectiveness of

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660283.

our analyses on cryptographic implementations, including
PolarSSL AES, DES and RC4, SHA256 and Salsa20.

Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and protection

Keywords
Information ﬂow control; non-interference; cache-based at-
tacks; constant-time cryptography; stealth memory; Coq

1.

INTRODUCTION

Cache-based attacks are side-channel attacks in which a
malicious party is able to obtain conﬁdential data through
observing cache accesses of programs. They are particularly
eﬀective in cloud-based environments, where hardware sup-
port is virtualized and shared among tenants. In such set-
tings, a malicious tenant can manage that an operating sys-
tem under its control co-resides with the operating system
which executes the program that the attacker targets. This
allows the attacker to share the cache with its victim and to
make ﬁne-grained observations about its own cache hits and
misses; using this knowledge, the attacker can then success-
fully retrieve conﬁdential data of the program. Cache-based
attacks are widely applicable, but are specially devastating
against cryptographic implementations that form the secu-
rity backbone of many Internet protocols (e.g. TLS) or
wireless protocols (e.g. WPA2). Known targets of cache-
based attacks include widely used implementations of AES,
DES, ECDSA and RC4.

Simple approaches for protecting oneself against cache-
based attacks are ﬂushing the cache on every context switch
and disabling the cache mechanism for critical computa-
tions. The ﬁrst one was formally analyzed in [11]. In addi-
tion, both approaches suﬀer from severe performance penal-
ties [17, 48]. Another approach is to build implementations
that do not leak information through the cache. One com-
mon strategy is to make implementations constant-time 1,

1The terminology is inherited from cryptography, where it is
generally used for source level programs that do not branch
on secrets and do not perform array accesses with indices
that depend on secrets. Because the property intends to
characterize the behavior of program executions on concrete
architectures, rather than in abstract operational models, we
focus on low-level languages, and on a variant of constant-
time expressed in terms of addresses (which consist of base
addresses plus oﬀsets) instead of arrays.

1267i.e. do not branch on secrets and do not perform memory
accesses that which depend on secrets. There exist constant-
time implementations of many cryptographic algorithms,
including AES, DES, RC4, SHA256, TEA, and Salsa20,
and even RSA, as well as general techniques for turning
implementations of cryptographic algorithms constant-time.
However, and quite astonishingly, there is no rigorous proof
that constant-time algorithms are protected against cache-
based attacks when executed concurrently on virtualization
platforms with shared cache. Moreover, many cryptographic
implementations such as PolarSSL AES, DES, and RC4 make
array accesses that depend on secret keys and are not constant-
time.

A diﬀerent more permissive approach is to allow imple-
mentations that are not constant-time, but to deploy system-
level countermeasures that prevent an attacker from drawing
useful observations from the cache. Some of these mecha-
nisms are transparent to applications, but sacriﬁce perfor-
mance: instances include ﬂushing the cache at each context
switch [48] or randomizing its layout [50]. Other mechanisms
are not transparent, and must be used correctly, either via
APIs or via compilers that enforce their correct usage. One
lightweight such mechanism is stealth memory [29, 34]; in
contrast to many of its competitors, stealth memory can be
implemented in software, does not require any speciﬁc hard-
ware and does not incur a signiﬁcant performance overhead.
Informally, stealth memory enforces a locking mechanism
on a small set of cache lines, called stealth cache lines, saves
them into (protected) memory and restores them upon con-
text switches, thereby ensuring that entries stored in stealth
cache lines are never evicted, and do not leak information.
From an abstract perspective, memory accesses to stealth
addresses, i.e addresses that map to stealth cache lines, be-
come “hidden” and have no visible eﬀect. Thus, applica-
tions can perform memory accesses that depend on secrets
without revealing conﬁdential information, provided these
accesses are done on stealth addresses. This induces a re-
laxation of constant-time, which we call S-constant-time: an
implementation is S-constant-time if it does not branch on
secrets and only memory accesses to stealth addresses may
depend on secrets. Although early work on stealth memory
suggests that several prominent cryptographic implementa-
tions meet the requirements of S-constant-time, this class
has not been considered formally before, and in particular,
there is no rigorous security analysis of S-constant-time al-
gorithms, and no mechanism to ensure that assembly code
makes a correct usage of stealth addresses.

Our contributions. We undertake the ﬁrst rigorous study
of constant-time and S-constant-time implementations. We
prove that such implementations are protected against cache-
based attacks in virtualized platforms where their support-
ing operating system executes concurrently with other, po-
tentially malicious, operating systems. Moreover, we pro-
vide support for deploying constant-time or S-constant time
applications, in the form of type-based enforcement mech-
anisms on x86 implementations; the mechanisms are inte-
grated into CompCert, a realistic veriﬁed compiler for C [38].
Finally, we experimentally validate our approach on a set of
prominent cryptographic implementations. To achieve these
goals, we make the following contributions:

1. We deﬁne an analysis for checking if x86 applications
are constant-time. Our analysis is based on a type system

that simultaneously tracks aliasing and information ﬂow.
For convenience, we package our analysis as a certifying com-
piler for CompCert. Our certifying compiler takes as input
a C program whose conﬁdential data is tagged with an an-
notation High, and transforms the program into annotated
x86 assembly code, which can be checked for constant-time.
2. We provide the ﬁrst formal proof that constant-time
programs are protected against cache-based attacks in vir-
tualization platforms. The proof contemplates a very strong
threat model with a malicious operating system that controls
the scheduler, executes concurrently with the operating sys-
tem on which the victim application runs, and can observe
how the shape of the cache evolves throughout execution.

3. As a ﬁrst key step in the proof, we prove that constant-
time programs is non-interfering with respect to an informa-
tion ﬂow policy which mandates that the control ﬂow and
the sequence of memory accesses during program execution
do not depend on secrets. The policy is captured using an
operational semantics of x86 programs where transitions are
labelled with their read and write eﬀects.

4. As a second key step in the proof, we prove isolation
between operating systems in virtualization platforms. The
proof is based on a model of virtualization that accounts
for virtual addresses, physical and machine addresses, mem-
ory mappings, page tables, TLBs, and cache, and provides
an operational semantics for a representative set of actions,
including reads and writes, allocation and deallocation, con-
text and mode switching, and hypercalls. The isolation the-
orem states that an adversary cannot distinguish between
two execution traces of the platform in which the victim op-
erating system performs two sequences of actions that have
the same visible eﬀects.

5. We extend our analysis and formal proofs to S-constant-
time. As a signiﬁcant contribution of the extension, we ob-
tain the ﬁrst rigorous security analysis of stealth memory.

6. We formalize our results in the Coq proof assistant
(over 50,000 lines of Coq). The formalization is based on
the ﬁrst formal model of stealth memory. The model is a
signiﬁcant development in itself (over 10,000 lines of Coq)
and is of independent interest.

7. We successfully evaluate the eﬀectiveness of our frame-
work on several cryptographic implementations, including
AES, DES, and RC4 from the PolarSSL library, and SHA256,
Salsa20. Figure 1 provides a selection of results.

Full version. Additional details are available in the full
version of the paper [12].
2. SETTING

Our ﬁrst step is to deﬁne static analyses for enforcing
constant-time (and variants) on x86 programs. Our anal-
ysis is built on top of CompCert [38], a formally veriﬁed,
optimizing C compiler that generates reasonably eﬃcient
assembly code for x86 platforms (as well as PowerPC and
ARM). In addition to being a signiﬁcant achievement on
its own, CompCert provides an excellent platform for devel-
oping veriﬁed static analyses. We take speciﬁc advantage
of two features of CompCert:
i. its memory model, which
achieves a subtle and eﬀective compromise between exposure
to machine-level representation of memory and tractability
of formal proofs, and is ideal for reasoning about properties
that relate to sequences of memory accesses; ii. its sophisti-
cated compilation chain, which involves over 15 passes, and

1268Example LoC CT SCT Stealth cache (KB)

Salsa20
SHA256

TEA
AES

Blowﬁsh

DES
RC4
Snow

1077 (cid:88)
(cid:88)
419
(cid:88)
70
744
279
836
164
757

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

4
4
2

0.25

6

A check in the CT or SCT column respectively indicates
whether programs are constant-time or S-constant-time. For
the latter, the last column gives the amount of stealth cache
required to run the application. All constant-time applica-
tions are also S-constant-time with 0KB stealth cache.

Figure 1: Selected experimental results

about 10 intermediate languages, which are judiciously cho-
sen to provide compact representations on which program
analyses can be veriﬁed.

Our goal is to implement static analyses for checking whether

programs perform conditional jumps or memory accesses
that depend on secrets, and to derive strong semantical
guarantees for the class of programs accepted by one of our
analyses. In order to obtain meaningful results, it is impor-
tant that our analyses are performed on intermediate repre-
sentations towards the end of the compilation chain, rather
than source C programs; indeed, some compilation passes
in the compiler middle-end (typically at RTL level) may
typically modify and reorder memory accesses and hence
a constant-time C program could well be transformed into
a non constant-time x86 program, or vice-versa. Therefore,
we settle on deﬁning our analysis on one of the ﬁnal in-
termediate forms. A natural representation for reasoning
about sequences of memory accesses is Mach, the last-but-
ﬁnal intermediate language in the compilation chain. The
Mach language is used after passes that may introduce new
memory accesses (such as register allocation, branch tunnel-
ing and layout of the activation records for procedure calls),
and immediately before generation of assembly code. Hence
the sequence of memory accesses at Mach and assembly lev-
els coincide. Moreover, Mach has a compact syntax, which
is important to reduce proof eﬀort. On the other hand, the
Mach language does not enjoy a control ﬂow graph represen-
tation, which is a drawback for performing static analyses.
We therefore adopt a minor variant of Mach, which we call
MachIR, that retains the same instruction set as Mach but
makes explicit the successor(s) of each instruction. MachIR
is an idoneous representation for building veriﬁed static anal-
yses about sequences of memory accesses of programs.

Syntax. A MachIR program p is represented by a (par-
tial) map of program nodes to instructions, i.e. as an el-
ement of N (cid:42) I. Each instruction carries its successor(s)
node(s) explicitly. The most basic instructions manipulate
registers and perform conditional and unconditional jumps:
op(op, (cid:126)r , r , n) (register r is assigned the result of the oper-
ation op on arguments (cid:126)r ; next node is n), goto(n) (uncon-
ditional jump to node n) and cond(c, (cid:126)r , nthen , nelse ) (condi-
tional jump; next node is nthen or nelse depending on the
boolean value that is obtained by evaluating condition c on

n
r
S

N (cid:51)
R (cid:51)
S (cid:51)
A (cid:51) addr ::=| based(S)

|
|

stack(δ)
indexed

O (cid:51) op ::=| addrof(addr )

| move
| arith(a)

CFG nodes
register names
global variable names

based addressing
stack position
indexed addressing

symbol address
register move
arithmetic operation

I (cid:51) instr ::=| op(op, (cid:126)r , r , n)

|
loadς (addr , (cid:126)r , r , n)
|
storeς (addr , (cid:126)r , r , n)
| goto(n)
| cond(c, (cid:126)r , nthen , nelse )

register operation
memory load
memory store
static jump
conditional static jump

Figure 2: Instruction set

arguments (cid:126)r ). Memory is manipulated trough two oper-
loadς (addr , (cid:126)r , r , n) (register r receives the content
ations:
of the memory at an address that is computed with ad-
dressing mode addr and arguments (cid:126)r ; next node is n) and
storeς (addr , (cid:126)r , r , n) (the content of the register r is stored
in memory at an address that is computed with addressing
mode addr and arguments (cid:126)r ; next node is n). ς describes
the type of memory chunk that is accessed (of size 1, 2 or
4 bytes). Addressing based(S) (resp. stack(δ)) directly de-
notes the address of a global symbol (resp. of the stack
memory block). Pointer arithmetic is performed through
addressing mode indexed. Additional instructions are used
to access the activation record of a procedure call, and to
perform the call. Figure 2 gives an excerpt of the language
instruction set.

Semantics. Values are either numeric values Vnum(i) or
pointer values Vptr(b, δ) with b a memory block name and
δ a block oﬀset. We let &SP denote the memory block that
stores the stack. A state (n, ρ, µ) is composed of the current
CFG node n, the register bank ρ ∈ R → Val and a CompCert
memory µ ∈ Mem.

The operational semantics is modelled with judgments:

(cid:48)

s (cid:44) a−→ s

The semantics is implicitly parameterized by a program p.
Informally, the judgment above says that executing the pro-
gram p with state s leads to a state s(cid:48), and has visible eﬀect
a, where a is either a read eﬀect read x (with x an address),
or a write eﬀect write x, or the null eﬀect ∅. Note that ef-
fects model the addresses that are read and written, but not
their value. Figure 3 presents selected rules of the seman-
tics. Note that an instruction like store4(stack(δ), [], r , n(cid:48))
will assign the four stack positions δ, δ + 1, δ + 2 and δ + 3.

3. A TYPE SYSTEM FOR CONSTANT-TIME
This section introduces a type-based information ﬂow anal-
ysis that checks whether a MachIR program is constant-
time, i.e.
its control ﬂow and its sequence of memory ac-

1269(cid:48)

(n, ρ, µ) (cid:44)

p[n] = op(op, (cid:126)r , r , n
∅−→ (n

, ρ[r (cid:55)→(cid:74)op(cid:75)(ρ, (cid:126)r )], µ)

)

(cid:48)

(cid:48)

p[n] = loadς (addr , (cid:126)r , r , n

)

(cid:74)addr(cid:75)(ρ, (cid:126)r ) = vaddr

(n, ρ, µ) (cid:44)

−−−−−−−−→ (n
read vaddr

µ[vaddr]ς = v
, ρ[r (cid:55)→ v], µ)

(cid:48)

(cid:48)

(cid:74)addr(cid:75)(ρ, (cid:126)r ) = vaddr

p[n] = storeς (addr , (cid:126)r , r , n

)

store(µ, ς, vaddr, ρ(r )) = µ

(cid:48)

(n, ρ, µ) (cid:44)

−−−−−−−−−→ (n
write vaddr

(cid:48)

(cid:48)
, ρ, µ

)

Figure 3: Mach IR semantics (excerpts)

cesses do not depend on secrets. To track how dependencies
evolve during execution, the information ﬂow analysis must
be able to predict the set of memory accesses that each in-
struction will perform at runtime. However, instructions
such as storeς (indexed, [r1; r2], r , n(cid:48)) do not carry this infor-
mation. The standard solution to recover this information is
to let the information ﬂow analysis use the results of another
static analysis that performs these computations. There are
several possible choices that achieve diﬀerent trade-oﬀs be-
tween expressiveness, precision, and simplicity. We opt for
a conventional points-to [7] analysis. A similar analysis has
already been formalized for the CompCert toolchain [43], but
it targets a diﬀerent language (RTL) and makes a diﬀerent
trade-oﬀ between eﬃciency and precision; we use our own
formalization here.

Alias (points-to) type system. The deﬁnition of the alias
type system is given in [12]. For the purpose of understand-
ing the rest of the paper, it is suﬃcient to know that the
type system computes statically the points-to information
PointsTo(n, addr , (cid:126)r ) at every node n for a memory access
with an addressing mode addr and arguments (cid:126)r . Hence,
if node n contains an instruction loadς (addr , (cid:126)r , r , n(cid:48)) or an
instruction storeς (addr , (cid:126)r , r , n(cid:48)), we have a prediction, at
compile time, of the targeted memory address. In this con-
text, a so-called points-to information is one of the follow-
i. Symb(S), which represents pointer values Vptr(b, δ)
ing:
such that b is equal to the memory address &S of the global
variable S; ii. Stack(δ), which represents the pointer value
Vptr(&SP, δ).
For example, if an instruction storeς (indexed, [r1; r2], r , n(cid:48))
is performed at node n when r1 contains Vptr(&S, 8) and
r2 contains the integer 16, the points-to static analysis may
safely predict PointsTo(n, addr , (cid:126)r ) = Symb(S), because the
accessed pointer is Vptr(&S, 24).

Information ﬂow type system. Next, we deﬁne an infor-
mation ﬂow type system for constant-time. As usual, we
consider a lattice of security levels L = {Low, High} with
Low (cid:118) High. Initially, the user declares a set X 0
h ⊆ S of high
variables.
Programs are assigned types (Xh, T ), where Xh ∈ S → L
is a global type, and T ∈ N → (N + R) → L is a mapping
from program nodes to local types. Xh is a ﬂow-insensitive
global type which assigns a security level Xh(S) for every
global variable S ∈ S. T is a ﬂow-sensitive local type which
assigns for every oﬀset δ ∈ N the security level T [n](δ) of the
stack cell at address Vptr(&SP, δ) and node n, and for every

PointsTo(n, addr , (cid:126)r ) = Symb(S)

(cid:48)

p(n) = op(op, (cid:126)r , r , n
)
Xh (cid:96) n : τ ⇒ τ [r (cid:55)→ τ ((cid:126)r )]
(cid:48)
p(n) = loadς (addr , (cid:126)r , r , n
)
τ ((cid:126)r ) = Low
Xh (cid:96) n : τ ⇒ τ [r (cid:55)→ Xh(S)]
(cid:48)
p(n) = loadς (addr , (cid:126)r , r , n
)

PointsTo(n, addr , (cid:126)r ) = Stack(δ)

Xh (cid:96) n : τ ⇒ τ [r (cid:55)→ τ (δ) (cid:116) ··· (cid:116) τ (δ + ς − 1)]

(cid:48)

p(n) = storeς (addr , (cid:126)r , r , n

)
PointsTo(n, addr , (cid:126)r ) = Symb(S)
τ (r ) (cid:118) Xh(S)
τ ((cid:126)r ) = Low

Xh (cid:96) n : τ ⇒ τ

p(n) = storeς (addr , (cid:126)r , r , n

(cid:48)

)

PointsTo(n, addr , (cid:126)r ) = Stack(δ)

Xh (cid:96) n : τ ⇒ τ [δ (cid:55)→ τ (r ), . . . , δ + ς − 1 (cid:55)→ τ (r )]

(cid:48)
p(n) = goto(n
)
Xh (cid:96) n : τ ⇒ τ

Figure 4: Information ﬂow rules for constant-time

register r ∈ R its security level T [n](r ) at node n. Formally,
the type system manipulates judgments of the form:

Xh (cid:96) n : τ1 ⇒ τ2

r∈(cid:126)r τ (r).

level of r with the supremum of the security levels of (cid:126)r .

are given in Figure 4; we note τ ((cid:126)r ) for(cid:70)

where Xh is a global type, n is a node, and τ1 and τ2 are
τ1, τ2 ∈ (N + R) → L. The type system
local types, i.e.
enforces a set of constraints on X 0
h, Xh and T . Typing rules
The rule for op(op, (cid:126)r , r , n(cid:48)) simply updates the security
There are two rules for loadς (addr , (cid:126)r , r , n(cid:48)). The ﬁrst one
considers the case where the value is loaded from a global
variable S.
In this case, the typing rule requires that all
τ ((cid:126)r ) = Low, as we want to forbid
registers are low, i.e.
memory accesses that depend on a secret. The security level
of the register r is updated with the security level Xh(S)
of the variable. The second rule considers the case where
the value is loaded from a stack position at oﬀset δ.
In
this case, our type system conservatively requires that the
memory access is constant (and statically predicted by the
alias type system). In this case, no information is leaked.
Note that the security level of the register r is set to the
maximum of τ (δ), . . . , τ (δ + ς − 1). Indeed, the security level
of τ (δ) models the level of the 8-bits value at position δ; if
the load is performed with a memory chunk of size strictly
bigger than 1, several 8-bits value will be accessed. Our type
system takes care of this subtlety.

The two typing rules for store are similar to the rules for
load. If the store is performed on a global variable, we again
require τ ((cid:126)r ) = Low to make sure the dereferenced pointer
does not leak secrets. The constraint τ (r ) ⊆ Xh(S) propa-
gates the security level of the stored value. For a store on
a stack oﬀset, we again make sure to consider enough stack
oﬀsets by considering the memory chunk of the instruction.

Definition 1

(Constant-time programs).
A program p is constant-time with respect to a set of vari-
h (cid:96) p, if there exists (Xh, T ) such that
ables X 0

h, written X 0

1270for every S ∈ X 0
its successors n(cid:48), there exists τ such that

h, Xh(S) = High and for all nodes n and all

Xh (cid:96) n : T (n) ⇒ τ ∧ τ (cid:118) T (n

(cid:48)

)

where (cid:118) is the natural lifting of (cid:118) from L to types.

We automatically infer Xh and T using Kildall’s algorithm [33].

4. SOUNDNESS OF TYPE SYSTEM

We capture the soundness of the static analyses with re-
spect to two distinct non-interference properties. The ﬁrst
property is expressed relative to the operational semantics
of MachIR (or equivalently x86) programs, and capture a
passive and non-concurrent attacker. This property is simi-
lar to non-interference results as they arise in the literature
on language-based security, and serves as a key step towards
the second property. The latter is cast relative to the oper-
ational semantics of a virtualization platform, and captures
an active and adaptive adversary. For the sake of readabil-
ity, this section deﬁnes the security policies, relates them
informally to existing threat models, and provides informal
soundness statements. Formalization details are deferred to
Section 6 and to the appendices.
4.1 Language-level security

Our ﬁrst soundness result establishes a non-interference
property based on the semantics of MachIR programs. We
assume given for every pair (Xh, τ ) consisting of a global
type and a local type an equivalence relation ∼Xh,τ on states.
Informally, two states s and s(cid:48) are equivalent if they have the
same program counter, and their bank registers and memory
mappings coincide on their low part. Given a typing deriva-
tion for p with witness (Xh, T ), equivalence can be extended
to traces2 of p as follows:

a0−→ s1 (cid:44)
a1−→ s2 (cid:44)
a2−→ s3 . . .
θ = s0 (cid:44)
a(cid:48)
a(cid:48)
a(cid:48)
2−→ s(cid:48)
1−→ s(cid:48)
0−→ s(cid:48)
θ(cid:48) = s(cid:48)
3 . . .
2 (cid:44)
1 (cid:44)
0 (cid:44)

are equivalent, written θ ∼Xh,T θ(cid:48), iﬀ i = 0 . . . ai = a(cid:48)
si ∼Xh,T (pci) s(cid:48)
si and s(cid:48)

i and
i, where pci denotes the program counters of

i (which in particular must coincide).

We say that a program p veriﬁes LL non-interference
(p), iﬀ for every two traces θ and

w.r.t. X 0
θ(cid:48) obtained by executing p from initial states s and s(cid:48):

h, written LLNIX0

h

s ∼Xh,T (pc0) s

(cid:48)

=⇒ θ ∼Xh,T θ

(cid:48)

Note that the deﬁnition is parameterized by (Xh, T ).

LL non-interference accurately captures the intended goal
of constant-time: indeed, it ensures that programs have the
same control ﬂow and perform the same sequence of memory
accesses for every pair of executions starting from equivalent
initial states.

Proposition 2

(Language-level security).

h (cid:96) p, then p is LL non-

If a program p is typable, i.e. X 0
interfering, i.e. LLNIX0

(p).

h

Proposition 2 states that constant-time programs verify LL
non-interference with respect to the set of secrets X 0
It
h.

2We allow inﬁnite traces. Later, we introduce partial traces,
which are necessarily ﬁnite. Moreover, we assume that s0
and s(cid:48)
0 are initial states, i.e. their program counter is set to
a distinguished entry point pc0.

proves security against a weak, passive attacker, which can
observe the sequence of memory accesses and program coun-
ters during program execution, but cannot observe the pro-
gram memory, or interleave the program’s execution with
execution of code of its choice. Although we do not es-
tablish a connection formally, this model is closely related
to a system-level attacker model, called the non-concurrent
attacker model. In this model, the attacker is a malicious
operating system oa that co-resides with the operating sys-
tem ov on which the victim program executes. The attacker
initially performs some computations, for instance to set the
cache in a state of his choice. Then, the hypervisor performs
a context switch and makes the victim operating system ac-
tive, so that the victim program executes uninterruptedly.
Upon termination of the victim program execution, the hy-
pervisor performs a context switch; the attacker becomes
active again, and tries to guess from its accumulated obser-
vations the secret material, e.g.
the secret cryptographic
keys, manipulated by the victim program.

4.2 System-level security

Our second soundness theorem establishes a non-interference

property for a much stronger model, called the concurrent
attacker model. The setting of this attacker model is sim-
ilar to the non-concurrent attacker model, and considers a
virtualization platform with a malicious operating system
oa and the victim operating system ov on which a victim
program p executes. However, this model assumes that the
attacker is both active and adapative. More explicitly, oa
and ov execute concurrently under a scheduler controlled by
oa, which decides at each step to execute a sequence of steps
of its choice, to force resolution of a pending hypercall, or
to switch context in order to give control to the victim ov.
Furthermore, the attacker oa can observe ﬁnely the struc-
ture of the cache during execution, but cannot read into
the memory of ov, or read in the cache the values of en-
tries belonging to ov. At each step, the attacker oa can use
its previous observations to decide how to proceed. This
model signiﬁcantly generalizes the non-concurrent attacker
model captured by language-level security and in particular
captures the class of access-driven attacks, in which the at-
tacker makes ﬁne-grained observations about the sequence
of cache hits and misses.

Formally, we model the attacker model on top of an oper-
ational semantics of the virtualization plaform. The seman-
tics is built on top of a rich memory model that accounts
for virtual, physical, and machine addresses, memory map-
pings, page tables, TLBs (translation lookaside buﬀers), and
VIPT (virtually indexed physically tagged) cache. Formally,
the semantics is modelled as a labelled transition system:

(cid:48)

t (cid:44) b−→ t

where t, t(cid:48) range over states and b is an action. Informally, a
labelled transition as above indicates that the execution of
the action b by o in an initial state t leads to a new state t(cid:48).
Figure 9 provides a representative set of actions considered,
including reads and writes, extending or restricting memory
mappings, (un)registering memory pages, context and mode
switching, and hypercalls. Each action b has an eﬀect eﬀ(b);
see Figure 9 for examples of eﬀects. As in the language-
level setting, the visible eﬀects of reads and writes record
the addresses that are read and written, but not their value.

1271Then, we model the attacker as a function A that takes as
input a partial trace and returns either a tag v if the attacker
lets the victim operating system perform the next step of
execution, or an action of its choice that it will execute in the
next step. Since the choice of the attacker can only depend
on its view of the system, we deﬁne an equivalence relation
∼ on partial traces, and require that A is compatible with ∼,
i.e. A(θ) = A(θ(cid:48)) for every partial traces θ and θ(cid:48) such that
θ ∼ θ(cid:48). Equivalence between partial traces is deﬁned from
equivalence ∼ on states (itself deﬁned formally in Section 6):

bn−1−−−→ tn
b2−→ . . . (cid:44)
b1−→ t2 (cid:44)
b0−→ t1 (cid:44)
θ = t0 (cid:44)
b(cid:48)
b(cid:48)
b(cid:48)
b(cid:48)
n(cid:48)−1−−−−→ t(cid:48)
1−→ t(cid:48)
0−→ t(cid:48)
θ(cid:48) = t(cid:48)
2−→ . . . (cid:44)
n(cid:48)
2 (cid:44)
1 (cid:44)
0 (cid:44)

are equivalent, written θ ∼ θ(cid:48), iﬀ n = n(cid:48), and for i = 0 . . . n−
1, ti ∼ t(cid:48)
i, and if the active OS of ti is ov then eﬀ(bi) = eﬀ(b(cid:48)
i)
else if the active OS of ti is oa then bi = b(cid:48)
i.
Given an attacker A and a victim program p, one can de-
ﬁne the concurrent execution (A (cid:107) p)[t] of A and p with ini-
tial state t; informally, (A (cid:107) p)[t] is the system trace that
interleaves execution of p by ov and adversarially-chosen
code by oa according to the adversarially-chosen schedul-
ing policy—both captured in the deﬁnition of A. Formally,
(A (cid:107) p)[t] is deﬁned recursively: given a partial trace θ for
the concurrent execution, one computes A(θ) to determine
whether the next action to be executed is the attacker action
A(θ), in case A(θ) (cid:54)= v, or the next step in the execution of
p, in case A(θ) = v.
h, we
deﬁne an equivalence relation ∼X0
on system states; the
relation is implicitly parameterized by a mapping of MachIR
(or equivalently x86) states to platform states. We say that
a program p veriﬁes SL non-interference w.r.t. an initial
set of high variables X 0
h, written SLNIXh (p), iﬀ for every
attacker A and initial states t and t(cid:48):

Given a program p and a set of initial secrets X 0

h

[t ∼X0

h

(cid:48) ∧ t ∼ t
(cid:48)

] =⇒ (A (cid:107) p)[t] ∼ (A (cid:107) p)[t

(cid:48)

t

]

Proposition 3

(System-level security).

h (cid:96) p, then p is SL non-

If If a program p is typable, i.e. X 0
interfering, i.e. SLNIX0

(p).

h

Proposition 3 states that constant-time programs verify SL
non-interference with respect to the set of secrets X 0
It
h.
proves security against a strong, active attacker, which can
interleave the program’s execution with execution of code of
its choice.

5. EXTENSIONS TO S-CONSTANT-TIME
We now outline an extension of the results of the previ-
Informally
ous section that accounts for stealth memory.
stealth memory provides a distinguished set of stealth ad-
dresses such that reading or writing from these addresses has
no visible eﬀect. We reﬂect this property of stealth memory
by relaxing the type system to allow secret-dependent mem-
ory accesses on stealth addresses. The modiﬁed typing rules
now involve a set Xs of addresses that must be mapped to
stealth memory. The main typing rules are now given in
Figure 5. Note that there is no requirement that stealth
addresses are high; in practice, stealth addresses often store
public tables.

Definition 4

constant-time with respect to a set of variables X 0

(S-constant-time). A program p is S-
h and a set

PointsTo(n, addr , (cid:126)r ) = Symb(S)

p(n) = loadς (addr , (cid:126)r , r , n
)
τ ((cid:126)r ) = High =⇒ S ∈ Xs

Xs, Xh (cid:96) n : τ ⇒ τ [r (cid:55)→ τ ((cid:126)r ) (cid:116) Xh(S)]

(cid:48)

(cid:48)

p(n) = storeς (addr , (cid:126)r , r , n

PointsTo(n, addr , (cid:126)r ) = Symb(S)

)

τ ((cid:126)r ) = High =⇒ S ∈ Xs

τ ((cid:126)r ) (cid:116) τ (r ) (cid:118) Xh(S)

Xs, Xh (cid:96) n : τ ⇒ τ

Figure 5: Information ﬂow rules for S-constant-time

(cid:74)addr(cid:75)(ρ, (cid:126)r ) = vaddr

p[n] = loadς (addr , (cid:126)r , r , n

vaddr /∈ Xs

(cid:48)

)

p[n] = storeς (addr , (cid:126)r , r , n

)

(n, ρ, µ) (cid:44)
vaddr /∈ Xs

−−−−−−−−→ (n
read vaddr
(cid:48)

µ[vaddr]ς = v

(cid:48)

, ρ[r (cid:55)→ v], µ)

(cid:74)addr(cid:75)(ρ, (cid:126)r ) = vaddr

(cid:48)

(n, ρ, µ) (cid:44)

store(µ, ς, vaddr, ρ(r )) = µ
−−−−−−−−−→ (n
write vaddr
vaddr ∈ Xs

(cid:48)
, ρ, µ
)

)

(cid:48)

(cid:48)

p[n] = loadς (addr , (cid:126)r , r , n

(cid:74)addr(cid:75)(ρ, (cid:126)r ) = vaddr

∅−→ (n
(cid:48)
p[n] = storeς (addr , (cid:126)r , r , n

(n, ρ, µ) (cid:44)

vaddr ∈ Xs

µ[vaddr]ς = v

(cid:48)

, ρ[r (cid:55)→ v], µ)
)

(cid:74)addr(cid:75)(ρ, (cid:126)r ) = vaddr

(cid:48)

store(µ, ς, vaddr, ρ(r )) = µ

(n, ρ, µ) (cid:44)

∅−→ (n

(cid:48)

(cid:48)
, ρ, µ

)

Figure 6: Modiﬁed IR semantics (excerpts)

h (cid:96) p, if there exists
of stealth addresses Xs, written Xs, X 0
(Xh, T ) such that for every S ∈ X 0
h, Xh(S) = High and for
all nodes n and all its successors n(cid:48), there exists τ such that

Xs, Xh (cid:96) n : T (n) ⇒ τ ∧ τ (cid:118) T (n

(cid:48)

)

where (cid:118) is the natural lifting of (cid:118) from L to to types.

We automatically infer Xs, Xh and T using Kildall’s algo-
rithm.

LL non-interference is extended to the setting of stealth
memory simply by considering a modiﬁed labelled opera-
tional semantics (see Figure 6) where accessing variables in
Xs has no visible eﬀect; the notion of state equivalence re-
mains unmodiﬁed. Below we let LLNIXs,X0
denote the re-
sulting policy.

h

Proposition 5

(Language-level security).

If Xs, X 0

h (cid:96) p then LLNIXs,X0

(p).

h

Given a program p, a set of initial secrets X 0
h, and a set of
stealth addresses Xs, we deﬁne an equivalence relation ∼X0
h
on system states; the relation is implicitly parameterized by
a mapping of MachIR (or equivalently x86) states to plat-
form states that map elements of Xs to stealth addresses.
We say that a program p veriﬁes SL non-interference w.r.t.
an initial set of high variables X 0
h and a set of stealth ad-
dresses Xs, written SLNIXs,X0
(p), iﬀ for every attacker A
and initial states t and t(cid:48):

h

[t ∼X0

h

(cid:48) ∧ t ∼ t

(cid:48)

] =⇒ (A (cid:107) p)[t] ∼ (A (cid:107) p)[t

(cid:48)

t

]

1272Proposition 6

(System-level security).

If Xs, X 0

h (cid:96) p then SLNIXs,X0

(p).

h

6. FORMALIZATION

In this section, we outline the formalization of the proof of
system-level security for S-constant-time. We ﬁrst describe
our model of virtualization; then we state an isolation theo-
rem; ﬁnally, we sketch how SL non-interference follows.

Simpliﬁcations. We make several simpliﬁcations. The most
relevant ones are listed next:
i. we take an abstract view of
page tables as mappings; ii. we abstract away implementa-
tion details such as encoding and size of values, and assume
given an abstract type Value of values with a distinguished
element ⊥ to denote undeﬁned values; iii. we consider a sin-
iv. we do not model registers. These
gle stealth address;
simpliﬁcations do not impact the security analysis.

Policies. Our model and henceforth results are parame-
terized by a write policy and a replacement policy for the
cache. They can be instantiated respectively to write back
and write through, and to all typical replacement policies,
such as LRU, pseudo-LRU or LFU.

Memory model. States (SLST) are modelled as 6-tuples
that respectively store data about operating systems and
about the active operating system, the memory, the hyper-
visor mapping, the cache and the TLB (translation lookaside
buﬀer); the formal deﬁnition appears in Figure 7.

There are three levels of address spaces: virtual addresses,
which are handled by guest operating systems (OSs) and
processes, physical addresses, a software abstraction used
to provide the illusion of hardware memory to each guest
OS and machine addresses, which refer to actual hardware
memory. Some virtual and machine addresses are marked
as stealth.

The ﬁrst component of a state records for each OS, drawn
from a set OSId of OS identiﬁers:
i. a physical address
ii. its pending hyper-
pointing to its current page table;
call. Hypercalls are priviledged functionalities exported by
the hypervisor to the guest OSs; there is at most one pending
hypercall per OS.

The second component of a state stores the current active
operating system (ActiveOS) together with its activity mode.
The active OS is either running or waiting for a hypercall
to be resolved.

The third component of the state stores the platform mem-
ory (Memory). The memory is modelled as a function from
machine addresses to memory pages; contrary to separation
kernels, pages are allocated on demand. Each page contains:
.i an owner (PageOwner); .ii a ﬂag indicating whether the
page can be cached or not3; .iii a content (PageContent).
A page owner is either the hypervisor or a guest OS; pages
may not have owners. The page content is either a read-
able/writable value or an OS page table. Page tables are
used by guest OSs for mapping the virtual addresses used
by running applications to machine addresses. Neither ap-
plications nor guest OSs have permission to read or write

3To properly deal with the problems posed by aliasing in
VIPT caches, pages mapped by two diﬀerent virtual ad-
dresses are ﬂagged as non-cacheable.

page tables; these actions can only be performed by the hy-
pervisor.

The fourth component of the state stores the hypervisor
mapping (HyperMap). This mapping is used to translate
physical page addresses to machine page addresses and is
under control of the hypervisor, which can allocate and deal-
locate machine memory.

The ﬁfth component of the state stores a Virtually In-
dexed Physically Tagged (VIPT) data cache (Cache). The
cache is used to speed up data fetch and store, and con-
sists of a collection of data blocks or cache lines that are ac-
cessed by cache indices. The cache consists of:
i. a bounded
map4 from pairs of virtual and machine addresses to mem-
ory pages, ii. a history (used by the replacement policy) and,
iii. a static mapping from virtual addresses to cache indices.
Each entry is tagged with a machine address. This avoids
the need of ﬂushing the cache on every context switch. Since
caches are usually set associative, there are many virtual ad-
dresses that map to the same index. All data that is accessed
using the same index is called a cache line set. We select one
cache index and one particular virtual address (stealth va)
in its cache line set for stealth use. All other virtual ad-
dresses in that cache line set are reserved and cannot be
used either by the guest operating systems or the hypervi-
sor. It is relatively straightforward to extend the deﬁnitions
to a set of stealth addresses.

The ﬁnal component of the state stores the Translation
Lookaside Buﬀer (TLB), which is used to improve virtual ad-
dress translation speed. The TLB is modelled as a bounded
map from virtual to machine addresses. It is used in conjunc-
tion with the current page table of the active OS to speed
up translation of virtual to machine addresses. The TLB is
ﬂushed on context switch and updates are done simultane-
ously in the page table, so its management is simpler than
the cache (we do not need to record the TLB access history,
as it is not necessary to write back evicted TLB entries).

State invariants. The model formalizes a notion of valid
state that captures several well-formedness conditions, and
an exclusion property, which is crucial for proving isolation,
and ensures that stealth and non-stealth addresses cannot
be mapped to the same cache line set. Both properties are
preserved by execution; for exclusion, this is achieved by a
careful treatment of allocation in the operational semantics.

Platform semantics. Our formalization considers a repre-
sentative set of actions to read and write from memories,
manage memory mappings, request and perform priviledge
actions, and switch between operating systems and the hy-
pervisor; see Figure 9. Figure 10 presents the semantics
of two important actions: write (write value in virtual ad-
dress) and new_sm (extends the stealth memory of the active
OS with a new mapping).

We use some helper functions to manipulate the compo-
nents of the state. These functions are explained in the
description of the actions semantics. There is, for example,
a function cache add that is used to add entries in the cache.
It returns the new cache and an optional entry selected for
replacement. The function cache add is parameterized by
an abstract replacement policy that determines which ele-

4A bounded map is a ﬁnite map whose domain must have
size less than some ﬁxed positive constant.

1273Va, Pa, Ma
OSId
::= new | del | lswitch| pin | unpin | none
HC
::= Pa × HC
OSData
::= OSId → OSData
GuestOSs
:= running | waiting
OSActivity
::= OSId × OSActivity
ActiveOS
PageContent := RW (Value) | P T (Va → Ma) | none
:= Hyp | OS(OSId) | none
PageOwner
:= PageContent × PageOwner × Bool
Page
::= Ma → Page
Memory
::= OSId → Pa → Ma
HyperMap
:= Va × Ma (cid:55)→ Page
CacheData
:= Va → Index
CacheIndex
CacheHistory := Index → Hist
::= CacheData × CacheIndex × CacheHistory
Cache
::= Va (cid:55)→ Ma
TLB
::= GuestOSs × ActiveOS × HyperMap × Memory × Cache × TLB System level state

virtual, physical and machine address
OS identiﬁer
hyper calls
OS data
guest OSs
exec modes
active OS
page content
page owner
memory page
memory map
hypervisor map
cache data
cache index
cache history
VIPT cache
TLB

SLST

Figure 7: System level state

ments are evicted from a full cache, and guarantees that
the inertia property, as deﬁned in [34], holds for the cache:
when adding an entry to the cache in a virtual address va, if
an eviction occurs, the evicted address is in the same cache
line set as va.

Attacker model and state equivalence. We let the at-
tacker observe:
i. its current page table; ii. its pending
hypercalls; iii. the identity of the active operating system;
iv. its activity when active; v. its own readable/writable
memory pages; vi. the values of its own cache entries; vii. the
memory layout of the victim, as deﬁned by the page meta-
data (owner and cacheable status) of the victim memory
pages; viii. the layout of the non-stealth part of the cache;
ix. the cache history. The attacker cannot, however, directly
read, write, or observe page table or the hypervisor map-
pings (either its own or the victim). This is because these
mappings are maintained by the hypervisor, and guest OSs
have no access to them. Moreover, the attacker cannot ob-
serve the values held in the memory or cache entries of the
victim. This very strong adversary model captures the kind
of attacks we are interested in:
if two states diﬀer in one
of these observable components, the execution of an action
might replace an attacker entry in the cache, potentially
leading to a cache-based attack. On the other hand, we
prove that if an action is executed in two states that are
equivalent from the attacker’s view, the attacker cache en-
tries are equal in the resulting states.

Dynamic allocation is a known diﬃculty when reasoning
about state equivalence; in our setting, the diﬃculty man-
ifests itself in the deﬁnition of equivalence for memory and
hypervisor mappings. In an object-oriented setting, this dif-
ﬁculty is normally solved using partial bijections [9]. How-
ever, we model both memory allocation and deallocation via
the pin and unpin actions; unfortunately, the partial bijec-
tion approach breaks in this setting5 and we do not know
any formal proof of soundness of an information ﬂow type

Figure 8: Equivalence of hypervisor mappings

system for a language with allocation and deallocation. For-
tunately, we can deﬁne state equivalence without using par-
tial bijections; instead, we rely on the hypervisor mapping
physical addresses, which are the same in both executions.
Formally, state equivalence ∼ is deﬁned as the conjunc-
tion of four equivalence relations for OS information, cache
history, hypervisor mapping, and memory mapping. The
ﬁrst two relations are straightforward. We deﬁne equiva-
lence of hypervisor mappings below; equivalence of memory
is deﬁned similarly.

Definition 7

(Equivalence of hypervisor mappings).

Two states t and t(cid:48) have equivalent hypervisor mappings for
the attacker (t ∼hyp t(cid:48)) if for every physical address pa,
readable/writable page pg and machine address ma:

• if get page hyp(t, oa, pa) = (ma, pg), there exists ma(cid:48)

such that get page hyp(t(cid:48), oa, pa) = (ma(cid:48), pg);

• if get page hyp(t, ov, pa) = (ma, pg), and no page table
maps stealth va to ma, then there exists ma(cid:48) such that
get page hyp(t(cid:48), ov, pa) = (ma(cid:48), pg(cid:48)), where pg and pg(cid:48)
are equal except in their contents;

and reciprocally for t(cid:48).

Figure 8 provides a pictural representation of the equiva-
lence: we require that the attacker readable/writable pages
are the same for hyp and hyp(cid:48). Furthermore, the layout
of the non-stealth memory pages of the victim must be the
same (non-stealth pages should have the same owner, and
same cacheable ﬂag, but arbitrary value).

5The approach requires that the partial bijection grows dur-
ing execution. With deallocation, one would require that the

ﬁnal partial bijection is a superset of a subset of the original
one, which is vacuous.

pamama'pgif RWhyphyp'memmem'1274Unwinding lemmas. The equivalence relation ∼ is kept
invariant by the execution of a victim stealth action. Fur-
thermore, if the same attacker action or two victim actions
with the same eﬀect are executed in two equivalent states,
the resulting states are also equivalent. These results are
variations of standard unwinding lemmas [44]. In the sequel,
we write tov and toa respectively to denote states where ov
and oa are the active operating system.

1, and soa

Lemma 8
1 (cid:44) a−→ s(cid:48)
soa
Lemma 9
1 (cid:44) a−→ s(cid:48)
sov
then s(cid:48)

1, and sov
1 ∼ s(cid:48)
2.

2. If s1 ∼ s2 then s(cid:48)

(oa step-consistent unwinding). Assume
2 (cid:44) a−→ s(cid:48)
(ov step-consistent unwinding). Assume
2. If eﬀ(a) = eﬀ(a(cid:48)) and s1 ∼ s2,
2 (cid:44) a(cid:48)−→ s(cid:48)

1 ∼ s(cid:48)
2.

The proofs of these lemmas critically rely on the inertia
property of cache [34]: upon adding a virtual address to the
cache, the evicted virtual address, if any, is in the same cache
line set as the added one; and on the exclusion property: the
hypervisor ensures that guest operating systems can only
allocate virtual addresses that are not in the same cache
line set as the stealth virtual addresses.

Isolation. We ﬁrst deﬁne a relation to capture that two
traces perform the same sequence of actions from the at-
tacker’s view:

eﬀ(b1) = eﬀ(b2) Θ1 ≈ Θ2
b2−→ Θ2
tov
1 (cid:44)

b1−→ Θ1 ≈ tov
2 (cid:44)

Θ1 ≈ Θ2
1 (cid:44) b−→ Θ1 ≈ toa
toa

2 (cid:44) b−→ Θ2

We then deﬁne equivalence of traces:

tov
1 (cid:44)

b2−→ Θ2

Theorem 10

t1 ∼ t2 Θ1 ∼ Θ2
1 (cid:44) b−→ Θ1 ∼ toa
2 (cid:44) b−→ Θ2
toa

t1 ∼ t2 Θ1 ∼ Θ2
b1−→ Θ1 ∼ tov
2 (cid:44)
(OS isolation). Let Θ and Θ(cid:48) be execu-
tion traces such that Θ ≈ Θ(cid:48). If t1 ∼ t(cid:48)
1 the
ﬁrst states of traces Θ and Θ(cid:48) respectively, then Θ ∼ Θ(cid:48),
i.e. Θ and Θ(cid:48) are indistinguishable traces for the attacker
system oa.

1, with t1 and t(cid:48)

The proof of the theorem follows from the unwinding lemmas
by co-induction on the execution traces.

System-level security for S-constant-time. We deﬁne a
relation between MachIR instructions and system-level ac-
tions, such that an instruction is related to an action if they
have the same eﬀect. In order to do this we use a mapping
from language variables to virtual addresses that guarantees
that program variables marked as stealth by the type system
are mapped to stealth addresses in the platform. The rela-
tion between instructions and actions is naturally extended
to programs and traces. With this extended relation, we
deﬁne the concurrent execution of an attacker and a victim
program ((A (cid:107) p)[t]), and state Proposition 5. The proof
of this proposition is a direct consequence of Theorem 10,
and shows that S-constant-time programs are protected to
cache-based attacks in virtualization platforms.

7. EVALUATION

We have tested the eﬀectiveness of our type systems on
two sets of examples. The ﬁrst set of examples consists
of small programs that violate the constraints of constant-
time algorithms, e.g. branch on secret values. The second

set of examples consists of a representative set of crypto-
graphic implementations, including some that are vulnerable
to cache-based attacks on common platforms, and constant-
time algorithms that were speciﬁcally designed to avoid such
attacks. In all cases, we picked standard and publicly avail-
able implementations of the constructions, and after per-
forming very minor modiﬁcations of the code6, compiled
them using CompCert, and run our certiﬁed type system
on the MachIR (or equivalently x86) programs output by
the compiler. Figure 1 summarizes the list of examples an-
alyzed, and provides in each case the number of variables
marked as stealth, and the amount of stealth memory that
is required to execute the program securely.

AES. Advanced Encryption Standard (AES) is a symmet-
ric encryption algorithm that was selected by NIST in 2001
to replace DES. AES is now used very widely and is antic-
ipated to remain the prevailing blockcipher for the next 20
years. Although NIST claimed the selected algorithm re-
silient against side-channels, AES is a prominent example
of an algorithm in which the sequence of memory accesses
depend on the cryptographic key.

Most applications of AES require that encryption and de-
cryption be very eﬃcient; therefore, the AES speciﬁcation
advises using S-boxes and other lookup tables to bypass ex-
pensive operations, such as arithmetic in the ﬁeld GF(28).
As a result of using S-boxes, most AES implementations are
vulnerable to cache-based attacks, and fail to comply with
even the weakest security guarantees. In 2005, Bernstein [17]
reports on a simple timing attack which allows to recover
AES keys by exploiting the correlation between execution
time and cache behavior during computation. Shortly af-
terwards, Tromer, Osvik, and Shamir [48] report on several
cache-based attacks against AES, including an eﬀective at-
tack that does not require knowledge of the plaintexts or the
ciphertexts. Further improvements are reported by Bonneau
and Mironov [19], Acii¸cmez, Schindler and Ko¸c [2], and Can-
teaut, Lauradoux and Seznec [21]. More recently, Bangerter,
Gullasch and Krenn [30] report on a new cache-based attack
in which key recovery is performed in almost real-time, and
Ristenpart et al [42] show that cache-based attacks are not
conﬁned to closed systems, and can be realized in cloud ar-
chitectures based on virtualization.
In a diﬀerent line of
work, Kasper and Schwabe [31] report on a constant-time
implementation of AES.

As a testcase for our approach, we have applied our S-
constant-time type system to the PolarSSL implementation
of AES. Our type system is able to prove that 4kB of stealth
memory is suﬃcient to execute AES securely.

DES and BlowFish. Data Encryption Standard (DES) and
BlowFish are symmetric encryption algorithms that were
widely used until the advent of AES. They are designed un-
der the same principles as AES, and their implementation
also relies on S-boxes. Cache-based attacks against DES
and BlowFish are reported by Tsunoo et al [49] and Kelsey
et al
[32] respectively. We have applied our S-constant-
time type system to PolarSSL implementations of both al-
gorithms; again, our tool proves that only a small amount

6We have modiﬁed some examples to declare some arrays
as global. This is a consequence of the relative coarseness
of the alias analysis, and could be solved by formalizing a
more precise value analysis.

1275of stealth memory (resp. 2kB and 4kB) is required for the
programs to execute securely.

SNOW. Snow is a stream cipher used in standards such as
the 3GPP encryption algorithms. Its implementation relies
on table lookups for clocking its linear feedback shift register
(LFSR). Cache-based attacks against SNOW—and similar
LFSR-based ciphers—are reported by Leander, Zenner, and
Hawkes [37]. We have applied our S-constant-time type sys-
tem on an ECRYPT implementation of SNOW; our tool
proves that SNOW can be executed securely with 6kB of
stealth memory.

RC4. RC4 is a stream cipher introduced by Rivest in 1987
and used in cryptographic standards such as SSL and WPA.
It is based on a pseudo-random generator that performs ta-
ble lookups. Chardin, Fouque and Leresteux [22] present a
cache-based attack against RC4. Analyzing the PolarSSL
implementation of RC4 with our S-constant-time type sys-
tem proves that the program can execute securely with only
0.25kB of stealth memory.

TEA, Salsa20, SHA256. We have applied our constant-
time type system to some cryptographic algorithms that
carefully avoid performing table lookups with indices depen-
dent on secrets: Tiny Encryption Algorithm, a block cipher
designed by Needham and Wheeler; Salsa20, a stream ci-
pher designed by Bernstein, and SHA256. For the latter,
we consider the input to be secret, with the intention to
demonstrate that SHA256 is suitable to be used in pass-
word hashing. In all cases, our type system establishes that
the programs are secure without using stealth memory.

RSA. RSA is a widely used encryption algorithm. We have
applied our constant-time type system to implementations
of modular exponentiation. As expected, our type system
rejects implementations that branch on secrets and accepts
constant-time implementations.

8. RELATED WORK

Side-channel attacks in cryptography. In [36], Kocher
presents a pratical timing attack on RSA and suggests that
many vectors, including the cache, can be exploited to launch
side-channel attacks. Acii¸cmez and Schindler [1] demon-
strate that not only data cache, but also instruction cache
attacks are also eﬀective. Over the last decade, researchers
have developed abstract models of cryptography that cap-
ture side-channels, and developed constructions that are se-
cure in these models, see e.g. [28] for a survey.

Analysis tools for cache-based attacks. CtGrind7 is an
extension of ValGrind that can be used to check automati-
cally that an implementation is constant-time.

CacheAudit [26] is an abstract-interpretation based frame-
work for estimating the amount of leakage through the cache
in straightline x86 executables. CacheAudit has been used
to show that several applications do not leak information
through the cache and to compute an upper bound for the

7It was developed circa 2010 by Adam Langley and is avail-
able from https://github.com/agl/ctgrind/.

information leaked through the cache by AES. These guar-
antees hold for a single run of the program, i.e.
in the
non-concurrent attacker model. A follow-up [14] provides
an upper bound for the leakage of AES in an abtract ver-
sion of the concurrent attacker model; however, the bound
is only valid under strong restrictions, e.g. on scheduling.
Moreover, the results of [14] cannot be used to assert the se-
curity of constant-time programs against concurrent cache
attacks.

Language-based protection mechanisms. Many authors
have developed language-based protection methods against
side-channel attacks. Agat [3] deﬁnes an information ﬂow
type system that only accepts statements branching on se-
crets if the branches have the same pattern of memory ac-
cesses, and a type-directed transformation to make programs
typable. Molnar et al [40] deﬁne the program counter model,
which is equivalent to path non-interference, and give a pro-
gram transformation for making programs secure in this
model. Coppens et al [24] use selective if-conversion to re-
move high branches in programs. Zhang et al [51] develop
a contract-based approach to mitigate side-channels. En-
forcement of contracts on programs is performed using a
type system, whereas informal analyses are used to ensure
that the hardware comply with the contracts. They prove
soundness of their approach. However, they do not consider
the concurrent attacker model and they do not provide an
equivalent of system-level non-interference. Stefan et al [47]
also show how to eliminate cache-based timing attacks, but
their adversary model is diﬀerent.

More recently, Liu et al [39] deﬁne a type system that an
information ﬂow policy called memory-trace non-interference
in the setting of oblivious RAM. Their type system has sim-
ilar motivations has ours, but operates on source code and
deals with a diﬀerent attacker model.

OS veriﬁcation. OS veriﬁcation is an active ﬁeld of re-
search [46]. One recent breakthrough is the machine-checked
reﬁnement proof of an implementation of the seL4 microker-
nel [35]. Subsequent machine-checked developments prove
that seL4 enforces integrity, authority conﬁnement [45] and
intransitive non-interference [41]. The formalization does
not model cache nor side-channel attacks.

Dam et al [25] formally verify information ﬂow security
for a simple separation kernel for ARMv7. The veriﬁcation
is based on an extant model of ARM in HOL, and relates an
ideal model in which the security requirements hold by con-
struction with a real model that faithfully respects the sys-
tem behavior. Extending the approach to handle the cache
is left for further work.

Our model of virtualization is inspired from recent work [11]

which proves isolation in an idealized model of virtualization
with a shared cache. However their model is based on a vir-
tually indexed virtually tagged (VIVT) cache and assumes
that the cache implements a write through policy, and is
ﬂushed upon context switch; thanks to these assumptions,
the cache is always consistent with the memory of the cur-
rent operating system. This coincidence allows lifting with-
out much diﬃculty the isolation result of earlier work [10],
which does not consider the cache.
In particular, the un-
winding lemmas of [10] can be used mutatis mutandis, with-
out the need to be reproved in this extended setting.
In
comparison, our notion of state equivalence is signiﬁcantly

1276more involved, and as a result the proof of isolation is far
more complex.

Stealth memory. Stealth memory is introduced in [29] as
a ﬂexible system-level mechanism to protect against cache-
based attacks. This ﬂexibility of stealth memory is con-
ﬁrmed by a recent implementation and practical evalua-
tion [34]. The implementation, called StealthMem, is based
on Microsoft Hyper-V hypervisor, and is reasonably eﬃcient
(around 5% overhead for the SPEC 2006 benchmarks and
less than 5% for cryptographic algorithms). Both [29, 34]
lack a rigorous security analysis and language-based support
for applications.

Veriﬁed cryptographic implementations. There is a wide
range of methods to verify cryptographic implementations:
type-checking, see e.g. [18], deductive veriﬁcation, see e.g. [27],
code generation, see e.g. [20] and model extraction, see e.g. [4].
However, these works do not consider side-channels. Re-
cently, Almeida et al [5] extend the EasyCrypt framework [13]
to reason about the security of C-like implementations in
idealized models of leakage, such as the Program Counter
Model, and leverage CompCert to carry security guarantees
to executable code; moreover they, instrument CompCert
with a simple check on assembly programs to ensure that
a source C program that is secure in the program counter
model is compiled into an x86 program that is also secure
in this model.

Veriﬁed compilation and analyses. CompCert [38] is a
ﬂagship veriﬁed compiler that has been used and extended
in many ways; except for [5], these works are not concerned
with security. Type-preserving and verifying compilation are
alternatives that have been considered for security purposes;
e.g. Chen et al [23] and Barthe et al [16] develop type-
preserving compilers for information ﬂow.

Formal veriﬁcation of information ﬂow analyses is an ac-
tive area of research; e.g. Barthe et al [15] and Amtoft et
al [6] formally verify type-based and logic-based methods
for enforcing information ﬂow policies in programs. More
recently, Azevedo et al [8] formally verify a clean-slate de-
sign that enforces information ﬂow.

9. FINAL REMARKS

Constant-time cryptography is an oft advocated solution
against cache-based attacks. In this work, we have devel-
oped an automated analyzer for constant-time cryptography,
and given the ﬁrst formal proof that constant-time programs
are indeed protected against concurrent cache-based attacks.
Moreover, we have extended our analysis to the setting of
stealth memory; to this end, we have developed the ﬁrst for-
mal security analysis of stealth memory. Our results have
been formalized in the Coq proof assistant, and our analyses
have been validated experimentally on a representative set
of algorithms. One direction for future work is to extend our
analysis to constant-time programs which branch on secrets.

Acknowledgements. We are grateful to Mart´ın Abadi for
suggesting to look at stealth memory. The work of G. Be-
tarte, J. Campo and C. Luna was partially funded by project
CSIC/Convocatoria 2012, Proyectos I + D, VirtualCert -
Fase II, Uruguay.

10. REFERENCES
[1] O. Acii¸cmez and W. Schindler. A vulnerability in rsa

implementations due to instruction cache analysis and
its demonstration on openssl. In CT-RSA’08, volume
4964 of LNCS, pages 256–273. Springer, 2008.

[2] O. Acii¸cmez, W. Schindler, and ¸Cetin Kaya Ko¸c.
Cache based remote timing attack on the AES. In
CT-RSA 2007, volume 4377 of LNCS, pages 271–286.
Springer, 2007.

[3] J. Agat. Transforming out Timing Leaks. In

Proceedings POPL’00, pages 40–53. ACM, 2000.

[4] M. Aizatulin, A. D. Gordon, and J. J¨urjens.

Computational veriﬁcation of c protocol
implementations by symbolic execution. In CCS 2012,
pages 712–723. ACM, 2012.

[5] J. B. Almeida, M. Barbosa, G. Barthe, and

F. Dupressoir. Certiﬁed computer-aided cryptography:
eﬃcient provably secure machine code from high-level
implementations. In CCS 2013, 2013.

[6] T. Amtoft, J. Dodds, Z. Zhang, A. W. Appel,

L. Beringer, J. Hatcliﬀ, X. Ou, and A. Cousino. A
certiﬁcate infrastructure for machine-checked proofs of
conditional information ﬂow. In POST 2012, volume
7215 of LNCS, pages 369–389. Springer, 2012.

[7] L. O. Andersen. Program analysis and specialization
for the C programming language. PhD thesis, 1994.

[8] A. Azevedo de Amorim, N. Collins, A. DeHon,

D. Demange, C. Hri¸tcu, D. Pichardie, B. C. Pierce,
R. Pollack, and A. Tolmach. A veriﬁed
information-ﬂow architecture. In POPL 2014. ACM,
2014.

[9] A. Banerjee and D. Naumann. Stack-based access

control for secure information ﬂow. Journal of
Functional Programming, 15:131–177, Mar. 2005.
Special Issue on Language-Based Security.

[10] G. Barthe, G. Betarte, J. Campo, and C. Luna.

Formally verifying isolation and availability in an
idealized model of virtualization. In FM 2011, pages
231–245. Springer-Verlag, 2011.

[11] G. Barthe, G. Betarte, J. Campo, and C. Luna.

Cache-Leakage Resilient OS Isolation in an Idealized
Model of Virtualization. In CSF 2012, pages 186–197,
2012.

[12] G. Barthe, G. Betarte, J. D. Campo, C. Luna, and

D. Pichardie. System-level non-interference for
constant-time cryptography (full version), 2014.

[13] G. Barthe, B. Gr´egoire, S. Heraud, and

S. Zanella-B´eguelin. Computer-aided security proofs
for the working cryptographer. In CRYPTO 2011,
volume 6841 of LNCS, Heidelberg, 2011.

[14] G. Barthe, B. K¨opf, L. Mauborgne, and M. Ochoa.

Leakage resilience against concurrent cache attacks. In
POST, 2014.

[15] G. Barthe, D. Pichardie, and T. Rezk. A certiﬁed

lightweight non-interference java bytecode veriﬁer. In
ESOP 2007, pages 125–140, 2007.

[16] G. Barthe, T. Rezk, and D. A. Naumann. Deriving an

information ﬂow checker and certifying compiler for
java. In S&P 2006, pages 230–242. IEEE Computer
Society, 2006.

[17] D. J. Bernstein. Cache-timing attacks on AES, 2005.

Available from author’s webpage.

1277[18] K. Bhargavan, C. Fournet, and A. D. Gordon.

[35] G. Klein, K. Elphinstone, G. Heiser, J. Andronick,

Modular veriﬁcation of security protocol code by
typing. In POPL 2010. ACM, 2010.

[19] J. Bonneau and I. Mironov. Cache Collision Timing

Attacks Against AES. In CHES ’06, 2006.

[20] D. Cad´e and B. Blanchet. From

computationally-proved protocol speciﬁcations to
implementations. In ARES 2012, pages 65–74. IEEE
Computer Society, 2012.

[21] A. Canteaut, C. Lauradoux, and A. Seznec.

Understanding cache attacks. Rapport de recherche
RR-5881, INRIA, 2006.

[22] T. Chardin, P.-A. Fouque, and D. Leresteux. Cache
timing analysis of RC4. In ACNS 2011, volume 6715
of LNCS, pages 110–129, 2011.

[23] J. Chen, R. Chugh, and N. Swamy. Type-preserving

compilation of end-to-end veriﬁcation of security
enforcement. In PLDI 2010, pages 412–423. ACM,
2010.

[24] B. Coppens, I. Verbauwhede, K. D. Bosschere, and
B. D. Sutter. Practical mitigations for timing-based
side-channel attacks on modern x86 processors. In
S&P 2009, pages 45–60, 2009.

[25] M. Dam, R. Guanciale, N. Khakpour, H. Nemati, and

O. Schwarz. Formal veriﬁcation of information ﬂow
security for a simple ARM-based separation kernel. In
CCS 2013, pages 223–234, 2013.

[26] G. Doychev, D. Feld, B. K¨opf, L. Mauborgne, and

J. Reineke. Cacheaudit: A tool for the static analysis
of cache side channels. In Usenix Security 2013, 2013.

[27] F. Dupressoir, A. D. Gordon, J. J¨urjens, and D. A.
Naumann. Guiding a General-Purpose C Veriﬁer to
Prove Cryptographic Protocols. In CSF 2011, pages
3–17. IEEE Computer Society, 2011.

[28] S. Dziembowski and K. Pietrzak. Leakage-resilient

cryptography. In FOCS, pages 293–302. IEEE
Computer Society, 2008.

[29] U. Erlingsson and M. Abadi. Operating system

protection against side-channel attacks that exploit
memory latency. Technical Report MSR-TR-2007-117,
Microsoft Research, 2007.

[30] D. Gullasch, E. Bangerter, and S. Krenn. Cache games

- bringing access-based cache attacks on AES to
practice. In S&P 2011, pages 490–505, 2011.

[31] E. K¨asper and P. Schwabe. Faster and timing-attack
resistant aes-gcm. In C. Clavier and K. Gaj, editors,
CHES, volume 5747 of Lecture Notes in Computer
Science, pages 1–17. Springer, 2009.

[32] J. Kelsey, B. Schneier, D. Wagner, and C. Hall. Side

Channel Cryptanalysis of Product Ciphers. Journal of
Computer Security, 8(2–3):141–158, 2000.

[33] G. A. Kildall. A uniﬁed approach to global program
optimization. In Proceedings of the 1st annual ACM
SIGACT-SIGPLAN symposium on Principles of
programming languages, POPL ’73, pages 194–206,
New York, NY, USA, 1973. ACM.

[34] T. Kim, M. Peinado, and G. Mainar-Ruiz.

Stealthmem: system-level protection against
cache-based side channel attacks in the cloud. In
USENIX Security 2012, pages 11–11, Berkeley, CA,
USA, 2012. USENIX Association.

D. Cock, P. Derrin, D. Elkaduwe, K. Engelhardt,
R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and
S. Winwood. seL4: formal veriﬁcation of an OS kernel.
In SOSP 2009, pages 207–220. ACM, 2009.

[36] P. Kocher. Timing Attacks on Implementations of
Diﬃe-Hellman, RSA, DSS, and Other Systems. In
CRYPTO’96, volume 1109 of LNCS, pages 104–113.
Springer, 1996.

[37] G. Leander, E. Zenner, and P. Hawkes. Cache Timing

Analysis of LFSR-Based Stream Ciphers. In IMACC
2009, volume 5921 of LNCS, pages 433–445. Springer,
2009.

[38] X. Leroy. Formal certiﬁcation of a compiler back-end,
or: programming a compiler with a proof assistant. In
POPL 2006, pages 42–54. ACM, 2006.

[39] C. Liu, M. Hicks, and E. Shi. Memory trace oblivious
program execution. In CSF 2013, pages 51–65, 2013.

[40] D. Molnar, M. Piotrowski, D. Schultz, and D. Wagner.

The program counter security model: Automatic
detection and removal of control-ﬂow side channel
attacks. In ICISC 2005, pages 156–168, 2005.

[41] T. Murray, D. Matichuk, M. Brassil, P. Gammie,

T. Bourke, S. Seefried, C. Lewis, X. G., and G. Klein.
sel4: from general purpose to a proof of information
ﬂow enforcement. In S&P 2013, pages 415–429, 2013.

[42] T. Ristenpart, E. Tromer, H. Shacham, and S. Savage.

Hey, you, get oﬀ of my cloud! Exploring information
leakage in third-party compute clouds. In CCS 2009,
pages 199–212. ACM Press, 2009.

[43] V. Robert and X. Leroy. A formally-veriﬁed alias

analysis. In CPP, pages 11–26, 2012.

[44] J. M. Rushby. Noninterference, Transitivity, and

Channel-Control Security Policies. Technical Report
CSL-92-02, SRI International, 1992.

[45] T. Sewell, S. Winwood, P. Gammie, T. Murray,

J. Andronick, and G. Klein. seL4 enforces integrity. In
ITP 2011, Nijmegen, The Netherlands, 2011.
[46] Z. Shao. Certiﬁed software. Commun. ACM,

53(12):56–66, 2010.

[47] D. Stefan, P. Buiras, E. Z. Yang, A. Levy, D. Terei,
A. Russo, and D. Mazi`eres. Eliminating cache-based
timing attacks with instruction-based scheduling. In
J. Crampton, S. Jajodia, and K. Mayes, editors,
ESORICS, volume 8134 of Lecture Notes in Computer
Science, pages 718–735. Springer, 2013.

[48] E. Tromer, D. A. Osvik, and A. Shamir. Eﬃcient

cache attacks on AES, and countermeasures. J.
Cryptology, 23(1):37–71, 2010.

[49] Y. Tsunoo, T. Saito, T. Suzaki, M. Shigeri, and

H. Miyauchi. Cryptanalysis of DES implemented on
computers with cache. In CHES 2003, volume 2779 of
LNCS, pages 62–76. Springer, 2003.

[50] Z. Wang and R. B. Lee. New cache designs for

thwarting software cache-based side channel attacks.
In ISCA 2007, pages 494–505. ACM, 2007.

[51] D. Zhang, A. Askarov, and A. C. Myers. Predictive
mitigation of timing channels in interactive systems.
In CCS 2011, pages 563–574. ACM, 2011.

1278Action

read va

write va val

Informal description

Guest OS reads virtual address va

Guest OS writes value val in va
Hypervisor extends non-stealth memory of active OS with va (cid:55)→ ma

new va pa
new_sm stealth va pa Hypervisor extends stealth memory of active OS with stealth va (cid:55)→ ma
switch o
lswitch pa
hcall c
chmod
page_pin pa t
page_unpin pa

Hypervisor sets o to be active OS
Hypervisor changes the current memory mapping of active OS to be pa
An OS requires privileged service c to be executed by the hypervisor
Hypervisor gives the execution control to active OS
Memory page corresponding to pa is registered and classiﬁed with type t
Memory page of active OS that corresponds to pa is un-registered

Effect
∅ if va is Stealth
read va otherwise
∅ if va is Stealth
write va otherwise
new va pa
∅
switch o
lswitch pa
hcall c
chmod
page_pin pa t
page_unpin pa

Figure 9: Selected actions and their eﬀects

Action write va val

Guest OS writes value val in va

Rule

Action new_sm stealth va pa

Add stealth va (cid:55)→ ma to stealth memory of active OS

Rule

aos act = (aos, running)

get page mem(t, va) = (ma, pg)

pg = (RW , OS aos, b)

pg = (RW val, OS aos, b)

cache add(cache, va, ma, pg) = (cache

(cid:48)

(cid:48)

, (ma
][ma := pg]pol = mem

:= pg
(cid:48)
tlb[va := ma] = tlb

mem[ma

(cid:48)

(cid:48)

, pg

))

(cid:48)
(cid:48)

t

t = (oss, aos act, hyp, mem, cache, tlb)
(cid:48)
(cid:48)
(cid:48)
= (oss, aos act, hyp, mem
, tlb
, cache
(cid:48)
−−−−−−−−−→ t
write va val
t (cid:44)

(cid:48)

)

aos act = (aos, running)

get page mem(t, va) = (ma, pg)

pg = (RW , OS aos, b)

pg = (RW val, OS aos, b)

cache add(cache, va, ma, pg) = (cache

mem[ma := pg]pol = mem

(cid:48)

(cid:48)
tlb[va := ma] = tlb

(cid:48)

,⊥)

t

t = (oss, aos act, hyp, mem, cache, tlb)
(cid:48)
(cid:48)
(cid:48)
= (oss, aos act, hyp, mem
, tlb
, cache
(cid:48)
−−−−−−−−−→ t
write va val
t (cid:44)

(cid:48)

)

Precondition The action write va val requires that the
active OS aos is running. Furthermore, the virtual ad-
dress va is mapped to a machine address ma and a read-
able/writable page pg in the current page table of the active
OS (get page mem).
Postcondition There are two rules for the write action,
one in which an entry is evicted from the cache when the writ-
ten page is added, and the other in which no entry is evicted.
In both cases the resulting state diﬀers in the value val of the
page associated to the pair (va, ma) in the cache cache, and
in the TLB tlb. If cache add returns an entry (ma(cid:48), pg(cid:48)) that
was evicted from the cache, the memory in ma(cid:48) is updated
with pg(cid:48). The ﬁnal value in memory of the page in ma is
dependent on the write policy in use (mem[ma := page]pol
updates the page in ma with page in write-through policies,
and it leaves it unchanged in write-back ones).

aos act = (aos, waiting)

(cid:48)

, N ew stealth va pa)
oss[aos] = (pa
get page hyp(t, aos, pa) = (ma, pg)
¬memory alias(mem, stealth va, ma)
(cid:48)
get page hyp(t, aos, pa
, cpt)

pg = (RW , OS aos, true)

) = (ma

(cid:48)

cpt[stealth va] = ∅

(cid:48)

, N one)] = oss
oss[aos := (pa
(cid:48)
cpt[stealth va := ma] = cpt
(cid:48)
mem[ma
] = mem

:= cpt

(cid:48)

(cid:48)

(cid:48)

cache add(cache, stealth va, ma, pg) = (cache

(cid:48)
tlb[stealth va := ma] = tlb

(cid:48)

t

(cid:48)

t = (oss, aos act, hyp, mem, cache, tlb)
(cid:48)
, tlb
= (oss

(cid:48)
, aos act, hyp, mem
(cid:48)
−−−−−−−−−−−−−−−→ t
new_sm stealth va pa
t (cid:44)

, cache

(cid:48)

)

(cid:48)

, )

Precondition The action new_sm stealth va pa requires
that the active OS aos is waiting for the hypervisor to ex-
tend its current page table cpt with stealth va. The physical
address pa maps to the machine address ma and page pg in
the hypervisor mapping of aos (get page hyp). This page
pg must be readable/writable and cacheable. Also, no page
table can map a virtual address to ma (no memory alias),
and stealth va is not mapped in cpt. This is needed in order
to guarantee that the stealth page pg in ma is always cached
and that no aliased pages are cached.
Postcondition In the resulting state, the pending hypercall
of aos is removed. The current page table cpt and tlb are up-
dated with the mapping of stealth va to ma. Furthermore,
the new stealth page is immediately stored in cache.

Figure 10: Semantics of write and new sm actions

1279