Fully Automated Analysis of Padding-Based Encryption

in the Computational Model

Gilles Barthe

IMDEA Software Institute

Madrid, Spain

Juan Manuel Crespo
IMDEA Software Institute

Madrid, Spain

Benjamin Grégoire
INRIA Sophia Antipolis
Sophia Antipolis, France

gilles.barthe@imdea.org

juanmanuel.crespo@imdea.org

benjamin.gregoire@inria.fr

César Kunz

Yassine Lakhnech

IMDEA Software Institute

U. de Grenoble & VERIMAG

Madrid, Spain

Grenoble, France

Benedikt Schmidt

IMDEA Software Institute

Madrid, Spain

cesar.kunz@imdea.org

yassine.lakhnech@imag.fr

benedikt.schmidt@imdea.org

Santiago Zanella-Béguelin

Microsoft Research

Cambridge, UK

santiago@microsoft.com

ABSTRACT
Computer-aided veriﬁcation provides eﬀective means of an-
alyzing the security of cryptographic primitives. However, it
has remained a challenge to achieve fully automated analyses
yielding guarantees that hold against computational (rather
than symbolic) attacks. This paper meets this challenge for
public-key encryption schemes built from trapdoor permu-
tations and hash functions. Using a novel combination of
techniques from computational and symbolic cryptography,
we present proof systems for analyzing the chosen-plaintext
and chosen-ciphertext security of such schemes in the ran-
dom oracle model. Building on these proof systems, we de-
velop a toolset that bundles together fully automated proof
and attack ﬁnding algorithms. We use this toolset to build a
comprehensive database of encryption schemes that records
attacks against insecure schemes, and proofs with concrete
bounds for secure ones.

Categories and Subject Descriptors
E.3 [Data encryption]: Public key cryptosystems; F.3.1
[Logics and Meanings of Programs]: Specifying and
Verifying and Reasoning about Programs

Keywords
Attack ﬁnding; automated proofs; provable security; public-
key encryption; static equivalence

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516663.

1.

INTRODUCTION

Two diﬀerent models for analyzing the security of cryp-
tographic constructions have developed over the years and
coexist until today, each with its own advantages and disad-
vantages: the computational model and the symbolic model.
The computational model has its roots in the work of
Goldwasser and Micali [21] and views cryptographic primi-
tives as functions on bitstrings. Adversaries are modeled as
probabilistic algorithms and security is deﬁned in terms of
their success probability and computational resources. Se-
curity proofs are reductions, showing how a successful attack
can be converted into an eﬃcient algorithm that breaks the
security of primitives. Often, computational proofs quantify
the eﬃciency of reductions, giving concrete security bounds.
The symbolic model, originating from the seminal work of
Dolev and Yao [19], views cryptographic primitives as func-
tion symbols in a term algebra. The properties of primitives
and the capabilities of adversaries are modeled using equa-
tional theories. This enables automated analysis, but can
miss attacks that are possible in the computational model.
A celebrated article by Abadi and Rogaway [2] bridges the
gap between the two models:
it gives suﬃcient conditions
under which symbolic security implies computational secu-
rity; symbolic methods that exhibit this property are called
cryptographically sound. This result, originally proved for
symmetric encryption, has since been extended to richer the-
ories [17]. Cryptographic soundness opens the perspective of
combining the best of both worlds: fully automated proofs
of computational security. However, its applications have re-
mained conﬁned to protocols. Developing cryptographically
sound symbolic methods for primitives remains a challenge.
A recent alternative to cryptographically sound symbolic
methods uses programming language techniques for reason-
ing about the security of constructions directly in the com-
putational model. This alternative is embodied in tools like
CryptoVerif [12] and EasyCrypt [4], which have been used
to verify emblematic cryptographic constructions. Proofs
built using these tools yield reductions with concrete secu-
rity bounds. However, these tools are primarily interactive
and their use requires expert knowledge. Combining them

1247

with fully automated methods that apply to large classes of
cryptographic primitives has remained an open problem.

A converse goal to proving security is ﬁnding attacks. Re-
cent work [3] explores the use of symbolic methods to ﬁnd
attacks and estimate their success probability. Automating
attack ﬁnding can provide valuable feedback during cryp-
tographic design and be used to evaluate empirically the
completeness of automated security analyses by answering
questions such as how many constructions that may be se-
cure cannot be proven so.

Contributions. We present new methods for automatically
analyzing the security of padding-based encryption schemes,
i.e. public-key encryption schemes built from hash functions
and trapdoor permutations, such as OAEP [11], SAEP [14] or
PSS-E [16]. Collectively, the methods presented can report
a proof, with a concrete security bound, or an attack. These
methods rest on two main technical contributions.

First, we introduce specialized logics for proving chosen-
plaintext and chosen-ciphertext security. Proof rules have
a symbolic ﬂavor and proof search can be automated, yet
one can extract concrete security bounds from valid deriva-
tions. This is achieved through a novel combination of sym-
bolic and computational methods; for instance, the logics
use symbolic deducibility relations for computing bounds of
the probability of events, and for checking the existence of
reductions to computational assumptions.

Second, we propose fully automated methods for ﬁnding
attacks against chosen-plaintext and chosen-ciphertext se-
curity. Our methods are inspired by static equivalence [1],
and exploit algebraic properties of trapdoor permutations to
ﬁnd attacks against realizations of schemes that are consis-
tent with computational assumptions.

We demonstrate the strengths of our methods by imple-
menting a toolset, called ZooCrypt, for analyzing fully auto-
matically a set of user-given or machine-generated schemes.
We generate more than one million examples and use the
toolset to analyze their (in)security. The output of the anal-
ysis is a database that records for each scheme and set of
assumptions, either an adversary that breaks the security of
the scheme or a formal derivation that proves its security.

We stress that we focus on padding-based encryption pri-
marily for illustrative purposes. Padding-based schemes in-
clude many practically relevant constructions, and provide
an excellent testbed to evaluate the eﬀectiveness of our meth-
ods and illustrate their working.

Contents. § 2 provides background on public-key encryp-
tion schemes and their security; § 3 introduces symbolic
tools that are the base of our analyses; § 4 describes logics
for chosen-plaintext and chosen-ciphertext security, while § 5
covers attack ﬁnding techniques; § 6 reports on the imple-
mentation of ZooCrypt and on its evaluation. We conclude
with a survey of related work and directions for future work.
A web interface for browsing a database of our results and
for experimenting with the interactive mode is available at
http://easycrypt.info/zoocrypt/

2.1 Padding-Based Public-Key Encryption

A public-key encryption scheme is a triple of probabilistic

algorithms (KG, E, D):
Key Generation The key generation algorithm KG out-
puts a pair of keys (pk, sk); pk is a public-key used for
encryption, sk is a secret-key used for decryption;

Encryption Given a public-key pk and a message m, the

encryption algorithm Epk(m) outputs a ciphertext c;

Decryption Given a secret-key sk and a ciphertext c, the
decryption algorithm Dsk(c) outputs either message m
or a distinguished value ⊥ denoting failure.

We require that for pairs of keys (pk, sk) generated by KG,
Dsk(Epk(m)) = m holds for any message m.

We study schemes built from trapdoor permutations, hash
functions and basic bitstring operations, such as bitwise
exclusive-or (⊕), concatenation ((cid:4)) and projection. We let
{0, 1}n denote the set of bitstrings of length n and [x](cid:2)
n the
bitstring obtained from x by dropping its n most signiﬁcant
bits and taking the (cid:2) most signiﬁcant bits of the result.

Trapdoor permutations are functions that are easy to eval-
uate, but hard to invert without knowing a secret trapdoor.
Formally, a family of trapdoor permutations on {0, 1}n is a
triple of algorithms (KG, f, f −1) such that for any pair of
keys (pk, sk) output by KG, fpk and f −1
sk are permutations
on {0, 1}n and inverse of each other. The security of a fam-
ily of trapdoor permutations is measured by the probability
that an adversary (partially) inverts f on a random input.

Deﬁnition 1 (One-Way Trapdoor Permutation)
Let Θ = (KG, f, f −1) be a family of trapdoor permutations
on {0, 1}n
and let k, (cid:2) be such that k +(cid:2) ≤ n. The probability
of an algorithm I in q-inverting Θ on bits [k + 1 . . . k + (cid:2)] is
(cid:3)

(cid:2)

Succ

s-pd-OW
Θ

(k, (cid:2), q, I) def= Pr

OW

(cid:2)
k : [s](cid:2)

k ∈ S ∧ |S| ≤ q

where OW

(cid:2)
k is the experiment:

(pk, sk) ← KG; s $← {0, 1}n; S ← I(fpk(s), pk)

This generalizes the set partial-domain one-wayness prob-
lem of Fujisaki et al. [20], which corresponds to the case
k = 0. We deﬁne Succ
(k, (cid:2), q, t) as the maximal suc-
cess probability over all inverters executing in time t, and
omit the ﬁrst parameter when it is 0. When k = 0, (cid:2) = n,
and q = 1, the experiment corresponds to the standard one-
wayness problem, and we note this quantity SuccOW

s-pd-OW
Θ

Θ (t).

We use PSS-E [16] as a running example, and we give a
practical interpretation of our proofs for RSA-PSS-E, which
instantiates PSS-E with RSA as trapdoor permutation.

Deﬁnition 2 (PSS-E) Let (KGf , f, f −1) be a family of one-
way trapdoor permutations on {0, 1}k

, k0 ∈ N, and let

G : {0, 1}k1 → {0, 1}k−k1

H : {0, 1}k−k1 → {0, 1}k1

be two hash functions such that k1 < k. PSS-E is composed
of the following triple of algorithms:
KG
Epk(m) def= r $← {0, 1}k0 ; s ← H(m (cid:4) r);

def= (pk, sk) ← KGf ; return (pk, sk)

t ← G(s) ⊕ (m (cid:4) r); return fpk(s (cid:4) t)

def= s (cid:4) t ← f −1

sk (c); x ← t ⊕ G(s);

if s = H(x) then return [x]k−k1−k0

0

else return ⊥

2. CRYPTOGRAPHIC BACKGROUND

This section provides some background on padding-based

public-key encryption schemes and their security.

Dsk(c)

1248

2.2 Security of Padding-Based Encryption

3.1 Syntax and Semantics of Expressions

We consider two security notions for public-key encryp-
tion: chosen-plaintext security, or IND-CPA, and adaptive
chosen-ciphertext security, or IND-CCA. Both can be de-
scribed succinctly using the following experiment, or game,
in which an adversary A represented as a pair of procedures
(A1, A2) interacts with a challenger:

(pk, sk) ← KG; (m0, m1, σ) ← A (cid:3)H
b $← {0, 1}; c(cid:4) ← Epk(mb); ¯b ← A (cid:3)H

1 (pk);
2 (c(cid:4), σ)

The challenger ﬁrst generates a fresh pair of keys (pk, sk)
and gives the public key pk to the adversary, which returns a
pair of messages (m0, m1) of its choice. The challenger then
samples uniformly a bit b, encrypts the message mb and gives
the resulting ciphertext c(cid:4) (the challenge) to the adversary.
Finally, the adversary outputs a guess ¯b for b. Note that
A1 and A2 can communicate with each other through σ and
have oracle access to all hash functions (cid:4)H used in the scheme.
We call this basic experiment CPA; we deﬁne the experiment
CCA similarly, except that the adversary A is given access to
a decryption oracle Dsk(·), with the proviso that A2 cannot
ask for the decryption of the challenge ciphertext c(cid:4). In the
remainder, we note LH the list of queries that the adversary
makes to a hash oracle H in either experiment, and LD the
list of decryption queries that A2 makes during the second
phase of the CCA experiment.

Security is measured by the advantage of an adversary

playing against a CPA or CCA challenger.

Deﬁnition 3 (Adversary Advantage) The advantage of
an adversary A against the CPA and CCA security of an
encryption scheme Π = (KG, E, D) is deﬁned respectively as:

AdvCPA
AdvCCA

Π (A) def= 2 Pr
Π (A) def= 2 Pr

CPA : ¯b = b
CCA : ¯b = b

− 1
− 1

(cid:4)
(cid:4)

(cid:5)
(cid:5)

We deﬁne AdvCPA
Π (t, (cid:4)q)) as the max-
imal advantage over all adversaries A that execute within
time t and make at most qO queries to oracle O.

Π (t, (cid:4)q) (resp. AdvCCA

To deﬁne asymptotic security, we consider instead of a
single scheme, a family of schemes Πη indexed by a security
parameter η ∈ N. The adversary advantage thus becomes a
function of η. We say that a scheme is secure if the advan-
tage of any adversary executing in time polynomial in η is a
negligible function ν of η, i.e. ∀c. ∃nc. ∀n > nc. ν(n) < n−c.
A security proof for a padding-based encryption scheme
is a reduction showing that any eﬃcient adversary against
the security of the scheme can be turned into an eﬃcient in-
verter for the underlying trapdoor permutation. Proofs are
typically in the random oracle model, where hash functions
are modeled as truly random functions. One seemingly arti-
ﬁcial property of the random oracle model is that reductions
to computational assumptions can adaptively choose the re-
sponses of oracles modeling hash functions; this property is
called programmability. In contrast, we only consider proofs
in the non-programmable random oracle model, where re-
ductions can only observe oracle queries and responses.

3. SYMBOLIC TOOLS

We introduce algebraic expressions to model encryption
schemes, and symbolic notions to model the knowledge that
adversaries or honest users can derive from an expression.

Expressions are built from a set R of random bitstrings
and a set X of variables, using bitstring operations, hash
functions drawn from a set H, and trapdoor permutations
drawn from a set F. The grammar of expressions is

e

::= x
|
r
0n
|
|
f(e)
−1(e)
|
f
| H(e)
|
e ⊕ e
e (cid:4) e
|
[e](cid:2)
|
n

variable
uniformly random bitstring
all-zero bitstring of length n
permutation
inverse permutation
hash function
exclusive-or
concatenation
drop n bits then take (cid:2) bits

where x ∈ X , r ∈ R, n, (cid:2) ∈ S, f ∈ F , and H ∈ H. We
let ⊕ take precedence over (cid:4) . For instance, the encryption
algorithm of PSS-E is represented as the expression:

f(H(m (cid:4) r) (cid:4) G(H(m (cid:4) r)) ⊕ (m (cid:4) r)).

Expressions are typed using a size-based type system. A
type (cid:2) ∈ S is either a size variable or the sum k + n of
two types. We note |e| the type of an expression e, which
intuitively represents the length of the bitstring it denotes.
For instance, the type of e1 (cid:4) e2 is |e1| + |e2| and e1 ⊕ e2
is well-typed iﬀ |e1| = |e2|.
In an asymptotic setting, we
interpret size variables as functions that grow polynomially
with the security parameter.

We let R(e), X (e), F (e) and H(e) denote, respectively, the
sets of random bitstrings, variables, trapdoor permutation,
and hash function symbols occurring in an expression e. We
note e {(cid:4)e1/(cid:4)e0} the simultaneous substitution of (cid:4)e0 by (cid:4)e1 in
e and STH (e) the set of sub-expressions of e that are of
the form H(e(cid:2)). Abusing notation, we write e.g. R(e1, e2)
instead of R(e1) ∪ R(e2).

Given values for size variables in |e| and trapdoor permu-
tations with adequate domains, we interpret a well-typed
expression e as a probabilistic algorithm (cid:2)e(cid:3) that calls or-
acles in H(e) and takes as parameters values for variables
in X (e). The algorithm is implicitly parametrized by public
and secret keys (if required) of the trapdoor permutations
that occur in e. See the full version for a formal deﬁnition.

3.2 Equality and Deducibility

We model algebraic properties of bitstrings using the equa-
tional theory =E, deﬁned as the smallest congruence relation
on well-typed expressions that contains all instances of the
axioms of Figure 1. The relation =E is sound [9] for all trap-
door permutations and valid key pairs. This means that for
all closed expressions s and t, s =E t implies that (cid:2)s(cid:3) and
(cid:2)t(cid:3) return the same value when shared random bitstrings are
jointly sampled; formally,

(cid:2)

(cid:3)

Pr

y ← (cid:2)s (cid:4) t(cid:3) : [y]

|s|
0 = [y]

|t|
|s|

= 1.

We use the standard notion of deducibility from symbolic
cryptography to reason about adversarial knowledge. Infor-
mally, an expression e(cid:2) is deducible from e if there exists an
eﬃcient algorithm that computes e(cid:2) from e. We use con-
texts to describe such algorithms symbolically. A context
is an expression with a distinguished variable ∗. The appli-
cation C[e] of a context C to an expression e is deﬁned by
substitution.

1249

(e1 ⊕ e2) ⊕ e3 = e1 ⊕ (e2 ⊕ e3)
e ⊕ e = 0|e|

e ⊕ 0|e| = e

e1 ⊕ e2 = e2 ⊕ e1
[0n]k

(e1 (cid:4) e2) (cid:4) e3 = e1 (cid:4) (e2 (cid:4) e3)
[e1 (cid:4) e2](cid:2)
|e|
0 = e

|e1| = [e2](cid:2)
[[e](cid:2)

n+n(cid:2)

0

[e1 ⊕ e2](cid:2)

[e]

n](cid:2)(cid:2)
n(cid:2) = [e](cid:2)(cid:2)
−1(e)) = e

f(f

(cid:2) = 0k
|e1|
0 = e1
n ⊕ [e2](cid:2)
n
n+(cid:2) = [e](cid:2)+(cid:2)(cid:2)

n

[e1 (cid:4) e2]
n = [e1](cid:2)
n (cid:4) [e](cid:2)(cid:2)
−1(f(e)) = e

[e](cid:2)

f

Figure 1: Equational theory for algebraic expressions

Deﬁnition 4 (Deducibility) An expression e(cid:2)
from another expression e, written e (cid:14) e(cid:2)
text C such that

is deducible
, if there is a con-

1. R(C) = ∅, X (C) ⊆ {∗};

does not occur in C, and

−1

2. f
3. C[e] =E e(cid:2)

.

We deﬁne (cid:14)(cid:4)

analogously, but dropping restriction 2.

In the full version we prove that (cid:14) is sound in the following
sense: e (cid:14) e(cid:2) implies that there is an eﬃcient algorithm that
computes e(cid:2) from e and the public keys of the trapdoor per-
mutations in e and e(cid:2). For (cid:14)(cid:4) we obtain an identical result,
except that the corresponding algorithm can also use the
secret keys of the trapdoor permutations. Note that we do
not require (cid:14)-completeness, also known as (cid:17)(cid:14)-soundness [9],
since we never use the deducibility relation to conclude that
an expression is not computable from another.

3.3

Inequality and Static Distinguishability

Static equivalence [1] models symbolic indistinguishabil-
ity of expressions. Informally, two expressions e0 and e1 are
statically equivalent if all tests of the form C[·] =E C (cid:2)[·] suc-
ceed for e0 if and only if they succeed for e1. Since the com-
pleteness of =E with respect to the computational interpre-
tation of expressions is an open question, we use a relation
inspired by static equivalence to model distinguishability of
expressions. We call this relation static distinguishability,
and deﬁne it in terms of an apartness relation (cid:7) in place
of (cid:17)=E. The soundness of this relation implies that if s (cid:7) t
holds, then the probability that the results of (cid:2)s(cid:3) and (cid:2)t(cid:3)
coincide when shared random bitstrings are jointly sampled
is negligible. The inductive deﬁnition of (cid:7) comprises axioms
such as r (cid:7) 0 and r (cid:7) r(cid:2), and rules stating that s (cid:7) t implies
H(s) (cid:7) H(t), that C[s] (cid:7) C[t] implies s (cid:7) t, and that s (cid:7) t and
t =E u implies s (cid:7) u.

Deﬁnition 5 (Static Distinguishability) Relation (cid:17)≈ is
the smallest symmetric relation on well-typed expressions
such that e0 (cid:17)≈ e1 iﬀ there are contexts C and C (cid:2)
such that

−1

1. R(C, C (cid:2)) = ∅, X (C) ⊆ {∗};
does not occur in C, C (cid:2)
2. f
3. C[e0] =E C (cid:2)[e0] and C[e1] (cid:7) C (cid:2)[e1].

, and

We use static distinguishability to ﬁnd attacks on encryp-
tion schemes. For the attacks to be meaningful, we rely on
the soundness of (cid:17)≈, which follows from the soundness of =E
and (cid:7). Informally, if e0 (cid:17)≈ e1 holds, then there is an eﬃcient

1250

algorithm distinguish that when given as input the public
keys of trapdoor permutations and a value computed using
(cid:2)e0(cid:3) returns 0, but when given instead a value computed
using (cid:2)e1(cid:3) returns 1, except with negligible probability.

As an example, the expressions e0 = f(r) (cid:4) (r ⊕ 0) and
e1 = f(r) (cid:4) (r1 ⊕ r2) are distinguishable, because for contexts

(cid:6)

(cid:7)

C = [∗]

|f(r)|
0

and C (cid:2) = f

[∗]

|r|
|f(r)|

it holds that C[e0] =E C (cid:2)[e0] and C[e1] (cid:7) C (cid:2)[e1]. A simple
distinguisher algorithm applies the algorithms correspond-
ing to C and C (cid:2) to its input and returns 0 if this yields equal
bitstrings and 1 otherwise.

4. PROOF SYSTEMS

This section introduces logics for proving chosen-plaintext
and chosen-ciphertext security of padding-based schemes by
reduction to computational assumptions on the underlying
trapdoor permutations. For the sake of readability, our pre-
sentation separates the derivation of valid judgments (§ 4.1
and § 4.2) from the computation of concrete security bounds
from valid derivations (§ 4.3). The soundness of the logics
is stated in § 4.4; proofs appear in the full version [6].

4.1 Chosen-Plaintext Security

Judgments predicate over the probability of an event φ
in the CPA experiment where the challenge ciphertext is
computed using (cid:2)c(cid:4)(cid:3), which we denote CPA(c(cid:4)). Events are
drawn from the grammar

φ ::= Guess | Ask(H, e) | φ ∧ φ

where Guess corresponds to the adversary correctly guessing
the hidden bit b, and Ask(H, e) corresponds to the adversary
asking the query H(e).

Judgments are of the form (cid:2) ˆp c(cid:4) : φ, where c(cid:4) is a well-
typed expression with X (c(cid:4)) ⊆ {m}, φ is an event, and
ˆp ∈ {0, 1/2} is a probability tag1. The CPA logic is designed
to ensure that if (cid:2) ˆp c(cid:4) : φ is derivable, then the probability
of φ in the experiment CPA(c(cid:4)) is upper bounded by ˆp plus
a negligible term. In particular, if (cid:2)1/2 c(cid:4) : Guess is deriv-
able, then any scheme Π with encryption algorithm (cid:2)c(cid:4)(cid:3) is
asymptotically secure against chosen-plaintext attacks.

Derivability in the logic is parametrized by a set Γ of com-
putational assumptions of the form (f, k, (cid:2)), where f ∈ F and
k, (cid:2) ∈ S. Such assumptions state that it is hard to compute
[r](cid:2)
k from f(r). There is no restriction on Γ: it may contain
assumptions for several permutations, and multiple assump-
tions for any given permutation.

Figure 2 presents the rules of the proof system. The ter-
minal rules [Rnd] and [OW] are decorated with information
necessary to compute concrete bounds (§ 4.3). We only allow
to apply a rule if all instances of expressions are well-typed;
this implies that for any valid derivation ∇ there exists a
common typing environment for all rule applications.

The rules [Opt], [Perm], [Merge], and [Split] correspond
to bridging steps in proofs and allow reformulating judg-
ments into equivalent forms. The rule [Opt] corresponds to
optimistic sampling, which allows substituting e ⊕ r by r
1Probability tags increase the readability of rules and sup-
port a more uniform interpretation of judgments. However,
they are superﬂuous and can be deduced from the shape of
the event: for every valid judgment (cid:2) ˆp c(cid:4) : φ, the probability
tag ˆp is 1/2 iﬀ φ = Guess.

(cid:2) ˆp c(cid:4) : φ

r /∈ R(e)

(cid:2) ˆp c(cid:4) {e ⊕ r/r} : φ {e ⊕ r/r} [Opt]

(cid:2) ˆp c(cid:4) : φ

(cid:2) ˆp c(cid:4) {f(r)/r} : φ {f(r)/r} [Perm]

(cid:2) ˆp c(cid:4)

2 : φ2

2 φ1 =⇒E φ2

1 =E c(cid:4)
c(cid:4)
(cid:2) ˆp c(cid:4)
1 : φ1

[Sub]

(cid:2) ˆp c(cid:4) {r1 (cid:4) r2/r} : φ {r1 (cid:4) r2/r}

r1, r2 /∈ R(c(cid:4), φ)

r1 (cid:17)= r2

(cid:2) ˆp c(cid:4) : φ

[Split]

(cid:2) ˆp c(cid:4) : φ r1, r2 /∈ R(c(cid:4), φ)

r1 (cid:17)= r2

(cid:2) ˆp c(cid:4) {r1 (cid:4) r2/r} : φ {r1 (cid:4) r2/r}

[Merge]

(cid:2) ˆp c(cid:4) : φ

(cid:2)0 c(cid:4) : Ask(H, e)

r /∈ R(e) H /∈ H(c(cid:4), φ, e)

(cid:2) ˆp c(cid:4) {H(e)/r} : φ {H(e)/r}

[Fail1]

(cid:2) ˆp c(cid:4) : φ

(cid:2)0 c(cid:4) {H(e)/r} : φ {H(e)/r} ∧ Ask(H, e)

r /∈ R(e) H /∈ H(c(cid:4), φ, e)

(cid:2) ˆp c(cid:4) {H(e)/r} : φ {H(e)/r}

[Fail2]

X (c(cid:4)) = ∅

(cid:2)1/2 c(cid:4) : Guess

[Ind]

(cid:4)e (cid:4) R(c(cid:4)) (cid:4) m (cid:14)(cid:4) r

r /∈ R(c(cid:4))

(cid:2)0 c(cid:4) : Ask(H1, e1) ∧ · · · ∧ Ask(Hn, en)

[Rnd(|r|, (cid:4)H)]

(cid:4)e (cid:4) r2 (cid:4) m (cid:14) [r1](cid:2)
k

f(r1) (cid:4) r2 (cid:4) m (cid:14) c(cid:4)

r1 (cid:17)= r2

(f, k, (cid:2)) ∈ Γ

(cid:2)0 c(cid:4) : Ask(H1, e1) ∧ · · · ∧ Ask(Hn, en)

[OW

(cid:2)

k(f, (cid:4)H)]

Figure 2: Proof rules of the CPA logic (=⇒E denotes implication in ﬁrst-order logic with respect to =E)

provided that r /∈ R(e). The rule [Perm] replaces all oc-
currences of f(r) by r. The rule [Merge] replaces the con-
catenation of two random bitstrings r1 and r2 with a fresh
random bitstring r. The rule [Split] performs the opposite
transformation; it replaces a random bitstring r with the
concatenation of two fresh random bitstrings r1 and r2.

Rule [Sub] can be used to weaken the event and replace
expressions in judgments with equivalent expressions. This
rule is often needed to prepare the ground for the application
of another rule: e.g. rule [Opt] can be applied to a judgment
that contains H(r) to obtain H(e ⊕ r) by ﬁrst using [Sub] to
replace H(r) by H(e ⊕ (e ⊕ r)).

The rules [Fail1] and [Fail2], for equivalence up to fail-
ure, correspond to specialized forms of Shoup’s Fundamental
Lemma [29] and create two branches in a derivation. These
rules can be used to substitute an expression H(e) by a ran-
dom bitstring r, incurring a probability loss in the reduction
corresponding to the probability of the CPA adversary ask-
ing the query H(e). One can choose to analyze this proba-
bility either after (as in rule [Fail1]) or before applying the
substitution (as in rule [Fail2]).

Finally, the rules [Ind], [Rnd], and [OW] are terminal and
provide a means of directly bounding the probability of an
event. The ﬁrst two rules are information-theoretic, whereas
the third formalizes a reduction to a computational assump-
tion. The rule [Ind] closes a branch when the challenge ci-
phertext no longer depends on a plaintext variable; in terms
of the CPA experiment, this means that the challenge is in-
dependent from the hidden bit b, and hence the probability
that an adversary guesses it is exactly 1/2. The rule [Rnd]
closes a branch in the case when the adversary must make
a number of oracle queries that would require guessing ran-
dom values that are independent from its view. The rule
[OW] closes a branch when it is possible to ﬁnd a reduction
to the problem of partially inverting a trapdoor permuta-
tion: this is the case when the image of a random element
(the challenge of an inverter) can be embedded in the chal-
lenge ciphertext of the CPA experiment in such a way that its
(partial) pre-image can be computed from the oracle queries
made by the CPA adversary. To apply this rule, r1 is usually
obtained by searching for applications of f in c(cid:4) and r2 is set

to the concatenation of all random bitstrings in R(c(cid:4))\{r1}.
Additionally, one must check that the assumption (f, k, (cid:2)) is
an assumption in Γ.

4.2 Chosen-Ciphertext Security

Judgments are of the form (cid:2) ˆp (c(cid:4), D) : φ, where ˆp is a
probability tag, c(cid:4) is an expression, D is a decryption oracle,
and φ is an event. The challenge ciphertext c(cid:4) and the tag
ˆp can take the same values as in the CPA logic, whereas the
decryption oracle is drawn from the following grammar

F ::= ﬁnd x in LH , F | (cid:21)
T
D ::= F : T  e

::= e = e(cid:2)

| Ask(H, e) | T ∧ T

We assume that D does not contain random bitstrings and
that all variables in expressions in D are bound by ﬁnd, ex-
cept for a distinguished parameter c denoting the ciphertext
queried to the oracle. The above grammar is suﬃciently ex-
pressive to encode decryption algorithms of padding-based
schemes, as well as plaintext-simulators used in reductions.2
Informally, given as input a ciphertext c, an algorithm
ﬁnd (cid:4)x in L (cid:3)H : T  e searches among the queries made by
an adversary to oracles (cid:4)H for values (cid:4)v satisfying T . If such
values are found, it returns the value of e {(cid:4)v/(cid:4)x}; otherwise,
it returns ⊥. Conditions in T are interpreted as equality
checks on bitstrings and membership tests in the lists of
oracle queries made by the adversary. We write T e instead
of (cid:21) : T  e and note (cid:2)D(cid:3) the interpretation of D as an
algorithm.

Events of the logic are as in the CPA logic or of the form
∃x ∈ LD. T . Events Guess and Ask(H, e) are deﬁned as in
the CPA logic but for the CCA experiment. For ∃x ∈ LD. T ,
the quantiﬁed variable ranges over the ciphertexts queried
to the decryption oracle during the second phase of the CCA
experiment; tests are interpreted as described above.

2A plaintext-simulator is an algorithm that extracts the
plaintext from a ciphertext by reconstructing it from oracle
queries made by an adversary, without using the trapdoor to
the underlying permutation; a plaintext-simulator that does
not query any hash oracle is called a plaintext-extractor.

1251

(cid:2) ˆp c(cid:4) : φ STf−1 (T, t) = ∅

(cid:2) ˆp (c(cid:4), F : T  t) : φ

[Pub(F, T, t)]

(cid:2) ˆp (c(cid:4), ﬁnd x in LH , F : T ∧ x = e  t) : φ
(cid:2) ˆp (c(cid:4), F : T {e/x} ∧ Ask(H, e)  t {e/x}) : φ [Find]

(cid:2) ˆp (c(cid:4)

2, F : T2  t2) : φ2

2 φ1 =⇒E φ2 T1 ⇐⇒E T2

c(cid:4)
1 =E c(cid:4)
(cid:2) ˆp (c(cid:4)

1, F : T1  t1) : φ1

t1 =E t2

[Conv]

(cid:2)0 (c(cid:4), D) : ∃c ∈ LD. c = c(cid:4) [False]

(cid:2) ˆp (c(cid:4), T ∧ Ask(H, e)  t) : φ

STH (c(cid:4)) = {H(e(cid:4))} STH (T, t) = {H(e)}
(cid:2)0 (c(cid:4), T ∧ Ask(H, e)  t) : ∃c ∈ LD. T ∧ e(cid:4) = e

(cid:2) ˆp (c(cid:4), T  t) : φ

(cid:2) neglr(T {r/H(e)})

[Bad]

(cid:2) neglr(Ti)

(cid:2) neglr(T1 ∧ T2)

[PAndi]

c (cid:4) e (cid:14)(cid:4) [r](cid:2)
k

r (cid:17)∈ R(e(cid:2))

(cid:2) neglr(e = e(cid:2))

[PEqs((cid:2))]

c (cid:4) e (cid:14)(cid:4) [r](cid:2)
k

(cid:2) neglr(Ask(H, e))

[PRnd((cid:2), H)]

r /∈ R(c(cid:4), e)
(cid:2)0 c(cid:4) : e = r [Eqs(|r|)]

(cid:4)e (cid:4) R(c(cid:4)) (cid:4) m (cid:14)(cid:4) r

r /∈ R(c(cid:4))

(cid:2)0 c(cid:4) : ∃c ∈ LD. Ask(H1, e1) ∧ · · · ∧ Ask(Hn, en)

[Rnd(|r|, (cid:4)H)]

(cid:4)e (cid:4) r2 (cid:4) m (cid:14) [r1](cid:2)
k

f(r1) (cid:4) r2 (cid:4) m (cid:14) c(cid:4)

r1 (cid:17)= r2

(f, k, (cid:2)) ∈ Γ

(cid:2)0 c(cid:4) : ∃c ∈ LD. Ask(H1, e1) ∧ · · · ∧ Ask(Hn, en)

[OW

(cid:2)

k(f, (cid:4)H)]

Figure 3: Proof rules for CCA judgments, proof rules for tests, and extended rules for the CPA logic

A judgment (cid:2) ˆp (c(cid:4), D) : φ predicates over the probability
of φ in the CCA experiment where the challenge ciphertext
is computed using (cid:2)c(cid:4)(cid:3), and decryption queries are answered
by (cid:2)D(cid:3); we note this experiment CCA(c(cid:4), D). The judgment
states that the probability of φ in this experiment is upper
bounded by ˆp plus a negligible term.

Figure 3 presents the rules of the logic. The rule [Bad]
allows to transform the decryption oracle so that it rejects
ciphertexts whose decryption requires to make oracle queries
that have not yet been made by the adversary. The resulting
decryption oracle no longer makes new queries to the given
oracle H.
It suﬃces to consider two events that can lead
the adversary to distinguish between the original and trans-
formed oracles: 1. when the adversary makes a decryption
query c such that T succeeds after making a query H(e) that
is also needed to compute the challenge ciphertext; 2. when
the test T succeeds, even though it gets a random answer
from H. The probability of this last event can be proven
negligible using the rules [PAnd], [PEqs], and [PRnd] in Fig-
ure 3.

The rule [False] captures the fact that the adversary can-
not ask for the decryption of c(cid:4) during the second phase
of the CCA experiment; the probability of this happening
is 0. Rule [Conv] allows switching between observationally
equivalent decryption oracles and weakening the event con-
sidered. This rule is usually used to transform a test that
−1 into an equivalent test that only requires f, so
requires f
that [Pub] becomes applicable.

The rule [Find] allows replacing an oracle that computes
a value explicitly by one that searches for it among oracle
queries made by the adversary.

The rule [Pub] links the CCA logic with the CPA logic,
and captures the intuition that an adversary does not gain
any advantage from getting access to a publicly simulatable
decryption oracle. Note that the judgment in the premise
may be of the form (cid:2) ˆp c(cid:4) : φ, where φ is an event of the CCA

logic. This kind of judgment is handled by the rule [Eqs] and
the generalized rules [Rnd] and [OW] given in Figure 3.

4.3 Concrete Bounds

In this section we show how to extract concrete security
bounds from derivations in our logics. Security bounds p are
drawn from the grammar

q ::= 1 | q × q | qH | qD

p ::=  | 1/2 + 
t ::= tA | q | q × tf | t + t
 ::= 0 | 2−k | Succ

s-pd-OW
Θf

(k, (cid:2), q, t) | q ×  |  + 

where k, (cid:2) ∈ S, H ∈ H, f ∈ F , tf is a worst-case time bound
for evaluating f, and tA is the execution time of A.

Security bounds are computed from a derivation ∇ in the
CPA or CCA logic using a function B parametrized by the
computational resources of an adversary, namely, its execu-
tion time tA and the number of oracle queries it can make,
(cid:4)q. The deﬁnition of function B is given in Figure 4. We omit
resource parameters when they remain unchanged and, for
a derivation ∇ with rule R at its root, we use L∇ to refer
to R’s label and ∇i to refer to the derivation of the i-th
premise of R (premises are enumerated from left to right).
For all bridging rules, the bound is inherited from their
single premise. For rules [Fail1] and [Fail2], the bound is
computed as p1 + p2 where p1 is the probability of the orig-
inal event in the transformed experiment and p2 bounds
the probability of failure. Rule [Bad] is similar except that
bounds come from the probability of two diﬀerent failure
events, and one can be triggered in any decryption query.

Rule [Pub] represents a reduction from CCA to CPA, where
a simulator S uses a CCA adversary A to win in the CPA
experiment. We therefore have to compute bounds for the
computational resources (tS , (cid:4)q S ) used by S in terms of the
resources of A and the plaintext-simulator F : T  u. We
ﬁrst deﬁne a function T that computes a bound for the time

1252

B(tA,(cid:3)q)(∇) =

⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩

B(∇1) + B(∇2)
B(∇1) + B(∇2) + qD B(∇3)
B(tS ,(cid:3)q S )(∇1)
1/2
0
q (cid:3)H × 2−(cid:2)
qH × 2−(cid:2)
2−(cid:2)
2−(cid:2)
s-pd-OW
Succ
Θf
B(∇1)

(k, (cid:2), q (cid:3)H , tI)

if L∇ = [Fail1,2]
if L∇ = [Bad]
if L∇ = [Pub(F, T, u)]
if L∇ = [Ind]
if L∇ = [False]
if L∇ = [Rnd((cid:2), (cid:4)H)]
if L∇ = [PRnd((cid:2), H)]
if L∇ = [Eqs((cid:2))]
if L∇ = [PEqs((cid:2))]
if L∇ = [OW
otherwise

k(f, (cid:4)H)]

(cid:2)

where tI = tA + T (C2) + q (cid:3)H × T (C1), where C1, C2 are the
contexts witnessing the ﬁrst and second deducibility condi-
Hi∈ (cid:3)H qHi , and
tions in the premise of [OW

k(f, (cid:4)H)], q (cid:3)H =

(cid:2)

tS = tA + qD × (T(u) + T(T ) ×

(cid:12)
(cid:13)

qHj )
(cid:13)

Hj in F

qS
Hi = qHi + qD × (Qi(u) + Qi(T ) ×

qHj )

Figure 4: Computation of concrete security bounds

Hj in F

required to evaluate a test T or an expression u. Then, tS
can be deﬁned as tA + qD × tD where tD is the the time re-
quired to evaluate the test T on each combination of queries
traversed by F , plus the time required to evaluate the an-
swer u. Similarly, we deﬁne a function Qi that bounds the
number of queries made to Hi during the simulation of the
decryption oracle, and use it to compute qS

Hi .

The rules [Ind] and [False], yield exact bounds that can
be readily used. The cases of rules [Rnd], and [PRnd], [Eqs],
[PEqs], correspond to the probability of guessing a random
bitstring of length (cid:2) in q (cid:3)H , qH , or just 1 tries. In the case
of rule [OW], the bound is the maximal success probability
against set partial-domain one-wayness over all inverters us-
ing the same resources as the reduction we construct. When
k = 0 and (cid:2) = |f|, we can alternatively use the standard re-
duction from set one-wayness to one-wayness to obtain the
bound SuccOW
Θf (tI +q (cid:3)H ×tf ). Here, the adjusted time bound
accounts for the fact that the inverter must apply f to ev-
ery value computed from the adversary queries to (cid:4)H using
C1 and compare the result to its challenge to ﬁnd the right
pre-image.

4.4 Soundness

Let Π be an encryption scheme with encryption algorithm
(cid:2)c(cid:4)(cid:3) and decryption algorithm (cid:2)D(cid:3). Assume that the inter-
pretations of trapdoor permutations satisfy all the assump-
tions in Γ.

Theorem 6 If ∇ is a derivation of (cid:2)1/2 c(cid:4) : Guess under Γ,
then

Adv

CPA
Π (tA, (cid:4)q) ≤ 2 B(tA,(cid:3)q)(∇) − 1

Moreover, this bound is negligible if tA and all qH in (cid:4)q are
polynomial in the security parameter.

Theorem 7 If ∇ is a derivation of (cid:2)1/2 (c(cid:4), D) : Guess un-
der Γ, then

Adv

CCA
Π (tA, (cid:4)q) ≤ 2 B(tA,(cid:3)q)(∇) − 1

Moreover, this bound is negligible if tA, all qH in (cid:4)q, and qD
are polynomial in the security parameter.

The proofs of these theorems rest on showing the soundness
of each individual rule using game-based techniques. They
appear in the full version [6].

4.5 Example

In this section we prove the chosen-plaintext security and
chosen-ciphertext security of PSS-E by exhibiting deriva-
tions in the CPA and CCA logics. Moreover, we illustrate
how to derive concrete security bounds from these deriva-
tions. Recall that the encryption algorithm of PSS-E is given
by the expression

f(H(m (cid:4) r) (cid:4) G(H(m (cid:4) r)) ⊕ (m (cid:4) r)).

4.5.1 Chosen-Plaintext Security

The derivation for chosen-plaintext security output by our
tool is depicted in Figure 5. The proof starts by applying
the rule [Fail1], replacing the hash G(H(m (cid:4) r)) by a fresh
random bitstring r(cid:2).

In the branch corresponding to the Guess event, we ap-
ply optimistic sampling, replacing r(cid:2) ⊕ (m (cid:4) r) by r(cid:2), and
then [Fail1] again, obtaining two premises. The premise cor-
responding to the original Guess event is proved using rule
[Ind] since the challenge ciphertext no longer depends on
m. The premise corresponding to the failure event can be
discharged using [Rnd] because m (cid:4) r (cid:14)(cid:4) r and r does not ap-
pear in the challenge ciphertext, meaning that the adversary
would have to guess r to trigger failure.

The derivation ∇Ask of the second premise of the ﬁrst ap-
plication of rule [Fail1] is obtained similarly. We ﬁrst apply
[Opt] followed by [Fail1], resulting in two premises:

1. (cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Ask(G, r(cid:2)(cid:2)) 2. (cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Ask(H, m (cid:4) r)
To prove the ﬁrst premise, observe that any adversary that
asks r(cid:2)(cid:2) to G, can be used to invert f on its k1 most signiﬁcant
bits. However, before applying rule OW, we must ﬁrst apply
[Merge] to replace r(cid:2)(cid:2) (cid:4) r(cid:2) by a fresh random variable r, so
that the judgment has the appropriate form.

The second premise corresponds to the same situation en-
countered before, where the adversary must query m (cid:4) r to
H to trigger failure, but r does not occur in the challenge
ciphertext. We conclude as before using [Rnd].

Concrete security bound.

Applying B(tA,(qG,qH )) to the derivation ∇PSS-E yields

1/2 + 2qH × 2−k0 + Succ

s-pd-OW
Θ

(k1, qG, tA + qG).

4.5.2 Chosen-Ciphertext Security

The derivation for chosen-ciphertext security output by
our tool is depicted in Figure 6. For the sake of clarity,
we use let notation and pattern matching to avoid explicit
projections and repetition.

Let n = k − k1 − k0. Initially, we have

c(cid:4) = f(H(m (cid:4) r) (cid:4) G(H(m (cid:4) r)) ⊕ (m (cid:4) r))
D1 = let s (cid:4) t = f

−1(c), x = G(s) ⊕ t in s = H(x)  [x]n
0

1253

∇Ask :

∇PSS-E :

(cid:2)0 f(r) : Ask(G, [r]k1
0 )
(cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Ask(G, r(cid:2)(cid:2))

[OW

k1
0 (f, G)]

[Merge]

(cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Ask(H, m (cid:4) r)

(cid:2)0 f(H(m (cid:4) r) (cid:4) r(cid:2)) : Ask(G, H(m (cid:4) r))

(cid:2)0 f(H(m (cid:4) r) (cid:4) r(cid:2) ⊕ (m (cid:4) r)) : Ask(G, H(m (cid:4) r))

[Opt]

[Rnd(k0, H)]
[Fail1]

(cid:2)1/2 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Guess

[Ind]

(cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Ask(H, m (cid:4) r)

(cid:2)1/2 f(H(m (cid:4) r) (cid:4) r(cid:2)) : Guess

(cid:2)1/2 f(H(m (cid:4) r) (cid:4) r(cid:2) ⊕ (m (cid:4) r)) : Guess

[Opt]

[Rnd(k0, H)]

[Fail1]

∇Ask

(cid:2)0 f(H(m (cid:4) r) (cid:4) r(cid:2) ⊕ (m (cid:4) r)) : Ask(G, H(m (cid:4) r))

(cid:2)1/2 f(H(m (cid:4) r) (cid:4) G(H(m (cid:4) r)) ⊕ (m (cid:4) r)) : Guess

Figure 5: A derivation for CPA security of PSS-E

[Opt]

[Fail1]

∇φ2 :

∇Guess :

(cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)

1 (cid:4) r(cid:2)

2) : φ5

(cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : φ4

[Rnd(k0, H)]
[Split], [Opt]

(cid:2)0 f(r(cid:2)(cid:2) (cid:4) r(cid:2)) : Ask(H, m (cid:4) r)

[Rnd(k0, H)]
[Fail1]

(cid:2)0 f(H(m (cid:4) r) (cid:4) r(cid:2)) : φ4

(cid:2)0 f(H(m (cid:4) r) (cid:4) r(cid:2) ⊕ (m (cid:4) r)) : φ3

[Opt], [Conv]

∇Ask

(cid:2)0 f(H(m (cid:4) r) (cid:4) G(H(m (cid:4) r)) ⊕ (m (cid:4) r)) : φ2

[Fail1]

∇PSS-E

(cid:2)1/2 (c(cid:4), D4) : Guess
(cid:2)1/2 (c(cid:4), D3) : Guess

[Pub]

[Find]

∇φ2

(cid:2)0 (c(cid:4), D4) : φ2
(cid:2)0 (c(cid:4), D3) : φ2

[Pub]
[Find]

(cid:2) neglr(cid:2) (let s(cid:4)t = f

−1(c) in Ask(H, r(cid:2) ⊕t))

(cid:2)1/2 (c(cid:4), D2) : Guess

[PRnd(k−k1, H)]
[Bad], [PAnd2]

∇CCA

PSS-E :

∇Guess

(cid:2)0 (c(cid:4), D2) : φ1

[Conv], [False]

(cid:2) neglr(cid:2) (let s (cid:4) t = f

−1(c) in s = r(cid:2))

(cid:2)1/2 (c(cid:4), D1) : Guess

[PEqs(k1)]

[Bad]

φ1
φ2
φ3
φ4
φ5

def= ∃c ∈ LD. let s (cid:4) t = f
def= ∃c ∈ LD. let s (cid:4) t = f
def= ∃c ∈ LD. let s (cid:4) t = f
def= ∃c ∈ LD. let s (cid:4) t = f
def= ∃c ∈ LD. let s (cid:4) t = f

−1(c) in let x = G(s) ⊕ t in s = H(x) ∧ x = m (cid:4) r
−1(c) in let x = G(s) ⊕ t in s = H(x) ∧ Ask(H, x) ∧ s = H(m (cid:4) r)
−1(c) in let x = r(cid:2) ⊕ t in s = H(x) ∧ Ask(H, x) ∧ s = H(m (cid:4) r)
−1(c) in Ask(H, r(cid:2) ⊕ (m (cid:4) r) ⊕ t)
−1(c) in Ask(H, (r(cid:2)

1 ⊕ m ⊕ [t]n

0 ) (cid:4) r)

Figure 6: A derivation for CCA security of PSS-E

We are interested in proving the judgment (cid:2)1/2 (c(cid:4), D1) :
Guess. We begin by applying rule [Bad] to strengthen the
test in the decryption oracle to check also that Ask(H, x)
holds, so as to reject ciphertexts that would require new
queries to H. The corresponding algorithm is

and is proven using rules [False] and [Conv], because the
event is equivalent to ∃c ∈ LD. c = c(cid:4).

To prove the premise corresponding to the original Guess
event, we apply rule [Bad] again, but this time with G(s).
We obtain the following decryption oracle

D2 = let s (cid:4) t = f

−1(c) in

let x = G(s) ⊕ t in s = H(x) ∧ Ask(H, x)  [x]n
0

D3 = let s (cid:4) t = f

−1(c), x = G(s) ⊕ t in

s = H(x) ∧ Ask(H, x) ∧ Ask(G, s)  [x]n
0

Note that an adversary can distinguish between D1 and D2
only if it can produce a ciphertext c that passes the test with-
out querying H(x) in the ﬁrst place. This is only possible if
the adversary either guesses this hash or learns something
about it from the challenge ciphertext. The former case cor-
−1(c) in s = r(cid:2))
responds to the premise (cid:2) neglr(cid:2) (let s (cid:4) t = f
and can be proven using [PEqs(k1)]. The latter case corre-
sponds to the premise
(cid:2)0 (c(cid:4), D2) : ∃c ∈ LD.

let s (cid:4) t = f

−1(c), x = G(s) ⊕ t in s = H(x) ∧ x = m (cid:4) r

The premise

(cid:2) neglr(cid:2) (let s (cid:4) t = f

−1(c), x = r(cid:2) ⊕ t in s = H(x) ∧ Ask(H, x))

can be discharged using rules [PAnd2] and [PRnd(k −k1, H)].
To prove the two premises corresponding to CCA judg-
ments, we ﬁrst apply rule [Find] (and [Conv]) to reformulate
the decryption oracle as follows:

D4 = ﬁnd s, x in LG, LH : c = f(s (cid:4) G(s)⊕x) ∧ s = H(x)  [x]n
0

1254

Note that this decryption oracle is public, i.e. it does not
−1 and can be eﬃciently simulated. Hence, we can
use f
apply rule [Pub] and proceed reasoning in the (extended)
CPA logic. The branch corresponding to the original Guess
event can be proven using the same derivation ∇PSS-E in
Figure 5 that we used to prove CPA security.

We have only one outstanding goal,
(cid:2)0 c(cid:4) : ∃c ∈ LD. let s (cid:4) t = f

−1(c), x = G(s) ⊕ t in

s = H(x) ∧ Ask(H, x) ∧ s = H(m (cid:4) r)
To prove it, we ﬁrst apply [Fail1] to replace G(H(m (cid:4) r)) with
a fresh random bitstring r(cid:2). The derivation ∇Ask that bounds
the probability of failure is as in the proof of CPA security
in Figure 5. We apply rules [Opt] and [Conv] to simplify the
premise corresponding to the original event, obtaining
(cid:2)0 f(H(m (cid:4) r) (cid:4) r(cid:2)) :

∃c ∈ LD. let s (cid:4) t = f

−1(c) in Ask(H, r(cid:2) ⊕ (m (cid:4) r) ⊕ t)
We then apply [Fail1] again, this time to replace H(m (cid:4)
r) with a fresh random bitstring r(cid:2)(cid:2). The premise corre-
sponding to the failure event can be readily proved using
[Rnd(k0, H)] as in the proof of CPA security. To prove
the remaining premise, observe that to trigger the event
Ask(H, r(cid:2) ⊕(m (cid:4) r)⊕t), the adversary should be able to com-
pute [r(cid:2) ⊕ t]k0
n ⊕ r, but r is now independent of the challenge
ciphertext. We formalize this reasoning by ﬁrst splitting r(cid:2)
and then applying rule [Opt] to replace [r(cid:2)⊕t]k0
n ⊕r by simply
r. We conclude applying the extended rule [Rnd(k0, H)].
(cid:15)

Concrete security bound.

(cid:14)

The concrete security bound B(tA,(qG,qH ,qD ))

∇CCA

PSS-E

ob-

tained from this proof is

B(tS ,(qG,qH ,qD ))(∇PSS-E) + B(tS ,(qG,qH ,qD ))(∇φ2 ) +
qD × (2−k1 + qH × 2k1−k)

where tS = tA + qD qG qH × tf , and

B(tS ,(qG,qH ,qD ))(∇PSS-E)

B(tS ,(qG,qH ,qD ))(∇φ2 )

≈ 1/2 + 2 qH × 2−k0 + Succ

s-pd-OW
Θ

(k1, qG, tS )

= 3 qH × 2−k0 + Succ

s-pd-OW
Θ

(k1, qG, tS )

Observe that tS comes from the two applications of rule
[Find] in the proof and can be improved to tA + qD qH × tf
because to answer a decryption query, the simulator D4 just
needs to traverse LH to ﬁnd a value for x, the value of
s is determined by H(x). The overall bound is, ignoring
constant factors,

1/2 + qH × 2−k0 + qD × 2−k1 + qD × qH × 2k1−k+

Succ

s-pd-OW
Θ

(k1, qG, tA + qD qH × tf )

In comparison, the bound given by Coron et al. [16] is:

1/2 + qH × 2−k0 + qD × 2−k1 +

Succ

s-pd-OW
Θ

(k1, qG + qH , tA + qD qH × tf )

The diﬀerences are due to the use of a slightly diﬀerent re-
duction. The proof of Coron et al. [16] assumes that the
hash oracle H issues a query G(s) each time it produces a
response s. This assumption would make redundant the ap-
plication of rule [Bad] in ∇Guess in our reduction, eliminating
the terms coming from ∇φ2 and qD × qH × 2k1−k. The re-
sulting bound, once adjusting qG for the additional queries
issued by H, coincides with that of Coron et al.

1255

5. ATTACKS

This section describes our approach for ﬁnding attacks
against chosen-plaintext and chosen-ciphertext security of
padding-based encryption schemes. Since our logics are in-
complete, we use attack ﬁnding to obtain negative results,
and additional data points to evaluate schemes for which we
cannot obtain proofs.

We distinguish between universal attacks and existential
attacks relative to a set of assumptions. An attack is uni-
versal if it works against every possible instantiation of the
trapdoor permutations used by a scheme. An attack is exis-
tential if it works for some trapdoor permutation consistent
with the assumptions, i.e. it may rely on speciﬁc properties
of the employed trapdoor permutation.

5.1 Universal Attacks

To ﬁnd universal attacks against the CPA security of an en-
cryption scheme with encryption algorithm e, we search for
closed expressions m0 and m1 that do not contain symbols
−1 such that e {m0/m} (cid:17)≈ e {m1/m}. By sound-
of the form f
ness of (cid:17)≈, there exists an eﬃcient algorithm distinguish that
returns 0 for input (cid:2)e {m0/m}(cid:3) and 1 for input (cid:2)e {m1/m}(cid:3)
with overwhelming probability. To mount an attack against
CPA security using this algorithm, an adversary chooses
plaintexts (cid:2)m0(cid:3) and (cid:2)m1(cid:3), receives the challenge ciphertext
c(cid:4), and returns distinguish(c(cid:4)). An example of a scheme vul-
nerable to this attack is a scheme with encryption algorithm
given by

e = f(r) (cid:4) (G(r) ⊕ m) (cid:4) H(m)

A CPA adversary can use the distinguisher obtained from
|r|+|m| and C (cid:2) = H(0|m|) to tell appart
the contexts C = [∗]
e {0/m} from e {1/m}.

|H(m)|

To refute CCA security, we search for malleability attacks
using deducibility. Speciﬁcally, we search for closed expres-
sions m0 and Δ (cid:17)= 0|m| such that e {m0/m} (cid:14) e {m0 ⊕ Δ/m};
let C be the context witnessing the deducibility. This would
imply an eﬀective attack against CCA security: choose plain-
texts m0 and m1 (cid:17)= m0 and obtain the challenge c(cid:4); then
query the decryption oracle on (cid:2)C[c(cid:4)](cid:3), xor the result with
Δ, and return 0 if it equals (cid:2)m0(cid:3) and 1 otherwise. An exam-
ple of a scheme vulnerable to a universal attack of this form
is the Zheng-Seberry cryptosystem [31], whose encryption
algorithm is given by e = f(r) (cid:4) (G(r) ⊕ (m (cid:4) H(m))); take
m0 = 0|m| and Δ = 1|m|.

5.2 Existential Attacks

To ﬁnd existential attacks against a scheme with encryp-
tion algorithm e w.r.t. a set of assumptions Γ, we ﬁnd uni-
versal attacks against modiﬁed versions of it. An example
can elucidate better the point.

Consider the encryption algorithm of ZAEP [7], given by
e = f(r (cid:4) G(r) ⊕ m). To show that there is no blackbox
reduction from the CPA security of ZAEP to the assumption
(f, 0, |f|), we instantiate f as follows

f(a (cid:4) b) = a (cid:4) f2(b)

(1)

If f2 is a one-way permutation, the permutation f satisﬁes
the assumption (f, 0, |f|). Using static distinguishability, we
ﬁnd an attack on e(cid:2) = r (cid:4) f2(G(r) ⊕ m) given by the contexts

C = [∗]

|m|

|r| and C (cid:2) = f2(G([∗]

|r|
0 ))

which can be used to distinguish e {0/m} and e {1/m}.

To show that there is no blackbox reduction of the CCA
security of ZAEP to an arbitrary Γ, we use the instantiation

(cid:6)

f(a) = f

(cid:2)

[a]

|a|−c
0

(cid:7)(cid:16)(cid:16)(cid:16) [a]c

|a|−c

(2)

where c is a size variable that we interpret as a constant. It
is easy to see that ciphertexts computed using this instan-
(cid:2) satisﬁes the
tiation are malleable. Moreover, assuming f
assumptions Γ (accounting for the size reduction by c), this
instance of f satisﬁes Γ. This is because size variables in as-
sumptions grow polynomially with the security parameter,
and leaking a constant fraction of a pre-image cannot be
used to attack any assumption in Γ. In contrast, the ability
to compute a ciphertext of a message that diﬀers in just one
bit from the decryption of a given ciphertext results in a
chosen-ciphertext attack.

In general, to prove that there is no blackbox reduction
for a ﬁxed set of one-wayness assumptions Γ, we must either
ﬁnd a universal attack or instantiations for the trapdoor
permutations that yield attacks and are compatible with
all assumptions in Γ. For example, the instantiation (2)
above is compatible with any set of assumptions, while (1)
is compatible with all assumptions except those of the form
(f, k, (cid:2)) with 0 < (cid:2) and k + (cid:2) ≤ |a|.
In addition to the
aforementioned instantiations, we also use instantiations of
the form

Well-typed

and invertible?

Yes

Search for chosen-plaintext attacks

No

Incorrect scheme

Attack found?

Yes

Output attack

Not CPA secure

No

Search for proof of CPA security

Proof found?

No

Search for malleability attacks

Yes

Output CPA bound

Attack found?

No

Security undecided

Search for malleability attacks

Yes

Attack found?

Yes

Output attack

CPA if proof found

Not CCA secure

No

Search for proof of CCA security

f(a (cid:4) b (cid:4) c) = f1(a) (cid:4) b ⊕ a (cid:4) c

Proof found?

Yes

Output CCA bound

CCA secure

which allow us to ﬁnd attacks if f is used in such a way that
part of its input is leaked or interdependent.

No

CPA secure, CCA undecided

6. EXPERIMENTAL VALIDATION

We implemented the proof search and attack ﬁnding meth-
ods described in § 4 and § 5 in a toolset that we name
ZooCrypt. ZooCrypt can prove the CPA and CCA security
of a scheme under diﬀerent assumptions on the trapdoor
permutations used, or ﬁnd attacks that are consistent with
these assumptions.

6.1 Security Analysis

To analyze the security of a scheme with encryption algo-
rithm given by an expression c(cid:4) under a set of assumptions
Γ, the toolset follows the workﬂow depicted in Figure 6.1:

1. Checks that c(cid:4) is well-typed and that encryption is

invertible, i.e. c(cid:4) (cid:14)(cid:4) m;

2. Searches for attacks against CPA security;

3. Searches for proofs of CPA security. If a proof is found,

computes the corresponding security bound;

4. Searches for malleability attacks against CCA security;

5. If a CPA proof has been found, synthesizes a decryp-
tion algorithm D and searches for a proof of CCA se-
curity. If a proof is found, computes the corresponding
security bound.

The results of this security analysis are an adversary for
each attack found, and derivations for all security proofs to-
gether with the set of assumptions eﬀectively used and the
corresponding concrete security bound. Steps 3 and 5 im-
plement proof search algorithms for the logics. These algo-
rithms try to build a valid derivation bottom up, by applying
rules in a prescribed order. Simple heuristics allow to im-
prove the eﬃciency of the search and to ensure termination.

Figure 7: Security analysis workﬂow

A crucial step in the above workﬂow is synthesizing a de-
cryption algorithm that reject as many invalid ciphertexts as
possible, with the aim of easing the construction of a plain-
text simulator during a CCA analysis. Indeed, an encryp-
tion algorithm typically admits several correct decryption
algorithms, because the consistency condition gives com-
plete freedom of choice as to what should be the result of
decrypting an invalid ciphertext. The tool infers such al-
gorithms using a method inspired by [8, 15] to analyze the
redundancy built into ciphertexts. We exploit the fact that
our algorithm for checking static equivalence computes as
a sub-routine non-trivial equations that hold for an expres-
sion; when applied to an expression denoting an encryption
algorithm, this sub-routine yields tests for checking the va-
lidity of ciphertexts.

6.2 Practical Interpretation for RSA

Concrete security bounds can be used to guide the choice
of practical parameters for realizations of encryption schemes
based on RSA. In order to validate the quality of the bounds
output by our tool, we implemented a method based on an
extrapolation of the estimated cost of factoring the RSA-768
integer from the RSA Factoring Challenge [23], and on the
lattice basis reduction of set partial-domain one-wayness to
one-wayness for RSA [20].

Let tN be the cost of factoring an N -bit RSA modulus:
Kleinjung [23] estimates that t768 = 267, while Lenstra [25]

1256

suggests to extrapolate based on the ratio

tN
tM

≈ exp((1.9229) log(N )1/3 log(log(N ))2/3
exp((1.9229) log(M )1/3 log(log(M ))2/3

The success probability of partially inverting RSA on its k
RSA(k, q, t) can be upper bounded

most signiﬁcant bits, SuccOW
by a function of SuccOW

RSA(t(cid:2)), where t(cid:2) depends on t.

Proposition 8 ([20]) Let Θ be RSA with an (cid:2)-bit modulus
such that (cid:2) < 2k. Then,

(cid:6)
Succ

(cid:7)
OW
Θ (k, q, t) − 2(cid:2)−2k+6

Succ

OW
Θ (t)

≤ Succ

OW
Θ (2t + q2(cid:2)3)

Fixing a maximum number of queries to oracles and an
admissible advantage p, our tool can estimate from the se-
curity bound obtained from a derivation, the minimum RSA
modulus length N such that no adversary executing in time
tA achieves either a CPA or CCA advantage greater than p.
For instance, a reasonable security target might be that
no CCA adversary executing in time 2128 and making at
most 260 hash queries and 230 decryption queries achieves
an advantage greater than 2−20. From these values, the
estimated cost of inverting RSA, and the bound found for
the CCA security of PSS-E under the same assumption as
in [20], our tool estimates a minimum modulus length of
4864 bits, and a ciphertext overhead of around 200 bits.

6.3 Generation of Encryption Schemes

Our tool also implements an algorithm that generates ex-
pressions denoting encryption algorithms within budget con-
straints speciﬁed as the number of concatenation, exclusive-
or, hash and trapdoor permutation constructors.

Candidate encryption schemes are generated following a
top-down approach that uses variables to represent holes in
partially speciﬁed expressions. Starting from a fully unspec-
iﬁed expression, i.e. just a variable x, at each iterative step
the tool picks a hole and replaces it with either:

• An expression of the form f(x), H(x), x ⊕ y or x (cid:4) y,

for fresh variables x and y, if the budget permits;

• A hole-free sub-expression of e or one of 0, m, r; this

does not consume the budget.

An incremental type-checker is used at each step to discard
partially speciﬁed expressions that do not have any well-
typed instance. For example, e ⊕ (e (cid:4) x) is immediately
discarded because e cannot be assigned a size regardless of
any substitution for the hole x.

We trim large parts of the search space by implementing
an early pruning strategy in the style of [27]. Concretely, we
apply some simple ﬁlters during generation. For instance,
given an expression e with holes, we check for the existence of
a substitution σ for holes respecting the budget constraints
such that eσ (cid:14)(cid:4) m, and that it is not the case that for all such
substitutions eσ (cid:14) m or eσ (cid:4) m (cid:14) R(e). These ﬁlters can
be implemented eﬃciently using memoization to drastically
reduce their computational cost.

6.4 Experiments

We evaluate our tools on encryption schemes generated
under diﬀerent budget constraints. Figure 1 summarizes
the results of the automated security analysis of §6.1. In the
ﬁgure, schemes are classiﬁed in rows by their size, measured

1257

by the total number of operators used in the expression de-
noting their encryption algorithm.

The reported experiment has been conducted under two

classes of assumptions:

1. Γ1 = {(f, 0, |f|) | f ∈ F (c(cid:4))}, i.e. assuming that all

trapdoor permutations are one-way;

2. Γ2 = {(f, kf , nf ) | f ∈ F (c(cid:4))} such that 0 ≤ kf and
kf + nf ≤ |f| for all f ∈ F (c(cid:4)), i.e. one arbitrary one-
wayness assumption for each trapdoor permutation;

The columns grouped under OW CPA report the results
obtained when analyzing CPA security under Γ1. Column
Proof indicates the number of schemes proved secure, col-
umn Attack the number of schemes for which some attack
(existential or universal) was found, and column Undecided
the number of schemes for which security could not be de-
cided. Similarly, the columns grouped under CPA and CCA
report the results when analyzing CPA and CCA security
under all assumptions of the form Γ2. In this case, column
Proof indicates the number of schemes proved secure un-
der some assumption of the form Γ2, column Attack the
number of schemes for which an attack was found for all
assumptions of the form Γ2, and column Undecided the
number of schemes for which security could not be decided.
The attack and proof search algorithms are extremely eﬃ-
cient, e.g. proof search for schemes of size 7 takes on average
0.1ms for CPA and 0.5ms for CCA on a modern workstation.
Observe that the ﬁgures in the ﬁrst two groups suggest
the separation between one-wayness and partial-domain one-
wayness: the stronger the assumption, the more schemes can
be proven secure and the less attacks can be found.

Finally, column NR in the CCA group counts the number
of schemes that are CPA secure but non-redundant, meaning
that all ciphertexts are valid. Non-redundant schemes can
be CCA secure [7, 24], but their proofs require random oracle
programmability, which is out of the scope of our logics.

Validation.

We also evaluated our automated proof search and attack
ﬁnding algorithms on a number of schemes from the litera-
ture, including the over one hundred variants of OAEP and
SAEP surveyed by Komano and Ohta [24]. In all cases, our
results are consistent with published results, and in most we
are able to prove security under exactly the same assump-
tions and obtain the same security bounds. As evidence of
the eﬀectiveness of our methodology, we observe that our
analyses decide the CPA security of all 72 variants of OAEP
in the taxonomy of [24]. The results for CCA security are
more nuanced:
for about 20% of schemes, we fail to ﬁnd
proofs or attacks when they exist.

For CPA security our methods seem to achieve empirical
completeness, suggesting that completeness may be provable
for some class of schemes or some mild extension. A closer
examination of the schemes on which our CCA analysis is
unable to decide security reveals that this is either due to our
approximation of inequality in rules [Eqs] and [PEqs] being
too coarse, or because the schemes are non-redundant.

Non-redundancy complicates enormously the task of sim-
ulating the decryption oracle in CCA reductions, because a
meaningful response must be returned in all cases. Proving
CCA security of non-redundant schemes, requires program-
ming random oracles in order to maintain consistency during
simulation, something that we have intentionally avoided in

Size

Total

4

5

6

7

8

9

2

44

335

3263

32671

350111

10

644563

Total

1030989

OW CPA (% of Total)

CPA (% of Total)

CCA (% of CPA Proof + CPA Undecided)

Proof
1
(50.00%)
8
(18.18%)
65
(19.40%)
510
(15.63%)
4430
(13.56%)
43556
(12.44%)
67863
(10.53%)
116433
(11.29%)

Attack Undecided
0
(0.00%)
0
(0.00%)
0
(0.00%)
18
(0.55%)
347
(1.06%)
4876
(1.39%)
7386
(1.15%)
12627
(1.22%)

1
(50.00%)
36
(81.82%)
270
(80.60%)
2735
(83.82%)
27894
(85.38%)
301679
(86.17%)
569314
(88.33%)
901929
(87.48%)

Proof
2
(100.00%)
12
(27.27%)
93
(27.76%)
750
(22.98%)
6718
(20.56%)
66775
(19.07%)
133476
(20.71%)
207826
(20.16%)

Attack Undecided
0
(0.00%)
0
(0.00%)
1
(0.30%)
38
(1.16%)
617
(1.89%)
8523
(2.43%)
19898
(3.09%)
29077
(2.82%)

0
(0.00%)
32
(72.73%)
241
(71.94%)
2475
(75.85%)
25336
(77.55%)
274813
(78.49%)
491189
(76.20%)
794086
(77.02%)

Proof
0
(0.00%)
0
(0.00%)
1
(0.98%)
45
(5.05%)
536
(6.26%)
7279
(8.16%)
20140
(11.29%)
28001
(10.11%)

Attack
2
(100.00%)
13
(100.00%)
96
(94.12%)
739
(82.94%)
6531
(76.25%)
62356
(69.93%)
112993
(63.36%)
182730
(65.95%)

NR Undecided
0
(0.00%)
0
(0.00%)
0
(0.00%)
62
(6.96%)
1192
(13.92%)
16496
(18.50%)
32397
(18.17%)
50147
(18.10%)

0
(0.00%)
0
(0.00%)
5
(4.90%)
45
(5.05%)
306
(3.57%)
3035
(3.40%)
12794
(7.17%)
16185
(5.84%)

Table 1: Evaluation of the tool on generated encryption schemes

our proof systems. Extending our proof systems to embody
some form of programmability would reduce the number of
schemes for which security cannot be decided, and would be
a step towards closing the empirical completeness gap.

7. RELATED WORK

Our work lies at the intersection between symbolic and
computational cryptography, and draws on veriﬁcation tech-
niques from both areas. We refer to [13, 17] for a recent ac-
count of symbolic veriﬁcation and focus on veriﬁcation tools
and methods for the computational model.

Since its inception [2], cryptographic soundness was ex-
tended to many settings [17]. Despite this success, exten-
sions for constructions based on exclusive-or and trapdoor
permutations have remained elusive. Negative results such
as [30] show that cryptographic soundness may indeed be
very diﬃcult to achieve for the setting of this paper.

CryptoVerif [12] and EasyCrypt [4] support the construc-
tion and veriﬁcation of cryptographic proofs in the compu-
tational model. Both CryptoVerif and EasyCrypt provide a
high level of automation, and CryptoVerif supports fully au-
tomated veriﬁcation of many cryptographic protocols.
In
addition, EasyCrypt has been applied to verify security of
several padding-based schemes. However, fully automated
proofs of padding-based schemes are out of reach of these
tools. Courant et al. [18] report on a Hoare-like logic and an
automated tool for proving CPA security of padding-based
schemes. The tool can verify the security of several schemes,
such as BR [10] and REACT [26], but fails to verify most
other examples. In our view, the limitations of the approach
are inherited from using a Hoare logic, which favors local
reasoning. In contrast, we use a global approach in which
one reasons about the probability of events in experiments.
In addition, a number of formalisms have been developed
to reason about security of cryptographic primitives and
constructions in the computational model [5, 22]. However,
these systems reason about constructions described in math-
ematical vernacular, and are thus not readily amenable to
automation. Similar formalisms exist for cryptographic pro-
tocols [28], but these are not automated either.

Finally, the batch mode of ZooCrypt is similar in spirit
to the AVGI toolkit [27]. The toolkit allows users to state
security requirements, for instance authentication or secrecy,
and non-functional requirements such as message length and
available bandwidth. The AVGI toolkit is composed of a
protocol generator, that applies pruning techniques to curb

the state space explosion problem, and a protocol screener
that applies symbolic methods to verify whether generated
protocols comply with the desired properties.

8. CONCLUSION

We have deﬁned, implemented and evaluated proof sys-
tems to reason about security of public-key encryption
schemes built from trapdoor permutations and hash func-
tions. Our work sets a new methodology for analyzing cryp-
tographic constructions in the computational model. Pre-
liminary investigations suggest that our methodology ex-
tends well to other settings, and we intend to apply it for
building a comprehensive database that includes other clas-
sical cryptographic constructions such as digital signature
schemes, modes of operation, and message authentication
codes. In the future, we plan to use the interactive mode
of ZooCrypt as the backbone for an online tutor that can
help users ﬁnding attacks or security proofs for padding-
based schemes of their choice, or automatically generated.
Moreover, we plan to connect ZooCrypt with EasyCrypt, and
implement a prototype mechanism that translates successful
derivations in our logics into EasyCrypt proofs.

Acknowledgments. This research is partially supported by
ONR grant N000141210914, Spanish project TIN2009-14599
DESAFIOS 10, and Madrid regional project S2009TIC-1465
PROMETIDOS.

References
[1] M. Abadi and C. Fournet. Mobile values, new names,
and secure communication. In 28th ACM SIGPLAN-
SIGACT symposium on Principles of Programming
Languages, POPL 2001, pages 104–115, 2001. ACM.

[2] M. Abadi and P. Rogaway. Reconciling two views of
cryptography (The computational soundness of formal
encryption). J. Cryptology, 15(2):103–127, 2002.

[3] G. Bana and H. Comon-Lundh. Towards uncondi-
tional soundness: Computationally complete symbolic
attacker.
In 1st Conference on Principles of Security
and Trust – POST 2012, volume 7215 of LNCS, pages
189–208, 2012. Springer.

[4] G. Barthe, B. Gr´egoire, S. Heraud, and S. Zanella-
Computer-aided security proofs for the

B´eguelin.

1258

working cryptographer.
In Advances in Cryptology –
CRYPTO 2011, volume 6841 of LNCS, pages 71–90,
2011. Springer.

[5] G. Barthe, B. Gr´egoire, Y. Lakhnech, and S. Zanella-
B´eguelin. Beyond provable security. Veriﬁable IND-
CCA security of OAEP. In Topics in Cryptology – CT-
RSA 2011, volume 6558 of LNCS, pages 180–196, 2011.
Springer.

[6] G. Barthe, J. M. Crespo, B. Gr´egoire, C. Kunz,
Y. Lakhnech, B. Schmidt, and S. Zanella-B´eguelin.
Fully automated analysis of padding-based encryp-
tion in the computational model. Cryptology ePrint
Archive, Report 2012/695.

[7] G. Barthe, D. Pointcheval, and S. Zanella-B´eguelin.
Veriﬁed security of redundancy-free encryption from
Rabin and RSA.
In 19th ACM Conference on Com-
puter and Communications Security, CCS 2012, pages
724–735, 2012. ACM.

[8] M. Baudet, V. Cortier, and S. Delaune. Yapa: A generic
tool for computing intruder knowledge.
In Rewrit-
ing Techniques and Applications, pages 148–163, 2009.
Springer.

[9] M. Baudet, V. Cortier, and S. Kremer. Computa-
tionally sound implementations of equational theories
against passive adversaries. Inf. Comput., 207(4):496–
520, 2009.

[10] M. Bellare and P. Rogaway. Random oracles are practi-
cal: a paradigm for designing eﬃcient protocols. In 1st
ACM Conference on Computer and Communications
Security, CCS 1993, pages 62–73, 1993. ACM.

[11] M. Bellare and P. Rogaway. Optimal asymmetric
encryption.
In Advances in Cryptology – EURO-
CRYPT 1994, volume 950 of LNCS, pages 92–111,
1994. Springer.

[12] B. Blanchet. A computationally sound mechanized
prover for security protocols.
In 27th IEEE Sympo-
sium on Security and Privacy, S&P 2006, pages 140–
154. IEEE Computer Society, 2006.

[13] B. Blanchet. Security protocol veriﬁcation: Symbolic
and computational models. In 1st International Confer-
ence on Principles of Security and Trust, POST 2012,
volume 7215 of LNCS, pages 3–29, 2012. Springer.

[14] D. Boneh. Simpliﬁed OAEP for the RSA and Rabin
functions. In Advances in Cryptology – CRYPTO 2001,
volume 2139 of LNCS, pages 275–291, 2001. Springer.

[15] ¸S. Ciobˆac˘a, S. Delaune, and S. Kremer. Computing
knowledge in security protocols under convergent equa-
tional theories.
In Automated Deduction–CADE-22,
pages 355–370. Springer, 2009.

[17] V. Cortier, S. Kremer, and B. Warinschi. A survey of
symbolic methods in computational analysis of cryp-
tographic systems. J. Autom. Reasoning, 46(3-4):225–
259, 2011.

[18] J. Courant, M. Daubignard, C. Ene, P. Lafourcade, and
Y. Lakhnech. Towards automated proofs for asymmet-
ric encryption schemes in the random oracle model. In
15th ACM Conference on Computer and Communica-
tions Security, CCS 2008, pages 371–380, 2008. ACM.

[19] D. Dolev and A. Yao. On the security of public key
protocols. IEEE Transactions on Information Theory,
29(2):198–208, 1983.

[20] E. Fujisaki, T. Okamoto, D. Pointcheval, and J. Stern.
RSA-OAEP is secure under the RSA assumption. J.
Cryptology, 17(2):81–104, 2004.

[21] S. Goldwasser and S. Micali. Probabilistic encryption.

J. Comput. Syst. Sci., 28(2):270–299, 1984.

[22] R. Impagliazzo and B. M. Kapron. Logics for reasoning
about cryptographic constructions. J. Comput. Syst.
Sci., 72(2):286–320, 2006.

[23] T. Kleinjung, K. Aoki, J. Franke, A. Lenstra,
E. Thom´e, J. Bos, P. Gaudry, A. Kruppa, P. Mont-
gomery, D. Osvik, H. te Riele, A. Timofeev, and P. Zim-
mermann. Factorization of a 768-bit RSA modulus. In
Advances in Cryptology – CRYPTO 2010, volume 6223
of LNCS, pages 333–350, 2010. Springer.

[24] Y. Komano and K. Ohta. Taxonomical security consid-
eration of OAEP variants. IEICE Transactions, E89-A
(5):1233–1245, 2006.

[25] A. K. Lenstra and E. R. Verheul. Selecting crypto-

graphic key sizes. J. Cryptology, 14(4):255–293, 2001.

[26] T. Okamoto and D. Pointcheval. The gap-problems: A
new class of problems for the security of cryptographic
schemes.
In 4th International Workshop on Practice
and Theory in Public Key Cryptography, PKC 2001,
volume 1992 of LNCS, pages 104–118, 2001. Springer.

[27] A. Perrig and D. Song. Looking for diamonds in the
desert – extending automatic protocol generation to
three-party authentication and key agreement proto-
cols.
In 13th IEEE Workshop on Computer Security
Foundations, CSFW 2000, pages 64–76, 2000. IEEE
Computer Society.

[28] A. Roy, A. Datta, A. Derek, and J. C. Mitchell. Induc-
tive trace properties for computational security. Journal
of Computer Security, 18(6):1035–1073, 2010.

[29] V. Shoup. Sequences of games: a tool for taming com-
plexity in security proofs. Cryptology ePrint Archive,
Report 2004/332.

[30] D. Unruh. The impossibility of computationally sound

XOR. Cryptology ePrint Archive, Report 2010/389.

[16] J.-S. Coron, M. Joye, D. Naccache, and P. Paillier. Uni-
versal padding schemes for RSA. In Advances in Cryp-
tology – CRYPTO 2002, volume 2442 of LNCS, pages
226–241, 2002. Springer.

[31] Y. Zheng and J. Seberry. Practical approaches to at-
taining security against adaptively chosen ciphertext
attacks. In Advances in Cryptology – CRYPTO 1992,
volume 740 of LNCS, pages 292–304, 1993. Springer.

1259

