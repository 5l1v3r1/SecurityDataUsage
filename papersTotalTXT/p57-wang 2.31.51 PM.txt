Seeing through Network-Protocol Obfuscation

Liang Wang

University of Wisconsin
liangw@cs.wisc.edu

Kevin P. Dyer

Portland State University
kdyer@cs.pdx.edu

Aditya Akella

University of Wisconsin
akella@cs.wisc.edu

Thomas Ristenpart

Cornell Tech

ristenpart@cornell.edu

ABSTRACT
Censorship-circumvention systems are designed to help users by-
pass Internet censorship. As more sophisticated deep-packet-
inspection (DPI) mechanisms have been deployed by censors to de-
tect circumvention tools, activists and researchers have responded
by developing network protocol obfuscation tools. These have
proved to be effective in practice against existing DPI and are now
distributed with systems such as Tor.

In this work, we provide the ﬁrst in-depth investigation of the
detectability of in-use protocol obfuscators by DPI. We build a
framework for evaluation that uses real network trafﬁc captures to
evaluate detectability, based on metrics such as the false-positive
rate against background (i.e., non obfuscated) trafﬁc. We ﬁrst
exercise our framework to show that some previously proposed
attacks from the literature are not as effective as a censor might
like. We go on to develop new attacks against ﬁve obfuscation
tools as they are conﬁgured in Tor, including:
two variants of
obfsproxy, FTE, and two variants of meek. We conclude by using
our framework to show that all of these obfuscation mechanisms
could be reliably detected by a determined censor with sufﬁciently
low false-positive rates for use in many censorship settings.

Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]: General—Secu-
rity and protection

Keywords
Censorship-resistance; network obfuscation; Tor

1.

INTRODUCTION

Nation-states and other Internet censors use deep-packet inspec-
tion (DPI) to detect and block use of circumvention tools. They do
so by recognizing the tools’ protocol headers or other telltale ﬁnger-
prints contained in application-layer content of network packets. In
response, researchers and activists have proposed a large number of
approaches for obfuscating the network protocol being used. These
obfuscation tools can be loosely categorized as either attempting to

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813715.

Thomas Shrimpton
University of Florida

teshrim@cise.uﬂ.edu

randomize all bytes sent on the wire [39, 40, 48, 52], attempting to
look like (or mimic) an unblocked protocol such as HTTP [12, 26,
45,46], or tunneling trafﬁc over an implementation of an unblocked
protocol [42]. Examples of network obfuscators from each of these
three classes are now deployed as Tor pluggable transports [3] and
with other anti-censorship tools [44, 48]. Currently, the available
evidence indicates that existing DPI systems are easily subverted
by these tools [12], and that nation-state censors are not currently
blocking their use via DPI [43]. Thus these systems provide
signiﬁcant value against today’s censors.

Can censors easily adapt and deploy new DPI algorithms that
accurately detect these protocol obfuscators? Houmansadr et
al. [16] proposed a number of attacks for detection of mimicry
obfuscators, but they do not measure false-positive rates. It may
be that their attacks are undeployable in practical settings, due to
labeling too many “legitimate” connections as emanating from an
anti-censorship tool. What’s more, the randomizing and tunneling
obfuscators, which are the most widely used at present [43],
have not been evaluated for detectability at all. (Despite folklore
concerns about possible approaches [42].) In short, no one knows
whether these obfuscators will work against tomorrow’s censors.

In this work, we provide the ﬁrst in-depth, empirical investiga-
tion of the detectability of modern network protocol obfuscators,
and of the collateral damage to real network trafﬁc due to false
positives. Our results suggest that all of the in-use protocol
obfuscation mechanisms can be reliably detected by methods
that require surprisingly little in the way of payload parsing
or DPI state. See Figure 1 for a summary of our best-performing
attacks against Tor’s pluggable transport obfuscators.

To obtain these results, we built a trace analysis framework and
exercised it with a variety of datasets. Prior attack evaluations [12,
16] have focused primarily on small, synthetic datasets generated
by a researcher running a target tool in a speciﬁc environment, and
evaluating true-positive and false-negative rates of a certain attack.
As mentioned above, this may lead to over-estimation of tool
efﬁcacy in practice: actual false-positive rates may be prohibitively
large, and the synthetic traces used in the lab evaluations may be
unlike the network traces seen in real environments. We address
both of these issues by employing an experimental methodology
that more closely reﬂects the setting of nation-state level DPI.

We collected nearly a terabyte of packet traces from routers
associated to various networks at our university campus. Together
these have about 14 million TCP ﬂows. Given the size of the
covered networks (ﬁve /16 networks and three /24 networks), this
represents a large, diverse dataset suitable for assessing false posi-
tives. We supplement with researcher-driven traces of obfuscation
tools (which do not appear in the traces already), collected across a
number of client environments.

57Type

Attack

Obfuscator
obfsproxy3 Randomizer entropy + length
obfsproxy4 Randomizer entropy + length
FTE
meek-amazon Tunneling
meek-google Tunneling

Mimicry URI entropy/length 1.0 0.00003
0.98 0.0002
0.98 0.00006

TPR FPR
1.0 0.002
1.0 0.002

decision tree
decision tree

Figure 1: Summary of best-found attacks against the network
obfuscators deployed as Tor pluggable transports. TPR is the true-
positive rate; FPR is the false-positive rate as measured using real
network traces from a university campus.

Using these datasets, we explore previously proposed DPI-based
attacks against obfuscation systems and develop new ones. To
begin, we evaluate a collection of semantics-based attacks, which
attempt to detect a mimicry obfuscator by looking for deviations
from expected behavior of the cover protocol. This type of attack
was recently introduced by Housmansadr et al. [16]. Next, we
explore entropy-based attacks, which seek to detect when network
packet contents (in whole, or in part) appear to be encrypted.
encryption may be in whole, or in speciﬁc parts where non-
obfuscated ﬂows would not be. Finally, we examine machine-
learning-based attacks. These use decision trees that are trained
from traces of both obfuscated and non-obfuscated trafﬁc. Some
of the features used were inspired by suggestions by the meek
designers [42], but we are the ﬁrst to build full attacks and evaluate
them. Our investigations reveal that:
•

Semantics-based attacks can sometimes have prohibitive false-
positive rates (up to 37% in the case discussed in §4.1). False
positives here arise because many non-censorship tools devi-
ate from standards in ways similar to mimicry protocols. In
these cases they are unlikely to be useful by censors. We also
show that other semantics attacks, including one suggested
in [16], have relatively low false-positive rates (0.03% as in
§4.2).

•

• Randomizers such as obfsproxy [40], which only emit ran-
dom payload bytes, are reliably detected by a combination of
entropy-based tests and simple heuristics (e.g. length checks).
In particular, these tests are applied only to the beginning of
the ﬁrst packet payload. This attack abuses the distinction
between conventional protocols’ plaintext headers and the
lack of same in randomizing obfuscators.
In short, having
“no ﬁngerprint” is itself a ﬁngerprint (§5.1).
Format-transforming encryption (FTE), as currently deployed
in Tor, is reliably detected by simple tests on the entropy
and length of the URI appearing in the ﬁrst FTE-produced
packet (§5.2).

• Tunneling protocols such as meek [42], broadly considered
the most secure current proposal for protocol obfuscation,
are reliably detected by classiﬁers trained on trafﬁc-analysis
and entropy features (§6). The trained classiﬁers are simple
decision trees, and do require the DPI to maintain state for the
ﬁrst part of a ﬂow.

In summary, our analyses show how to reliably detect all of the
currently deployed Tor pluggable transports. For example, our
testing reveals that we can detect 100% of obfsproxy3/obfsproxy4
traces using just the ﬁrst packet in the ﬂow, and with false-positive
rate of 0.2%.

A false-positive rate of 0.2% is likely to still be considered
prohibitively high for some censors. In particular, since the base-
rate of obfuscator-produced trafﬁc is dominated by that of non-
obfuscated trafﬁc, the vast majority of ﬂows that are tagged as
obfuscated will in fact be false positives.
In the near term,

false positive rates could be improved via white-listing of speciﬁc
protocols. In addition, more robust and expensive tests on tagged
trafﬁc such as the active probing techniques used by the Great
Firewall [51] could be used to achieve a false positive rate of
essentially zero. Using our network trace data sets, we give a
preliminary analysis of the expected burden such secondary checks
would impose on a censor’s infrastructure (§6.2). Nevertheless,
evidencing negligible false positive rates in realistic deployment
settings remains an important challenge for future work.
Summary and discussion. We are the ﬁrst to provide an in-depth
analysis of attacks against modern network protocol obfuscation.
We quantify, for the ﬁrst time, the false-positive rates of previously
proposed attacks, as well as ones that we introduce. To do so we
use real network trafﬁc like what censors would see in practice.
The framework for this analysis, while built mostly off existing
open-source tools (e.g., Bro, MySQL, etc.)
required signiﬁcant
engineering effort to handle the scale of our analyses. We will open
source and make public the framework for other researchers to use.
The university network captures cannot be released.

Our results suggest that censors can easily adapt their current
tools to efﬁciently detect state-of-the-art network obfuscators. New
obfuscators could, in turn, easily defeat the speciﬁc tests that we
propose. Under current knowledge, whichever of the censor or
protocol obfuscator can adapt to the other will have the upper
hand in protocol (mis)classiﬁcation. Developing practical, network
obfuscation mechanisms that are robust to adaptation by the DPI
remains a compelling open problem of practical import.

2. BACKGROUND
Censorship. Nation-states and other organizations assert control
over Internet communications by blocking connections to websites
based on IP address, application-layer content of packets, active
probing of remote servers, or some combination of the preceding.
For a more ﬁne-grained taxonomy of attacks see [16].

IP ﬁltering is a commonly-used censorship technique. Here
the censors monitor a list of IPs and block all communications
whose source or destination IP that belongs to the list. IP ﬁltering
can be deployed in border ASes or local ISPs by nation-states
censors [53]. To bypass IP ﬁltering, a simple method is to use
anonymous proxies. By deploying proxies outside the censored
network, users within the censored network can submit trafﬁc
past censors to the (unﬁltered) proxy IP. Various proxy-based
censorship circumvention systems have been developed such as
freegate, Ultrasurf and JonDo. Tor [11], an onion routing system,
helps circumvent IP-based ﬁltering due to its use of a large number
of proxies (and bridges). A more recent proposal is to use domain
fronting, in which one sends trafﬁc through an unwitting reverse
proxy [42].

In addition to ﬁltering by IPs, and partly because of the bur-
den of maintaining an exhaustive and accurate list of proxy IP
addresses, censors have increasingly also deployed deep packet
inspection (DPI) techniques. This enables censors to attempt
protocol identiﬁcation: inspecting the application-layer content of
packets (e.g., application-layer headers) as well as packet size or
timing information, in order to classify the trafﬁc as generated by
communication protocols associated with an anti-censorship tool.
In the past, Tor trafﬁc itself contained unique application-layer
ﬁngerprints patterns that can be recognized by DPIs [51]. In this
work we focus primarily on DPI-based censorship.

A ﬁnal class of protocol identiﬁcation attacks uses active probing
of a remote server. The Great Firewall of China, for example, is
known to attempt Tor handshakes with destination IP addresses

58should a DPI test ﬂag a ﬂow to that IP as possibly emanating from
a Tor client [51]. We will consider an active attack brieﬂy in §4.2,
and also in consideration of ﬁltering out a (passive) DPI test’s false
positives (§6.2).
Network protocol obfuscation.
In response censors’ efforts to
carry out protocol identiﬁcation, researchers have developed a
number of approaches to protocol obfuscation. In large part, the
goals have been to force DPI to misidentify ﬂows of a censored
protocol as those of a protocol that is not blocked, or to prevent
DPI from recognizing the ﬂows’ protocol at all. The latter helps
in the case that censors do not block unidentiﬁed ﬂows. Suggested
obfuscation techniques roughly fall into three categories:
• Randomizers: A randomizing obfuscator aims to hide all
application-layer static ﬁngerprints, usually by post-processing
trafﬁc with an obfuscation step that emits only bits that are
indistinguishable from random ones. Examples are Dust [48],
ScrambleSuit [52], and the various versions of obfsproxy [40,
54]. The last are currently deployed with Tor.

• Protocol mimicry: A mimicry obfuscator attempts to produce
trafﬁc that looks to DPI as if it were generated by some
“benign” protocol, also called the cover protocol. One
example of light-weight mimicry is format-transforming en-
cryption (FTE) [12, 24], now deployed with Tor and imple-
mented elsewhere [44].
It encrypts messages to produce
ciphertexts that match regular expressions commonly used
by DPI for identifying protocols. Less efﬁcient obfuscators
like Stegotorus [46], SkypeMorph [26], CensorSpoofer [45]
and Marionette [13] use heavier steganographic techniques to
produce messages that look like a cover protocol. Marionette
also provides mechanisms to mimic higher-level protocol
behaviors, to perform trafﬁc shaping, and to protect against
some forms of active attacks.
Tunneling: A logical extreme of mimicry is to simply tunnel
data over a (typically encrypted) cover protocol. Intuitively
this should provide best-possible mimicry as one is, in fact,
using an existing implementation of the cover protocol. An
example now deployed with Tor is meek, which uses domain
fronting and tunnels trafﬁc over HTTPS connections to popu-
lar cloud load balancers such as Google (we will refer to this
as meekG) and Amazon (meekA).

•

As mentioned, several of these are now in-use with Tor as pluggable
transports (PTs). A PT is just Tor’s terminology for an obfuscator
that works in their framework to obfuscate the trafﬁc between Tor
clients and bridges [3].

Available evidence indicates that the currently deployed obfus-
cators are able to circumvent deployed DPI systems [12, 43]. The
main question we address is: Can censors easily adapt their DPI
to detect and block obfuscators, without also blocking a signiﬁcant
fraction of non-obfuscator trafﬁc?
Unobservability. Houmansadr et al. [16] suggest that protocol-
mimicry obfuscators will not foil future censors because they do
not provide (what they refer to as) complete unobservability. They
informally deﬁne the latter to be achieved only when a mimicry
obfuscator faithfully follows the standards of the target protocol,
in addition to imitating all aspects of common implementations.
They give a number of DPI-based detection techniques for mimicry
obfuscators and show that these have few false negatives (missed
obfuscated ﬂows) and high true positives (correctly identiﬁed
obfuscated ﬂows) using synthetic trafﬁc generated by the re-
searchers. Their attacks target semantic mismatches between
obfuscated trafﬁc and the cover protocol, for example checking for

valid application-level headers for ﬁles, that header values such as
length ﬁelds are correct, etc.

These semantics-based attacks have not, however, been assessed
in terms of false positives:
a ﬂow that is labeled as having
been obfuscated but was actually not generated by the targeted
anti-censorship tool. A high false-positive rate could make such
attacks less useful in practice, since it may lead to blocking too
many “legitimate” connections or overwhelm systems performing
additional checks after the DPI ﬁrst labels a ﬂow as obfuscated,
as in the case of the Great Firewall’s secondary active probing
mentioned above.
In fact, as we mentioned earlier, there are
realistic settings in which a false-positive rate that seems small (e.g.
0.2%) may be troublesome for censors.

Thus a question left open by this prior work is: Do the semantics-
based attacks proposed in [16] have prohibitively high false-
positive rates? Clearly a negative answer would help us answer
our main question above, but, as we will see, some semantics-based
attacks do not work as well as a censor might like.
Threat model, scope, and approach.
In the rest of this paper,
we focus on answering the two questions just posed. We will
adopt the viewpoint of a censor, and attempt to build efﬁcient
algorithms that reliably and accurately detect network ﬂows that
have been produced by obfuscators. Our primary consideration
will be for obfuscators deployed as Tor pluggable transports, since
these are in wide use. These are: obfsproxy3 and its successor
obfsproxy4, the Tor pluggable transport version of FTE, meek
using Google AppEngine proxies (called meekG), and meek using
Amazon CloudFront proxies (called meekA).

A handful of other obfuscators will be considered, although less
deeply, in order to address the open question from [16]. For ex-
ample, we will investigate false-positive rates for the Houmansadr
et al. detection attacks for Stegotorus, even though Stegotorus
currently is unsupported and unusable with Tor. We are aware that
we evaluate only a very small fraction of proposed attacks for other
obfuscators, and we would like to investigate more attacks in the
future. However, the few attacks we considered give useful insights
into developing efﬁcient attacks.

Our study is restricted to the efﬁcacy of existing obfuscators.
As such, we assume that the IP address, port number, and trafﬁc
features that existing obfuscators do not attempt to hide are out
of scope. Network-visible information that one or more existing
obfuscators do attempt to hide, including application layer content,
packet timing, and packet lengths may be leveraged in attacks.

3. ANALYSIS FRAMEWORK AND DATA

We implement a framework for empirical analysis of obfuscator
detection techniques. It will leverage two groups of datasets: the
ﬁrst is a collection of network packet traces collected at various
locations at our university at different points in time, and the second
is synthetic trafﬁc generated by target obfuscators.

We use our packet traces to examine false positives in existing
proposals for attacking censorship circumvention systems, as well
as in the new attacks we propose in this paper. We use the synthetic
packet traces to study true-positive rates of the new attacks.

We start by providing details of the two sets of data and then

discuss the analysis framework.
3.1 Datasets

We use two major types of datasets:

(1) packet-level trafﬁc
traces collected at various locations in a campus network, and (2)
packet-level traces for Tor Pluggable Transport trafﬁc collected in
controlled environments.

59Size (GB)

Collection year
2014
Deployed PTs Obfs3/FTE/meek
389
1.89
1.22
37.0
45.3
0.2
17.5

OfﬁceDataset CloudDataset WiﬁDataset
2010
-
446
13.17
5.32
76.6
12.9
0.1
10.4

2012
-
239
9.34
7.48
73.6
5.4
0.2
20.8

Total ﬂow No. (M)
TCP ﬂow No. (M)
TCP-HTTP (%)

TCP-unknown (%)

TCP-SSL/TLS (%)

TCP-other (%)

Table 2: A summary of campus network datasets and breakdowns
of TCP ﬂows by services.
“TCP-other” are ﬂows with non-
HTTP/SSL/TLS protocols. “TCP-unknown” are ﬂows of which
protocols are failed to identiﬁed by Bro. “Deployed PTs” shows
the Tor pluggable transports that had been deployed by the time we
collected the traces.

Campus network traces. Over a period of 43 hours between
Sep. 6, 2014 to Sep. 8, 2014, we monitored all packets entering
or leaving a /24 IPv4 preﬁx and a /64 IPv6 preﬁx belonging to our
university. In all, this resulted in 389 GB of network trafﬁc with
full packet payloads. The networks correspond to two different
academic departments within our campus. We call this dataset
OfﬁceDataset.

In addition, we employed two other campus network traces,
which we call CloudDataset and WiﬁDataset. These were collected
at earlier points in time. In particular, CloudDataset was collected
between June 26, 2013 and to June 27, 2013 (over a period of
24 hours), and contains all trafﬁc recorded between our entire
campus network and the public IP address ranges published by
EC2 and Azure. The dataset WiﬁDataset constitutes all packets
captured over a period of 12 contiguous hours in April 2010 from
roughly 1,920 WiFi access points belonging to our campus.
It
contains data exchanged between all wireless clients (e.g., laptops
and smartphones) connected to the campus wireless networks and
other (internal or external) networks. A summary of these three
datasets is shown in Table 2.

The most recent trace could, hypothetically, contain ﬂows cor-
responding to actual use of Tor with the obfuscators turned on. In
our analyses, we ignore this possibility and assume that all trafﬁc is
non-obfuscated. Given that these ﬂows are only used to assess false
positives (FPs), our assumption is conservative when we argue the
FP rates are low.

These traces contain potentially sensitive information of network
users. We obtained an IRB exemption for these analyses. We
performed analysis on an isolated cluster with no connectivity to
the Internet, and with suitable access controls so that only approved
members of the research team were able to use the systems. Only
the bare minimum of research team members were approved to
access the machines.
Tor traces. A Tor trafﬁc trace captures the network trafﬁc
exchanged when a client visits a website over Tor conﬁgured to use
a speciﬁc obfuscator. To collect a trace, we follow the procedures
for collecting traces for website ﬁngerprint attacks as described
in [19]. We built a framework to automate these procedures.
Our framework uses the Stem Python controller library for Tor,
and the Selenium plugin for automating control over a Firefox
Browser when visiting websites [37, 41].1 We record all trafﬁc
using tcpdump (or WinDump on Windows) at the same time.
1Also, our Firefox browser uses the exact same proﬁles as the
default browser in the Tor Browser bundle (TBB) 4.06. The
versions of obfuscators and Tor we used are also the same as those
being used in TBB 4.06.

Before and after visiting a website, our framework visits the
“about:blank” webpage and dwells there for 5–15 seconds. The
ﬁrst time this is done is to ensure that the obfuscator connection
is fully built; in our experiments, we found that most obfuscators
forced a few seconds (usually less than 5 seconds) delay when
building connections after Tor starts successfully. The second visit
to “about:blank” is for making sure we can capture any lingering
packets.

We collected three sets of Tor traces under different com-
binations of network links (with different capacities), end-host
hardware, and operating systems, and labeled them as TorA, TorB
and TorC. We collected TorA and TorB on Ubuntu 12.04 (32-bit)
virtual machines (VMs) and TorC on a Windows 7 (32-bit) virtual
machine. The Ubuntu VMs are built on the same image. All VMs
run on VirtualBox 4.3.26 and are conﬁgured with 4G RAM and 2
virtual processors. The VMs for TorA run on a workstation and are
connected to a campus wired network, whereas the VMs for TorB
and TorC are run on a laptop and connect to a home wired network,
Each of these three datasets contains 30,000 traces collected as
follows: (1) For each target obfuscator, we used our trace collection
framework to visit Alexa Top 5,000 websites to collect 5,000 traces
(labeled as obfs3, obfs4, fte, meekG, and meekA, corresponding
to obfsproxy3, obfsproxy4, FTE, meek-google, and meek-amazon
respectively); (2) In addition, we visited the same set of websites
without Tor and obfuscators to collect 5,000 traces and labeled
them as nonTor.

A handshake message of a ﬂow is the application-layer con-
tent of the ﬁrst client-to-server packet in the ﬂow. We extract
5,000 handshake messages from each of obsproxy3, obfsproxy4,
SSL/TLS, HTTP, and SSH ﬂows to construct a new dataset. The
ﬁrst two types of ﬂows are sampled randomly from Tor datasets
and the other types of ﬂows are from unused campus network
traces (recall that we only use a part of the collected campus
network traces to construct the campus datasets). We call this
dataset HandShakeDataset and use it when examining attacks
based (only) on handshake messages.
3.2 Trace Analysis

We use Bro 2.3.2 [31] with the “-r” option to analyze the
collected network traces, and format and store the results into
MySQL tables. Each table corresponds to a “.log” ﬁle generated
by Bro, and it stores the information for ﬂows of a given type
(UDP, HTTP, SSL, etc.). Each ﬂow is assigned an unique ﬂow
ID, which is also generated by Bro. Also, for each trace packet,
we compute an MD5 hash to generate a packet ID, and store
the packet ID, the ﬂow ID of the associated ﬂow, the raw packet
content (in hexadecimal) and the packet timestamp into an Apache
Hive database [38]. The usage of Hive facilitates the management
and processing of terabytes of data. Users only need to query
the MySQL database to get the basic statistics of a trace, while
using Hive for more time-consuming, sophisticated analysis such
as analyzing packet payloads.

We develop a set of APIs to analyze the above data. These
APIs are encapsulations of Hive or MySQL queries. For some
simple analyses (e.g, counting the packets with a given keyword
in the payload), pure Hive queries are enough. To facilitate more
complex analysis and provide more ﬂexibility, we leverage User-
Deﬁned Functions (UDFs) in Hive to allow users to provide their
own mapper/reducer scripts [2]. We plan to release all our scripts
publicly for other researchers or activists to use.

60Other

Standard Malformed Partial
OfﬁceDataset
26 (89.7)
3 (10.3)
CloudDataset 4,293 (62.8) 1,313 (19.2) 338 (4.9)
WiﬁDataset 1,860 (46.7) 1,252 (31.5) 572 (14.4)

6,839
3,979
6,182 (57.0) 2,565 (23.6) 913 (8.4) 1,190 (11.0) 10,847
Table 3: Breakdown of PDFs by their categories. The percentages
of all PDFs found are shown in parentheses.

895 (13.1)
295 (7.4)

Total
29

Total

0

0

4. SEMANTICS-BASED ATTACKS

We seek to determine whether in-use obfuscators can be reliably
detected by censors. The starting point is previously proposed
attacks. As described in §2, Houmansadr et al. suggest a variety
of attacks against mimicry obfuscators. For example, a Stegotorus
client may generate invalid PDF documents, whereas legitimate
trafﬁc presumably does not.
Their attacks therefore use the
deviations of a target system from expected behavior as evidence
for detecting mimicry obfuscators. We call these attacks semantics-
based attacks.

In this section, we evaluate three semantics based attacks,
two proposed by Houmansadr et al. against Stegotorus and one
suggested by Dyer et al. [12] for detecting FTE. None of these
attacks have been evaluated in terms of false positives, and the latter
has not received any analysis at all. Looking ahead, we ﬁnd that the
ﬁrst attack is unlikely to work well in practice due to the high false-
positive rates we discover. The other two work better, but have
deﬁciencies that our later attacks avoid.
4.1 Stegotorus PDF attack
Description. The Stegotorus HTTP obfuscator attempts to hide Tor
trafﬁc in commonly-seen documents, such as PDF and JavaScript.
However, StegoTorus-HTTP does not guarantee the semantic cor-
rectness of the generated ﬁle. The authors in [16] proposed an
attack that can detect ﬁles (more speciﬁcally, PDF ﬁles) generated
by StegoTorus at a low cost and line speed. The key idea is to check
the validness of the xref table in a PDF ﬁle.

Clearly the efﬁcacy of this attack relies on the assumption that
PDFs generated by non-obfuscated trafﬁc, e.g., normal HTTP,
indeed has valid xref
tables. This was not evaluated in [16],
presumably due to a lack of access to real trafﬁc.

For an HTTP ﬂow, we use a Python library pyndis to reassemble
HTTP sessions. If the Content-Type in the response of a session is
“application/pdf”, we assume the response body is a PDF ﬁle. We
extract the content from the response, store the content as a PDF
ﬁle, and use the PyPDF2 library to test the semantic correctness of
the ﬁle. We deﬁne four categories of PDFs:
•

Standard: According to [17], a standard PDF ﬁle should
start with “%PDF” and end with “%%EOF”, and have a xref
keyword in the content. The PDFs in this category have these
keywords and also pass the PyPDF2 semantic check.

•

• Malformed: The PDFs have “%PDF”, “%%EOF” or xref
keywords (at least one keyword), but do not pass the PyPDF2
semantic check.
Partial: A request may have a Range ﬁeld that speciﬁes the
parts of a PDF ﬁle the client wants (e.g., only request the ﬁrst
200 bytes of a ﬁle). The PDFs carried by the HTTP response
of which status code is “206 Partial Content” is “partial PDF”.
The PDFs in this category will not pass the semantic check
because they are only parts of the original PDFs.

• Other: All PDFs that are not in the aforementioned three
categories. The PDFs in this category do not pass the
semantic check.

Request
GET long

GET non-existing
HEAD existing

OPTIONS common
DELETE existing

TEST method

GET wrong protocol

None
3
2
2
3
3
4
24

200
3xx
12 < 1
18 < 1
95 < 1
82 < 1
72 < 1
66 < 1
10
33

4xx
83
79
2
13
21
19
28

5xx Other
0
< 1
< 1
< 1
< 1
< 1
< 1

2
1
1
2
4
10
5

Table 4: Percentage of Alexa top 10 K servers that return a
given type of response for each type of request (rounded to the
nearest whole percent). The bolded entries indicate the standard
response(s) for a given request type.

We ﬁnd in our tests these four categories are mutually exclusive.
Only the PDFs in Standard can pass the PyPDF2 semantic check,
and the PDFs in other categories could not pass the test for different
reasons.
Results. We performed the test described above on the Ofﬁce-
Dataset, CloudDataset and WiﬁDataset university capture datasets.
As shown in Table 3, the false-positive rate can be as high as 43%
across all the datasets, should the censor mark any non-standard
PDF ﬂow as Stegotorus, as per the suggestion in [16]. More
restrictive checks would still have high false-positive rates.

To explain these results, we observe that there are many reasons
that non-obfuscator PDFs fall into Malformed or Other category.
For instance, the ﬁle is encoded or encrypted, or there are bugs in
the PDF generation software [21]. Partial content is also widely
used by browsers and applications. As an example usage, FireFox
will build several connections to fetch different parts of a single
resource with range request in parallel, and reconstruct the resource
by itself. The PDF content in each connection is incomplete,
so a censor could not directly do semantics checks. A similar
technique is called Byte Serving [22]. An application can retrieve
the necessary portion of a ﬁle instead of the entire ﬁle. For example,
a byte-serving-enabled PDF viewer can request and load a large
PDF ﬁle from a ﬁle server page by page (“page on demand”). If a
user only reads a few pages, the censorship system will never see
the whole ﬁle.
4.2 HTTP response ﬁngerprinting attack
Description.
the authors suggest that a censor can
ﬁngerprint a StegoTorus server by observing the server’s reactions
to different types of HTTP requests, since the StegoTorus server
would respond differently from a genuine HTTP server. Of course
HTTP servers in practice may have various implementations and
it’s possible that the HTTP servers used by real websites have the
same HTTP-response-based ﬁngerprint as the StegoTorus server.
This would lead to false positives.

In [16],

We reverse-engineered httprecon, the tool used for ﬁngerprinting
HTTP servers in [16]. We wrote our own version, a Python script
that sends the same set of requests. One exception to this is that
we omitted a particular request that is often viewed as an attack
by server operators, as we used the scanner with public servers
and therefore could only send non-malicious requests.2 We used
our implementation to scan each of the Alexa top 10 K domains
to quantify false-positive rates. For each target server, we stored
its response header for each request into a MySQL database for
analysis. We removed the servers that fail to respond to the GET
existing request or respond with non-200 code, which may indicate
the corresponding websites are down, and got 9,320 servers.

2This was not an issue in [16] as they did not apply their scanner to
public servers.

61Results. Table 4 shows the percentages of servers that return a
given type of response for each type of request. The responses
are put into six categories, with boldface indicating the standard
response (as described in [16]) for a given type of request. Since
GET existing requests always receive a “200 OK” for the servers
examined, we remove the corresponding row from the table. We
can see that for some types of requests, a majority but not all of the
target servers return standard responses. Only 73 servers (0.8%)
respond like a “standard” server.

Examining the response headers more closely, we observe that
the target servers do not follow standards in various aspects (other
than the response code):
•

•

•

For a GET existing request, a server should set the Connection
ﬁeld in the response to keep-alive. We ﬁnd of the response
headers of all the servers, 1,547 (17%) don’t have the Con-
nection ﬁeld, 6,503 (71%) are keep-alive and 1,126 (12%) are
Close.
For a TEST method request, a server should set Connection
ﬁeld to Close. However, we ﬁnd 1,408 (15%) responses have
no Connection ﬁeld, 5,572 (61%) are keep-alive, 1,823 (20%)
are Close, and 378 (4%) fail to respond.
For an OPTIONS common request, a standard server should
set the supported HTTP methods in the Allow line. We
ﬁnd 8,026 (87%) the responses don’t have this ﬁeld, only
844 (9%) return the standard supported methods (as deﬁned in
RFC), 45 (0.5%) return non-standard methods, and 266 (3%)
fail to respond. We observe a total of 36 unique non-standard
methods.

We ﬁnd only three servers that have the same HTTP-response
ﬁngerprint as Stegotorus, suggesting that the false-positive rate of
this active attack is quite low (or 0.03%).

We note that there are a total of 1,447 unique HTTP-response
ﬁngerprints. About 40% of these ﬁngerprints are shared by
more than 2 servers. The most-seen ﬁngerprint is shared by 845
servers (9% of all the servers examined). Looking ahead, one might
therefore update the Stegotorus server to have the same ﬁngerprint
as these servers, which will cause a false-positive rate of close to
10% and, moreover, ﬂag network ﬂows associated with 5 of the top
100 domains and 74 of the top 1 K domains.
4.3 FTE content-length attack
Description. One possible approach for detecting FTE, as dis-
cussed by the authors of [12],
is to check the correctness of
the Content-Length ﬁelds of an HTTP message (HTTP request
or HTTP response), since the HTTP message generated by the
currently used version of FTE has an invalid Content-Length ﬁeld
that is mismatched with the real length of the content.
Results. For an HTTP ﬂow, we use the same technique as we used
in the PDF attack to reassemble HTTP sessions. Then, we check
if the message has the Content-Length ﬁeld in a message, calculate
the length of the message body if it has the ﬁeld, and compare the
calculated length with the length speciﬁed in the Content-Length
ﬁeld. The false-positive rate is deﬁned as the number of sessions
with incorrect content length over the total number of sessions (in
percentage). The false-positive rates are 1.86%, 1.95% and 3.5%
for OfﬁceDataset, CloudDataset, and WiﬁDataset respectively.

Further examining the false positives, we ﬁnd 34.2% of them
are caused by early terminated connections, and 6.8% are caused
by Transfer-Encoding ﬁelds (which trumps any existing Content-
Length ﬁelds). More sophisticated checks could remove these false
positives. There are other reasons for such mismatches, including

extra control bytes added in the message body by some versions of
web browsers; non-ASCII characters in the content-body, and bugs
in web applications [15, 25].
4.4 Discussion

The semantics-based attacks we analyzed are relatively costly in
terms of performance, because they require ﬂow reconstruction (in
the ﬁrst and last case) or active probing (in the second case). The
active probing and FTE attacks have arguably low false-positive
rates, whereas the ﬁrst PDF analysis has a clearly prohibitively
large one. Based on our analysis of the three semantics-based
attacks, we suggest that semantics-based attacks should account for
the noisy, non-standards-compliant nature of the web.

5. ENTROPY-BASED ATTACKS

Entropy-based analyses have been used for various purposes
such as randomness testing, network anomaly detection, and trafﬁc
classiﬁcation [29,35,36,55]. As trafﬁc generated by the obfuscators
are encrypted, one expects them to have noticeably higher entropy
than conventional, unencrypted protocols (e.g., HTTP). Prior works
show that entropy tests can be effectively used to detect and cull
encrypted or compressed packets from network streams [47]. Their
goal was to speed up DPI analyses by avoiding such opaque
packets. One might expect that similar techniques could work
here, but we will need to adapt them to our setting of obfuscator
detection.

The obfsproxy methods directly apply encryption to every trans-
mitted message, thereby “randomizing” even the ﬁrst messages
sent. On the other hand, conventional encryption protocols like
TLS (or HTTPS) use handshake messages that typically contain
unencrypted data from small, ﬁxed sets of strings. Thus, the
entropy of initial messages may provide a reliable way to distin-
guish obfsproxy messages from normal trafﬁc. FTE also employs
encryption from the start, although ciphertexts are designed not to
look randomized. Nonetheless, the initial messages produced by
the FTE obfuscators (as currently deployed in the TBB) are HTTP
GET messages containing URIs that directly surface random-
looking bytes from an underlying encryption scheme. So both
the obfsproxy methods and FTE may admit detection by entropy-
based tests on their initial messages. We explore this conjecture in
a moment. First, let us explain the statistics we will use.
Shannon-entropy estimator. Let X = x1x2 ··· xL be a string
of L bytes, i.e., each xi ∈ {0, 1, . . . , 255} (where we map between
bytes and integers in the natural way). Let nj be the number of
times that the value j appears in X, and let pj = nj/L. Then
our estimate of the (byte-oriented) Shannon entropy is computed
i=0 pi log2 pi. Notice that the maximum value
of H(X) is 8 = log2 256, and this occurs when pi = 1/256
for all i. That means that the payload string X contains every
symbol in {0, 1, . . . , 255} an equal (positive) number of times.
Furthermore, we note that a string with only printable ASCII
characters will never have an entropy more than 6.6 = log2 95.
The entropy-distribution test.
The traditional Kolmogorov-
Smirnov (KS) two-sample test provides a tool for deciding whether
or not two sets of samples were drawn from the same distribution.
We use it to help us detect high-entropy byte sequences. As above,
let X be a string of L bytes. Fix an integer block size k > 0, deﬁne
B = (cid:98)L/k(cid:99), and write X = S0 || S1 || ··· || SB−1, where each
block Si is length k bytes (or possibly less for SB−1). We will
treat the sequence H(S0), H(S1), . . . , H(SB−1) as B samples
from some unknown distribution Dk over entropy values. The
second distribution we consider is the distribution of entropy values

as H(X) = −(cid:80)255

62when the underlying strings are uniformly random. We denote
this distribution by ˜Dk, and a method for calculating ˜Dk is given
in [47]. As shown,
the distributions under consideration are
parameterized by the block size k, whose value we will address
later.

For our entropy-distribution test, we compute the two-sample
KS-test3 for H(S0), H(S1), . . . , H(SB−1) and an equal-length
sequence of samples from ˜Dk, and observe the p-value of the
test. If the p-value is smaller than our chosen signiﬁcance-level of
α = 0.1, then the null hypothesis that Dk = ˜Dk is rejected, and we
conclude that the bytes are not uniformly distributed. Otherwise,
the test does not provide statistically signiﬁcant evidence for
rejecting the null hypothesis, and we conclude that the bytes are
uniformly distributed.4 Our choice of α = 0.1 was based on it
being commonly used as a less restrictive (than 0.5) signiﬁcance
level in hypothesis testing in other settings. Higher α would label
ﬂows as uniform less often, lower α the opposite. Looking ahead,
our experiments show that many choices of α around 0.1 would
achieve the same obfuscator detection accuracy.

5.1 Detecting Obfsproxy

(Our tests currently make no effort

We start by showing how to use the entropy-distribution test to
detect that a network ﬂow corresponds to one of the two obfsproxy
methods.
to distinguish
between obfsproxy3 and obfsproxy4.) As discussed above, we
will make use of the observation that randomizers like obfsproxy3
and obfsproxy4 encrypt all bytes in the ﬁrst message of a ﬂow.
Conventional encryption protocols such as TLS and SSH do not:
they have ﬁxed plaintext headers. We therefore apply the entropy-
distribution test to the ﬁrst 2,048 bytes of the ﬁrst client-to-server
packet’s application-layer contents.
If the length of a ﬁrst-seen
content is less than 2,048 bytes, we will just test on all the bytes
of the content. If the entropy-distribution test applied to these bytes
indicates that they are uniformly distributed we ﬂag the ﬂow as
obfsproxy.

First, based on the protocol speciﬁcations, the minimum payload
length for obfsproxy3 is 193 bytes. For obfsproxy4 it is 149 bytes.
Thus, we will check payload lengths for the ﬁrst packet and require
that the length be at least 149 bytes to be labeled as obfuscated. We
will couple this check with an entropy-based test.
We experiment with the entropy distribution test described above
for block sizes k ∈ {4, 8, 16, 32, 64}. We also considered two
kinds of alternative tests. First is the byte uniformity test, in
which we use a KS test with null hypothesis that the payload
byte values are uniformly distributed (which is different than the
entropy distribution test described above, where the null hypothesis
is that the distribution of entropy values match closely those that
one would get form a uniform distribution). We also consider
the truncated sequential probability ratio test (SPRT) from [47]
applied to payload byte values. This was used by [47] to detect
“opaque” trafﬁc (encrypted or compressed), and was shown to be
more powerful than the (plain) entropy-test in their setting. Please
see [47] for details of that test. We consider it for block sizes
of 8, 16, and 32 bytes. This gives us a total of nine tests, the
entropy distribution test with the ﬁve distinct block sizes, the byte
uniformity test, and the SPRT tests with three different block sizes.
In all cases we apply the payload length checks mentioned already.

3Using scipy.stats.ks_2samp [18].
4Technically, accepting the null hypothesis in this way should only
be performed when a test has sufﬁcient power. As we will see using
the test in this way performs well, and so we dispense with a power
analysis.

To evaluate these tests we proceeded as follows. We use stratiﬁed
random sampling (in our case we sample the same number of
traces of each of the type of trafﬁc) to select a 30% fraction of
the traces from HandShakeDataset to construct a validation set and
use the remaining 70% as a test set. Recall that HandShakeDataset
consists of 5,000 handshake messages for each of obsproxy3,
obfsproxy4, SSL/TLS, HTTP, and SSH ﬂows, meaning that we
have both obfuscated and un-obfuscated traces represented. We
discuss false positives on the university data sets below.

We use the validation set to pick the best performing of the nine
tests, and then analyze the test’s performance on the test set. We
repeat this procedure 10 times with fresh random splits of the test
sets. In all 10 iterations the best-performing test on the validation
set is the entropy distribution test with block size k = 8. Table 5
shows the results broken down by protocol types and including
for comparison the performance of some of the other tests on the
test set. The results are strong: the entropy distribution test with
k = 8 had only one false positive and zero false negatives in the
worst case. We note that the payload length checks are critical
here, we showed that SSL/TLS ﬂows had a false-positive rate of
roughly 23% on average when one omits the check. With the length
checks in place, however, the p-values computed during the entropy
distribution test for SSL, HTTP and SSH handshake messages are
always near zero (a deﬁnitive rejection of the null hypothesis),
whereas the median p-values for the ﬂows declared to be obfsproxy
is 0.99. Thus we consider the tests decisive.
False positive analysis using campus traces. The above analysis
of false positives was in a closed-world setting with just the
three protocol types (SSH/HTTP/TLS). We take the best test from
above and evaluate false positives against the network traces seen
from the university data sets. Speciﬁcally we apply the entropy
distribution test (with k = 8) on the ﬁrst packet of every TCP ﬂow
in OfﬁceDataset, CloudDataset, and WiﬁDataset (assuming the
packet is non-empty). We found 3,998 (0.33%), 19,247 (0.25%),
and 12,786 (0.24%) false positives, respectively.

According to Bro,

the 36,031 false-positive ﬂows were dis-
tributed as follows: 18,939 were SSL/TLS, 9,873 were HTTP,
and the remaining 7,219 ﬂows were reported as “unknown”. We
applied nDPI [28], an open source DPI that can detect hundreds
of application protocols, to the unknown ﬂows.
It was able to
classify 1,673 (23.1%) of these as follows: 1,275 were Real Time
Messaging Protocol (RTMP), 92 were SMTP, 14 were SSH, and
the remaining were generated by other various applications.

The false-positive SSL/TLS ﬂows account for 1.22% of all
SSL/TLS ﬂows examined, while the false-positive HTTP ﬂows ac-
count for 0.10% of all HTTP ﬂows examined. We ﬁnd the SSL/TLS
false positives are associated with 1,907 unique destination IPs, and
90% of these false positives are associated with only 685 unique
destinations. Therefore, a large fraction of these false positives
could be caused by speciﬁc server-side settings. Upon further
examination of the destinations in the latter mislabeled HTTP
ﬂows, we ﬁnd just 357 unique servers. The URLs of these servers
contain only printable ASCII characters but have the same entropy
proﬁle as a random string. The false-positive SSH ﬂows all have
encrypted handshakes, which suggests they may use obfuscated
SSH [23]. The handshake message of RTMP consists of a 1-
byte protocol version and a 1536-byte random string, causing our
embellished entropy test to label all RTMP ﬂows as positive.
5.2 Detecting FTE

As currently implemented in the Tor Browser Bundle,

the
ﬁrst message in an FTE ﬂow is an HTTP GET request. The
URIs in these requests also have large Shannon entropies because

63Entropy dist. test
Uniform byte test

SPRT (8-byte)
SPRT (16-byte)
SPRT (32-byte)

FNR

Obfs3 Obfs4
0
5.0
58.3
24.8
6.9

0
5.1
60.2
24.4
6.6

FPR
SSL HTTP
0.02
0
0
0
0
30.6
0
0.06
5.3
0

SSH
0
0
0
0
0

Table 5: A comparison of the average false-positive/false-negative
rates (in percentage) of different tests for obfsproxy handshake
message detection, across ten rounds of randomized validation/test
splits. While the entropy distribution test (only shown for k = 8)
was chosen in all ten rounds, we show the test-set performance of
the other style of tests for comparison. All these tests are performed
with the payload length check.

1

F
D
C

0.5

1

F
D
C

0.5

0

0

234

1,000

2,000

0

0

URI length

Figure 6: CDF of lengths (left) and entropies (right) of all URIs
extracted for three campus network datasets.

2
4
URI entropy

5.5

6

their characters are direct encodings of ciphertext bits into bytes.
Estimating the entropies of all URIs produced by FTE in 30%
of traces (randomly sampled) in HandShakeDataset, we ﬁnd a
relatively narrow range of 5.5 to 5.8 bits. In HandShakeDataset, for
non-FTE HTTP GET messages, the URIs always have entropies of
less than 5.1 bits. This leads to a simple URI-entropy test: if the
URI in the ﬁrst GET request of a HTTP ﬂow has entropy of at least
5.5 bits, then we label the ﬂow FTE.

Unsurprisingly, this test produces zero false negatives and zero
false positives against HandShakeDataset. We also evaluated
the URI-entropy test against OfﬁceDataset, CloudDataset, and
WiﬁDataset. For an HTTP ﬂow that contains GET requests, we
extract the URI from the ﬁrst of these, and perform the URI-entropy
test on it. We found a total of 420,795 URIs are mislabeled as FTE,
or about 4% of the roughly 10 M URIs examined.

To sharpen our test, we observe that the URIs in the HTTP
requests generated by FTE have a constant length of 239 bytes. So
we embellish our URI-entropy test so that positively labeled ﬂows
must also have a URI length of exactly 239 bytes. This signiﬁcantly
reduces the false-positive rate: only 55, 167, and 42 non-FTE ﬂows
are mislabeled as FTE in the OfﬁceDataset, CloudDataset, and
WiﬁDataset datasets, respectively. That is a total of just 264 false-
positives out of around 10 M samples, giving the embellished test a
very small false-positive rate.

Note that the above tests can in fact be implemented without
message reconstruction, since the tests only involve data in the ﬁrst
packet at ﬁxed locations.

We note that [8] suggests using FTE URI length alone for
detection. But we ﬁnd that a length-only test causes about a 15%
false-positive rate over the same 10 M ﬂows. The CDFs of URI
lengths and entropies are given in Figure 6.
5.3 Discussion

Our results show that entropy-based tests, embellished with
simple length heuristics, can accurately detect obfsproxy3/4 and

FTE with relatively low false-positive rates on real network trafﬁc.
White et al. [47] show that slightly simpliﬁed versions of our
entropy-based tests can be implemented on commodity hardware,
making them applicable at enterprise scale. The main simpliﬁca-
tion is that their tests make use of a ﬁxed-size string, whereas ours
use up to one full TCP payload. We have not yet considered the
efﬁcacy of our tests using truncated payloads.

We note that our entropy-based tests do not perform well
at detecting meek-generated trafﬁc, because meek tunnels over
HTTPS. To detect meek one will need more sophisticated attacks,
as shown in the next section. Finally, we point out that the entropy-
based tests in this section are far less resource-intensive than the
semantics-based attacks of §4. Those attacks in most cases require
ﬂow reconstruction, and these do not.

6. ML-BASED ATTACKS

Using machine learning (ML) for trafﬁc classiﬁcation is not a
novel idea [1, 5, 49], but we are unaware of any prior work that has
attempted its use in detecting obfuscated trafﬁc. In this section, we
develop attacks using ML with carefully selected features.

Our classiﬁcation model will be binary, with output labels
“positive” (obfuscated) and “negative” (not obfuscated). During
training, we will label all training traces that were generated
by a targeted obfuscator with “positive”, and all other traces as
“negative”. Thus we will have a classiﬁer for each obfuscator that
aims to distinguish a given obfuscator from all other trafﬁc. When
attempting to detect the use of any Tor pluggable transports, one
could run all of our tests in parallel (one targeting each obfuscation
method) and if any of them returns “positive” then the meta-
decision would be that Tor with some pluggable transport is in use.
Before describing the actual classiﬁers, let us discuss the features
that they will use, training considerations, and the details of how we
evaluated their efﬁcacy.
Features. Our ML-based attack will make use of three types of
features. The ﬁrst are entropy-based features. For a given ﬂow, we
calculate the Shannon entropy of every packet payload, and use the
maximum/minimum/average entropies in packets in each direction
(upstream or downstream) as features. The selection of this feature
is inspired by the results of the entropy-based tests in §5.

The second feature type is timing-based features, which are
based on an observation regarding trafﬁc patterns in meek. Ac-
cording to the documentation, meek clients will send packets to a
meek server periodically, to check if the server has data to send.
This results in timing patterns in the TCP ACK trafﬁc of meek
connections that differ from typical TLS connections [42]. To
capture this as a feature, we calculate the intervals between two
consecutive TCP ACK packets (in the same direction) in a ﬂow,
and group the intervals into 30 bins. Based on our observations
of meek trafﬁc, the intervals are usually very small: 55% of them
are less than 10 ms, and 99.9% are less than one second. So we
limit the maximum considered ACK interval to one second. We
use (x, y] to denote a bin of width y − x, accepting all numbers r
such that x < r ≤ y. (All numbers are milliseconds.) Across
our 30 bins, the widths are as follows: between 0 and 10 the
bin width is 1 (i.e., (0, 1], (1, 2], etc.), between 10 and 100 the
bin width is 10, between 100 and 1000 the bin width is 100, and
the ﬁnal bin is (1000,∞]. We use variable-width bins to balance
timing granularity and computational efﬁciency, and because the
interval distribution is skewed towards lower values.
Instead of
using absolute numbers, our per-bin feature is the percentage of
inter-ACK intervals that fall into a given bin.

64Finally, we consider packet-header features. The ﬁrst of these is
the percentage of TCP ACK packets sent in each direction. This is
motivated by the behavior of meek just discussed; we expect to see
a larger-than-normal number of TCP ACK packets in meek ﬂows.
The second follows previous works (e.g. [7, 30]) by exploiting
packet length as a distinguishing characteristic. For a given ﬂow,
we use the ﬁve most common packet-payload lengths (in each
direction) as a feature.
Windowing strategies. We will have two main goals for our
classiﬁers. The ﬁrst is to accurately detect all of the obfuscators
under consideration. The second is to detect obfuscated trafﬁc
as soon as possible within a ﬂow, which helps to minimize the
amount of state required. Based on our results for the entropy-
based tests, we can hope to classify some obfuscated ﬂows based
solely on the ﬁrst message. For meek, however, this seems unlikely
to work because meek leverages genuine TLS connections. So,
to accommodate both goals, we allow the classiﬁer to train over a
window of ﬂow trafﬁc. Inspired by [6, 20, 27], we consider two
windowing strategies:

(1)

(2)

The classiﬁer inspects the ﬁrst X packets of a ﬂow (including
SYN and ACK packets), and extracts features from these
packets to do classiﬁcation.
The classiﬁer extracts features from the packets within the
ﬁrst X seconds of a ﬂow to do classiﬁcation.

Examining the distributions of durations and sizes (number of
packets in a ﬂow) of all obfuscator traces collected, and considering
that we want the classiﬁer to be able to make a decision as soon
as possible, we limit the range of X in our tests as follows. For
the packet-count strategy, X ∈ {30, 35, 40, . . . , 300}, and for
the time-based strategy X ∈ {2, 3, 4, . . . , 10}.
Choosing the
endpoints for the packet-count strategy, we can hope to classify
between 90 and 99 percent of obfuscator ﬂows before they termi-
nate; simulating online classiﬁcation, as opposed to after-the-fact.
The same reasoning applies to the boundaries for the time-based
strategy.
Details of classiﬁer evaluation. Our initial measure of classiﬁer
performance uses the TorA, TorB, and TorC datasets. Recall that
these include both synthetic Tor traces under each of the pluggable
transports, as well as synthetic traces for SSL/TLS and HTTP.

For any given dataset, we perform nested cross validation with
ten outer folds and ten inner folds. We measure performance
for that dataset by taking an average over ten outer folds. In an
outer fold, we perform a stratiﬁed random sampling of the target
dataset to select 70% of the traces to create the test set, and use
the remaining 30% for training and validation of classiﬁers for the
inner folds.

Each inner fold is as follows: First, we perform a second
stratiﬁed random sampling, taking a one-third for training and
leaving the remainder for validation.5 Next, we ﬁx a classiﬁcation
strategy by choosing: classiﬁcation algorithm (K-nearest neighbor,
Naive Bayes, or CART), windowing strategy (number of packets
or time for each allowed X), and feature set (any single feature,
any pair of features, or all features). There are 1,344 different
classiﬁcation strategies, in total. For a given strategy, we train ﬁve
classifers, one for each of the obfuscators. Each of these is tested
on the validation set, and we record the average performance of

5There are perhaps more standard choices for the split sizes, but we
do not expect different choices to signiﬁcantly impact results. The
large test set size will tend to produce conservative estimations of
our classiﬁers’ performances.

the ﬁve classiﬁers. This gives an average measure for a particular
classiﬁcation strategy.

We pick the parameter combination that results in the classiﬁers
that perform best on average across all inner folds. Then, using the
“winning” classiﬁcation strategy, we ﬁnally train a new classiﬁer
using all traces from the training/validation portion. This ﬁnal
classiﬁer is what is tested on the test set.

As mentioned, we repeat the training and testing for 10 ran-
domized 70-30 outer folds, and we will report the averages over
these folds in a moment. In addition to reporting true-positive and
false-positive percentages, we will report area under the precision-
recall curve (PR-AUC) (c.f., [10]). A higher PR-AUC indicates a
higher true-positive rate and lower false-positive rate. Speciﬁcally,
a classiﬁer with PR-AUC equal to one is perfect: it gives only true
positives with no false positives. We calculate PR-AUC using the
scikit-learn tool [9].

Looking ahead, we will sometimes also report on the average
result of testing classiﬁers not chosen by the training/validation
regime in order to understand the beneﬁt of using, e.g., some
particular feature.

6.1 Results

We will ﬁrst analyze the performance of ML-based attacks using
the synthetic datasets, and then present the false-positive rates
seen on the campus traces. To summarize, the best classiﬁer
achieves a high average PR-AUC (0.987), a high average true-
positive rate (0.986), and a low average false-positive rate (0.003),
across all ﬁve obfuscators as measured on the same synthetic
data set it is trained on. The classiﬁers all perform signiﬁcantly
worse when tested on a synthetic dataset for which they were not
trained. Finally, the highest false-positive rate of any classiﬁer as
measured on the campus datasets (none of which were available
during training) is 0.65%.
Classiﬁer parameters. Using TorA, we found that the best-
performing classiﬁers were essentially always CART decision trees
using the packet-count windowing strategy. The best classiﬁers
used between 280 and 300 packets, which we consider too large
for practicality. However, classiﬁers using up to 30 packets already
perform within 0.3% PR-AUC of the best performing, and so we
from now on restrict our attention to them.
Feature performance. We next discuss how the different types of
features effect classiﬁer performance. Recall that we used entropy-
based, packet-timing, and packet-header features. In Figure 7 we
compare classiﬁer true positive and false positive rates when testing
speciﬁc combinations of features for the TorA dataset. We can
see that using only entropy-based and/or packet-header features
can already achieve high true positives and low false positives,
with pretty low variance across folds (indicated by the error bars).
Timing-based features showed a higher false-positive rate, and we
conclude that a combination of entropy-based and packet-heading
features performs best. Our training procedure indeed always
selected the combination of the entropy-based and packet-header
features.

Unexpectedly, entropy-based features work well for detecting
meek. Examining the number of packets with non-zero-byte
payload in the ﬁrst 30 packets of the meek traces and the SSL/TLS
traces in the Tor datasets, we ﬁnd 70% of SSL/TLS ﬂows have
more than 18 packets with non-zero-byte payload, whereas at least
96% of the meek traces have less than 18 packets with non-zero-
byte payload. So the number of samples for calculating entropy
statistics in a meek trace and a SSL/TLS trace are often different,
which biases the minimum, average, and maximum entropy scores

65E

T

H

EH

1

0.98

0.96

0.94

0.92

R
P
T

0.02

0.015

R
P
F

0.01

0.005

0

obfs3 obfs4
E

fte meekA meekG
T

EH

H

obfs3 obfs4

fte meekA meekG

Figure 7: A comparison of true-positive (top graph) and false-
positive (bottom graph) rates by features used.
“E” indicates
entropy-based feature, “T” the timing-based features, “H” the
packet header feature set, and “EH” indicates a combination of
entropy-based and packet-header features. Note that for clarity the
graphs have truncated y-axes.

used as features. This bias is caught by our classiﬁer to differentiate
between meek and SSL/TLS.
Portability. We now turn to testing the “portability” of this
ML approach. We used the two additional data sets TorB and
TorC, which are collected in environments distinct from that of
TorA. Whereas TorA is collected on an Ubuntu VM connected
to a campus network, TorB is an Ubuntu VM connected to a
home wireless network and TorC is a Windows VM connected
to a home wireless network. We build three distinct classiﬁers
using each of the three datasets using our procedure as above, but
now augmenting the testing phase to also test against a stratiﬁed
random sample of 70% of each of the other two datasets. The
resulting matrix of average true and false positive rates (across all
target obfuscators) is given in Table 8. The diagonal corresponds
to training and testing on the same environment, whereas scores
off the diagonal correspond to training and testing on different
environments.

As can be seen, the ML classiﬁers do very well when trained and
tested in the same environment. However, using the classiﬁers to
attempt to classify a network ﬂows generated by a distinct operating
system and/or network signiﬁcantly hinders performance. When
using the same operating system, but different networks (the
TorA/TorB and TorB/TorA entries) one sees less drastic reduction
in performance. Changing operating systems however has large
impact, with true positive rates being as low as 52% and false-
positive rates reaching 12%. This provides some evidence that
censors will indeed need to train classiﬁers on example traces
representing all of the target types for which they need to be
deployed.
False positives in campus traces. We ﬁnally turn to analyzing
false-positive rates of a classiﬁer trained with the methodology and
data above when faced with real, not synthetic, network traces.
We ﬁrst combine the TorA, TorB and TorC datasets and use the
combination to train and validate a classiﬁer. We perform stratiﬁed
randomized splits of 30% for training and 70% for validation,
train a classiﬁer for each obfuscator, and compute the PR-AUC on

TRAIN\TEST TorA
TorA
TorB
TorC

TorB

TorC

0.99 (0.002) 0.88 (0.01) 0.52 (0.02)
0.93 (0.009) 0.99 (0.002) 0.78 (0.03)
0.57 (0.12) 0.64 (0.12) 0.99 (0.002)

Table 8: The effect of training and testing in the same or different
environments. Reported is the average true-positive rate (average
false-positive rate in the parentheses) across classiﬁers for all
obfuscators using the dataset labeling the row for training and the
dataset labeling the column for testing.

PT\Dataset

obfs3
obfs4
FTE
meekA
meekG
Total

OfﬁceDataset
5,281 (0.43%)
730 (0.06%)
6,437 (0.53%)
2,065 (0.17%)
837 (0.07%)

0.98%

CloudDataset
14,714 (0.20%)
16,257 (0.22%)
23,432 (0.31%)

787 (0.01%)

3 (0%)
0.70%

WiﬁDataset

34,726 (0.65%)
24,221 (0.46%)
19,857 (0.37%)
1,024 (0.02%)

2 (0%)
1.40%

Table 9: False positives of classiﬁers on the campus network
datasets. The value in the parentheses is the false-positive rate of
the selected classiﬁer on a given campus network dataset. Recall
that the number of ﬂows tested for OfﬁceDataset, CloudDataset,
and WiﬁDataset are 1.22 M, 7.48 M, and 5.32 M respectively.

the validation set. We repeat this procedure 20 times with fresh
random splits, and select the classiﬁers with the highest PR-AUC.
The PR-AUC of all the classiﬁers are greater than 0.90 (ranging
from 0.91 - 0.99). The true-positive rates (false-positive rates) of
the best/selected classiﬁers are 97.2% (0.13%), 97.0% (0.19%),
97.3% (0.08%), 98.3% (0.08%), and 97.8% (0.06%) for obf-
sproxy3, obfsproxy4, meek-amazon, meek-google, and FTE re-
spectively.

Next, for each TCP ﬂow in the campus datasets, we extract the
features using the ﬁrst 30 packets, label it as negative, and then test
it with each obfuscator classiﬁer. A summary of the results are in
Table 9. The total false-positive rate of the classiﬁers across all
three datasets is 0.98%. As broken down by dataset, we see as low
as 0.70% (CloudDataset) and as high as 1.40% (WiﬁDataset).6

The classiﬁer for obfsproxy3 produces the most false positives,
followed by the classiﬁer for FTE. The classiﬁer for meek-google
produces a relatively small number of false positives, which is a
total of 842 false positives out of 14 M ﬂows. That the wireless
network exhibits the largest number of false positives may be due
to their noisier nature [33,34]. For instance, when there are multiple
TCP retransmissions in a ﬂow, most of the packets we examined in
the ﬁrst 30 packets could be identical, hindering classiﬁcation.

The false positives are associate with 12,551 distinct hosts, a
small fraction of all monitored hosts, in the monitored networks.
Meanwhile, they are only associated with 6,239 distinct destination
IPs outside the campus networks. Less than 30% of these hosts
or destination IPs are associated with more than 90% of the false
positives. We ﬁnd that a single IP outside the campus networks
can contribute to as high as 4.6% of the false positives (as high as
1.2% for a single source IP inside the networks). This suggests that
speciﬁc server-side or client-side settings could be the reasons for
false positives.

We also determined the protocols of the false-positive ﬂows.
As shown in Table 10, most of the false positives are HTTP,
SSL/TLS or unknown ﬂows, according to Bro. The false positives

6Note that the total rates are not equal to the sum of the individual
obfuscator false-positive rates, as some traces are falsely labeled by
multiple classiﬁers.

66Protocol\PT

obfs3

obfs4

FTE

meekA

meekG

HTTP

12,295 (0.12%) 10,383 (0.10%) 43,673 (0.42%) 1,414 (0.01%)

SSL/TLS 29,705 (1.91%) 22,768 (1.47%) 3,773 (0.24%) 1,684 (0.11%) 391 (0.03%)

114 (0.55%)
2,739 (0.12%) 6,345 (0.27%) 2,148 (0.09%) 609 (0.03%) 451 (0.02%)

13 (0.06%)

33 (1.94%)
73 (0.35%)

0
0

SSH
SMTP

Unknown

0

0

0

0
0

Total

44,853

39,509

49,700

3,707

842

Table 10: Breakdown of the numbers of ﬂows from our campus traces incorrectly labeled by our ML classiﬁers as the indicated obfuscator.
The values in the parentheses are the percentage of ﬂows labeled by Bro as the indicated protocol that represent false positives (e.g., 0.12%
of HTTP ﬂows are mislabeled as obfsproxy3 by our classiﬁer). “Unknown” means Bro fails to identify the protocol of the ﬂow. The total
number of false positives across all protocols is shown in the ﬁnal row.

of the meek-amazon classiﬁer have a diversity in their protocols.
We examine some of the mislabeled ﬂows, and realize they may
use a patched version of protocols such as SSH with encrypted
handshakes [23].

We use nDPI to examine the ﬂows labeled as unknown by Bro.
nDPI fails to identify 13.5% of the unknown ﬂows, and reports 45
protocols found in the remainder. Of these, 21 are built atop HTTP
or SSL/TLS. These protocols account for 78.2% of the unknown
ﬂows. Whether an ML approach can be enhanced to reduce false
positives even further remains an open question.
6.2 Discussion

Our results show that trained classiﬁers using trafﬁc-analysis-
type techniques are effective at detecting obfuscators. This holds
true even for the meek family of obfuscators, which are widely
considered the hardest to detect by DPI. The true-positive rates are
high, and the false-positive rates are relatively small. We discuss
the impact of the latter in more detail in the next section.

Though the training process of the ML-based approaches are
complex, the decision trees emitted by training are, themselves,
actually quite simple: evaluating the trees requires between 6 and
13 integer comparisons. These comparisons use per-ﬂow state
including just a small number of integer counters, for up to the
ﬁrst 30 packets. We therefore believe the trees themselves will be
relatively easy to deploy, while the trickier issue will be the lack
of portability we observed. This speciﬁcally implies that building
good decision trees requires careful training in, ideally, the local
network environment to which they will be deployed.

7. ESTIMATING THE IMPACT OF FALSE

POSITIVES

As we have emphasized, a critical component of successful
obfuscator detection is achieving low false-positive rates and our
work is the ﬁrst that assesses them. Here we discuss the impact
of false positives and whether the rates achieved by our detection
approaches are sufﬁcient for a censor’s purpose.

Let us ﬁx a particular representative scenario from our data, other
scenarios can be analyzed similarly. Say a nation-state censor
deploys the combined ML-based classiﬁers for each of the ﬁve
obfuscators in the ofﬁce environment, and assume a true-positive
rate of 99% (as measured with TorA) and the false-positive rate of
about 1% (as measured using the OfﬁceDataset dataset). For the
foreseeable future, the base rate of obfuscator trafﬁc will continue
to be a tiny fraction of the overall trafﬁc. Suppose, pessimistically
for our analyses, that one out of every one billion ﬂows is actually
obfuscated trafﬁc. Because of the low base rate, only about 1 in
10,000,000 ﬂows marked as obfuscated will, in fact, be obfuscated.
(Not 1 in 100 of marked ﬂows, as one falling victim to the base
rate fallacy might assume.) This is likely to result degradation of
Internet performance, as perceived by “legitimate” users.

Aggressive censors may be willing to cause such degradation.
Of the blocked connections in this scenario, about 34.9% will be
encrypted connections (TLS, SSH), and some censors have already
demonstrated a willingness to block these. Iran, for example, has
been known to block all TLS connections, or at least degrade their
performance [4].
(Degrading bandwidth of such ﬂows will tend
to force Tor to fail, but not non-Tor TLS.) Other countries have
mandated that ISPs prevent or limit use of encrypted protocols [14,
32]. Even so, the majority of ﬂows erroneously labeled by our
techniques as obfuscated are plain, unencrypted HTTP. It seems
reasonable that blocking these will be less palatable for censors
with sensitivity to collateral damage.

Some sophisticated censors have moved to a two-stage detection
pipeline to improve accuracy. China’s so-called Great Firewall ﬁrst
uses DPI to ﬂag ﬂows as potentially resulting from a censorship
circumvention tool. Measurements suggest that they ﬂag any TLS
connection that has the same list of allowed ciphers as a Tor client
as a possible Tor connection [50, 51]. The destination IP address
of all such ﬂows is then submitted to a distributed system that
asynchronously performs an active probe of the remote IP address
using a Tor client. If the remote IP completes a Tor handshake,
then the IP is is added to a blacklist. See [50, 51] for a detailed
discussion of this behavior.

When using our obfuscator detection approaches in such a two-
stage pipeline, the false-positive rate of the deployed approach
will dictate the load on the more expensive, but more accurate,
second-stage. (Perfectly accurate, active attack on Tor that was just
described.) We refer to this second-stage as the DPI’s slow path,
and now turn to analyzing the slow-path load that would result from
using our tests using the collected traces for simulation.

Table 11 shows a summary of the load seen by the DPI in terms
of active ﬂows per second as broken down by the various traces.
For our purposes, a ﬂow is active from the time stamp of its ﬁrst
packet to the time stamp of its last packet. We also report statistics
regarding the load on the slow-path. A ﬂow is labeled as going to
the slow path whenever the combined ML-based classiﬁer labels
the trafﬁc as obfuscated (i.e., any of the individual classiﬁers gives
a positive label to the ﬂow). As is shown, the maximum number
of new slow-path ﬂows per second is modest –in the worst case
54 are active in any given second– and the average is less than
one. This suggests that, with minimal investment in the slow-
path infrastructure, a censor could easily keep up with the false-
positive rate of our obfuscation detectors. Of course, nation-state
censors deal networks even larger than those considered in our
work. Hence, caution should be exercised when extrapolating
results from our setting to others.

8. CONCLUSION

We set out to answer the question of whether censors can use DPI
to detect use of in-use network protocol obfuscators. Unfortunately,

67Avg. DPI load
Max. DPI load
Avg. slow-path load
Max. slow-path load
Slow-path active time

OfﬁceDataset CloudDataset WiﬁDataset
182.2
1,580
0.77
54
39.1%

138.5
1,042
0.60
24
38.2%

14.6
362
0.08
29
4.7%

Table 11: Summary statistics for DPI load (number of ﬂows per
second) and the slow-path load—the number of ﬂows per second
ﬂagged as any obfuscator by our best-performing ML classiﬁers.

our analyses suggest that the answer is ‘yes’. We present the ﬁrst
comprehensive analysis of detectability of in-use network protocol
obfuscators, as they are deployed in Tor. Our analyses reveal fast
entropy-based tests for randomizer protocols and FTE (which is
mostly randomized), and slightly less efﬁcient, but still practical,
machine learning-based attacks that reliably detect meek, a state-
of-the-art tunneling obfuscator. We also show that some semantics-
based detection tests suggested in the literature are less effective
than a censor might like, due to the inherent long tail of non-
standard network trafﬁc. This suggests that future development
of semantics-based tests should necessarily perform false positive
analyses. Towards helping future researchers with such tasks, we
will make our analysis platform open source for other researchers.
It is important to note that the detection techniques we explore
can be,
in turn, easily circumvented in almost all cases with
simple updates to the obfuscator. This suggests that with the
current state-of-the-knowledge on building practical obfuscators,
anti-censorship tools will only have the advantage when censors
remain ignorant of (or choose to ignore knowledge of) the details
of their design. Building more robust, future-proof obfuscators
that cannot be blocked by future, efﬁcient DPI algorithms with
knowledge of the obfuscator design remains an open question.

9. ACKNOWLEDGMENTS

The authors would like to especially thank the system admin-
istrators at the University of Wisconsin who helped ensure the
experiments went smoothly. This work was supported in part by the
National Science Foundation under grants CNS-1546033, CNS-
1330308, CNS-1065134, CNS-0845610, and CNS-1319061, and
by a generous gift from Dr. Eric Schmidt (New Digital Age grant).

10. REFERENCES
[1] M. AlSabah, K. Bauer, and I. Goldberg. Enhancing tor’s

performance using real-time trafﬁc classiﬁcation. In
Proceedings of the 2012 ACM conference on Computer and
communications security, pages 73–84. ACM, 2012.
[2] Apache. Hive operators and user-deﬁned functions.

https://cwiki.apache.org/confluence/
display/Hive/LanguageManual+UDF, 2015.

[3] J. Appelbaum and N. Mathewson. Pluggable transports for

circumvention. https://www.torproject.org/
docs/pluggable-transports.html.en, 2012.

[4] S. Aryan, H. Aryan, and J. A. Halderman. Internet censorship
in iran: A ﬁrst look. Free and Open Communications on the
Internet, Washington, DC, USA, 2013.

[5] J. Barker, P. Hannay, and P. Szewczyk. Using trafﬁc analysis
to identify the second generation onion router. In Embedded
and Ubiquitous Computing (EUC), 2011 IFIP 9th
International Conference on, pages 72–78. IEEE, 2011.

[6] L. Bernaille, R. Teixeira, I. Akodkenou, A. Soule, and

K. Salamatian. Trafﬁc classiﬁcation on the ﬂy. ACM

SIGCOMM Computer Communication Review, 36(2):23–26,
2006.

[7] X. Cai, X. C. Zhang, B. Joshi, and R. Johnson. Touching

from a distance: Website ﬁngerprinting attacks and defenses.
In Proceedings of the 2012 ACM conference on Computer
and Communications Security, pages 605–616. ACM, 2012.
[8] A. Communeau, P. Quillent, and A. Compain. Detecting FTE

proxy. 2014.

[9] D. Cournapeau. Scikit-learn: Machine learning in Python.

http://scikit-learn.org/, 2007.

[10] J. Davis and M. Goadrich. The relationship between

precision-recall and roc curves. In Proceedings of the 23rd
international conference on Machine learning, pages
233–240. ACM, 2006.

[11] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
second-generation onion router. Technical report, DTIC
Document, 2004.

[12] K. P. Dyer, S. E. Coull, T. Ristenpart, and T. Shrimpton.

Protocol misidentiﬁcation made easy with
format-transforming encryption. In Proceedings of the 2013
ACM SIGSAC conference on Computer & communications
security, pages 61–72. ACM, 2013.

[13] K. P. Dyer, S. E. Coull, and T. Shrimpton. Marionette: A

programmable network-trafﬁc obfuscation system. In
Proceedings of USENIX Security 2015, August 2015.

[14] Eugene. Age of surveillance: the ﬁsh is rotting from its head.

http://non-linear-
response.blogspot.com/2011/01/age-of-
surveillance-fish-is-rotting.html, 2011.

[15] Hill01. "Weird" utf-8 characters in POST body causing
content-length mismatch. https://github.com/
strongloop/express/issues/1816, 2013.

[16] A. Houmansadr, C. Brubaker, and V. Shmatikov. The parrot
is dead: Observing unobservable network communications.
In Security and Privacy (SP), 2013 IEEE Symposium on,
pages 65–79. IEEE, 2013.

[17] ISO. 171/sc 2: Iso 32000–1: 2008 document

management-portable document format-part 1: Pdf 1.7.

[18] E. Jones, T. Oliphant, P. Peterson, et al. SciPy: Open source
scientiﬁc tools for Python. http://www.scipy.org/,
2001.

[19] M. Juarez, S. Afroz, G. Acar, C. Diaz, and R. Greenstadt. A

critical evaluation of website ﬁngerprinting attacks. In
Proceedings of the 2014 ACM SIGSAC Conference on
Computer and Communications Security, pages 263–274.
ACM, 2014.

[20] T. Karagiannis, K. Papagiannaki, and M. Faloutsos. Blinc:

multilevel trafﬁc classiﬁcation in the dark. In ACM
SIGCOMM Computer Communication Review, volume 35,
pages 229–240. ACM, 2005.

[21] K. H. Kremer. The trouble with the XREF table.

http://khkonsulting.com/2013/01/the-
trouble-with-the-xref-table/, 2013.

[22] B. Krishnamurthy, J. C. Mogul, and D. M. Kristol. Key

differences between HTTP/1.0 and HTTP/1.1. Computer
Networks, 31(11):1737–1751, 1999.

[23] B. Leidl. Obfuscated-openssh. https:

//github.com/brl/obfuscated-openssh, 2009.

[24] D. Luchaup, K. P. Dyer, S. Jha, T. Ristenpart, and

T. Shrimpton. LibFTE: A toolkit for constructing practical,
format-abiding encryption schemes. In Proceedings of
USENIX Security 2014, August 2014.

68[25] Microsoft. Invalid content-length header may cause requests

to fail through ISA server. https:
//support.microsoft.com/en-us/kb/300707,
2007.

[26] H. Mohajeri Moghaddam, B. Li, M. Derakhshani, and
I. Goldberg. Skypemorph: Protocol obfuscation for tor
bridges. In Proceedings of the 2012 ACM conference on
Computer and communications security, pages 97–108.
ACM, 2012.

[27] T. T. Nguyen and G. Armitage. Training on multiple

sub-ﬂows to optimise the use of machine learning classiﬁers
in real-world ip networks. In Local Computer Networks,
Proceedings 2006 31st IEEE Conference on, pages 369–376.
IEEE, 2006.

[28] Ntop.org. nDPI.

http://www.ntop.org/products/deep-
packet-inspection/ndpi/, 2015.

[29] G. Nychis, V. Sekar, D. G. Andersen, H. Kim, and H. Zhang.

An empirical evaluation of entropy-based trafﬁc anomaly
detection. In Proceedings of the 8th ACM SIGCOMM
conference on Internet measurement, pages 151–156. ACM,
2008.

[30] A. Panchenko, L. Niessen, A. Zinnen, and T. Engel. Website

ﬁngerprinting in onion routing based anonymization
networks. In Proceedings of the 10th annual ACM workshop
on Privacy in the electronic society, pages 103–114. ACM,
2011.

[31] V. Paxson. Bro: a system for detecting network intruders in

real-time. Computer networks, 31(23):2435–2463, 1999.
[32] Phobos. Kazakhstan upgrades censorship to deep packet

inspection. https://blog.torproject.org/blog/
kazakhstan-upgrades-censorship-deep-
packet-inspection, 2012.

[33] S. Rayanchu, A. Mishra, D. Agrawal, S. Saha, and

S. Banerjee. Diagnosing wireless packet losses in 802.11:
Separating collision from weak signal. In INFOCOM 2008.
The 27th Conference on Computer Communications. IEEE.
IEEE, 2008.

[34] C. Reis, R. Mahajan, M. Rodrig, D. Wetherall, and

J. Zahorjan. Measurement-based models of delivery and
interference in static wireless networks. volume 36, pages
51–62. ACM, 2006.

[35] A. Rukhin, J. Soto, J. Nechvatal, M. Smid, and E. Barker. A
statistical test suite for random and pseudorandom number
generators for cryptographic applications. Technical report,
DTIC Document, 2001.

[36] C. Sanders, J. Valletta, B. Yuan, and D. Johnson. Employing

entropy in the detection and monitoring of network covert
channels. 2012.

[37] Seleniumhq.org. Selenium - web browser automation.

http://www.seleniumhq.org/, 2015.

[38] A. Thusoo, J. S. Sarma, N. Jain, Z. Shao, P. Chakka,

S. Anthony, H. Liu, P. Wyckoff, and R. Murthy. Hive: a
warehousing solution over a map-reduce framework.
Proceedings of the VLDB Endowment, 2(2):1626–1629,
2009.

[39] Tor project. Obfsproxy2.

https://gitweb.torproject.org/pluggable-
transports/obfsproxy.git/tree/doc/obfs2/
obfs2-protocol-spec.txt, 2015.

[40] Tor project. Obfsproxy3.

https://gitweb.torproject.org/pluggable-
transports/obfsproxy.git/tree/doc/obfs3/
obfs3-protocol-spec.txt, 2015.

[41] Tor project. Stem. https://stem.torproject.org/,

2015.

[42] Tor project. Tor meek. https://trac.torproject.

org/projects/tor/wiki/doc/meek, 2015.

[43] Tor project. Tor metrics.

https://metrics.torproject.org/, 2015.

[44] University of Washington. uProxy.

https://www.uproxy.org/, 2015.

[45] Q. Wang, X. Gong, G. T. Nguyen, A. Houmansadr, and
N. Borisov. Censorspoofer: asymmetric communication
using ip spooﬁng for censorship-resistant web browsing. In
Proceedings of the 2012 ACM conference on Computer and
communications security, pages 121–132. ACM, 2012.

[46] Z. Weinberg, J. Wang, V. Yegneswaran, L. Briesemeister,

S. Cheung, F. Wang, and D. Boneh. Stegotorus: a
camouﬂage proxy for the tor anonymity system. In
Proceedings of the 2012 ACM conference on Computer and
communications security, pages 109–120. ACM, 2012.

[47] A. M. White, S. Krishnan, M. Bailey, F. Monrose, and P. A.

Porras. Clear and present data: Opaque trafﬁc and its security
implications for the future. In NDSS, 2013.

[48] B. Wiley. Dust: A blocking-resistant internet transport

protocol. Technical rep ort. http://blanu. net/Dust. pdf, 2011.

[49] N. Williams, S. Zander, and G. Armitage. A preliminary

performance comparison of ﬁve machine learning algorithms
for practical IP trafﬁc ﬂow classiﬁcation. ACM SIGCOMM
Computer Communication Review, 36(5):5–16, 2006.

[50] P. Winter and J. R. Crandall. The great ﬁrewall of China:

How it blocks tor and why it is hard to pinpoint. 2012.

[51] P. Winter and S. Lindskog. How the great ﬁrewall of China is

blocking tor. Free and Open Communications on the
Internet, 2012.

[52] P. Winter, T. Pulls, and J. Fuss. Scramblesuit: A polymorphic

network protocol to circumvent censorship. In Proceedings
of the 12th ACM workshop on Workshop on privacy in the
electronic society, pages 213–224. ACM, 2013.

[53] X. Xu, Z. M. Mao, and J. A. Halderman. Internet censorship

in China: Where does the ﬁltering occur? In Passive and
Active Measurement, pages 133–142. Springer, 2011.

[54] Yawning. Obfsproxy4.

https://github.com/Yawning/obfs4/blob/
master/doc/obfs4-spec.txt, 2015.

[55] J. Yuan, Z. Li, and R. Yuan. Information entropy based

clustering method for unsupervised internet trafﬁc
classiﬁcation. In Communications, 2008. ICC’08. IEEE
International Conference on, pages 1588–1592. IEEE, 2008.

69