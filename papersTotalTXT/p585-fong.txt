Relational Abstraction in

Community-Based Secure Collaboration

Philip W. L. Fong and Pooya Mehregan

University of Calgary

{ pwlfong, pmehrega }@ucalgary.ca

Ram Krishnan

University of Texas at San Antonio

ram.krishnan@utsa.edu

ABSTRACT
Users of an online community are willing to share resources
because they can expect reasonable behaviour from other
members of the community. Such expectations are known
as social contracts.
In this work, we study the speciﬁca-
tion and enforcement of social contracts in a computer me-
diated collaboration environment. Speciﬁcally, we examine
social contracts that contain both relationship- and history-
based elements. A series of policy languages, all based on
modal and temporal logics, with increasing expressiveness,
have been proposed to express social contracts. Reference
monitors are designed to correctly and eﬃciently enforce the
speciﬁed policies. A technique called “relational abstraction”
is employed to reduce the reference monitor into a purely
relationship-based protection system, that is, what is com-
monly known as a social network system.

Categories and Subject Descriptors
D.4.6 [Security and Protection]: Access Controls

Keywords
Online community; Social contract; Relationship-based ac-
cess control; History-based access control; Policy language;
Reference monitor; Temporal logic; Hybrid logic

1.

INTRODUCTION

Online communities are increasingly organized around so-
cial computing platforms or other collaborative software.
Examples include collaborative authoring through Wiki and
Google Docs, internet forums, online calendar sharing, or
open-source development platforms like Source Forge. Pro-
prietary collaboration software tools, such as IBM LotusLive
and Microsoft Oﬃce 365, are also representative examples.
Individuals are willing to get together as a community, in
which they feel safe to share their resources, because they
can expect reasonable behaviour from other members of the

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516720.

community. Such behavioural expectations that form the
foundation of a community is called a social contract [27].
Social contracts must be carefully articulated as well as
enforced in order for them to be eﬀective in binding individ-
uals into a community. This work is about supporting the
eﬀective articulation and enforcement of social contracts in
online communities. We use the term Community-based
Secure Collaboration (CSC) to refer to the kind of on-
line collaboration that is mediated by a globally speciﬁed
and enforced social contract.

From an access control perspective, social contracts deter-
mine what accesses are acceptable, and what are not. For
example, a seller who has never missed a delivery shall be
granted a preferred seller status, which in turn allows her
to access privileged advertisement channels. As another ex-
ample, a volunteer programmer who has contributed code
to a certain module of an open source software shall not be
a tester for that module. Social contracts typically contain
access policies that are not only about who the requestor
is (identity), what quality he has (attribute) or the kind of
job functions he assumes (role). In the era of social comput-
ing, it is typical for social contracts to have policies of the
following kinds:

• Relationship-based. Some policies base authoriza-
tion decisions on how users are related to one another.
• History-based. Other policies determine accessibility
by considering how users interacted with one another
in the past, or how they were related to one another
in the past.

Previous works in access control have addressed isolated
requirements of social contract articulation and enforcement,
but none provides a generic framework for specifying and
enforcing policies that are simultaneously relationship based
and history based. Krukow et al. [25, 26] proposed a history-
based framework for specifying the interaction protocol be-
tween a pair of users using Pure Past Linear Temporal Logic
(PPLTL), and designed an execution monitor architecture
for enforcing such policies. Yet, the scheme cannot sup-
port interaction protocols (aka social contracts) that span
the joint behaviour of a community of individuals. Fong
[16] proposed a formal model for Relationship-based Access
Control (ReBAC), in which the protection state is a social
network of users, authorization decisions are based on how
users are related to one another, and policies are expressed in
a modal logic, with subsequent extension to employ hybrid
logic as a policy language [6]. That line of work, however,
does not take into account the historical interactions and

585relationships among users. Krishnan et al. [24, 22] studied
a speciﬁc type of social contract that is built on the protec-
tion abstraction of groups, and employed First-Order Lin-
ear Temporal Logic (FOLTL) to specify interaction proto-
cols. The intended application is secure information sharing.
They also studied the correspondence between the formal
speciﬁcation and its implementation via reference monitors
[23]. While their work has a history-based ﬂavour, it applies
only to a speciﬁc kind of social contract, and access control
constraints are phrased in terms of the concerned user and
object in a group rather than generic relationships among
them or among groups.

Building on the three lines of research above, this work

makes the following contributions.

1. We devised an access control model for supporting
CSC (§ 5). The protection system tracks the history of
the community’s state, which takes the form of gener-
alized social networks. Social contracts are expressed
as policies that guard the interaction events of users.

2. Extending the modal logic of Fong [16], we designed a
policy language that incorporates both modal and tem-
poral operators for expressing intermingled relationship-
based and history-based policy elements (§ 6).

3. We proposed a reference monitor architecture for en-
forcing social contracts speciﬁed in our policy language
(§ 7). To reduce the space usage of the monitor, we
employed a technique that we call relational abstrac-
tion, in which historical dealings between two parties
are documented as binary relationships between them.
A pleasantly surprising consequence is that the result-
ing reference monitor tracks a single generalized social
network rather than a history of social networks. Thus
we obtain the core thesis of this work: although the
CSC model oﬀers speciﬁcation convenience in terms
of mixing history- and relationship-based policy ele-
ments, the underlying enforcement mechanism can be
optimized into a ReBAC system!

4. Recognizing the need for further expressiveness, we
proposed a hybridized extension of our policy language
(§ 8). By employing relational abstraction once again,
we obtained a novel fragment of the hybridized pol-
icy language that is amenable to eﬃcient enforcement,
thereby recovering the core thesis that the reference
monitor is essentially a ReBAC system.

Consult [17] for proofs of theorems.

2. RELATED WORK

Relationship-Based Access Control.

With the advent of social network systems, Gates [20] and
Carminati and Ferrari [10] independently coined the term
Relationship-Based Access Control to refer the access con-
trol models in which inter-personal relationships form the
basis of authorization decisions. Fong formalized this type
of access control in a ReBAC model [16], and showed that
classical access control approaches, such as RBAC, do not
oﬀer the right abstractions for expressing policies commonly
found in social computing and electronic health record sys-
tems. By adopting relationship-based access control (Re-
BAC), one avoids tedious role parameterization and achieves

delegation in an elegant manner. A modal logic [5] with a
single propositional symbol has been adopted for specifying
ReBAC policies. Subsequent works study the expressive-
ness of ReBAC policy languages [18], and extend the modal
language by way of hybridization [6] (i.e., incorporating con-
structs from hybrid logic [1]).

Cheng et al. proposed a ReBAC model with a regular
expression-based policy language [12]. They subsequently
extended their model to capture not only user-to-user rela-
tionships, but also user-to-resource and resource-to-resource
relationships [11].

None of the above works take into account the history
of interactions and relationships in policy speciﬁcation and
enforcement. Support for temporal reasoning is necessary
for expressing interaction protocols in social contracts. A
contribution of this work is to demonstrate that such a
history-based extension of ReBAC is a non-trivial research
undertake, involving complex algorithm design issues and
shift of representation (via relational abstraction) to achieve
space-eﬃcient enforcement. This present work is also capa-
ble of expressing user-to-resource and resource-to-resource
relationships.

Other Protection Models for Social Computing.

Carminati et al. proposed an access control model for so-
cial network systems that is based on a trust metric [9].
A subsequent work explored the use of established seman-
tic web technologies for encoding policies and relationships
[7, 8]. ACON is an access control model designed speciﬁ-
cally for social computing [30, 29]. It controls user activities
by considering, e.g., user and resource attributes as well as
user-to-user relationships.

History-Based Access Control.

History-based access control tracks past access events and
uses access history as the basis for authorization. Previous
work includes both system implementation techniques [14]
as well as theoretical study of enforceability [31, 15, 21, 28].
Of particular relevance to this work is the work of Krukow
et al.
[25, 26]. They used a PPLTL as a policy language
for specifying the interaction protocol between two parties,
and proposed a reference monitor framework for enforcing
the policies. Their work does not capture community-wide
policies.

Our reference monitor framework employs two related tech-
niques for optimizing space usage: (1) using LTL expansion
laws [2, Chapter 5] to reduce dependencies on history, and
(2) augmenting the generalized social network with addi-
tional edges to record historical dealings between parties.
Similar techniques have been employed in previous works:
(1) in [3, 25, 26] and (2) in [13, 4]. Our novelty has been in
applying these techniques in (a) demonstrating that a Re-
BAC system is all that one requires to enforce CSC policies
speciﬁed in our policy languages, and (b) devising an ap-
propriate fragment of our hybridized policy language that is
amenable to such optimization techniques.

Group-centric Secure Information Sharing.

Krishnan et al. proposed a formal speciﬁcation of group-
centric secure information sharing (g-SIS) [24, 22]. LTL is
employed to specify the various properties of groups, as well
as accessibility conditions. In this sense, g-SIS authorization
is history-based. Yet g-SIS is only a speciﬁc form of commu-

586nity, and the speciﬁcation approach does not support notions
of accessibility that depends on relationships among users or
groups. Subsequent work also applies formal methods to es-
tablish the correspondence between a stateless speciﬁcation
and a stateful implementation (i.e., reference monitor) of g-
SIS [23]. In our work, the policy speciﬁcation is guaranteed
to be faithfully enforced by the reference monitor architec-
ture. Manual application of formal methods is not required.

3. USE CASES

This section outlines use cases that are representative of

the applications targeted by our CSC protection model.

Example 1

(Online Social Networks (OSNs)).

OSNs such as Facebook have recently been used for pur-
poses other than staying in touch with friends. Speciﬁcally,
people in many countries coordinated and planned their po-
litical gatherings and demonstrations using Facebook. This
drew the attention of totalitarian governments, resulting in
surveillance of such OSNs. It is therefore desirable for users
to be able to set up ﬁne-grained access control policies.

Sarah, a member of an OSN, is a supporter for a minor-
ity party called Fighting Citizens (FC). FC has been banned
from further activities by the majority party, which has risen
to power recently. In the past, Sarah has posted contents in
favour of FC in an OSN group of FC supporters. She as
well as other members of that group wish to prevent certain
users from joining that group. Speciﬁcally, OSN users who
previously joined OSN groups associated with the governing
party are not allowed to join the FC-supporter group.

Example 2

(Online Coauthoring Communities).

Some online communities, such as Wikipedia, provide users
with an environment for coauthoring contents and collective
editing. Since deviant users may not conform to the so-
cial contract that deﬁnes a community, such communities
need to be equipped with means for formal articulation of
social contracts as well as mechanisms for enforcing these
contracts. The following are sample components of such so-
cial contracts.

1. A user who has been reported for using inappropriate
language for two times is suspended for further editing.

2. A user who has already created two distinct objects that
have since remained untouched by any member of the
community (including herself ) is not allowed to further
create new objects.

4. NOTATIONS

Sets and Functions.
be the set of boolean values {0, 1}.

Let N be the set of natural numbers {0, 1, 2, . . .}, and B
Given a function f : A → B, we write dom(f ) for the
domain of f (i.e., the set A), and ran(f ) for the range of
f (i.e., the set {f (x) | x ∈ A}). We write f : A(cid:48) (cid:42) B
if dom(f ) ⊆ A(cid:48) and ran(f ) ⊆ B. Suppose f : A (cid:42) B,
a ∈ A, and b ∈ B. We then write f [a (cid:55)→ b] to denote the
function g : A (cid:42) B such that g(a) = b, and g(x) = f (x)
for x (cid:54)= a. Given a1, a2, . . . , an ∈ A and b1, b2, . . . , bn ∈ B,
where a1, a2, . . . , an are pairwise distinct, we write {a1 (cid:55)→
b1, a2 (cid:55)→ b2, . . . , an (cid:55)→ bn} to denote the function g : A (cid:42) B
such that g(a1) = b1, g(a2) = b2, . . . , g(an) = bn.

Relational Structures.

Intuitively, a relational structure (or simply a graph)
is an edge-labelled directed graph. Formally, a relational
structure is a pair G = (cid:104)V,{Rl}l∈L(cid:105). The component V is a
ﬁnite set of vertices. The component {Rl}l∈L is an indexed
family of binary relations. The set L is a ﬁnite set of edge
labels. For each label l ∈ L, Rl ⊆ V × V is a binary relation
deﬁned over V . We also write V (G), E(G) and Rl(G) to
represent V , {Rl}l∈L and Rl respectively.
Given a countably inﬁnite set V and a ﬁnite set L, we de-
note by G[V,L] the set of all relational structures (cid:104)V,{Rl}l∈L(cid:105)
for which V ⊆ V. Note that L is common across every
G ∈ G[V,L], and V (G) is always ﬁnite by deﬁnition.
Given G ∈ G[V,L], u, v ∈ V, and e may or may not be
a member of L, then G + e(u, v) denotes the graph (cid:104)V (cid:48),
l}l∈L∪{e}(cid:105), where V (cid:48) = V (G)∪{u, v}, R(cid:48)
e = Re∪{(u, v)}
{R(cid:48)
if e ∈ L, R(cid:48)

e = {(u, v)} if l (cid:54)∈ L, and R(cid:48)

l = Rl if l (cid:54)= e.

5. ACCESS CONTROL MODEL

This section deﬁnes a formal model for Community-based
Secure Collaboration. The model consists of two parts: (a) a
behaviour model for the community (§ 5.1), and (b) a protec-
tion system that constrains the behaviour of that community
based on explicitly speciﬁed policies (§ 5.2).
5.1 Community

Social States

A community is modeled as a state transition system.
At any point of time, the community is in a social state
(§ 5.1.1). A communication event (§ 5.1.2) that occurs
within a state triggers a state transition (§ 5.1.3), bringing
the community to a new social state. Formally, a commu-
nity is speciﬁed as a community schema, which is a 4-tuple
(cid:104)V,R,E,−→(cid:105). We explain the four components below.
5.1.1
A community evolves over time. At any point of time
the community is in a certain social state. In this work we
are interested in basing authorization decisions on the his-
tory of this evolving social state. We see the social state
of a community to be relational in nature: the social state
is characterized by, for example, interpersonal relationships
that are either persistant or transient, past dealings with one
another, and their reputational assessment of one another.
There are also times when users and their relationships are
not suﬃcient for modelling the community’s state. For ex-
ample, there may be non-user entities including resources
(e.g., ﬁles, photos, user proﬁles, etc) and social construc-
tions (e.g., groups, departments, etc), as well as their rela-
tionships with one another and with users, that may inform
authorization decisions. We use the generic term entities
to refer to either user or non-user entities.

We model the social state of a community as a relational
structure. Recall that a relational structure is an edge-
labelled directed graph. The vertices of the graph represent
entities (i.e., either users or non-user entities). A directed
edge models a relationship between two entities, and the la-
bel of the edge indicates the type of relationship represented
by that edge. Note that the social network of the users in
the community is a subgraph of this relational structure.
In a community schema (cid:104)V,R,E,−→(cid:105), the component V is
a countably inﬁnite set of entity identiﬁers. The social
state of the community is made up of a ﬁnite subset of V.
The component R is a ﬁnite set of relation identiﬁers.

587The set R speciﬁes the set of relationship types among enti-
ties. Therefore, the space of social states is the set G[V,R].
5.1.2 Communication Events
As a community evolves over time, its social state changes.
We assume that a community evolves only because of user
activities, and model an activity as a communication event
(or simply an event). In essence, the model does not ac-
count for any spontaneous change in social state that is not
accompanied by an event explicitly tracked by the protec-
tion system1.
In short, an event is the sole trigger for a
community to transition from one social state to another.

The objective of the protection system is to control the
triggering of communication events. While a communication
event may involve many participants, we assume that only
two of them are signiﬁcant for the purpose of authorization.
More speciﬁcally, the request to trigger a communication
event presents to the reference monitor an event signature
of the form e(u, v), where:

• e is an event identiﬁer , the type of this event,
• u is the initiator , the entity to initiate this event, and
• v is the target, the entity to which this event is di-

rected.

For example, the event signature send(john, mary) represents
the event of John sending Mary a message. From the per-
spective of the protection system, only the event signature
(but not the event) is visible. Hereafter we use the terms
event and event signature interchangeably. We also write
ES[E,V] for the set of all event signatures e(u, v) for which
e ∈ E and u, v ∈ V.
The component E in a community schema (cid:104)V,R,E,−→(cid:105) is a
ﬁnite, non-empty set of event identiﬁers for that community.
5.1.3
Given a community schema (cid:104)V,R,E,−→(cid:105), the last compo-
·−→ · ⊆ G[V,R] × ES[E,V] × G[V,R] is a transition
nent ·
e(u,v)−−−−→ H when the occurrence of event
relation. That is, G
e(u, v) in state G transitions the community into state H.

State Transition

Furthermore, the transition relation must be well-formed :
e(u,v)−−−−→ H, then V (G) = V (H) and u, v ∈ V (G). Intu-
if G
itively, a well-formed transition does not alter the vertex set
of the graph, and the initiator and target are both mem-
bers of the vertex set. That is, entity creation is modeled as
dormant entities becoming active over time2.
5.2 Protection System

If a community schema speciﬁes the possible behaviour of
a community, then a protection system speciﬁes a mecha-
nism that constrains such behaviour (§ 5.2.3). Speciﬁcally,
1Examples of such spontaneous events may include time out,
change of environmental conditions, or feedback events gen-
erated by the system itself. One way to accommodate such
events into our model, is to introduce a special entity into
the relational structure, for representing the community it-
self. An event in which both the initiator and target are this
special entity represents a spontaneous event.
2This requirement is imposed to reduce the complexity of
presentation. The subtlety of entity creation can be eas-
ily incorporated into the model, at the cost of unnecessary
complexities that do not inspire.

such a protection system is a reference monitor. When a
communication event is to be triggered, the signature of that
event is ﬁrst presented to the protection system for autho-
rization (§ 5.2.4). Unless the system grants the event, the
latter will be suppressed. The reference monitor is stateful:
it tracks the historical evolution of social state of the com-
munity, as well as events that occurred in the past (§ 5.2.1).
The reference monitor applies an access control policy to the
reference monitor state when an authorization decision is to
be made (§ 5.2.2).
5.2.1 Traces
We model the history of the community in a trace, which
is a sequence of relational structures. More speciﬁcally, a
sequence of transitions
−−−−−−→ G1

−−−−−−→ G2 ··· en(un,vn)

−−−−−−−→ Gn

G0

e1(u1,v1)

e2(u2,v2)

can be encoded as the sequence of relational structures
G0 · (G1 + e1(u1, v1))· (G2 + e2(u2, v2))··· (Gn + en(un, vn))
That is, the ﬁrst element of the sequence, G0, is the oldest
snapshot in the history, and, for each time point 0 < i ≤ n,
the relational structure Gi + ei(ui, vi) contains both the so-
cial state Gi as well as an edge that records the communi-
cation event that produced Gi (i.e., the event ei(ui, vi)). In
summary, the history of a community is modeled as a se-
quence from G[V,L]+, where L = R (cid:93) E. An edge with a
label in R is a relation edge, and an edge with a label in E
is an event edge. Such a sequence is what we call a trace.
Suppose we ﬁx V and L = R(cid:93)E. A trace γ = G0G1 ··· Gn

is well formed if both of the following hold:

• G0 ∈ G[V,R], and
• for 1 ≤ i ≤ n, Gi = G(cid:48)

and e ∈ E.

i +ei(u, v) for some G(cid:48)

i ∈ G[V,R]

We denote by T [V,R,E] the set of all well-formed traces.
5.2.2 Access Control Policies
A protection system controls the authorization of commu-
nication events in a community. In such a system, one needs
to impose policies for access control. A policy predicate (or
simply a policy ) P is a function of the following signature.

T [V,R,E] × V × V → B

(1)

That is, a policy P (γ, u, v) takes as input a well-formed trace
γ, an initiator vertex u and a recipient vertex v, and returns
a boolean authorization decision. We write P[V,R,E] for
the set of all policies with the signature on line (1).
5.2.3 Protection System
Given a community schema C = (cid:104)V,R,E,−→(cid:105), a protec-
tion system for C is a pair (cid:104)C, policy(cid:105), where the function
policy : E → P[V,R,E] assigns a policy predicate to each
event identiﬁer. That is, policy predicate policy(e) mediates
the triggering of events of type e.
5.2.4 Authorization
A protection state (i.e., a state of the protection system)
contains the information by which authorization decisions
are made. In our case, a protection state is simply a well-
formed trace γ. Note that this identiﬁcation of protection
states to well-formed traces is conceptual, meaning that the

588actual implementation of the protection system may choose
to encode the protection state in some space-eﬃcient repre-
sentations, which is exactly what we will do in § 7. For now,
we focus on the conceptual description of the model.
Let γ = G0 · (G1 + e1(u1, v1)) · (G2 + e2(u2, v2))··· (Gn +
en(un, vn)) be a well-formed trace (i.e., a protection state),
where n ≥ 0, Gi ∈ G[V,R] for 0 ≤ i ≤ n, and ei ∈ E for
1 ≤ i ≤ n. Then we write head(γ) for the graph Gn.
We model both the transition of protection states and au-
thorization with the binary relation =⇒ ⊆ T [V,R,E] ×
T [V,R,E]. Intuitively, the relation =⇒ transitions one pro-
tection state (which is a well-formed trace) to another pro-
tection state (which is also a well-formed trace) of length one
more than the ﬁrst. Formally, the transition below holds

γ =⇒ γ · (G + e(u, v))

whenever both of the following conditions are met:

1. head(γ)

e(u,v)−−−−→ G. That is, G is the next social state

according to the social state transition relation.

2. policy(e)(γ, u, v) = 1. That is, the policy predicate

assigned to event e authorizes the transition.

Example 3

(Online Social Networks). We model
Example 1 using our protection model. We begin by de-
scribing the community C = (cid:104)V,R,E,−→(cid:105). The entity set is
V = U (cid:93) G, which is partitioned into the set U of users and
the set G of user groups. We assume that groups may “black-
list” one another. For example, the FC group black-lists all
the groups associated with the majority party. To support
that, the relation identiﬁer set is set up to be R = { bl},
such that if there is a bl edge from group g1 to group g2, it
means g1 has black-listed g2. We assume that the bl edges
are static, and they do not change over time. At run time,
users may join groups. We model that by setting the event
identiﬁer set to be E = { join}, such that the event signa-
ture join(u, g) signiﬁes the event of user u joining group g.
Now the transition relation models group joining activities.
−−−−−→ G. That is, the relational structure
Speciﬁcally, G
that represents the social state of the community does not
change over time, as the social state contains only bl edges.
However, the graphs in a trace will contain join edges that
record group joining events.
The protection system (cid:104)C, policy(cid:105) speciﬁes a policy predi-
cate policy(join) for guarding group joining events. Speciﬁ-
cally, policy(join)(γ, u, g) will check if u has previously joined
a group g(cid:48) that is black-listed by g.

join(u,g)

Example 4

(Online Coauthoring Communities).
Consider C = (cid:104)V,R,E,−→(cid:105), the community of Example 2.
There are two kinds of entities. S is the set of subjects, O is
the set of objects, and we set V = S (cid:93) O. There is only one
relation identiﬁer: R = { own}. An own edge from subject
s to object o signiﬁes that s is the creator of o. We assume
that objects that have not yet been created are already in the
relational structure. “Uncreated” objects are not joined to
any own edge.
We model three event identiﬁers: E = {create, edit, report}.
The event create(s, o) signiﬁes that s is creating a new object
o. The event edit(s, o) signiﬁes that s is editing an existing
object o. The event report(s1, s2) indicates that s1 reports
the use of inappropriate language by s2.

The transition “G

−−−−−−→ G + own(s, o)” adds an own
edge from the initiator s to the target o. The transition
−−−−−→ G” does not alter the social state, and the same

create(s,o)

edit(s,o)

“G

is true for “G

report(s1,s2)

−−−−−−−→ G”.

The protection system (cid:104)C, policy(cid:105) deﬁnes the policy predi-
cates policy(create), policy(edit) and policy(report) for guard-
ing the three kinds of events.
5.3 Discussion

A limitation in the scope of this work is that our protec-
tion model handles only communication events with a bi-
nary signature. While many interaction patterns are binary
or reducible to binary signatures, some other lose semantics
if we force a binary representation. Group messaging is an
example of events that can be represented as a binary event.
The idea is to model the group by an entity, and members
are related to the group entity by membership edges. The
initiator of the communication event is the message sender,
and the target is the group entity. While the eﬀect of the
event may involve updating a subgraph that contains the
member vertices, the event signature itself involves only the
message sender (initiator) and the group vertex (target).
An example of a high-arity event is a real-estate transac-
tion, involving a buyer, a seller, and their agents. This time
the event signature has to capture all the four parties, since
it is necessary to ensure that the agents are indeed repre-
senting the buyer and the seller, and that there is no issue
of dual agency. When the access control policy for an event
needs to verify a relationship among three or more parties,
a binary event signature is not suﬃcient. Although we are
fully aware there are event signatures with an arity higher
than two, this work illustrates that even by considering only
binary events, the technical challenges are already daunting,
necessitating careful design of enforcement mechanisms (§7
and §8.2). Further extension to handle events of higher arity
is a future work.

6. POLICY LANGUAGE

One of the goals of this work is to provide conﬁgurability
to online communities founded on social contracts. As so-
cial contract evolves, it should not necessitate recompiling
the system source code. Rather, the community administra-
tor shall be equipped with declarative policy languages that
let him or her revise the social contract without rebuilding
the system. This section describes such a declarative policy
language. The targeted users of our policy languages are
not end users in the community, but rather community ad-
ministrators. The situation is analogous to, say, conﬁguring
a system with technically-oriented policy languages such as
XACML. Our design goal is therefore the balancing of ex-
pressiveness and enforceability.

Recall that authorization decisions are reached by con-
sulting policy predicates, each of which takes as input the
community’s history, the initiator and the target, and re-
turns a boolean authorization decision. The policy language
in this section is designed for expressing such a predicate.
This language forms the basis of a more expressive language
to be described in § 8. For now we examine this basic policy
language to facilitate the development of our core thesis in
§ 7.

Our policy language is an extension of the modal language
proposed in [16]. That modal language oﬀers a means to

589specify binary relations between a pair of vertices in a rela-
tional structure. Inspired by [22], we extend that language
by incorporating the pure-past temporal operators of Linear
Temporal Logic (LTL). The result is a language that allows
us to articulate binary relations of a pair of vertices in the
backdrop of an evolving relational structure. We name this
language T R (for temporal-relational).
6.1 Syntax

Policies are expressed as formulas in T R. The abstract

syntax of formulas is given below:

φ ::= (cid:62) | target | ¬φ | φ ∨ φ | (cid:104)l(cid:105)φ | (cid:104)−l(cid:105)φ | Y φ | φS φ

where l ∈ L, with L being the edge label set (i.e., R(cid:93)E). We
write FormT R(L) to denote the set of all formulas generated
by the above grammar.

A formula φ essentially speciﬁes a search to be performed
by an agent that “crawls around” a given trace γ =
G0G1 ··· Gn, and determines along the way if the initiator
and the target forms a certain binary relation. As the search
unfolds, at any point of time, the agent is standing at a cer-
tain coordinate (i, u) within the trace γ, where i is a time
point, and u is a vertex of the relational structure Gi. The
agent may do three things: (1) Check the current location of
the agent (via target or (cid:62)); (2) Move about in the relational
structure of the current time point (via (cid:104)l(cid:105)φ or (cid:104)−l(cid:105)φ); (3)
Move back in time (via Y φ or φ1 S φ2). The above checks
can be composed using basic boolean connectives such as
negation (¬) and disjunction (∨). We formalize the above
intuitive description in the following.
6.2 Semantics
The semantics of T R is deﬁned in terms of the satisfaction
relation |=. Given a trace γ = G0G1 ··· Gn for which n ≥ 0,
an index i such that 0 ≤ i ≤ n, and vertices u, v ∈ V (Gn),
the satisfaction relation γ, i, u, v |= φ is deﬁned as follows:

• γ, i, u, v |= (cid:62) always holds.
• γ, i, u, v |= target iﬀ u = v.
• γ, i, u, v |= ¬φ iﬀ it is not the case that γ, i, u, v |= φ.
• γ, i, u, v |= φ1 ∨ φ2 iﬀ γ, i, u, v |= φ1 or γ, i, u, v |= φ2.
• γ, i, u, v |= (cid:104)l(cid:105)φ iﬀ there exists u(cid:48) ∈ V (Gi) such that

(u, u(cid:48)) ∈ Rl(Gi) and γ, i, u(cid:48), v |= φ.

• γ, i, u, v |= (cid:104)−l(cid:105)φ iﬀ there exists u(cid:48) ∈ V (Gi) such that

(u(cid:48), u) ∈ Rl(Gi) and γ, i, u(cid:48), v |= φ.

• γ, i, u, v |= Y φ iﬀ i > 0 and γ, i − 1, u, v |= φ.
• γ, i, u, v |= φ1 S φ2 iﬀ there exists j, 0 ≤ j ≤ i, such
that both (a) γ, j, u, v |= φ2, and (b) for all k, j < k ≤
i, we have γ, k, u, v |= φ1.

Note that, in the inductive deﬁnition of |=, the pair (i, u) is
the “coordinate” of the agent, and γ and v remains constant
as the structural induction unfolds. In particular v gives the
meaning of the propositional symbol target, which records
the target entity’s location.
Lastly, we also write the shorthand γ, u, v |= φ to mean
γ, n, u, v |= φ. (Recall that n = |γ| − 1.) That is, we be-
gin traversal at the most recent time point. Essentially, this

shorthand checks if a certain binary relationship exists be-
tween u and v within the history γ. The binary relation
in question is speciﬁed as φ, with the propositional symbol
target representing v, and the agent begins evaluation at u.
6.3 Derived forms

[−l]φ = ¬(cid:104)−l(cid:105)¬φ

Standard derived forms can be deﬁned as follows:
φ1 ∧ φ2 = ¬(¬φ1 ∨ ¬φ2) O φ = (cid:62)S φ
⊥ = ¬(cid:62)
[l]φ = ¬(cid:104)l(cid:105)¬φ
H φ = ¬O ¬φ
The box operator [l] is the dual of (cid:104)l(cid:105). Speciﬁcally, the for-
mula [l]φ holds at coordinate (i, u) if every l-neighbor of u
satisﬁes φ at time point i. The converse [−l] can be un-
derstood similarly. The “once” operator O checks that there
was at least one time point in the past for which the operand
formula φ holds. The “historically” operator H checks that
the operand formula φ holds in every past time point.
6.4 Policy predicate

Given a formula φ, we write [[φ]] to denote the policy pred-
icate induced by φ. Speciﬁcally, [[φ]](γ, u, v) returns 1 when-
ever γ, u, v |= φ.
Previously, a protection system is deﬁned as a pair (cid:104)C,
policy(cid:105). The component policy is supposed to map event
identiﬁers to policy predicates. As we will use our policy
language to express policy predicates, we also allow policy
to be a function of type E → FormT R(R∪E): that is, policy
assigns a formula to each event identiﬁer. We then take
[[policy(e)]] to be the policy predicate guarding event identi-
ﬁer e. We adopt this convention uniformly in the following.
With the convention above, the range of the function
policy, written ran(policy), is the set of all formulas that are
used by the protection system for guarding event identiﬁers.
This set will be of interest to us in the sequel.
6.5 Examples

Example 5

(Online Social Networks). Continuing
with Example 3, we capture the policy of Example 1 as
policy(join). Speciﬁcally, the formula below speciﬁes the pol-
icy predicate that guards the event join(u, g):

¬O(cid:104)join(cid:105)(cid:104)−bl(cid:105)target

The formula exploits the fact that the social state does not
change over time.

Example 6

(Online Coauthoring Communities).

Continuing with Example 4, we capture Policy 1 of Exam-
ple 2 as policy(create). Speciﬁcally, the event create(s, o) is
allowed only if the following holds.

¬O(cid:0)((cid:104)−report(cid:105)(cid:62)) ∧ (Y O(cid:104)−report(cid:105)(cid:62))(cid:1)

(2)

The formula detects violation of Policy 1 by looking for two
distinct, historical occurrences of report edges that point to
the initiator.

7. REFERENCE MONITOR
7.1 Motivation

The enforcement of policies can be achieved by a refer-
ence monitor, which is essentially an implementation of the
protection system as described in § 5.2. To ﬁx thoughts, let

590G0 be the initial social state of the community, and Gt be
the social state of the community after the t’th transition
(t ≥ 1). Deﬁne also traces γ0 = G0, and γt = γt−1 · Gt
(for t ≥ 1). That is, γt is the history of the community
after the t’th transition. At time point t, if the reference
monitor intercepts an event signature e(u, v), it evaluates
the policy predicate policy(e) against γt, u and v. There-
fore, a naively implemented reference monitor will have to
track the entire history of the community (i.e., γt). In ad-
dition, if authorization is successful, then transition occurs,
and the reference monitor will have to update its internal
state to γt+1 = γt · Gt+1. This naive implementation strat-
egy is obviously not practical for its unreasonable memory
requirement. We explore in the following a space-eﬃcient
implementation strategy, in which the memory usage is com-
parable to tracking only one relational structure.
7.2

Implementation Strategy

The core insight is inspired by the work of Krukow et
al. [26], who proposed a scheme for enforcing a safety prop-
erty, speciﬁed as a pure-past LTL formula, using a refer-
ence monitor. Every authorization decision is made by a
constant-time check against the current state of the reference
monitor. The space requirement for their reference monitor
is linear to the size of the formula but independent of the
size of the history. Every system transition involves the exe-
cution of an “update algorithm,” which changes the internal
state of the reference monitor. Eﬃcient memory usage is
possible because of the extensive application of expansion
laws in LTL [2, Chapter 5]. Applying their insights to our
case, we observe the following:

γt+1, u, v |= Y φ iﬀ γt, u, v |= φ
γt+1, u, v |= φ1 S φ2 iﬀ (γt+1, u, v |= φ2) or

(cid:16)

(cid:17)

(3)

(4)

(γt, u, v |= φ1 S φ2) and (γt+1, u, v |= φ1)

Note that, in the cases above, the evaluation of a formula at
time point t + 1 can be reduced to either (i) the evaluation
of a subformula at time point t, or (ii) the evaluation of a
proper subformula at time point t + 1. This suggests the ref-
erence monitor only needs to track the evaluation results of
all subformulas at a given time, and, when a transition oc-
curs, the reference monitor updates the evaluation results by
consulting the evaluation results of the previous state, and
performs the updates from subformulas to superformulas.
7.3 Notation

We begin by deﬁning a few supporting notations. We
G(u) to denote the set {v ∈ V (G) | (u, v) ∈
write succl
Rl(G)}. That is, succl
G(u) is the set of all l-successors of
vertex u in graph G. Similarly, the set of all l-predecessors
G(u), is the set {v ∈ V (G) | (v, u) ∈
of u in G, written predl
Rl(G)}. Let sub(φ) be the set of all subformulas of φ. Note
that φ is also considered a subformula of φ itself. A sub-
formula of φ that is not φ itself is called a proper subfor-
mula. Given a set Φ of formulas, we also write sub(Φ) for
φ∈Φ sub(φ). An enumeration of the formulas in a set Φ of
formulas is in an admissible order if the enumeration is
generated as follows:

(cid:83)

AO-1 First, list the formulas for which the outermost op-
erator is Y. Among these formulas, list the superfor-
mulas before the subformulas.

Algorithm 1: Update(G, B)

: G ∈ G[V,R ∪ E]

1 in
2 in out: B : sub(ran(policy)) × V (G) × V (G) → B
3 for φ ∈ sub(ran(policy)), in an admissible order, do

for u ∈ V (G) do
for v ∈ V (G) do
switch φ do
case (cid:62)
B[φ][u][v] ← 1;
case target
B[φ][u][v] ← (u = v);
case ¬φ1
B[φ][u][v] ← ¬B[φ1][u][v];
case φ1 ∨ φ2
B[φ][u][v] ← B[φ1][u][v] ∨ B[φ2][u][v];
case (cid:104)l(cid:105)φ1
G(u) B[φ1][u(cid:48)][v];
G(u) B[φ1][u(cid:48)][v];

B[φ][u][v] ←(cid:87)
B[φ][u][v] ←(cid:87)

case (cid:104)−l(cid:105)φ1

u(cid:48)∈succl

u(cid:48)∈predl

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

case Y φ1
B[φ][u][v] ← B[φ1][u][v];
case φ1 S φ2
B[φ][u][v] ← B[φ2][u][v]∨ (B[φ][u][v]∧ B[φ1][u][v]);

AO-2 Second, list the remaining formulas, with subformu-

las listed before the superformulas.

For example, the following enumeration of the members of
sub(Y Y(cid:104)l(cid:105)target) is in an admissible order:

Y Y(cid:104)l(cid:105)target

Y(cid:104)l(cid:105)target

target

(cid:104)l(cid:105)target

7.4 Reference Monitor State
a pair of data structures (cid:104)G, B(cid:105):

The mutable state of the reference monitor is captured in

1. G is a relational structure, and
2. B : sub(ran(policy)) × V (G) × V (G) → B is a three-
dimensional boolean matrix. The ﬁrst index is a sub-
formula of a member of ran(policy), which is the set of
formulas used by the protection system for guarding
event identiﬁers. The last two indices are vertices of
G. Each entry of the matrix holds a boolean value.

It is an invariant of the reference monitor that, after the t’th
transition, the following conditions hold:

G = Gt

B[φ][u][v] = 1 iﬀ γt, u, v |= φ

(5)

(6)

7.5 Authorization and State Transition

At time point t, suppose an event signature e(u, v) is in-
tercepted, then the following steps will be performed by the
reference monitor:

1. Look up formula φ = policy(e).

2. Look up B[φ][u][v]. If the value is 0, reject the event
signature. Otherwise, proceed with the following steps.

3. Update G to Gt+1.

5914. Update B by invoking Algorithm 1. The algorithm
takes two arguments: (a) the updated graph G, and
(b) the matrix B. On return, B will be updated.

(It is assumed that system parameters such as R, E and
policy are global information known to the algorithm.) Steps
1 and 2 are responsible for making authorization decisions.
Steps 3 and 4 are responsible for updating the internal state
of the reference monitor. At the core of this procedure is
the invocation of Algorithm 1 to update B.

We explain how Algorithm 1 works at the intuitive level.
The algorithm essentially goes through the entries of the ma-
trix B in a speciﬁc order, updating each entry it encounters
by values of other entries. Lines 8, 10, 12, 14, 16 and 18 are
direct encoding of the semantic deﬁnitions of (cid:62), target, ¬,
∨, (cid:104)l(cid:105) and (cid:104)−l(cid:105). Line 20 is the encoding of (3), the expansion
law for Y. Line 22 is the encoding of (4), the expansion law
for S. The correctness of the algorithm hinges on the order
in which the subformulas are enumerated on line 3.

Theorem 7. Suppose B satisﬁes invariant (6).

If Al-
gorithm 1 is invoked with Gt+1 and B, then on return B
satisﬁes the following condition:

B[φ][u][v] = 1 iﬀ γt+1, u, v |= φ

To establish invariants (5) and (6) in the ﬁrst place, the
reference monitor is to (i) set G to G0, (ii) set all entries of
B to 0, and then (iii) invoke Algorithm 1.

Theorem 8. Let M = (cid:80)
and E = (cid:80)

φ∈ran(policy) |φ|, N = |V (G)|,
l∈R∪E |Rl(G)|. Algorithm 1 runs in time
O(M N (N + E)). The space requirement for the reference
monitor is the space for maintaining G plus O(M N 2) bits
overhead for matrix B.
7.6 Reference Monitor as ReBAC System

Speciﬁcally,

The boolean matrix B could be seen as an array of adja-
cency matrices.
for each formula φ in
sub(ran(policy)), the submatrix B[φ][·][·] characterizes a bi-
nary relation Rφ over V (G), such that (u, v) ∈ Rφ iﬀ γt, u,
v |= φ. Therefore, the internal state of the reference monitor,
comprising of G and B, could be seen as a single relational
structure (cid:104)V (G),{Rl}l∈L(cid:105) where L = R∪E∪sub(ran(policy)).
If we interpret the reference monitor state in this way, then
the reference monitor essentially tracks a single relational
structure, and makes authorization decisions by consulting
the topology of this relational structure. In short, the refer-
ence monitor is essentially a ReBAC system! Speciﬁcally, if
the entities of the community are all users, then the reference
monitor is a social network system.

This result is surprising. Even though we have introduced
a temporal dimension to policy predicates, it turns out that
the enforcement of these policies requires only the tracking
of a single relational structure, rather than a full history
of relational structures, as long as we specify policy predi-
cates using T R. That is, space eﬃciency is predicated on
restraining the expressiveness of our policy language.

What is even more interesting is the way history infor-
mation is tracked. Speciﬁcally, history information is ab-
stracted into binary relations between entities (i.e., the bi-
nary relations Rφ above). This is possible because the pol-
icy language can only express the past dealings between two
parties (i.e., the initiator and the target). This is essen-
tially a generalization of the core observation of [16]. It has

been observed in [16] that a modal logic with exactly one
propositional symbol can be used for representing a binary
relation between two entities in a relational structure.
In
our policy language, this is generalized to include a tempo-
ral dimension: a modal-temporal language with exactly one
propositional symbol can be used for representing the past
dealings between two entities. We call this methodological
technique relational abstraction:

By constraining the policy language to express
only past dealings between two entities, history
information can be tracked by binary relations.

8. A HYBRID POLICY LANGUAGE

While the policy language T R serves well in highlighting
the core thesis of this work, it is limited in expressive power.
In § 8.1, we extend T R by incorporating constructs from
hybrid logic [1, 6]. Hybrid logic oﬀers constructs that are
normally found in ﬁrst-order logic rather than modal logic:
the ability to name an entity and later on refer to it. This
is required for separating entities and to reposition search
focus. Then in § 8.2, we look at the enforcement of policies
under this extension, especially in how the core thesis of this
work is played out in such an expressive language.
8.1 Hybridization
T R, resulting in a policy language that we call HT R.
8.1.1
The syntax of HT R diﬀers from T R in two ways: (1) the
specialized propositional symbol target is now generalized
to entity variables, and (2) new constructs are introduced
for deﬁning entity variables and repositioning the crawling
agent. The grammar of a formula in HT R is shown below.

We introduce hybrid constructs into the policy language

Syntax

φ ::= (cid:62) | ¬φ | φ ∨ φ | (cid:104)l(cid:105)φ | (cid:104)−l(cid:105)φ | Y φ | φS φ |

x | ↓ x . φ | @x φ

(7)
where l ∈ L, L is the edge label set, and x ∈ Var is an
entity variable. We assume that the set Var provides a
countably inﬁnite supply of entity variables, and that target
is a distinguished member of Var.
On the ﬁrst line of (7) are the constructs inherited from
T R (with the omission of target). Hybridization introduces
three new constructs on the second line. Common to the
three constructs is the assumption that a formula is evalu-
ated with respect to a variable assignment. A variable
assignment deﬁnes the values of some entity variables. In
particular, each variable is bound to a single entity in the
relational structure. The ﬁrst new construct x, an entity
variable, tests if the crawling agent is currently located at
the entity referenced by x. This is a generalization of target,
as target is but a member of Var. A second new construct
is the binder (↓). The formula ↓ x . φ introduces a new
variable deﬁnition, binding x to the current location of the
crawling agent. The third new construct is the satisfaction
operator (@x). The formula @x φ repositions the crawling
agent to the entity referenced by x, and then evaluates φ
from that location. The formal semantics is given below.
8.1.2
The semantics of formulas is given by the relation γ, i, g, u (cid:13)
φ. As before, φ is evaluated in the context of a trace γ =

Semantics

592G0 . . . Gn, recording the history of evolution of a relational
structure. During evaluation, the crawling agent is situated
a certain time index i where 0 ≤ i ≤ n, and located at a cer-
tain entity u ∈ V (Gi). In addition, the formula is evaluated
against a variable assignment g : Var (cid:42) V, which assigns
an entity to each of the variables in dom(g). Formally, the
evaluation of formulas is deﬁned as follows.

• γ, i, g, u (cid:13) (cid:62) always holds.
• γ, i, g, u (cid:13) ¬φ iﬀ it is not the case that γ, i, g, u (cid:13) φ.
• γ, i, g, u (cid:13) φ1 ∨ φ2 iﬀ γ, i, g, u (cid:13) φ1 or γ, i, g, u (cid:13) φ2.
• γ, i, g, u (cid:13) (cid:104)l(cid:105)φ iﬀ there exists u(cid:48) ∈ V (Gi) such that

(u, u(cid:48)) ∈ Rl(Gi) and γ, i, g, u(cid:48) (cid:13) φ.

• γ, i, g, u (cid:13) (cid:104)−l(cid:105)φ iﬀ there exists u(cid:48) ∈ V (Gi) such that

(u(cid:48), u) ∈ Rl(Gi) and γ, i, g, u(cid:48) (cid:13) φ.

• γ, i, g, u (cid:13) Y φ iﬀ i > 0 and γ, i − 1, g, u (cid:13) φ.
• γ, i, g, u (cid:13) φ1 S φ2 iﬀ there exists j, 0 ≤ j ≤ i, such
that both (a) γ, j, g, u (cid:13) φ2, and (b) for all k, j < k ≤ i,
we have γ, k, g, u (cid:13) φ1.
• γ, i, g, u (cid:13) x iﬀ u = g(x).
• γ, i, g, u (cid:13)↓ x . φ iﬀ γ, i, g[x (cid:55)→ u], u (cid:13) φ.
• γ, i, g, u (cid:13) @x φ iﬀ γ, i, g, g(x) (cid:13) φ.

All the semantic rules are familiar except for the last three.
The construct x tests if the crawling agent is located at the
entity referenced by x (i.e., u = g(x)). The construct ↓ x . φ
extends the current assignment into g[x (cid:55)→ u], in which x is
bound to the current location u, and then the subformula φ
is evaluated with this extended assignment. The construct
@x φ repositions the crawling agent at g(x), that is, the en-
tity referenced by variable x, before φ is evaluated.
We introduce two shorthands. First, we write γ, u, v (cid:13)x φ
to assert γ, n,{x (cid:55)→ v}, u (cid:13) φ, where n = |γ| − 1. This
shorthand asserts that a certain binary relationship exists
between u and v within the trace γ, and the binary relation
is speciﬁed as formula φ, where the variable x is used in φ
to denote the second end point of the relationship. Second,
we write γ, u, v (cid:13) φ to assert γ, u, v (cid:13)target φ.
8.1.3 Derived forms and other syntactic conventions
The same set of derived forms from § 6.3 can be deﬁned

for the extended language.

With the introduction of entity variables and the binder,
the notion of free variables will play a crucial role in the
following discussion. Intuitively, a free variable is one that
is not within the scope of a binder that deﬁnes that variable.
Given a formula φ, we write fv(φ) for the set of free variables
of φ. The formal deﬁnition of fv(·) is given in [17].

A formula φ is regular iﬀ it satisﬁes the following:

1. No two binders in φ bind the same variable. (That is,

every binder deﬁnes a unique variable.)

2. For every subformula of φ that has the form ↓ x . φ1,
we have x ∈ fv(φ1). (That is, no binder is redundant.)
By renaming variables and eliminating redundant binders,
every irregular formula can be rewritten into a semantically
equivalent formula that is regular, without increase in for-
mula size. From now on, we assume that all formulas are
regular. We call this the regularity convention.

8.1.4 Policy Predicate
Given a formula φ for which fv(φ) ⊆ {target}, we write
[[φ]] to denote the policy predicate induced by φ, such that
[[φ]](γ, u, v) returns 1 iﬀ γ, u, v (cid:13) φ. As before, we adopt the
convention that the policy component of a protection system
maps event identiﬁers to formulas.

8.1.5 Examples
We illustrate the utility of hybridization with two exam-
ples. The ﬁrst illustrates the use of hybrid constructs to
“reposition” the crawler.

The advanced example below illustrates the use of hybrid
constructs to name entities in the present, and then go back
in time to verify past relationships among named entities.

Example 9

(Online Coauthoring Communities).

Revisiting Example 6, we specify Policy 2 of Example 2 using
HT R. We begin by deﬁning a utility formula φo.

φo = @o ¬O(cid:104)−edit(cid:105)(cid:62)

(8)

Given an entity variable o, the formula φo checks that o has
never been edited in the past. With this, the requirements of
Policy 2 can be captured by the following formula.

(cid:17)
¬(cid:16) ↓ s .(cid:104)own(cid:105) ↓ o1 . @s(cid:104)own(cid:105) ↓ o2 .(¬o1 ∧ φo1 ∧ φo2 )

(9)

The formula above begins by deﬁning two entity variables,
o1 and o2, both are owned by the initiator s in the present
(↓ s .(cid:104)own(cid:105) ↓ o1 . @s(cid:104)own(cid:105) ↓ o2 . . . .). It then checks that o1
and o2 are distinct (¬o1). The check φo is then applied to
both o1 and o2, verifying that each of o1 and o2 has never
been edited in the past. Finally, the above check corresponds
to a violation of Policy 2, and thus the outermost negation
(¬) ensures absence of violations. To appropriate the above,
we set policy(create) to the conjunction of (2) and (9).
8.2 Enforcement

The enforcement of HT R is non-trivial. With T R, the
evaluation of every subformula can be tracked by a binary
relation in the internal state of the reference monitor. This
is possible because there is only one propositional symbol.
By hybridization, we introduce an arbitrary number of vari-
ables into subformulas. Speciﬁcally, a formula with k free
variables represents a relation of arity k + 1. Therefore, the
space requirement of the reference monitor grows exponen-
tially with the number of variables involved.
Fortunately, one can constrain the expressiveness of HT R
slightly, to obtain a language fragment that still retains
much of the advantages of the hybrid language, but yields a
reference monitor with the same space requirement of T R.
The trick, again, is relational abstraction, now applied in
a meticulous manner. We will demonstrate once again the
core thesis of § 7.6, that the reference monitor of the result-
ing policy language is comparable to a ReBAC system.

8.2.1 Overview of Strategy
A temporal formula is one in which the outermost oper-
ator is a temporal operator (i.e., Y φ or φ1 S φ2). Note that
the reference monitor needs to track additional state infor-
mation (i.e., B) other than the current relational structure
(i.e., G) because of the existence of temporal subformulas. If
a formula contains no temporal operators, then a local model
checking algorithm for hybrid logic, such as the one in [6],

593will suﬃce. It is when state transition occurs that the up-
date algorithm needs to abstract the evaluation of temporal
subformulas into binary relations. To apply this technique
of relational abstraction, we impose syntactic restrictions on
the hybrid policy language, such that every temporal subfor-
mula of a policy must have no more than one free variable.
With this restriction, temporal subformulas again represent
binary relations, which can be tracked by the reference mon-
itor in a space-eﬃcient manner. As before, this amounts to
the reference monitor tracking a single relational structure,
such that history information is recorded as edges.

The syntactic restriction still allows certain subformulas
to express higher-arity relations, so long as they are not tem-
poral formulas. Intuitively, the crawling agent is allowed to
remember multiple locations through the use of variables so
long as it is crawling within the relational structure of a sin-
gle time point. When the agent moves through time, then
it is only allowed to remember at most one variable. With
these restrictions, the subformulas that represent binary re-
lations are handled by a bottom-up update algorithm in the
spirit of [26], and the higher-arity relations are handled by a
top-down update algorithm [19], which trades time eﬃciency
for space eﬃciency. Our novelty is in the careful scheduling
of top-down and bottom-up processing by exploiting the the
syntactic structure of the language fragment, as well as com-
bining the techniques of [19] and [26].

8.2.2 A Language Fragment
A formula φ is proper iﬀ both conditions below hold.
1. |fv(φ(cid:48))| ≤ 1 for every temporal subformula φ(cid:48) ∈ sub(φ).

2. fv(φ) ⊆ {target}.

Intuitively, a proper formula is such that every temporal
subformula has at most one free variable, and the only free
variable permitted in the formula itself is target. Let HT R−
be the fragment of HT R that contains only proper formulas.
Given a formula in HT R, checking if it is proper (and
thus belongs to HT R−) takes time linear to the size of the
formula. This is achieved simply by calling fv(·) once on the
formula, annotating each subformula by its free variables,
and checking that the two conditions above hold.
The following example illustrates that, despite requiring
temporal subformulas to be proper, HT R− is still expressive
enough for specifying useful policies.

Example 10. Formulas (8) and (9) from Example 9 are

both proper. See Example 11 for a justiﬁcation.

8.2.3 Preprocessing via Annotation
Our claim is that HT R− permits a space-eﬃcient imple-
mentation of the reference monitor, because temporal for-
mulas represent binary relations rather than high-arity rela-
tions. To help the reference monitor recognize subformulas
that correspond to binary relations, so that the reference
monitor can switch to an appropriate model checking strat-
egy for each kind of subformulas (i.e., bottom-up for binary
relations, and top-down for higher-arity relations), we intro-
duce an annotation scheme for formulas in HT R. Speciﬁ-
cally, we introduce an annotation construct (cid:100)·(cid:101)x for HT R
formulas and their subformulas.

The grammar for an annotated formula ϕ is given be-

low.

ϕ ::= ρ | (cid:100)ρ(cid:101)x
ρ ::= (cid:62) | ¬ϕ | ϕ ∨ ϕ | (cid:104)l(cid:105)ϕ | (cid:104)−l(cid:105)ϕ | Y ϕ | ϕS ϕ |

x | ↓ x . ϕ | @x ϕ

An annotated formula is like an HT R formula, except that
each subformula (including the formula itself) can be op-
tionally decorated by an annotation construct. If an HT R
formula φ is obtained from an annotated formula ϕ by re-
moving all occurrences of the annotation construct, then φ
is said to be the erasure of ϕ, and ϕ is said to be an an-
notation of φ.
The intended meaning of an annotated formula (cid:100)ρ(cid:101)x is
that fv(ρ) ⊆ {x}. Intuitively, (cid:100)·(cid:101)x imposes an “upper bound”
to the free variable set of ρ. We make this requirement
formal as follows. First, we extend the deﬁnition of fv(·) to
account for annotated formulas:

fv((cid:100)ρ(cid:101)x) = fv(ρ) ∪ {x}

Second, ϕ is well annotated if every subformula (including
ϕ itself) of the form (cid:100)ρ(cid:101)x is such that fv(ρ) ⊆ {x}. That
is, a well annotated formula is one in which the annotation
constructs mean what they are supposed to mean.

A well annotated formula ϕ is properly annotated (or

simply proper ) iﬀ both of the following conditions hold.

1. Every temporal subformula ρ is decorated by an anno-

tation construct, as in (cid:100)ρ(cid:101)x, for some variable x.

2. ϕ is of the form (cid:100)ρ(cid:101)target.

A properly annotated formula ϕ is completely annotated
(or simply complete) iﬀ every subformula ρ that satisﬁes
|fv(ρ)| ≤ 1 is decorated by an annotation construct (cid:100)·(cid:101)x for
some appropriately selected x. Intuitively, a complete anno-
tation is one in which every subformula that can potentially
be annotated without violating the well-annotation require-
ment is indeed annotated. That is, a complete annotation
conveys maximal information to the model checker.

Example 11

(Online Coauthoring Communities).
A complete annotation of (8) in Example 9 is the following.

φo = (cid:100)@o(cid:100)¬(cid:100)O(cid:100)(cid:104)−edit(cid:105)(cid:100)(cid:62)(cid:101)o(cid:101)o(cid:101)o(cid:101)o(cid:101)o

A complete annotation of (9) in Example 9 is given below.

(cid:100)¬(cid:100)↓ s .(cid:100)(cid:104)own(cid:105)(cid:100)↓ o1 . @s(cid:100)(cid:104)own(cid:105)(cid:100)↓ o2 .

((cid:100)(cid:100)¬(cid:100)o1(cid:101)o1(cid:101)o1 ∧ φo1(cid:101)o1∧

φo2 )(cid:101)o1(cid:101)o1(cid:101)s(cid:101)s(cid:101)target(cid:101)target

The following proposition oﬀers alternative characteriza-

tions of the HT R− language.

Proposition 12.
1. An HT R formula φ is in HT R− iﬀ φ has a proper

annotation.

2. The complete annotation of an HT R formula exists
whenever the formula belongs to HT R−. When it ex-
ists, the complete annotation of an HT R formula is
unique.

5943. Given an HT R− formula φ, constructing its complete

annotation takes only time linear to the size of φ.

Given a completely annotated formula ϕ, a subformula
of the form (cid:100)ρ(cid:101)x is called an α subformula:
i.e., α subfor-
mulas represent binary relations. A subformula that is not
decorated in ϕ is called a β subformula:
i.e., β subformu-
las represent higher-arity relations. See the Appendix for a
formal treatment.

Hereafter we assume that the policy component of the
protection system maps event identiﬁers to completely anno-
tated formulas. That is, the inputs to the update algorithm
of the reference monitor are completely annotated formulas.

8.2.4 Reference Monitor Implementation
The reference monitor for HT R− has the same basic struc-
ture as the one in § 7. Speciﬁcally, its internal state is a pair
(cid:104)G, B(cid:105), similar to the pair discussed in § 7.4, and this state
is updated using the steps described in § 7.5. The main dif-
ferences are two. First, the dimensions of B are slightly
diﬀerent from before. Second, in Step 4 of the update pro-
cedure, rather than invoking Algorithm 1 for updating B, a
diﬀerent algorithm is invoked.

The component B of the monitor state is a three-dimensional

boolean matrix. There is an entry B[α][u][v] for every α sub-
formula of members of ran(policy) and for every u, v ∈ V (G).
The diﬀerence is that, in the previous monitor state the
ﬁrst dimension ranges among the subformulas of ran(policy),
whereas for the present monitor state the ﬁrst dimension
ranges among the α subformulas of ran(policy).

The invariant of the reference monitor is the conjunction

of (5) and the following.

B[(cid:100)ρ(cid:101)x][u][v] = 1 iﬀ γt, u, v (cid:13)x erasure(ρ)

(10)

Here, erasure(ρ) denotes the erasure of ρ. While the index
v in (6) is the entity referenced by target, the index v in (10)
is the entity referenced by the annotation variable x.
The updating of B is conducted by a pair of algorithms
in the Appendix. The updating of entries B[ϕ][·][·], for α
subformulas ϕ, is handled by a bottom-up algorithm in the
style of Algorithm 1. A top-down algorithm is invoked as a
subroutine to process β subformulas.

8.2.5 Complexity
To articulate the time complexity of the update algo-
rithms, we deﬁne the notion of local binder nesting degree
(LBND) of an α formula. Speciﬁcally, the LBND of (cid:100)ρ(cid:101)x
is the nesting degree of binders (↓) that appear within the
top-level decoration (cid:100)·(cid:101)x but not in nested decorations. For
example, the LBND of the following formula is 2.
(cid:100)(↓ x2 . ↓ x3 . . . .(cid:100)↓ x5 . . . .(cid:101)x4 ) ∧ (↓ x6 . . . .)(cid:101)x1

Theorem 13. Let M = (cid:80)
E =(cid:80)

ϕ∈ran(policy) |ϕ|, N = |V (G)|,
l∈R∪E |Rl(G)|, and D be the maximum LBND among
all members of ran(policy). The update algorithm in the Ap-
pendix runs in time O(M N D+1(N + E)). The space usage
is the size of G plus O(M N 2) bits overhead for matrix B.

So long as we limit D to a constant, the time complexity
is polynomial. To put this into perspective, the formulas in
Example 9 has a maximum LBND of 1 (see also Example
11).

9. CONCLUSION AND FUTURE WORK

We proposed an access control model for supporting col-
laborative communities that are founded on social contracts
made up of both relationship- and history-based elements.
Through the development of a series of policy languages and
their reference monitors, we demonstrated the thesis that,
although CSC oﬀers the convenience of speciﬁcation via both
relationship- and history-based policy elements, the under-
lying enforcement mechanism can be rendered purely rela-
tionship based. This space eﬃciency is achieved by rela-
tional abstraction, in which the past dealings between two
parties are abstracted into edges in a relational structure.

Future work includes the formal characterization of ex-
pressiveness: What policies can be enforced via relational
abstraction? Another direction is to explore the optimiza-
tion of the update algorithm for the reference monitor: If
the transition relation only makes local changes to the social
state, then can we bound the updates made to the reference
monitor state? A third direction is the development of tech-
nologies for facilitating policy engineering. This includes the
devising of graphical formalisms for editing policies, captur-
ing reusable social contract patterns at a higher level of ab-
straction, and designing policy composition frameworks for
combining canned policy modules.
10. ACKNOWLEDGMENTS

We thank the anonymous reviewers for their helpful com-
ments. This research was supported in part by an NSERC
Discovery Grant and a Canada Research Chair.
11. REFERENCES
[1] Carlos Areces and Balder ten Cate. Hybrid logics. In

Patrick Blackburn, Johan van Benthem, and Frank
Wolter, editors, Handbook of Modal Logic, chapter 14,
pages 821–868. Elsevier, 2007.

[2] C. Baier and J.-P. Katoen. Principles of Model

Checking. MIT, 2008.

[3] H. Barringer, A. Goldberg, K. Havelund, and K. Sen.

Rule-based runtime veriﬁcation. In Proc. of
VMCAI’04, volume 2937 of LNCS, 2004.

[4] D. Basin, F. Klaedtke, and S. M¨uller. Policy

monitoring in ﬁrst-order temporal logic. In Proc. of
CAV’10, volume 6174 of LNCS, 2010.

[5] P. Blackburn, M. de Rijke, and Y. Venema. Modal

Logic. Cambridge, 2001.

[6] G. Bruns, P. W. L. Fong, I. Siahaan, and M. Huth.

Relationship-based access control: Its expression and
enforcement through hybrid logic. In Proc. of
CODASPY’12, San Antonio, TX, USA, Feb. 2012.

[7] B. Carminati, E. Ferrari, R. Heatherly,

M. Kantarcioglu, and B. Thurainsingham. A semantic
web based framework for social network access control.
In Proc. of SACMAT’09, Stresa, Italy, June 2009.

[8] B. Carminati, E. Ferrari, R. Heatherly,

M. Kantarcioglu, and B. Thuraisinghaim. Semantic
web-based social network access control. Computers
and Security, 30(2–3):108–115, 2011.

[9] B. Carminati, E. Ferrari, and A. Perego. Enforcing
access control in Web-based social networks. ACM
TISSEC, 13(1), 2009.

[10] Barbara Carminati and Elena Ferrari. Enforcing
relationships privacy through collaborative access

595control in web-based social networks. In Proceedings of
CollaborateCom’09, November 2009.

reputation systems. J. Computer Security,
16(1):63–101, 2008.

[11] Y. Cheng, J. Park, and R. Sandhu. Relationship-based

access control for online social networks: Beyond
user-to-user relationships. In Proc. of the 4th IEEE
Int. Conf. on Information Privacy, Security, Risk &
Trust (PASSAT’12), Amsterdam, Netherlands,
September 2012.

[12] Y. Cheng, J. Park, and R. Sandhu. A user-to-user
relationship-based access control model for online
social networks. In Proceedings of DBSec’12, 2012.

[13] Jan Chomicki. Eﬃcient checking of temporal integrity

constraints using bounded history encoding. ACM
TODS, 20(2), 1995.

[14] ´Ulfar Erlingsson and Fred B. Schneider. IRM

enforcement of Java stack inspection. In Proc. of the
2000 IEEE Symp. on Security and Privacy (S&P’00),
pages 246–255, Berkeley, CA, USA, May 2000.

[15] Philip W. L. Fong. Access control by tracking shallow

execution history. In Proceedings of the 2004 IEEE
Symposium on Security and Privacy (S&P’04), pages
43–55, Berkeley, CA, USA, May 2004.

[16] Philip W. L. Fong. Relationship-based access control:

Protection model and policy language. In Proc. of
CODASPY’11, San Antonio, TX, USA, Feb. 2011.

[17] Philip W. L. Fong, Pooya Mehregan, and Ram

Krishnan. Relational abstraction in community-based
secure collaboration. Technical Report 2013-1045-12,
Department of Computer Science, University of
Calgary, August 2013.

[18] Philip W. L. Fong and Ida Siahaan. Relationship-

based access control policies and their policy
languages. In Proc. of SACMAT’11, Innsbruck,
Austria, June 2011.

[19] M. Franceschet and M. de Rijke. Model checking

hybrid logics. J. Applied Logic, pages 279–304, 2006.

[20] Carrie E. Gates. Access Control Requirements for
Web 2.0 Security and Privacy. In IEEE W2SP’07,
Oakland, CA, USA, 2007.

[21] K. W. Hamlen, G. Morrisett, and F. B. Schneider.
Computability classes for enforcement mechanisms.
ACM TOPLAS, 28(1), 2006.

[22] R. Krishnan, J. Niu, R. Sandhu, and W. H.

Winsborough. Group-centric secure information
sharing models for isolated groups. ACM TISSEC,
14(3), 2011.

[23] R. Krishnan and R. Sandhu. Authorization policy

speciﬁcation and enforcement for group-centric secure
information sharing. In Proc. of the 7th Int. Conf. on
Info. Sys. Security (ICISS’11), volume 7093 of LNCS.
Springer, 2011.

[24] Ram Krishnan, Ravi Sandhu, Jianwei Niu, and

William Winsborough. Foundations for group-centric
secure information sharing models. In Proceedings of
SACMAT’09, Stresa, Italy, June 2009.

[25] K. Krukow, M. Nielsen, and V. Sassone. A framework

for concrete reputation-systems with applications to
history-based access control. In Proceedings of
CCS’05, Alexandria, VA, USA, November 2005.

[26] K. Krukow, M. Nielsen, and V. Sassone. A logical

framework for history-based access control and

[27] M. H. Lessnoﬀ. Social Contract. Macmillan, 1986.
[28] J. Ligatti, L. Bauer, and D. Walker. Run-time

enforcement of non-safety policies. ACM TISSEC,
12(3), 2009.

[29] J. Park, R. Sandhu, and Y. Cheng. ACON:

Activity-centric access control for social computing. In
Proc. of the 5th Int. Conf. on Availability, Reliability
& Security (ARES’11), Vienna, Austria, August 2011.

[30] J. Park, R. Sandhu, and Y. Cheng. A

user-activity-centric framework for access control in
online social networks. IEEE Internet Computing,
15(5), 2011.

[31] F. B. Schneider. Enforceable security policies. ACM

TISSEC, 3(1), 2000.

APPENDIX
A. PRELIMINARIES

Completely annotated formulas have certain structures.
Observation 14. The complete annotation ϕ of an HT R−

formula satisﬁes the following grammar:

ψ ::= α | β

ϕ ::= α
α ::= (cid:100)(cid:62)(cid:101)x | (cid:100)¬α(cid:101)x | (cid:100)α ∨ α(cid:101)x | (cid:100)(cid:104)l(cid:105)α(cid:101)x | (cid:100)(cid:104)−l(cid:105)α(cid:101)x |
(cid:100)Y α(cid:101)x | (cid:100)αS α(cid:101)x | (cid:100)x(cid:101)x | (cid:100)↓ x . ψ(cid:101)x | (cid:100)@x α(cid:101)x

β ::= ¬ψ | ψ ∨ ψ | (cid:104)l(cid:105)ψ | (cid:104)−l(cid:105)ψ | ↓ x . ψ | @x ψ

If we construct the abstract syntax tree (AST) of a com-
pleted annotated formula ϕ according to the grammar above,
then we call an AST node that corresponds to the non-
terminal α an α subformula, and one that corresponds to
the non-terminal β a β subformula.

The syntactic structure of a complete annotation ϕ pro-
vides the recursive structure of the model checker. As we
shall see, the α subformulas are processed bottom-up, while
the β subformulas are processed top-down.

Let subα(ϕ) and subβ(ϕ) denote respectively the set of α
subformulas and the set of β subformulas of a completely an-
notated formula ϕ. We write subψ(ϕ) for subα(ϕ)∪ subβ(ϕ).
As before, we overload subα(·), subβ(·) and subψ(·) to take
a set of completely annotated formulas as an argument:
i.e., if Φ is a set of completely annotated formulas, then
subα(Φ) = ∪ϕ∈Φsubα(ϕ).

Given a set Φ of α formulas, an enumeration of Φ’s mem-
bers is in an admissible order if the enumeration is gener-
ated in accordance to the following.

First, list the α formulas of the form (cid:100)Y α(cid:101)x.

α-AO-1

Among them, list superformulas before subformulas.

α-AO-2

Second, list the remaining α formulas, with sub-

formulas listed before superformulas.

B. UPDATING ALGORITHMS

In Step 4 of the update procedure, Algorithm 2 is invoked
Algorithm 2, Update⇑,

to update B. Algorithm 2 in turn invokes Algorithm 3.
is a bottom-up model checking
algorithm for α subformulas. Algorithm 3, Update⇓, is a
top-down model checking algorithm invoked by Update⇑ to
evaluate β subformulas. The recursion pattern of the two
algorithms closely follow the grammar in Observation 14.

5966

7

8

9

: G ∈ G[V,R ∪ E]
: C : subψ(ran(policy)) × V (G) → B

Algorithm 2: Update⇑(G, B)
1 in
2 in out: B : subα(ran(policy)) × V (G) × V (G) → B
3 local
4 for α ∈ subα(ran(policy)), in an admissible order, do
5 for u ∈ V (G) do
for v ∈ V (G) do
switch α do
case (cid:100)(cid:62)(cid:101)x
B[α][u][v] ← 1;
case (cid:100)¬α1(cid:101)x
B[α][u][v] ← ¬B[α1][u][v];
case (cid:100)α1 ∨ α2(cid:101)x
B[α][u][v] ← B[α1][u][v] ∨ B[α2][u][v];
case (cid:100)(cid:104)l(cid:105)α1(cid:101)x
G(u) B[α1][u(cid:48)][v];
G(u) B[α1][u(cid:48)][v];

B[α][u][v] ←(cid:87)
B[α][u][v] ←(cid:87)

case (cid:100)(cid:104)−l(cid:105)α1(cid:101)x

u(cid:48)∈predl

u(cid:48)∈succl

case (cid:100)Y α1(cid:101)x
B[α][u][v] ← B[α1][u][v];
case (cid:100)α1 S α2(cid:101)x
B[α][u][v] ← B[α2][u][v]∨ (B[α][u][v]∧ B[α1][u][v]);
case (cid:100)x(cid:101)x
B[α][u][v] ← (u = v);
case (cid:100)↓ x . ψ1(cid:101)y
Update⇓(G, B, C, ψ1,{x (cid:55)→ u, y (cid:55)→ v});
B[α][u][v] ← C[ψ1][u];
case (cid:100)@x α1(cid:101)x
B[α][u][v] ← B[α1][v][v];

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

Algorithm 2. The bottom-up model checker Update⇑
has a structure almost identical to that of Update. It enu-
merates α subformulas in some admissible order, as deﬁned
by α-AO-1 and α-AO-2 (line 4). For each subformula α,
it updates the submatrix B[α][·][·]. The updates of lines 9,
11, 13, 15, 17, 19 and 21 are identical to their counterparts
in Algorithm 1. Line 23 functions in the same way as line
10 of Algorithm 1. Line 28 performs update in the case of
(cid:100)@x α1(cid:101)x. (Note that the x in (cid:100)·(cid:101)x must be the same vari-
able as the x in @x α1.) Essentially the evaluation of @x α1
at u is the same as the evaluation of α1 at v, which is the
entity referenced by x.
The genuinely complex case is that of (cid:100)↓ x . ψ1(cid:101)y, the up-
date of which begins on line 24. What is at stake is that B
is only capable of diﬀerentiating the evaluations of an α for-
mula (cid:100)ρ(cid:101)x at entity u for diﬀerent bindings of x. The binder
(↓) now introduces an additional binding, causing B not to
be able to capture the bindings of multiple variables. Con-
sequently, the bottom-up model checking strategy no longer
applies. The top-down updating algorithm (Algorithm 3)
is thus invoked (line 25) to evaluate ψ1 with an extended
variable assignment (containing assignments for both x and
y). The result of evaluation is deposited into the matrix C.
Such results are then copied back into B (line 26).
Algorithm 3. The top-down algorithm Update⇓ evalu-
ates a formula ψ in G at every u ∈ V (G), with a variable
assignment g that deﬁnes the free variables in ψ. On return,
the evaluation results are stored in a boolean matrix C, such
that C[ψ][u] holds the evaluation of ψ at entity u.

8

9

: G ∈ G[V,R ∪ E]
: B : subα(ran(policy)) × V (G) × V (G) → B
: ψ ∈ subψ(ran(policy))
: g : Var (cid:42) V (G)

Algorithm 3: Update⇓(G, B, C, ψ, g)
1 in
2 in
3 in out: C : subψ(ran(policy)) × V (G) → B
4 in
5 in
6 switch ψ do
case ¬ψ1
7
Update⇓(G, B, C, ψ1, g);
for u ∈ V (G) do
C[ψ][u] ← ¬C[ψ1][u];
case ψ1 ∨ ψ2
Update⇓(G, B, C, ψ1, g);
Update⇓(G, B, C, ψ2, g);
for u ∈ V (G) do
C[ψ][u] ← C[ψ1][u] ∨ C[ψ2][u];
case (cid:104)l(cid:105)ψ1
Update⇓(G, B, C, ψ1, g);
for u ∈ V (G) do

u(cid:48)∈succl

G(u) C[ψ1][u(cid:48)];

C[ψ][u] ←(cid:87)
C[ψ][u] ←(cid:87)

case (cid:104)−l(cid:105)ψ1
Update⇓(G, B, C, ψ1, g);
for u ∈ V (G) do

u(cid:48)∈predl

G(u) C[ψ1][u(cid:48)];

case @x ψ1
Update⇓(G, B, C, ψ1, g);
for u ∈ V (G) do
C[ψ][u] ← C[ψ1][g(x)];
case ↓ x . ψ1
for u ∈ V (G) do
Update⇓(G, B, C, ψ1, g[x (cid:55)→ u]);
C[ψ][u] ← C[ψ1][u];
case (cid:100)ρ(cid:101)x
for u ∈ V (G) do
C[ψ][u] ← B[ψ][u][g(x)];

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

The storage for C is allocated entirely in Algorithm 2 (line
3), and C is then passed into Algorithm 3 3. The matrix B
is passed as an input argument: i.e., it is not mutated.

The algorithm computes recursively. The base case is
when ψ is an α formula. Admissible ordering guarantees
that the evaluation of this α formula is already in B. Line
33 copies that evaluation from B to C. (Recall that, if ψ is
of the form (cid:100)ρ(cid:101)x, then B[ψ][u][v] is the evaluation of ψ at u
with the variable assignment g = {x (cid:55)→ v}.) The inductive
case is when ψ is a β formula. In this case, Update⇓ is called
recursively to evaluate the subformulas of ψ, the results of
which is used for evaluating ψ itself.
The cases of ¬ψ1, ψ1 ∨ ψ2, (cid:104)l(cid:105)ψ1, (cid:104)−l(cid:105)ψ1 and @x ψ1 are
relatively straightforward. The case of ↓ x . ψ1, however,
warrants further explanation. Speciﬁcally, when Update⇓ is
recursively invoked to evaluate the subformula ψ1 on line 29,
the variable assignment is extended to g[x (cid:55)→ u], such that
x points to u during the evaluation of ψ1.

3One could have presented Algorithm 3 in such a way that
the storage for C is allocated dynamically, on demand.
Such a presentation reduces comprehensibility without sav-
ing anything in the asymptotic space complexity.

597