A Secure Data Deduplication Scheme for Cloud

Storage

Jan Stanek∗, Alessandro Sorniotti†, Elli Androulaki†, and Lukas Kencl∗

Abstract. As more corporate and private users outsource their data
to cloud storage providers, recent data breach incidents make end-to-
end encryption an increasingly prominent requirement. Unfortunately,
semantically secure encryption schemes render various cost-eﬀective stor-
age optimization techniques, such as data deduplication, ineﬀective. We
present a novel idea that diﬀerentiates data according to their popular-
ity. Based on this idea, we design an encryption scheme that guarantees
semantic security for unpopular data and provides weaker security and
better storage and bandwidth beneﬁts for popular data. This way, data
deduplication can be eﬀective for popular data, whilst semantically se-
cure encryption protects unpopular content. We show that our scheme
is secure under the Symmetric External Decisional Diﬃe-Hellman As-
sumption in the random oracle model.

1

Introduction

With the rapidly increasing amounts of data produced worldwide, networked
and multi-user storage systems are becoming very popular. However, concerns
over data security still prevent many users from migrating data to remote stor-
age. The conventional solution is to encrypt the data before it leaves the owner’s
premises. While sound from a security perspective, this approach prevents the
storage provider from eﬀectively applying storage eﬃciency functions, such as
compression and deduplication, which would allow optimal usage of the resources
and consequently lower service cost. Client-side data deduplication in particular
ensures that multiple uploads of the same content only consume network band-
width and storage space of a single upload. Deduplication is actively used by a
number of cloud backup providers (e.g. Bitcasa) as well as various cloud services
(e.g. Dropbox). Unfortunately, encrypted data is pseudorandom and thus can-
not be deduplicated: as a consequence, current schemes have to entirely sacriﬁce
either security or storage eﬃciency.

In this paper, we present a scheme that permits a more ﬁne-grained trade-oﬀ.
The intuition is that outsourced data may require diﬀerent levels of protection,
depending on how popular it is: content shared by many users, such as a popular
song or video, arguably requires less protection than a personal document, the
copy of a payslip or the draft of an unsubmitted scientiﬁc paper.
Around this intuition we build the following contributions: (i) we present Eµ,
a novel threshold cryptosystem (which can be of independent interest), together
with a security model and formal security proofs, and (ii) we introduce a scheme
∗Czech Technical University in Prague. (jan.stanek|lukas.kencl)@fel.cvut.cz.
†IBM Research - Zurich, R¨uschlikon, Switzerland. (aso|lli)@zurich.ibm.com.

that uses Eµ as a building block and enables to leverage popularity to achieve
both security and storage eﬃciency. Finally, (iii) we discuss its overall security.

2 Problem Statement
Storage eﬃciency functions such as compression and deduplication aﬀord stor-
age providers better utilization of their storage backends and the ability to serve
more customers with the same infrastructure. Data deduplication is the process
by which a storage provider only stores a single copy of a ﬁle owned by sev-
eral of its users. There are four diﬀerent deduplication strategies, depending on
whether deduplication happens at the client side (i.e. before the upload) or at
the server side, and whether deduplication happens at a block level or at a ﬁle
level. Deduplication is most rewarding when it is triggered at the client side,
as it also saves upload bandwidth. For these reasons, deduplication is a critical
enabler for a number of popular and successful storage services (e.g. Dropbox,
Memopal) that oﬀer cheap, remote storage to the broad public by performing
client-side deduplication, thus saving both the network bandwidth and storage
costs. Indeed, data deduplication is arguably one of the main reasons why the
prices for cloud storage and cloud backup services have dropped so sharply.

Unfortunately, deduplication loses its eﬀectiveness in conjunction with end-
to-end encryption. End-to-end encryption in a storage system is the process by
which data is encrypted at its source prior to ingress into the storage system. It
is becoming an increasingly prominent requirement due to both the number of
security incidents linked to leakage of unencrypted data [1] and the tightening
of sector-speciﬁc laws and regulations. Clearly, if semantically secure encryption
is used, ﬁle deduplication is impossible, as no one—apart from the owner of
the decryption key—can decide whether two ciphertexts correspond to the same
plaintext. Trivial solutions, such as forcing users to share encryption keys or using
deterministic encryption, fall short of providing acceptable levels of security.

As a consequence, storage systems are expected to undergo major restruc-
turing to maintain the current disk/customer ratio in the presence of end-to-end
encryption. The design of storage eﬃciency functions in general and of dedupli-
cation functions in particular that do not lose their eﬀectiveness in presence of
end-to-end security is therefore still an open problem.

2.1 Related Work
Several deduplication schemes have been proposed by the research commu-
nity [2–4] showing how deduplication allows very appealing reductions in the
usage of storage resources [5, 6].

Most works do not consider security as a concern for deduplicating systems;
recently however, Harnik et al. [7] have presented a number of attacks that can
lead to data leakage in storage systems in which client-side deduplication is
in place. To thwart such attacks, the concept of proof of ownership has been
introduced [8, 9]. None of these works, however, can provide real end-user conﬁ-
dentiality in presence of a malicious or honest-but-curious cloud provider.

Convergent encryption is a cryptographic primitive introduced by Douceur
et al. [10, 11], attempting to combine data conﬁdentiality with the possibility of

data deduplication. Convergent encryption of a message consists of encrypting
the plaintext using a deterministic (symmetric) encryption scheme with a key
which is deterministically derived solely from the plaintext. Clearly, when two
users independently attempt to encrypt the same ﬁle, they will generate the same
ciphertext which can be easily deduplicated. Unfortunately, convergent encryp-
tion does not provide semantic security as it is vulnerable to content-guessing
attacks. Later, Bellare et al. [12] formalized convergent encryption under the
name message-locked encryption. As expected, the security analysis presented
in [12] highlights that message-locked encryption oﬀers conﬁdentiality for un-
predictable messages only, clearly failing to achieve semantic security.

Xu et al. [13] present a PoW scheme allowing client-side deduplication in a
bounded leakage setting. They provide a security proof in a random oracle model
for their solution, but do not address the problem of low min-entropy ﬁles.

Recently, Bellare et al. presented DupLESS [14], a server-aided encryption for
deduplicated storage. Similarly to ours, their solution uses a modiﬁed convergent
encryption scheme with the aid of a secure component for key generation. While
DupLESS oﬀers the possibility to securely use server-side deduplication, our
scheme targets secure client-side deduplication.

3 Overview of the Solution

Deduplication-based systems require solutions tailored to the type of data they
are expected to handle [5]. We focus our analysis on scenarios where the out-
sourced dataset contains few instances of some data items and many instances of
others. Concrete examples of such datasets include (but are not limited to) those
handled by Dropbox-like backup tools and hypervisors handling linked clones of
VM-images. Other scenarios where such premises do not hold, require diﬀerent
solutions and are out of the scope of this paper.

The main intuition behind our scheme is that there are scenarios in which
data requires diﬀerent degrees of protection that depend on how popular a datum
is. Let us start with an example: imagine that a storage system is used by multiple
users to perform full backups of their hard drives. The ﬁles that undergo backup
can be divided into those uploaded by many users and those uploaded by one
or very few users only. Files falling in the former category will beneﬁt strongly
from deduplication because of their popularity and may not be particularly sen-
sitive from a conﬁdentiality standpoint. Files falling in the latter category, may
instead contain user-generated content which requires conﬁdentiality, and would
by deﬁnition not allow reclaiming a lot of space via deduplication. The same can
be said about common blocks of shared VM images, mail attachments sent to
several recipients, to reused code snippets, etc.

This intuition can be implemented cryptographically using a multi-layered
cryptosystem. All ﬁles are initially declared unpopular and are encrypted with
two layers, as illustrated in Figure 1: the inner layer is applied using a convergent
cryptosystem, whereas the outer layer is applied using a semantically secure
threshold cryptosystem. Uploaders of an unpopular ﬁle attach a decryption share
to the ciphertext. In this way, when suﬃcient distinct copies of an unpopular

ﬁle have been uploaded, the threshold layer can be removed. This step has two
consequences: (i) the security notion for the now popular ﬁle is downgraded
from semantic to standard convergent (see [12]), and (ii) the properties of the
remaining convergent encryption layer allow deduplication to happen naturally.
Security is thus traded for storage eﬃciency as for every ﬁle that transits from
unpopular to popular status, storage space can be reclaimed. Once a ﬁle reaches
the popular status, space is reclaimed for the copies uploaded so far, and normal
deduplication can take place for future copies. Standard security mechanisms
(such as Proof of Ownership [8, 9]) can be applied to secure this step. Note that
such mechanisms are not required in the case of unpopular ﬁles, given that they
are protected by both encryption layers and cannot be deduplicated.

There are two further challenges
in the secure design of the scheme.
Firstly, without proper identity man-
agement, sybil attacks [15] could be
mounted by spawning suﬃcient sybil
accounts to force a ﬁle to become pop-
ular: in this way, the semantically se-
cure encryption layer could be forced
oﬀ and information could be inferred
on the content of the ﬁle, whose only
remaining protection is the weaker
convergent layer. While this is accept-
able for popular ﬁles (provided that
storage eﬃciency is an objective), it is
not for unpopular ﬁles whose content
– we postulate – has to enjoy stronger
protection. The second issue relates to
the need of every deduplicating sys-
tem to group together uploads of the
same content. In client-side dedupli-
cating systems, this is usually accomplished through an index computed deter-
ministically from the content of the ﬁle so that all uploading users can compute
the same. However, by its very nature, this index leaks information about the
content of the ﬁle and violates semantic security for unpopular ﬁles.

Fig. 1. The multi-layered cryptosystem
used in our scheme. Unpopular ﬁles are pro-
tected using two layers, whereas for popular
ﬁles, the outer layer can be removed. The
inner layer is obtained through convergent
encryption that generates identical cipher-
text at each invocation. The outer layer (for
unpopular ﬁles) is obtained through a se-
mantically secure cryptosystem.

For the reasons listed above, we extend the conventional user-storage provider
setting with two additional trusted entities: (i) an identity provider, that deploys
a strict user identity control and prevents users from mounting sybil attacks, and
(ii) an indexing service that provides a secure indirection for unpopular ﬁles.

3.1 System Model
Our system consists of users, a storage provider and two trusted entities, the
identity provider, and the indexing service, as shown in Figure 2.

The storage provider (S) oﬀers basic storage services and can be instantiated
by any storage provider (e.g. Bitcasa, Dropbox etc.) Users (Ui) own ﬁles and
wish to make use of the storage provider to ensure persistent storage of their

content. Users are identiﬁed via credentials issued by an identity provider IdP
when a user ﬁrst joins the system.
A ﬁle is identiﬁed within S via a
unique ﬁle identiﬁer (I), which is is-
sued by the indexing service IS when
the ﬁle is uploaded to S. The indexing
service also maintains a record of how
many distinct users have uploaded a
ﬁle.

3.2 Security Model
The objective of our scheme is conﬁ-
dentiality of user content. Speciﬁcally,
we achieve two diﬀerent security no-
tions, depending on the nature of each
datum, as follows:
i)Semantic secu-
rity [16] for unpopular data; ii) Con-
ventional convergent security [12] for
popular data. Note that integrity and
data origin authentication exceed the
scope of this work.

Fig. 2. Illustration of our system model.
The schematic shows the main four entities
and their interaction for registration and
ﬁle upload process.

In our model, the storage provider is trusted to reliably store data on behalf of
users and make it available to any user upon request. Nevertheless, S is interested
in compromising the conﬁdentiality of user content. We assume that the storage
provider controls nA users: this captures the two scenarios of a set of malicious
users colluding with the storage provider and the storage provider attempting
to spawn system users. We also assume that the goal of a malicious user is only
limited to breaking the conﬁdentiality of content uploaded by honest users.

Let us now formally deﬁne popularity. We introduce a system-wide popularity
limit, plim, which represents the smallest number of distinct, legitimate users that
need to upload a given ﬁle F for that ﬁle to be declared popular. Note that plim
does not account for malicious uploads. Based on plim and nA, we can then
introduce the threshold t for our system, which is set to be t ≥ plim + nA.
Setting the global system threshold to t ensures that the adversary cannot use
its control over nA users to subvert the popularity mechanism and force a non
popular ﬁle of its choice to become popular. A ﬁle shall therefore be declared
popular once more than t uploads for it have taken place. Note that this accounts
for nA possibly malicious uploads. Fixing a single threshold t arguably reduces
the ﬂexibility of the scheme. While for the sake of simplicity of notation we stick
to a single threshold, section 7 discusses how this restriction can be lifted.

The indexing service and the identity provider are assumed to be completely
trusted and to abide by the protocol speciﬁcations. In particular, it is assumed
that these entities will not collude with the adversary, and that the adversary
cannot compromise them. While the existence of an identity provider is not un-
common and is often an essential building block of many practical deployments,
we adopt the indexing service as a way to focus our analysis on the security of

the content of ﬁles, and to thwart attacks to its indexes by means of the trusted
nature of this separate entity. TTPs are indeed often adopted as a means of
achieving security objectives all the while preserving usability [17, 18].

4 Building Blocks

Modeling Deduplication In this Section we will describe the interactions
between a storage provider (S) that uses deduplication and a set of users (U)
who store content on the server. We consider client-side deduplication, i.e., the
form of deduplication that takes place at the client side, thus avoiding the need
to upload the duplicate ﬁle and saving network bandwidth. For simplicity, we
assume that deduplication happens at the ﬁle level. To identify ﬁles and detect
duplicates, the scheme uses an indexing function I: {0, 1}∗ → {0, 1}∗; we will
refer to IF as the index for a given ﬁle F . The storage provider’s backend can be
modeled as an associative array DB mapping indexes produced by I to records
of arbitrary length: for example DB [IF ] is the record mapped to the index of ﬁle
F . In a simple deduplication scheme, records contain two ﬁelds, DB [IF ] .data
and DB [IF ] .users. The ﬁrst contains the content of ﬁle F , whereas the second
is a list that tracks the users that have so far uploaded F . The storage provider
and users interact using the following algorithms:
Put: user u sends IF to S. The latter checks whether DB [IF ] exists. If it does,
the server appends u to DB [IF ] .users. Otherwise, it requests u to upload the
content of F , which will be assigned to DB [IF ] .data. DB [IF ] .users is then
initialized with u.
Get: user u sends IF to the server. The server checks whether DB [IF ] exists
and whether DB [IF ] .users contains u. If it does, the server responds with
DB [IF ] .data. Otherwise, it answers with an error message.

Symmetric Cryptosystems and Convergent Encryption A symmetric
cryptosystem E is deﬁned as a tuple (K, E, D) of probabilistic polynomial-time
algorithms (assuming a security parameter κ). K takes κ as input and is used to
generate a random secret key k, which is then used by E to encrypt a message
m and generate a ciphertext c, and by D to decrypt the ciphertext and produce
the original message.
A convergent encryption scheme Ec, also known as message-locked encryp-
tion scheme, is deﬁned as a tuple of three polynomial-time algorithms (assuming
a security parameter κ) (K, E, D). The two main diﬀerences with respect to E
is that i) these algorithms are not probabilistic and ii) that keys generated by
K are a deterministic function of the cleartext message m; we then refer to keys
generated by Ec.K as km. As a consequence of the deterministic nature of these
algorithms, multiple invocations of K and E (on input of a given message m)
produce identical keys and ciphertexts, respectively, as output.

Threshold Cryptosystems Threshold cryptosystems oﬀer the ability to share
the power of performing certain cryptographic operations (e.g. generating a sig-
nature, decrypting a message, computing a shared secret) among n authorized
users, such that any t of them can do it eﬃciently. Moreover, according to the

security properties of threshold cryptosystems it is computationally infeasible to
perform these operations with fewer than t (authorized) users. In our scheme we
use threshold public-key cryptosystem. A threshold public-key cryptosystem Et
is deﬁned as a tuple (Setup, Encrypt, DShare, Decrypt), consisting of four prob-
abilistic polynomial-time algorithms (in terms of a security parameter κ) with
the following properties:
Setup(κ, n, t) → (pk, sk, S): generates the public key of the system pk, the cor-
responding private key sk and a set S = {(ri, ski)}n−1
i=0 of n pairs of key shares
ski of the private key with their indexes ri; key shares are secret, and are
distributed to authorized users; indexes on the other hand need not be secret.
Encrypt(pk, m) → (c): takes as input a message m and produces its encrypted
version c under the public key pk.
DShare(ri, ski, m) → (ri, dsi): takes as input a message m and a key share ski with
its index ri and produces a decryption share dsi; the index is also outputted.
Decrypt(c, St) → (m): takes as input a ciphertext c, a set St = {(ri, dsi)}t−1
i=0 of t
pairs of decryption shares and indexes, and outputs the cleartext message m.

5 Our Scheme
In this Section we will formally introduce our scheme. First, we will present
a novel cryptosystem of independent interest, whose threshold and convergent
nature make it a suitable building block for our scheme. We will then describe
the role of our trusted third parties and ﬁnally we will detail the algorithms that
compose the scheme.
5.1 Eµ: a Convergent Threshold Cryptosystem
In the remainder of this paper we will make use of pairing groups G1, g, G2, ¯g, GT ,
ˆe, where G1 = (cid:104)g(cid:105), G2 = (cid:104)¯g(cid:105) are of prime order q, where the bitsize of q is
determined by the security parameter κ, and ˆe : G1×G2 → GT is a computable,
non-degenerate bilinear pairing. We further assume that there is no eﬃcient
distortion map ψ : G1 → G2, or ψ : G2 → G1. These groups are commonly
referred to as SXDH groups, i.e., groups where it is known that the Symmetric
Extensible Diﬃe Hellman Assumption(SXDH) [19] holds.
Eµ is deﬁned as a tuple (Setup, Encrypt, DShare, Decrypt), consisting of four
probabilistic polynomial-time algorithms (in terms of a security parameter κ):
Setup(κ, n, t) → (pk, sk, S): at ﬁrst, q, G1, g, G2, ¯g, GT and ˆe are generated
as described above. Also, let secret x ←R Z∗
i=0 be n shares of x
such that any set of t shares can be used to reconstruct x through polynomial
interpolation (see [20] for more details). Also, let ¯gpub ← ¯gx. Finally, let H1 :
{0, 1}∗ → G1 and H2 : GT → {0, 1}l for some l, be two cryptographic hash
functions. Public key pk is set to {q, G1, G2, GT , ˆe, H1, H2, g, ¯g, ¯gpub}, sk to x;
S is the set of n pairs (ri, ski), where ski is set to xi and ri is the preimage of
xi under the aforementioned polynomial.
q and let E ← ˆe (H1(m), ¯gpub)r. Next, set
Encrypt(pk, m) → (c): let r ←R Z∗
c1 ← H2(E) ⊕ m and c2 ← ¯gr. Finally, output the ciphertext c as (c1, c2).
DShare(ri, ski, m) → (ri, dsi): let dsi ← H1(m)ski.

q and {xi}n−1

(cid:89)

(cid:89)

(cid:80)

Decrypt(c, St) → (m): parse c as (c1, c2) and St as {(ri, dsi)}t−1

i=0; compute

λSt
0,ri =

dsi

H1(m)skiλSt

0,ri = H1(m)

(ri ,ski)∈S

skiλSt
0,ri

(cid:48)
t

= H1(m)sk,

(ri,dsi)∈St

(cid:48)
(ri,ski)∈S
t

where λSt
0,ri
(cid:48)
points from the set S
output c1 ⊕ H2( ˆE).

are the Lagrangian coeﬃcients of the polynomial with interpolation
i=0. Then compute ˆE as ˆe (H1(m)x, c2) and

t = {(ri, ski)}t−1

Note that decryption is possible because, by the properties of bilinear pair-
ings, ˆe (H1(m)x, ¯gr) = ˆe (H1(m), ¯gpub)r = ˆe (H1(m), ¯gx)r . This equality satisﬁes
considerations on the correctness of Eµ.
Eµ has a few noteworthy properties: i) The decryption algorithm is non-
interactive, meaning that it does not require the live participation of the enti-
ties that executed the Eµ.DShare algorithm; ii) It mimics convergent encryption
in that the decryption shares are deterministically dependent on the plaintext
message. However, in contrast to plain convergent encryption, the cryptosystem
provides semantic security as long as less than t decryption shares are collected;
iii) The cryptosystem can be reused for an arbitrary number of messages, i.e.,
the Eµ.Setup algorithm should only be executed once. Finally, note that it is
possible to generate more shares skj (j > n) anytime after the execution of the
Setup algorithm, to allow new users to join the system even if all the original n
key-shares were already assigned.

5.2 The Role of Trusted Third Parties

Our scheme uses two trusted components, namely, an identity provider (IdP) and
an indexing service (IS). The main role of the IdP is to thwart sybil attacks by
ensuring that users can sign in only once: we treat this as an orthogonal problem
for which many eﬀective solutions have been outlined [15]. The identity provider
is also responsible for the execution of Eµ.Setup, and is trusted not to leak the
secret key of the system, nor to use this knowledge to violate conﬁdentiality of
unpopular data. This assumption is consistent to the trust users put on today’s
identity providers.

The main role of the second trusted third party, i.e., the indexing service,
is to avoid leaking information about unpopular ﬁles to the storage provider
through the index used to coalesce multiple uploads of the same ﬁle coming
from diﬀerent users (see Section 4), without which reclaiming space and saving
network bandwidth through deduplication would be infeasible. The leakage is
related to the requirement of ﬁnding a common indexing function that can be
evaluated independently by diﬀerent users whose only shared piece of informa-
tion is the content of the ﬁle itself. As a result, the indexing function is usually
a deterministic (often one-way) function of the ﬁle’s content, which is leaked
to the cloud provider. We introduce the indexing service to tackle this problem
before deduplication takes place, i.e., when the ﬁle is still unpopular.

Recall from Section 4 that the indexing function I produces indexes IF
for every ﬁle F . This function can be implemented using cryptographic hash
functions, but we avoid the usual notation with H to prevent it from being
confused with the other hash functions used in Eµ. Informally, the indexing
service receives requests from users about IF and keeps count of the number of
requests received for it from diﬀerent users. As long as this number is below the
popularity threshold, IS answers with a bitstring of the same length as the output
of I; this bitstring is obtained by invoking a PRF (with a random seed σ) on
a concatenation of IF and the identity of the requesting user. The domain of I
and of the PRF is large enough to ensure that collisions happen with negligible
probability. IS also keeps track of all such indexes. Whenever the popularity
threshold is reached for a given ﬁle F , the indexing service reveals the set of
indexes that were generated for it. More formally, the IS maintains an associative
array DBIS [IF ] with two ﬁelds, DBIS [IF ] .ctr and DBIS [IF ] .idxes. The ﬁrst is
a counter initialized to zero, the second is an initially empty list. IS implements
the GetIdx algorithm in Figure 3.
An important consequence of the choice of how Irnd is computed is that
repeated queries by the same user on the same target ﬁle will neither shift a
given ﬁle’s popularity nor reveal anything but a single index.

5.3 The Scheme

i=0 secret.

We are now ready to formally introduce our scheme, detailing the interactions
between a set of n users Ui, a storage provider S and the two trusted entities, the
identity provider IdP and the indexing service IS. S is modeled as described in
Section 4; the database record contains an extra boolean ﬁeld, DB [IF ] .popular,
initialized to false for every new record.
Recall that E and Ec are a symmetric cryptosystem and a convergent sym-
metric cryptosystem, respectively (see Section 4); Eµ is our convergent threshold
cryptosystem. The scheme consists of the following distributed algorithms:
Init: IdP executes Eµ.Setup, publishes the public key system pk of the system.
IdP keeps key shares {ski}n−1
Join: whenever a user Ui wants to join the system, they contact IdP. IdP veri-
ﬁes Ui’s identity; upon successful veriﬁcation, it issues the credentials Ui will
need to authenticate to S and a secret key share ski (generating a new skj if
necessary).
Upload (Fig. 4): this algorithm is executed between a user Ui, the storage server
S and the indexing service IS whenever Ui requests upload of a ﬁle F . First,
Ui uses convergent encryption to create ciphertext Fc; Ui then interacts with
IS to obtain an index Iret (note that either Iret = Irnd or Iret = IFc ) to use
for the interaction with S and possibly a list of indexes used by other users
when uploading the same ﬁle. Depending on IS’s response, Ui proceeds with
one of the following sub-algorithms:
– Upload.Unpopular (Fig. 5): this algorithm captures the interaction between
Ui and S if F is not (yet) popular. In this case, Iret is a random index.
The user uploads a blob containing two ciphertexts, obtained with E and Eµ,

Ui:
Ui → IS: IF
IS:

return IF , ∅

IF ← I(F )
if (DBIS [IF ] .ctr > t)
Irnd ← PRFσ(Ui||IF )
if (Irnd /∈ DBIS [IF ] .idxes)
increment DBIS [IF ] .ctr
add Irnd to DBIS [IF ] .idxes
return Irnd, DBIS [IF ] .idxes
return Irnd, ∅

if (DBIS [IF ] .ctr = t)

else

Ui:

Ui −→ IS:
Ui ←− IS:
Ui:

Kc ← Ec.K(F )
Fc ← Ec.E(Kc, F )
IFc ← I(Fc)
IFc
(cid:104)Iret, I(cid:105) ← GetIdx(IFc )
if (Iret = IFc )
else if (I = ∅)

execute Upload.Popular

execute Upload.Unpopular

else

execute Upload.Unpopular
execute Upload.Reclaim

Fig. 3. The GetIdx algorithm.

Fig. 4. The Upload algorithm.

respectively. The ﬁrst ciphertext allows Ui to recover the ﬁle if it never becomes
popular. The second gives S the ability to remove the threshold encryption
layer and perform deduplication if the ﬁle becomes popular1. Ui replaces F
with a stub of the two indexes, Iret, IFc, and the two keys K and Kc.
– Upload.Reclaim (Fig. 6): this algorithm is executed exactly once for every
popular ﬁle whenever Ui’s upload of F reaches the popularity threshold.The
user sends to S the list of indexes I received from IS. S collects the decryption
shares from each uploaded blob. It is then able to decrypt each uploaded
instance of cµ and can trigger the execution of Put, to store the outcome of
the decryption as DB [IFc ] .data. Note that, because of the nature of convergent
encryption, all decrypted instances are identical, hence deduplication happens
automatically. Finally, S can remove all previously uploaded record entries,
thus eﬀectively reclaiming the space that was previously used.
– Upload.Popular (Fig. 7): this algorithm captures the interaction between Ui
and S if F is already popular; note that in this case, Iret = IFc . Here, the
user is not expected to upload the content of the ﬁle as it has already been

Ui:

c ← E.E(K, F )

K ← E.K();
cµ ← Eµ.Encrypt(pk, Fc)
dsi ← Eµ.DShare(ski, Fc)
F (cid:48) ← (cid:104)c, cµ, dsi(cid:105)
if (¬DB [Iret] .popular)

execute Put(IFc , Ui, F (cid:48))

Ui −→ S: Iret, F (cid:48)
S:

Ui:

else signal an error and exit
F ← (cid:104)K, Kc,Iret,IFc(cid:105)

Ui −→ S:
S:

I
DS ← {ds : (cid:104)c, cµ, ds(cid:105) ←
← DB [I] .data, I ∈ I}
foreach(Ii ∈ I)
(cid:104)c, cµ, dsi(cid:105) ← DB [IF ] .data
Fc ← Eµ.Decrypt(cµ, DS)
IFc ← I(Fc)
Ui ← DB [Ii] .users
execute Put(IFc , Ui, Fc)

DB [IFc ] .popular ← true
delete all records indexed by I

Fig. 5. The Upload.Unpopular alg.

Fig. 6. The Upload.Reclaim algorithm

1We have chosen to formalize this approach for the sake of readability. In practice,
one would adopt a solution in which the ﬁle is encrypted only once with K; this key,
not the entire ﬁle, is in turn encrypted with a slightly modiﬁed version of Eµ that allows
H1(Fc) to be used as the H1-hash for computing ciphertext and decryption shares for
K. This approach would require uploading and storing a single ciphertext of the ﬁle
and not two as described above.

Ui −→ S: IFc
S:

declared popular. Ui replaces F with a stub containing the index IFc and of
the key Kc.

Download: whenever user Ui wants to re-
trieve a previously uploaded ﬁle, it reads
the tuple used to replace the content of
F during the execution of the Upload al-
Ui:
gorithm. It ﬁrst attempts to issue a Get
request on S, supplying Iret as index. If
Fig. 7. The Upload.Popular algorithm
the operation succeeds, it proceeds to decrypt the received content with E.D,
using key K, and returns the output of the decryption. Otherwise, it issues a
second Get request, supplying IFc as index; then it invokes Ec.D on the received
content, using Kc as decryption key, and outputs the decrypted plaintext.

if (DB [IFc ] .popular)
execute Put(IFc , Ui)
else abort
F ← (cid:104)Kc,IFc(cid:105)

6 Security Analysis
We formally analyze the security of the Eµ cryptosystem and we argue informally
that the security requirements of Sec. 3.2 are met by our scheme as a whole.
6.1 Security Analysis of Eµ
In this section we will deﬁne and analyze semantic security for Eµ. The security
deﬁnition we adopt makes use of a straightforward adaptation of the IND-CPA
experiment, henceforth referred to as INDµ-CPA. Additionally, we introduce the
concept of unlinkability of decryption shares and prove that Eµ provides this
property: informally, this property assures that an adversary cannot link together
decryption shares as having been generated for the same message, as long as less
than t of them are available. We will refer to the experiment used for the proof
of this property as DSµ-IND. Both experiments require the adversary to declare
upfront the set of users to be corrupted, similarly to selective security [21].

Unlinkability of Decryption Shares Informally, in DSµ-IND, the adversary is
given access to two hash function oracles OH1 , and OH2 ; the adversary can corrupt
an arbitrary number nA < t − 1 of pre-declared users, and obtains their secret
keys through an oracle OCorrupt. Finally, the adversary can access a decryption
share oracle ODShare, submitting a message m of her choice and a non-corrupted
user identity Ui; for each message that appears to ODShare-queries, the challenger
chooses at random whether to respond with a properly constructed decryption
share that corresponds to message m and secret key share ski as deﬁned in Eµ,
or with a random bitstring of the same length (e.g., when bm∗ = 0). At the
end of the game, the adversary declares a message m∗, for which up to t −
nA − 1 decryption share queries for distinct user identities have been submitted.
m∗ = bm∗ . Eµ is said
The adversary outputs a bit b(cid:48)
to satisfy unlinkability of decryption shares, if no polynomial-time adversary
can win the game with a non-negligible advantage. Formally, unlinkability of
decryption shares is deﬁned using the experiment DSµ-IND between an adversary
A and a challenger C, given security parameter κ:
Setup Phase C executes the Setup algorithm with κ, and generates a set of
user identities U = {Ui}n−1
i=0 secret.

i=0 . Further, C gives pk to A and keeps {ski}n−1

m∗ and wins the game if b(cid:48)

At this point, A declares the list UA of |UA| = nA < t − 1 identities of users
that will later on be subject to OCorrupt calls.
Access to Oracles Throughout the game, the adversary can invoke oracles
for the hash functions H1 and H2. Additionally, the adversary can invoke the
corrupt oracle OCorrupt and receive the secret key share that corresponds to
any user Ui ∈ UA. Finally, A can invoke the decryption share oracle ODShare
to request a decryption share that corresponds to a speciﬁc message, say m,
and the key share of a non-corrupted user, say Ui /∈ UA. More speciﬁcally,
for each message m that appears in ODShare-queries, the challenger chooses at
random (based on a fair coin ﬂip bm) whether to respond to ODShare-queries
for m with decryption shares constructed as deﬁned by the protocol, or with
random bitstrings of the same length. Let dsi,m denote the response of a
ODShare-query for m and Ui. bm = 1 correspond to the case, where responses
in ODShare-queries for m are properly constructed decryption shares.
Challenge Phase A chooses a target message m∗. The adversary is limited
in the choice of the challenge message as follows: m∗ must not have been the
subject of more than t − nA − 1 ODShare queries for distinct user identities.
At the challenge time, if the limit of t − nA − 1 has not been reached, the
adversary is allowed to request for more decryption shares for as long as the
aforementioned condition holds. Recall that C responds to challenge ODShare-
queries based on bm∗ .
Guessing Phase A outputs b(cid:48)
versary wins the game, if bm∗ = b(cid:48)

m∗ , that represents her guess for bm∗ . The ad-

m∗ .

Semantic Security Informally, in INDµ-CPA, the adversary is given access to
all oracles as in DSµ-IND. However, here, oracle ODShare responds with properly
constructed decryption shares, i.e., decryption shares that correspond to the
queried message and non-corrupted user identity. At the end of the game, the
adversary outputs a message m∗; the challenger ﬂips a fair coin b, and based on
its outcome, it returns to A the encryption of either m∗ or of another random
bitstring of the same length. The adversary outputs a bit b(cid:48) and wins the game
if b(cid:48) = b. Eµ is said to be semantically secure if no polynomial-time adversary
can win the game with a non-negligible advantage. Formally, the security of Eµ
is deﬁned through the INDµ-CPA experiment between an adversary A and a
challenger C, given a security parameter κ:
Setup Phase is the same as in DSµ-IND.
Access to Oracles Throughout the game, the adversary can invoke oracles
for the hash functions H1 and H2 and the OCorrupt oracle as in DSµ-IND. A
is given access to the decryption share oracle ODShare to request a decryption
share that corresponds to a speciﬁc message, say m, and the key share of a
non-corrupted user, say Ui.
Challenge Phase A picks the challenge message m∗ and sends it to C; the
adversary is limited in her choice of the challenge message as follows: the
sum of distinct user identities supplied to ODShare together with the challenge
message cannot be greater than t − nA − 1. C chooses at random (based on
a coin ﬂip b) whether to return the encryption of m∗ (b = 1), or of another

random string of the same length (b = 0); let c∗ be the resulting ciphertext,
which is returned to A.
Guessing Phase A outputs b(cid:48), that represents her guess for b.The adversary
wins the game, if b = b(cid:48).

A
DSµ-IND := Pr[b(cid:48)

The following lemmas show that unlinkability of decryption shares and semantic
security are guaranteed in Eµ as long as the SXDH problem is intractable [19].
Lemma 1. Let H1and H2 be random oracles. If a DSµ-IND adversary A has a
m∗ = bm∗ ] −
non-negligible advantage Adv
2 , then, a probabilistic, polynomial-time algorithm C can create an environment
1
where it uses A’s advantage to solve any given instance of the SXDH problem.
Lemma 2. Let H1, and H2 be random oracles. If an INDµ-CPA adversary A has
INDµ-CPA := Prob[b(cid:48) ← A(c∗) : b = b(cid:48)] − 1
A
a non-negligible advantage Adv
2 , then,
a probabilistic, polynomial-time algorithm C can create an environment where it
uses A’s advantage to solve any given instance of the SXDH problem.
Proofs for Lemma 1 and Lemma 2 are available in the appendices.

m∗ ← A(m∗, ds∗,m∗ ) : b(cid:48)

6.2 Security Analysis of the Scheme
A formal security analysis of the scheme under the UC framework [22] is not
presented here due to space limitations and is left for future work. We instead
present informal arguments, supported by the proofs shown in the previous sec-
tion and the assumptions on our trusted third parties, showing how the security
requirements highlighted in Section 3 are met.

Let us brieﬂy recall that the adversary in our scheme is represented by a set of
users colluding with the cloud storage provider. The objective of the adversary is
to violate the conﬁdentiality of data uploaded by legitimate users: in particular,
the objective for unpopular data is semantic security, whereas it is conventional
convergent security for popular data. We assume that the adversary controls a
set of nA users {Ui}nA
i=1. The popularity threshold plim represents the smallest
number of distinct, legitimate users that are required to upload a given ﬁle F
for that ﬁle to be declared popular. We ﬁnally recall that the threshold t of Eµ–
also used by the indexing service – is set to be t ≥ plim + nA. This implies that
the adversary cannot use its control over nA users to subvert the popularity
mechanism and force a non-popular ﬁle of its choice to become popular. This
fact stems from the security of Eµ and from the way the indexing service is im-
plemented. As a consequence, transition of a ﬁle between unpopular and popular
is governed by legitimate users.

The adversary can access two conduits to retrieve information on user data:
i) the indexing service (IS) and ii) the records stored by S in DB. The indexing
service cannot be used by the attacker to retrieve any useful information on
popular ﬁles; indeed the adversary already possesses IFc for all popular ﬁles and
consequently, queries to IS on input the index IFc do not reveal any additional
information other than the notion that the ﬁle is popular. As for unpopular ﬁles,
the adversary can only retrieve indexes computed using a PRF with a random

secret seed. Nothing can be inferred from those, as guaranteed by the security of
the PRF. Note also that repeated queries of a single user on a given ﬁle always
only yield the same index and do not inﬂuence popularity.

Let us now consider what the adversary can learn from the content of the
storage backend, modeled by DB. The indexing keys are either random strings
(for unpopular ﬁles) or the output of a deterministic, one-way function I on the
convergent ciphertext (for popular ﬁles). In the ﬁrst case, it is trivial to show
how nothing can be learned. In the latter case, the adversary may formulate a
guess F (cid:48) for the content of a given ﬁle, compute IF (cid:48) and compare it with the
index. However this process does not yield any additional information that can
help break standard convergent security: indeed the same can be done on the
convergent ciphertext. As for the data content of DB, it is always in either of
two forms: (cid:104)c, cµ, dsi(cid:105) for unpopular ﬁles and Fc for popular ﬁles. It is easy to
see that in both cases, the length of the plaintext is leaked but we argue this
does not constitute a security breach. The case of a popular ﬁle is very simple to
analyze given that security claims stem directly from the security of convergent
encryption. As for unpopular ﬁles, c is the ciphertext produced by a semantically
secure cryptosystem and by deﬁnition does not leak any information about the
corresponding ciphertext. cµ and dsi represent the ciphertext and the decryption
share produced by Eµ, respectively. Assuming that t is set as described above, the
adversary cannot be in possession of t decryption shares. Consequently, Lemma 2
guarantees that no information on the corresponding plaintext can be learned.

7 Discussion

Here we justify some of our assumptions and discuss the scheme’s limitations:
Prototype Performance. To demonstrate the practicality and functionality
of our proposal, we implemented a prototype of the core of the scheme as a
client-server C++ application. Results show that the most overhead stems from
symmetric and convergent encryption operations implemented via AES-256 and
SHA-256; the execution of Eµ.Encrypt and Eµ.Decrypt forms only a fraction of
the computational overhead. Additionally, while Eµ.Encrypt is executed for every
store and retrieval operation, Eµ.Decrypt is used only during ﬁle state transition
and user share generation is done only once per every new registered user. In
conclusion, most of the computational overhead is caused by convergent and
symmetric encryption to protect unpopular ﬁles, while the overhead introduced
by the threshold cryptosystem is comparatively small.
Privacy. Individual privacy is often equivalent to each party being able to con-
trol the degree to which it will interact and share information with other parties
and its environment. In our setting, user privacy is closely connected to user
data conﬁdentiality: it should not be possible to link a particular ﬁle plaintext
to a particular individual with better probability than choosing that individ-
ual and ﬁle plaintext at random. Clearly, within our protocols, user privacy is
provided completely for users who own only unpopular ﬁles, while it is slightly
degraded for users who own popular ﬁles. One solution for the latter case would
be to incorporate anonymous and unlinkable credentials [23, 24] every time user

authentication is required. This way, a user who uploads a ﬁle to the storage
provider will not have her identity linked to the ﬁle ciphertext. On the contrary,
the ﬁle owner will be registered as one of the certiﬁed users of the system.

Dynamic Popularity Threshold. In our scheme, ﬁles are classiﬁed as popular
or unpopular based on a single popularity threshold. One way of relaxing this
requirement would be to create multiple instances of Eµ with diﬀerent values of
t and issue as many keys to each user. Diﬀerent users are then free to encrypt an
input ﬁle using diﬀerent thresholds, with the property that a ﬁle uploaded with a
given threshold t1 does not count towards popularity for the same ﬁle uploaded
with a diﬀerent threshold t2 (otherwise, malicious users could easily compromise
the popularity system). A label identifying the chosen threshold (which does
not leak other information) must be uploaded together with the ciphertext.
Furthermore, the indexing service needs to be modiﬁed to keep indexes for a given
ﬁle and threshold separate from those of the same ﬁle but diﬀerent thresholds.
This can be achieved by modifying the GetIdx interface.

Deletion. Deletion of content is challenging in our scheme, given that the stor-
age provider may be malicious and refuse to erase the uploaded content. Ideally,
a deletion operation should remove also the uploaded decryption share and de-
crease the popularity of that ﬁle by one. A malicious storage provider would
undoubtedly refuse to perform this step. However, the indexing service, which
is a trusted entity, would perform the deletion step honestly by removing the
random index generated for the ﬁle and decreasing the popularity. This alone
however does not guarantee any security. Indeed, we may be faced with the sce-
nario in which the popularity threshold has not yet been reached (that is, the
storage provider has not been given the set of indexes), and yet more than t
decryption shares exist at unknown locations. The property of unlinkability of
decryption shares described in Lemma 1 however guarantees that the adversary
has no better strategy than trying all the dsi shares of currently unpopular ﬁles
stored in the storage. While this does not constitute a formal argument, it is
easy to show how, if number of shares grows, this task becomes infeasible.

8 Conclusion

This work deals with the inherent tension between well established storage opti-
mization methods and end-to-end encryption. Diﬀerently from the approach of
related works, that assume all ﬁles to be equally security-sensitive, we vary the
security level of a ﬁle based on how popular that ﬁle is among the users of the
system. We present a novel encryption scheme that guarantees semantic security
for unpopular data and provides weaker security and better storage and band-
width beneﬁts for popular data, so that data deduplication can be applied for
the (less sensitive) popular data. Files transition from one mode to the other in
a seamless way as soon as they become popular. We show that our protocols are
secure under the SXDH Assumption. In the future we plan to deploy and test
the proposed solution and evaluate the practicality of the notion of popularity
and whether the strict popular/unpopular classiﬁcation can be made more ﬁne-
grained. Also, we plan to remove the assumption of a trusted indexing service
and explore diﬀerent means of securing the indexes of unpopular ﬁles.

Acknowledgements

This work was supported by the Grant Agency of the Czech Technical University
in Prague, grant No. SGS13/139/OHK3/2T/13.
References

1. Open Security Foundation: DataLossDB (http://datalossdb.org/).
2. Meister, D., Brinkmann, A.: Multi-level comparison of data deduplication in a

backup scenario. In: SYSTOR ’09, New York, NY, USA, ACM (2009) 8:1–8:12

3. Mandagere, N., Zhou, P., Smith, M.A., Uttamchandani, S.: Demystifying data

deduplication. In: Middleware ’08, New York, NY, USA, ACM (2008) 12–17

4. Aronovich, L., Asher, R., Bachmat, E., Bitner, H., Hirsch, M., Klein, S.T.: The
design of a similarity based deduplication system. In: SYSTOR ’09. (2009) 6:1–6:14
5. Dutch, M., Freeman, L.: Understanding data de-duplication ratios. SNIA fo-
rum (2008) http://www.snia.org/sites/default/files/Understanding_Data_
Deduplication_Ratios-20080718.pdf.

6. Harnik, D., Margalit, O., Naor, D., Sotnikov, D., Vernik, G.: Estimation of dedu-

plication ratios in large data sets. In: IEEE MSST ’12. (april 2012) 1 –11

7. Harnik, D., Pinkas, B., Shulman-Peleg, A.: Side channels in cloud services: Dedu-

plication in cloud storage. Security Privacy, IEEE 8(6) (nov.-dec. 2010) 40 –47

8. Halevi, S., Harnik, D., Pinkas, B., Shulman-Peleg, A.: Proofs of ownership in
remote storage systems. In: CCS ’11, New York, NY, USA, ACM (2011) 491–500
9. Di Pietro, R., Sorniotti, A.: Boosting eﬃciency and security in proof of ownership

for deduplication. In: ASIACCS ’12, New York, NY, USA, ACM (2012) 81–82

10. Douceur, J.R., Adya, A., Bolosky, W.J., Simon, D., Theimer, M.: Reclaiming
space from duplicate ﬁles in a serverless distributed ﬁle system. In: ICDCS ’02,
Washington, DC, USA, IEEE Computer Society (2002) 617–632

11. Storer, M.W., Greenan, K., Long, D.D., Miller, E.L.: Secure data deduplication.

In: StorageSS ’08, New York, NY, USA, ACM (2008) 1–10

12. Bellare, M., Keelveedhi, S., Ristenpart, T.: Message-locked encryption and secure
deduplication. In: Advances in Cryptology–EUROCRYPT 2013. Springer 296–312
13. Xu, J., Chang, E.C., Zhou, J.: Weak leakage-resilient client-side deduplication of

encrypted data in cloud storage. In: 8th ACM SIGSAC symposium. 195–206

14. Bellare, M., Keelveedhi, S., Ristenpart, T.: DupLESS: server-aided encryption for

deduplicated storage. In: 22nd USENIX conference on Security. (2013) 179–194

15. Douceur, J.R.: The sybil attack. In: Peer-to-peer Systems. Springer (2002) 251–260
16. Goldwasser, S., Micali, S.: Probabilistic encryption. J. Comput. Syst. Sci. (1984)
17. Fahl, S., Harbach, M., Muders, T., Smith, M.: Conﬁdentiality as a service–usable

security for the cloud. In: TrustCom 2012. 153–162

18. Fahl, S., Harbach, M., Muders, T., Smith, M., Sander, U.: Helping johnny 2.0 to

encrypt his facebook conversations. In: SOUPS 2012. 11–28

19. Ateniese, G., Blanton, M., Kirsch, J.: Secret handshakes with dynamic and fuzzy

matching. In: NDSS ’07

20. Shamir, A.: How to share a secret. Commun. ACM 22(11) (November 1979)
21. Goyal, V., Pandey, O., Sahai, A., Waters, B.: Attribute-based encryption for ﬁne-

grained access control of encrypted data. In: ACM CCS ’06. 89–98

22. Canetti, R., Lindell, Y., Ostrovsky, R., Sahai, A.: Universally composable two-

party and multi-party secure computation. In: STOC ’02. (2002)

23. Camenisch, J., Hohenberger, S., Lysyanskaya, A.: Balancing accountability and
privacy using e-cash. In: Security and Cryptography for Networks. Springer (2006)
24. Lysyanskaya, A., Rivest, R.L., Sahai, A., Wolf, S.: Pseudonym systems. In: Selected

Areas in Cryptography, Springer (2000) 184–199

1, G(cid:48)

1, G2 ← G(cid:48)

2, GT ← G(cid:48)

i=0}, where ri, yi ←R Z∗

Challenger C is given an SXDH context G(cid:48)

Appendix A: Proof of Lemma 1
SXDH assumes two groups of prime order q, G1, and G2, such that there is not an
eﬃciently computable distortion map between the two; a bilinear group GT , and an
eﬃcient, non-degenerate bilinear map ˆe : G1 ×G2 → GT . In this setting, the Decisional
Diﬃe-Hellman (DDH) holds in both G1, and G2, and that the bilinear decisional Diﬃe-
Hellman (BDDH) holds given the existence of ˆe [19].
2, G(cid:48)
T , ˆe(cid:48) and an instance of the DDH
problem (cid:104)G(cid:48)
1, g(cid:48), A = (g(cid:48))a, B = (g(cid:48))b, W(cid:105) in G1’. C simulates an environment in which
A operates, using its advantage in the game DSµ-IND to decide whether W = g(cid:48)ab. C
interacts with A in the DSµ-IND game as follows:
Setup Phase C sets G1 ← G(cid:48)
T , ˆe = ˆe(cid:48), g ← g(cid:48); picks a random
generator ¯g of G2 and sets ¯gpub = (¯g)sk, where sk ←R Z∗
q . C also generates the set of
i=0 . The public key pk = {q, G1, G2, GT ˆe,OH1 ,OH2 , ¯g, ¯gpub}
user identities U = {Ui}n−1
and U are forwarded to A. A declares the list UA of nA < t − 1 user identities that
will later on be subject to OCorrupt calls. Let UA = {Ui}nA−1
. To generate key-shares
{ski}n−1
i=0 , C constructs a t − 1-degree Lagrange polynomial P() with interpolation
points IP = {(0, sk)∪{(ri, yi)}t−2
q , for i ∈ [0, t− 3], and rt−2 ←R
q , yt−2 ← a. Secret key-shares are set to ski ← yi, i ∈ [0, n − 1]. Since a is not
Z∗
known to C, A sets the corrupted key-shares to be ski for i ∈ [0, nA − 1].
Access to Oracles C simulates oracles OH1 , OH2 , OCorrupt and ODShare:
OH1 : to respond to OH1 -queries, C maintains a list of tuples {H1, v, hv, ρv, cv} as
explained below. We refer to this list as OH1 list, and it is initially empty. When
A submits an OH1 query for v, C checks if v already appears in the OH1
list
in a tuple {v, hv, ρv, cv}. If so, C responds with H1(v) = hv. Otherwise, C picks
ρv ←R Z∗
q , and ﬂips a coin cv; cv ﬂips to (cid:48)0(cid:48) with probability δ for some δ to
be determined later. If cv equals (cid:48)0(cid:48), C responds H1(v) = hv = gρv and stores
{v, hv, ρv, cv}; otherwise, she returns H1(v) = hv = Bρv and stores {v, hv, ρv, cv}.
OH2 : The challenger C responds to a newly submitted OH2 query for v with a
randomly chosen hv ∈ GT . To be consistent in her OH2 responses, C maintains the
history of her responses in her local memory.
OCorrupt: C responds to a OCorrupt query involving user Ui ∈ UA, by returning the
coordinate yi chosen in the Setup Phase.
ODShare: simulation of ODShare is performed as follows. As before, C keeps track of the
submitted ODShare queries in her local memory. Let (cid:104)m, Ui(cid:105) be a decryption query
submitted for message m and user identity Ui. If there is no entry in H1-list for
m, then C runs the OH1 algorithm for m. Let {m, hm, ρm, cm} be the OH1 entry
in C’s local memory for message m. Let IP
(cid:48) ← IP \ (rt−2, skt−2). C responds with
where X ← A iﬀ cm = 0, and X ← W iﬀ

dsm,i =
cm = 1. In both cases, C keeps a record of her response in her local memory.

Challenge Phase A selects the challenge message m∗. Let the corresponding entry
in the OH1 list be {m∗, hm∗ , ρm∗ , cm∗}. If cm∗ = 0, then C aborts.
Guessing Phase A outputs one bit b(cid:48)
m∗ representing the guess for bm∗ . C responds
positively to the DDH challenger if b(cid:48)
m∗ = 0, and negatively otherwise.
It is easy to see, that if A’s answer is (cid:48)0(cid:48), it means that the ODShare responses for m∗
constitute properly structured decryption shares for m∗. This can only be if W = gab
and C can give a positive answer to the SXDH challenger. Clearly, if cm∗ = 1 and
cm = 0 for all other queries to OH1 such that m (cid:54)= m∗, the execution environment

ρm

g

(rj ,skj )∈IP

i=0

(cid:80)

(cid:48)
IP
ri ,rj

(cid:48) skjλ

(cid:48)

IP
ri ,rt−2

X λ

1

SXDH.

1QH1

1, G(cid:48)

−1) and the success probability of the adversary can be bounded as AdvA

is indistinguishable from the actual game DSµ-IND. This happens with probability
Pr[cm∗ = 1 ∧ (∀m (cid:54)= m∗ : cm = 0)] = δ(1 − δ)QH1
−1, where QH1 is the number of
distinct OH1 queries. By setting δ ≈
−1 the above probability becomes greater than
DSµ-IND ≤
e·(QH1
e · (QH1 − 1) · AdvC
Appendix B: Proof of Lemma 2
Challenger C is given an instance (cid:104)q(cid:48), G(cid:48)
2, G(cid:48)
T , ˆe(cid:48), g(cid:48), ¯g(cid:48), A = (g(cid:48))a, B = (g(cid:48))b, C =
(g(cid:48))c, ¯A = (¯g(cid:48))a, ¯B = (¯g(cid:48))b, ¯C = (¯g(cid:48))c, W(cid:105) of the SXDH problem and wishes to use A
to decide if W = ˆe (g(cid:48), ¯g(cid:48))abc. The algorithm C simulates an environment in which A
operates, using its advantage in the game INDµ-CPA to help compute the solution to
the BDDH problem, as described before. C interacts with A within an INDµ-CPA game:
Setup Phase C sets q ← q(cid:48), G1 ← G(cid:48)
T , ˆe = ˆe(cid:48), g ← g(cid:48), ¯g ← ¯g(cid:48),
¯gpub = ¯A. Notice that the secret key sk = a is not known to C. C also generates the
list of user identities U. C sends pk = {q, G1, G2, GT ˆe,OH1 ,OH2 , ¯g, ¯gpub} to A. At this
point, A declares the list of corrupted users UA as in DSµ-IND. Let UA = {Ui}nA−1
.
To generate key-shares {ski}n−1
i=0 , C picks a t − 1 degree Lagrange polynomial P()
q . She
then sets the key-shares to ski ← yi, i ∈ [0, n − 1] and assigns ski for i ∈ [0, nA − 1]
to corrupted users.
Access to Oracles C simulates oracles OH1 , OH2 , OCorrupt and ODShare:
OH1 , OH2 , OCorrupt: C responds to these queries as in DSµ-IND.
ODShare: C keeps track of the submitted ODShare-queries in her local memory. Let
(cid:104)m, Ui(cid:105) be a decryption query submitted for message m and user identity Ui.
If there is no entry in H1-list for m, then C runs the OH1 algorithm for m. Let
{m, hm, ρm, cm} be the OH1 entry in C’s local memory for message m. If cm = 1,
and A has already submitted t − nA − 1 queries for m, C aborts. If the limit of
t − nA − 1 queries has not been reached, C responds with a random dsm,i ∈ G1
and keeps a record for it. From Lemma 1, this step is legitimate as long as less
(cid:48) ← IP \ (0, a). If cm = 0, C
than t decryption shares are available for m. Let IP

assuming interpolation points IP =(cid:8)(0, a) ∪ {(ri, yi)}t−2

(cid:9) , where ri, yi ←R Z∗

2, GT ← G(cid:48)

1, G2 ← G(cid:48)

i=0

i=0

g

(cid:80)

(rj ,skj )∈IP

(cid:48)
IP
ri ,rj

(cid:48) skjλ

(cid:48)
IP
ri ,0

Aλ

rm

.

responds with dsm,i =

W ρm∗ = ˆe (g, ¯g)abcρm∗ = ˆe ((Bρm∗ )a, ¯gc) = ˆe(cid:0)H1(m∗)sk, ¯C(cid:1) . Clearly, if cm∗ = 1 and

Challenge Phase A submits m∗ to C. A has not submitted ODShare-queries for the
challenge message with more than t − nA − 1 distinct user identities. Next, C runs
the algorithm for responding to OH1 -queries for m∗ to recover the entry from the
OH1 -list. Let the entry be {m∗, hm∗ , ρm∗ , cm∗}. If cm∗ = 0, C aborts. Otherwise, C
computes e∗ ← W ρm∗ , sets c∗ ← (cid:104)m∗ ⊕ H2(e∗), ¯C(cid:105) and returns c∗ to A.
Guessing Ph. A outputs the guess b(cid:48) for b. C provides b(cid:48) for its SXDH challenge.
If A’s answer is b(cid:48) = 1, it means that she has recognized the ciphertext c∗ as the
encryption of m∗; C can then give the positive answer to her SXDH challenge. Indeed,
cm = 0 for all other queries to OH1 such that m (cid:54)= m∗, then the execution environment
is indistinguishable from the actual game INDµ-CPA. This happens with probability
−1, where QH1 is the number of
Pr[cm∗ = 1 ∧ (∀m (cid:54)= m∗ : cm = 0)] = δ(1 − δ)QH1
diﬀerent OH1 -queries. By setting δ ≈
−1 , the above probability becomes greater
than
INDµ-CPA is bounded as
AdvA

−1) , and the success probability of the adversary AdvA

e·(QH1
INDµ-CPA ≤ e · (QH1 − 1) · AdvC

1QH1

SXDH.

1

