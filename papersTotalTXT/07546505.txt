2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy

Cinderella: Turning Shabby X.509 Certiﬁcates

into Elegant Anonymous Credentials

with the Magic of Veriﬁable Computation

Antoine Delignat-Lavaud

C´edric Fournet

{antdl,fournet,markulf,parno}@microsoft.com

Markulf Kohlweiss

Bryan Parno

Microsoft Research

Abstract—Despite advances in security engineering, authenti-
cation in applications such as email and the Web still primarily
relies on the X.509 public key infrastructure introduced in 1988.
This PKI has many issues but is nearly impossible to replace.

Leveraging recent progress in veriﬁable computation, we
propose a novel use of existing X.509 certiﬁcates and infras-
tructure. Instead of receiving & validating chains of certiﬁcates,
our applications receive & verify proofs of their knowledge,
their validity, and their compliance with application policies.
This yields smaller messages (by omitting certiﬁcates), stronger
privacy (by hiding certiﬁcate contents), and stronger integrity
(by embedding additional checks, e.g. for revocation).

X.509 certiﬁcate validation is famously complex and error-
prone, as it involves parsing ASN.1 data structures and inter-
preting them against diverse application policies. To manage
this diversity, we propose a new format for writing application
policies by composing X.509 templates, and we provide a template
compiler that generates C code for validating certiﬁcates within
a given policy. We then use the Geppetto cryptographic compiler
to produce a zero-knowledge veriﬁable computation scheme for
that policy. To optimize the resulting scheme, we develop new
C libraries for RSA-PKCS#1 signatures and ASN.1 parsing,
carefully tailored for cryptographic veriﬁability.

We evaluate our approach by providing two real-world ap-
plications of veriﬁable computation: a drop-in replacement for
certiﬁcates within TLS; and access control for the Helios voting
protocol. For TLS, we support ﬁne-grained validation policies,
with revocation checking and selective disclosure of certiﬁcate
contents, effectively turning X.509 certiﬁcates into anonymous
credentials. For Helios, we obtain additional privacy and veri-
ﬁability guarantees for voters equipped with X.509 certiﬁcates,
such as those readily available from some national ID cards.

I. INTRODUCTION

Since its standardization in 1988, the X.509 public key
infrastructure (PKI) has become ubiquitous. It serves as the
cornerstone of security for Web browsing (TLS), software
updates (Authenticode), email (S/MIME), document authen-
tication (PDF), virtual private networks (IPSec), and much
more. In part because of this ubiquity, the X.509 PKI is averse
to change. Even when concrete attacks are known, as when
Stevens et al. [64] used a collision on MD5 to forge a bogus
certiﬁcate, it still takes years to replace insecure algorithms.
Given this structural inertia, it is perhaps unsurprising that,
despite almost thirty years of innovation in security and cryp-
tography, the X.509 PKI primarily employs techniques and
algorithms known at its inception. Since that time, the cryp-
tographic community has developed schemes for anonymous
authentication [61], pseudonymous authentication [24] and

2375-1207/16 $31.00 © 2016 IEEE
© 2016, Antoine Delignat-Lavaud. Under license to IEEE.
DOI 10.1109/SP.2016.22
DOI 10.1109/SP.2016.22

235
235

attribute-based authentication [15], for group signatures [25],
and for cryptographic access control [22]. However, none of
these features are available in the world’s default PKI.

Beyond inertia, one barrier to innovation is a disconnect
between the existing X.509 infrastructure and the ‘primitive’
operations required in these cryptographic schemes. The vast
majority of X.509 keys and certiﬁcates employ RSA, whereas
many modern schemes rely on a particular algebraic structure,
often in an elliptic curve group [46], e.g. a discrete logarithm
representation or a bilinear relation between elements [1, 20].
the private RSA keys
Furthermore,
reside in secure hardware (e.g.,
in a smartcard for client
authentication, or in a hardware security module (HSM) for
server authentication), and hence can only be accessed via a
predeﬁned API. Finally, X.509 certiﬁcate parsing and process-
ing is notoriously complex even in native code [17], let alone
in the context of a cryptographic scheme.

in many deployments,

With Cinderella, we leverage recent progress in veriﬁable
computation to bridge the gap between existing X.509 in-
frastructure and modern cryptography. Abstractly, a veriﬁable
computation protocol [41] enables a veriﬁer to outsource an
arbitrary computation to an untrusted prover before efﬁciently
checking the correctness of that computation. Both the veriﬁer
and the prover can supply inputs to the computation, and the
prover may opt to keep some or all of his inputs private.

Cinderella employs such a veriﬁable computation protocol
so that a prover can demonstrate that he holds (1) a valid
X.509 certiﬁcate chain and (2) a signature computed with the
associated private key, without actually sending them to the
veriﬁer. In other words, Cinderella outsources to the prover
all of the checks that the veriﬁer would have done on those
certiﬁcates, and the veriﬁer’s job is simpliﬁed to checking only
that the outsourced validation was performed correctly.

Cinderella’s approach allows us to re-use existing certiﬁcate
chains (including well-established certiﬁcate authorities and
issuance policies) and their signing mechanisms in more
advanced applications. It integrates well with existing infras-
tructure, since it does not require direct access to X.509
signing keys, making it compatible with existing hardware-
based solutions, such as smartcards and HSMs. Furthermore,
as discussed shortly, Cinderella can drop seamlessly into
existing protocols such as TLS. As an important example,
several countries such as Belgium, Estonia, and Spain issue
“national identity” X.509 certiﬁcates on smartcards, and even

provide APIs for commercial applications. We can directly re-
use these carefully-managed, highly-trusted identity providers,
without support or even approval from their authorities.

Cinderella adds “cryptographic power” by improving the
ﬂexibility, expressivity, and privacy of X.509 authentication
and authorization decisions. For instance, although the PKI
currently supports certiﬁcate revocation via signed revocation
lists (CRLs) and online checks (OCSP), checking for revo-
cation remains brittle, as one may need to collect evidence
from third-party servers and deal with potential failures in
the process. With Cinderella, a given validation policy can
move the responsibility of collecting (and validating) recent
evidence of non-revocation to the certiﬁcate holder, therefore
making revocation checking simpler and more efﬁcient for the
veriﬁer. Other issuers may prefer a policy that accepts only
recent, short-lived certiﬁcates. Both approaches can co-exist,
and the resulting joint policy can be enforced by the veriﬁer
without any additional local processing. Similarly, Cinderella
proofs can embed other advanced validation policies, such as
controlled delegation and Certiﬁcate Transparency (CT [45]).
Our evaluation (§VIII) shows that, depending on the chain
length and certiﬁcate type, Cinderella proofs are 1.2–5.4×
smaller than the evidence that would otherwise be communi-
cated. Policies that embed checks that would involve collecting
additional evidence from a third party (such as OCSP) also
allow signiﬁcant
latency gains by eliminating this request
entirely. Even though some protocols (e.g., TLS) feature mech-
anisms to attach (“staple”) third party evidence, Cinderella
still saves the cost of sending such evidence (which can take
several additional kilobytes). Cinderella proofs can be veriﬁed
at a cost comparable to native certiﬁcate chain validation (8
ms). However, proof generation is many orders of magnitude
slower than native execution (10 minutes for the most complex
policies in §VIII) and involves large keys (up to 1 GB). In the
applications we consider, we deal with the prover overhead by
computing proofs ofﬂine, and by re-using the computed proof
for short periods of time.

From a privacy standpoint, because modern veriﬁable com-
putation protocols support zero knowledge properties for the
prover’s inputs, Cinderella enables the selective disclosure of
information embedded in standard X.509 certiﬁcates. Instead
of revealing these certiﬁcates in the clear, the prover can
convey only the attributes needed for a particular application.
For example, the outsourced computation can validate the
prover’s certiﬁcate chain, and then check that the issuer is on
an approved list, that the prover’s age is above some threshold,
or that he is not on a blacklist. The veriﬁer learns that these
checks were performed correctly, and nothing more. As a
concrete example, Estonian ID certiﬁcates embed information
about the subject’s name, address and email, as well as a
unique national identity number (“isikukood”), which encodes
the gender and birth date of the owner. Estonian law mandates
ownership of an ID card for citizens over 15, and by necessity
considers the information it contains public (as it may be sent
in clear), even though many users, if given the choice, may
prefer to keep some of this information private when signing
into government or commercial websites. Certiﬁcate privacy

236236

is also compelling for scenarios such as e-voting, where the
strong identiﬁcation provided by X.509-based ID cards needs
to be balanced with voter privacy.

Cinderella uses Pinocchio [30, 59], a state-of-the-art system
for veriﬁable computation. Pinocchio compiles C code ﬁrst
into arithmetic equations in a large prime ﬁeld, and then
into cryptographic keys. While Pinocchio accepts C code as
input, programmed na¨ıvely, it will produce enormous keys that
require tremendous work from the prover. Thus, an important
challenge for Cinderella is developing C code for standards-
compliant X.509 certiﬁcate-chain validation that Pinocchio
will compile into an efﬁcient cryptographic scheme.

The ﬁrst part of the chain-validation challenge is to en-
code the veriﬁcation of RSA PKCS#1 signatures. Cinderella
achieves this via a carefully implemented multi-precision
arithmetic C library tailored to Pinocchio; the library takes
non-deterministic hints—the quotients, residues, and carries—
as input to circumvent costly modular reductions. The second
challenge is to verify X.509 parsing, hashing, and ﬁltering
of certiﬁcate contents. These tasks are already complicated in
native code. To handle X.509 formats efﬁciently, Cinderella
supports policies based on certiﬁcate templates, written in a
declarative language, and ﬁrst compiled to tailored C code
before calling Pinocchio on whole certiﬁcate-chain-validating
veriﬁable computations.

To demonstrate Cinderella’s practicality, we ﬁrst show how
to seamlessly integrate Cinderella-based certiﬁcate-chain vali-
dation into SSL/TLS. Rather than modifying the TLS standard
and implementations, we replace the certiﬁcate chains com-
municated during the handshake with a single, well-formed,
564-byte X.509 pseudo-certiﬁcate that carries a short-lived
ECDSA public key (usable in TLS handshakes) and a proof
that this key is correctly-signed with a valid RSA certiﬁcate
whose subject matches the peer’s identify. We experiment
with both client and server authentication. For clients, we
use templates and test certiﬁcates for several national ID
schemes. For servers, we use typical HTTPS policies on
certiﬁcate chains featuring intermediate CAs and OCSP sta-
pling. Although the resulting Cinderella pseudo-certiﬁcates
can take up to 9 minutes to generate for complex policies,
they can be generated ofﬂine and refreshed, e.g., on a daily
basis. Online veriﬁcation of the pseudo-certiﬁcates and their
embedded proof takes less than 10 ms.

We also employ Cinderella as a front end to Helios [2],
a popular e-voting platform. Assuming that every potential
voter is identiﬁed by some X.509 certiﬁcate, we enhance
voter privacy while enabling universal veriﬁability of voter
eligibility. Similarly, we do not modify the Helios scheme or
implementation. Rather, to each anonymous ballot, we attach
a Cinderella proof that the ballot is signed with some valid
certiﬁcate whose identiﬁer appears on the voter list, and that
the ballot is linked to an election-speciﬁc pseudo-random alias
that is in turn uniquely linked to the voter’s certiﬁcate. This
allows multiple ballots signed with the same certiﬁcate to be
detected and discarded. The proof reveals no information about
the voter’s identity. Proof generation takes 90 s, and proof
veriﬁcation is fast enough to check 400,000 ballots in an hour.

Contributions In a nutshell, Cinderella contributes:

• a new practical approach to retroﬁt some ﬂexibility and

• a real-world application of veriﬁable computation: out-

privacy into an ossiﬁed X.509 infrastructure (§II-B);
sourcing certiﬁcate-chain validation (§III);
• a template-based compiler and a collection of libraries for
RSA-PKCS#1 (§IV) and ASN.1 (§V) carefully tailored
for veriﬁable computations over X.509 certiﬁcates;
• deployment case studies for TLS (§VI) and Helios [2]
(§VII) and their detailed evaluation (§VIII).

Limitations While Cinderella does not require changes to
certiﬁcate authorities or other existing X.509 infrastructure
(e.g., smartcards or HSMs), it does require changes to both
clients and servers, which may hinder its deployment for gen-
eral purpose applications like HTTPS. Conversely, under the
assumption that both clients and servers can be changed, some
of Cinderella’s features may be achieved without advanced
cryptography. For instance, one may re-use Cinderella’s com-
piler from high-level policies to certiﬁcate-validation functions
and simply run the resulting code natively at the veriﬁer.

Hiding certiﬁcate contents may prevent local checks, such
as public key pinning [38] or CAge [48]. This is a matter
of policy: Cinderella may enable these checks if desired, by
disclosing sufﬁcient information.

An essential limitation of systems based on succinct proofs
of outsourced computation is their reliance on a trusted party to
generate the cryptographic keys. An honest key generator uses
a randomly selected value to create the scheme’s keys and then
deletes the random value. A rogue Cinderella key provider,
however, could save the random value and use it as a backdoor
to forge proofs for the associated policy. Dangerously, and in
contrast to the use of rogue certiﬁcates, such proofs would be
indistinguishable from honest proofs and thus undetectable.
Besides careful key management and local checks to reduce
the scope of policies, a partial remedy is to generate keys using
a multi-party protocol [10], which only requires that one of
the parties involved is honest.

II. BACKGROUND

We review key facts about the veriﬁable computation tech-
niques (§II-A) used by Cinderella and the X.509 PKI (§II-B).
A. Veriﬁable Computation

Cinderella requires a succinct, zero knowledge, public,
veriﬁable computation protocol to validate X.509 certiﬁcates.
In our implementation, we use the Geppetto compiler [30] for
the Pinocchio [59] protocol, itself a reﬁnement of a protocol
developed by Gennarro et al. [42]. We refer to this combination
as Pinocchio, and we review it below, but our approach is
compatible with similar schemes [3, 6, 8, 9, 16, 68].

Pinocchio enables a veriﬁer to efﬁciently check compu-
tations performed by untrusted provers, even when the un-
trusted provers supply some of the computation’s inputs.
Concretely, the untrusted prover generates a proof that he
computed F (u, w), where F is a veriﬁer-speciﬁed function,
u is a veriﬁer-speciﬁed public input, and w is a private
input provided by the prover. Veriﬁable computation protocols

237237

supporting zero knowledge (also known as succinct, non-
interactive zero-knowledge arguments [14, 43]) allow the
prover to optionally keep w secret from the veriﬁer.

More formally, Pinocchio consists of three algorithms:
1) (EKF , V KF ) ← KeyGen(F, 1λ): takes the function
F to be computed and the security parameter λ, and
generates a public evaluation key EKF and a public
veriﬁcation key V KF .
2) (y, πy) ← Compute(EKF , u, w): run by the prover,
takes the public evaluation key, an input u supplied by
the veriﬁer, and an input w supplied by the prover. It
produces the output y of the computation and a proof of
y’s correctness (as well as of prover knowledge of w).
3) {0, 1} ← Verify(V KF , u, y, πy): using the public
veriﬁcation key, takes a purported input, output, and
proof and outputs 1 only when F (u, w) = y for some w.
In brief, Pinocchio is Correct, meaning that a legitimate
prover can always produce a proof that satisﬁes Verify; Zero
Knowledge, meaning that the veriﬁer learns nothing about
the prover’s input w; and Sound, meaning that a cheating
prover will be caught with overwhelming probability. Prior
work provides formal deﬁnitions and proofs [30, 59].

Pinocchio offers strong asymptotic and concrete perfor-
mance: cryptographic work for key and proof generation scales
linearly in the size of the computation (measured roughly as
the number of multiplication gates in the arithmetic circuit rep-
resentation of the computation), and veriﬁcation scales linearly
with the veriﬁer’s IO (e.g., |u| + |y| above), regardless of the
computation, with typical examples requiring approximately
10 ms [59]. The proofs are constant size (288 bytes).

To achieve this performance, Pinocchio’s compiler takes C
code as input and transforms the program to be veriﬁed into
a Quadratic Arithmetic Program (QAP) [42]. In a QAP, all
computation steps are represented as an arithmetic circuit (or
a set of quadratic equations) with basic operations like addition
and multiplication taking place in a large (254-bit) prime ﬁeld.
In other words, unlike a standard CPU where operations take
place modulo 232 or 264, in a QAP, the two basic operations
are x + y mod p and x∗ y mod p, where p is a 254-bit prime.
As a result, care must be taken when compiling programs.
For example, multiplying two 64-bit numbers will produce the
expected 128-bit result, but multiplying four 64-bit numbers
will “overﬂow”, meaning that the result will be modulo p,
which is unlikely to be the intended result. To prevent such
overﬂow, the Pinocchio compiler tracks the range of values
each variable holds, and inserts a reduction step if overﬂow is
possible. Reduction involves a bit-split operation, which splits
an arithmetic value into its constituent bits. Bit splits are also
necessary for bitwise operations, such as XOR, as well as for
inequality comparisons.

In Pinocchio’s cost model, additions are free, multiplications
cost 1, and bit splits cost 1 per active bit
in the value
split. Hence splitting the result of multiplying two 64-bit
numbers costs 128× more than the initial multiplication did.
Finally, dynamic array accesses (i.e., those where the index
into the array is a run-time value) must be encoded and

Issuer

Public Key

Subject

Signature
Root

Issuer

Public Key

Subject

Signature

…

Intermediates

Matches
Signature Verified by
Output

Certificate ::= SEQUENCE {
tbsCertificate
signatureAlgorithm
signature

ToBeSigned,
AlgorithmIdentifier,
BIT STRING }

Issuer

Public Key

Subject
Signature
Endpoint

[0] Version DEFAULT v1,

ToBeSigned ::= SEQUENCE {
version
serialNumber
signature
issuer
validity
subject
subjectPublicKeyInfo SubjectPublicKeyInfo,
issuerUniqueID [1] IMPLICIT UID OPTIONAL,
subjectUniqueID [2] IMPLICIT UID OPTIONAL,
extensions
[3] Extensions OPTIONAL }

SerialNumber,
AlgorithmIdentifier,
Name,
Validity,
Name,

Fig. 1. High-level overview of the X.509 PKI

can be expensive. While various techniques have been de-
vised [5, 9, 13, 16, 56, 68, 70], the costs remain approximately
O(log N ) per access to an array of N elements.

From the programmer’s perspective, Pinocchio compiles
typical C functions. Each function takes as arguments the
inputs and outputs known to the veriﬁer (the values u and y
above). The function can also read, from local ﬁles, additional
inputs available only to the prover (the value w above).

B. The X.509 Public Key Infrastructure

We recall X.509’s salient characteristics and summarize the
main classes of issues with the PKI. Clark et al. provide more
details and references [28].

X.509 deﬁnes the syntax and semantics of public key
certiﬁcates and their issuance hierarchy. The purpose of a
certiﬁcate is to bind a public key to the identity of the owner
of the matching private key (the subject), and to identify the
entity that vouches for this binding (the issuer). Certiﬁcates
also contain lifetime information, extensions for revocation
checking, and extensions to restrict the certiﬁcate’s use.

The PKI’s main high-level API is certiﬁcate-chain validation
(illustrated in Figure 1), which works as follows: given a
list of certiﬁcates (representing a chain) and a validation
context (which includes the current time and information on
the intended use), it checks that:

1) the certiﬁcates are all syntactically well-formed;
2) none of them is expired or revoked;
3) the issuer of each certiﬁcate matches the subject of the

application policy (e.g. “valid for signing emails”).

If all these checks succeed, chain validation returns a parsed
representation of the identity and the associated public key in
the ﬁrst certiﬁcate (the endpoint).
Syntactic & semantic issues X.509 certiﬁcates are encoded
using the Distinguished Encoding Rules (DER) of ASN.1,
whose primary goal is to ensure serialization is injective: no
two distinct certiﬁcates have the same encoding. In ASN.1,
there is no absolute notion of syntactic correctness; instead, a
payload is well-formed with respect to some ASN.1 grammar

238238

next in the chain;

4) the signature on the contents of each certiﬁcate can be

veriﬁed using the public key of the next in the chain;

5) the last, root certiﬁcate is trusted by the caller; and
6) the chain is valid with respect to some context-dependent

Fig. 2. ASN.1 Grammar of X.509 Certiﬁcates

that speciﬁes the overall structure of the encoded data, with
semantic annotations such as default values and length bound-
aries (Figure 2 depicts a fragment of the X.509 grammar).

Mistakes and inconsistencies in implementations of X.509
have led to dozens of attacks [26]. Famously, the ﬁrst ver-
sion of X.509 did not include a clear distinction between
certiﬁcate-authority (CA) and endpoint certiﬁcates. A later
version introduced an extension to clarify this distinction,
but Marlinspike [55] showed that several browsers could
be confused to accept endpoint certiﬁcates as intermediates
in a chain, and similar errors have reoccurred periodically.
Similarly, Bleichenbacher showed that many implementations
of DER are incorrect, leading to universal forgery attacks
against PKCS#1 signatures; again, variations of this attack
have reappeared every so often. In contrast, Cinderella does
not trust X.509 parsers; instead, it veriﬁes the correctness of
untrusted parsing by re-serializing and hashing (§V).
Cryptographic failures The X.509 PKI is slow to change;
it is not uncommon for certiﬁcation authorities (CAs) to use
the same root and intermediate certiﬁcates for years, without
upgrading the cryptographic primitives used for signing. For
instance, the MD5 hashing algorithm remained widely used for
several years after Wang et al. [69] demonstrated that it was
vulnerable to collision attacks. The ongoing migration from
SHA1 to SHA2 has also been delayed by over a year, due
to pressure to maintain legacy support. Similarly, a number
of certiﬁcation authorities have allowed the use of short RSA
public keys [33], or keys generated with low entropy [47]. As
a moot point, Cinderella may partially mitigate these issues
by allowing certiﬁcate owners to hide their public keys and
certiﬁcate hashes, and hence to prevent some ofﬂine attacks;
arguably, it also makes such issues harder to measure.
Issuance & validation policy issues As explained above,
certiﬁcate-chain validation includes a notion of compliance
with respect
to some application policy. For instance, for
HTTPS, a certiﬁcate needs to satisfy a long list of conditions
to be considered valid. Even the most basic condition is quite
complicated: the HTTP domain of the request must match
either the common name ﬁeld of the subject of the certiﬁcate,
or one of the entries of type DNS from the Subject Alternative
Names (SAN) extension. This matching is not simply string

equality, as domains in certiﬁcates may contain wildcards.

Fahl et al. [39] show that a large number of Android applica-
tions use a non-default validation policy for their application.
More generally, Georgiev et al. [44] report that a large fraction
of non-browser uses of the PKI use inadequate validation
policies. Instead of writing a custom policy suited to their
application (e.g., pinning, custom root certiﬁcates, trust on ﬁrst
use), most developers simply use an empty validation policy
that can be trivially bypassed by an attacker.

Similarly, even though all certiﬁcation authorities are subject
to a common set of issuance guidelines [18, 23, 37], the
variability of their issuance policies remains high [33]. Thus
current validation policies are only as strict as the PKI’s most
permissive policy (in terms of key sizes, maximum lifetime,
or availability of revocation information). With Cinderella,
validation policies are mostly speciﬁed through a declarative
template system (§III) and transformed into Pinocchio keys,
allowing greater ﬂexibility from one issuer to the other.
Revocation X.509 revocation checking can take one of two
forms: revocation lists (CRL) must be downloaded out of
band, while the online certiﬁcate status protocol (OCSP)
can either be queried by the validator to obtain a signed
proof of non-revocation; or this proof may be stapled to
the certiﬁcate to prevent a high-latency query. Unfortunately,
these mechanisms are not widely used in practice; a 2013
study indicated that only 20% of servers supported OCSP
stapling [58]. A similar study conducted in 2015 showed an
even lower number: only 3% of certiﬁcates were served by
hosts supporting OCSP stapling [54]. Worse, once a certiﬁcate
is compromised and subsequently revoked [51], they prevent
attacks only inasmuch as failures to verify non-revocation are
treated as fatal errors, an issue recognized and quantiﬁed in
recent PKI papers [4, 63, 65]. As shown in §VI, Cinderella
naturally supports OCSP stapling with no additional effort
from the veriﬁer.
Delegation Many practical applications rely on some form of
authentication delegation. In particular, many servers delegate
the delivery of their web content to content delivery networks
(CDNs). Websites that use HTTPS with a CDN need to give
their X.509 credentials to the CDN provider, which can cause
serious attacks when CDNs improperly manage customer cre-
dentials [32]. In a survey about this problem, Liang et al. [52]
propose to reﬂect the authentication delegation of HTTPS
content delivery networks as X.509 delegation. Unfortunately,
this is impractical, because it requires an extension of X.509
which CAs are unlikely to implement, as it is detrimental to
their business. Cinderella allows a content-owner to implement
secure X.509 delegation to CDNs using short-lived pseudo-
certiﬁcates, without the CA’s cooperation (§VI).

III. CINDERELLA’S CERTIFICATE-CHAIN VALIDATION

A. Architecture Overview

Cinderella targets applications in which a certiﬁcate holder
presents a certiﬁcate chain to a validator who checks both
that the chain is well formed (§II-B) and that it adheres to the
application’s validation policy. With Cinderella, the validator

9
9

9
9

Today

π

π

π

Cinderella

Fig. 3. Cinderella S/MIME example. Today, an email sender includes her
signature and a certiﬁcate-chain for her public key, and the email’s recipient
checks both. With Cinderella, the sender performs those checks using veriﬁ-
able computation and produces a succinct proof π that the recipient checks.

no longer performs these checks; instead, we outsource them
to the certiﬁcate holder using veriﬁable computation (§II-A).
Speciﬁcally, we write a procedure (as C code) that checks
a certiﬁcate chain and checks that the chain adheres to the
validation policy. We then compile this procedure into public
evaluation and veriﬁcation keys.

As a concrete running example, consider a client who
wishes to sign her email using the S/MIME protocol (Fig-
ure 3). She holds a certiﬁcate issued by a well-known CA for
her public key, and she uses her corresponding private key to
sign a hash of her message.

With the current PKI, she attaches her certiﬁcate and
signature to the message. The recipient of the message extracts
the sender’s email address (from), parses and checks the
sender’s certiﬁcate, and veriﬁes, in particular, that the sender’s
certiﬁcate forms a valid chain together with a local, trusted
copy of the CA certiﬁcate; that its subject matches the sender’s
address (from); and that it has not expired. Finally, he veriﬁes
the signature on a hash of the message using the public key
from the sender’s certiﬁcate. These checks may be performed
by a C function, declared as
void validate (SHA2∗ hash , char∗ from ,
CHAIN∗ certs , SIG∗ sig ) ;

time∗ now,

For simplicity, assume that all S/MIME senders and receivers
agree on this code for email signatures, with a ﬁxed root CA.
With Cinderella, we compile validate into cryptographic
keys for S/MIME, i.e., an evaluation key and a veriﬁcation key
(§II-A). Email-signature validation then proceeds as follows.
• The sender signs the hash of her message as usual, using
the private X.509 key associated with her certiﬁcate.
Instead of attaching her certiﬁcate and signature, however,
she attaches a Pinocchio proof. To generate this proof,
she calls Cinderella with the S/MIME evaluation key,
her message hash, email address, time, certiﬁcate, and
signature. Cinderella runs validate on these arguments
and returns a proof that it ran correctly.

• Instead of calling validate, the recipient calls Cin-
derella with the S/MIME veriﬁcation key and the received
message’s hash, its from ﬁeld, and its proof. Although the
certiﬁcate and signature never leave the sender’s machine,
the recipient is guaranteed that validate succeeded,
and hence that the message was not tampered with.

While this protocol transformation requires the sender to gen-
erate the Pinocchio proof, it still fully enforces the recipient’s
validation policy (by Pinocchio’s soundness); it offers greater
privacy to the sender, since her certiﬁcate need not be revealed

239239

(by Pinocchio’s zero-knowledge properties); and it simpliﬁes
the recipient’s task, since he now runs a ﬁxed veriﬁcation
algorithm on a ﬁxed proof format.

Furthermore, it is possible to generate Cinderella keys for
extended policies not supported by S/MIME. For instance, if
the recipient is a mailing list, validate may also check
that the email address listed in the certiﬁcate is a member
of the mailing list, or even that the sender holds a valid
list-membership certiﬁcate. Thus, Cinderella naturally enables
group or attribute-based signatures using existing credentials.
Next, we address the challenges in specifying policies
(§III-B), checking certiﬁcate chains (§III-C), and managing
Cinderella’s evaluation and veriﬁcation keys (§III-D).

B. Template-Based Certiﬁcate Validation Policies

We need to capture application policies in a high-level,
programmatic manner. Indeed, while Pinocchio guarantees the
correct execution of the validation code, it will not check that
the code itself correctly implements the intended policy.

To this end, Cinderella supports validation policies written
by composing certiﬁcate templates [33] (one for each kind of
certiﬁcate that may appear in a chain) and by adding custom
application checks, for instance matching an email address
with the common name of a certiﬁcate. Thus, application
writers can author mostly-declarative policies by customizing
templates and adding a few lines in C, while Cinderella au-
tomatically translates their templates into custom, lower-level,
optimized C code that deals with parsing and cryptography.

None of this relies on new cryptography for veriﬁable
computation. Arguably, our templates and declarative policies
for certiﬁcate-chain validation are of independent
interest.
Their translation may be adapted to generate code for local
enforcement at the veriﬁer, instead of outsourcing.

1) Writing X.509 Templates: Certiﬁcate templates deﬁne
classes of certiﬁcates that differ only in the values of a ﬁxed
set of variable ﬁelds. Fortunately, issuers tend to conform to a
relatively small set of templates: a recent study used machine
learning to derive 1500 endpoint templates that sufﬁced to
cover over a million certiﬁcates issued during a one year
period [33]. As we also use templates for CA certiﬁcates
and partial chains, we claim our approach can scale to the
whole PKI, at the cost of managing more Cinderella keys than
(∼ 200) root certiﬁcates.

Cinderella deﬁnes a syntax similar to ASN.1 grammars
for writing certiﬁcate templates. This syntax supports all the
ASN.1 types for data structures in X.509: sequences and
sets, encapsulated bit and octet strings, and custom tagging.
Our template syntax also supports the primitive types used
in certiﬁcates:
timestamps, and
various ﬂavors of strings. All primitive ﬁelds must be deﬁned
as constant or variable.

integers, object

identiﬁers,

Variable ﬁelds (var<type,x,n,m>) use four parameters:
type is the ASN.1 type of the variable, x is the name of the
variable ﬁeld, and n..m is the range of the length (in bytes) of
the ﬁeld. As we discuss in detail in §V, bounding the length
of variable ﬁelds is critical for performance.

240240

seq { # Validity Period

var<date, notbefore, 13, 13>;
var<date, notafter, 13, 13>; };

seq { # 2 to 3 subjects fields

varlist<subjectnum, 2, 3>:
set {

seq { # each with an OID and a value

var<oid, subject_oid, 3, 6>;
var<x500, subject_val, 5, 25>; };};};

seq { # Public Key

seq { # Key algorithm (RSA)

const<O1.2.840.113549.1.1.11>;
const<null>; };

bitstring: # Encapsulated key

seq {

var<int, pubkey, 257, 257>; # 2048 bits
const<65537L>; # fixed public exponent

};};

Fig. 4. Fragment of a template for a class of email certiﬁcates

As a concrete example, Figure 4 shows a fragment from a
certiﬁcate template for S/MIME (the full template requires less
than 200 lines). The fragment speciﬁes the validity period, the
subject, and the public key of the certiﬁcate. Following current
practice, this template uses a constant signature algorithm
(1.2.840.113549.1.1.1 is the object identiﬁer for RSA keys),
and public exponent e = 65537. The ASN.1 type of constants
is inferred from the syntax; for instance, object identiﬁers start
with an O, while integer types end with an L.

In addition to variable ﬁelds, we support constructors
for structural variability: option<x> allows an entire sub-
structure to be omitted (e.g. an optional extension), while
varlist<x,n,m> allows a substructure to be repeated a
bounded number of times. For instance, the subject of a certiﬁ-
cate is encoded as a list of key-value pairs (where the key is an
object identiﬁer that represents, say, the country, organization
or address of the subject). The template in Figure 4 allows
certiﬁcates with either 2 or 3 subject ﬁelds (allowing for
instance subjects with an optional contact email).

A certiﬁcate matches a given template when there exists a
(well-typed) assignment to the template variables such that the
certiﬁcate and the template yield exactly the same sequence
of bytes according to the X.509 grammar.

Besides algorithm identiﬁers,

templates mandate many
checks on certiﬁcates. For example, one portion of our
S/MIME template (not shown in Figure 4) mandates that the
sender-certiﬁcate’s issuer matches the (ﬁxed) CA certiﬁcate’s
subject, and that its ‘extended key usage’ have its ‘email
authentication’ ﬂag set.

2) Compiling X.509 Templates to C Veriﬁers: Cinderella
includes a compiler from templates to C certiﬁcate-veriﬁers,
that is, C functions that take as parameters the RSA modulus of
the certiﬁcate parent, an assignment to the template variables
and (as auxiliary input) an RSA signature σ. Each function
(1) computes a hash of the ASN.1-formatted certiﬁcate that re-
sults from instantiating the template with the concrete variable
assignments; and (2) veriﬁes that σ is a valid signature on that
hash using the parent’s modulus. Thus, given an assignment,
the certiﬁcate-veriﬁer code guarantees the existence of a well-
signed certiﬁcate that matches its template.

typedef struct { unsigned char v[13]; } notbefore;
typedef struct { unsigned char v[13]; } notafter;
typedef struct { int len; unsigned char v[6]; } subject_oid;
. . .
void hash_MailCert(SHA2* hash, subject_oid* soid, . . . ){

hashBuffer b; // hash buffer, explained in §V
append(&b, 0x30);
. . .
for(i=0; i<6; i++) // appends a string of at most 6 chars

if(i < soid[0].len))

append(&b, soid[0].v[i]);

. . .
SHA2(hash, b); // computes the certificate hash

}
void verify_MailCert(modulus* mod /* parent key */,

subject_oid* soid, notbefore* nbefore, . . .){

SHA2 hash; // certificate hash
hash_MailCert(hash, soid, nbefore, nafter, . . .);
load_Signature("MAILCERT_SIGNATURE", signature, . . .);
verify_Signature(mod, signature, hash); }

Fig. 5. Fragment of the C code compiled from the template of Figure 4

On the prover side, Cinderella includes a template-based
parser that reads a certiﬁcate and returns the variable assign-
ments and auxiliary inputs necessary to produce a proof. This
parser is not trusted by the veriﬁer.

Figure 5 shows a fragment of the 900 lines of C code
compiled from the template in Figure 4. It
includes a C
structure deﬁnition for each of the variables of the template. It
deﬁnes an auxiliary function hash_MailCert, to compute
the hash of the email certiﬁcate based on concrete values for
all of the template variables. This automatically generated code
handles the many complications of ASN.1 encoding. As one
small example, it handles the fact that the length of structured
tags (such as sequences) depends on variable length ﬁelds
within the structure, and even the length of the length encoding
may vary. Figure 5 shows a small example with conditional
calls to append to add the variable-length ﬁeld soid[0] to
the certiﬁcate’s hashed contents, one byte at a time.

The generated code also deﬁnes a function verify_
MailCert that takes as an additional input the RSA modulus
of the parent certiﬁcate, loads a signature from a local ﬁle, and
veriﬁes that it is a correct signature on that hash. This code
may fail on bad inputs; it returns only if all checks succeed.
3) Writing Template-Based Application Policies: Although
templates offer a convenient, declarative way of enforcing
certiﬁcate policies, we still have to write the ‘top-level’
validate function that properly chains together template-
veriﬁer calls (following the chaining of the actual certiﬁcates)
and includes application-speciﬁc checks on the values of
template variables. In our prototype, these are written in C.

For example, our S/MIME policy checks that the sender’s
email address is listed in the subject of
the certiﬁcate,
that the current time is within the certiﬁcate’s notbefore
..notafter interval, and that the signature on the message
hash veriﬁes using the public key of the certiﬁcate. These
checks are facilitated by Cinderella’s library functions.
Figure 6 outlines the resulting ‘top-level’ validator in C,
whereas §VI and §VII describe more complex examples.
The code illustrates the three checks explained above. By
convention, the arguments of validate are those provided

#include "RSA.c"
#include "SHA.c"
#include "MailCert.c" // compiled from MailCert template

// explained in §IV
// explained in §V

// The function outsourced by the recipient to the sender
void validate(SHA2* hash, char* from, time* now) {

. . .
// validate sender certificate
load_Modulus("S/MIME_CA_MODULUS", root, COMPILE_TIME);
verify_MailCert(root, soid, nbefore, nafter, sval, pkey . . .);

// check contents against ‘from’ and ‘now’ arguments
match_email_address(from, soid, sval);
assert(time_compare(nbefore, now) == 1);
assert(time_compare(now, nafter) == 1);

// verify signature on the email hash argument
load_Signature("MSG_SIGNATURE", signature, RUN_TIME);
verify_Signature(pkey, signature, hash); }

Fig. 6. Fragment of a certiﬁcate validator for S/MIME

by the veriﬁer, whereas prover inputs are read from ﬁles. In
our sample validator, the (ﬁxed) modulus of the root certiﬁcate
is read from a ﬁle, whereas the (variable) signature value is
read from a ﬁle provided by the prover. More complex valida-
tors involving intermediates would include further certiﬁcate-
veriﬁers compiled from their templates.

At

C. Compiling Validation Policies from C to Cinderella Keys
this point, we have constructed a C validator that
implements our application policy but, in principle, given the
additional prover inputs (the certiﬁcate, the signature, etc.) we
could still run this code at the veriﬁer.

The next step is to call Cinderella in key-generation mode,
passing the validator code, the template-derived certiﬁcate-
veriﬁer code, auxiliary input ﬁles for constants, and Cin-
derella’s cryptographic libraries for handling RSA-PKCS#1
(§IV) and ASN.1 (§V). Cinderella ‘bakes’ all these inputs
into public evaluation and veriﬁcation keys for the applica-
tion policy. The key-generation step is similar to certiﬁcate
issuance; it must be trusted by the application users, which
may in turn involve existing PKI mechanisms, or it may rely
on decentralized key generation protocols [10]. In contrast
with plain X.509 certiﬁcates, however, Cinderella policies are
more expressive, so fewer keys may need to be deployed.
In our S/MIME example, for instance, a single pair of keys
covers all certiﬁcate-based signature validations for a given
CA; veriﬁer keys (which use about a kilobyte of storage) are
then distributed together with mail clients and kept in their
local conﬁguration instead of the CA certiﬁcate (which use
a similar amount of space). Certiﬁcate holders who wish to
use Cinderella for S/MIME must download the prover key
associated with their certiﬁcate’s policy; this incurs a much
larger overhead, as these keys may be over 160 MB.

In effect, we propose to partition all X.509 certiﬁcates of
interest into classes via templates and then generate one pair of
evaluation and veriﬁcation keys for each combination of class
and validation policy. Na¨ıvely, we could try to compile a few
generic, lax policies that accommodate, for example, all cer-
tiﬁcate chains currently accepted for webserver authentication.
This approach would impose an unrealistic computational cost

241241

on the prover (see §V) and, besides, it would not help enforce
custom application policies. Conversely, restricting a key pair
to a particular certiﬁcate class and application policy simpliﬁes
the task of parsing and validating certiﬁcates in that class, and
hence results in less effort for the Cinderella prover.

D. Discussion: Managing Cinderella keys

1) Controlling Policies (the Application’s Viewpoint): Even
with Cinderella, determining the ‘right’ X.509 certiﬁcate vali-
dation policy for a given application remains a hard problem.
Nonetheless, Cinderella simpliﬁes policy deployment: since
each policy is ‘baked’ into a pair of public keys, a new policy
can be deployed to all users by installing the short (1 to
2KB) veriﬁer key. Since there are no changes to the veriﬁer’s
software, there is no risk of inserting remotely-exploitable
software errors. In comparison, today, deploying a new policy
may involve a combination of software, conﬁguration, and
certiﬁcate updates.

Our approach enables applications to design and distribute
their own custom policies, rather than rely on those currently
supported by popular client software. For example, a service
or a regulator (say, for a school, or the banking industry) may
decide which checks to include, which roots to trust, which
algorithms to use, and which latency to tolerate for OCSP
certiﬁcates. The policy may incorporate some application logic
or even algorithms not implemented by the certiﬁcate veriﬁer.
The policy may be deployed, e.g., as a key in the conﬁguration
of the client banking application, or by re-using existing public
key management mechanisms, such as key-pinning. We expect
such ad hoc, application-speciﬁc deployment of policies to
help break the circular dependency of servers only wanting to
use a policy once supported by almost all clients.

Cinderella policies also provide a greater degree of control
to the application, inasmuch as their enforcement is not left
up to the interpretation of the veriﬁer’s software—indeed, the
proof veriﬁcation steps are largely independent of the policy.
Cinderella policies also enable some emancipation from
traditional certiﬁcate issuers, notably root CAs, who can
currently impersonate any of their customers. As an example,
an S/MIME policy may require that a class of ofﬁcial mail be
signed by two certiﬁcates, issued by two independent CAs, or
that the sender certiﬁcate be endorsed by some independent
organization. Similarly, such policies can be deployed just by
pushing a new key to the browser or the client software.

2) Enforcing Certiﬁcate Validation (the Veriﬁer’s View-
point): At the other end, enforcing general-purpose certiﬁcate
validation is also known to be difﬁcult and error-prone; it
involves managing a certiﬁcate store, vetting root CAs, storing
pinned certiﬁcates, checking for key revocation, etc.

From the veriﬁer’s viewpoint, Cinderella veriﬁcation keys
are just as easy (and as hard) to manage and to use as any
others; in that sense, we do not ‘solve’ the PKI problem, we
just introduce a new set of keys.

However, a single Cinderella key can enforce more ﬂexible
and expressive authorization and authentication policies than
those expressible within the X.509 certiﬁcate text. Thus, a

single, long-lived Cinderella key can encapsulate a complex
policy that might otherwise require many short-lived tradi-
tional certiﬁcates. Experimental data suggests that, for a given
application, a few policies and templates may sufﬁce to cover
the uses of X.509 certiﬁcates for most client platforms [33].
For example, instead of installing a root certiﬁcate key to
access some exotic service, installing a Cinderella key for that
service is more speciﬁc and more versatile, inasmuch as the
client, or some trusted third party, can review the precise policy
associated with the key.

Empirically, many past vulnerabilities have been due to
bugs in X.509 certiﬁcate parsing and validation code, for
example in their handling of ill-formed certiﬁcates, or their
lax interpretation of certiﬁcate-signing ﬂags, and each of those
bugs required a full software patch. Our technical answer to
this class of problem is to mostly generate the parsing and
validation routines from high-level speciﬁcations; however, we
note that this approach can be applied to the native validation
code, and an interesting research direction is to certify the
compilation process. In addition, we argue any (potential)
bug in a Cinderella policy or its implementation would be
easier to patch by updating the policy key, regardless of
the variety of application implementations. Furthermore, after
Cinderella’s key generation phase, if the generation is done
honestly, there is no longer any secret associated with the
Cinderella keys, so they cannot be dynamically compromised.
The ﬁxed code used by the Cinderella veriﬁer itself constitutes
a smaller trusted computing base, used in a uniform manner,
independent of the actual certiﬁcate contents. However, it also
means that
implementation-speciﬁc checks that depend on
non-public values of the certiﬁcate are no longer possible.

E. Cinderella’s Security

In Appendix A, we show that Cinderella is (almost) as se-
cure as a system in which the certiﬁcate-chain validation code
is performed by the veriﬁer. Cryptographically, the argument
relies on Pinocchio’s proof-of-knowledge property. In other
words, if Cinderella successfully veriﬁes a proof, even one
generated by a malicious prover, then given sufﬁcient control
of the prover and its randomness, a simulator can extract
valid inputs to successfully run the validate function.
Continuing with our example, we can thus reduce the security
of Cinderella’s S/MIME to the security of plain S/MIME
signing and its PKI. The proof of privacy is straightfor-
ward and relies on Pinocchio’s zero-knowledge property. A
simulator that controls a trapdoor installed during Pinocchio
parameter generation can create a proof without knowledge of
the prover’s private inputs to validate.

In practice, any deployment must preclude the existence
of such a trapdoor, e.g., using the techniques of Ben-Sasson
et al. [10]. In addition, one should carefully balance what is
hidden by the proof and what is veriﬁed in the clear, to ensure
compatibility with, e.g., Certiﬁcate Transparency [45] and the
EFF’s SSL Observatory [36].

242242

IV. RSA SIGNATURE VERIFICATION

Cinderella supports the RSA PKCS#1v1.1 signature veri-
ﬁcation algorithm on keys of up to 2048 bits, coupled with
the SHA1 and SHA256 hash functions. This combination
of algorithms is sufﬁcient to validate over 95% of recently
issued certiﬁcate chains on the Web, according to recent PKI
measurement studies [33, 35]. We assume all RSA certiﬁcates
use the public exponent e = 65537, the only choice in practice.
To prove knowledge of a valid RSA signature, given as
input a SHA digest h, an RSA modulus N, and the signature
value s, we must show that

se

mod N = Padding(h)

(1)

Depending on the application, either N or h may be a ﬁxed
input, i.e., a value known when we generate Cinderella keys.
For a given modulus size, Padding(h) is simply h + P for
some constant P . However, the arithmetic operations above
operate on much larger numbers than the 254-bit prime
used by Pinocchio’s computations (§II-A); hence, the main
challenge of this section is multi-precision QAP arithmetic.

We encode a big integer S as an array of n words (S[j])
(cid:2)n−1
of w bits each, such that w < 254 and nw > 2048. Thus,
j=0 S[j]2jw. Inlining the standard square-and-multiply
S =
algorithm for computing the exponentiation in Equation (1)
on the (sparse) binary decomposition of e = 65537, we can
calculate the result recursively as follows

⎧⎪⎨
⎪⎩

Si =

if i = 0

s
S2
i−1 mod N if 0 < i < 17
sSi−1 mod N if i = 17

This gives us the result se mod N = s65537 mod N = S17.

Instead of veriﬁably computing the Si (which requires ex-
pensive modular reductions), we have the prover pre-compute
them externally and provide them as private prover inputs
during the veriﬁable computation. The goal of the validation
program is then to verify that the values Si were computed
honestly. To this end, we perform the multi-precision squaring
of steps 1 to 16 without propagating carries (that is, as a
multiplication between formal polynomials

(cid:2)

Si[j]xj):
(cid:8)

k=0 Si−1[k]Si−1[j − k]

2jw

(cid:7)(cid:2)j

(cid:2)2n−1
(cid:2)2n−1

j=0
j=0 Ci[j]2jw

Ci =

=

For the ﬁnal multiplication in step 17, the same formula is
used but with S0[j − k] instead of Si−1[j − k]. Observe that if
the maximum width of Ci[j], denoted w(cid:2)
= 2w+[log2(w)]+1,
is under 254 bits, and if we decompose inputs over n(cid:2)
= 2n
words (i.e., the n most signiﬁcant words are 0), it becomes
possible to compute Ci[j] by using native Pinocchio additions
and multiplications.

Still, the computed values Ci[j] must be related to the
untrusted input values Si[j]. To verify that Ci mod N = Si,
j=0 Qi[j]2jw
we ask the prover to provide a value Qi =

(cid:2)n(cid:2)

243243

big_copy(Si, s);
for(i=0; i < 17; i++) {

if(i < 16) big_square(Ci, Si);
else big_mul(Ci, Si, s);

big_mul(Mi, Ni, Q[i]);
big_sub(Di, Ci, Mi, compl); // compl = 2w(cid:2)−w
check_eqmod(Di, S[i], R[i]);
big_copy(Si, S[i]); }

Fig. 7. Cinderella code for modular exponentiation

void check_eqmod(bignum D, bignum S, bignum R){

int i, j; Elem U, V;
elem_init(U) elem_init(V);
elem_copy(U, compl); // compl = 2w(cid:2)−w

for(i=0; i < INPUT_WORDS; i++) {

elem_add(U, U, D[i]);
elem_mul(V, R[i], wf); // wf = 2w
elem_add(V, V, compl);
elem_add(V, V, D[i]);
elem_sub(U, U, V);
zeroAssert(1-elem_eq_zero(U));
elem_copy(U, R[i]); }}

Fig. 8. Cinderella code for checking Equation (2)

such that Ci − Si = N Qi. The computations of N Qi can also
be carried out as words Mi[j] of w(cid:2) bits as before:

(cid:2)2n−1
(cid:2)2n−1

j=0

j=0 Mi[j]2jw

(cid:7)(cid:2)j

N Qi =

=

k=0 Ni[k]Qi[j − k]

(cid:8)

2jw

Let Di[j] = Ci[j] − Mi[j]. Since Si and Ci are equal
modulo N, Di[0] and Si[0] are equal on their w least sig-
niﬁcant bits. Furthermore, the most signiﬁcant w(cid:2) − w bits
of Di[0] − Si[0], denoted Ri[0], are such that the w least
signiﬁcant bits of Ri[0] + Di[1] − Si[1] are all 0.

This propagation of carries leads to the following invariant:

Ri[j] + Di[j + 1] − Si[j + 1] = 2

wRi[j + 1]

(2)

While at ﬁrst glance it appears that computing Ri[j + 1] from
Di[j + 1] − Si[j + 1] requires a division by 2w, we instead
assume the Ri[j] are given as private prover inputs, and we
verify their correctness with a (cheap) multiplication by 2w.
The main fragment of the code that veriﬁes the correctness
of the Si is shown in Figure 7. In particular, the function that
veriﬁes equation (2) is shown in Figure 8. A ﬁnal concern in
implementing Equations (1) and (2) is the handling of signed
values. Our choice of w(cid:2) allows one spare bit for encoding
values x < 0 as x + 2w(cid:2)−w.

In our implementation, inputs are encoded as 36 words of
120 bits each (with the exception of the Ri[j] words, which
use 128 bits because of additive overﬂows). Note that it is
necessary to verify that all prover inputs are within these
bounds; otherwise the prover may be able to cheat using
the overﬂows produced in the multiplications between inputs.
The (omitted) code that performs this check using binary
decompositions and that compares the ﬁnal value of S17 to
h + P is straightforward.

V. ASN.1 FORMATTING & HASHING

To verify a signature on a certiﬁcate, we must ﬁrst format
the certiﬁcate’s contents (roughly the concatenations of the
binary encodings of all its ﬁelds) and compute a SHA digest.
1) SHA review: We rely on a new, custom C library
for SHA1 and SHA256 tailored to Pinocchio. We omit the
algorithm’s details and only recall its structure. SHA1 and
SHA256 take as input a variable number of bytes x0 . . . xn−1
and compute their ﬁxed-sized cryptographic digest as follows:
• append to the input some minimal padding followed by
the input length (in bits) to obtain a sequence of 64-
byte blocks B0, . . . BN−1 (the padding and length prevent
some input-extension attacks);

• iterate a cryptographic compression function f to hash
each of these blocks together with an accumulator (start-
ing from a constant block C) and ﬁnally return h =
f (. . . f (f (C, B0), B1) . . . ..., BN−1).

2) Concatenating ASN.1 ﬁelds: Many X.509 ﬁelds have
variable lengths, making their (veriﬁable) concatenation ex-
pensive. Recall that random access within arrays (using, in
our case, indexes computed from the actual run-time lengths
of ﬁelds in certiﬁcates) would require a potentially expensive
encoding of memory. To improve performance (§VIII-A), we
instead write custom, ‘arithmetic’ code for concatenations.
A direct, na¨ıve implementation of concatenation As an
example, consider concatenating two ﬁelds whose lengths
range over 0..n − 1 and 0..m − 1, respectively. Assume those
ﬁelds are stored in two byte arrays b and c of ﬁxed lengths
m and n, padded with 0s, with the actual length of the ﬁrst
ﬁeld stored in variable (cid:5). Using just comparisons, additions
and multiplications, each byte of the resulting m + n byte
array may be computed as:

xi = (i < n) ∗ bi +

j=0(j = (cid:5)) ∗ ci−(cid:3)

(cid:2)n

Although we may optimize this code, for instance by
sharing sub-expressions, the concatenation still involves at
least (n + 1)m quadratic equations. Worse, as we concatenate
sequences of variable-length ﬁelds, the range of the result is
the sum of the ranges of the inputs, making their concatena-
tions increasingly expensive; this is problematic for ASN.1-
formatted certiﬁcates, which typically include thousands of
bytes and dozens of variable-length ﬁelds. Fortunately, we do
not actually need to concatenate the entire certiﬁcate’s contents
into a single byte array to compute its digest.
Concatenating and Hashing We instead compute hashes
incrementally, using a buffer of bytes to be hashed and
carefully controlling the actual length of that buffer.

To leverage length annotations in the template as we gener-
ate the corresponding C program, we track precise bounds on
the number of bytes available for hashing; this allows us to
reduce the complexity of concatenating the certiﬁcate’s bytes
by emitting calls to SHA’s compression function.

The main insight leading to an efﬁcient implementation
is that, by conditionally applying the compression function
on partial concatenations, we can reduce the range of the

remaining bytes to be hashed in the buffer, and hence the
cost of the next concatenations. For instance, if we know (at
compile-time) that the buffer currently holds between 5 and
123 bytes to be hashed, then by emitting code that hashes one
block if there is at least 64 bytes, we know that the resulting
buffer will hold between 0 and 63 bytes.

Another insight is that, by using Pinocchio’s large words
instead of bytes, we can minimize the number of variables
that represent the hash buffer and the number of branches to
consider for inserting a byte at a variable position.

Next, we explain our buffer implementation. Let x be an
array of B 16-byte words, holding n bytes c0, . . . , cn−1 to be
hashed. We encode x as:

25616i+15−j ∗ cj
∗ cj
256n−j

for i < n/16
for i = n/16
for i > n/16

⎧⎪⎪⎨
⎪⎪⎩

(cid:9)j=16i+15
(cid:9)j=n

j=16i

j=16i

0

x[i] =

and consider two functions that operate on this buffer:

• append requires that the buffer be not full (n < 16B);

it adds one byte to it and increments n;

• reduce requires that the buffer contain at least 64 bytes;
it calls the SHA compression function on the ﬁrst 4
words of the buffer (x[0],x[1],x[2],x[3]) and the
accumulator; it decrements n by 64 and shifts the buffer
contents by 4 words (x[0] = x[4]; ...).

As we compile a template to C code, as illustrated in
Figure 5, we emit a sequence of append and reduce calls
that meet the requirements and preserves the invariant above,
based on a (static) approximation of the range of values n
may take at each step of the program at run time. More
precisely, the template generator uses the variants appendif
and reduceif that accept an additional boolean condition—
the function does nothing if the condition is set to false. We
emit calls to reduce whenever n is at least 64. This shifts
the range, without changing its size. Otherwise, we emit a
conditional reduceif call when the maximal value of n
reaches the capacity of our buffer: this reduces the range by 64,
but incurs the cost of a call to the compression function.

To ﬁnalize the hash, we ‘ﬂush’ the buffer using similar
conditional calls to ensure that n < 55; we then add minimal
padding and the total length; and we return the digest obtained
by calling the compression function one last time.

As a ﬁnal example of ‘arithmetic’ programming, we include
in Figure 9 the optimized code for conditionally appending
one byte to the buffer as we concatenate variable-sized ﬁelds:
if b is 1, then append c to x; otherwise do nothing. Note
that our code uses multiplications by Boolean ﬂags instead of
conditionals (which are usually less efﬁcient when compiling
to arithmetic circuits). It also uses native operations on ﬁeld
elements (Elem) to operate on the buffer’s 128-bit words.

VI. APPLICATION: TLS AUTHENTICATION

Transport Layer Security (TLS) is the most widespread
cryptographic protocol on the Internet. It secures commu-
nications between billions of users and millions of HTTPS

244244

typedef struct { int n, total; Elem x[B];} buffer;

void appendif(buffer* x, int c, int b) {

Elem f, ce, z, t; (...) // local field elements
elem_set_ui(f, b * 255);// conditional shift
elem_set_ui(ce, b * c); // conditional new byte
int high = ((b * x->n) >> 4) & 31;
for (int i = 0; i < B; i++) {

// possibly add the byte to any word i
elem_set_ui(t, (i == high));
elem_mul(z, x->x[i], f);
elem_add(z, z, ce);
elem_mul(z, z, t); // no change when t = 0
elem_add(x->x[i], x->x[i], z); }

x->n += b; x->total += b; }

Fig. 9. Cinderella code for conditionally hashing a byte

websites on a daily basis. It primarily relies on X.509 cer-
tiﬁcates to identify and authenticate both clients and servers.
Server certiﬁcates are pervasive and have been the focus
of many attacks and controversies (§II-B). Client certiﬁcates
are optional, but widely deployed by large organizations and
embedded in several national identity card schemes.

In the context of TLS, the need for a stronger PKI has been
advocated [4, 49, 65], and improvements have been proposed
in a patchwork, ‘opt-in’ fashion. Annoyingly, any proposed
improvement must remain backward compatible with X.509
certiﬁcates issued many years ago.

Communicating Cinderella proofs instead of traditional
X.509 certiﬁcate chains is a radical departure from existing
proposals; we show how it
improves the prover’s privacy
and the veriﬁer’s performance (by exchanging less data and
checking small constant-size proofs), without any change to
current CAs or the TLS standard.

Arguably, Cinderella also helps improves security once
deployed (by embedding additional checks such as OCSP
or Certiﬁcate Transparency [45] and mandating uniform ap-
plication of certiﬁcate policies), without requiring additional
bandwidth or changes at the client.

A. Approach: Pseudo-certiﬁcates

During TLS session establishment, certiﬁcate chains are
treated as opaque byte arrays, encapsulated in speciﬁc hand-
shake messages, and passed to a certiﬁcate manager to be
validated and to extract the public key associated with the
peer. Endpoint authentication is typically achieved by checking
(using the key extracted from the endpoint certiﬁcate) a signa-
ture over some session-speciﬁc parameters (nonces and Difﬁe-
Hellman parameters for server authentication; the transcript of
protocol messages for client authentication).
With Cinderella, one could replace this signature by a proof
of its knowledge, as illustrated in §III. However, such a design
is impractical for two reasons. First, the proof would have
to be computed online by the certiﬁcate holder during the
handshake (as it depends on the session parameters), and
thus, the connection would be signiﬁcantly delayed due to
the computational cost of building the proof. Second, the
handshake message in which the signature is sent would have
to be extended by introducing new cipher suites. To minimize

245245

seq {
tag<0>: const<2L>; # Version
const<0L>; # Serial number
seq { # RSA with SHA256
const<O1.2.840.113549.1.1.11>;
const<null>; };
seq { set { seq { # Issuer
const<O2.5.4.3>;
const<printable:"Cinderella Pseudonym">;
}; }; };
# Validity period
seq { var<date, pseudostart, 13, 13>;

var<date, pseudoend, 13, 13>; };

seq { set { seq { # Subject
const<O2.5.4.3>;
const<printable:"Cinderella Pseudonym">;
}; }; };
seq { seq { # Elliptic curve key on NIST P256 curve
const<O1.2.840.10045.2.1>;
const<O1.2.840.10045.3.1.7>; };
var<bitstring, pseudokey, 66, 66>; };
tag<3>: seq { ... } # Basic mandatory extensions
}

Fig. 10. Template for the signed part of a TLS pseudonym

the disruption to TLS, we opt not to change the protocol, but
rather to extend the associated certiﬁcate libraries.

Instead of proving knowledge of a signature on the protocol
session, we leverage the modularity of X.509 by replacing
existing certiﬁcate chains (owned by clients and servers) with
short-lived pseudo-certiﬁcates. A pseudo-certiﬁcate combines
an ephemeral public key pair with a Cinderella proof that
the original chain has been veriﬁed to correctly connect to
the pseudo-certiﬁcate. This proof can be computed ofﬂine;
then, during the online TLS session establishment, the prover
computes a standard signature using the private portion of
the ephemeral key pair. The validator then checks both the
signature and the Cinderella proof.

In more detail, a pseudo-certiﬁcate carries an ephemeral
public key, a subset of the public attributes from the original
certiﬁcate chain, and a Cinderella proof that the original chain
has been veriﬁed to correctly connect to the pseudo-certiﬁcate.
Within the pseudo-certiﬁcate, the Cinderella proof takes the
place of the RSA or ECDSA signature typically found in a
standard certiﬁcate. Figure 10 shows the concrete template
for a bare-bones pseudo-certiﬁcate in which no attribute from
the original chain is kept. Except for the unusual signature,
pseudo-certiﬁcates are still well-formed X.509. They can be
passed to TLS unchanged and cached in existing certiﬁcate
stores. Their processing is relatively cheap (see §VIII).

Before running TLS, the owner of an endpoint certiﬁcate
can prepare any number of pseudo-certiﬁcates (each associated
with a freshly generated key pair) and compute Cinderella
proofs that each pseudo-certiﬁcate indeed stands for the proper
validation of the chain they replace. For instance, a web server
may generate a fresh, short-lived pseudo-certiﬁcate every day,
or a content provider may generate one pseudo-certiﬁcate for
every server hosting its content for the day.
B. Security Enhancement: Revocation Checking
Certiﬁcate revocation has consistently failed to prevent mis-
use of compromised certiﬁcates (§II-B). Combining Cinderella

seq {

tag<2>: const<octet string:X...>; # KeyHash of responder
var<gen date, producedAt, 15, 15>; # Timestamp
seq { seq { seq {

seq { const<O1.3.14.3.2.26>; const<null>; }; # SHA1 OID
const<octet string: X....>;# Hash of issuer’s subject
const<octet string: X...>; # Hash of issuer’s public key
var<int, ocspserial, 16, 20>; # Queried serial number
}; const<0:"">; # Response status (0 = good)
var<gen date, thisupdate, 15, 15>;
tag<0>: var<gen date, nextupdate, 15, 15>; }; };
tag<1>: # OCSP extensions
seq { seq {

const<O1.3.6.1.5.5.7.48.1.2>; # OCSP nonce
var<octet string, nonce, 18, 18>; }; };

}

Fig. 11. Template for the signed part of an OCSP proof

with OCSP can help optimize revocation checks and hence
make them more widely used. A Cinderella policy can easily
embed the validation of an OCSP proof,
thus saving the
cost for the veriﬁer to fetch one from the CA, using an
additional ASN.1 template to hash and verify. While TLS
already features an extension for the server to attach an
OCSP proof (OCSP stapling), with Cinderella, the server does
not need to send it to the client, thus saving an additional
1 to 3KB of data in the handshake. Figure 11 illustrates
a concrete OCSP template where we assume that both the
OCSP responder certiﬁcate and the issuer of the certiﬁcate to
verify are ﬁxed in advance. The only variables in the OCSP
proof are the timestamps, and the OCSP query nonce. In
practice, CAs may use additional intermediates for their OCSP
responder certiﬁcates; each such intermediary requires its own
template. Besides OCSP, it is possible to verify other X.509
extensions as part of an application’s validation policy. For
instance, Certiﬁcate Transparency [45] offers signed proofs
that a certiﬁcate has been included in a public, closely audited
certiﬁcate log. Such proofs can be easily veriﬁed as part of
an application’s validation policy. More advanced schemes
that assume mutually distrusting auditors of the certiﬁcate
logs [4, 65] can similarly be embedded.

C. Using Cinderella to Validate TLS Server Certiﬁcates

To demonstrate Cinderella’s support for large, complex
application validation policies, we describe the steps we took
to apply Cinderella to the validation policy that existing TLS
clients apply to server certiﬁcate chains.

Building a complete certiﬁcate policy validator involves sev-
eral templates, each of which gets compiled into a certiﬁcate-
veriﬁer function that
loads (as private, prover inputs) the
variable ﬁelds of the template, computes the hash of the
certiﬁcate, and checks its signature. While these template
veriﬁer functions are automatically generated by Cinderella’s
template compiler, the application policy developer still must
still manually ‘chain’ them together and write any application-
speciﬁc checks on their variable ﬁelds (see §III-B).

Below, we summarize the top-level validate function
that a TLS client
typically applies to certiﬁcate chains it
receives from the server (Figure 12 contains more detail).

246246

#include "maincert.c" // Server certificate template
#include "ocsp.c"
#include "pseudo.c"

// OCSP template
// Pseudo-certificate template

// Checks whether the CN field of the subject matches hostname,
// or a SAN entry of type DNS matches hostname
void check_subject(hostname* host, subjectoid* soid,
subjectval* sval, sanentry* san);

int cmp_date(date d1, date d2);
int cmp_serial(serial s1, serial s2); // Compare serial numbers

// Compare dates

void validate(unsigned char* d, date t, bignum pseudokey,

date pstart, date pend)

{

bignum ca_key; bignum end_key; // Public keys (CA & endpoint)
date start; date end; serial sn; // Validity interval; SN
subjectoid soid[MAX_SUBJECT_FIELDS]; // Subject fields (keys)
subjectval sval[MAX_SUBJECT_FIELDS]; // (values)
sanentry san[MAX_SAN_ENTRIES]; // Subject alternative names
// ... other variable fields

// Load top-of-the-chain public key (e.g. root)
load_Modulus("maincert", &ca_key, 0, COMPILE_TIME);

// ... intermediate CA checks go here

// Load private inputs; hash; verify signature with ca_key
verify_maincert(ca_key, &sn, &start, &end, &soid[0],

&sval[0], &end_key, &san[0], /*...*/);

date producedAt; serial ocsp_sn; // OCSP variables ...
load_Modulus("ocsp", &ca_key, 0, COMPILE_TIME); // OCSP CA
verify_ocsp(ca_key, &ocsp_sn, &producedAt, /* ... */);
assert(!cmp_serial(sn, ocsp_sn)); // Check SN in OCSP

// Hash & check signature of pseudo-certificate
// The variables in this template are **verifier** inputs
verify_pseudo(end_key, pstart, pend, pseudokey);

check_subject(d, soid, sval, san);
assert(!cmp_date(producedAt, pstart)); // Check dates
assert(cmp_date(pstart, end));
assert(!(cmp_date(pend, end)+1)); }

// Match domain name

Fig. 12. Top-level validator for TLS clients, without intermediate certiﬁcates.

Cinderella outsources the execution of validate to the
server, so the client only checks a succinct proof.

The validate function involves the following templates:
• one template for the endpoint certiﬁcate we replace, with

additional templates for any intermediate CAs;

• one template for the OCSP proof (Figure 11), with addi-
tional templates for any OCSP intermediate certiﬁcates;

• one template for the pseudo-certiﬁcate (Figure 10).
Given the domain name d that the client expects to connect

to and the current time t, the validator proceeds as follows:
1) Load the (static) public key of the “root” of the chain.
2) Hash and verify all potential intermediates, based on
their templates, and the public key of their parent (either
the root public key for the ﬁrst intermediate, or the
veriﬁed public key returned by the previous intermediate
template veriﬁer function).

3) Hash and verify the endpoint certiﬁcate (returning the

assignment from the variable template ﬁelds).

4) Load the (static) public key of the “root” of the OCSP
chain, unless it is one of the intermediate keys previously
veriﬁed on the main chain.

5) Hash and verify all intermediates from the OCSP chain.
6) Hash and verify the OCSP proof, returning the times-

tamps and serial number it contains.

7) Check that the serial number in the OCSP proof is equal

to the serial number of the endpoint certiﬁcate.

8) Hash and verify the pseudo certiﬁcate, taking as input
the ephemeral key and validity time interval from the
veriﬁer;
the signature is veriﬁed using the endpoint
certiﬁcate’s public key.

9) Check that the veriﬁer’s input domain d either matches
the Common Name ﬁeld of the subject or one of the
Subject Alternative Names entries, taking into
account wildcards, such as *.a.com.

10) Check that the veriﬁer time t is within the validity

intervals of every template.

The above steps are very close to what current browsers
implement, except for the steps already enforced by our
certiﬁcate templates. For instance, for a chain to be valid for
TLS server authentication, a speciﬁc object identiﬁer needs to
appear in the extended key usage extension of all certiﬁcates
in the chain. Extensions like the basic constraints specify the
certiﬁcates that can be used to sign other certiﬁcates and the
maximum length of a chain rooted at a given intermediate.
The improper validation of these extensions have led to critical
attacks (§II-B); in contrast, we encode all these checks in our
certiﬁcate templates, whose conformance with browser valida-
tion policies can be easily tested—indeed, the original motiva-
tion for certiﬁcate templates was to evaluate their conformance
with CA/Browser Forum’s baseline requirements [33].
Delegation As short-lived Cinderella pseudo-certiﬁcates are
used in place of the X.509 chain they represent in TLS, they
can be handed to third parties (such as content delivery net-
work operators) without exposing the corresponding certiﬁcate
and its private key.
D. Security

After applying the extraction techniques from Cinderella’s
general proof of security, the only difference compared with
existing certiﬁcate-chain validation is the additional signature
veriﬁcation introduced by the pseudo-certiﬁcate (Appendix A).
The TLS proof then relies on the security of the signature
scheme used in the pseudo-certiﬁcates.

Cinderella’s zero-knowledge property also implicitly pro-
tects user privacy. The contents of the pseudo-certiﬁcate are
constant, except for the freshly generated public key and the
proof, and they do not contain private information.
VII. APPLICATION: VOTER ANONYMITY

AND ELIGIBILITY IN HELIOS

A. Helios (Review)

Classically, the privacy of users in elections, petitions, and
surveys can be protected in two ways: (1) unlink users’
input from their identities through a process of anonymous
submission; or (2) compute the result from encrypted user
inputs by exploiting homomorphic properties of the encryption
scheme. These approaches are complementary: users may
submit encrypted inputs anonymously.

247247

The popular online voting system Helios [2] follows the
second approach: its public election trail includes a list of
identities and encrypted ballots for all participants. The Helios
speciﬁcation, however, notes that “in some elections, it may
be preferable to never reveal the identity of the voters” and
supports voter aliases for that purpose.1 Such aliases are
used, e.g., in IACR elections. Helios does not support any
mechanism for authorizing anonymous voters to the voting
server. Consequently, even if voter aliases are used over an
anonymous communication system, the voting server is still
able to link submitted ballots to user login credentials.

Helios expects an external mechanism to authenticate voters,
and thus does not provide what Kremer et al. call eligibility
veriﬁability [50]. From the veriﬁcation trail, one cannot pub-
licly check whether a ballot was cast by a legitimate voter.
This enables ballot stufﬁng by the voting server, which may for
instance wait until the end of the election and then inject bal-
lots for all voters who have not participated. The use of voter
aliases as suggested in the Helios speciﬁcation makes the lack
of eligibility veriﬁability even more problematic. Conversely,
assuming voters are equipped with X.509 certiﬁcates and a
trustworthy PKI, Helios may ask voters to sign their ballot,
thereby cryptographically binding voter identities to ballots.
This strengthens veriﬁability, but precludes the use of aliases.

B. Cinderella at the Polling Station

We design and implement a front-end extension of Helios,
providing additional privacy and veriﬁability about who is
actually voting, without affecting the core of the Helios
protocol and the guarantees it already provides. Hence, we
treat Helios ballots as opaque anonymous messages and, for
each election, we ensure that a correct subset of anonymous
ballots is passed to Helios for tallying:

1) Each voter contributes at most one ballot of her choice.
2) Only the election result and the total number of ballots

are disclosed—not the identity of the actual voters.

Relying on Cinderella for access control and ballot authentica-
tion, we achieve both the same level of eligibility veriﬁability
afforded by X.509 certiﬁcates and voter anonymity, even
against fully corrupted election authorities. Neither the Helios
servers nor the election audit trail contain useable information
about who actually voted.

In more detail, relying on an existing X.509 PKI, we assume
each voter is identiﬁed by some unique personal certiﬁcate,
though the certiﬁcate need not be speciﬁc to voting and may
have been issued for some other purpose. Below, we simply
use the certiﬁcate subject as voter identiﬁer; more generally,
we may extract the identiﬁer from other ﬁelds and perform
some ﬁltering, e.g. to check that the voter is at least 18.

With Helios, each election comes with a fresh identiﬁer
(EID) and a list of voters that may take part in the election.
In principle, we could generate a fresh set of Cinderella keys
for each election; Pinocchio, like Helios, supports distributed
key generation [10], which can increase conﬁdence in the

1http://documentation.heliosvoting.org/veriﬁcation-specs/helios-v3-

veriﬁcation-specs

election policy (in particular, if the list of voters is ﬁxed at
compile time). For the sake of generality, we implement a
generic policy for Helios that works for any election, taking
as veriﬁer inputs the EID and list of registered voters. We
conﬁgure Helios voting servers to run in ‘open election’ mode
with ‘voter aliases’: instead of using a ﬁxed list of voters,
the servers freely register new voter aliases (without any a
priori authentication) and record their votes, each with a
corresponding Cinderella proof, until the end of the election.
Given the election identiﬁer, voter list, and a recorded triple
of an alias (N), a ballot (B), and a proof (π), everyone can
efﬁciently verify π to conﬁrm that B is a ballot signed by some
authorized voter for the election, and that N is that voter’s
unique alias for the election. Typically, the voting server will
verify π before recording the vote, and an auditor will later
verify the entire election log. Hence, although N and π do
not reveal the voter’s identity, multiple valid ballots from the
same voter can be detected and eliminated before the normal
Helios vote tallying begins.

We now detail the voting process and the meaning of its
proof. Each voter computes her voter alias (N) for the election,
prepares a ballot (B), produces a ballot signature (σ), and
generates a Cinderella proof of knowledge π of both her
certiﬁcate and the signature σ such that

1) the certiﬁcate subject (id) appears in the list of autho-

rized voters for the election (voters);

2) σ is a valid signature on B with the certiﬁcate key (vk);
3) N is the result of a (ﬁxed) function of the certiﬁcate key

and the election identiﬁer (EID).

The voter then anonymously contacts a Helios voting server
for the election to register the alias N and cast her vote B
with additional data π.

The third proof requirement is the most challenging, as we
need N to be unique to each voter and each election (to prevent
multiple voting) and to preserve the anonymity of the voter.
If the signing key is embedded into a smartcard, we cannot
simply use a secure hash of that secret. Instead, using the
smartcard’s usual API and the fact that PKCS#1 signing is
deterministic, we ask for a signature on a reserved constant,
e.g., "Helios Seed", and use the resulting signature as a
unique, unpredictable secret for the certiﬁcate’s owner. Finally,
we use that secret as the key of a pseudo-random function
applied to the election description (including its identiﬁer and
voter list) to derive the unique alias N. Both the signature and
the derivation of N are veriﬁable in zero-knowledge.

C. Implementation & Security Analysis

Figure 13 provides an overview of our top-level Helios
veriﬁer, using a certiﬁcate template for Estonian ID cards. In
Appendix A-C, we model our Helios extension as a linkable
ring signature scheme [53, 57, 66] and prove its security.

VIII. PERFORMANCE EVALUATION

To evaluate Cinderella’s practicality, we measured its per-
formance on micro- and macro-benchmarks. All experiments
were performed on a Dell Precision 5810 workstation powered

248248

#include "estonia.c" // Compiled template
void validate(char* EID, subject* IDs, hash* N, hash* B)
{

pubkey ipk0, vk; subject id; signature sig0, sig1;
load_Modulus(&ipk0, COMPILE_TIME); // Static
verify_estonia(&ipk0, &vk, &id /* ... */);
load_Signature(&sig0, RUN_TIME); // Prover input
PKCSVerify(&vk, "Helios Seed", sig0);
char x[276]; concat(pseudo, sig0.v, eid);
zeroAssert(cmp_hash(N, sha1(pseudo)));
filter(&id, IDs); // Checks that id is in IDs
load_Signature(&sig1, RUN_TIME); // Prover input
ballot_concat(x, "Helios Ballot", EID, IDs, B);
PKCSVerify(&vk, x, sig1);

}

Fig. 13. Fragment of the concrete top-level veriﬁer code for Helios

by an Intel Xeon E5-1620v3 3.5 GHz CPU with 16 GB of
RAM and running Windows 10.

When reporting key generation times, we include compila-
tion from C. For the veriﬁcation times, we omit the overhead
of loading and initializing the cryptographic engine, assuming
that a Pinocchio veriﬁer can be queried as a local service. In
all cases, we measure single-threaded execution time, although
we note that almost all steps are embarrassingly parallel.

Similar to prior work [59],

the largest determinant of
our key and proof generation performance is the number of
quadratic equations produced when compiling our C programs.
Evaluation keys use 320 bytes per equation; veriﬁcation keys
are much smaller, roughly the size of their public I/Os.

A. Micro-benchmarks

To better understand and predict Cinderella’s costs, we
measure the major components of certiﬁcate-chain validation:
RSA signature veriﬁcation (§IV), hashing (§V), and certiﬁcate
generation from a template (§V).

RSA Key Equations KeyGen
47.4 s
Fixed
Variable
47.4 s

164,826
180,774

ProofGen Verify
8 ms
8 ms

26.6 s
31.0 s

Fig. 14. RSA signature veriﬁcation when we know the public key in advance
(Fixed) and when we learn it online (Variable).

RSA Signature Veriﬁcation The cost of generating a proof of
signature veriﬁcation depends on whether, when we compile
and generate Cinderella keys, we know the RSA public key
that will be used. If we do, e.g., when verifying an RSA
signature using the public key of a root certiﬁcate, then all
of the values associated with that key are constants and
can be folded into Cinderella’s key. If we only learn the
RSA key at run time, e.g., when verifying an intermediate
certiﬁcate, then the prover must perform additional proof work
to incorporate it. In particular, such keys are represented as
bytes in the certiﬁcate and must be converted to our high-
precision arithmetic representation. We account for this extra
step in the run-time signature veriﬁcation costs.

Figure 14 summarizes our results for the two conditions
using 2048-bit keys. During proof generation, Cinderella pro-
duces 58 KB of data representing the computed quotients,
residues and carries.

SHA1
SHA256

Equations/byte KeyGen/byte
377 ms / B
112 ms / B

254.9 / B
541.4 / B

ProofGen/byte
116 ms / B
84 ms / B

Fig. 15. Costs to verify hashing, reported per byte hashed.

Hashing Figure 15 reports the costs of verifying the com-
putation of the SHA1 and SHA256 hash functions, per input
byte (unknown at key generation). Overall, each block (64
bytes) of SHA256 requires around 34.6K equations. Perhaps
surprisingly, SHA256 performs better per byte than SHA1.
The main distinction is that while SHA256 has a larger internal
state, it only performs 64 iterations vs. SHA1’s 80.

Since our complex applications (involving multiple inter-
mediate CAs and OCSP proofs) need to hash 1–3 KB of data,
in our macro-benchmarks below, we ﬁnd that the total cost
of hashing dominates the cost of formatting, RSA signature
validation, and application-speciﬁc policies.

Complexity Eqns/byte KeyGen/byte
8.0 ms / B
15.8 ms / B
17.9 ms / B
19.0 ms / B

17.0 / B
42.8 / B
51.4 / B
61.3 / B

0 B
100 B
200 B
300 B

ProofGen/byte
3.8 ms / B
9.4 ms / B
9.5 ms / B
10.9 ms / B

Fig. 16. ASN.1 formatting costs per byte as a function of the template’s
complexity (size difference between the largest and smallest certiﬁcate).

ASN.1 Formatting The cost of ASN.1 formatting is highly
dependent of the source template. In particular, it depends
on the number of variable ﬁelds in the template, and on the
difference between the upper and lower length bounds of these
ﬁelds. As a metric, we deﬁne a template’s complexity to be
the difference between the maximum and minimum sizes of
certiﬁcates that match it. In our experiment, starting from a
fully constant (0 complexity) template for a typical 960-byte
TLS server certiﬁcate, we increase its complexity by making
more ﬁelds variable and by widening the range of the lengths
of the variable ﬁelds until we reach a highly generic template.
Figure 16 reports the results of this experiment for different
complexities. The generated equations, key generation time
and proof generation times are normalized with respect to the
maximum size of a certiﬁcate that ﬁts the template; hence, the
table reports per-byte values.

While equations per byte increases with template complex-
ity, note that even for relatively generic templates (allowing
a total difference of 300 bytes between the smallest and
largest certiﬁcate it covers), the cost of formatting is still only
11% of the cost of hashing. Hence, the maximum certiﬁcate
size (and the total number of templates) are by far the most
important factors for the prover. Also note that formatting
using our custom concatenation routines use approximately
40-60 equations per byte, whereas generic memory techniques

249249

Estonian EID
S/MIME (SHA256)
TLS server (SHA1)
TLS server (SHA256)
OCSP proof (SHA1)
OCSP proof (SHA256)
Pseudo-cert (SHA256)

Equations KeyGen ProofGen Verify
8 ms
8 ms
8 ms
8 ms
8 ms
8 ms
8 ms

530,389
967,740
547,940
858,855
267,135
357,878
367,488

160 s
152 s
165 s
137 s
60 s
58 s
61 s

480 s
252 s
496 s
219 s
174 s
85 s
84 s

Fig. 17. Overall cost (formatting, hashing, signature veriﬁcation) of certiﬁcate
validation for various templates

(§II-A) would require approximately 153 equations per byte
for a 2048-byte certiﬁcate [68, Figure 5].
Certiﬁcate Validation Combining all of the steps above,
Figure 17 summarizes the overall cost of certiﬁcate validation
for various types of templates. The reported costs include
ASN.1 formatting, hashing, and RSA signature validation
(assuming the signer’s key is not known at compile time).
Our tests were conducted on valid X.509 certiﬁcates obtained
from various CAs, as detailed below.

For client credentials, we use a template based on a public
test certiﬁcate from the Estonian ID system. This template
is moderately constrained but also quite large (with a length
range of 977 to 1130 bytes). Its main variable ﬁelds are in
the subject (name, surname, and social security number). We
also build a client certiﬁcate template based on the StartCom
authority, intended to be used for S/MIME and TLS client
authentication. This is also a rather large template (covering
certiﬁcates from 1223 to 1399 bytes long) signed using a
SHA256 hash, resulting in a large number of equations.

For server credentials, we use a TLS template based on the
AlphaSSL authority. It is a relatively constrained template,
allowing certiﬁcates sizes from 856 to 1128 bytes. The main
variable ﬁelds of the template are the subject (which can
include from 1 to 3 variable length ﬁelds) and the subject
alternative names. We also evaluate the SHA256 version of
this template, which is quite similar.

Lastly, we look at the OCSP proofs returned by the Al-
phaSSL CA and the pseudo-certiﬁcates we use for TLS. As
these are both short and constant-length, their templates are
signiﬁcantly faster to check than other certiﬁcates.

B. Macro-benchmarks
Figure 18 summarizes our evaluation of the complete cer-
tiﬁcate validation policies for our applications in §VI and §VII.
1) TLS: Recall from §VI that our TLS application involves
many templates: one for the endpoint certiﬁcate, one for the
OCSP certiﬁcate, one for the pseudo-certiﬁcate, and optionally,
several more for any intermediates included in the chain. Fur-
thermore, the TLS policy also performs hostname validation
and expiration checks.

According to the 2010 Qualys SSL survey [60], based on
a sample of 600,000 trusted chains, 44% of sites use one
intermediate CA certiﬁcate, 55% use two, while the remaining
1% use even longer chains. Thus, in our experiments, we vary
the number of intermediate CAs from 0–2.

Application
TLS SHA256
TLS SHA256
TLS SHA256
TLS SHA1
Helios

2
1
0
0
0

CAs Equations KeyGen ProofGen Verify
9 ms
9 ms
9 ms
9 ms
8 ms

3,033,071
2,314,811
1,588,340
1,095,386
434,177

697 s
530 s
411 s
1,207 s
196 s

531 s
421 s
266 s
328 s
90 s

Fig. 18. Evaluation of complete application policies with varying numbers of
intermediate CAs.

As shown in Figure 18, for our most general policy (with
two intermediate CAs, using SHA256), it takes the prover nine
minutes (ofﬂine) to create a single pseudo-certiﬁcate. On the
other hand, the veriﬁer (e.g. a web browser) can verify the
Cinderella proof contained in the pseudo-certiﬁcate in 9 ms.
The comparison of TLS handshake performance using the
pseudo-certiﬁcate vs. the original chain depends on the client
and server conﬁguration for the baseline. For instance, ap-
plying OCSP with Cinderella removes the bandwidth and
online computational overhead of OCSP stapling. In terms of
raw signature performance, the cost of natively hashing and
verifying the signatures in the certiﬁcate chain is comparable
to the time to verify Cinderella’s proof. In terms of bandwidth,
typical RSA certiﬁcate chains with one intermediate take 2 to
3 KB, with one additional KB per extra intermediate. Even
ECDSA certiﬁcates currently issued by CAs are typically
over 700 bytes long. Pseudo-certiﬁcates, in contrast, are a
ﬂat 564 bytes. Thus, Cinderella improves on bandwidth by
1.2–5.4× even for short chains;
this gain scales with the
number of additional intermediates. The overall performance
impact of this gain depends on the application protocol: in
HTTPS, request pipelining and session resumption amortize
these savings.

2) Helios: For our Helios application, we use the Estonian
identity card template with no further intermediates. Although
an OCSP service is provided, we do not believe checking
revocation as part of the Cinderella policy is useful, as we sup-
port a per-election registered voter list. The voter pseudonym
computation and ballot signature are otherwise implemented
as described in §VII. We use as a voter identiﬁer the social
security number found in the subject of the certiﬁcate.

Since our policy only needs to verify two RSA signatures,
the computational costs for Helios (listed in Figure 18) are
much smaller than for TLS: it only takes a minute and a half
to build a proof of the ballot’s signature.

Although our tests were performed on small voter lists, our
approach would scale up to lists with millions of voters repre-
sented as a Merkle tree using an algebraic hash function [16],
at a negligible cost compared with the two RSA signature
veriﬁcations.

Tallying an election now requires the Helios servers (or
anyone who wishes to verify the election) to check all Cin-
derella proofs attached to all the ballots. At 8 ms per proof
veriﬁcation, we are able to verify over 120 ballots per second,
which greatly exceeds the tallying capacity of Helios (reported
to be around 7 ballots per second just for decryption [2]).

IX. RELATED WORK

We refer to §II-A for related work on general-purpose veri-
ﬁable computation. Although recent work provides substantial
cryptographic implementations and claims ‘near-practicality’,
few real-world applications have been attempted. The most no-
table exception is privacy-enhanced variants of Bitcoin [7, 31].
Several papers also evaluate simple MapReduce and data
processing applications, but proof-generation overhead is a
signiﬁcant bottleneck [3, 16, 27, 30].
We refer to §II-B for related work on X.509 certiﬁcates
and PKI. The use of zero-knowledge proofs in public-key
infrastructures was pioneered by Chaum [24] and Brands [15].
Wachsmann et al. [67] extend TLS with anonymous client
authentication by integrating an anonymous-credential-based
signature scheme directly into TLS using a custom extension.
Camenisch et al. [21] extend federated identity management
protocols with anonymous credentials based on [19]. Our
approach differs from classic anonymous credentials and other
custom PKI elaborations [4, 49, 65], as we do not rely on the
cooperation of CAs to deploy Cinderella, and we only change
the usage of plain, existing certiﬁcates.

Regarding voting protocols, Kremer et al. [50] distinguish
between individual, universal, and eligibility veriﬁability and
note that Helios 2.0 does not guarantee eligibility veriﬁability
and is vulnerable to ballot stufﬁng by dishonest administrators.
Cortier et al. [29] address this problem by adapting the Helios
protocol. They envision an additional registration authority that
generates signature key pairs for users that then sign their
ballots. This corresponds to using X.509 certiﬁcates directly
to sign the ballot and does not allow for voter anonymity.
Springall et al. [62] analyzed the security of Estonia’s online
elections and noted their lack of end-to-end veriﬁability.

X. CONCLUSION

We propose, implement, apply, and evaluate a radically
different use of existing X.509 certiﬁcates and infrastructure.
Taking advantage of recent advances in cryptographically ver-
iﬁable computation, we outsource the enforcement of ﬂexible
X.509 certiﬁcate validation policies from certiﬁcate veriﬁers to
certiﬁcate owners, thereby simplifying the task of the veriﬁer
and improving the privacy of the owner. Our prototype imple-
mentation supports complex policies involving multiple certiﬁ-
cates and application checks. It includes a template compiler
and carefully-crafted libraries to ﬁt standard-compliant X.509
processing within the constraints of veriﬁable computation.

Our applications to TLS and electronic voting show ex-
cellent performance for the veriﬁer and substantial overhead
for the prover. Cinderella is applicable when policies can
be evaluated and turned into proofs ofﬂine, or when the
burden of producing a proof can be amortized by many faster
veriﬁcations. It is not a full replacement for X.509, but it
already enables the deployment of new, interesting policies,
and offers a graceful integration of old and new cryptography.

ACKNOWLEDGEMENTS

The authors thank the anonymous reviewers for insightful

comments, and Joseph Bonneau for shepherding the paper.

250250

REFERENCES

[1] M. Abe, G. Fuchsbauer, J. Groth, K. Haralambiev, and
M. Ohkubo. Structure-preserving signatures and commitments
to group elements. In Proc. of CRYPTO, 2010.

[2] B. Adida. Helios: Web-based open-audit voting.

In Proc. of

USENIX Security, 2008.

[3] M. Backes, D. Fiore, and R. M. Reischuk. Nearly practical and
privacy-preserving proofs on authenticated data. In Proc. of the
IEEE Symposium on Security and Privacy, May 2015.

[4] D. Basin, C. Cremers, T. H.-J. Kim, A. Perrig, R. Sasse, and
P. Szalachowski. ARPKI: Attack resilient public-key infrastruc-
ture. In Proc. of ACM CCS, 2014.

[5] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. Fast
reductions from RAMs to delegatable succinct constraint sat-
isfaction problems.
In Innovations in Theoretical Computer
Science (ITCS), Jan. 2013.

[6] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza.
SNARKs for C: Verifying program executions succinctly and in
zero knowledge. In Proc. of CRYPTO, 2013.

[7] E. Ben-Sasson, A. Chiesa, C. Garman, M. Green, I. Miers,
E. Tromer, and M. Virza. Zerocash: Decentralized anonymous
payments from Bitcoin.
In Proc. of the IEEE Symposium on
Security and Privacy, 2014.

[8] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Scalable
In Proc. of

zero knowledge via cycles of elliptic curves.
CRYPTO, 2014.

[9] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Succinct
non-interactive zero knowledge for a von Neumann architecture.
In Proc. of USENIX Security, 2014.

[10] E. Ben-Sasson, A. Chiesa, M. Green, E. Tromer, and M. Virza.
Secure sampling of public parameters for succinct zero knowl-
edge proofs. In Proc. of the IEEE Symposium on Security and
Privacy, May 2015.

[11] K. Bhargavan, C. Fournet, M. Kohlweiss, A. Pironti, P. Strub,
and S. Z. B´eguelin. Proving the TLS handshake secure (as it
is). In Proc. of CRYPTO, 2014.

[12] N. Bitansky, R. Canetti, O. Paneth, and A. Rosen. On the
In Proc. of ACM

existence of extractable one-way functions.
Symposium on the Theory of Computing (STOC), 2014.

[13] M. Blum, W. Evans, P. Gemmell, S. Kannan, and M. Naor.
Checking the correctness of memories. In IEEE Symposium on
Foundations of Computer Science (FOCS), 1991.

[14] M. Blum, A. D. Santis, S. Micali, and G. Persiano. Noninter-

active zero-knowledge. SIAM J. on Computing, 20(6), 1991.

[15] S. Brands. Rethinking Public Key Infrastructures and Digital

Certiﬁcates. MIT Press, 2000.

[16] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and
M. Walﬁsh. Verifying computations with state. In Proc. of the
ACM SOSP, 2013.

[17] C. Brubaker, S. Jana, B. Ray, S. Khurshid, and V. Shmatikov.
Using Frankencerts for automated adversarial testing of certiﬁ-
cate validation in SSL/TLS implementations.
In Proc. of the
IEEE Symposium on Security and Privacy, 2014.

[18] CA/Browser Forum. Baseline requirements for the issuance and

management of policy-trusted certiﬁcates, v.1.1.5.

[19] J. Camenisch and A. Lysyanskaya. Efﬁcient non-transferable
system with optional

anonymous multi-show credential
anonymity revocation. In Proc. of EUROCRYPT, 2001.

[20] J. Camenisch and A. Lysyanskaya. A signature scheme with
efﬁcient protocols. In Proc. of the Conference on Security in
Communication Networks (SCN), 2002.

[21] J. Camenisch, T. Groß, and D. Sommer. Enhancing privacy of
federated identity management protocols: anonymous creden-
tials in ws-security. In Proc. of the ACM Workshop on Privacy
in the Electronic Society (WPES), 2006.

[22] J. Camenisch, S. M¨odersheim, G. Neven, F. Preiss, and D. Som-
mer. A card requirements language enabling privacy-preserving

251251

[24] D. Chaum. Security without identiﬁcation: Transaction systems
to make big brother obsolete. Commun. ACM, 28(10):1030–
1044, 1985.

[25] D. Chaum and E. van Heyst. Group signatures.

In Proc. of

EUROCRYPT, 1991.

access control.
Control Models and Technologies (SACMAT), 2010.

In Proc. of the ACM Symposium on Access

[23] Canadian Institute of Chartered Accountants. WebTrust for

certiﬁcation authorities.

[26] Y. Chen and Z. Su. Guided differential testing of certiﬁcate
validation in SSL/TLS implementations. In Proc. of the ACM
Symposium Foundations of Software Engineering, 2015.

[27] A. Chiesa, E. Tromer, and M. Virza. Cluster computing in zero

knowledge. In Proc. of EUROCRYPT, Apr. 2015.

[28] J. Clark and P. van Oorschot. SoK: SSL and HTTPS: Re-
visiting past challenges and evaluating certiﬁcate trust model
enhancements.
In Proc. of the IEEE Symposium on Security
and Privacy, May 2013.

[29] V. Cortier, D. Galindo, S. Glondu, and M. Izabach`ene. Election
veriﬁability for Helios under weaker trust assumptions. In Proc.
of ESORICS, 2014.

[30] C. Costello, C. Fournet, J. Howell, M. Kohlweiss, B. Kreuter,
M. Naehrig, B. Parno, and S. Zahur. Geppetto: Versatile
veriﬁable computation.
In Proc. of the IEEE Symposium on
Security and Privacy, May 2015.

[31] G. Danezis, C. Fournet, M. Kohlweiss, and B. Parno. Pinocchio
coin: Building Zerocoin from a succinct pairing-based proof
system. In ACM PETShop, 2013.

[32] A. Delignat-Lavaud and K. Bhargavan. Network-based origin
In Proc. of

confusion attacks against HTTPS virtual hosting.
the ACM Conference on World Wide Web (WWW), 2015.

[33] A. Delignat-Lavaud, M. Abadi, A. Birrell, I. Mironov, T. Wob-
ber, and Y. Xie. Web PKI: closing the gap between guidelines
and practices. In Proc. of the ISOC NDSS, 2014.

[34] C. Diaz, E. Kosta, H. Dekeyser, M. Kohlweiss, and G. Nigusse.
Privacy preserving electronic petitions. Identity in the Informa-
tion Society, 1(1):203–209, 2009.

[35] Z. Durumeric, J. Kasten, M. Bailey, and J. A. Halderman.
Analysis of the HTTPS certiﬁcate ecosystem. In Proc. of ACM
Internet Measurement Conference (IMC), 2013.

[36] Electronic Frontier Foundation. The EFF SSL Observatory.

https://www.eff.org/observatory, 2010.

[37] European Telecommunications Standards Institute. Policy re-
quirements for certiﬁcation authorities issuing public key cer-
tiﬁcates.

[38] C. Evans, C. Palmer, and R. Sleevi.

Public key pinning

extension for HTTP. Technical report, 2015.

[39] S. Fahl, M. Harbach, T. Muders, L. Baumg¨artner, B. Freisleben,
and M. Smith. Why Eve and Mallory love Android: An analysis
of Android SSL (in)security. In Proc. of ACM Conference on
Computer and Communications Security, 2012.

[40] D. Fiore and A. Nitulescu. On the (in)security of SNARKs
in the presence of oracles. Cryptology ePrint Archive, Report
2016/112, Feb. 2016.

[41] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veriﬁable
computing: Outsourcing computation to untrusted workers. In
Proc. of CRYPTO, 2010.

[42] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic
span programs and succinct NIZKs without PCPs. In Proc. of
EUROCRYPT, 2013.

[43] C. Gentry and D. Wichs. Separating succinct non-interactive
In Proc. of ACM

arguments from all falsiﬁable assumptions.
Symposium on the Theory of Computing (STOC), 2011.

[44] M. Georgiev, S. Iyengar, S. Jana, R. Anubhai, D. Boneh, and
V. Shmatikov. The most dangerous code in the world: Validating
SSL certiﬁcates in non-browser software.
In Proc. of ACM
Conference on Computer and Communications Security, 2012.
[45] Google. Certiﬁcate transparency. https://sites.google.com/site/

certiﬁcatetransparency/.

[46] J. Groth and A. Sahai. Efﬁcient non-interactive proof systems
for bilinear groups. SIAM Journal on Computing, 41(5), 2012.
[47] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman.
Mining your Ps and Qs: Detection of widespread weak keys in
network devices. In Proceedings of USENIX Security, 2012.

[48] J. Kasten, E. Wustrow, and J. A. Halderman. Cage: Taming
certiﬁcate authorities by inferring restricted scopes. In Financial
Cryptography and Data Security. 2013.

[49] T. H.-J. Kim, L.-S. Huang, A. Perrig, C. Jackson, and V. Gligor.
Transparent Key Integrity (TKI): A Proposal for a Public-Key
Validation Infrastructure. Technical Report CMU-CyLab-12-
016, Carnegie Mellon University, July 2012.

[50] S. Kremer, M. Ryan, and B. Smyth. Election veriﬁability in

electronic voting protocols. In Proc. of ESORICS, 2010.

[51] A. Langley. Revocation still doesn’t work.

https://www.
imperialviolet.org/2014/04/29/revocationagain.html, Apr. 2014.
[52] J. Liang, J. Jiang, H. Duan, K. Li, T. Wan, and J. Wu. When
HTTPS meets CDN: A case of authentication in delegated
service.
In Proc. of the IEEE Symposium on Security and
Privacy, 2014.

[53] J. K. Liu, V. K. Wei, and D. S. Wong. Linkable spontaneous
anonymous group signature for ad hoc groups. In Proc. of the
Australasian Conference on Information Security and Privacy
(ACISP), 2004.

[54] Y. Liu, W. Tome, L. Zhang, D. R. Choffnes, D. Levin, B. M.
Maggs, A. Mislove, A. Schulman, and C. Wilson. An end-to-
end measurement of certiﬁcate revocation in the web’s PKI. In
Proc. of the ACM Internet Measurement Conference, 2015.

[55] M. Marlinspike. More tricks for defeating SSL in practice.

Black Hat USA, 2009.

[56] R. C. Merkle. A certiﬁed digital signature. In CRYPTO, 1989.
[57] T. Nakanishi, T. Fujiwara, and W. H. A linkable group signature
and its application to secret voting. Transactions of Information
Processing Society of Japan, 40(7), 1999.

[58] Netcraft. SSL survey. http://www.netcraft.com/internet-data-

mining/ssl-survey/, May 2013.

[59] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio:
Nearly practical veriﬁable computation. In Proc. of the IEEE
Symposium on Security and Privacy, May 2013.

[60] I. Ristic. Internet SSL survey. Black Hat USA, 3, 2010.
[61] R. L. Rivest, A. Shamir, and Y. Tauman. How to leak a secret:
Theory and applications of ring signatures.
In Theoretical
Computer Science, Essays in Memory of Shimon Even, 2006.
[62] D. Springall, T. Finkenauer, Z. Durumeric, J. Kitcat, H. Hursti,
M. MacAlpine, and J. A. Halderman. Security analysis of the
Estonian Internet voting system. In Proc. of ACM Conference
on Computer and Communications Security, Nov. 2014.

[63] E. Stark, L.-S. Huang, D. Israni, C. Jackson, and D. Boneh. The
case for prefetching and prevalidating TLS server certiﬁcates.
In Proc. of the ISOC NDSS, 2012.

[64] M. Stevens, A. Sotirov, J. Appelbaum, A. K. Lenstra, D. Molnar,
D. A. Osvik, and B. de Weger. Short chosen-preﬁx collisions
for MD5 and the creation of a rogue CA certiﬁcate. In Proc.
of CRYPTO, 2009.

[65] P. Szalachowski, S. Matsumoto, and A. Perrig. PoliCert: Secure
and ﬂexible TLS certiﬁcate management.
In Proc. of ACM
Conference on Computer and Communications Security, 2014.
[66] P. P. Tsang and V. K. Wei. Short linkable ring signatures for e-
voting, e-cash and attestation. In Information Security Practice
and Experience Conference (ISPEC), 2005.

[67] C. Wachsmann, L. Chen, K. Dietrich, H. L¨ohr, A. Sadeghi, and
J. Winter. Lightweight anonymous authentication with TLS and
DAA for embedded mobile devices.
In Information Security
Conference (ISC), 2010.

[68] R. S. Wahby, S. Setty, Z. Ren, A. J. Blumberg, and M. Wal-
ﬁsh. Efﬁcient RAM and control ﬂow in veriﬁable outsourced
computation. In Proc. of the ISOC NDSS, Feb. 2015.

[69] X. Wang, D. Feng, X. Lai, and H. Yu. Collisions for hash
functions MD4, MD5, HAVAL-128 and RIPEMD. Cryptology
ePrint Archive, Report 2004/199, 2004. http://eprint.iacr.org/.
[70] S. Zahur and D. Evans. Circuit structures for improving
efﬁciency of security and privacy tools. In Proc. of the IEEE
Symposium on Security and Privacy, May 2013.

APPENDIX A

PROOFS OF SECURITY

In this appendix we explain our cryptographic security
arguments for the Cinderella protocol transformation and its
applications to S/MIME, TLS, and Helios. For Helios we also
express our notion of security as linkable ring signatures.

and randomness r.

First, we restate knowledge soundness of proofs-of-
knowledge in a style more amenable to splitting a larger
system into those parts that rely on veriﬁable computations
and those that do not.
• The adversary consists of two parts A1 and A2. A1
runs on input 1λ before KeyGen and generates F and
auxiliary input z.
• Then KeyGen runs, and A2 is passed EKF , V KF , z,
A proof system is knowledge-sound if for every benign A1
and every PPT A2 that outputs a verifying y, πy with some
probability, there exists an extractor E that when run on the
same input as A2, including r, produces u, w such that y =
F (u, w) with almost the same probability. The randomness is
taken over the choices of A1, KeyGen, and r.
The benign restriction arises from the possibility of A1
providing an obfuscator as part of z that creates a proof from
which E cannot extract [12].

The auxiliary input z may for instance contain the signatures
of a PKI. It, together with its benign restriction, may however
not always be sufﬁcient in settings in which certiﬁcates and
signatures are generated on the ﬂy and the adversary A2 has
access to a signing oracle. This setting was recently analyzed
by Fiore and Nitulescu [40] who introduced the notion of O-
SNARKs, which allow us to assume the existence of extractors
even against more powerful adversaries that have access to
oracles O. In terms of the deﬁnitions above,
this means
that adversary A2 is given access to signing oracles O. We
conjecture that Pinocchio [59] is an O-SNARK with signing
oracles if the knowledge assumption underlying Pinocchio
holds against adversaries with access to oracles O.
A. Security of Cinderella Generic: Exemplary for S/MIME

Our general approach is to prove that Cinderella, when
employed in a system X, is (almost) as secure as system X in
which the certiﬁcate-chain validation is performed at the point
of signature veriﬁcation.
Cryptographically, the argument relies on O-SNARK knowl-
edge soundness, since emails can be signed after Cinderella
key generation. Alternatively, we may modify our scheme to
communicate both the signature, the veriﬁcation modulus, and
a proof validating the chain for this modulus.

We refer to the system in which Cinderella is used to
extend X as ˜X. In the ﬁrst step of the proof, we split the

252252

system ˜X into four parts: the part A1 of the system that is
executed before the generation of Pinocchio keys; the signing
authorities O that provide certiﬁcates and signatures generated
after the generation of Pinocchio keys; the adversary A2 that
generates the proof π; and the veriﬁer that veriﬁes proofs.
For every pair (A1,A2), we then consider a different
experiment in which we make use of the extractor E which
exists given the O-SNARK knowledge soundness. In this
experiment, we abort whenever E fails to extract inputs such
that validate succeeds but the proof veriﬁes. The difference
between the success probabilities of (A1,A2) in the original
experiment and the new experiment is bounded by the O-
SNARK’s knowledge soundness.
We are now in a position to reduce the security of ˜X to the
security of X. We assume that part A1 executed before the
generation of Pinocchio keys and that the signing authorities O
are unchanged. We deﬁne the adversary A(cid:2) to include the
generation of Pinocchio keys, as well as algorithms A2 and E.
A(cid:2) also continues to query O. Instead of outputting the proof
π, A(cid:2) outputs valid inputs for validate which break the
security of X whenever they break the security of ˜X.

We conjecture that

the security of S/MIME where the
veriﬁer runs the validate function reduces to INT-CMA
security for PKCS#1 signatures.
B. Security of Cinderella for TLS

The security argument for TLS follows the generic argu-
ment, except that we have to consider the additional signature
veriﬁcation introduced by the pseudo-certiﬁcate.
We can thus apply the generic security argument to reduce
the security of TLS with Cinderella to a system X(cid:2)
in
which pseudo-certiﬁcates are veriﬁed locally by the veriﬁer.
It remains to be shown that this adapted system, which now
no longer involves SNARKs is secure. Because of the addition
of the pseudo-certiﬁcate and its signature veriﬁcation step, any
security proof for the TLS protocol and its PKI would need
to be extended. As pseudo-certiﬁcates are used only once, or
at most brieﬂy and for a speciﬁc purpose, we argue that such
an extension of the certiﬁcate chain, although non-standard,
can be soundly reduced to the INT-CMA security of PKCS#1
signatures. Most existing security proofs for TLS (e.g., [11])
assume the PKI provides honest keys and are thus unaffected
by this change. The formal soundness of the X509 PKI as
used by TLS, however, is much in doubt; to our knowledge
no realistic end-to-end formal treatment has been attempted.
C. Security of Cinderella for Helios

In addition to the O-SNARK knowledge soundness of
Pinocchio, we will need an additional assumption on the
pseudo-randomness of hashed PKCS#1 signatures. Consider
the following game.

Deﬁnition 1 (Hash Pseudo-randomness): A signature
scheme PKCSGen, PKCSSign, PKCSVerify is hash pseudo-
random if for all probabilistic polynomial time adversaries A,
we have

where

• PKCSSign(m) calls PKCSSign(sk, m) if m does not start

U (ipk, id) ↔ Reg

with the preﬁx "Helios Seed".
• F(EID) returns, depending on b, either the result of
calling H(PKCSSign(sk, "Helios Seed"||EID)) or a
random function with the same input and output domains.
We model our e-voting extension as a linkable ring signa-
ture scheme [53, 57, 66]. For each election, the authorized
voters can sign anonymously once. Subsequent signatures are
linkable to the same signer and can thus be ﬁltered out. Our
scheme has 4 algorithms and models legacy key usage:
• (ipk, isk) ← Setup(1λ). Generates public parameters
ipk available to all users and a private issuer key isk.
• usk ← Reg

I (isk, id). Generates and
registers a user signing key for identiﬁer id. For honest
registration, we write usk ← Reg(ipk, isk, id).
• (π, N ) ← Sign(usk, EID, IDs, B). Signs the message
B with respect to ring (EID, IDs) and returns signature
π. EID is the ring identiﬁer and corresponds to the
election identiﬁer in our election setting. IDs is the set
of identities allowed to sign, sometimes called the ring.
B is the message to be signed, in our case the ballot. N
is a unique, pseudo-random pseudonym computed from
EID and usk. It makes repeated signatures linkable while
protecting the signer’s identity.
• {0, 1} ← Verify(ipk, EID, IDs, B, π, N ). Veriﬁes the
• σ ← Legacy(usk, m). Generates a legacy signature.
We discuss how these algorithms are employed in our Helios
front-end extension. Setup is run once the Cinderella voting
application policy is agreed on. The keys ipk, isk include
the Pinocchio veriﬁcation and evaluation keys, as well as the
certiﬁcate issuer’s public and private keys respectively. One
could split Setup into two algorithms to isolate the legacy
X.509 keys, or reﬁne it with an explicit X.509 template. The
Reg protocol models certiﬁcate issuance. For Cinderella, the
ids correspond to the subject
identiﬁer encoded in X.509
certiﬁcates. The value usk contains both the user’s certiﬁcate
and his RSA private keys. Sign corresponds to the vote
submission process of our front-end, while Verify is used
for ballot validation.

ring signature.

The linkable ring-signatures literature already discusses
similar voting applications [53, 57, 66]. However, they often
require a freshly generated user key for each election, while
we reuse long-term legacy keys. A similar primitive was also
employed in [34] to implement a primitive anonymous petition
system. Here we achieve the same security guarantees but
piggyback on the client certiﬁcates of National ID cards, which
is very appealing for e-government scenarios.

We formally deﬁne correctness, unforgeability, and unlinka-
bility properties of linkable ring signatures and prove that they
are met by our construction.
Security deﬁnitions The scheme R = (Setup, Reg, Sign,
Verify, Legacy) is a linkable ring signature scheme if it is
correct, unforgeable and anonymous, as deﬁned next.

Users may sign any messages in any ring they belong to.

⎡
⎣ (vk, sk) ← PKCSGen(1λ);
b ← {0, 1} :
b = APKCSSign,F(vk)

⎤
⎦ ≈ 1

2

Pr

,

253253

Deﬁnition 2 (Correctness): R is correct if, for all adversaries

A, we have

⎡

⎢⎢⎢⎢⎣

Pr

(ipk, isk) ← Setup(1λ);
usk ← Reg(ipk, isk, id)
(EID, IDs, B) ← A(ipk)
(π, N ) ← Sign(usk, EID, id ∪ IDs, B) :
Verify(ipk, EID, id ∪ IDs, B, π, N ) = 1

⎤

⎥⎥⎥⎥⎦ = 1.

When deﬁning unforgeability, we give the adversary access
to Corrupt queries that reveal user secret keys and Legacy
the use of usk in legacy algorithms,
queries that request
paradigmatically PKCS#1 signing. Intuitively, R is unforge-
able (with respect to insider corruption and legacy algorithms
Legacy) if an adversary cannot create signatures with respect
to more one-time pseudonyms than he controls.
Deﬁnition 3 (Unforgeability): R is unforgeable when for all
probabilistic polynomial-time adversaries A, we have
⎡
(ipk, isk) ← Setup(1λ)
⎢⎢⎣
EID, IDs, Π ← AReg,Legacy,Sign,Corrupt(ipk) :
¬Cond(EID, IDs, Π) ∧ ∀(N, B, π) ∈ Π.

⎤
⎥⎥⎦ ≈ 0,

Pr

Verify(ipk, EID, IDs, B, π, N ) = 1

where

rithm if uski exists.

• Reg(i, id) checks that id /∈ I, otherwise aborts; adds id
to set I; if i = ⊥, runs Reg
I with the adversary (enabling
it to register his own identiﬁers); otherwise runs uski ←
Reg(ipk, isk, id), adds uski to set C and id to set H.
• Legacy(i, m) calls the Legacy(uski, m) signing algo-
• Sign(i, EID, IDs, B) returns (π, N ) ← Sign(uski,
EID, IDs, B), provided uski has been generated by Reg
and was not leaked using Corrupt(i). The oracle records
(EID, IDs, B) in a set T .
Reg(i, id), returns uski and removes id from H.
the names N recorded in Π to IDs ∩ I such that
∀(N, B, π) ∈ Π . φ(N ) ∈ H ⇒ (EID, IDs, B) ∈ T .
Anonymity means that signatures by different users in the
same ring on the same message have the same distribution.
Deﬁnition 4 (Anonymity): R is anonymous when, for any
adversary A, we have
⎡

• Corrupt(i), provided uski has been generated by

• Cond(Π) holds when there is an injective function φ from

⎤

⎢⎢⎢⎢⎣

Pr

(ipk, isk) ← Setup(1λ);
(EID, i0, i1, IDs, B) ← AReg,Legacy,Sign(ipk)
b ← {0, 1};
(π, N ) ← Sign(uskib
A(π, N ) = b | Cond(EID, i0, u1)

, EID, IDs, B) :

⎥⎥⎥⎥⎦

≈ 1
2

,

where Cond(EID, i0, i1) holds if

Reg(i0, idi0 ) and Reg(i1, idi1 );

• uski0 and uski1 have been honestly generated by calling
• idi0 , idi1 ∈ IDs; and
• neither (EID, i0) nor (EID, i1) were queried to Sign.
On realizing the algorithms Figure 19 realizes the algo-
rithms (Setup, Reg, Sign, Verify) using a veriﬁable compu-
tation system for a function validate(ipk0, EID, IDs, N, B)

254254

whose concrete code is partially shown in Figure 13, and any
ordinary INT-CMA signing scheme. Pragmatically, we will
assume that PKCS#1 is INT-CMA secure.

Setup creates an issuer key pair ipk0, isk0 and an eval-
uation key pair ipk1, isk1 for certiﬁcates of ﬁxed template
and issuer public key. Reg is just the legacy issuing process
for the users’ X.509 certiﬁcates. Certiﬁcates of eligible voters
must match the template ﬁxed in Setup. Sign computes the
inputs for validate, a pseudonym N derived from σid and
the signature σ on (EID, B), and a proof that they satisfy the
computation using EK. Verify checks the proof.

We instantiate Legacy(usk, m) by PKCS#1 signing, but

messages with the preﬁx "Helios" are never signed.

Theorem 1: This realization is correct, anonymous, and
unforgeable, if PKCS#1 is INT-CMA secure and hash pseudo-
random, and Pinocchio is O-SNARK knowledge sound.
Proof sketch:

Correctness follows from inspection.
Anonymity follows from the perfect zero-knowledge prop-
erty of Pinocchio, and hash pseudo-randomness of PKCS#1.
The proof proceeds in two steps. First, we replace real
Pinocchio proofs by simulated proofs. Second, we replace
pseudonyms N by random values. The ﬁrst step is justiﬁed
by the zero-knowledge property of Pinocchio and the second
by hash pseudo-randomness.
Unforgeability relies on the O-SNARK knowledge sound-
ness of Pinocchio, which allows extraction of valid signatures
from the proof. Either extraction fails and we break the
security of Pinocchio, or we obtain values cert[id], σid, σ such
that
the certiﬁcate is valid and the signatures verify with
respect to the subject public key in cert. If the certiﬁcate
was not generated by Reg or if for any id in H, σ signs a
hitherto fresh message (EID, B) we give a reduction to the
unforgeability of PKCS#1 signatures.

Setup(){

ipk0, isk0 = X509Setup();
store_Modulus(ipk0);
EK, VK = KEYGEN(validate);
return ({ipk0, EK, VK}, isk0); }

Reg(ipk, isk, id){

vk, sk = PKCSGen();
cert = X509Issue(isk0, vk, id);
return {ipk, cert, sk}; }

Legacy(usk{ipk, cert, sk}, T) {

assert(notPrefix("Helios", T));
return PKCSSign(sk, T);}

Sign(usk{ipk, cert, sk}, EID, IDs, B){
sig0 = PKCSSign(sk, "Helios Seed");
sig1 = PKCSSign(sk, "Helios Ballot"||EID||\IDs||B);
N = H(sig0||EID);
π = COMPUTE(EK, EID, IDs, N, B, cert, sig0, sig1);
return N,π; }

Verify(ipk, EID, IDs, B, N, π){

return VERIFY(VK, EID, IDs, N, B, π); }
Fig. 19. Pseudocode for realizing our linkable ring-signature scheme R

