UIPicker: User-Input Privacy Identification  

in Mobile Applications

Yuhong Nan, Min Yang, Zhemin Yang, and Shunfan Zhou, Fudan University;  

Guofei Gu, Texas A&M University; Xiaofeng Wang, Indiana University Bloomington

https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/nan

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXUIPicker: User-Input Privacy Identiﬁcation in Mobile Applications

Yuhong Nan 1, Min Yang 1, Zhemin Yang 1, Shunfan Zhou 1, Guofei Gu 2, and XiaoFeng Wang 3

1School of Computer Science, Fudan University

1Shanghai Key Laboratory of Data Science, Fudan University

2SUCCESS Lab, Texas A&M University

3Indiana University at Bloomington

{nanyuhong, m yang, yangzhemin, 11300240020}@fudan.edu.cn

guofei@cse.tamu.edu, xw7@indiana.edu

Abstract

Identifying sensitive user inputs is a prerequisite for pri-
vacy protection. When it comes to today’s program anal-
ysis systems, however, only those data that go through
well-deﬁned system APIs can be automatically labelled.
In our research, we show that this conventional approach
is far from adequate, as most sensitive inputs are actu-
ally entered by the user at an app’s runtime: in our re-
search, we inspect 17, 425 top apps from Google Play,
and ﬁnd that 35.46% of them involve sensitive user in-
puts. Manually marking them involves a lot of effort, im-
peding a large-scale, automated analysis of apps for po-
tential information leaks. To address this important issue,
we present UIPicker, an adaptable framework for auto-
matic identiﬁcation of sensitive user inputs. UIPicker is
designed to detect the semantic information within the
application layout resources and program code, and fur-
ther analyze it for the locations where security-critical
information may show up. This approach can support a
variety of existing security analysis on mobile apps. We
further develop a runtime protection mechanism on top
of the technique, which helps the user make informed
decisions when her sensitive data is about to leave the
device in an unexpected way. We evaluate our approach
over 200 randomly selected popular apps on Google-
Play. UIPicker is able to accurately label sensitive user
inputs most of the time, with 93.6% precision and 90.1%
recall.

1 Introduction

Protecting the privacy of user data within mobile appli-
cations (apps for short) has always been at the spotlight
of mobile security research. Already a variety of pro-
gram analysis techniques have been developed to evalu-
ate apps for potential information leaks, either dynami-
cally [19, 23, 41] or statically [15, 26]. Access control
mechanisms [27, 22, 33, 17] have also been proposed to

enforce ﬁne-grained security policies on the way that pri-
vate user data can be handled on a mobile system. These
techniques are further employed by mobile app market-
places like Google Play (e.g., Bouncer [7]) to detect the
apps that conduct unauthorized collection of sensitive
user data.

Identifying sensitive user inputs. Critical to those pri-
vacy protection mechanisms is the labeling of sensitive
user data. Some of the data are provided by the operating
system (OS), e.g., the GPS locations that can be acquired
through system calls like getLastKnownLocation().
Protection of such information, which we call System
Centric Privacy data, can leverage relevant data-access
APIs to set the security tags for the data. More compli-
cated here is the content the user enters to a mobile app
through its user interface (UI), such as credit-card infor-
mation, username, password, etc. Safeguarding this type
of information, called User-Input Privacy (UIP) data in
this paper, requires understanding its semantics within
the app, before its locations can be determined, which
cannot be done automatically using existing techniques.
Just like the system-controlled user data (e.g., GPS),
the private content entered through the UI is equally vul-
nerable to a variety of information-leak threats. It has
been reported [5, 10, 4, 6] that adversaries can steal sen-
sitive user inputs through exploiting the weaknesses in-
side existing protection mechanisms. For example, fraud
banking apps to steal user’s ﬁnancial credentials with
very similarity UIs. Besides, less security-savvy de-
velopers often inadvertently disclose sensitive user data,
for example, transmitting plaintext content across public
networks, which subjects the apps to eavesdropping at-
tacks. Recent work further shows that side channels [18]
and content-pollution vulnerabilities [42] can be lever-
aged to steal sensitive user inputs as well.
In our re-
search, we found that among 17,425 top Google-Play
apps, 35.46% require users to enter their conﬁdential in-
formation.

Given its importance, UIP data urgently needs protec-

USENIX Association  

24th USENIX Security Symposium  993

tion. However, its technical solution is by no means triv-
ial. Unlike system-managed user data, which can be eas-
ily identiﬁed from a few API functions, sensitive user
inputs cannot be found without interpreting the context
and semantics of UIs. A straightforward approach is to
mark all the inputs as sensitive [15], which is clearly an
overkill and will cause a large number of false positives.
Prior approaches [43, 15, 36, 38, 40] typically rely on
users, developers or app analysts to manually specify the
contents within apps that need to be protected. This re-
quires intensive human intervention and does not work
when it comes to a large-scale analysis of apps’ privacy
risks.

To protect sensitive user inputs against both deliberate
and inadvertent exposures, it is important to automati-
cally recognize the private content the user enters into
mobile apps. This is challenging due to the lack of ﬁxed
structures for such content, which cannot be easily re-
covered without analyzing its semantics.

Our work. To address this issue, we propose our re-
search UIPicker, a novel framework for automatic, large-
scale User-Input Privacy identiﬁcation within Android
apps. Our approach leverages the observation that most
privacy-related UI elements are well-described in lay-
out resource ﬁles or annotated by relevant keywords on
UI screens. These UI elements are automatically recov-
ered in our research with a novel combination of several
natural language processing, machine learning and pro-
gram analysis techniques. More speciﬁcally, UIPicker
ﬁrst collects a training corpus of privacy-related con-
tents, according to a set of keywords and auto-labelled
data. Then, it utilizes the content to train a classiﬁer that
identiﬁes sensitive user inputs from an app’s layout re-
sources. It also performs a static analysis on the app’s
code to locate the elements that indeed accept user in-
puts, thus ﬁltering out those that actually do not contain
private user data, even though apparently they are also
associated with certain sensitive keywords, e.g., a dialog
box explaining how a strong password should be con-
structed.

Based on UIPicker, we further develop a runtime pri-
vacy protection mechanism that warns users whenever
sensitive data leave the device. Using the security labels
set by UIPicker, our system can inform users of what
kind of information is about to be sent out insecurely
from the device. This enables the user to decide whether
to stop the transmission. UIPicker can be used by the
OS vendors or users to protect sensitive user data in the
presence of untrusted or vulnerable apps. It can be easily
deployed to support any existing static and dynamic taint
analysis tools as well as access control frameworks for
automatic labeling of private user information.

the prototype of UIPicker is implemented for Android,
the idea can be applied to other platforms as well. We im-
plemented UIPicker based on FlowDroid [15] and built
our identiﬁcation model using 17,425 popular Google
Play apps. Our evaluation of UIPicker over 200 ran-
domly selected popular apps shows that it achieves a high
precision (93.6%) and recall (90.1%).

Contributions. In summary, this paper makes the fol-
lowing contributions.

• We measure the distribution of UIP data based on
17,425 classiﬁed top free applications from differ-
ent categories. The results show that in some cate-
gories, more than half of applications contain UIP
data. Further protection of these UIP data is in ur-
gent need.

• We propose UIPicker, a series of techniques for au-
tomatically identifying UIP data in large scale. Lots
of existing tools can beneﬁt from UIPicker for bet-
ter privacy recognition in mobile applications.

• Based on UIPicker, we propose a runtime security
enhancement mechanism for UIP data protection,
which helps user to make informed decisions when
such data prepare to leave the device with insecure
transmission.

• We conduct a series of evaluation to show the effec-

tiveness and precision of UIPicker.

Roadmap. The rest of this paper is organized as follows.
Section 2 gives the motivation, challenges and identiﬁca-
tion scope of UIP data, then introduces some background
knowledge about Android layout resources. Section 3
gives an overview of UIPicker and illustrates the key
techniques applied for identifying UIP data. Section 4
describes the identiﬁcation approach step by step. Sec-
tion 5 describes the runtime security enhancement frame-
work based on UIPicker’s identiﬁcation results. Sec-
tion 6 gives some implementation details about UIPicker.
Section 7 gives evaluation and Section 8 discusses the
limitation of UIPicker. Section 9 describes related work,
and Section 10 concludes this work.

2 Problem Statement

In this section, we ﬁrst provide a motivating example
of users’ sensitive input in two UI screens, then we in-
vestigate challenges in identifying such data and clarify
our identiﬁcation scope of UIP data. We also give some
background knowledge about Android layout resources
for further usage.

2.1 Motivating Example

To the best of our knowledge, UIPicker is the ﬁrst ap-
proach to help detect UIP data in a large scale. Although

Figure 1 shows two UI screens that contain some criti-
cal sensitive information in the Amazon Online Store [1]

994  24th USENIX Security Symposium 

USENIX Association

2

monitoring. As these sensitive data are highly unstruc-
tured, they can not be simply matched by regex expres-
sions when users input them. Besides, like any normal
inputs, privacy-related inputs are sparsely distributed in
various layouts in a single app, and most UI screens con-
tain such private data require login or complex trigger
conditions, which makes it very difﬁcult for automatic
testing tools like [8, 34] to traverse such UI screens ex-
haustively without manual intervention.

Identifying UIP data by traditional static analysis ap-
proaches is also impractical. In program code’s seman-
tic, sensitive input does not have explicit difference com-
pared to normal input. Speciﬁcally, all of such input data
can be accepted by apps, then transmitted out or saved in
local storage in the same way, which makes it difﬁcult to
distinguish them through static analysis approaches.

UIPicker identiﬁes UIP data in apps from another
perspective, it analyzes texts describing sensitive inputs
other than data themselves. This is because texts in UI
screens usually contain semantic information that de-
scribes the sensitive input. Besides, layout description
texts in layout ﬁles also contain rich semantic informa-
tion to reveal what the speciﬁc element is intended to
be in the UI screen by developers. UIPicker is primar-
ily designed to help identify UIP data in benign apps.
The identiﬁcation results can be further used for secu-
rity analysis or protection of users’ sensitive data. Note
that in this work we do not deal with malicious apps that
intentionally evade our analysis, e.g., malware that con-
structs its layout dynamically or uses pictures as labels
to guide users to input their sensitive data.

2.3 Identiﬁcation Scope

UIP data could be any piece of data that users consider
to be sensitive from inputs.
In the current version of
UIPicker, we consider the following 3 categories as they
cover most existing UIP data in current apps:

• Account Credentials and User Proﬁles: Informa-
tion that reveals users’ personal characters when
they login or register, which includes but not limited
to data such as username, user’s true name, pass-
word, email address, phone number, birth date.

• Location: Plain texts that represent address infor-
mation related to users. Different from system de-
rived location (latitude and longitude), what we fo-
cus here is location data from users’ input, e.g., the
delivering address in shopping apps or the billing
address for credit cards.

• Financial: Information related to users’ ﬁnancial
activities, e.g., credit card number, expire date and
security code.

The objective of UIPicker is to automatically iden-
tify such data from app resources in large-scale. Note

Figure 1: Examples of User-Input Privacy (UIP) Data

app. In Figure 1(a), the user is required to input his/her
detailed address for delivering products. Figure 1(b) re-
quires user to input the credit card credential to accom-
plish the payment process. Many apps in mobile plat-
form would require such sensitive data for various func-
tional purposes. Most of such data are personal informa-
tion that users are unwilling to expose insecurely to the
public.

Although UIP data can be highly security-sensitive
and once improperly exposed, could have serious con-
sequences, little has been done so far to identify them at
a large scale. The key issue here is how to automatically
differentiate sensitive user inputs from other inputs. In
our research, we check the top 350 free apps on Google
Play, and ﬁnd that on average each of them contains 11
ﬁelds across 6 UI screens to accept user inputs; however
many of these ﬁelds do not accommodate any sensitive
data. Static analysis tools like FlowDroid [15] only pro-
vide options to taint all user inputs as sensitive sources
(e.g. Element.getText()). Analyzing in this way would
get fairly poor results because sensitive user inputs we
focus are mixed in lots of other sources we do not care.
Such problem also exists in runtime protection on users’
sensitive inputs. For example, in order to prevent sensi-
tive user inputs insecurely leaking out, an ideal solution
would be warning users when such data leave the device.
Alerting all user inputs in this way would greatly annoy
the users and reduce the usability because many normal
inputs do not need to be treated as sensitive data.

2.2 Challenges

UIP data can be easily recognized by human. How-
ever, it is quite challenging for the machine to auto-
matically identify such data with existing approaches in
large-scale.

First, UIP data can not be identiﬁed through runtime

USENIX Association  

24th USENIX Security Symposium  995

3

that UIP data might not be limited to items listed here.
UIPicker is capable of expanding its identiﬁcation scope
easily, as further discussed in Section 4.2.

2.4 Android Layout Background

Here we give some background knowledge about An-
droid layout resources which UIPicker will use in our
identiﬁcation approach.

constructing the UI in Figure 1(b). The entry is a
layout ﬁle named add credit card.xml. It contains two
EditText elements to accept the credit card number and
the card holder’s name, three Dropdown list elements
(named as spinner in Android) to let user select card
type and expiration date. In the EditText for requesting
the card number, it uses @id/opl credit card number
to uniquely identify this element for the app. Syn-
tax like android:inputType=number
that
this EditText only accepts digital
There is
also a TextView before EditText with attribute an-
droid:text=@string/opl new payment credit card number,
which means the content showed in this label will be
string referenced to opl new payment credit card -
number in /res/values/stings.xml.

suggests

input.

3 System Overview

In this section, we give an overview of UIPicker and de-
scribe the key techniques applied in our identiﬁcation
framework.

Overall Architecture. Figure 3 shows the overall archi-
tecture of UIPicker. UIPicker is made up of four com-
ponents to identify layout elements which contain UIP
data step by step. The major components can be divided
into two phases: model-training and identiﬁcation.
In
the model-training phase (Stage 1,2,3), UIPicker takes a
set of apps to train a classiﬁer for identifying elements
contain UIP data from their textual semantics.
In the
identiﬁcation Phase (Stage 1,3,4), UIPicker uses both the
trained classiﬁer (Stage 3) and program behavior (Stage
4) to identify UIP data elements.

Pre-Processing. In the Pre-Processing module, UIPicker
extracts the selected layout resource texts and reorga-
nizes them through natural language processing (NLP)
for further usage. This step includes word splitting, re-
dundant content removal and stemming for texts. Pre-
Process can greatly reduce the format variations of texts
in layout resources caused by developers’ different cod-
ing practice.

Privacy-related Texts Analysis. For identifying UIP
data from layout resources, the ﬁrst challenge is how to
get privacy-related texts. One can easily come up with a
small set of words about UIP data, but it is very difﬁcult
to get a complete dictionary to cover all such semantics.
In our case, leveraging an English dictionary like Word-
Net [14] for obtaining semantically related words is lim-
ited in the domain of our goals. Many words that are
semantically related in privacy may not be semantically
related in English, and many words that are semantically
related in English may not appear in layout resource texts
as well. For example, both “signup” and “register” repre-
sent to create a new account in an app’s login screen, but

Figure 2: Android Layout Description Resources

Layout resources deﬁne what will be drawn in the UI
screen(s) of the app. In Android, a User Interface is made
up of some basic elements (e.g., TextView, EditText, But-
ton) to display information or receive input. Android
mainly uses XML to construct app layouts, thus devel-
opers can quickly design UI layouts and screen elements
they wish to contain, with a series of elements such as
buttons, labels, or input ﬁelds. Each element has vari-
ous attributes or parameters which are made up of name-
value pairs to provide additional information about the
element.

Android layout resources are distributed in different
folders in the app package. Layout ﬁles for describ-
ing UI screens are located in folder res/layout. The
unique hex digit IDs for identifying each element in lay-
out ﬁles are in res/value/public.xml and texts showed in
UI screens to users are in res/values/strings.xml. Re-
sources in res/values/ are referenced by texts with spe-
ciﬁc syntax (e.g. @String, @id) in the layout ﬁles in
res/layout for ease of development and resource manage-
ment.

Figure 2 shows some layout resources used for

996  24th USENIX Security Symposium 

USENIX Association

4

Figure 3: System Overview of UIPicker

they can not be correlated from a dictionary like Word-
Net.

Besides, UIP data in apps are often described with a
single word or very short phrases (e.g. “password” or
“input password”) in layout resources. Due to the lack
of complete sentences describing UIP data, natural lan-
guage processing techniques [35] like dependency rela-
tion pattern extraction is not suitable in our scenario.

UIPicker expands UIP semantic texts with a few
privacy-related seeds based on a speciﬁc feature extrac-
tion approach.
It ﬁrst automatically labels a subset of
layouts which could contain UIP data by heuristic rules,
then extracts privacy-related semantics from such layouts
by applying clustering algorithms. It helps us to auto-
matically extract privacy-related texts with little manual
effort. As a result, these inferred texts can be used as
features for identifying whether an element is privacy-
related or not in the next step.

UIP Data Element Identiﬁcation. Based on the given
set of privacy-related textual semantics from the previ-
ous step, to what extent an element contains privacy-
related texts can be identiﬁed as sensitive? As previ-
ous work [37] showed, purely relying on keyword-based
search would result in a large number of false positives.
For example, sensitive item “username” could always be
split into “user” and “name” as two words in apps, and
none of the single word can represent “username”. Be-
sides, certain words like “address” have a confounding
meaning. For instance, such phrase showed in a layout
screen “address such problem” does not refer to location
information.

In this step, UIPicker uses a supervised machine learn-
ing approach to train a classiﬁer based on a set of se-
mantic features generated in the previous stage. Besides,
it fully takes the element’s context in the whole layout
into consideration for deciding whether the element is
privacy-related or not. With this trained model, for any
given layout element with description texts, UIPicker can

tell whether it is related to UIP from its textual semantics.

Behavior Based Result Filtering. Besides identifying
elements that contain UIP data from their textual seman-
tics, we also need to check whether a privacy-related el-
ement is actually accepting user input. In other words,
we need to distinguish user inputs from other static ele-
ments such as buttons or labels for information illustra-
tion in layout screens. Although Android deﬁnes Edit-
Text for accepting user input, developers can design any
type of element by themselves (e.g. customized input
ﬁeld named as com.abc.InputBox). Besides, apps also re-
ceive user inputs in an implicit way through other system
deﬁned elements without typing the keyboard by users.
For example, in Figure 1(b), the expire date of credit card
is acquired by selecting digits from the Spinner element.
We observe that for each privacy-related element iden-
tiﬁed by UIPicker in the previous stage, the data should
be acquired by the app with user’s consent if it is actually
accepting user input. For example, the user clicks a but-
ton “OK” to submit data he/she inputs. When reﬂected in
the program code, the user input data should be acquired
by the system under certain event trigger functions. We
use static code analysis to check whether an arbitrary el-
ement can be matched with such behavior, thus ﬁlter out
irrelevant elements we do not expect.

4 IDENTIFICATION APPROACH

In this section, we explain the details of four stages in
UIPicker’s identiﬁcation approach.

4.1 Stage 1: Pre-Processing

Resource Extraction. We ﬁrst decode the Android APK
package with apktool [2] for extracting related resource
ﬁles we need. Our main interest is in UI-related content,
thus for each app, we extract UI Texts and Layout De-
scriptions from its decompiled layout ﬁles.

USENIX Association  

24th USENIX Security Symposium  997

5

Layout Resource

UI Texts

Sample

Add a new credit card, Credit Card Number
Expiration Date, Card Type, Cardholder’s name

Layout Descrioptions @string/opl new credit card expiration date month

@string/opl new credit card save buton

@id/opl credit card number

Table 1: Selected resources of Amazon Online’s “Add
Credit Card” screen

• UI Texts. UI texts are texts showed to users in the
layout screen. In Android, most of such texts are
located in /res/values/strings.xml and referenced by
syntax @String/[UI text identiﬁer] in element’s at-
tribute. Some UI texts are directly written in lay-
out ﬁles as attribute values of UI elements, e.g., an-
droid:hint=‘Please input your home address here’.
• Layout Descriptions. Layout Descriptions are
texts only showed in layout ﬁles located in
/res/layout/. For these texts, we consider all strings
starting with syntax @id and @String to reﬂect
what the element is intended to be from their tex-
tual semantics.

The main difference between UI texts and layout de-
scriptions is that UI texts are purely made up of natu-
ral language while layout descriptions are mainly name
identiﬁers (both formatted and unformatted) with seman-
tic information. As developers have different naming
behaviors when constructing UIs, in most cases, seman-
tic information in layout descriptions is more ambiguous
than that in UI texts.

We extract these groups of resources for further analy-
sis because these selected targets can mostly reﬂect the
actual content of the app’s layout. For example, the
selected resources about Amazon’s “Add Credit Card”
screen in Figure 1(b) are showed in Table 1.

identiﬁers for ease of

Word Splitting. Although most of layout descrip-
tions are meaningful
read-
ing and program development, normally they are
delimiter-separated words or letter-case separated words.
For example, “phone number” can be described as
“phone number” or “PhoneNumber”. Thus we split such
strings into separated word sets. Besides, some of layout
descriptions are concatenated by multiple words without
any separated characters. For these data, we split them
out by iteratively matching the maximum length word in
WordNet [14] until the string cannot be split any more.
For example, string “conﬁrmpasswordﬁeld” will be split
into “conﬁrm”, “password”, and “ﬁeld”.

Redundant Content Removal. For all UI texts we ex-
tracted, we remove non-English strings through encod-
ing analysis. For each word, we also remove non-text
characters from all extracted resources such as digits,
punctuation. After this, we remove stop words. Stop

Figure 4: After Pre-Processing, texts in left are trans-
formed into formats in right

words are some of the most common words like “the”,
“is”, “have”. We remove such contents because they can
not provide meaningful help in our analysis process.

Stemming. Stemming is the process for reducing in-
ﬂected (or sometimes derived) words to their stem, base
or root form. Stemming is essential to make words such
as “changed”, “changing” all match to the single com-
mon root “change”. Stemming can greatly improve the
results of later identiﬁcation processes since they reduce
the number of words in our resources. We implement
Porter Stemmer [11] with python NLTK module [9].

Figure 4 shows part of texts before and after pre-
processing for Amazon’s “Add credit card” layout ﬁle.
As we can see, all texts concatenated by ‘ ’ are split into
separated words, “edthomephonecontact” is split into
“edt”, “home”, “phone” and “contact” instead. We also
transform words like “forgot”, “forget” into a single uni-
formed format as “forget”.

4.2 Stage 2: Privacy-related Texts Analysis

In this stage, we use Chi-Square test [39] to extract
privacy-related texts from a subset of speciﬁc layouts.
The intuition here is that privacy-related words prefer to
be correlated in speciﬁc UIs such as the login, registra-
tion or settings page of the app. If some words appear
together in these UI, they are likely to have semantic rel-
evance to users’ sensitive information. Thus, we use such
layouts to extract privacy-related texts in contrast to other
normal layouts.
Chi-Square Based Clustering. Chi-Square (Chi2) test
is a statistical test that is widely used to determine
whether the expected distributions of categorical vari-
ables signiﬁcantly differ from those observed. Speciﬁ-
cally in our case, it is leveraged to test whether a speciﬁc
term on UI screens is privacy-related or not according to
its occurrences in two opposite datasets (privacy-related
or non privacy-related).

Here we choose UI texts rather than layout descrip-
tions to generate privacy-related texts due to the follow-

998  24th USENIX Security Symposium 

USENIX Association

6

e.g., the pair (your, username).

As such patterns strongly imply actions that the app
is requesting the user’s sensitive input, for those layout
samples satisfying one of these two patterns, we label
them as privacy-related (positive samples). On the other
hand, for layout samples that do not contain any of texts
in the pattern (both noun phrase and verb, possessive
phase), we label them as negative samples. Note that we
do not label those layouts only containing initial seeds as
positive or negative because a single word is insufﬁcient
for us to identify whether the layout is privacy-related or
not.

Based on the two classiﬁed sample sets, for all distinct
words appearing in positive samples, we use Chi-Square
test and rank their results in a descending order. As a re-
sult, texts with higher Chi-Square scores mean they are
more representative as privacy-related, which can easily
be picked up from the top-ranked words in the test re-
sults.

The following example explains our analysis approach
for ﬁnding ﬁnancial-related textual semantics. We set
“credit card” as an initial seed, then the layout shown
in Figure 1(b) will be identiﬁed as a positive sample be-
cause both “credit card” and verb phrase “add” are in-
cluded in this layout. Thus in our dataset, other similar
layouts will be labeled as positive if it requires users to
input credit card information as well. As a result, the
positive sample will include more texts such as “expire”,
“date”, “year”, “month”, which are also related to ﬁnan-
cial credentials and ranked in top of the Chi-Square test
results.

Noisy Text Removal. Although Chi-Square test aims
to cluster privacy-related texts, it still unavoidably in-
troduces some irrelevant texts into its clustering results.
This is mainly because not all texts in privacy-related lay-
out are necessarily related to privacy. In order to generate
a highly precise cluster of privacy-related texts to elim-
inate false positives in the UIP data element identiﬁca-
tion process, we introduce a little manual effort here for
ﬁltering out such irrelevant texts from the clustering re-
sult. Since Chi-Square test already helps us extract texts
that are most probably related to privacy, looking through
such a list is quite simple and effortless.

Alternative Approaches. In our research, we compared
the Chi-Square test with two popular alternatives, fre-
quency based text extraction and TF-IDF [31], both of
which are found to be less effective. They all bring in
more irrelevant contents than the Chi-Square test, more
susceptible to the limitation of the layout level samples,
that is, privacy related UI screens often contain a lot of
normal texts, which become noises in our sensitive term
identiﬁcation. Also, using these two approaches, we
need to continuously adjust their thresholds for select-

Figure 5: For each word assigned as the initial seed,
UIPicker calculates its Chi-Square test for each word in
positive samples and appends part of its top results into
the privacy-related texts feature set.

ing two reasons: First, layout descriptions are not well
structured as the naming behaviors vary very differently
between apps (or developers), while UI texts are in a rel-
atively uniformed format, thus making it easy to extract
privacy-related texts from them. For example, a layout
requesting a user’s password must contain term “pass-
word” in the UI screen, while in layout descriptions it
could be text like “pwd”, “passwd”, “pass”. Second, as
layout descriptions aim for describing layout elements,
it may contain too much noisy texts like “button”, “text”
which would bring negative impact to the privacy-related
text extraction.

Figure 5 shows how UIPicker generates privacy-
related texts. First, we give a few words that can ex-
plicitly represent users’ sensitive input we focus (e.g.,
email, location, credit card), and we call them initial
seeds. Each layout sample is made up of a set of UI texts
in its layout screen. Then, the initial seeds will be used
to identify whether a speciﬁc layout sample is privacy-
related or not based on the following two patterns:

• Logical relation between sensitive noun phrase (ini-
tial seed) and verb phrase, e.g., the pair (save, pass-
word).

• Logical relation between possessive (mainly word
“your”) and sensitive noun phrase (initial seed),

USENIX Association  

24th USENIX Security Symposium  999

7

ing privacy-related text when their sample sizes change.
This can be avoided when using the Chi-Square test.
Nevertheless, we acknowledge that there may exist other
feature extraction mechanisms that could perform better,
which is one of our future work.

4.3 Stage 3: UIP Data Element Identiﬁca-

tion

In this stage, we explain the details of our machine-
learning approach, which automatically identiﬁes UIP
data elements based on their textual semantics. UIPicker
uses supervised learning to train a classiﬁer based on a
subset of element samples with privacy-related seman-
tic features. As a result, for a given unclassiﬁed UI ele-
ment, this step could identify whether it is semantically
privacy-related from its description texts.

Feature Selection. We use privacy-related texts inferred
from the previous stage as features for the identiﬁcation
module. A single word alone usually does not provide
enough information to decide whether a given element is
privacy-related. However, all such features in combina-
tion can be used to train a precise classiﬁer. The main
reason why these features work is that both UI texts and
layout descriptions do in fact reveal textual semantic in-
formation, which a machine learning approach such as
ours can discover and utilize. Note that in layout descrip-
tions, it is often the case that developers use text abbrevi-
ations for simplicity when naming identiﬁers. For exam-
ple, “address” in layout descriptions could be “addr”. For
this, we construct a mapping list of such texts we visited
during the manual analysis. Thus, for each word in lay-
out descriptions, we transform the abbreviation into com-
plete one if it is contained by any privacy-related texts.

Besides, we also take semantic features of layout
structure into consideration: the texts of this element’s
siblings. We observe that many elements are described
by texts in its siblings. For example, In Figure 1(b),
most of input ﬁelds are described by static labels which
contain privacy-related text as instructions for requesting
user inputs. As a result, texts from sibling elements can
bring more semantic information for better identiﬁcation
results.

The classiﬁer works on a matrix organized by one col-
umn per feature (one word) and one row per instance.
The dimension for each instance is the size of our feature
set (the number of texts from the previous step). The ad-
ditional column indicates whether or not this instance is
a privacy-related element.

Training Data. Since text ﬁelds can have different
input types for determining what kind of characters
are allowed inside the ﬁeld, Android provides the an-
droid:inputType attribute to specify what kind of char-

acters are allowed for EditText. For example, an el-
ement with inputType valued textEmailAddress means
only email address is accepted in this input ﬁeld. There
are several input types explicitly reﬂect the element con-
taining UIP data we focus on, which can be used as the
training data of the identiﬁcation module. We list such
sensitive attribute values1 in the ﬁrst column of Table 2.

Privacy Category

Attribute Value

Account Credentials

& User Proﬁle

textEmailAddress textPersonName
textPassword textVisiblePassword

password/email/phoneNumber

Location

textPostalAddress

Table 2: Sensitive attribute values in layout descriptions

The training data is constructed as follows: First, we
automatically label all elements with sensitive attributes
as positive samples since they are a subset of UIP data
elements. We further manually label a set of elements
involving ﬁnancial information from the category “Fi-
nancial” because such elements are covered by sensitive
attributes Android provides. Besides, a set of negative
samples are picked out through human labeling after ﬁl-
tering out the elements that contain any of the privacy-
related texts we generated in Stage 2.

Classiﬁer Selection. We utilize the standard support
vector machine (SVM) as our classiﬁer. SVM is widely
used for classiﬁcation and regression analysis. Given a
set of training examples with two different categories,
the algorithm tries to ﬁnd a hyper-plane separating the
examples. As a result, it determines which side of hyper-
plane the new test examples belong to. In our case, for an
unclassiﬁed unknown layout element with corresponding
features (whether or not containing privacy-related texts
extracted in the previous step) the classiﬁer can decide
whether it contains UIP data or not from its textual se-
mantics.

4.4 Stage 4: Behavior Based Result Filter-

ing

As a non-trivial approach for identifying UIP data, for
each element identiﬁed as privacy-related from its layout
descriptions, UIPicker inspects the behaviors reﬂected in
its program code to check whether it is accepting user in-
puts, thus ﬁltering out irrelevant elements from the iden-
tiﬁcation results in the previous step.

1In some older apps, developers also use speciﬁc attribute like “an-
droid:password=True” to achieve the same goal as inputType. We list
them in Table 2 and call them sensitive attribute values as well for sim-
plicity.

1000  24th USENIX Security Symposium 

USENIX Association

8

Plain Text Transmission. We consider any piece of
UIP data should not be transmitted in plain text. Such sit-
uation can be easily identiﬁed by checking if the tainted
sink is HTTP connection in runtime.

Insecure SSL Transmission. Previous works [34]
showed that a large number of apps implement SSL with
inadequate validations (e.g., app contains code that al-
lows all hostnames or accepts all certiﬁcates). Insecure
SSL transmission could be more dangerous because they
may carry over critical sensitive data in most cases. UIP
data should not be transmitted in this way as well.

Since UIPicker is deployed in off-line analysis by cus-
tomized system vendors, one can also check whether the
apps have securely implemented SSL off-line at the same
time. We integrate a static analysis framework named
MalloDroid [20] with UIPicker to automatically check
SSL security risks by evaluating the SSL usage in apps.
As MalloDroid can only ﬁnd broken SSL usage regard-
less what data is transmitted via this channel, we also use
FlowDroid to check if there exists data/control ﬂow inter-
sections between UIP data sources and SSL library invo-
cation sinks in the app, thus conﬁrming whether the UIP
data in the app will be transmitted with security risks.

6 IMPLEMENTATION

Dataset. We crawled apps from Google Play Store based
on its pre-classiﬁed 35 categories in Oct. 2014. For each
category, we downloaded the top 500 apps. Excepting
some connection errors occurred in the crawling process,
totally we collected 17,425 apps as our dataset. This
dataset will be used in both model training and evalua-
tion of UIPicker.

Identiﬁcation Approach. We implement the prototype
of UIPicker as a mix of Python Scripts and Java code.
The ﬁrst three steps of UIPicker are developed using
Python with 3,624 lines of code (LOC). The last step,
static analysis for result ﬁltering, is implemented in Java,
which extends FlowDroid[15] and introduces additional
985 LOCs. All experiments are performed on a 32 core
Debian server with Linux 2.6.32 kernel and 64GB mem-
ory.

For privacy-related text analysis, the initial seeds are
assigned as texts in the second column of Table 3 for
each privacy category. For each initial seed, we run the
Chi-Square test using apps in our dataset. Since Android
allows developers to use nested layout structures for ﬂex-
ibility, we also group sub-layout UI texts into their root
layouts. For each round, we collect the top 80 words
from the test results, this threshold is determined by bal-
ancing between the number of privacy-related terms that
can be detected and the amount of noisy text introduced.
After 7 (7 initial seeds) rounds of the Chi-Square test,

Figure 6: Sample codes for requesting a user’s credit card
number

User input data is generated based on a user’s inter-
actions with the app during runtime.
In other words,
the data will be acquired by the app under the user’s
consent. In Android, to get any data from a UI screen
is achieved by calling speciﬁc APIs. Getting such data
under user consent means these APIs are called under
user-triggered system callbacks. For example, code frag-
ments in Figure 6 shows the behavior reﬂected in the
program when the app gets the user’s credit card num-
ber in Figure 1(b). Here, the input ﬁeld IB is deﬁned
by IB=ﬁndViewById(21...1) in activity addCreditCard.
When the user clicks the “Add your card” button, in
the program code, the OnClick() function in class Ad-
dCardListener() will be triggered by pre-registered sys-
tem callback submitBtn.setOnClickListener(). Then, it
invokes sendText(IB), which sends the inputBox’s object
by parameter, and ﬁnally gets the user’s card number by
IB.getText(). One might consider why don’t catch UIP
data simply by checking whether the element is invoked
by getText() API. The reason is that sometimes develop-
ers may also get values from UI screens like static text
labels as well as user inputs, resulting in false negatives
for our identiﬁcation approach.

5 Runtime Security Enhancement with

UIPicker

The security implications about UIP data are rooted from
the fact that users have to blindly trust apps when they
input sensitive data. With the help of UIPicker differen-
tiating UIP data from other normal inputs, we can use
taint tracking techniques to trace users’ sensitive inputs
and enable users to make informed decisions with a pop-
up window when such data insecurely leave the device,
thus effectively mitigating the potential threats posed by
apps.

For UIP data, we consider the following two situations
as insecure and should inform users to let them decide
whether to proceed or not.

USENIX Association  

24th USENIX Security Symposium  1001

9

we collect 273 words from layout samples (some texts
are overlapped in different round of Chi-Square test). We
then remove 45 words as the noisy text by manual anal-
ysis within less than 3 minutes. As a result, UIPicker
extracts 228 privacy-related terms from 13,392 distinct
words. We list part of them in the third column of Ta-
ble 3 corresponding to the privacy category they belong
to. Such data are used as features for privacy-related ele-
ment identiﬁcation in the follow-up step.

Privacy Category

Initial Seeds

Representative Inferred Texts(Stemmed)

Login Credenticals

username, password, email

&User Proﬁle

mobil phone middl proﬁle cellphon
account nicknam ﬁrstnam lastnam

person birth login conﬁrm detail regist

Location

Financial

address, location

zip citi street postal locat countri

credit card, bank

secur month date pay year bill expir

debit transact mm yy pin code

we discuss its effectiveness and precision in Section 7.2
and Section 7.3. Then we evaluate our runtime security
enhancement mechanism in Section 7.4.

7.1 Performance

During our experiment, the training phase of the clas-
siﬁer takes about 2.5 hours on average, the identiﬁca-
tion phase for the whole dataset takes 30.5 hours (6.27
seconds per app). Pre-Processing time for apps is in-
cluded in both of these two phases. The static analy-
sis for behaviour based result ﬁltering is proceeded in 32
threads concurrently. Since UIPicker mainly targets for
customized system vendors or security analysts, we con-
sider such overhead quite acceptable.

Table 3: Initial seeds and part of inferred privacy-related
texts from Chi-Square test

7.2 Effectiveness

The SVM classiﬁer

is implemented with scikit-
learn[13] in poly kernel. We optimize the classiﬁer pa-
rameters (gamma=50 and degree=2) for performing the
best results.

For each element identiﬁed as privacy-related by the
machine learning classiﬁer, UIPicker conducts static
taint analysis using FlowDroid[15] to check whether it
satisﬁes speciﬁc behavior described in Section 4.4. Since
FlowDroid successfully handles android life cycle (sys-
tem event based callbacks) and UI widgets, the data-
ﬂow results should be both precise and complete. We
set FlowDroid’s layout mode as “ALL” to get each el-
ement’s propagation chain that starts with function ﬁnd-
ViewById([elementId]) and ends in getText(). As a result,
for any element’s info-ﬂow path which contains system
event function like OnClick(), the element can be identi-
ﬁed as accepting user input.

Runtime Enhancement For each app, we use a
list of elements containing UIP data identiﬁed from
UIPicker with their unique IDs as the taint sources
of TaintDroid[19] build in Android 4.1. Since Taint-
Droid allows 32 different taint markings through a 32-bit
bitvector to encode the taint tag, for those UIP data el-
ements involved in insecure SSL usage, we label them
as “SSL Insecure” in the taint source list, thus provide
warnings to users when such data leave the device as
well. We add a pop-up window for showing the leaked
information to users when sensitive data leave the device.
Our modiﬁcation to TaintDroid is implemented with 730
LOCs in total.

7 Evaluation

UIP Data Distribution. We show the general identiﬁ-
cation results of UIPicker in Table 4.
In 17,425 apps,
UIPicker ﬁnds that 6,179 (35.46%) contain UIP data. We
list our results in a descending order of the identiﬁed to-
tal app amounts. As we can see, in 9 out of 35 categories,
more than half of apps contain UIP data.

We make the following observations from this ta-
ble. First, application categories such as BUSINESS,
FINANCE, SHOPPING, COMMUNICATION and SO-
CIAL are more likely to request Account Credentials
and User Proﬁle information, which showed that these
apps are closely related to users’ personal activities.
APP WIDGETS (54.08%) is also ranked among top of
the table. It is a set of apps which have small UIs em-
bedded in the home screen of the device, e.g., Facebook,
Youtube, Twitter. Since most of such apps provide lo-
gin and account-speciﬁc functions, they prefer to request
more UIP data as well. The SHOPPING category con-
tains many location-related elements (1,605, 37%) be-
cause the delivering address are always generated from
user inputs.
It is also reasonable that both FINANCE
and SHOPPING apps require many ﬁnancial-related sen-
sitive inputs. We believe such apps containing rich UIP
data should be treated more carefully in both developing
and security vetting process in order to make sure that
sensitive data are well protected in both transmission and
storage.

Comparative Results. We illustrate the effectiveness of
UIPicker from two aspects. First, UIPicker identiﬁes pri-
vacy data that system deﬁned APIs do not touch but still
be sensitive to users. Second, UIPicker achieves far bet-
ter coverage than simply identifying UIP data by speciﬁc
sensitive attribute values from the Android design speci-
ﬁcation.

In this section, we present our evaluation results. We ﬁrst
show the performance of UIPicker in Section 7.1, then

Comparison with System Deﬁned Sensitive APIs.
As previously mentioned, speciﬁc sensitive resources

1002  24th USENIX Security Symposium 

USENIX Association

10

Application Category

BUSINESS
WEATHER
FINANCE
COMMUNICATION
SHOPPING
APP WIDGETS
NEWS AND MAGAZINES
SOCIAL
TRAVEL AND LOCAL
PRODUCTIVITY
LIFESTYLE
TRANSPORTATION
SPORTS GAMES
MEDICAL
HEALTH AND FITNESS
MEDIA AND VIDEO
TOOLS
MUSIC AND AUDIO
PHOTOGRAPHY
ENTERTAINMENT
BOOKS AND REFERENCE
EDUCATION
COMICS
PERSONALIZATION
CARDS
GAME WIDGETS
ARCADE
LIBRARIES AND DEMO
GAME WALLPAPER
BRAIN
GAME
SPORTS
CASUAL
APP WALLPAPER
RACING

4,314
1,102
4,821
2,756
3,380
3,161
1,994
2,889
2,826
1,923
2,243
1,634
2,023
1,478
1,795
1,079
1,110
1,053
1,008
973
924
1,753
390
440
360
302
390
302
242
396
302
209
267
187
82

61.52%
46.18%
50.90%
53.83%
51.80%
51.22%
47.38%
52.62%
49.00%
45.45%
43.29%
39.00%
41.70%
40.04%
39.56%
37.15%
36.36%
37.20%
26.65%
27.71%
26.80%
20.68%
16.60%
16.23%
14.20%
13.25%
12.22%
10.84%
11.00%
10.60%
9.82%
10.22%
9.60%
6.25%
4.60%

30.59%

1,112
1,086
1,106
439
1,605
816
529
555
1,494
394
853
750
509
302
344
170
252
219
205
249
213
461
84
77
40
17
66
89
21
102
53
26
23
34
16

38.28%
59.24%
33.47%
21.77%
37.00%
31.43%
34.68%
27.42%
41.16%
18.59%
28.66%
28.60%
22.67%
15.49%
15.06%
13.05%
16.16%
11.40%
9.82%
9.24%
9.80%
9.84%
4.00%
3.85%
3.20%
2.01%
3.61%
3.61%
2.00%
4.00%
3.81%
1.40%
2.60%
2.42%
0.40%

14,311

16.26%

399
32

1,815
213
609
352
133
146
452
113
341
273
151
169
165
72
121
91
122
215
156
83
69
32
58
56
24
136
55
71
16
15
10
20
20

6,805

18.04%
3.01%
30.46%
14.31%
24.80%
15.71%
12.50%
8.27%
16.87%
9.29%
14.03%
11.00%
6.68%
7.04%
8.43%
3.61%
8.08%
3.20%
5.21%
5.62%
5.60%
5.02%
3.00%
1.83%
4.60%
4.42%
0.80%
3.01%
4.20%
2.20%
0.80%
0.80%
0.40%
1.61%
0.60%

5,825
2,220
7,742
3,408
5,594
4,329
2,656
3,590
4,772
2,430
3,437
2,657
2,683
1,949
2,304
1,321
1,483
1,363
1,335
1,437
1,293
2,297
543
549
458
375
480
527
318
569
371
250
300
241
118

62.73%
62.45%
55.31%
55.24%
54.60%
54.08%
54.03%
54.03%
52.21%
48.69%
45.29%
44.60%
43.32%
40.24%
39.96%
38.55%
38.38%
38.00%
28.46%
28.31%
27.40%
21.69%
17.20%
16.43%
15.80%
13.45%
12.42%
11.24%
11.00%
10.80%
10.22%
10.22%
9.60%
6.65%
4.60%

7.57%

71,224

35.46%

Account Credentials & User Proﬁle
#element

%app

Location

Financial

Total

#element

%app

#element

%app

#element

%app

TOTAL

50,108

Table 4: UIP data distribution. #element denotes the number of UIP data elements in each category by different privacy
type. %app denotes the percentage of apps in which these elements appear (500 per category). The last column shows
the total number of UIP data elements and apps that contain UIP data.

Privacy Category

Android System Deﬁned APIs

Account Credentials

& User Proﬁle

android.tel...TelephonyManager getLine1Number()
android.accounts.AccountManager getAccounts()

Location

and...LocationManager getLastKnownLocation()
android.location.Location: getLongitude()
android.location.Location: getLatitude()

Table 6: System deﬁned sensitive APIs related to
UIPicker’s identiﬁcation scope

such as phonenumber, account and location can be regu-
lated by ﬁxed system APIs which we list in Table 6. We
compare the amount of UIPicker’s identiﬁcation results
with Android system derived sensitive data, which can
help us understand to what extent, system deﬁned sensi-
tive APIs are insufﬁcient to cover users’ privacy.

As Table 5 shows, in our dataset, 4,900 apps use sys-
tem deﬁned APIs for requesting Account Credentials
and Proﬁle Information while UIPicker identiﬁes 5,330
(30.59%) apps containing UIP. UIPicker identiﬁes 2,883
(16.26%) apps in the whole dataset that request location

privacy data from user inputs. Besides, 1,318 (7.57%)
apps request ﬁnancial privacy data from users, and none
of system deﬁned APIs can regulate such data. In gen-
eral, UIPicker identiﬁes 6,179 (35.46%) apps contain-
ing at least one category of UIP data, which have been
largely neglected by previous work in privacy security
analysis and protection.

As Column 4 in Table 5 shows, there is some overlap
between system deﬁned APIs and UIP data (1,340 for
Account Credentials & User Proﬁle, 2,282 for Location
respectively). For each app, we check whether it contains
both the system deﬁned APIs and the UIP data in the
same privacy category, e.g., invoking the getLastKnown-
Location() API and requesting address information from
the user input of the same app. In some cases, the same
piece data may come from either UI input or API call.
For example, using a phone number as the login account
of the app. However in most cases, the overlapped data
in the same privacy category may come from different
sources without overlapping in code paths. For example,
the invocation of get-location APIs is used for realtime
geographic locating, while some location input could be

USENIX Association  

24th USENIX Security Symposium  1003

11

Privacy Category

Account Credentials
& User Proﬁle
Location
Financial
Total

System Deﬁned APIs (#Apps)
UIPicker Overlap

API

Elements with Sensitive Attribute Values (#Elements)
InputType UIPicker

Incremental

4,900

5,330

1,340

24,021

46,227

15,221

-

15,632

2,883
1,318
6,179

2,282

-
-

941

-

24,962

14,311
6,353
71,224

26,087

13,370

-

46,262

Table 5: We compare UIPicker’s identiﬁcation results with apps containing system deﬁned sensitive APIs (column
2-4) and elements containing sensitive attribute values (column 5-7).

a shopping address for delivering goods. Since precisely
analyzing which input element may overlap with system
deﬁned APIs requires additional information-ﬂow anal-
ysis, which is beyond this paper’s scope, we leave it as
future work for measuring the relationship between these
two types of sensitive data.

Comparing to sensitive attribute values.

In Sec-
tion 4.3, we use elements containing sensitive attribute
values as part of training data for our identiﬁcation mod-
ule. However, they can only cover a portion of UIP data
because they are not intended for this purpose. Here
we compare the amount of UIPicker’s identiﬁcation re-
sults with elements containing sensitive attribute values
to show the effectiveness of UIPicker.

As Table 5 shows,

in general, UIPicker identiﬁes
46,262 more UIP data elements than simply identifying
them by sensitive attribute values (e.g.
textPassword).
Especially for the Location category, UIPicker identiﬁes
14,311 elements, which is nearly 15 times more than
simply identifying them based on attribute “textPostal-
Address”.

Types of UIP Elements. We list the identiﬁcation results
of UIP data elements other than EditText in Table 7. In
general, UIPicker ﬁnds 18,403 (25.84%) elements other
than EditText to accept users’ sensitive inputs. It is inter-
esting to note that UIPicker also ﬁnds a large portion of
TextView as UIP data elements. In most cases, although
data in TextViews are not editable, they could be gener-
ated by users from other layouts and dynamically ﬁlled
in TextView later. For example, the data from previous
steps of a registration form, or fetched from the server
after users’ login. There are 5,075 (7.13%) customized
input elements and 1,962 (2.75%) dropdown lists (Spin-
ners) containing UIP data. Type “Others” in table con-
tains elements such as RadioButton, CheckBox.

7.3 Precision

For evaluating the precision of UIPicker, we perform
the evaluation of classiﬁer based on the machine-leaning
dataset mentioned in Section 4. We also conduct a man-
ual validation for two reasons. First, since the training

Type

# Elements % in UIP Data

TextView
Customized
Spinner
Others
Total

10,582
5,075
1,962
784

18,403

14.86%
7.13%
2.75%
1.10%
25.84%

Table 7: Types of UIP Elements Other than EditText

data of classiﬁer is not absolutely randomly selected (part
of them are labeled by sensitive attributes automatically),
a manual validation is required to conﬁrm that the iden-
tiﬁcation results of the classiﬁer carries over the entire
dataset. Second, the classiﬁer is only capable of distin-
guishing UIP data elements from their textual semantics,
the manual validation can be used to check whether static
text labels are effectively excluded by UIPicker after be-
haviour based result ﬁltering.

Evaluation of Classiﬁer. The training set contains
53,094 elements in total, which includes 24,962 labeled
by sensitive attribute values and ﬁnancial-related ele-
ments, with 25,331 negative samples labeled by manual
efforts.

We use ten-fold cross validation which is the standard
approach for evaluating machine-learning classiﬁers. We
randomly partition the entire set of sample elements into
10 subsets, and we train the classiﬁer on nine of them and
then test the remaining 1 subset. The process is repeated
on each subset for 10 times. In the end, the average pre-
cision and recall is 92.5% and 85.43% respectively.

As shown in Table 8, we also compare the average
precision and recall with other two classiﬁers, i.e., One-
Class Support Vector Machine learning (OC-SVM) [32]
and Naive Bayes [30]. The results show that the stan-
dard SVM performs the best. We tried OC-SVM with
only positive samples (elements containing sensitive at-
tributes) to train the classiﬁer. OC-SVM generated more
false negatives than the standard SVM due to the lack
of negative samples. Naive Bayes, a traditional proba-
bilistic learning algorithm, also produced very imprecise
results. This happens especially when it deals with ele-

1004  24th USENIX Security Symposium 

USENIX Association

12

ments that contain low-frequency privacy-related texts.

Classiﬁer

Avg.Precision Avg.Recall

SVM

OC-SVM

Naive Bayes

92.50%
93.74%
95.42%

85.43%
68.48%
26.70%

Table 8: Classiﬁer Comparison

Manual Validation. We envision UIPicker to be used as
an automated approach for labeling elements that con-
tain UIP data. UIPicker achieves this by using some eas-
ily available UIP data (elements containing sensitive at-
tributes or hand-annotated) and then using the classiﬁer
to automatically explore larger parts of UIP data. Mea-
suring precision is hard in this setting as there is no entire
pre-annotated elements (labeling sensitive or insensitive
for all of them) for a set of apps that could compare with
UIPicker’s identiﬁcation results.

As a best-effort solution, we randomly select 200 apps
from top 10 categories (20 in each) ordered by %apps
which UIP data appear most in Table 4 as the man-
ual validation dataset. As such categories may contain
much more UIP data than others, it provides the oppor-
tunity that our experts can walk through less apps (and
activities) to validate more UIP elements. The selected
apps are excluded from the classiﬁer’s training process
to avoid overlap. Such way can greatly improve the ef-
fectiveness of the manual validation. Since the subset of
apps is randomly picked, we believe that the evaluation
results can provide a reasonable accuracy estimation on
the entire dataset. For each element that UIPicker iden-
tiﬁes as UIP data, we check their corresponding descrip-
tions in XML layout ﬁles with some automated python
scripts for efﬁciency (quickly locating the element in lay-
out ﬁles and trying to understand it from descriptions).
If this is still insufﬁcient for us to identify whether it is a
UIP data element, we conﬁrm them by launching the app
and ﬁnd the element in the layout screen. The manual
validation over 200 apps shows that UIPicker identiﬁes
975 UIP data elements with 67 false positives and 107
false negatives.

False Positives: The false positive rate is 6.4%
(67/1042 elements UIPicker identiﬁes). In most cases,
this is caused by the element’s neighbors. That is, the
element’s neighbors contain privacy-related texts while
the element itself is not privacy-related. Consider the
following example, an EditText with only one description
“message” while its previous element requires the user to
input username with many sensitive textual phrases. As
UIPicker takes neighbor elements’ texts into considera-
tion for better identiﬁcation results, the privacy-related
texts in its neighbor make UIPicker falsely identify the

current element as UIP data. We consider such false
alarm as acceptable because once such false alarm hap-
pens, their neighbor elements (the actual UIP data ele-
ments) are very possible to be identiﬁed by UIPicker as
well.

False Negatives: We manually inspect each app in the
evaluation dataset by traversing their UI screens as much
as possible to see whether there exists UIP data elements
that missed by UIPicker. In 200 apps, we ﬁnd 107 ele-
ments not identiﬁed by UIPicker as privacy-related, and
we conclude the reasons as follows: (1) Some very low-
frequency texts representing UIP were not inferred from
UIPicker by the privacy-related text analysis module.
For example, “CVV” represents the credit card’s security
code, however we ﬁnd this only happened in 4 Chinese
apps. The low occurrence frequency of texts like “CVV”
in our croups makes UIPicker fail to add them as fea-
tures for the identiﬁcation process. (2) In static analysis
for behavior-based element ﬁltering, due to FlowDroid’s
limitations, the call trace of some element was broken
in inter-procedural analysis which makes UIPicker miss
such elements in the ﬁnal output.

Based on the total number of TPs, FPs and FNs
(975, 67, 107), we compute the precision and recall of
UIPicker as follows:

Precision =

T P

T P + FP

Recall =

T P

T P + FN

Overall, UIPicker precisely identiﬁed most of UIP

data, with 93.6% precision and 90.1% recall.

7.4 Runtime Enhancement Evaluation

System Overhead. We compare the performance over-
head with TaintDroid using Antutu Benchmark [3]. We
run Antutu 10 times in both systems under a Nexus Prime
device, and the average scores are basically the same.
This is reasonable because our mechanism only provides
additional UIP data sources. We conclude that the secu-
rity enhancement mechanism does not introduce notice-
able additional performance overhead to TaintDroid.

Case Study. We ﬁnd that some critical UIP data are
under threats in Android apps.
In Figure 7, a popu-
lar travel app “Qunar”, which has 37 million downloads
in China [12], sends users’ credit card information with
vulnerable SSL implementation during the payment pro-
cess. The insecure transmission is reported to the user
with a pop-up window when such data leave the device,
thus the user can decide whether to proceed or use an
alternative payment method to avoid the security risk.

USENIX Association  

24th USENIX Security Symposium  1005

13

9 RELATED WORK

Privacy source identiﬁcation. Existing work [16, 29]
focuses on mapping Android system permissions with
API calls. PScout [16] proposes a version-independent
analysis tool for complete permission-to-API mapping
through static analysis. SUSI [29] uses a machine learn-
ing approach to classify and categorize more Android
sources and sinks which are missed by previous info-
ﬂow taint tracking systems. The most similar work with
UIPicker is SUPOR [25], which also aims to automat-
ically identify sensitive user inputs using UI rendering,
geometrical layout analysis and NLP techniques. SU-
PER mainly focuses on speciﬁc type of UI elements
(EditText) while UIPicker is not limited to this.

Text analysis in Android app. Several studies utilize
UI text analysis for different security proposes. As-
Droid [24] detects stealthy behaviors in Android app by
UI textual semantics and program behavior contradic-
tion. However, it only uses a few keywords to cover
sensitive operations such as “send sms”, “call phone”.
CHABADA [21] checks application behaviors against
application descriptions.
It groups apps that are sim-
ilar with each other according to their text descrip-
tions. The machine learning classiﬁer OC-SVM is used
in CHABADA to identify apps whose used APIs dif-
fer from the common use of the APIs within the same
group. Whyper [37] uses natural language processing
(NLP) techniques to identify sentences that describe the
need for a given permission in the app description.
It
uses Stanford Parser to extract short phrases and de-
pendency relation characters from app descriptions and
API documents related to permissions. AutoCog [28]
improves Whyper’s precision and coverage through a
learning-based algorithm to relate descriptions with per-
missions. UIPicker could potentially leverage their tech-
niques to generate more complete privacy-related texts
for UIP data identiﬁcation.

Static analysis. There are lots of work [24, 26, 15, 20,
34] on using static analysis to detect privacy leakage,
malware or vulnerabilities in Android apps. AsDroid
takes control ﬂow graphs and call graphs to search in-
tent from API call sites to top level functions (Activi-
ties). UIPicker’s behavior-based result ﬁltering is sim-
ilar to AsDroid while they have different goals. SMV-
HUNTER [34] uses static analysis to detect possible
MITM vulnerabilities in large scale. The static analy-
sis extracts input information from layout ﬁles and iden-
tiﬁes vulnerable entry points from the application pro-
gram code, which can be used to guide dynamic testing
for triggering the vulnerable code.

Figure 7: Insecure Transmission of UIP data. We use
faked sensitive data in the experiment.

8 Discussion

In this section, we discuss the general applicability of
UIPicker, as well as limitations and future work.

UIPicker is able to efﬁciently handle UIP data which
previous work does not concentrate on, nor be able to
cover. Compared with existing approaches that focus on
System-Centric Privacy data, UIPicker rethinks privacy
from a new perspective: sensitive data generated from
user inputs, which is largely neglected for a long period.
UIPicker provides an opportunity for users to make in-
formed decisions in a timely manner when sensitive data
leave the device insecurely, instead of letting users as-
sume the app can be trusted.

UIPicker uses not only texts in UI screens but also
texts in layout descriptions for UIP data identiﬁcation.
This framework is generic to all kinds of apps without lo-
cality limitation. The way UIPicker correlates UIP data
from layout descriptions could also be leveraged by ex-
isting work [37, 28] that attempts to map the permission
usage with app descriptions.

UIPicker has the following limitations. (1) UIPicker
does not consider dynamically generated UI elements,
although we have not found any UIP data element be-
ing generated at runtime in our experiments. Dynamic
UI elements could be analyzed through more sophis-
ticated static/dynamic analysis with the app’s program
code, which is our future work. (2) Currently, UIPicker
can not handle sensitive user inputs in Webview because
they are not included in app layout resources. In the fu-
ture, we plan to download such webpages by extracting
their URLs from the app, then analyze their text contents
as well.

1006  24th USENIX Security Symposium 

USENIX Association

14

10 CONCLUSION

In this paper, we propose UIPicker, a novel framework
for identifying UIP data in large scale based on a novel
combination of natural language processing, machine
learning and program analysis techniques. UIPicker
takes layout resources and program code to train a pre-
cise model for UIP data identiﬁcation, which overcomes
existing challenges with both good precision and cover-
age. With the sensitive elements identiﬁed by UIPicker,
we also propose a runtime security enhancement mech-
anism to monitoring their sensitive inputs and provide
warnings when such data insecurely leave the device.
Our evaluation shows that UIPicker achieves 93.6% pre-
cision and 90.1% recall with manual validation on 200
popular apps. Our measurement in 17,425 top free apps
shows that UIP data are largely distributed in market
apps and our run-time monitoring mechanism based on
UIPicker can effectively help user to protect such data.

Acknowledgements

We thank the anonymous reviewers and our shepherd
Franziska Roesner for their insightful comments that
helped improve the quality of the paper. We also thank
Cheetah Mobile Inc.
(NYSE:CMCM), Antiy labs, Li
Tan and Yifei Wu for their assistance in our experiments.
This work is funded in part by the National Program
on Key Basic Research (NO. 2015CB358800), the Na-
tional Natural Science Foundation of China (61300027,
61103078, 61170094), and the Science and Technology
Commission of Shanghai Municipality (13511504402
and 13JC1400800). The TAMU author is supported in
part by the National Science Foundation (NSF) under
Grant 0954096 and the Air Force Ofﬁce of Scientiﬁc Re-
search (AFOSR) under FA-9550-13-1-0077. Also the
IU author is supported in part by the NSF (1117106,
1223477 and 1223495). Any opinions, ﬁndings, and con-
clusions expressed in this material do not necessarily re-
ﬂect the views of the funding agencies.

References

[1] Amazon online store. https://goo.gl/jYdVPr.

[2] Android-apktool. https://goo.gl/UgmPXp.

[3] Antutu benchmark. https://goo.gl/78W9xL.

[4] Av-comparatives : Mobile security review - september 2014.

http://goo.gl/JfmcYh.

[5] Bank

users
http://goo.gl/PWcqUy.

app

warned

over

android

security.

[6] Cm security :

A peek into 2014’s mobile

security.

http://goo.gl/i58ihW.

[7] Google bouncer. http://goo.gl/ET4JDW.

[8] Monkeyrunner. http://goo.gl/AQsIQu.

[9] Natural language toolkit. http://goo.gl/qzWulA.

[10] Phishing attack replaces android banking apps with malware.

http://goo.gl/cJqqyX.

[11] Python implementations of various

stemming algorithms.

https://goo.gl/kdxkqv.

[12] Qunaer 7.3.8. http://goo.gl/1vB2k7.

[13] scikit-learn. http://goo.gl/mBzGUZ.

[14] Wordnet, a lexical database for english. http://goo.gl/KwzO0r.

[15] ARZT, S., RASTHOFER, S., FRITZ, C., BODDEN, E., BARTEL,
A., KLEIN, J., LE TRAON, Y., OCTEAU, D., AND MCDANIEL,
P. Flowdroid: Precise context, ﬂow, ﬁeld, object-sensitive and
lifecycle-aware taint analysis for android apps. In Proceedings of
the 35th ACM SIGPLAN Conference on Programming Language
Design and Implementation (2014), ACM, p. 29.

[16] AU, K. W. Y., ZHOU, Y. F., HUANG, Z., AND LIE, D. Pscout:
analyzing the android permission speciﬁcation.
In Proceedings
of the 2012 ACM conference on Computer and communications
security (2012), ACM, pp. 217–228.

[17] BUGIEL, S., DAVI, L., DMITRIENKO, A., FISCHER, T.,
SADEGHI, A.-R., AND SHASTRY, B. Towards taming privilege-
escalation attacks on android. In NDSS (2012).

[18] CHEN, Q. A., QIAN, Z., AND MAO, Z. M. Peeking into
your app without actually seeing it: Ui state inference and novel
android attacks.
In Proc. 23rd USENIX Security Symposium
(SEC14), USENIX Association (2014).

[19] ENCK, W., GILBERT, P., CHUN, B.-G., COX, L. P., JUNG, J.,
MCDANIEL, P., AND SHETH, A. N. Taintdroid: an information
ﬂow tracking system for real-time privacy monitoring on smart-
phones. vol. 57, ACM, pp. 99–106.

[20] FAHL, S., HARBACH, M., MUDERS, T., BAUMG ¨ARTNER, L.,
FREISLEBEN, B., AND SMITH, M. Why eve and mallory love
android: an analysis of android ssl (in)security. In Proceedings
of the 2012 ACM SIGSAC Conference on Computer & Commu-
nications Security(CCS) (2012).

[21] GORLA, A., TAVECCHIA, I., GROSS, F., AND ZELLER, A.
Checking app behavior against app descriptions. In ICSE (2014),
pp. 1025–1035.

[22] HEUSER, S., NADKARNI, A., ENCK, W., AND SADEGHI, A.-
R. Asm: A programmable interface for extending android secu-
rity. In Proc. 23rd USENIX Security Symposium (SEC14) (2014).

[23] HORNYACK, P., HAN, S., JUNG, J., SCHECHTER, S., AND
WETHERALL, D. These arent the droids youre looking for.
Retroﬁtting Android to Protect Data from Imperious Applica-
tions. In: CCS (2011).

[24] HUANG, J., ZHANG, X., TAN, L., WANG, P., AND LIANG,
B. Asdroid: detecting stealthy behaviors in android applications
by user interface and program behavior contradiction.
In ICSE
(2014), pp. 1036–1046.

[25] JIANJUN HUANG, PURDUE UNIVERSITY; ZHICHUN LI, X. X.,
AND WU, Z. Supor: Precise and scalable sensitive user input
detection for android apps.
In Proc. of 24rd USENIX Security
Symposium (2015).

[26] LU, L., LI, Z., WU, Z., LEE, W., AND JIANG, G. Chex: stat-
ically vetting android apps for component hijacking vulnerabili-
ties. In Proceedings of the 2012 ACM conference on Computer
and communications security (2012), ACM, pp. 229–240.

[27] NAUMAN, M., KHAN, S., AND ZHANG, X. Apex: extend-
ing android permission model and enforcement with user-deﬁned
runtime constraints. In Proceedings of the 5th ACM Symposium
on Information, Computer and Communications Security (2010),
ACM, pp. 328–332.

USENIX Association  

24th USENIX Security Symposium  1007

15

[28] QU, Z., RASTOGI, V., ZHANG, X., CHEN, Y., ZHU, T., AND
CHEN, Z. Autocog: Measuring the description-to-permission
ﬁdelity in android applications. In Proceedings of the 2014 ACM
SIGSAC Conference on Computer and Communications Security
(2014), ACM, pp. 1354–1365.

[29] RASTHOFER, S., ARZT, S., AND BODDEN, E. A machine-
learning approach for classifying and categorizing android
sources and sinks. In 2014 Network and Distributed System Se-
curity Symposium (NDSS) (2014).

[30] RISH, I. An empirical study of the naive bayes classiﬁer.

In
IJCAI 2001 workshop on empirical methods in artiﬁcial intelli-
gence (2001), vol. 3, IBM New York, pp. 41–46.

[31] SALTON, G., WONG, A., AND YANG, C.-S. A vector space
model for automatic indexing. Communications of the ACM 18,
11 (1975), 613–620.

[32] SCH ¨OLKOPF, B., PLATT, J. C., SHAWE-TAYLOR, J., SMOLA,
A. J., AND WILLIAMSON, R. C. Estimating the support of a
high-dimensional distribution. Neural computation 13, 7 (2001),
1443–1471.

[33] SMALLEY, S., AND CRAIG, R. Security enhanced (se) android:
Bringing ﬂexible mac to android. In The 20th Annual Network
and Distributed System Security (NDSS) (2013).

[34] SOUNTHIRARAJ, D., SAHS, J., GREENWOOD, G., LIN, Z.,
AND KHAN, L. Smv-hunter: Large scale, automated detection
of ssl/tls man-in-the-middle vulnerabilities in android apps.
In
Proceedings of the 19th Network and Distributed System Secu-
rity Symposium. San Diego, California, USA (2014).

[35] SPYNS, P. Natural language processing. Methods of information

in medicine 35, 4 (1996), 285–301.

[36] WEI, F., ROY, S., OU, X., ET AL. Amandroid: A precise and
general inter-component data ﬂow analysis framework for secu-
rity vetting of android apps.
In Proceedings of the 2014 ACM
SIGSAC Conference on Computer and Communications Security
(2014), ACM, pp. 1329–1341.

[37] XU, R., SADI, H., AND ANDERSON, R. Whyper: Towards au-
tomating risk assessment of mobile applications. In USENIX Se-
curity Symposium (2013), pp. 539–552.

[38] XU, R., SA¨IDI, H., AND ANDERSON, R. Aurasium: Practical
policy enforcement for android applications. In USENIX Security
Symposium (2012), pp. 539–552.

[39] YANG, Y., AND PEDERSEN, J. O. A comparative study on fea-
In ICML (1997), vol. 97,

ture selection in text categorization.
pp. 412–420.

[40] YANG, Z., YANG, M., ZHANG, Y., GU, G., NING, P., AND
WANG, X. S. Appintent: Analyzing sensitive data transmission
in android for privacy leakage detection.
In Proceedings of the
2013 ACM SIGSAC conference on Computer & communications
security (2013), ACM, pp. 1043–1054.

[41] ZHANG, Y., YANG, M., XU, B., YANG, Z., GU, G., NING, P.,
WANG, X. S., AND ZANG, B. Vetting undesirable behaviors in
android apps with permission use analysis. In Proceedings of the
2013 ACM SIGSAC conference on Computer & communications
security (2013), ACM, pp. 611–622.

[42] ZHOU, Y., AND JIANG, X. Detecting passive content leaks and
In The 20th Annual Network

pollution in android applications.
and Distributed System Security (NDSS) (2013).

[43] ZHOU, Y., SINGH, K., AND JIANG, X. Owner-centric protection
of unstructured data on smartphones. In Trust and Trustworthy
Computing (2014), Springer, pp. 55–73.

1008  24th USENIX Security Symposium 

USENIX Association

16

