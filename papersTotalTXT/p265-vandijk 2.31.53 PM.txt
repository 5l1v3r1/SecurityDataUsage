Hourglass Schemes:

How to Prove that Cloud Files Are Encrypted

Marten van Dijk
RSA Laboratories
Cambridge MA

marten.vandijk@rsa.com

Ari Juels

RSA Laboratories
Cambridge MA

ari.juels@rsa.com

Ronald L. Rivest

MIT

Cambridge MA
rivest@mit.edu

Emil Stefanov

UC Berkeley
Berkeley CA

emil@berkeley.edu

Alina Oprea

RSA Laboratories
Cambridge MA

alina.oprea@rsa.com
Nikos Triandopoulos

RSA Laboratories
Cambridge MA

nikolaos.triandopoulos@rsa.com

ABSTRACT
We consider the following challenge: How can a cloud storage
provider prove to a tenant that it’s encrypting ﬁles at rest,
when the provider itself holds the corresponding encryption
keys? Such proofs demonstrate sound encryption policies
and ﬁle conﬁdentiality. (Cheating, cost-cutting, or miscon-
ﬁgured providers may bypass the computation/management
burdens of encryption and store plaintext only.)

To address this problem, we propose hourglass schemes,
protocols that prove correct encryption of ﬁles at rest by im-
posing a resource requirement (e.g., time, storage or compu-
tation) on the process of translating ﬁles from one encoding
domain (i.e., plaintext) to a diﬀerent, target domain (i.e.,
ciphertext). Our more practical hourglass schemes exploit
common cloud infrastructure characteristics, such as limited
ﬁle-system parallelism and the use of rotational hard drives
for at-rest ﬁles. For ﬁles of modest size, we describe an hour-
glass scheme that exploits trapdoor one-way permutations
to prove correct ﬁle encryption whatever the underlying stor-
age medium.

We also experimentally validate the practicality of our
proposed schemes, the fastest of which incurs minimal over-
head beyond the cost of encryption. As we show, hourglass
schemes can be used to verify properties other than correct
encryption, e.g., embedding of “provenance tags” in ﬁles for
tracing the source of leaked ﬁles. Of course, even if a provider
is correctly storing a ﬁle as ciphertext, it could also store a
plaintext copy to service tenant requests more eﬃciently.
Hourglass schemes cannot guarantee ciphertext-only stor-
age, a problem inherent when the cloud manages keys. By
means of experiments in Amazon EC2, however, we demon-
strate that hourglass schemes provide strong incentives for
economically rational cloud providers against storage of ex-
tra plaintext ﬁle copies.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

Categories and Subject Descriptors
C.2.4 [Communication Networks]: Distributed Systems—
Client/server ; E.3 [Data Encryption]; H.3.2 [Information
Storage and Retrieval]: Information Storage—File orga-
nization

General Terms
Algorithms, Security, Theory, Veriﬁcation

Keywords
cloud storage security, cloud auditing, challenge-response
protocol, economic security model

1.

INTRODUCTION

Uncontrolled data leakage is an enormous problem today.
It costs the industry billions of dollars of damage each year
and attracts signiﬁcant media attention with high-proﬁle in-
cidents such as [2, 20]. This problem is further ampliﬁed as
cloud storage becomes increasingly popular. Cloud data is
often subject to a larger number of attack vectors and the
responsibility of securely managing this data is split across
multiple parties.

Today’s cloud providers implement complex distributed
storage and caching systems, but usually oﬀer this service
as a simple API for their tenants. A negative side-eﬀect is
that these cloud storage APIs do not provide tenants with
the necessary degree of transparency for them to verify that
data is properly secured, e.g., via encryption. They simply
have to trust that the cloud provider is “doing the right
thing.” Unfortunately, history has demonstrated that parties
often overlook even basic security measures without strong
up-front motivation [1]. It is only after a serious incident oc-
curs, that security measures are implemented, but even then
it is not possible for users to verify that they were imple-
mented correctly because such security measures typically
lack visibility.

To strongly protect against unauthorized access or disclo-
sure, one option is for clients to always encrypt their data
before uploading it to the cloud and decrypt it on-the-ﬂy
when needed, using their own keys that are kept secret from
the cloud. While this option may work for some scenarios,
it is too restrictive in many other cases as it undermines
much of the beneﬁt of outsourcing to the cloud. Clouds are

265often used for more than just plain storage: To provide more
essential services, it’s very common for clouds to require ac-
cess to the unencrypted data (e.g., for processing the data
or simply furnishing it as plaintext to authorized users).

This then necessitates that data encryption is enforced by
the cloud provider itself. Knowing the encryption/decryption
keys enables the provider to oﬀer services of better func-
tionality and also minimizes the security burden on tenants
that lack security sophistication. But as cloud providers now
assume responsibility for data conﬁdentiality they must al-
ways keep data at rest encrypted, and protect the encryption
keys. However, such data-management cloud services are of-
ten proprietary software developed by the providers them-
selves, thus lacking the necessary transparency for tenants to
verify that their private data is handled securely. This ren-
ders the above cloud-centric approach preferable in terms
of usability, but at the same time less desirable in terms of
trustworthiness as it only provides the promise but no guar-
antees for data protection. There is no assurance that cloud
data will not leak.

In such settings of cloud-managed encrypted data, it seems
that very little can be done to provide transparency to ten-
ants about the correct handling by the cloud providers of
their own sensitive data.

In this paper, we demonstrate that this is actually not
the case. In fact, it is possible to design a storage pro-
tocol that imposes a strong economical incentive onto the
cloud provider to store data securely encrypted at rest. With
our protocol, tenants can remotely verify that data in the
cloud is encrypted at rest. We ensure that a negligent cloud
provider that wishes to store the data unencrypted has a
much higher operating cost: Essentially, this provider will
need to double its storage capacity and the underlying in-
frastructure that provides access to that storage in order to
pass the veriﬁcation protocol.

In particular, we present a general framework for econom-
ically motivating a cloud provider to transform and store
data F outsourced by a tenant into a particular encoding G
of tenant’s choice. To achieve this we introduce a new prim-
itive that we call an hourglass scheme that essentially seals
the data immediately after the data has been encoded in the
format requested by the tenant. This sealing is performed by
applying a special transformation that we call an hourglass
function over the encoded format G to get an encapsulation
of it in a new format H that is ﬁnally stored by the provider.
Our framework includes a challenge-response protocol that
a tenant can use to verify that the cloud provider is storing
the data with this desired particular encoding G and hour-
glass function applied to it (i.e., format H). This function is
speciﬁcally designed to ensure that the cloud provider can-
not apply a subsequent encoding of their choice to reverse
the initial one (i.e., format G). The hourglass function is
also designed to impose signiﬁcant resource constraints—
and hence an economical disincentive—on a cloud provider
that tries to apply the encoding and hourglass functions on
demand (on the raw data F ) when the client initiates the
challenge-response veriﬁcation protocol.

Speciﬁcally, we are able to show that under the assump-
tion that cloud providers are economically rational, our hour-
glass schemes provide strong disincentives for direct leakage
of “raw” data through a double storage dilemma. Given that
an hourglass scheme is in use to verify correct encryption of
data at rest at all times, retention of encrypted data only is

the rational strategy for economically motivated providers.
Indeed, an economically rational provider who wishes to also
store unencrypted data needs to essentially double its stor-
age cost. We actually experimentally demonstrate that in
many settings of interest, it is less expensive for a provider
to comply fully with an hourglass scheme and store only
encrypted data than to cheat and store an additional, un-
ecrypted copy of the data.
Contributions. Overall, our work has several contributions,
both theoretical and practical:

• We are among the ﬁrst to explore economic security
models for cloud services that provide incentives to
cloud providers to implement security measures cor-
rectly.

• We introduce hourglass schemes as a new solution con-
cept for ensuring that cloud-managed data is securely
protected via encryption and formalize a general frame-
work for the design of a class of such schemes.

• We propose several concrete hourglass schemes that
impose a strong economic incentive on cloud storage
providers to store data properly encrypted at rest.

• We extend our constructions to incentivize the cloud
provider to embed watermarks in data ﬁles so that the
origin of a data leak can be traced back.

• We implement our constructions and experimentally
quantify the monetary cost induced on a misbehaving
or negligent cloud provider.

Paper organization. We introduce hourglass schemes and
present our new framework in Section 2. Our main protocol
is presented in Section 3 and is general enough to support
multiple kinds of hourglass and encoding functions, lend-
ing itself to a generic method for the design of hourglass
schemes. In Section 4, we describe three speciﬁc hourglass
functions that we call the butterﬂy, permutation and RSA
constructions, where the ﬁrst two are time-based imposing
resource constraints on a misbehaving cloud provider that
are related to storage access time whereas the third im-
poses constraints related to computation, and we present
their security properties. In Section 5, we explore the eﬀec-
tiveness of our hourglass schemes against an economically
motivated cloud provider and validate our economic argu-
ments experimentally by implementing our two time-based
hourglass schemes in Amazon’s EC2 service. Finally, we re-
view related work in Section 6 and conclude in Section 7.
Additional technical materials on our formal security model
and protocols for proving correct encoding appear in the
Appendix. This extended abstract omits proofs of security
which appear in the full version of our paper.

2. GENERAL FRAMEWORK

The overall goal of our paper is to strongly motivate cloud
providers to properly protect client data to minimize the
damage when an accidental data leakage occurs. We achieve
this through a general framework that involves the design
of protocols that ensure that client data is stored at rest in
an encoding of client’s choice. Example encodings supported
by our framework include encryption of data with keys man-
aged by the cloud provider, and encoding with an embedded

266watermark that enables tracking back the origin of a data
leak. Both of these provide protection against data leakage.
To elaborate: encryption of data at rest preserves conﬁden-
tiality in case of accidental data leakage; watermarked en-
coding reveals the source of data leakage (more speciﬁcally,
the identity of the cloud provider), further incentivizing the
cloud provider to strongly protect data and implement se-
curity measures correctly.

Our framework introduces a new solution concept for en-
suring that cloud data resides in a given correct and desired
format. It enables the client to specify an encoding of its
choice and then remotely verify using an eﬃcient challenge-
response protocol that its data is stored at rest in the cloud
in the desired format. Since the cloud provider in our setting
has access to raw data, it can also store (parts of) unencoded
data. While we can not completely prevent this situation,
our framework provides strong economic incentives for the
cloud provider to store data only in the encoded format: A
misbehaving cloud provider storing raw data would have to
double its storage cost in order to reply correctly to client
challenges.

To illustrate the challenges of building a framework with
these requirements, consider the problem of verifying that
a certain ﬁle F is stored in an encrypted format G by the
cloud provider—the main use case in this paper. The client
might challenge the cloud provider for some randomly se-
lected blocks of the encrypted ﬁle G (or even the full en-
crypted ﬁle G). Demonstrating knowledge of G by itself
does not prove that G is stored by the cloud provider. In-
deed, the cloud provider could store the plaintext ﬁle F ,
and compute the encryption G on-the-ﬂy when challenged
by the client! For most symmetric-key encryption schemes
(e.g., block-chaining modes of a block cipher), encryption is
a fast operation, and thus on-the-ﬂy computation is feasible.

2.1 Solution overview

To overcome these challenges, we propose that an addi-
tional transformation, called an hourglass function, is ap-
plied to the encrypted ﬁle G to get an hourglass format
H that encapsulates G, and that the client challenges the
provider on this new ﬁle format H.

An hourglass is an ancient timetelling device. It consists
of two glass bulbs connected by a narrow neck and partially
ﬁlled with sand. In order for sand accumulated in one half
to move to the other, it must pass through the neck—a rate-
limited process that can measure the passage of time. Sim-
ilarly, an hourglass function imposes a resource constraint
(e.g., time) on the translation of a message from one encod-
ing domain to another, target domain.

In particular, such a scheme might ensure a certain lower
bound τ on the time required to translate a ciphertext ﬁle
G into its encapsulation ﬁle H. The client can then chal-
lenge the cloud provider at a random time to produce ran-
dom chunks of the encapsulated ﬁle H, and require that the
cloud provider do so in time < τ . By successfully comply-
ing, the cloud provider proves that it has actually stored the
hourglass ﬁle H that encapsulates G (from which G can be
eﬃciently extracted), and is not encrypting it on-the-ﬂy.

Moreover, the hourglass function must be carefully crafted
to ensure that it is not possible to store partial information
(e.g., 20% of the ﬁle size) to enable eﬃciently recovering
random chunks of the output. In other words, the hourglass
function should be applied to the encrypted ﬁle G as a whole,

and it should be equally diﬃcult or costly to evaluate on por-
tions of the encrypted ﬁle as it is to evaluate on the whole
ﬁle. Existing modes of encryption such as block chaining
fail to meet this criteria. Another important requirement is
that recovery of the ciphertext G (and, in turn, recovery of
plaintext F ) from the encapsulation H should be a reason-
ably eﬃcient operation, in case raw data is needed by the
cloud for processing.

Our general framework combines in a challenge-response
protocol two basic components, a properly parameterized re-
source bound with a complementary hourglass function that
exploits this bound:

• A resource bound: An hourglass scheme assumes a
bound on some resource at the cloud side—storage,
computation, or networking. For example, hard drives
experience delays due to seek time (time to access a
data block) and bandwidth (rate at which they can
read out data)—as they are the predominant storage
device in storage infrastructures today, they provide
one possible foundation for time-based protocols.

• An hourglass function: An hourglass function in-
volves an invertible transformation which imposes a
lower bound on the resources required to translate be-
tween coding domains, i.e., makes translation moder-
ately hard.

An example hourglass scheme. To gain intuition and
assuming a computational resource bound on the server,
we describe a simple, but somewhat impractical hourglass
scheme based on inversion of a small-image hash function.
Let F consist of n blocks, F1, F2, . . . , Fn, each of l bits. Sup-
pose that the client wishes to verify that the server applies
format-preserving encryption to F , to obtain a ciphertext G.
Let h : {0, 1}∗ → {0, 1}l denote a ﬁxed-length hash function.

Hourglass function. Consider then an hourglass
function deﬁned as follows. Transform G into H
by inverting each block of G under h; the server
computes and stores a pre-image Hi = h−1(Gi)
for every i ∈ {1, . . . , n}.1

A well-behaving server, then, stores the encapsulated ci-
phertext H (not the ciphertext G, nor, of course, the plain-
text F ). Note that recovery of G (and then F ) from H is
very practical for this hourglass function, by simply com-
puting the hash values Gi = h(Hi) for i ∈ [1, n].

Veriﬁcation of storage of H in the hourglass scheme here
will rely on the fact that even for fairly small values of l
(e.g., 35-bit or 40-bit blocks), the transformation from Gi to
Hi is computationally costly on average. In particular, we
might appeal to a simple, concrete resource bound, such as
the following:

Resource bound. The server can perform at most
2l−1 executions of h in time τ .

To verify that a server stores H, then, the client simply
selects a random block index i, and challenges the server to
furnish Hi. An honest server that has stored H just retrieves
and serves Hi—a quick operation. But a cheating server that

1Obviously, the server tries to ﬁnd the shortest possible such
pre-image, which will usually be of length close to l.

267has stored only the plaintext ﬁle F , has to compute Hi on
the ﬂy. It must compute ciphertext block Gi and then per-
form a costly computation of Hi which, on average, takes
time τ . In other words, because inversion of h is a moder-
ately hard computational task, it will delay the response of
a cheating server, by τ on average. A client can therefore use
the response time, r, to distinguish an honest server (r < τ )
from a dishonest one (r ≥ τ ).

While feasible, this hash-function-based hourglass func-
tion has some unattractive properties. First, a pre-image Hi
will, on average, be a little larger than its image Gi, resulting
in some degree of message expansion in the transformation
from G to H. Additionally, the full transformation from G
to H is quite costly, as it requires n inversions of h. And a
cheating server can easily parallelize the inversion of h.

The function h used here is a (compressed-range) one-
way function. Later in the paper, we consider the use of
a trapdoor one-way function, which removes these various
drawbacks.
Alternative approaches. Trusted computing oﬀers an al-
ternative approach to address the problem of verifying that
data at rest is encrypted. With trusted computing enabled
hardware, the client could require that the cloud provider
place all of its code that needs to access unencrypted data
inside of a trusted computing environment so that the client
can remotely attest that the code is correctly encrypting
data at rest. The main problem with this approach is that
trusted computing can easily be circumvented because the
cloud provider has physical access to the machines. Addi-
tionally, it would be diﬃcult and costly for a cloud provider
to move all of their cloud services into a trusted environ-
ment, especially since a large portion of their existing hard-
ware might not be capable of ensuring trusted execution.
2.2 Framework description

Let n denote the number of ﬁle blocks in a target ﬁle
F , where each block belongs in a domain B. We refer to
this original format as raw. We let Fi denote block i of F ,
and l(cid:48) denote the length (in bits) of a ﬁle block, i.e., Fi ∈
B = {0, 1}l(cid:48)
. We let G ∈ Ln be the block-by-block encoded
ﬁle, where blocks belong in a domain L, and let l denote
the length (in bits) of an encoded ﬁle block, i.e., Gi ∈ L =
{0, 1}l. For simplicity, we also let l be the security parameter
for our system (typically l = 128).
Framework encoding. First, the tenant speciﬁes as input
to the hourglass scheme an encoding algorithm deﬁned by
three operations:

• keygen-enc R→ κ1: A key-generation function that out-
puts a secret key κ1. To support publicly computable
encodings, κ1 could be the null string.

• encode(κ1, F ) → G: An encoding mapping that takes
a raw ﬁle F ∈ Bn and transforms it block by block
into an encoded ﬁle G ∈ Ln. We assume, as detailed in
Appendix B, that G is uniformly distributed in Ln.

• decode(κ1, G) → F : A decoding mapping that takes
an encoded ﬁle G ∈ Ln and transforms it into a raw
ﬁle F ∈ Bn.

While our framework is general in supporting arbitrary
encoding algorithms, we detail three speciﬁc encodings in
Appendix A.

Framework operations. Then, an hourglass scheme HG is
employed that consists of the following set of operations:

• An encoding algorithm given by keygen-enc, encode,

decode.

• keygen-hg R→ (κ2, κ3): A key generation function that
yields l-bit keys κ2, κ3 ∈ L, where κ3 is optional (only
used in our RSA-based construction in Section 4.3). If
κ3 is not used in a particular construction, its value is
set to the null string.

• hourglass(κ2, κ3, G) → H: An hourglass function en-
capsulates an encoded ﬁle G ∈ Ln in a format suitable
for proof of correct application of encode. The encapsu-
lation produces H ∈ Dn (where in general |D| ≥ |L|).
The function hourglass may be deterministic or prob-
abilistic.

• reverse-hourglass(κ2, H) → G: The inverse of the hour-
glass function reverses hourglass, reverting a storage-
formatted ﬁle H ∈ Dn back to an encoded ﬁle G ∈ Ln.
• challenge R→ c: A function that generates a challenge.
For simplicity, we assume a randomly selected block
index c ∈ {1, . . . , n} of H.

• respond(H, c) → r: An algorithm that operates over
an hourglass-encapsulated ﬁle H ∈ Dn to respond to
a challenge c ∈ {1, . . . , n}. For simplicity, we assume
r ∈ D.

• verify(H, c, r): Veriﬁes the response to a challenge c ∈
{1, . . . , n}. For simplicity, we assume that the veri-
ﬁer knows H. In practice, of course, this requirement
can be easily relaxed by, e.g., having the veriﬁer MAC
blocks of H or maintain a Merkle tree over blocks of
H (i.e., an authentication tree which itself can be out-
sourced to the cloud).

We say that an hourglass scheme HG is valid if for all keys
produced as output by keygen-enc R→ κ1 and keygen-hg R→
(κ2, κ3) the following three conditions hold with overwhelm-
ing probability in l:

1. decode(κ1, encode(κ1, F )) = F ;

2. reverse-hourglass(κ2, hourglass(κ2, κ3, G)) = G;
3. For all c ← challenge, verify(H, c, respond(H, c)) = 1.

Note that the second condition above implies that G can
be eﬃciently extracted from the encapsulated ﬁle H, i.e., G
can be recovered from H. Thus, veriﬁcation (by the client)
of challenged blocks of H implies that H is stored (by the
cloud) and that, thus, G is recoverable.

Appendix B presents the formal security deﬁnitions for
hourglass schemes. While an honest server will store repre-
sentation H in its storage, intuitively, the goal of an adver-
sarial server is to construct storage H(cid:48) with two properties:
(1) The adversary can respond to a large fraction of client
challenges by accessing blocks of H(cid:48); and (2) The adversary
leaks parts of the plaintext ﬁle F in H(cid:48). We make a simplify-
ing assumption about the adversary in the security analysis
of the three constructions described in Section 4. This parti-
tioning assumption detailed in Appendix B requires that the

268F (cid:107) H(cid:48)

adversary separates its storage H(cid:48) into H(cid:48) = (H(cid:48)
G),
where H(cid:48)
F is derived from the plaintext ﬁle F (representing
what the adversary leaks about ﬁle F ) and H(cid:48)
G is computed
over G (and used to answer client challenges). In our the-
orem statements in Section 4 we give lower bounds on the
amount of extra storage s(cid:48) = |HG| imposed on a cheating
server trying to leak part of the plaintext ﬁle and to achieve
success probability α in the challenge-response protocol.

We give three concrete instantiations of hourglass func-
tions in Section 4 along with their security analysis. (These
are based on either storage bounds—in particular bounds on
hard drive access time and throughput—or computational
bounds). But ﬁrst, we next show how an encoding algorithm
and an hourglass function with appropriate properties can
be combined in a generic protocol, thus overall supporting
a rich class of hourglass schemes.

3. GENERIC HOURGLASS PROTOCOL

To review our discussion thus far, the goal of an hour-
glass protocol is to provide assurance to a client that its
data outsourced to a server is stored in a desired, encoded
format G. The encoded format is computed by applying the
encode algorithm to the original ﬁle F . For most ﬁle encod-
ings of interest (e.g., encryption, watermarking), the output
of encode is fast to compute given ﬁle F . As such, the client
cannot challenge the server directly on encoding G to ensure
the application of encode to F : The server can store ﬁle F
and compute G on-the-ﬂy when challenged!

To resolve this issue, an hourglass protocol encapsulates
the encoding G into another format H suitable for remote
format veriﬁcation. The transformation from G to H is per-
formed with an hourglass function that enforces a resource
bound (e.g., minimum amount of time, storage or computa-
tion). This function is easily reversible: Knowledge of H im-
plies that G can be easily retrieved and, in turn, that blocks
of the original ﬁle F can only be obtained with access to
the decode algorithm. To ensure storage of format H, the
client challenges the server on randomly selected blocks of
H. By the correctness and speed of the response, the client
gets guarantees about the fact that the server stores the ﬁle
in hourglass-encapsulated format H.

Accordingly, our framework considers a generic hourglass
protocol that consists of three phases. Phase 1 performs the
ﬁle encoding, where the ﬁle F is encoded into G by the server
and a proof of correct encoding is generated and sent back
to the client. Phase 2 performs the hourglass encapsulation,
where the hourglass transformation is applied to G to obtain
ﬁle H, stored by the server. Finally, Phase 3 performs for-
mat checking, where the client checks that the server indeed
stores H by challenging the server with randomly chosen
blocks of H. The ﬁrst two phases are executed only once,
whereas the third one is executed periodically, in unpre-
dicted (e.g., randomized) intervals. Below we elaborate on
each one of the three phases of our generic hourglass protocol
which is formally presented in Figure 1.
3.1 Phase 1: ﬁle encoding

A generic hourglass protocol performs the initial trans-
formation from the original ﬁle F provided by the client to
the target encoding G using the encode algorithm. Given G,
the original ﬁle F can be retrieved using the corresponding
decode algorithm. In particular, in Phase 1 the server ap-
plies encode to the original ﬁle F (received from the client)

to obtain G. The encoding G, as well as a proof of correct
encoding, is sent to the client—G is needed by the client
in order to apply the hourglass transformation in Phase 2.
At the end of this phase, the client is assured (with high
probability) that encode has been applied correctly to F .

Overall, by appropriately instantiating this pair of algo-
rithms (encode, decode), our framework can support proto-
cols for ensuring storage of the following three ﬁle encod-
ings (these are detailed in Appendix A):

1. Encryption: We present a protocol by which a client
(or third party, e.g., auditor) can verify that a storage
provider stores a ﬁle F in encrypted form. As men-
tioned before, we consider a natural (and technically
challenging) model in which the provider manages the
encryption key, and never divulges it to the veriﬁer.
(This protocol is the main focus of the paper.)

2. Watermarking: We show how a server can prove that
a ﬁle F is encoded with an embedded provenance tag
τ : If F is leaked, τ identiﬁes the server as the source,
and thus the responsible/liable entity. We describe an
encoding such that it is infeasible to learn F without
learning τ , i.e., learning the ﬁle implies learning its
provenance tag. The major challenge in implementing
an hourglass scheme for this encoding is enabling the
server to prove to the client that τ is embedded in F
without revealing τ itself. This is important, as a client
(or third party) that learns τ could frame the storage
provider, falsely furnishing τ as evidence that F has
leaked.

3. File bindings: We show how a server can prove that
a pair of ﬁles (F1, F2) are stored in such a way that
retrieval of one ﬁle implies retrieval of the other. For
instance, F1 might be a piece of software and F2 an
accompanying license agreement: Binding the two to-
gether ensures that any entity retrieving F1 also gets
F2 and thus cannot claim failure to receive critical legal
information governing software usage.

Above we highlight only three concrete encodings that are
useful in practice, but these applications are by no means ex-
haustive. They just represent examples of ﬁle encodings for
which we can construct hourglass protocols. We believe an
interesting area of research is ﬁnding other classes of encod-
ings that could be embedded into an hourglass protocol.

Note that this phase involves more than just outsourc-
ing of ﬁle F to the server. While function hourglass is always
computable by the client, function encode is not always avail-
able to the client.2 We thus remove this obstacle by requir-
ing the server to send in this phase G to the client along
with a proof that G is a correct encoding. Once this proof
is veriﬁed, the client can then apply in the next phase the
hourglass transformation on G to obtain H. These protocols
appear in Appendix A.
3.2 Phase 2: hourglass encapsulation

The hourglass protocol additionally performs the trans-
formation from G to the hourglass format H that involves
applying the hourglass function hourglass on the encoded ﬁle
G. In particular, in Phase 2 the client and, in some cases,

2Recall that in the case of proving correct at-rest ﬁle en-
cryption, the client does not know the ﬁle encryption key.

269Client / Veriﬁer

Server / Prover

Phase 1: Generate ﬁle encoding
Input: ﬁle F = F1 . . . Fn

F−→ κ ← keygen-enc
G,π←−

G = encode(κ, F )
π ← Proof correct encoding

Phase 2: Hourglass encapsulation
H ← hourglass(G)
Generate integrity checks IH on H

Phase 3: Format checking
{ci ← challenge}t
Start timer

i=1

Stop timer, τ : elapsed time
Accept iﬀ {verify(H, ci, ri) = true}t
(using IH ) [and τ ≤ T ]

i=1

IH [,H]−→

{ci}t
i=1−→

{ri}t
i=1←−

[H ← hourglass(G)]

{ri = respond(H, ci)}t

i=1

Figure 1: Generic hourglass protocol

the server applies hourglass to encoding G to compute the
encapsulation H for storage on the server. This is a block-
by-block transformation that produces n hourglass blocks
H1, . . . , Hn. Note that if hourglass does not use a secret key,
then both parties can compute H directly from G. This ob-
servation saves one round of n-block communication in our
butterﬂy and permutation constructions from Section 4.

An issue arising in the design of an hourglass protocol is
the fact that the client needs to verify responses from the
server in the challenge-response below (Phase 3). In our sys-
tem deﬁnition we assume for simplicity that H is available
to the veriﬁer (algorithm verify(H, c, r) explicitly receives H
as input). In a practical implementation of an hourglass
protocol—particularly in cloud applications—it’s desirable
to have H stored only by the server.3 To verify a block of
H (returned by the server as a response to a challenge), the
client can pre-compute integrity checks for blocks of H. This
requires that the client itself possess the authentic H.
3.3 Phase 3: format checking

The hourglass protocol includes a ﬁnal challenge-response
component (executed multiple times at unpredictable time
intervals) in which the client can check that the server is
indeed storing the ﬁle in format H. In particular, in Phase
3 the client challenges the server to verify that the server
in fact stores H. In the challenge protocol the client chooses
t random block indices {ci}t
i=1 and challenges the server to
produce responses {ri}t

i=1 which are sent to the client.

The client then proceeds with the veriﬁcation of the re-
ceived responses by ﬁrst simply checking their correctness
with respect to the authentic blocks of H (originally pro-
duced in Phase 2). This is achieved by making use of the
integrity checks on the received blocks of H (as discussed
above). In addition, in our time-based constructions, the
client measures the time between its sending the challenge
and receiving a reply. It accepts the response if it arrives

3Ideally, the client’s storage needs should be of constant-
size (independent of the ﬁle size n); otherwise the beneﬁts
of data outsourcing diminish.

in time less than some security parameter T . We note that
as an optimization, the server can optionally aggregate re-
sponses before sending them to the client (as, e.g., in [27]).
We emphasize that the client’s integrity-checking mech-
anism is orthogonal to the rest of our hourglass protocols.
The client can use any standard scheme that supports ver-
iﬁcation of blocks of H, e.g., MACs or Merkle trees. Once
generated by the client, integrity checks can be stored by the
client, or preferably stored on the server and retrieved in the
challenge-response protocol. If MACs are used, the client re-
tains any secret keys required for veriﬁcation; if Merkle trees
are used, the client needs store no secret state but just the
root of the tree. For the remainder of the paper, we assume
the use of an integrity checking scheme and omit details.

4. HOURGLASS FUNCTIONS

We now present our concrete hourglass functions. To illus-
trate the challenge of constructing good hourglass functions,
we ﬁrst present a na¨ıve approach and brieﬂy explain why it
doesn’t work. Then we explore three constructions, namely:

1. A butterﬂy hourglass function in Section 4.1, that cor-
rects the ﬂaw in the na¨ıve approach. This approach
is timing based and assumes general bounds on stor-
age speed (that as we will discuss typically hold in all
existing storage media).

2. A permutation-based hourglass function in Section 4.2.
This timing-based scheme assumes a more speciﬁc stor-
age model: It relies on particular properties of rota-
tional hard-drives, namely their performance gap in
accessing sequential disk sectors versus randomly se-
lected ones (whose access induce an expensive drive
seek operation). Using non-cryptographic data-word
permutation, this construction is very eﬃcient.

3. An RSA-based hourglass function in Section 4.3. This
scheme involves application of an RSA signing opera-
tion (repeatedly for strong security properties) to indi-
vidual ﬁle blocks. It’s less eﬃcient than the other two

270schemes, but has the advantage of relying on the hard-
ness of the RSA problem, rather than timing, and it
supports random access to ﬁles as well as ﬁle updates.

We analyse the security guarantees for all of our pro-
posed constructions above (and we provide complete security
proofs in the full version of this paper). We experimentally
explore their performance in Section 5.

Challenges. Recall that both the encoded ﬁle G and the
hourglass transformation H in our framework are repre-
sented as n-block ﬁles, where each block has ﬁxed size. Our
ﬁrst two time-based hourglass functions that exploit delays
on data-access speed rely on a common underlying approach.
They transform G into H so that every block Hi function-
ally depends on a large set Si of blocks in G. Intuitively, an
hourglass function that achieves good “mixing” of this sort
seems to oﬀer good security. Suppose that a server cheats
by storing F instead of H. When challenged to produce Hi,
the server would have to retrieve all the blocks in Si. By
our speciﬁc bounds on data retrieval speed this task is slow
imposing a noticeable response delay.

We might then consider a simple and eﬃcient hourglass
function that “mixes” optimally, in the sense that every block
Hi depends on all of G. This is achievable with a full-ﬁle
(known-key) pseudorandom permutation (PRP) over G, com-
putable with two cipher-block chaining (CBC) passes over
the ﬁle, one in the forward direction and one in the reverse
direction: Then every block of H depends on all blocks of G.
Speciﬁcally, let IVf and IVb be initialization vectors and
Encκ(·) denote encryption under a block cipher. (The key
κ should be known to the server so that it can reverse
the PRP: This doesn’t impact the cryptographic eﬀect of
“mixing.”) The forward pass computes intermediate values
A1 = Encκ(G1 ⊕ IVf ), Ai = Encκ(Gi ⊕ Ai−1), for 1 < i ≤ n;
the backward pass computes output blocks Hn = Encκ(An⊕
IVb), and Hi = Encκ(Ai ⊕ Hi+1), for 1 ≤ i < n.

As it turns out, though, because this double-pass CBC
function involves chaining of blocks, it is possible for a cheat-
ing server to store F and a “shortcut,” namely staggered,
intermediate blocks within a chain. In particular, let H(cid:48) =
{Hv, H2v, . . . Hv×(cid:98)n/v(cid:99)} for some parameter v. These inter-
mediate blocks allow the server to compute blocks of H ef-
ﬁciently on the ﬂy from a compact H(cid:48). For small enough v,
the server could quickly compute a challenge block Hi (for
jv ≤ i ≤ (j + 1)v) by computing the forward chain seg-
ment Ajv, . . . A(j+1)v to retrieve H(j+1)v, and then comput-
ing the backward chain segment H(j+1)v, H(j+1)v−1, . . . , Hi.
Of course, a small value of v induces a large amount of extra
storage, thus parameter v needs to be chosen to balance the
storage overhead of intermediate blocks, as well as the cost
of computing responses to challenges on-the-ﬂy.

This approach fails because a single block Aj: (1) Sits on
the path of computation for many output blocks in H and
(2) Allows a server with knowledge of Aj (along with G)
to compress substantially the amount of computation along
many of these paths. Good mixing is thus a necessary but
not suﬃcient security condition.

This example illustrates the subtle challenges in construct-
ing a good hourglass function, and the motivation for our
next two hourglass function constructions.
4.1 A butterﬂy hourglass function

We now propose what we call a butterﬂy hourglass func-

tion. It replaces the ﬂawed, chained-block dependencies of
the na¨ıve double-pass CBC construction that we saw above,
with a structure of overlapping binary trees. At the same
time, this function is a full-ﬁle PRP, and so achieves the
security requirement of strong “mixing.” Storage of interme-
diate results in a butterﬂy provides little beneﬁt to a cheat-
ing server: As we explain, a server can’t eﬀectively compress
computational paths from G to H into a “shortcut.”

A butterﬂy function applies an (atomic) cryptographic op-
eration w to pairs of blocks in a sequence of d = log2 n
rounds, as shown in Figure 2.4 The resulting structure of
pairwise operations resembles a butterﬂy network commonly
used for parallelized sorting, FFT, etc.
Let G and H be n-block ﬁles, with each block having size
l bits (that is, |L| = |D| = l). Let w : L× L ↔ L× L denote
the atomic operation over a pair of ﬁle blocks. In practice,
we can instantiate w as a (known-key) PRP, i.e., a block
cipher. Formally, hourglass : Ln ↔ Ln computes in d rounds
a transformation from n-block input ﬁle G to output ﬁle H
as follows. Deﬁne G0[i] = Gi for all i. For 1 ≤ j ≤ d, we
compute the output Gj[1] . . . Gj[n] of level j as a function
of level j − 1, as speciﬁed in Algorithm 1 of Figure 2.

In Figure 2, we present an example butterﬂy network for
the case n = 8. In this representation, each set of values
Gj[1], . . . , Gj[n] is a row of nodes. Two edges connect the
input and output node pairs involved in each application
of w, where w itself is depicted as a small square. Globally,
hourglass involves n log2 n invocations of w to achieve strong
mixing of all input blocks (of G) into every output block (of
H), so its total computational cost is O(n log n). The func-
tion reverse-hourglass is computed in the obvious manner,
exploiting the invertibility of w.

Timing. Recall that the butterﬂy hourglass scheme is a
time-based one: It relies on storage access time as its re-
source bound. As we assume a limit on the server’s stor-
age access speed, the eﬀect of the timing bound T in the
challenge-response protocol is to impose an upper bound on
the amount of data the server can use to compute its re-
sponse. In our security analysis, we thus rely on the fact
that the time bound T translates into an upper bound of
at most n storage accesses that the server can make within
time T for some  < 1.

We’d like to highlight that we can support any existing
storage device (e.g., hard drives, solid-state drives) with this
model, but we need to set the parameters  and T depending
on the exact characteristics of the storage medium. On rota-
tional drives, for instance, disk access time is highly variable.
Sequential block accesses are generally much faster than ac-
cesses to blocks at distant locations on disk (or random ac-
cesses). Solid-state drives exhibit less variable data access
rates. When the challenge-response protocol is run remotely,
network latency will also impact the server’s response time
and needs to be considered when setting the time bound T .
With respect to the above considerations, the use of multi-
ple challenges, i.e., having the client request multiple blocks
of H, proves to be a useful approach in smoothing out the
variability in storage and network latencies. Below we give
a precise analysis for the security of the butterﬂy construc-

4Here we assume n is a power of 2. For n not equal to a
power of 2 we may use a diﬀerent permutation of outputs to
inputs between levels. We may also use a higher branching
butterﬂy network.

271Algorithm 1: Butterﬂy hourglass algorithm

1: for k from 0 to n/2j − 1 do
2:
3:

for i from 1 to 2j−1 do

(Gj[i + k · 2j], Gj[i + k · 2j + 2j−1]) ← w(Gj−1[i + k ·
2j], Gj−1[i + k · 2j + 2j−1]);

end for

4:
5: end for

Figure 2: Butterﬂy hourglass construction: Butterﬂy graph for n = 8 (left) and general algorithm (right).

tion for multiple challenges issued in the challenge-response
protocol.

Security analysis. We analyze the butterﬂy construction
using a standard “pebbling” argument that treats w as an
atomic operation and intermediate butterﬂy computations
as “pebbles” sitting on the nodes in the butterﬂy graph. (See,
e.g., [9, 10] for similar proofs.) In obtaining a conﬁguration
of its storage H(cid:48), an adversary A is allowed to play a peb-
ble game. It starts with a given conﬁguration of pebbles in
its storage H(cid:48) that includes both (some of) the original ﬁle
blocks of F (denoted “red pebbles”) and those blocks cor-
responding to (some of) the intermediary nodes in the but-
terﬂy computation from G to H (denoted “black pebbles”).
Given a pair of black pebbles in H(cid:48) input to a w operation
in the butterﬂy graph, they can be replaced in the pebble
game with the corresponding output pair of nodes. The goal
of the adversary is to ﬁnd a pebble conﬁguration within a
ﬁxed storage bound for H(cid:48) that will allow him to reply cor-
rectly to a large fraction of challenges, and at the same time
embed a large number of red pebbles in its storage H(cid:48).
Assumptions. Note that this way of modeling an adver-
sary A through a pebbling game embeds several assumptions
about the behavior of the adversary. First, the partitioning
assumption deﬁned in Appendix B follows naturally from
this model, as the adversary clearly separates its storage H(cid:48)
into red pebbles H(cid:48)
F (derived from ﬁle F ) and black pebbles
H(cid:48)
G (derived from formats G and H). Second, the pebbling
game encompasses an implicit assumption on w resembling
the random oracle model: Output nodes of a w computation
in the butterﬂy graph can only be computed with complete
knowledge of both input nodes. In this setting, we are able to
show a lower bound on the amount of extra storage s(cid:48) that
a cheating server needs, deﬁned as the amount of storage
needed for answering client challenges besides any plaintext
ﬁle blocks. (See also Appendix B for a deﬁnition of s(cid:48).)

Theorem 1. Suppose A can successfully respond to t chal-
lenges on randomly selected blocks of size l bits of H with
probability α, using extra storage of size s(cid:48) and up to n
timely block accesses. Then the following bound holds:
(cid:48) ≥ min{α1/tnl(1 − ), nl(1 − ) + log2 α1/t} .

s

In other words, the adversary’s storage overhead for cheat-
ing is linear in its probability of successfully responding
to challenges and inversely related to its ﬁle-block retrieval
rate. Let us give some intuition for the bound in Theorem 1

for t = 1 challenges. Ideally, an adversary achieving suc-
cess probability α of responding to a challenge would need
to store s(cid:48) = αnl bits in its storage (corresponding to all
the challenges that the adversary can successfully answer).
Nevertheless, there are two strategies for generating addi-
tional bits (besides those in its storage) that the adversary
can leverage to respond to challenges and improve its suc-
cess probability. The ﬁrst strategy is to access a number of
at most nl bits in time bound T (and it aﬀects the ﬁrst
term in the bound of Theorem 1). The second strategy is
to guess a number of bits in the butterﬂy network. As the
overall probability of success of the adversary in answering
challenges is α, an upper bound on the number of bits the
adversary can successfully guess is − log2(α). These guessed
bits aﬀect the second term in the bound of Theorem 1. A
detailed proof is given in the full version of the paper.

For example, suppose that the adversary would like to
leak plaintext ﬁle F through its storage, and it can retrieve
ﬁle blocks equivalent to at most 5% of F in the allotted
response time T . Then to respond successfully to a challenge
with 99% probability, A must incur an 94% overhead, i.e.,
it must store not just the n blocks of F , but an additional
.94n ﬁle blocks.
4.2 A permutation-based hourglass function
We now propose an extremely fast and simple hourglass
function, one that involves no cryptographic operations. Its
security depends upon the performance characteristics of
rotational drives. Such drives are optimized for sequential
ﬁle accesses. They perform relatively poorly for random ac-
cesses, i.e., accesses to widely distributed ﬁle locations, as
these result in an expensive disk seek operation.

Capitalizing on this characteristic, our hourglass function
computes H as a permutation of data elements in G. To re-
spond with a challenged block Hi on the ﬂy, then, a cheat-
ing server that has only stored partial information about Hi
must gather together disparate data elements of G (or F ).
This process induces a number of random accesses to disk,
slowing the server’s reply.

Recall that the encoding G of F consists of n blocks of l
bits. Let Gi[j] denote the jth symbol of Gi, where we deﬁne
a symbol as a sequence of z bits, e.g., a byte or word, for
z | l. Thus 0 ≤ j ≤ m − 1 with m = l/z. Let G[k] denote
the kth symbol in the symbolwise representation of G, for
0 ≤ k ≤ nm − 1.

Any permutation that scatters the symbols of G widely
across H can achieve good security. Our simple hourglass
function permutes the symbols of G with the property that
for each block Gi the permutation uniformly distributes the

272m symbols of Gi over the hourglass blocks in H. That is,
each of the hourglass blocks receives (cid:100)m/n(cid:101) or (cid:98)m/n(cid:99) sym-
bols of Gi. In addition, if m (cid:28) n, then the permutation
composes each block Hi of m symbols from widely staggered
positions in G.

We need to emphasize that the block size l of the encryp-
tion algorithm needs to be much larger than the symbol
size z used for permuting the encrypted ﬁle. This will re-
sult in a large value of m, the number of symbols within a
block. For large m, the intuition behind the security of the
permutation-based scheme is as follows. A malicious cloud
server that stores a permuted plaintext ﬁle has diﬃculty
responding to a challenge consisting of a randomly chosen
block Hi = (Gi1 [j1], . . . , Gim [jm]) of the hourglass transfor-
mation: To compute the k-th encrypted symbol Gik [jk] of a
challenge block, 1 ≤ k ≤ m, the server needs to read a large
plaintext block Fiv and encrypt it. Reading the m plain-
text blocks Fi1 , . . . , Fim requires up to m disk seeks. A large
value of m results in large disk access time and detection of
server misbehavior.
Security analysis. Although the proposed hourglass func-
tion is simple, its security analysis is delicate. It relies on
a timing model for rotational drives. Rotational drives are
designed for optimal access speed over sequential physical
locations on a platter. Accesses to blocks at distant location
induce a seek, a time-consuming physical repositioning of
the magnetic head of the drive. In particular, we make the
following concrete considerations.

• Drive model: For simplicity we assume that a rota-
tional drive has a constant seek time τs, i.e., it takes
τs time to reposition the head. We also assume a con-
stant sequential block-read rate of τr. Thus, a sequen-
tial read of e blocks is assumed to cost τs + (e − 1)τr
time.5

• Time bound: As before, we also consider a particular
timing bound T on the response given by an adversar-
ial server A to a challenge provided by the client.

• Parallelism: Of course, a server will in practice stripe
ﬁles across multiple drives or storage subsystems: In-
deed, d-way parallelism enables it to retrieve symbols
d times more quickly. This does not, however, actually
reduce the extra storage overhead s(cid:48) that is incurred
to the adversary A by a factor of d. An honest server
can seek one block of H faster than a cheating server
can gather m symbols across d drives, for d < m. In
practice, m is on the order of hundreds, and d is much
smaller [11], so parallelism has a muted eﬀect on our
permutation-based hourglass function. (Note too that
if the client can estimate the parallelism d of A, it
can request t = d blocks of H during the challenge-
response phase.)

Assumptions. Within this model (which assumes a rota-
tional drive model where reading is done at the granularity
of blocks), we have analyzed the security guarantees that our

5In practice, drive performance is complicated by inexact
mapping between logical and physical addresses—due to
fragmentation or sector errors—and by non-uniformities in
the physical data surface, e.g., the fact that outer rings hold
more data than inner ones. But we believe our model is an
accurate approximation.

permutation-based hourglass function provides. Our analy-
sis relies also on the compression and partitioning assump-
tions detailed in Appendix B. To reiterate, we assume the
adversary cheats by leaking a portion of plaintext ﬁle F in its
storage. However, the adversary needs to storage addition-
ally s(cid:48) bits in a string H(cid:48)
G to help it respond to challenges.
Our full security analysis and accompanying proofs are
rather technical and below we state a simpliﬁed, but rep-
resentative, version of our analysis results followed by an
example parametrization—in fact, that one we use in our
experiments in Section 5.

Theorem 2. Let T , τs, τr, m, l and n be deﬁned as above
satisfying 2m ≤ l(m − T /τr). Suppose A can successfully
respond to a challenge on a randomly selected block of H with
probability α ≥ 3/4, using extra storage of size s(cid:48). Then the
following bound holds, where k = min{(cid:98)τs/τr(cid:99), 1+(cid:98)n/(2m2+
4l/3)(cid:99)}:

(cid:48) ≥ (2α − 1) · nl · m − T /(k · τr)

m − 1

s

.

In other words, for large m and α close to 1, the theorem
states that s(cid:48) needs to be at least a fraction ≈ 1− T /(mkτr)
of the nl bits that represent F . The intuition behind this is
as follows. The quantity T /(kτr) represents an upper bound
on the number of ﬁle blocks that can be read within time T
(either through random seeks or sequential reads). Due to
the permutation, each block read (after its encryption) con-
tributes at most one symbol to the reconstruction of a chal-
lenge block from H. This means that the additional storage
needs to have suﬃcient information for the reconstruction of
the remaining (1 − T /(mkτr)) · m out of m challenge block
symbols. For this reason s(cid:48) needs to be at least a fraction
1 − T /(mkτr) of the total number of bits that represent H.
Example parametrization. In our experimental setup,
blocks are of size 4KB, as currently used by rotational drives.
Since CPU instructions typically operate over 64 bits in to-
day’s architectures, we choose a symbol size of z = 64 bits.
Thus, a block of 4KB consists of m = 29 symbols. Enterprise
drives have an average seek time of around τs = 6ms and
a disk-to-buﬀer data transfer rate of ≈ 128KB/ms, hence
τr = 0.03125ms. Our experiments include a 8GB ﬁle, with
n = 221 blocks; we use that size for our analysis. We con-
sider a time of T = 6ms, that is required to respond to a
one-block challenge. (This is much smaller than the network
latency between two remote points on the internet. By using
multiple challenges we can compensate for network latency.)
In this setting, Theorem 2 states that a server A that leaks
the entire plaintext F in its storage and replies correctly
to challenges with probability 99% incurs an 89% overhead,
i.e., in addition to the n blocks of F A must store .89n extra
blocks.

Implementation in practice. For practical implementa-
tions, as in our experiments in section 5, it is reasonable to
consider a weak adversary that stores plaintext blocks Fi in
their original order. This is the natural behavior of a server,
as it enables ﬁle segments to be easily retrieved for ordinary
use. In this case, the security bounds of our theorem still
hold when we implement a highly structured permutation
(instead of a uniformly random one) that staggers plaintext
symbols at large distances across the hourglass output.

The following choice, used in our experiments, has the

273advantages of simplicity and high computational eﬃciency:

H[i] = G[ih mod nm] and G[i] = H[ig mod nm]

with gcd(hg, nm) = 1.

Another parameter choice in our design is the symbol size
z. Smaller values of z oﬀer stronger security, in the sense that
the number of blocks m of F whose data make up a block of
H scales with 1/z. CPU instructions, however, operate over
data words, typically of 64 bits in today’s architectures. So
larger values of z (up to 64) mean faster operation for a
staggered hourglass function.
4.3 An RSA-based hourglass function

We next present a realization of an hourglass function by
applying RSA signing to translate an encoded format G of
ﬁle F to an hourglass-encapsulated version H of G. At a
high level, our protocol employs a hard-to-invert function f
in a straightforward way: Each block Gi of the encoded ﬁle
is mapped to an hourglass block Hi by inverting Gi under f .
Critical to this protocol, however, is the requirement that f
is a trapdoor one way permutation, where knowledge of the
trapdoor by the client only, and not by the server, allows ef-
ﬁcient inversion of f . The approach is similar to the example
hourglass function described in Section 1, which made use of
a compressed-range hash function, but with two important
diﬀerences. First, for the server, inverting RSA is compu-
tationally infeasible, not just moderately diﬃcult to perform
as compressed-range hash functions (or similar puzzles) are.
Second, for the client, the transformation from G to H is easy
to perform using the secret RSA exponent to sign each Gi.
Unlike our previous time-based constructions, here our re-
source bound is now solely computation, and no assumptions
are made on storage usage. We assume that an adversary A
can do at most lW work for some W > 0, i.e., A runs in poly-
nomial time in the security parameter deﬁned as the length l
of the blocks Gi and Hi (for this construction |L| = |D| = l).
Thus, based on the cryptographic assumption that inverting
the RSA function f is infeasible, translating Gi (or Fi) to
Hi without knowledge of the trapdoor is also infeasible for
any such A.
Hourglass protocol. If f : {0, 1}l → {0, 1}l is a one way
trapdoor permutation with trapdoor κ (that is, f−1(·) is
hard but f−1(κ,·) is easy to compute), then an f -inversion
hourglass protocol is as follows:

1. The client generates f and κ, and then applies function
hourglass(f, κ, G) by individually inverting blocks Gi
to Hi = f−1(Gi). The client discards the key sk and
sends blocks Hi to the server.

2. On challenge a random index i ∈ {1, . . . n}, the server

returns the corresponding inverse image Hi.

3. The client then checks the correctness of the returned
answer ˆHi (which might diﬀer from Hi) by running
verify(H, i, ˆHi), and accepts if and only if Hi = ˆHi.
(Recall that, in practice and as we discussed in Sec-
tion 3, the authentic format H is available to the client
implicitly, through the use of appropriate integrity checks
for inverted blocks Hi.)

Note that in the above protocol f , i.e., the RSA signature
veriﬁcation, is used only to recover blocks Gi from Hi, in
particular, the veriﬁcation of the challenge blocks ˆHi is done
independently, without using f .

We instantiate the above protocol using the RSA func-
tion f (x) = xd mod N , its inverse f−1(y) = ye mod N
and κ = (d, φ(N )), where e > |N|. Here, l is equal to the
modulus size |N|. Also, the underlying security parameter (cid:96),
determined by the best known algorithm for inverting RSA
without knowing κ, is polynomially related to l.
Security analysis. To get an intuition of why the above
scheme is secure, we note that a computationally bounded
A can’t itself feasibly invert blocks under f : To reply to chal-
lenge i, it must actually store the original inverted block Hi.
Thus, under our partitioning assumption (see Appendix B
for more details), to respond correctly to challenges with
probability α, A must store ≈ αn blocks in H(cid:48)
G, i.e., s(cid:48) ≈
αnl, yielding an extra storage overhead of factor ≈ α. Note
that as we assume blocks in G are random, A can’t save
space by using the same Hi for duplicate blocks of G. (In-
deed, when G is uniformly distributed, blocks Hi are sta-
tistically independent of each other, and therefore H(cid:48)
G can
be optimally partitioned into ≈ αn parts, each containing
information about a unique challenge Hi.)
That said, A can “compress” a stored block Hi = f−1(Gi)
slightly by throwing away a small number—O(log l)—of bits.
By verifying conjectured Hi values against f , it can recom-
pute discarded bits by brute force (with work O(l)) when
challenged to produce Hi. We refer to as near-incompressible
any f−1 that doesn’t admit feasible “compression” of more
than the O(log l) bits of this trivial approach. It is com-
monly conjectured that RSA signatures with e > |N| are
near-incompressible.
We can eliminate this e > |N| conjecture and still get
near-incompressible RSA-based signatures by chaining ap-
plications of f−1. In particular, let

t = (Π ◦ f
−1

g

−1)t ∈ {0, 1}l → {0, 1}l

be a composite inversion function that alternates applica-
tions of f−1 with applications of a pseudorandom permuta-
tion (PRP) Π in a chain of length t, and let us assume that
Π is an ideal cipher. If f is a trapdoor permutation that can-
not be inverted by a probabilistic algorithm with l2W work
with success probability at least , then for

t ≥ (cid:100)(l − W log l)/(W log l − log )(cid:101)

the length-t chained inversion function g
be near-incompressible.

−1
t

can be shown to

To get an intuition of why this is true, ﬁrst note that
because f is hard to invert there is a lower bound on the
amount by which Hi = f−1(Gi) can be compressed. Also,
based on our assumption that Π is an ideal cipher, each of
the t blocks that are inverted in the chain is an independent
random block, therefore the storage dedicated for challenge
block Hi must be further partitioned by the adversary into
at least t parts, each storing (a possibly compressed) inde-
pendent inverted block in the chain. But when the length t
of the chain is suﬃciently long, the adversary must utilize a
relatively large amount of storage for exclusively responding
to a challenge Hi, thus making Hi near-incompressible.
Assumptions. Overall, we employ the following assump-
tions in analyzing the security of the above two schemes,
namely the unchained f -inversion protocol and the chained
gt-inversion protocol: (1) The partition assumption (of Ap-
pendix B) holds for the adversary A, i.e., its used storage
H(cid:48) can be split into H(cid:48)
G (to an-
swer to challenges); (2) The encoded blocks Gi are random,

F (to leak raw data) and H(cid:48)

274or equivalently encoding G is uniformly distributed; and (3)
either RSA signatures are near-incompressible when e > |N|
for an unchained inversion, or the used PRP Π serves as an
ideal cipher and suﬃciently long chains (as speciﬁed above)
are used for chained inversions.

Then, for the resulting chained g = gt, with t lower-
bounded as above, or the unchained g = f , under the e >
|N| conjecture, we can prove the following result.

Theorem 3. Let f be a trapdoor permutation that can-
not be inverted by any algorithm with l2W work with success
probability at least , let ξ = 2−(l−W log l), and let g be as
above. Suppose that A can successfully respond to challenges
in a g-inversion hourglass protocol with probability α, using
extra storage of size s(cid:48) and running in time lW . Then the
following bound holds:

(cid:48) ≥ α − ξ
1 − ξ

s

· n · (l − W log l) .

In other words, under the RSA near-incompressibility as-
sumption or for suﬃciently long inversion chains, the (trap-
door permutation) inversion-based hourglass protocol incurs
an extra storage overhead to the adversary that is close to
the optimal αnl minus the logarithmic-factor savings that
the adversary is able to achieve through the trivial compres-
sion (via brute force guessing of logarithmic many missing
bits) of inverted blocks. In the theorem, the intuition be-
hind ξ is that it is related to6 the probability that an ad-
versary A running in time lW is able to successfully recon-
struct/decompress a block of H from a compressed/truncated
version of the block of size less than l − W log l bits. This
means that in the best case, the adversary needs at least
(l− W log l) bits of storage for u(cid:48) = [(α− ξ)/(1− ξ)]n blocks
of H such that a total of u(cid:48) · 1 + (n − u(cid:48)) · ξ = αn blocks of
H can be reconstructed. This gives the lower bound on the
extra storage s(cid:48).

As an example application, consider an RSA key length
of l = 1024 = 210 and security of (cid:96) = 80 bits (as deter-
mined, e.g., by NIST, Pub. 800-57), work of l2W = 260 op-
erations (i.e., W = 3), implies a maximum success proba-
bility of  = 2−20, and Theorem 3 suggests use of t = (cid:100)(l −
W log l)/(W log l−log )(cid:101) = (cid:100)(1024−3·10)/(3·10+20)(cid:101) = 20
iterations. For l = 2048 bits with corresponding security of
112 bits, we similarly get t = 25 rounds for the same amount
of work (W = 1.5,  = 2−52) or t = 28 rounds for work of
280 (W = 2,  = 2−32). In all cases, the bound on s(cid:48) is very
close to the optimal nl for α close to 1.

5. EXPERIMENTS

We have performed an experimental evaluation in Ama-
zon EC2 of our butterﬂy construction and one of our permu-
tation constructions. We did not experiment with the RSA
construction because the performance of RSA signing opera-
tions is well known, thus an evaluation wouldn’t provide ad-
ditional insights. We also acknowledge that the RSA-based
construction is less eﬃcient than our other two schemes (in

6But it is not exactly equal to: In our proof we show that
for an adversary running in time lW the probability that
a block from H can be reconstructed from a compressed
version of c bits is at most 2−(l−c−W log l). We show that the
best strategy for the adversary is to use a compression of
l − W log l bits or of 0 bits for each block.

Table 1: Performance (in seconds) and cost (in cents) of
transformation from F to H for ﬁle encryption.

File size

1 GB
2 GB
4 GB
8 GB

Permutation
Time Cost Time Cost
0.03
50.91
0.06
103.96
213.07
0.12
0.24
432.91

1.64
3.24
6.45
12.73

Butterﬂy

0.96
1.96
4.02
8.17

terms of the cost of the hourglass transformation and its
inverse), and it’s mainly of theoretical interest.

We consider a scenario in which the cloud provider (server)
runs on Amazon, but isn’t Amazon itself. Thus it’s subject
to Amazon pricing—a fact useful for economic analysis. The
tenant acting as a client in our experiments also runs within
Amazon EC2.

We implement the butterﬂy construction using AES en-
cryption with 128-bit ﬁle blocks. We parallelize the imple-
mentation once the ﬁle size exceeds 8MB. For the permu-
tation construction, we consider 4KB ﬁle block sizes, and
64-bit symbol sizes as discussed in Section 4.2; as the ma-
chine word size, it’s a good choice for eﬃciency. The number
of symbols in a block is m = 512. We permute the ﬁle using
the simple construction in Section 4.2. The hourglass ﬁle H
consists of 512 segments; we include in segment i symbol i
of every ﬁle block. (Again, this scheme disperses ﬁle symbols
widely across H.)

We run experiments on Amazon EC2 using a quadruple-
extra-large high-memory instance and EBS storage. We also
run them on a local machine (i7 980X processor with 6 cores
running at 4 GHz). For all our experiments, we show aver-
ages over 5 runs.

Hourglass function performance. We ﬁrst measure the
in-memory hourglass function computation time for both
the butterﬂy and permutation constructions for diﬀerent ﬁle
sizes. We report computation times in the local machine’s
memory and in memory for our Amazon EC2 instance in
Figure 3.

The butterﬂy function is at least a factor of 4 faster on
our local machine due to hardware support for AES. The
butterﬂy construction also beneﬁts from multiple cores: For
large ﬁle sizes the multi-threaded implementation is faster
by a factor of 5 (on both local and Amazon machines). The
permutation scheme permutes machine-size words in main
memory, and its cost is determined by cache misses and main
memory latency. The implementation on the local machine
is about twice as fast as that on Amazon.

Compared to the multi-threaded butterﬂy implementa-
tion, the permutation hourglass function is about 8 times
faster on Amazon and 4 times faster locally (since it does
not use cryptographic operations). More importantly, this
permutation-based hourglass function can be computed in a
streaming fashion: After a ﬁle block is read from EBS (and
before the next block is received), its symbols can be ar-
ranged in the corresponding positions in the hourglass out-
put. We performed a preliminary experiment to determine
the overhead of such a streamed implementation, in the sense
of marginal time above that of simply uploading the ﬁle from
EBS into main memory. We ﬁnd that this overhead is negli-
gible. The only extra time the permutation scheme imposes
is that of decryption/encryption once the ﬁle is uploaded.

275Figure 3: In-memory hourglass function performance for the butterﬂy and permutation schemes; local machine (left) vs.
Amazon EC2 (right).

Table 2: Challenge-response performance

File size No challenges Honest Adversarial

2 GB

4 GB

2
4
6
8
2
4
6
8

0.047
0.062
0.093
0.109
0.0468
0.062
0.078
0.094

8.403
9.65
27.40
26.807
30.321
101.015
114.579
121.431

Economic analysis. We present in Table 1 the total time
and cost for computing the transformation from ﬁle F to
format H for a ﬁle-encryption application. (For the permu-
tation scheme, we used the streamed implementation.) We
use a cost basis of 68 cents per hour (as charged by EC2 for
our instance type).

An honest cloud provider stores transformed ﬁle H and
computes plaintext F when needed. We described in Sec-
tion 1 the double-storage problem: A cloud provider might
store data in format H to respond correctly in the challenge-
response protocol, but also store the plaintext for conve-
nience. Using the Amazon EBS pricing scheme for storage
(10 cents per GB per month) and the results in Table 1, we
argue that this scenario is not economically well motivated.
For the butterﬂy transformation, the cost of computing the
plaintext is about 10 times lower than the cost of storing
the plaintext (per month). For the permutation scheme, this
cost is about 270 times lower than monthly storage. This
demonstrates that the butterﬂy scheme might be used in
archival settings (where plaintext data is rarely accessed).
On the other hand, the permutation scheme provides eco-
nomical motivation for the provider to comply and store H
even when plaintext accesses are frequent (several hundred
times a month).

Challenge-response protocol. We also present in Table 2
the challenge-response protocol times for both honest and
adversarial servers (storing plaintext F , but not H). For 2
random challenges, an adversarial server needs to retrieve
1024 symbols distributed across the input ﬁle. We observe
that the response of an honest server is at least 150 times
lower for 2GB ﬁles, and at least 650 times lower for 4GB ﬁles
than that of an adversarial server. We measure the sequential

throughput of EBS volumes at around 95MB per second
(resulting in 10.77s to read a 1GB ﬁle). Based on results
in Table 2, once we exceed 6 challenges for 2GB ﬁles, (and,
respectively 4 challenges for 4GB ﬁles), it’s faster for an
adversarial server to read the full ﬁle sequentially rather
than access blocks at random. Finally, to demonstrate how
the response timing scales, we also plot in Figure 4 the time
to read up to 1000 randomly selected blocks from ﬁles of
diﬀerent sizes.

The impact of parallelism. An adversary could try to
reduce its response time to challenges by spreading ﬁle F
across multiple EBS volumes in Amazon. Such ﬁle distri-
bution improves I/O performance, seek-time latencies, and
throughput. In principle, striping a ﬁle across v volumes can
yield a v-fold performance improvement. Bandwidth con-
straints suggest that such a strategy would be of limited
utility against the butterﬂy hourglass function, which re-
quires adversarial access to all (or at least a large portion)
of F to compute responses. Preliminary experiments suggest
that the network interface for a compute instance supports a
maximum bandwidth of about 1Gbit/s ≈ 125 MB/s. Thus,
retrieving a 1GB ﬁle, for instance, would require about 8s.7
By contrast, for an honest service that stores H to respond
to a very large challenge, e.g., of 100 blocks, requires less
than 1s. (See Figure 4.) Distribution across EBS volumes
would be more eﬀective against our permutation hourglass
function, where an adversary is constrained by seek-time
latency, rather than bandwidth. Still, to achieve response
times comparable to those of an honest service, an adver-
sary must distribute F across roughly v = m independent
storage systems, i.e., achieve an m-fold seek-time speedup,
where m is the number of symbols per challenge block. Our
experiments run with m = 512 (64-bit symbols and 4096-
byte blocks). Experiments suggest, however, that Amazon
supports a mere 8-fold speedup in seek times through dis-
tribution across EBS volumes [11].

6. RELATED WORK

Hourglass schemes—particularly our proposals based on
storage-access speed—intersect technically and conceptually
with a few diﬀerent lines of research.

Economic incentives. Several works have studied the prob-

7An adversary would also incur substantial overhead in
terms of time and compute-instance cost.

276devoted a certain, minimum amount of storage to a com-
mitted ﬁle F . Their protocols, however, don’t provide direct
assurance that the server has actually stored F itself. Later
schemes, including [6, 19, 27] and [5], a variant of [4], enable
a server to prove that it has stored some representation of
a ﬁle F such that F itself can be extracted from the server.
But these techniques don’t prove anything about the actual
representation of F at rest, e.g., that it’s encrypted.
Remote posture veriﬁcation. The Pioneer system [26],
and a later variant for mobile handsets [16], remotely times
the execution of a software module to measure its trustwor-
thiness. Misconﬁguration or the presence of malware slows
this execution, creating a measurable delay. Our storage-
based hourglass schemes may be viewed as a time-based
measurement of a server’s posture—not its software posture,
but its ﬁle-system posture.

Figure 4: Time to read random blocks from EBS.

7. CONCLUSION

lem of creating economic incentives for coordinated protocol
participation in various scenarios [22], including peer-to-peer
systems, communication networks and information security,
examined primarily in the context of algorithmic game the-
ory. Additionally, a growing body of work studies economic
incentives and security analysis against a rational adversary
in the context of rational cryptography (e.g., [15, 22]) and
network security (e.g., [12, 21]).

Puzzles. A moderately hard computational problem is often
called a puzzle or “proof of work” [17]. Dwork and Naor [8]
introduced the idea in a seminal work proposing puzzles as
a form of postage to combat spam. Puzzles have also found
application in the construction of digital time capsules [25]
and denial-of-service resistance [18].

Our storage-bounded hourglass schemes are loosely like
puzzles, but rely on storage access as the bounding resource,
rather than computation. (Our RSA-based hourglass scheme
isn’t really puzzle-like.) Additionally, unlike puzzles, hour-
glass schemes only impose high resource requirements on a
cheating server when it attempts to respond to a challenge,
as in, e.g., [28].

Memory-bound functions. Abadi et al. [3] and Dwork,
Naor, and Wee [9] explore puzzle variants that depend not on
a computational bound, but a bound s on available memory.
In a similar vein, Dziembowski, Kazana, and Wichs [10]
introduce the notion of one-time computable pseudorandom
functions (PRF). They consider a model in which compu-
tation of a PRF FK (·) requires so much memory that it
forces overwriting of the key K itself. Gratzer and Nac-
cache [14] and subsequently Perito and Tsudik [23] similarly
propose the idea of “squeezing out” data, namely purging
the entire memory of a target device by writing in a long
(pseudo)random string and reading it out again.

An hourglass scheme adopts the conceptually related ap-
proach of having a server prove correct behavior to a client
by showing that it ﬁlls its storage with a (nearly) valid en-
coded version H(cid:48) (e.g., ciphertext) of the raw ﬁle F (e.g.,
plaintext). The presence of this validly encoded H(cid:48) in stor-
age “squeezes out” invalidly encoded data (e.g., plaintext)
when the associated storage s is bounded.

Storage-enforcing schemes. Building on the notion of
“incompressible functions” [7], Golle et al. [13] have pro-
posed schemes in which a server demonstrates that it has

We have introduced hourglass schemes, a new crypto-
graphic construct that enables clients to verify remotely that
a server stores ﬁles in a particular target format. The for-
mats we have considered here are encryption, encoding with
“provenance tags” to enable tracing of leaked ﬁles, and the
binding together of two (or more) ﬁles. Hourglass schemes
leverage server resource bounds to achieve their security as-
surances. We have proposed three main hourglass construc-
tions here. Two draw on storage-access times as a resource
bound, another on hardness assumptions on the RSA cryp-
tosystem.

Hourglass schemes hold particular promise as means of
monitoring the ﬁle-handling practices of cloud services. With
this in mind, we have presented a series of experiments
demonstrating the feasibility of our proposals in Amazon’s
cloud service. More generally, as cloud computing prolifer-
ates, we believe that hourglass schemes and related tech-
niques will prove a valuable way of penetrating the cloud’s
abstraction layers and restoring security assurances sacri-
ﬁced to cloud-based outsourcing.

Acknowledgements
We thank all anonymous reviewers for providing detailed
comments and suggestions. Emil Stefanov was supported by
a National Science Foundation Graduate Research Fellow-
ship under Grant No. DGE-0946797, a DoD National De-
fense Science and Engineering Graduate Fellowship and a
grant from the Amazon Web Services in Education program.

8. REFERENCES
[1] American Express may have failed to encrypt data.

Available at http://www.scmagazine.com/
american-express-may-have-failed-to-encrypt-data/
article/170997/.

[2] Sony playstation data breach, 2011. Available at http:

//en.wikipedia.org/wiki/PlayStation_Network_outage.

[3] M. Abadi, M. Burrows, M. Manasse, and T. Wobber.

Moderately hard, memory-bound functions. ACM Trans.
Internet Technol., 5:299–327, May 2005.

[4] G. Ateniese, R. Burns, R. Curtmola, J. Herring, L. Kissner,

Z. Peterson, and D. Song. Provable data possession at
untrusted stores. In ACM CCS, pages 598–609, 2007.

[5] G. Ateniese, S. Kamara, and J. Katz. Proofs of storage

from homomorphic identiﬁcation protocols. In
ASIACRYPT ’09, pages 319–333, Berlin, Heidelberg, 2009.

277[6] Y. Dodis, S. Vadhan, and D. Wichs. Proofs of retrievability

via hardness ampliﬁcation. In TCC, pages 109–127, 2009.

[7] C. Dwork, J. Lotspiech, and M.Naor. Digital signets:

self-enforcing protection of digital information. In STOC,
pages 489–498. ACM, 1996.

[8] C. Dwork and M. Naor. Pricing via processing or

combatting junk mail. In CRYPTO, pages 139–147, 1993.

[9] C. Dwork, M. Naor, and H. Wee. Pebbling and proofs of

work. In CRYPTO, pages 37–54, 2005.

[10] S. Dziembowski, T. Kazana, and D. Wichs. One-time

computable self-erasing functions. In TCC, pages 125–143,
2011.

[11] E. Giberti. Honesty box: EBS performance revisited. Blog

posting, available at http://tinyurl.com/3nqxngv, 2010.

[12] S. Goldberg, S. Halevi, A. D. Jaggard, V. Ramachandran,

and R. N. Wright. Rationality and traﬃc attraction:
incentives for honest path announcements in BGP. In
SIGCOMM, pages 267–278, 2008.

[13] P. Golle, S. Jarecki, and I. Mironov. Cryptographic

primitives enforcing communication and storage
complexity. In FC ’02, pages 120–135, 2003.

[14] V. Gratzer and D. Naccache. Alien vs. quine. IEEE

Security and Privacy, 5(2):26–31, 2007.

[15] J. Halpern and V. Teague. Rational secret sharing and
multiparty computation: extended abstract. In STOC,
pages 623–632, 2004.

[16] M. Jakobsson and K. Johansson. Retroactive detection of
malware with applications to mobile platforms. In HotSec,
pages 1–13, 2010.

[17] M. Jakobsson and A. Juels. Proofs of work and bread

pudding protocols. In Communications and Multimedia
Security, pages 258–272, 1999.

[18] A. Juels and J. Brainard. Client puzzles: A cryptographic

countermeasure against connection depletion attacks. In
NDSS, pages 151–165, 1999.

[19] A. Juels and B. S. K. Jr. PORs: proofs of retrievability for

large ﬁles. In ACM CCS, pages 584–597, 2007.

[20] M. Labs and M. F. P. Services. Protecting your critical
assets: Lessons learned from “Operation Aurora”, 2010.
Whitepaper available at
http://www.mcafee.com/us/resources/white-papers/
wp-protecting-critical-assets.pdf.

[21] M. H. Manshaei, Q. Zhu, T. Alpcan, and J.-p. Hubaux.
Game theory meets network security and privacy. Main,
V(April):1–44, 2010.

[22] N. Nisan, T. Roughgarden, E. Tardos, and V. V. Vazirani.

Algorithmic Game Theory. Cambridge University Press,
New York, NY, USA, 2007.

[23] D. Perito and G. Tsudik. Secure code update for embedded

devices via proofs of secure erasure. In ESORICS, pages
643–662, 2010.

[24] R. Rivest. All-or-nothing encryption and the package

transform. In Fast Software Encryption, pages 210–218,
1997.

[25] R. L. Rivest, A. Shamir, and D. A. Wagner. Time-lock

puzzles and timed-release crypto. Technical report, 1996.

[26] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and
P. Khosla. Pioneer: Verifying code integrity and enforcing
untampered code execution on legacy systems. In SOSP,
pages 1–16, 2005.

[27] H. Shacham and B. Waters. Compact proofs of

retrievability. In ASIACRYPT, pages 90–107, 2008.
[28] R. Sion. Query execution assurance for outsourced

databases. In VLDB, pages 601–612, 2005.

APPENDIX
A. ENCODINGS

We now elaborate on Phase 1 of our generic hourglass pro-
tocol that we presented in Section 3. We give more details

on how the server generates an encoded version of F , as well
as a proof of correct encoding. In both the case of encryp-
tion and watermarking encoding, the provider must encode
ﬁle F into G using a secret unknown to the veriﬁer, i.e., the
client. In the case of encryption, the secret is the key κ. For
watermarking, the secret consists of multiple digital signa-
tures produced by the server that attest to the provenance
of the ﬁle; the signatures, if divulged, can be used to frame
the provider. Thus proving that G is correctly encoded cre-
ates a diﬃculty: The cloud provider has provided the veriﬁer
(client) with the encoded ﬁle G and must prove to the veriﬁer
that G is correctly computed from F , but without revealing
the secret used to produce encoding G.
Encryption encoding. For the case of encryption, the idea
is as follows. The prover encodes F under a pseudorandom
permutation (PRP), and partitions the ﬁle into n blocks. It
uses master key κ to derive a set of keys {κi}n
i=1, encrypting
the ith block of the ﬁle under κi. To verify that G is cor-
rectly formatted, the veriﬁer challenges the prover to reveal
a subset of the keys for randomly chosen blocks. The PRP
ensures that revealing a subset of the shares does not reveal
κ and therefore doesn’t permit decryption of the full ﬁle.

Figure 5 (left) speciﬁes our protocol for a server to prove
to a client that G represents a correct encryption of F . Here,
P RPκ(cid:48) denotes a keyed PRP, and Eκi,κ∗ denotes encryption
under keys κi and κ∗ (the two keys could be hashed together,
for instance, to obtain the ﬁle block encryption key). Also,
KD(κ, i) denotes an indexed key-derivation function that
takes master key κ as input. The number q of challenged
blocks can be adjusted to obtain a desired conﬁdence prob-
ability that ﬁle blocks are correctly encrypted.
The client supplies some randomness (in the form of a key
κ∗) that is used in combination with the secret key gener-
ated by the server for generating ﬁle block encryption keys.
The randomness provided by the client serves the goal of
enforcing that ﬁle block encryption keys are generated with
proper randomness.

As with any cryptographic scheme, it is important that the
server protect the encryption key κ. There are various well-
studied techniques for ensuring that the key is kept secret
such as using hardware security modules, trusted hardware,
or secure co-processors.
Watermark encoding. Figure 5 (right) speciﬁes our pro-
tocol for a server to prove to a client that G represents the
application of an hourglass function to F under a correct
incorporation of a provenance tag π. We let σ(M ) denote a
digital signature by the server on message M .

The main idea is to divide the ﬁle into n blocks and em-
bed a signature σi with each block Fi so that no block Fi
can be retrieved without revealing the signature embedded
with Fi. This property is achieved by applying an AONT
transformation [24] to each ﬁle block and the corresponding
signature. Block Gi of encoded ﬁle G is then computed as
AoNT[σi, Fi], where σi is a signature by the server on the
ﬁle handler handler and block index i.

The provenance tag π consists of the ﬁle handler and
hashes on signatures σi and is published by the server. A
proof of leakage by an external entity consists of a number
v of correct signatures, i.e., v signatures corresponding to
hashed signatures in π. The value v is a security parameter
such that q < v ≤ n.

The challenge procedure is exactly like that for ﬁle en-
cryption. The client challenges q randomly selected segments

278Client / Veriﬁer

Server / Prover

Input: ﬁle F = F1 . . . Fn
κ∗ R← {0, 1}l
{κ∗

i = KD(κ∗, i)}n

i=1

{zi
F (cid:48)
1 . . . F (cid:48)
{Gzi

R← {1, 2, . . . , n}}q
n ← P RPκ(cid:48) (F )
]}q

?= Eκzi

[F (cid:48)
zi

,κ∗

i

i=1

i=1

F,κ∗−→

κ(cid:48) ,G←−
{zi}q
i=1−→
{κzi
}q
i=1←−

n ← P RPκ(cid:48) (F )

κ R← {0, 1}l
κ(cid:48) R← {0, 1}l
1 . . . F (cid:48)
F (cid:48)
{κi = KD(κ, i)}n
i = KD(κ∗, i)}n
{κ∗
G = {Eκi ,κ∗
i ]}n

[F (cid:48)

i=1

i

i=1

i=1

Client / Veriﬁer

Input: ﬁle F = F1 . . . Fn

F−→

R← {1, 2, . . . , n}}q

{zi
{h(σzi ) ?= hzi}q
{Gzi

?= AoNT[σzi , Fzi ]}q

i=1

i=1

i=1

π,G←−
{zi}q
i=1−→
}q
←−
,σzi
i=1

{Gzi

Server / Prover
{σi = σ(handler||i)}n
{hi = h(σi)}n
π = (handler, {hi}n
i=1)
G = {AoNT[σi, Fi]}n

i=1

i=1

i=1

Figure 5: Proof of correct encodings: The cases of ﬁle encryption (left) and watermarking encoding (right).

of the ﬁle, and the server replies with the corresponding
signatures. The client veriﬁes that the AoNT encoding is
performed correctly on the challenged segments and that
signature hashes match those published in the provenance
tag. Using large sized blocks reduces the additional storage
expansion for signatures. At the same time, a large block
size reduces the challenge space and incurs overhead in the
challenge procedure of Phase 1, as large ﬁle blocks have to
be retrieved to check signature correctness. Thus, we have
to achieve a balance among diﬀerent metrics of interest. A

good choice is a block size of O((cid:112)|F|) bits, resulting in
n = O((cid:112)|F|) blocks.

File binding encoding. In some scenarios, it might be
useful to verify that multiple ﬁles are stored together (i.e.,
that they have been bound together). This feature can be
useful if, for example, we want to verify that source code
is stored together with its corresponding license. The pro-
tocol for ﬁle binding can very easily be constructed from
watermarking. A pair of ﬁles, F1 and F2 are bound together
or encoded via application of AoNT. Subsequent application
of an hourglass function, setup, and the challenge-response
protocol are then similar to the watermarking encoding pro-
tocol. This can easily be generalized to any number of ﬁles.

B. FORMAL SECURITY DEFINITION
We assume that the server is controlled by an adversary
A who has resources polynomially bounded in l. We let s de-
note an upper bound on the size of A’s storage (expressed in
bits). Both s and the ﬁle size n are polynomial in l. Also, A
is stateless, in the sense that distinct adversarial algorithms
(e.g., A(Store) and A(ChalRes)) cannot intercommunicate.
(The two algorithms represent the state of cloud at diﬀer-
ent times, so the only channel between them is the stored
value H.)

General security deﬁnition. Figure 6 presents the ex-
periment ExpHGA [l, n, s, δ] that characterizes the security of
general hourglass schemes. We deﬁne succHGA [l, n, s, δ] (cid:44)
Pr[ExpHGA [l, n, s, δ] = 1].

We found that coming up with the right deﬁnition for
an hourglass system (one of the paper’s technical contribu-
tion) is quite subtle. The adversary’s objective is to leak F ,
i.e., to store a ﬁle representation from which F can be re-
covered without decoding/decryption. We model the adver-
sary’s goal, however, as leakage of a random string ρ embed-
ded in F . We can think of ρ as the underlying entopy of F or
a maximally compressed version of F . If F is compressible,

Security experiment ExpHGA [l, n, s, δ]:

Initialize:
ρ R← {0, 1}δs
F ∈ Bn ← A(FileGen, ρ)
κ1 ← keygen-enc(l)
(κ2, κ3) ← keygen-hg(l)
G ∈ Ln ← encode(κ1, F )
H ∈ Dn ← hourglass(κ2, κ3, G)
Generate Storage:
H(cid:48) ∈ {0, 1}s ← Aencode(κ1 ,·),decode(κ1,·)(Store, ρ, F, G, H, κ2)
Recover Raw Data:
ρ(cid:48) ← A(RecRaw, H(cid:48), κ2)
Challenge-Response:
c R← challenge
r ← Astorage(H(cid:48),·),encode(κ1,·),decode(κ1,·)(ChalRes, c, κ2)
Finalize:
return (ρ(cid:48) ?= ρ) AND (verify(H, c, r) ?= 1)

Figure 6: General hourglass security experiment.

then it is easier for the adversary to recover ρ than to recover
the longer representation F directly. In our experiment, the
adversary may encode ρ in F arbitrarily.

In an honest execution of the protocol, a server will store
a ﬁle encoding H that has two properties: (1) By accessing
stored data format H, the server can respond correctly to
client challenges with overwhelming probability; and (2) H
is a function of G and, in this sense, prevents disclosure of
ρ unless decode is called.
In contrast, the goal of the adversary A is to construct
some H(cid:48) for storage with a diﬀerent pair of properties, namely:
(1) By accessing stored data H(cid:48), the adversary can respond
correctly, with high probability, to client challenges; and (2)
The adversary can extract ρ from H(cid:48) without calling decode.
In other words, A would like to appear to store a valid ﬁle
encoding H that does not contain raw data, but actually
store a ﬁle encoding H(cid:48) that leaks raw data.
In the experiment above, we model storage as an ora-
cle storage(H(cid:48),·) that reﬂects resource bounds on access to
stored ﬁle H(cid:48) ∈ Ls/l of size s bits. Oracle storage(H(cid:48),·) takes
an index i as input, and outputs either the i-th block of H(cid:48),
or ⊥ if the modeled resource bound has been exceeded.
On modeling leakage. In our experiment A aims to re-
cover ρ from H(cid:48) (while correctly answering challenges). Our
experiment requires that A(RecRaw,·) do so without access to
decode(κ1,·). The decode oracle models the underlying cryp-
tographic access-control mechanism. For instance, in prac-
tice, decode might correspond to a module based on trusted

279hardware that decrypts ciphertext data. Denying adversary
A(RecRaw,·) access to decode models the presumption that
an attacker can’t breach the trusted hardware module. (For
technical reasons, it also doesn’t have access to encode(κ1,·).)

Compression assumption. We assume that the output of
the encode function G on input raw ﬁle F ∈ Bn is uniformly
distributed in domain Ln. G is thus a string independent
of plaintext ﬁle F that can not be further compressed by
the adversary. This assumption is necessary in our security
analysis in order to provide meaningful lower bounds on the
amount of extra storage incurred by a cheating server.

We brieﬂy justify the compression assumption for our three
encodings of interest detailed in Appendix A. For the encryp-
tion encoding, we can model the (encode, decode) operations
as an ideal cipher. In this case, the ciphertext G resulting
after encrypting plaintext ﬁle F is uniformly distributed and
independent on the plaintext. For the watermark encoding,
the all-or-nothing transformation AoNT can be modeled as
a random oracle, resulting again in uniformly distributed
output G. File binding encoding is a simple extension of
watermark encoding and as such the same random oracle
modeling of the AoNT transform can be used to justify the
compression assumption.

Partitioning assumption. We make a simplifying techni-
cal assumption on A throughout our security proofs (which
are omitted for lack of space). This partitioning assumption

G|.

, H(cid:48)

F , κ2) → ρ.

F

• H(cid:48)

F and H(cid:48)

F , i.e., there is an algorithm

requires that A(Store,·) output H(cid:48) of the form H(cid:48) = (H(cid:48)
F (cid:107)
H(cid:48)
G), where H(cid:48)
G are distinct substrings as follows:
• H(cid:48)
F is a raw representation of F . In other words, A can
recover ρ from H(cid:48)
A(RecRawH(cid:48)
G is “extra” storage used by A to help it respond to
challenges. We can think of H(cid:48)
G as the storage overhead
imposed on A in order to cheat and answer challenges
correctly while it is leaking F . We assume that A com-
putes H(cid:48)
G over G and H, without knowledge of F . (But
A is allowed to use all of H(cid:48) to respond to challenges.)
The partitioning assumption renders security analysis of
our concrete hourglass constructions simpler. We conjecture,
however, that the assumption doesn’t in fact result in a
weaker class of adversary.8 It seems implausible that mixing
together H(cid:48)
G into a combined representation would
advantage A. After all, G is uniformly distributed in domain
Ln and therefore an independent string in the view of A. We
leave this conjecture on the partitioning assumption as an
open problem. In our security analysis, we use s(cid:48) to denote
|H(cid:48)
8In particular, our conjecture applies to hourglass schemes
that are valid, as deﬁned in Section 2.2. Clearly, for a degen-
erate scheme with challenges constructed over F , A would
beneﬁt from computing H(cid:48)

F and H(cid:48)

G as a function of F .

280