HIFS: History Independence for File Systems

Sumeet Bajaj

Stony Brook University

New York, USA

sbajaj@cs.stonybrook.edu

Radu Sion

Stony Brook University

New York, USA

sion@cs.stonybrook.edu

ABSTRACT
Ensuring complete irrecoverability of deleted data is diﬃcult
to achieve in modern systems. Simply overwriting data or
deploying encryption with ephemeral keys is not suﬃcient.
The mere (previous) existence of deleted records impacts
the current system state implicitly at all layers. This can
be used as an oracle to derive information about the past
existence of deleted records.

Yet there is hope. If all system layers would exhibit history
independence, such implicit history-related oracles would
disappear. However, achieving history independence eﬃ-
ciently is hard due to the fact that current systems are de-
signed to heavily beneﬁt from (data and time) locality at all
layers through heavy caching, and existing history indepen-
dent data structures completely destroy locality.

In this work we devise a way to achieve history indepen-
dence while preserving locality (and thus be practical). We
then design, implement and experimentally evaluate the ﬁrst
history independent ﬁle system (HIFS). HIFS guarantees se-
cure deletion by providing full history independence across
both ﬁle system and disk layers of the storage stack. It pre-
serves data locality, and provides tunable eﬃciency knobs to
suit diﬀerent application history-sensitive scenarios.

Categories and Subject Descriptors
H.3.2 [Information Storage and Retrieval]: Information
Storage—File organization; D.4.3 [Operating Systems]:
File Systems Management—File organization

Keywords
History Independence; File System; Secure Deletion

1.

INTRODUCTION

Numerous regulatory frameworks in ﬁnance, government
and health-care, require secure deletion assurances typically
by overwriting records on deletion. However, simply over-
writing records does not guarantee deletion since the write

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516724.

history itself implicitly leaves artifacts in the layout of the
resulting storage medium at all layers. The artifacts can be
used as an oracle to answer questions about the past exis-
tence of deleted records. For example, the current layout of
data blocks on disk is a function of the sequence and timing
of previous writes to ﬁle system or database search indexes.
Questions such as “was John’s record ever in the HIV pa-
tients’ dataset” can then be answered much more accurately
than guessing by simply looking at the storage layout of
the search index on disk (which will look diﬀerent depend-
ing on whether John has previously been in the data set
or not). Yet, these are the very questions that secure dele-
tion promises to prevent anyone (including insiders) from
answering once John’s record has been deleted.

We posit that if all relevant system layers exhibit history
independence, the implicit history-related oracles would dis-
appear making the recovery of deleted records impossible.

Although prior work has focussed on designing history in-
dependent 1 data structures [5, 8, 12, 13, 16, 19], many chal-
lenges remain un-addressed for their successful deployment
in systems. The ﬁrst challenge is the un-availability of system-
wide, space-allocation mechanisms that are also history in-
dependent. Such mechanisms are needed because data struc-
tures typically reside in storage sub-systems such as memory
or disk. Hence, even if a data structure is history inde-
pendent the behavior of the underlying storage sub-system
may compromise its history. For example, the allocation of
disk blocks by the ﬁle system can reveal information about
the past operations performed on an otherwise history in-
dependent data structure (detailed examples in Section 3).
Therefore, to realize complete history independence all sys-
tem components on the data path need to possess the same
characteristics [11]. Next, individual component character-
istics render the existence of a single history independent de-
sign for all components unlikely. For instance, the low RAM
latency vs. disk seek times, and the linear-ordered storage
of disks vs. the wear leveling of SSDs. Hence, speciﬁc his-
tory independent designs are needed for each system com-
ponent. Finally, achieving history independence eﬃciently
in actual systems is hard due to the fact that current system
designs heavily beneﬁt from (data and time) locality at all
layers through heavy caching, and existing history indepen-
dent data structures completely destroy locality.

In this work we address the challenges of providing his-
tory independence for ﬁle storage over disk devices (Figure

1A data structure is history independent if its storage layout
is a function of the current state and not of the history of
past operations that led to it.

1285Applications

History Independent Data Structures

Operating System

Middleware

Management

insert  order

insert  order

Adam, Chad, John, Katy

Katy, John, Chad, Adam

Chad  .  _

John .  _

Network

Process

Memory

A

File System

Adam  .  _

John  .  Katy

Adam . Chad

Katy . _

Device Drivers

Physical Components

M
e
m
o
r
y

Network 

Storage

B

Figure 1: Potential system components that require
history independent designs. This work targets ﬁle
systems (A) using hard disks (B) for ﬁle storage.

1). We achieve this by introducing the ﬁrst history indepen-
dent ﬁle system (HIFS) with the following key design and
performance characteristics.

(1) Varying degrees of data locality with minimal modiﬁ-

cations for diﬀerent application scenarios (Section 4.5.1).

(2) Customizable history independent layouts via simple

modiﬁcations of a few key procedures (Section 4.5.1).

(3) Sequential read throughputs within 0.7x - 0.5x as com-
pared to existing non-history independent ﬁle systems such
as Ext3 for loads up to 60% (Section 6). Random read
throughputs within 0.7x - 0.5x of Ext3 for loads up to 90%.
Low performance for write operations at loads >60%.

(4) Eﬃcient history independent ﬁle meta-data operations
(Section 6). File delete and move operations as expensive as
an entire ﬁle write (Section 4.5.4).

2. MODEL
Adversary. We assume an adversary with full access to
the storage medium (e.g., the system disk). By forensic anal-
ysis of the disk contents the adversary aims to illegitimately
derive sensitive information. Adversary actions include (but
are not limited to) the following.

(1) Determine the existence and content of records deleted

in the past, thereby violating regulatory compliance [4].

(2) Determine the order of past ﬁle operations to subvert

privacy in voting applications [5].

(3) Compromise history independence of data structures
stored within ﬁles via ﬁle system meta-data and disk layouts.
Storage Medium. The underlying storage device is re-
quired to be a mechanical disk drive, not ﬂash storage (dis-
cussion on SSD storage in Section 5).
Files. All data structures stored within ﬁles are history
independent [5, 8, 12, 13, 16, 19].

3. HISTORY INDEPENDENCE

3.1 File Systems

Existing ﬁle systems do not preserve history independence
because the disk layouts they produce are not just a func-
tion of ﬁle contents but also depend on the sequence of ﬁle
operations. The exact same set of ﬁles can be organized
diﬀerently on disk depending on the sequence of operations
that created the set. As a result, a simple examination of

(a)

(b)

Figure 2: B-Tree, a non history independent data
structure.

the disk layouts can reveal sensitive information about past
operations. Moreover, the data structures used to maintain
ﬁle system meta-data also contain information about past
operations, both in their layouts, and in their contents (e.g.,
list of allocated blocks). Therefore, when disk layouts are
combined with ﬁle system meta-data and knowledge of data
structures that are stored within ﬁles, signiﬁcantly more in-
formation can be derived, even full recovery of deleted data.
Such leakage can violate secure deletion requirements and
compromise privacy in applications such as e-voting.

At ﬁrst it may appear that a simple replacement of all ﬁle
system data structures (ﬁle meta-data, free block list etc)
with their history independent versions would suﬃce to re-
solve the issue and preserve privacy. However, this is not the
case, for the privacy leaks are not due to the data itself but
due to the organization of data on disk. File system encryp-
tion too cannot solve the problem since the concern here is
not data conﬁdentiality. The relevant adversary is in fact an
insider that requires and is rightfully granted full access to
the data in the future (including disk encryption keys etc)
and thus can easily bypass any protections encryption may
oﬀer. The solution then is to make ﬁle systems completely
history independent. The disk layouts of a history indepen-
dent ﬁle system (deﬁned in Section 3.1.2) are only a function
of data and not of the sequence of past operations.

3.1.1 Example Illustration

To illustrate the need for history independence in ﬁle sys-
tems we consider an admissions management application at
a hospital that records patients’ data as new patients are
admitted. The application API permits the hospital staﬀ to
add new patient records, lookup existing records and delete
patient records on discharge. We will use this example for
illustration but note that in essence, most existing applica-
tions of history independent data structures cannot be se-
curely realized in practice without an underlying ﬁle system
providing history independent persistence.

The patient application will typically utilize a database to
manage its data. Now, a database in turn stores and ma-
nipulates data by utilizing eﬃcient data structures of which
B-Trees [7] are the most common example. However, the
use of B-Trees causes several privacy concerns. This is be-
cause the storage layout of B-Trees (or of variations such as
B+-Trees) often depends on the order in which operations
are performed on them due to their deterministic insertions
and deletions. For example, consider the the illustration in
Figure 2 which shows two B-Trees that store the exact same
elements. Yet the layouts of the two B-Trees diﬀer due to
diﬀerent insertion orders. Hence, simply by examining the
tree layout (Figure 2(a)) one can ascertain with a probabil-
ity of 75% that Chad was admitted before John. This is
due to the fact that out of the total 4! ways of insertion

1286operation
sequence

B-Treap
General

(G)

B-Treap
Special

(S)

Disk layout

Free Block

Block Allocated to G

Block Allocated to S

1

2

3

4

5

6

IG(Katy)

Katy . _

IG(Chad)

Chad,Katy

IS(Adam)

IG(Rick)

Katy . _

Chad . _

Rick . _

Katy . _

Chad,Katy

Adam._

Chad,Katy Adam . _

Katy . _ Adam . _ Chad . _ Rick . _

IS(Jane)
IS(Rick)

Adam,Jane

Jane .  _

Adam ._

Rick . _

Katy . _ Adam,Jane Chad . _ Rick . _

Katy . _

Jane . _ Chad . _ Rick . _

Adam . _

Rick . _

7

DG(Rick)

Chad,Katy

Chad,Katy Jane . _

Adam . _

Rick . _

(a)

operation
sequence

B-Treap
General

(G)

B-Treap
Special

(S)

Disk layout

Free Block

Block Allocated to G

Block Allocated to S

1

2

3

4

5

IG(Katy)

Katy . _

Katy . _

IS(Adam)

Adam._

Katy . _ Adam . _

IG(Chad)

Chad,Katy

Chad,Katy Adam . _

IS(Jane)

IS(Rick)

Adam,Jane

Chad.Katy Adam,Jane

Jane .  _

Chad.Katy Jane . _ Adam . _ Rick . _

Adam ._

Rick . _

(b)

Figure 3: B-Treaps and ﬁle system layouts. IR(t) and DR(t) denote insertion and deletion respectively of
element t in relation R.

for the four elements Adam, Chad, John and Katy, Chad is
the root in only twelve, and inserted before John in nine of
those twelve sequences.

The above limitation of B-Trees can be prevented by de-
ploying corresponding history independent versions, such as
B-Treaps [12]. The treaps will yield the same layout irre-
spective of the insertion order. However, such a simple re-
placement of application data structures with their history
independent versions does not suﬃce unless the underlying
persistent mechanisms (e.g., ﬁle system) are also history in-
dependent. To clarify, suppose that the B-Trees from above
are replaced by the history independent B-Treaps [12]. Also,
suppose that the application has two relations, one for ad-
missions to the General ward and another for admissions to
the Special ward, and that both relations are persisted us-
ing a simple ﬁle system that allocates the ﬁrst available free
block on request (and is hence not history independent). For
simplicity, assume that the B-Treap node size is equal to the
ﬁle system block size.

Now, consider the sequence of operations, the resultant
B-Treaps, and the space allocation by the underlying ﬁle
system as shown in Figure 3(a). At the end of operation
7, the disk layout (Figure 3(a)) reveals the following.
(i)
The fact that a delete operation was performed. The gaps
left by the ﬁle system allocation form evidence for a delete.
(ii) That the deleted node belonged to the General relation.
Since otherwise there would be no gaps in the ﬁle system.
(iii) The ﬁrst patient was not admitted to the Special ward,
since the root node of Special relation is not the ﬁrst block
on storage. Note that neither the layout of the B-Treaps nor
the application API reveal any of (i) - (iii). The leaks are
solely due to ﬁle system allocation.

Figure 3(b) shows an alternate sequence of operations that
yield the exact same trees as in Figure 3(a) yet with signif-
icantly diﬀerent disk layouts, showing that the disk layouts
produced by the ﬁle system allocation heavily depend on
ﬁle system operation sequencing. Hence, underlying storage
mechanisms can defeat the history independence of higher
level data structures.

While we used a simple ﬁle system scenario for illustra-
tion, we note that existing ﬁle systems (e.g., Ext2/Ext3 [3])
suﬀer from the same problems, since, for eﬃciency, and to
preserve locality, they too allocate new blocks based on ex-
isting state, resulting in heavily history dependent layouts.
A history independent ﬁle system on the other hand would
reveal none of (i) to (iii) above since it would carry no evi-
dence of a delete, such as gaps in block allocation. Similarly,
its allocation policy would not be dependent on the order of

ﬁle operations, resulting in the exact same disk layouts for
the operation sequences of both Figures 3(a) and 3(b).

3.1.2 History Independent File System

Let ΨΓ

F denote the distribution (layout) over secondary
storage of the state F , of a ﬁle system Γ. F represents all
ﬁle contents plus meta-data for individual ﬁles and for the
overall ﬁle system. Also, let S Γ
F→F 0 denote a set of opera-
tions performed by ﬁle system Γ transforming its state from
F into F 0. We can then deﬁne the following.

Definition 1. History Independent File System (HIFS)
Γ is a history independent ﬁle system if any two sequence of
operations X Γ
F→F 0 result in an identical distri-
bution ΨΓ

F→F 0 and Y Γ

F 0 .

F→F 0

Formulated diﬀerently, for two sequences of operations X Γ
and Y Γ
F→F 0 , an adversary having access to both the start
state F and the end state F 0, should not be able to deduce
which of X or Y was executed to transform the state from F
into F 0. It can be easily seen that satisfying this deﬁnition
immediately implies that, the data at a particular oﬀset of
any ﬁle f in F , is always stored at the same device-speciﬁc
location, irrespective of the sequence of operations that re-
sult in F . That is, the representation of the state F over
the storage medium is canonical.

3.2 System-Wide History Independence

Although detailed discussion is out of scope, we brieﬂy

generalize history independence for an entire system.

Consider a typical system composed of multiple layers,
ranging from software applications to hardware (Figure 1).
Let these layers be denoted by L0 , L1 , L2 etc, where L0 is
the bottom layer, L1 the next higher layer and so on. Also,
let S Li
A→B denote the set of operations that transform Li
from state A to B . Further suppose that, for each state A
of Li , there exists a state A0 of Li−1 with the requirement
that when Li is in state A, Li−1 must be in state A0 – we
A → Li−1
denote this relationship between A and A0 as Li
.
Then we can deﬁne the following.

A0

Definition 2. History Independent System

A system is history independent if (i) each system layer Li
is history independent, i ≥ 0, and (ii) any sequence of op-
erations X Li
A→B causes Li−1 to change from state A0 to B 0,
where Li

B → Li−1

B 0 and i > 0.

A → Li−1

A0

, Li

1287super block

block  group 0

block group 1

block group Gn

disk

disk

buckets map

buckets

group

descriptors

disk

bucket 0

disk

bucket 1

disk

bucket Bn

Inode
table

data blocks 0 - dbn

Figure 4: HIFS disk layout. Key parameters: Gn ←
number of block groups, Bn ← number of disk buck-
ets per block group, ds ← Data block size in bytes,
dbn ← number of data blocks per disk bucket.

4. ARCHITECTURE

4.1 Overview

The goals of the HIFS design are three-fold. (a) For any
given set of ﬁles, the layout of their contents (including ﬁle
and system meta-data) on disk are in a canonical form which
is independent of the sequence of ﬁle operations, thus being
history independent as per the deﬁnition 1. (b) Despite his-
tory independent layouts on disk, data locality is preserved.
(c) The canonical layouts are customizable to suit a wide
range of application requirements.

HIFS closely resembles existing Linux ﬁle systems such
as Ext2 [3], exposing the exact same API and utilizing a
similar disk structure (Figure 4). The key diﬀerences that
give it history independent characteristics are the use of new
locality-preserving history independent data structures for
all ﬁle system meta-data (e.g., the inode table, Section 4.5.3)
and the fact that the allocation of free disk blocks to ﬁles
is not based on history. Hence HIFS does not use indirect
and double indirect blocks to map ﬁle blocks to disk blocks.
Instead, the entire data blocks section on disk is managed
as a history independent data structure to allocate blocks to
ﬁles (Section 4.5.1).

In the following sections we detail. Space constraints pre-
vent too much in-depth detail on each operation. Instead
we focus more on the features that speciﬁcally give HIFS its
history independent characteristics.

4.2 History Independent Hash Table [5]

The key feature of HIFS is the replacement of all ﬁle sys-
tem disk structures with history independent versions that
we then endow with data locality preservation properties.
The data structure of choice here is the history independent
hash table in [5]. Hence, ﬁrst we describe the hash table
construction and in subsequent sections illustrate its use in
various HIFS components.

The hash table in [5] is based on the stable matching prop-
erty of the Gale-Shapley Stable Marriage algorithm [10] de-
tailed in the following.

Stable Marriage Algorithm. Let M and W be a set of
men and women respectively, |M | = |W | = n. Also, let each
man in M rank all women in W as per his set of preferences.
Similarly, each women in W ranks all men in M .

The goal of the stable marriage algorithm is to create n
matchings (m, w) where m ∈ M and w ∈ W s.t no two pairs
(mi, wj ), (mk, wl) (i 6= k, j 6= l) exist where (a) mi ranks wl
higher than wj and (b) wl ranks mi higher than mk. If no
such pairings exists then all matchings are considered stable.
The algorithm works as follows. In each round, a man m
proposes to one woman at a time based on his ranking of
W .
If a woman w being proposed to is un-matched then
a new match (m, w) is created. If the woman w is already
matched to some other man m0 then one of the following
occurs. (a) if w ranks m higher than m0 then the match
(m0, w) is broken and a new match (m, w) is created, or (b)
if w ranks m lower than m0, then m proposes to the next
woman based on his rankings. The algorithm terminates
when all men are matched.

[10] shows that if all the men propose in decreasing order
of their preferences (ranks) then the resulting stable match-
ing is unique. This holds even if the selection of a man m
(who gets to propose) in each round is arbitrary.
History Independent Hash Table.
[5] then uses the
above property of the Stable Marriage algorithm to con-
struct a history independent hash table as follows. (1) The
set of keys to be inserted in to the table are considered as the
set of men. (2) The set of hash table buckets are considered
as the set of women. (3) Each key has an ordered preference
of buckets and vice versa. (4) The preference order of each
key is the order in which the buckets are probed for inser-
tion, deletion and search. (5) In case of a collision between
two keys, the key which ranks higher on the bucket’s pref-
erence takes the slot. The lower ranked key is relocated to
the next bucket in its preference list.

(1) - (5) ensure that the layout of keys in the hash table is
the same irrespective of the sequence of key insertions and
deletions, thereby making it history independent [5].

4.3 Key Insights

A simple replacement of all ﬁle system structures with the
above history independent hash table will suﬃce to yield a
history independent layout of ﬁles on disk. However, this
neither preserves data locality nor gives the ﬂexibility to
choose diﬀerent layouts based on application characteristics,
both of which are key goals in the design of HIFS. Then a
key observation in this context is the following. In the Stable
Marriage algorithm each man in M can rank the n women
in W in n! ways, and vice-versa. Hence, several set of prefer-
ences from keys to buckets and buckets to keys are possible,
each resulting in a distinct hash table instance. Therefore,
by changing the preference order of keys and buckets we can
control the layout of keys within the hash table.

The re-ordering of preferences leads to the realization that
we can rewrite the algorithms in [5] to enable easy-custom
selection of history independent layouts with minimal mod-
iﬁcations. For this, we categorize the hash table operations
in two Procedure Sets, a generic set and a customizable set.
The generic procedures implement the overall search, insert
and delete operations, and can be used unaltered for all sce-
narios. The customizable procedures determine the speciﬁc
key and bucket preferences thereby governing the resultant
hash table layouts.

1288if H r[i] is null then

H r[i] ← k
return <i, r>

SWAP(k, H r[i])

c ← c + 1

if BUCKET PREFERS(i, r, k, H r[i]) then

Procedure Set 1 History Independent Hash Table
Procedure:
Desc: insert the given key in to the hash table.
Input: Tables H 0−m[n], key k
1: <i, r>← GET MOST PREFERRED BUCKET(k)
2: c ← 0
3: while c < (n ∗ (m + 1)) do
4:
5:
6:
7:
8:
9: <i, r>← GET NEXT BUCKET(k, i, r)
10:
11: return <null, null> {tables are full}
——————————————————————
Procedure: SEARCH
Desc: search for the given key in the hash table.
Input: Tables H 0−m[n], key k
1: <i, r>← GET MOST PREFERRED BUCKET(k)
2: c ← 0
3: while c < (n ∗ (m + 1)) AND H r[i] is not null do
4:
return <i, r> {key found at H r[i]}
5:
6: <i, r>← GET NEXT BUCKET(k, i, r)
7:
8: return <null, null> {key not found}
——————————————————————
Procedure: DELETE
Desc: delete the given key from the hash table.
Input: Tables H 0−m[n], key k
1: <i, r>← SEARCH(k)
2: while i is not null AND H r[i] is not null do
3: <j, s>← GET NEXT BUCKET(k, i, r)
4:

if k == H r[i] then

c ← c + 1

INSERT

if H s[j]
H s[j], i, j, r, s) then

is not null AND KEY PREFERS(

5:

H r[i] ← H s[j], k ← H s[j], i ← j, r ← s

The generic procedures include INSERT, SEARCH and
DELETE, listed in Procedure Set 1. These in turn use the
customizable procedures, which include GET MOST PRE-
FERRED BUCKET, GET NEXT BUCKET, BUCKET PR
EFERS and KEY PREFERS. We list the scenario speciﬁc
customizable procedures later in Sections 4.5.1 and 4.5.2
while discussing ﬁle system operations.

In short, this new procedure classiﬁcation and rewrite en-
ables new distinct history independent layouts for the same
data set through modiﬁcations to the customizable proce-
dures. Moreover, these modiﬁcations can now be targeted
to maximize locality or to favor other application character-
istics, e.g., read-only, sequential access etc. (Section 4.5.1).

4.4 Disk Layout

Not unlike Ext2 [3] HIFS divides the disk into block groups,
each with its own inode table, map and data blocks. The su-
per block contains information about the overall ﬁle system
(e.g., number of block groups, disk block size etc.), and the
individual group descriptors describe their respective block
groups (e.g., inode table size, location of the disk buckets
map etc.). Parameters aﬀecting the disk layout (Figure 4)
can be set up at ﬁle system creation time. The superblock
and group descriptors have ﬁxed sizes and occupy the same
locations on disk independent of ﬁle contents. Hence, no spe-
cial history independent designs are needed for them. The

ds (cid:5)/dbn(cid:5)(cid:1)

Procedure Set 2 Customizable Procedures for Case A
(Block Group Locality) from Section 4.5.1
Procedure: GDB
Desc: get the logical ﬁle bucket number from ﬁle oﬀset.
Input: ﬁle oﬀset fo : fo ∈ N
1: return (cid:0)(cid:4)(cid:4) fo
——————————————————————
Procedure: GET MOST PREFERRED BUCKET
Input: key k : k = {ﬁle path fp, ﬁle oﬀset fo}
1: return <h(fp||GDB(fo)) mod Bn, h(fp) mod Gn>
——————————————————————
Procedure: GET NEXT BUCKET
Input: key k : {fp, fo}, bucket i, block group r : (i, r) ∈ N
1: i ← (i + 1) mod Bn
2: if i == (h(fp||GDB(fo)) mod Bn) then
3:
4: return <i, r>
——————————————————————
Procedure: BUCKET PREFERS
Input: bucket i, block group r : (i,r) ∈ N, key a : {fpa , foa },

r ← (r + 1) mod Gn, i ← h(fp||GDB(fo)) mod Bn

key b : {fpb , fob }

1: return h(fpa ||GDB(foa )) >h(fpb ||GDB(fob ))
——————————————————————
Procedure: KEY PREFERS
Input: key k : {fp, fo}, bucket i, bucket j, block group r,

block group s : (i,j,r,s) ∈ N

1: if r <>s then
2:

return ((h(fp) mod Gn) - r + Gn) mod Gn < ((h(fp)
mod Gn) - s + Gn) mod Gn

3: return ((h(fp||GDB(fo)) mod Bn) - i + Bn) mod Bn <

((h(fp||GDB(fo)) mod Bn) - j + Bn) mod Bn

disk bucket maps and the inode tables however, play a crit-
ical role in history independent ﬁle storage, and we discuss
them in detail below.

4.5 File Storage
Disk Buckets. File data is stored in blocks on disk. These
are grouped into units, where each unit consists of a ﬁxed
number of (multiple) data blocks. Each such unit is termed
as a disk bucket (Figure 4). Although read and write op-
erations access individual data blocks, space is allocated to
ﬁles in multiples of disk buckets.
Disk Buckets Map. HIFS relies on a special region in
each block group referred to as the disk buckets map for
allocation of new disk buckets to ﬁles and for locating disk
blocks in read and write operations. Each entry within the
disk buckets map has a one-one mapping to the correspond-
ing disk bucket within that block group (Figure 4). The en-
try in the map contains meta-data about the corresponding
disk bucket (e.g., whether the bucket is free or occupied).

All ﬁle system operations ﬁrst locate the target entry in
the disk buckets map and only then perform the actual read
or write operation on the corresponding disk bucket. This
avoids the need to perform expensive seek operations on
actual ﬁle contents to locate data blocks. Also, the relative
smaller size of the maps means that they are often cached
in memory for faster access.

4.5.1 History Independent Layouts

Existing ﬁle systems such as Ext2 [3] maintain a list of
allocated blocks within the ﬁle inode which renders the disk
space allocation history dependent. HIFS however, does
not rely on such lists; instead location of data blocks are

12891

2

3

4

5

write(fp1, 4, 0)
write(fp2, 5, 0)
write(fp3, 1, 0)
write(fp1, 2, 4 . ds)
write(fp3, 2, 2. ds)

logical file buckets

logical file
data blocks
file offsets

File 1 (fp1) 
0

1

2

File 2 (fp2) 
0

1

2

0 1 2 3 4 5

0

…

5.ds

0 1 2 3 4 5
0

…

5.ds

File 3 (fp3) 

0 1

0 1 2 3
0

…

4.ds

1

2

3

4

5

write(fp3, 1, 0)

write(fp2, 5, 0)
write(fp1, 2, 4 . ds)

write(fp3, 2, 2. ds)
write(fp1, 4, 0)

1

2

3

4

5

1

2

3

0 1

0 1

0 1 2 3

0 1 2 3

1 2

0 2 3 4

1 2 0 2 3 4

0 0 1 0

0 1 2 3

1 2 0 2 3 4

0 1

0 1

0 1

2 0 0 1 4 5 0

0 1 2 3

1 2 1 0 2 3 4

2 3 0 1

2 0 0 1 4 5 0

0 1 2 3

1 2 1 0 2 3 4

2 3 0 1

I0

B0

D0

(a)

I1

B1

D1

1

write(fp2, 5, 0)

2

write(fp1, 2, 4 . ds)

3

write(fp1, 4, 0)

0 1

0 1 2 3

2

4 5

1 2 0 2 3 4

1 2 0 2 3 4

0 1

0 1

2 0 1 4 5

0 1 2 3

1 2 1 0 2 3 4

2 3 0 1

1

2

3

4

5

6

0

0

2 0

4 5 0

1 2 0 2 3 4

1 2 0 2 3 4

2 0 1

4 5 0

2 3

1 2 0 2 3 4

0 1

0 1

0 1

2 0 0 1 4 5 0

0 1 2 3

1 2 1 0 2 3 4

2 3 0 1

I0

B0

D0

I1

B1

D1

(b)

6

delete(fp3)

2 0 1 4 5

0 1 2 3

1 2 1 0 2 3 4

2 3 0 1

I0

B0

D0

I1

B1

D1

I0

B0

D0

(c)

I1

B1

D1

(d)

Figure 5: Sample executions and corresponding disk layouts for Case A from Section 4.5.1. Here Gn = 2,
Bn = 4, dbn = 2.
Ii, Bi and Di denote the inode table, disk buckets map, and the disk blocks respectively of
block group i. Also, h(fp1 ) = 2, h(fp2 ) = 3 and h(fp3 ) = 4. write(fp, fd, fo) represents a write operation of fd
blocks on ﬁle fp at oﬀset fo. The disk blocks occupied by ﬁles with paths fp1, fp2 and fp3 are shaded with their
respective colors. Blocks that are not shaded indicate free blocks. The number within a block represents the
data block number of the corresponding ﬁle.

derived directly from ﬁle attributes. Thus, for each read
or write operation the location of data blocks on disk are
determined only by the parameters to the current operation
and do not depend on any past operation. To this end,
the disk bucket maps from all block groups are collectively
treated as a single history independent hash table. Hash
table keys are derived from ﬁle attributes such as the ﬁle
paths and read-write oﬀsets. The entries in the maps are
themselves the hash table buckets.

As discussed in Section 4.3, by altering the derivation of
keys and the keys↔buckets preference sets we can attain
customized layouts of the hash table to suit diﬀerent re-
quirements. Hence, ﬁle system operations use the generic
hash table procedures from Procedure Set 1 to locate free
blocks for allocation or to ﬁnd existing blocks for reading
or writing. Diﬀerent history independent layouts of ﬁle con-
tents on disk are realized solely by altering the customiz-
able Procedure Set. Thus, the ﬁle system operations (read,
write, mkdir etc) have implementations independent of the
underlying history independent layouts, which in turn can
be designed as needed, by speciﬁc customizable procedure
implementations. To illustrate this, the actual ﬁle system
write operation is included in Procedure Set 6 (Appendix).
We now describe a speciﬁc history independent layout sce-

nario in detail and then brieﬂy discuss others.
Case A: Block Group Locality. For data locality and
overall eﬃciency, it is highly desirable that data blocks of the
same ﬁle are located close together on disk, ideally within the
same block group. To realize this scenario we tailor the cus-
tomizable procedures as shown in Procedure Set 2. All other
generic history independent hash table procedures from set
1, and the generic ﬁle system operations are unchanged.

To understand this better, consider Figure 5 which gives
a detailed example for a set of three ﬁles. Each of Figures
5(a)-5(d) list a sequence of ﬁle system operations and depict
the resultant disk layout (including ﬁles meta-data and con-
tent) at the end of each operation. Note that although the
sequence of operations in Figures 5(a) and 5(b) diﬀer, the
resultant disk layouts at the end of either operation sequence
are exactly the same (i.e., canonical).

To achieve canonical disk layouts the ﬁle system opera-
tions are translated in to hash table operations as follows:
(a) Keys are derived from the full ﬁle path fp and the read or
write oﬀset fo. (b) The hash table buckets are the disk buck-
ets map entries. (c) Key preferences are set such that each
key ﬁrst prefers all buckets from one speciﬁc block group, in
a ﬁxed order. Then, buckets from the next adjacent block
group and so on.
(d) Finally, buckets simply prefer keys
with higher numerical values.

To give an intuition of how (a) - (d) preserve locality and
yet give history independent layouts, consider the ﬁle system
write operation (Procedure Set 6 in Appendix). The write
operation ﬁrst needs to locate the correct entry in the disk
buckets maps. Once this entry is located it will perform the
actual write on the corresponding disk bucket. Since the disk
buckets maps from all block groups are treated as a single
history independent hash table locating the correct buckets
map entry is equivalent to ﬁnding the corresponding hash
table bucket. Hence, locating the disk buckets map entry
requires probing of the disk buckets maps. The probe order
is exactly what is determined by the key preferences.
The probe order for any write operation al-
Locality.
ways starts with the most preferred bucket as determined by
the procedure GET MOST PREFERRED BUCKET (Pro-

1290cedure Set 2). For a given ﬁle fp, the block group of the
most preferred bucket for all its write operations are derived
only from the ﬁle path’s hash h(fp) (line 1, second return
parameter). Hence, all write operations of the same ﬁle be-
gin their probing from the same block group independent of
their target ﬁle oﬀsets. Note that the probing for two write
operations that target diﬀerent oﬀsets may start from two
diﬀerent buckets, but both buckets will be located within
the same block group.

Moreover, subsequent buckets in the probing of the disk

buckets map are determined using the GET NEXT BUCKET
procedure which ensures that all buckets in the current se-
lected block group are probed (line 1) before moving to the
next adjacent block group (lines 2-4). Hence, data blocks of
the same ﬁle prefer to be located in the same block group,
preserving locality.
History Independence. For each bucket map entry in the
probe sequence, the following two cases are possible.

(a) The bucket map entry is free. The data is written to
the corresponding disk bucket and the key is stored in the
bucket map entry, which is also marked as occupied.

(b) The bucket map entry is occupied by a previous write.
A collision has occurred. Now it is exactly the collision reso-
lution process that gives HIFS its history independence. To
clarify, let w1 and w2 be two write operations on ﬁles fp1
and fp2 respectively. Also let w1 target oﬀset fo1 of fp1 and
w2 target oﬀset fo2 of fp2 . Hence the keys for w1 and w2
for probing the disk bucket maps are h(fp1 ||GDB(fo1 )) and
h(fp2 ||GDB(fo2 )) respectively (procedure GET NEXT BUC
KET, line 2). Also, let h(fp1 ||GDB (fo1 )) > h(fp2 ||GDB(fo2 )).
Finally, suppose that the keys for both w1 and w2 prefer the
same entry in the disk bucket map of the same block group
and hence result in a collision. Now, there are two pos-
sible write sequences for w1 and w2. (i) w1 occurs before
w2: Here, when w2 is executing, the bucket is already oc-
cupied by the key of w1. Also since h(fp1 ||GDB(fo1 )) >
h(fp2 ||GDB(fo2 )) the bucket prefers key of w1 to that of
w2, as per procedure BUCKET PREFERS (line 1). Hence,
w2 looks to the next bucket in its key’s preference list and
the bucket map entry remains unchanged.
(ii) w2 occurs
before w1: Here, the bucket entry is already occupied by
the key of w2 when w1 is executing. But the bucket instead
prefers the key of w1 over that of w2. Hence, the key of w2
is now evicted from the bucket entry and is replaced by w1’s
key. The key of w2 is relocated to a new bucket based on
its preference list and probe order. Also in this case, the
data written by w1 is now placed in the corresponding disk
bucket, while the data previously written by w2 is moved to
the new disk bucket corresponding to the new bucket map
entry determined for its key’s relocation.

Figure 5 lists several examples of the two cases (i) and (ii)
from above. Speciﬁcally, consider execution of operation 5
of Figure 5(b). Here, the write of data blocks zero and one
of ﬁle fp1 replaces and relocates the data blocks two and
three of fp3 which were previously written by operation 4.
As a result of (a) and (b), the bucket entry and hence the
corresponding disk bucket contents are the same irrespec-
tive of the write sequence. Generalizing this example gives
the following. For a given set of ﬁles F , and any operation
sequence that creates F , a particular oﬀset of a ﬁle f in F ,
is always stored at the same location on disk. That is, the
disk layouts are history independent as per deﬁnition 1.

(a)

(b)

0 1 2 0 0 1 2 3 4 5 0

1 0 1 2 2 3 0 1 2 3 4

2 2 0 0 4 5 4

0 1 0 1

0 1 1 1 0 2 3 2 3 2 3

I0

B0

D0

I1

B1

D1

Figure 6: HIFS disk layouts for operation sequences
of Figure 5. (a) Case B ← Complete Sequential and
(b) Case C ← External Parameters, from Section
4.5.2. Also, h(user(fp1 )) = 2, h(user(fp2 )) = 4 and
h(user(fp3 )) = 3.

4.5.2 Customizing History Independence

The above description (Case A) and the Procedure Set 2
provide just one speciﬁc scheme for a history independent
disk layout for a given set of ﬁles. Diﬀerent applications may
prefer diﬀering layouts based on their speciﬁc characteristics.
Here we list additional examples that can be achieved using
diﬀerent implementations of the customizable procedures.
The relevant customizable procedures for these scenarios are
listed in Procedure Sets 3 and 4 (Appendix).
Case B: Completely Sequential.
Applications that
have very few writes as compared to read operations (e.g.,
databases for data mining) can greatly beneﬁt if the entire
ﬁle is stored sequentially on disk, giving maximal locality.
To realize this, only the key and bucket preferences need to
be modiﬁed. The keys of all write operations prefer buckets
within the same block group as in case A above. However,
the probe sequence starts with the ﬁrst bucket in the block
group and probes linearly henceforth. The buckets in turn
prefer blocks in increasing order of ﬁle oﬀsets.
Case C: External Parameters. Many applications ac-
cess multiple ﬁles simultaneously [14]. I/O performance of
such applications can be greatly enhanced if the ﬁles are
located close together on disk. For example, ﬁles created
by a single user/process are located in adjacency within the
same block group. Again, this scenario can be realized with
very minimal changes. In fact, the only change required is
that key’s preferences for block groups are now based on ex-
ternal (not ﬁle system related) parameters such as the user
(procedure set 4, Appendix).

Figure 6 gives the resultant layouts for both cases B and
C after the execution of operations from Figures 5(a) and
5(b). Again, note that the resultant layouts will be the same
for both cases irrespective of the operation sequence.

Several other distributions are possible. Individual cases
can also be combined to create more complex ones. For
example, cases B and C can be combined to have a distribu-
tion wherein ﬁles from the same user are located adjacently
on disk with each ﬁle laid out sequentially. Any new set
of customizable procedures only needs to ensure that the
key↔buckets preferences are unambiguous, that is, no key
should prefer any two buckets equally and vice-versa.
In
Section 4.6, we show that as long as this condition is met
the resulting distribution will be history independent.

4.5.3 Inode Table

Each inode is of ﬁxed size and contains ﬁle meta-data
such as ﬁle type, access rights, ﬁle size etc. Each inode
table contains a ﬁxed number of inode entries. Inodes are
allocated to ﬁles at creation time.

Similar to the disk buckets maps, the inode tables from
all block groups are collectively treated as a single history

1291independent hash table. Then, inode allocation and search
is done using the generic procedures from Procedure Set 1.
History independent layouts for the inode tables are also de-
termined by the customizable procedures. One such set of
inode-speciﬁc customizable procedures are listed in Proce-
dure Set 5 (Appendix). Here the ﬁle inode is located in the
same block group as that preferred by the ﬁle data blocks.
The intuition and reasoning for history independence is sim-
ilar to that described for case A above.

4.5.4 File delete, rename etc

HIFS also hides all evidence of a ﬁle delete operation. To
illustrate, consider the sample executions and disk layouts
from Figures 5(c) and 5(d). Figure 5(c) shows the resulting
layouts of a sequence of write-only operations. Figure 5(d)
shows the layout after execution of all operations of 5(b)
plus the delete operation on ﬁle fp3 . Both sequences create
the exact same set of ﬁles. Note how the disk layout after
the delete operation (Figure 5(d)) is exactly the same as the
layout after the write-only sequence of Figure 5(c). This is
because HIFS relocates data blocks on delete to their more
preferred locations (procedure DELETE in Set 1). For ex-
ample, in Figure 5(d) blocks 2 and 3 of ﬁle fp1 are relocated
to more preferred locations when ﬁle fp3 is deleted (by op-
eration 6). Overall, when a ﬁle is deleted, the resultant disk
layout carries no traces of the delete operation, as if the ﬁle
was never created in the ﬁrst place.

The ﬁle delete is realized by execution of the delete pro-
cedure from Set 1 for each disk bucket allocated to the ﬁle.
This makes a delete operation equivalent (cost-wise) to a
write of the entire ﬁle. A rename or move operation for a
particular ﬁle is a delete of each allocated disk bucket fol-
lowed by a write (of the same bucket) with the new path.

4.6 Proofs of History Independence

Let K denote the set of keys and β denote the buckets
within the hash table. Also, let k.pref (b) denote bucket b’s
position on key k’s preference list (k ∈ K and b ∈ β) where,
lower value of k.pref indicates higher preference. Then, we
have the following deﬁnition

Definition 3. Un-ambiguous Preferences

A set of preferences from K → β and β → K are un-
ambiguous if
(a) ∀k ∈ K, @ (bi, bj) ∈ β, i 6= j s.t. k.pref (bi) = k.pref (bj)
and
(b) ∀b ∈ β, @ (ki, kj) ∈ K, i 6= j s.t. b.pref (ki) = b.pref (kj).

Theorem 1. The customizable procedures listed in Pro-
cedure Set 2 result in a history independent hash table with
unique representation.

Proof. The Gale-Shapley Stable Marriage algorithm [10]
has shown that if (a) men propose in decreasing order of their
preference, and (b) all preferences are un-ambiguous, then
the resulting stable matching is unique. [5] then showed that
the hash table discussed in Section 4.2 satisﬁes both (a) and
(b). They then proved that as a result the distribution of
keys in the hash table is canonical and thus history inde-
pendent. Thus, distributions from any set of customizable
procedures are history independent if they exhibit the above
two properties.

We now detail this for the customizable procedures in Pro-
cedure Set 2 applicable to case A (Block Group Locality)
from Section 4.5.1.

(a) Proposal Order. Each time a new key is inserted in
to the hash table, the ﬁrst attempt is to place the key in
its most preferred bucket i.e. bucket b where k.pref (b) is
minimum (see procedure INSERT in set 1 which foremost
calls GET MOST PREFERRED BUCKET in set 2). Each
new bucket in the probe sequence is selected by the proce-
dure GET NEXT BUCKET which given a bucket bi ﬁnds
the bucket bj such that @ bl where k.pref (bi) < k.pref (bl) <
k.pref (bj). In other words bj is always the next preferred
bucket on key k’s preference list. Thus analogous to men
in the stable marriage algorithm the matching of keys to
buckets is attempted in decreasing order of key preferences.
(b) Un-ambiguous preferences. A bucket’s preference
between two keys is resolved in BUCKET PREFERS using
the condition h(fpa ||GDB(foa ))>h(fpb ||GDB(fob )). Hence,
if the two values compared above are always distinct then the
comparison is un-ambiguous. We note that for any given set
of ﬁles F the combination of the ﬁle path and the logical ﬁle
bucket number is unique, that is, ∀f ∈ F , <fp,GDB(fo)>is
unique. Hence, the hash value h(fp||GDB(fo)) is unique.
The proof then reduces to collision resistance of the hash
function (e.g., SHA [9]).

Similarly, a key’s preference amongst two buckets is re-
solved by the procedure KEY PREFERS. Here, ﬁrstly if the
two buckets belong to separate block groups (line 1) then the
key simply prefers the bucket in the block group with the
lower index (line 2). Hence, this condition is un-ambiguous.
If the two buckets are in the same block group, then the key
prefers the bucket closer to its most preferred bucket in that
block group (line 3). Again, since the comparison is based
on the hash of the unique combination <fp,GDB(fo)>the
proof reduces to collision resistance of the hash function.

Similar proofs exist for the customizable procedures of

cases B and C from Section 4.5.2, and for the inode table.

5. DISCUSSION
Data Shredding. When an element is deleted from a
history independent table it is imperative that proper data
shredding is employed, that is, the data at the location is
made irrecoverable (e.g., by overwriting [21]). Any resid-
ual data artifacts can compromise the history of operations.
Hence, HIFS does not mark hash table entries as deleted
but immediately performs an overwrite on each delete oper-
ation. This applies to all history independent disk structures
(inode table, disk bucket maps) and to the ﬁle data blocks.
Temporal Meta-data. File systems typically maintain
temporal meta-data such as modiﬁcation times (for ﬁles and
directories) which are then made available to applications.
For certain composite applications it may be desired that the
history of operations across ﬁles is also private. HIFS can
optionally be conﬁgured to provide such functionality, which
it does by (a) not maintaining any temporal meta-data for
ﬁles, and (b) using history independent directories.

A directory ﬁle consists of a set of directory entries, one
entry for each ﬁle in that directory. If cross-ﬁle history in-
dependence is desired then HIFS maintains the contents of
each directory ﬁle in a history independent manner. For
this, no additional data structures are employed, instead
the directory entries are always stored sorted. Since a simple
sorted list is history independent [20] the sorting of directory
contents suﬃces.

1292System failure and Recovery. File system operations
access multiple disk data structures which cannot all be
updated simultaneously. Hence, in case of an inopportune
system failure, the history independence related to certain
records can be violated. For example, consider a ﬁle delete
operation that accesses ﬁle system data structures in the fol-
lowing sequence – (a) deletes ﬁle inode entry from the inode
table, (b) deletes an entry from the disk buckets map, and
(c) deletes ﬁle contents from the corresponding disk bucket.
Now, suppose that a system failure occurs after step (b)
and an adversary gains access to the disk layout at this ex-
act moment. By examining the disk buckets map and the
data blocks on disk, the adversary can deduce that the last
operation was a delete.

Existing recovery mechanisms such as journaling can be
utilized to eﬃciently restore system consistency after a fail-
ure. However, we note that this breaks history independence
since the adversary can potentially gain information about
the recent operations. In case of journaling data can reside
on disk without the associated updated meta-data (or vice
versa). Hence data residing on disk with stale or missing
meta-data is likely to be identiﬁed as recently written. De-
signing eﬃcient recovery mechanisms that completely pre-
serve history independence remains an open problem.
In-Memory History Independence. HIFS protects his-
tory independence only for data residing on disk. It does not
target in-memory structures such as the ﬁle system cache.

Although the need for a history independent memory allo-
cator for in-memory data structures has been voiced [11], we
posit that extension of history independence to data in mem-
ory requires further careful examination. Simply replacing
in-memory caches with history independent versions will not
suﬃce. Firstly, an in-memory system cache cannot treat
each disk block independently, but instead needs to main-
tain inter-block associations. For example, it must avoid
scenarios such as the disk buckets map is written to disk
but the modiﬁed ﬁle data blocks still reside in the cache for
a signiﬁcant time interval after. This can potentially reveal
to an adversary details about the last ﬁle operation per-
formed. Further, the relationships between in-memory data
and its disk copies in a history independent context need to
be investigated. This includes not just ﬁle system cache and
data structures but also other system components such as
the operating system kernel and low level system caches.
Storage Media. HIFS does not provide history indepen-
dence if deployed (as is) on top of devices that manage their
own internal block placement, such as SSDs, due to the wear-
leveling mechanisms. The ﬂash ﬁrmware’s relocation of data
blocks (wear leveling) is aimed to increase the life span of
the drive. This essential functionality of the ﬂash controller
directly contradicts with history independence, since history
independence requires ﬁxed layouts. As of today we do not
know how to reconcile both. Hence in HIFS we only focus
on hard disk devices.

6. EXPERIMENTS

We benchmarked HIFS to understand the impact of his-

tory independence on performance.
Platform. All experiments were conducted on servers with
8 Intel i7 CPUs at 3.4GHz, 16GB RAM, and kernel v3.2.0-
37. The storage devices of choice are Hitachi HDS72302
SCSI drives. The benchmark tool used is Filebench [1].

Parameter

Database Web Server

File system size
Mean ﬁle size

No. of ﬁles

Disk block size (ds)

No. of block groups (Gn)
Disk blocks / bucket (dbn )

proﬁle
100 GB

1 GB
L · 100
4 KB

8

5120

proﬁle
10 GB
512 KB

(L · 10) · 211

4 KB

24
128

Inode size

IO Size

281 bytes

32KB

281 bytes

512KB

Table 1: Experimental parameters. L ← File System
Load factor.

Implementation. HIFS is implemented as a C++ based
user-space Fuse [2] ﬁle system. All data structures, includ-
ing customizable history independence were written from
scratch. The entire HIFS code is ≈10K LOC.
Measurements. Each test run commences with an empty
ﬁle system, then creates and writes new ﬁles to storage. The
number of ﬁles stored is increased until the ﬁle system is 90%
full. Throughputs are measured at speciﬁc load factors (disk
space utilization) ranging from 10% to 90%. The writes and
subsequent read operations were separated by a complete
clearing of the system cache. This was done to minimize the
eﬀect of caching since ﬁle system cache is not yet designed
to be history independent.

6.1 Results

Database Proﬁle. Databases typically feature access
to a few large ﬁles with random access patterns. To simu-
late such a proﬁle we evaluate random reads and writes on
multiple ﬁles with a mean ﬁle size of 1 GB. The number of
ﬁles is varied from 10 to 90 to reﬂect the ﬁle system load
factor. Table 1 summarizes all ﬁle system parameters while
Figure 7(a) shows the results.

As detailed in Section 4.5.1, the allocation of a new disk
bucket to a ﬁle in response to a write request potentially
causes the displacement of existing data of other ﬁles due
to the history independent collision resolution. The number
of such collisions increases with the load factor. For load
factors beyond 60% a sharp decrease in throughputs is ob-
served for random writes. Read operations however, do not
modify data, hence are not aﬀected by collisions, in turn
showing less throughput declines with load factors. Also,
since the customizable procedures for case A (Block Group
Locality, Section 4.5.1) are employed here, data locality is
preserved. Write operations incur the overheads to maintain
this locality while reads beneﬁt from it.

The tradeoﬀ between write and read performance is fur-
ther evident from Figure 7(b) which shows the throughputs
when the customizable procedures for case B (Complete Se-
quential, Section 4.5.1) are employed, that is, each ﬁle is
laid out sequentially on disk. Here, read operations show a
13% average increase in throughput for sequential reads and
17% for random reads as compared to Case A (Figure 7(a)).
To maintain this higher locality, write throughputs incur an
average decline of 90% compared to Case A. All the above
hold under history independence assurances.
Web Server Proﬁle. Web servers are characterized by
accesses to a large number of very small ﬁles [22]. To model
this, we use use a mean ﬁle size of 512 KB, but increase
the number of ﬁles up to ≈18,500 for a load factor of 90%.
Refer to Table 1 for a full parameter list. The read and

1293HIFS
Random writes
Random reads
Sequential reads

Ext3
Random writes
Random reads
Sequential reads

l

e
a
c
s
 
g
o

l
 
,
)
s
/
B
M

(
 
t

u
p
h
g
u
o
r
h
T

256
128
64
32
16
8
4
2
1

HIFS
Random writes
Random reads
Sequential reads

Ext3
Random writes
Random reads
Sequential reads

l

e
a
c
s
 
g
o

l
 
,
)
s
/
B
M

(
 
t

u
p
h
g
u
o
r
h
T

256
128
64
32
16
8
4
2
0

10

20

40

30
70
File system load factor (%)

60

50

80

90

10

20

40

30
70
File system load factor (%)

50

60

80

90

(a) Database proﬁle, Case A: Block Group Locality
(Section 4.5.1). HIFS in black, Ext3 in gray.

(b) Database proﬁle, Case B: Complete Sequential (Section
4.5.1). HIFS in black, Ext3 in gray.

l

e
a
c
s
 

g
o

l
 
,
)
s
/
B
M

(
 
t

u
p
h
g
u
o
r
h
T

256
128
64
32
16
8
4
2
1
0.2
0.4

10

20

HIFS
File writes
File reads

Ext3
File writes
File reads

40

30
70
File system load factor (%)

50

60

225

220

215

210

25

l

e
a
c
s
 

g
o

l
 
,
)
s
m

(
 
y
c
n
e

t

a
L

80

90

10

20

Database profile (create)
Database profile (delete)
Web server profile (create)
Web server profile (delete)

40

30
70
File system load factor (%)

50

60

80

90

(c) Web Server proﬁle, Case A: Block Group Locality (Sec-
tion 4.5.1). HIFS in black, Ext3 in gray.

(d) HIFS latencies for ﬁle create and delete operations for
Case A: Block Group Locality from Section 4.5.1.

Figure 7: HIFS throughputs and latencies. A load factor of L indicates that the ﬁle system is L% full.

write operations access entire ﬁles. Figure 7(c) summarizes
the results for this proﬁle.
File create and delete operations. Figure 7(d) shows
the latencies of ﬁle create and delete operations.

A create operation involves locating a free inode for the
new ﬁle, writing the ﬁle meta-data to the inode table, lo-
cating the parent directory and writing the ﬁle entry in to
the directory. The writes to the inode table and to the di-
rectory are both history independent. Since the inode table
also employs a history independent hash table to store in-
dividual inode entries (Section 4.5.3), the latency increases
gradually with the load factor.

As discussed in Section 4.5.4 a ﬁle delete is equivalent to
a write of the entire ﬁle in order to preserve history inde-
pendence. As a result deletes have high latencies.
Overhead of history independence. Figures 7(a) and
7(c) also illustrate the throughputs for the Ext3 ﬁle system.
For consistent comparisons all Ext3 ﬁle system operations
are also routed via Fuse.

The performance of HIFS for read operations is compara-
ble to read throughputs of Ext3 for load factors up to 70%.
The write operations sustain signiﬁcant overheads especially
for higher load factors. This is again because once the write
operations provide history independence while preserving lo-
cality, the reads incur signiﬁcantly lower seek operations on
the storage medium and are hence perform eﬃciently.

For the web server proﬁle the overhead of history inde-
pendence is higher even for reads. This is because each
operation accesses the entire ﬁle at once and although the
locality of data blocks withing a ﬁle is maintained the ﬁles
themselves are distributed over the entire disk.

6.2 Summary and Analysis

HIFS employs history independent hash tables for all its
data structures including ﬁle meta-data and data blocks.
The performance of hash tables in turn depends on their load
factor. In fact, the asymptotic performance per operation of
the history independent hash table employed is O(1/(1−α)3)
[5], showing expected exponential decrease in performance
with increasing load factor α. Hence, for load factors >60%
the performance degrade for writes is signiﬁcant. The same
behavior is clearly evident in the experimental results for
HIFS (Figures 7(a)-7(d)).

To remove these fundamental limitations on performance

the following directions are most promising.

(1) Designing new history independent data structures
speciﬁcally suited to secondary storage (current designs tar-
get only memory).

(2) Exploring trade-oﬀs by lowering the degree of history
independence, for example, batching of write operations.
Delaying write operations will help reduce the total num-
ber of disk seeks and writes per operation.

1294Data Structure Year Ops
I,L,D

2-3 Tree [16]

Runtime
O(log N )

I,L

I,L,D
I,P,D

O(log(1/(1 − α)))

O(1/(1 − α)3)
O(log log N )

Hash Table [20]
Hash Table [5]

Ordered

Dictionary [5]

1997
2001
2007
2007

Order

2007

I,C,D

O(1)

Maintenance [5]
Hash Table [19]

2008

I,L,D

I,D → O(log N )

B-Treaps [12]
B-SkipList [13]

R-Trees [23]

2009
2010
2012

I,D,R
I,D,R
I,D,R

S → O(1)
O(logBN )
O(logBN )

n/a

Table 2: Summary of history independent data
structures. α ← load factor, N ← number of keys, B
← block transfer size. Also, I : insert, L : lookup, D
: delete, R : range, P : predecessor, C : compare.

7. RELATED WORK

Prior work has focussed on designing several history inde-
pendent data structures (summarized in Table 2). These
data structures have several applications including incre-
mental signature schemes [19], privacy in voting systems
[5, 17–19], performing updates without revealing intermedi-
ate states [20], debugging parallel computations [5], recon-
ciliation of dynamic sets [19], and un-traceable deletion [4].
Write Once Storage. The data structures in Table 2 as-
sume a re-writable storage medium. [17] designed a history
independent solution for a write-once medium suitable for
deployment in voting machines. The construction is based
on the observation from [20] that a lexicographic ordering
of elements in a list is history independent. However, write-
once memories do not allow in-place sorting of elements.
Instead [17] employs copy-over lists [20]. When a new ele-
ment is inserted, a new list is stored while the previous list is
erased. However, this requires O(n2) space to store n keys.
[17] suggests to store each new element at a random loca-
tion on the write-once storage. In case of collisions, a new
random location is selected. Note that although simple and
space-eﬃcient, this requires the random bits to be hidden
from the adversary which may not be possible in the tar-
geted scenario involving voting machines in poll booths. [18]
improves on [17] requiring only linear storage. The key idea
here is to store all elements in a global hash table and for
each entry of the hash table maintain a separate copy-over
list which contains only the colliding elements.
Survey Works. Various deﬁnitions of history indepen-
dence are analyzed in [15], most relying on canonical repre-
sentations which are shown to be necessary in achieving it.
[6] analyzes the lower and upper bounds on the runtime of
the heap and the queue. A summary of various data struc-
tures from Table 2 is available in [11] along with techniques
to transform basic data structures such as arrays, stacks and
queues into their respective history independent versions.

8. CONCLUSION

The contributions of this paper are three-fold. First, we
extend the concepts of history independence from in-memory
data structures to ﬁle systems. Second, we devise a practi-
cal way to achieve history independence that preserves data
locality. And last, we design, implement and evaluate the
ﬁrst history independent ﬁle system (HIFS). HIFS guaran-
tees truly secure deletion by providing full history indepen-

dence across both ﬁle system and disk layers of the storage
stack. Additionally, it preserves data locality, and provides
tunable eﬃciency knobs to suit diﬀerent application history-
sensitive scenarios.

9. REFERENCES
[1] Filebench, http://linux.die.net/man/1/ﬁlebench.
[2] Filesystem in userspace, http://fuse.sourceforge.net/.
[3] R. Appleton. Kernel korner: A non-technical look

inside the ext2 ﬁle system. Linux J., 1997(40es), Aug.
1997.

[4] S. Bajaj and R. Sion. Ficklebase: Looking into the

future to erase the past. In Proceedings of the
International Conference on Data Engineering, 2013.

[5] G. E. Blelloch and D. Golovin. Strongly

history-independent hashing with applications. In
Proceedings of IEEE Symposium on Foundations of
Computer Science, FOCS ’07, pages 272–282. IEEE
Computer Society, 2007.

[6] N. Buchbinder and E. Petrank. Lower and upper
bounds on obtaining history independence, 2003.

[7] D. Comer. Ubiquitous b-tree. ACM Comput. Surv.,

11(2):121–137, June 1979.

[8] S. A. Crosby and D. S. Wallach. Super-eﬃcient

aggregating history-independent persistent
authenticated dictionaries. In Proceedings of European
conference on Research in computer security,
ESORICS, pages 671–688. Springer-Verlag, 2009.
[9] P. A. DesAutels. SHA1: Secure Hash Algorithm,

www.w3.org/PICS/DSig/SHA1 1 0.html. 1997.

[10] D. Gale and L. Shapley. College admissions and the

stability of marriage. American Mathematical
Monthly, 69(1):9–15, 1962.

[11] D. Golovin. Uniquely represented data structures with

applications to privacy. PhD thesis, 2008. AAI3340637.

[12] D. Golovin. B-treaps: A uniquely represented

alternative to b-trees. In Proceedings of International
Colloquium on Automata, Languages and
Programming: Part I, ICALP ’09, pages 487–499.
Springer-Verlag, 2009.

[13] D. Golovin. The b-skip-list: A simpler uniquely

represented alternative to b-trees. CoRR,
abs/1005.0662, 2010.

[14] T. Harter, C. Dragga, M. Vaughn, A. C.

Arpaci-Dusseau, and R. H. Arpaci-Dusseau. A ﬁle is
not a ﬁle: Understanding the i/o behavior of apple
desktop applications. ACM Trans. Comput. Syst.,
30(3):10:1–10:39, Aug. 2012.

[15] J. Hartline, E. Hong, A. Mohr, E. E. Mohr,

W. Pentney, and E. Rocke. Characterizing history
independent data structures, 2002.

[16] D. Micciancio. An oblivious data structure and its
applications to cryptography. In In Proceedings of
ACM Symposium on the Theory of Computing, pages
456–464. ACM Press, 1997.

[17] D. Molnar, T. Kohno, N. Sastry, and D. Wagner.

Tamper-evident, history-independent, subliminal-free
data structures on prom storage-or-how to store
ballots on a voting machine (extended abstract). In
Proceedings of IEEE Symposium on Security and
Privacy, SP ’06, pages 365–370. IEEE Computer
Society, 2006.

1295[18] T. Moran, M. Naor, and G. Segev. Deterministic

history-independent strategies for storing information
on write-once memories. In Proceedings of
International Colloquium on Automata, Languages
and Programming, pages 303–315. Springer, 2007.

[19] M. Naor, G. Segev, and U. Wieder.

History-independent cuckoo hashing. In Proceedings of
international colloquium on Automata, Languages and
Programming, Part II, ICALP ’08, pages 631–642.
Springer-Verlag, 2008.

[20] M. Naor and V. Teague. Anti-persistence: History
independent data structures. In In Proceedings of
ACM symposium on Theory of computing, pages
492–501. ACM Press, 2001.

[21] J. Reardon, D. Basin, and S. Capkun. Sok: Secure

data deletion. In Proceedings of the 2013 IEEE
Symposium on Security and Privacy, SP ’13, pages
301–315. IEEE Computer Society, 2013.

[22] A. S. Tanenbaum, J. N. Herder, and H. Bos. File size
distribution on unix systems: then and now. SIGOPS
Oper. Syst. Rev., 40(1):100–104, Jan. 2006.

[23] T. Tzouramanis. History-independence: a fresh look

at the case of r-trees. In Proceedings of ACM
Symposium on Applied Computing, SAC ’12, pages
7–12. ACM, 2012.

APPENDIX

A. PROCEDURE SETS

Procedure Set 3 Customizable Procedures for Case B
(Complete Sequential) from Section 4.5.2
Procedure: GET MOST PREFERRED BUCKET
Desc: get the top most bucket on key’s preference list.
Input: key k = {ﬁle path fp, ﬁle oﬀset fo}
1: return <0, h(fp) mod Gn>
——————————————————————
Procedure: GET NEXT BUCKET
Desc: get the next bucket on key’s preference list.
Input: key k = {fp, fo}, bucket i, block group r
1: i ← (i + 1) mod Bn
2: if i == 0 then
3:
4: return <i, r>
——————————————————————
Procedure: BUCKET PREFERS
Desc: ﬁnd which of two keys the given bucket prefers.
Input: bucket i, block group r, key a = {fpa , foa }, key b =

return <0, (r + 1) mod Gn>

{fpb , fob }

return GDB(foa ) <GDB(fob )

1: if fpa == fpb then
2:
3: return h(fpa ) >h(fpb )
——————————————————————
Procedure: KEY PREFERS
Desc: ﬁnd which of two buckets the given key prefers.
Input: key k = {fp, fo}, bucket i, bucket j, block group r,

block group s
1: if r 6= s then
2:

return ((h(fp) mod Gn) − r + Gn) mod Gn < ((h(fp)
mod Gn) − s + Gn) mod Gn

3: return i < j

Procedure Set 4 Customizable Procedures for Case C (Ex-
ternal parameters) from Section 4.5.2
Procedure: GET MOST PREFERRED BUCKET
Input: key k : k = {ﬁle path fp, ﬁle oﬀset fo, user u}
1: return <h(fp||GDB(fo)) mod Bn, h(u) mod Gn>
——————————————————————
GET NEXT BUCKET and BUCKET PREFERS same as
in procedure set 2.
——————————————————————
Procedure: KEY PREFERS
Input: key k : {fp, fo, u}, bucket i, bucket j, block group

r, block group s : (i, j, r, s) ∈ N

1: if r 6= s then
2:

return
((h(u)modGn) − s + Gn) mod Gn

((h(u) mod Gn) − r + Gn) mod Gn <

3: return ((h(fp||GDB(fo)) mod Bn) − i + Bn) mod Bn <

((h(fp||GDB(fo)) mod Bn) − j + Bn) mod Bn

Procedure Set 5 Inode Table Customizable Procedures
Procedure: GET MOST PREFERRED BUCKET
Input: key k = ﬁle path fp
1: return <h(fp) mod In, h(fp) mod Gn>
——————————————————————
Procedure: GET NEXT BUCKET
Input: key k = fp, bucket i, block group r
1: i ← (i + 1) mod In
2: if i == (h(fp) mod In) then
3:
4: return <i, r>
——————————————————————
Procedure: BUCKET PREFERS
Input: bucket i, block group r, key a = fpa , key b = fpb
1: return h(fpa ) > h(fpb )
——————————————————————
Procedure: KEY PREFERS
Input: key k = fp, bucket i, bucket j, block group r, block

r ← (r + 1) mod Gn, i ← h(fp) mod In

group s

1: if r 6= s then
2:

return ((h(fp) mod Gn) − r + Gn) mod Gn < ((h(fp)
mod Gn) − s + Gn) mod Gn

3: return ((h(fp) mod In) − i + In) mod In < ((h(fp) mod

In) − j + In) mod In

Procedure Set 6 HIFS write operation
Procedure: write
Input: ﬁle path fp, ﬁle oﬀset fo, data ∂, data length ∂l

: Disk Bucket Maps, GDt : Group

: Inode tables, BGn

IGn
t
Descriptor table

t

, {fp, fo})

t

, fp)

t

if bi is null then

1: <ii, in>← SEARCH(IGn
2: check ﬁle permissions in inode data
3: bs ← (dbn ∗ ds), wl ← 0
4: while wl < ∂l do
5: <bi, gi>← SEARCH(BGn
6:
7:
8:
9:
10:
11:
12:
13:

<bi, gi>← INSERT(BGn

∂i ← bs − (fo mod bs)

∂i ← ∂l − wl

else

, {fp, fo}, {})
if (∂l − wl) > (bs − (fo mod bs)) then

t

sd ← start oﬀset of disk buckets in GDt[gi]
write ∂[wl : wl + ∂i] bytes to disk at oﬀset sd + (bs ∗
bi) + (fo mod bs)
fo ← fo + ∂i, wl ← wl + ∂i

14:

1296