AUTOCRYPT: Enabling Homomorphic Computation on

Servers to Protect Sensitive Web Content

Shruti Tople

Shweta Shinde

Zhaofeng Chen

Prateek Saxena

School of Computing

National University of Singapore

{shruti90, shweta24, chenzhao, prateeks} @comp.nus.edu.sg

ABSTRACT
Web servers are vulnerable to a large class of attacks which can al-
low network attacker to steal sensitive web content. In this work,
we investigate the feasibility of a web server architecture, wherein
the vulnerable server VM runs on a trusted cloud. All sensitive
web content is made available to the vulnerable server VM in en-
crypted form, thereby limiting the effectiveness of data-stealing at-
tacks through server VM compromise.

In this context, the main challenge is to allow the legitimate func-
tionality of the untrusted server VM to work. As a step towards
this goal, we develop a tool called AUTOCRYPT, which transforms
a subset of existing C functionality in the web stack to operate on
encrypted sensitive content. We show that such a transformation
is feasible for several standard Unix utilities available in a typical
LAMP stack, with no developer effort. Key to achieving this ex-
pressiveness over encrypted data, is our scheme to combine and
convert between partially-homomorphic encryption (PHE) sche-
mes using a small TCB in the trusted cloud hypervisor. We show
that x86 code transformed with AUTOCRYPT achieves performance
that is signiﬁcantly better than its alternatives (downloading to a
trusted client, or using fully-homomorphic encryption).
Categories and Subject Descriptors
D.3 [ Programming Languages]: Processors—Compilers; D.4
[Operating Systems]: Security and Protection—Cryptographic Con-
trols
Keywords
Web Security; Homomorphic Encryption; Type Systems
1.

INTRODUCTION

Web hosting services, such as RackSpace and Amazon Web Ser-
vices, enable web server stacks (e.g. a LAMP web server) to be
hosted on public clouds using VMs. User and enterprises often
wish to maintain strong data protection of sensitive data stored on
public cloud servers from web and network attacks. Web server
stacks are prone to a large class of attacks ranging from SQL injec-
tion, memory corruption vulnerabilities, OS command injection,
server misconﬁguration, ﬁle type confusion bugs, and so on. These

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516666 .

attacks can be used to compromise web servers and install malware.
Despite heightened security concerns [10], stronger data protection
laws [4, 8, 9], and availability of commercial detection tools [6, 7],
server-side data breaches have been persistently high for the last 3
years [25].

Previous work has proposed partitioning monolithic web servers
into multiple pieces, as a second line of defense. For instance,
separating the web application logic into multiple VMs based on
roles [49], privilege separating users using OS protections [39], or
using trusted hardware features to attest the integrity of server VMs
[44, 45, 61]. In this work, we advocate a new approach for build-
ing second line of defense: we investigate how to protect sensitive
web content in a compromised web server (running in a VM) on a
trusted cloud. Speciﬁcally, we focus on ensuring the conﬁdentiality
of sensitive ﬁle-based web content while still allowing legitimate
applications to operate on them.
Problem Setting. In this paper, we investigate the practical fea-
sibility of protecting sensitive web content transparently in an un-
trusted server VM on a trusted cloud provider. We assume that the
cloud provider and underlying VMM / hypervisor is trusted, but the
attacker can exploit a vulnerability in the server-side web stack to
run arbitrary code on the web server VM. One promising approach
to achieve this is to encrypt all sensitive ﬁle content before expos-
ing it to the untrusted server VM [52]. With this mechanism, at-
tacks through the VM are forced to access information in encrypted
form and computationally bounded adversaries cannot learn the in-
formation in sensitive ﬁles. Sensitive content is encrypted outside
the untrusted VM (e.g. on a separate trusted key server or on the
client’s device) and encryption keys are made available only to the
trusted hypervisor. A compromised VM would only be able to leak
encrypted content to remote adversaries (which don’t have the de-
cryption keys). In this conceptual setting, the hypervisor acts as a
static root-of-trust and does not execute any unprivileged code from
the untrusted VM in privileged land. We discuss the merits of this
conceptual architecture in Section 2 in more depth to motivate the
context and need for our auto-transformation tools.
Challenge & Approach. The main challenge in enabling this de-
fense is that naïvely encrypting content in the untrusted VM dis-
ables all legitimate (or benign) functionality. The standard solution
for this problem is to download the encrypted data on the client side
and then compute on the decrypted data. We call this approach as
the ‘download-and-compute’ mechanism. Indeed, several commer-
cial solutions — such as BoxCryptor [18] and CloudFogger [21] —
allow users to store encrypted data on the server and only permit
operating on the data by downloading full contents to the trusted
client device before computation. However, for large amounts of
data (say over a 1 TB of logﬁle), downloading the data incurs huge
network communication which has direct ﬁnancial costs for the

1297service provider, and are slow as well as expensive for the client
user. An alternative solution is to use fully-homomorphic encryp-
tion (FHE) schemes that allow arbitrary computation on encrypted
data [31]. Though promising, these techniques are presently too
slow for practical usage [30].

As a step towards practicality, we investigate execution of user-
level benign applications, using partially homomorphic encryption
schemes (PHE). Partially homomorphic encryption schemes allow
speciﬁc (limited) computations on encrypted content [24, 48, 58].
As the main contribution of this paper, we develop a new compiler
called AUTOCRYPT that takes real-world C applications and auto-
matically transforms them to operate on encrypted data. The trans-
formed (or AUTOCRYPT-ed) x86 code runs in the untrusted VM
and is allowed to invoke only 6 ﬁxed hypervisor API, by making a
hypercall, to support useful functionality. Our design ensures that
all computations in the untrusted VM are privacy preserving, as de-
ﬁned formally in Section 3, using standard deﬁnitions of privacy-
preserving homomorphic computation [58, 64]. The trusted hyper-
visor approach combined with AUTOCRYPT opens up a compelling
alternative to the 2 existing solutions for enabling rich functional-
ity in an uncompromised web server setting. It provides a high-
bandwidth channel between an untrusted VM and hypervisor (via
hypercalls) and adds little to the hypervisor’s TCB.

In designing AUTOCRYPT, we carefully avoid schemes such as
full-homomorphic encryption (FHE), which are presently too slow
for practical usage [30, 31]. To avoid using FHE, the hypervisor
APIs allows to perform safe conversions between encryption sche-
mes. AUTOCRYPT analyzes program written in C and internally
infers an encryption type for each variable in the program. We de-
sign a secure type system that combines various partially homomor-
phic encryption (PHE) schemes to support a subset of C operations.
This type inference captures the right homomorphic encryption to
apply to the variable’s content to enable the legitimate computa-
tion to work. To summarize, our solution consists of two parts: a)
a compiler AUTOCRYPT that type checks a given application and
automatically transforms it to operate on encrypted data b) a ﬁxed
set of static hypervisor APIs in the trusted hypervisor that switches
data between encryption schemes.
Summary of Results. We test AUTOCRYPT on 30 Unix ﬁle pro-
cessing applications from the COREUTILS package available on a
typical LAMP stack, and 3 custom programs commonly used in
image processing applications. AUTOCRYPT automatically trans-
forms the 25 COREUTILS applications and all the custom applica-
tions to AUTOCRYPT-ed programs with no developer effort, show-
ing the expressiveness of our new abstractions. Our experiments
validate our three main empirical hypotheses that (a) only a small
fraction of internal program state and code needs transformation
(but is difﬁcult to manually identify) (b) several programs can use a
combination of inexpensive PHE techniques rather than expensive
FHE to implement their functionality (c) performance of operat-
ing on encrypted data using combination of PHE techniques can be
better than the traditional ‘download-and-compute’ mechanism and
exisiting fully-homomorphic encryption schemes. We ﬁnd that the
execution time of AUTOCRYPT-ed COREUTILS programs grows
linearly with data size. Our (unoptimized) AUTOCRYPT-ed pro-
grams are faster for 19 utilities and slower by factor of 2 to 6 for
6 utilities as compared to the ‘download-and-compute’ mechanism
and faster by orders of magnitude than previous reported perfor-
mance of FHE techniques. Thus, AUTOCRYPT makes homomor-
phic computation on a trusted hypervisor a compelling alternative
to the ‘download-and-compute’ and FHE mechanisms.

Contributions. In this work, we focus on the problem of retroﬁtting
partially-homomorphic encryption (PHE) schemes transparently to
existing application with no developer effort. To our knowledge,
our work is one of the ﬁrst to investigate how to automatically
transform existing C applications using PHE schemes transparently
without requiring any expertise or knowledge on behalf of the de-
veloper. Prior work has developed transformation tools for secure
function evaluation on encrypted data, but mostly in the context
of interactive secure two-party protocol implementations [32, 36–
38, 43]. We target a new class of applications, motivated by our
conceptual setting of a vulnerable web server hosted on a trusted
hypervisor.

Speciﬁcally, we claim the following main contributions:
• We develop an automatic compilation tool for applications
written in C language called AUTOCRYPT, which transpar-
ently embeds homomorphic computation to transform pro-
grams to operate on encrypted data.
• AUTOCRYPT provides experimental basis to the hypothe-
sis that many applications can utilize a combination of PHE
techniques instead of the more general (and expensive) FHE
techniques. We successfully transform 25 (out of 30 stud-
ied) existing ﬁle-processing Unix utilities and 3 custom pro-
grams with no developer effort. This shows that the cheaper
PHE techniques are sufﬁcient for most of the applications we
study, with a limited support from the trusted hypervisor.

2. OVERVIEW

To enable protection of sensitive content, we envision a concep-
tual architecture (Section 2.1) which splits the web server into 2
VMs, where the main web processing is an untrusted VM. The
main focus of this paper is providing a small, secure hypervisor
API and a type-based tool to transform existing applications to op-
erate on PHE encrypted data.
2.1 Setting: A Split Server Architecture

Instead of trusting the web server VM completely, we envison
a setting where the server is partitioned into 2 server VMs:
the
main untrusted server VM which handles the bulk of the client re-
quest processing and a thin authentication and key server. The thin
authentication server handles the user authentication (via HTTPS)
and initializes the hypervisor with the allowed encryption keys at
the start of a session. The hypervisor then launches the untrusted
main VM to handle the client’s request in the session.

The untrusted VM executes a standard LAMP web stack which,
in part, processes sensitive or encrypted ﬁles. Applications which
implement the server’s legitimate functionality are pre-transformed
using our AUTOCRYPT on the client side. A client with his secret
key and AUTOCRYPT tool transforms an application to AUTOCRYPT-
ed program and uploads it to the web server.

In our design, ﬁles are stored encrypted under more than one
partially homomorphic encryption schemes on the web server. For
simplicity, we assume that each ﬁle has n (= 3) copies on the
server, each encrypted with a different encryption scheme under
the user’s secret key set κ. Each encryption scheme allows a cer-
tain kind of computation to be homomorphically executed on the
encrypted ﬁle contents, under inputs encrypted with κ provided by
the trusted client. For example, a ﬁle encrypted using searchable
encryption allows only the trusted client to search for constant key-
words on a ﬁle content, without revealing the encryption keys to
the server [58]. Similarly, homomorphic schemes with respect to
addition / subtraction (e.g.Paillier [48]), multiplication (e.g. Elga-
mal [24]) allow respective computations on the data. Our main
goal is to transparently transform a program f that isn’t designed

1298Ensuring Conﬁdentiality On a Trusted Hypervisor. In this set-
ting, however, ensuring conﬁdentiality when a known computation
is performed on the data ﬁles is an important challenge. We assume
that the attacker can infer which application is being executed, i.e.
we do not require functional privacy. We conservatively model the
attacker’s knowledge set to include f, f(cid:48), the encrypted inputs and
outputs of f(cid:48), and everything that can be computed1 from these.
The installed malware on the untrusted VM can independently run
AUTOCRYPT-ed f(cid:48) on available encrypted data, and can observe
each memory access and instruction executed in f(cid:48). Therefore, any
information implied by the path constraints along any given exe-
cution are assumed to be part of the attacker’s knowledge set. In
addition, the adversary is not restricted to running only benign f(cid:48)
on the encrypted data available to it. Indeed, for a data element en-
crypted under κ with a particular homomorphic scheme, the mal-
ware can run arbitrary computation permissible by the scheme. The
catch, of course, is that it is bound to compute with data which is
already encrypted under κ with the same homomorphic encryption
scheme. The results are decrypted outside the VM and not by the
attacker (as the key is unknown to the attacker). Therefore, a im-
portant challenge is to limit the expressiveness (or richness) of the
computation possible on sensitive data in the untrusted VM, while
allowing “sufﬁciently interesting” benign functionality to execute.
2.3 Problem Deﬁnition

Our goal is to develop AUTOCRYPT, a tool that given a benign
application f, checks if its computation can be transformed into a
safe computation to run on the server. If so, AUTOCRYPT trans-
form f into f(cid:48) while preserving the semantics / correctness of the
original computation and guaranteeing the safety of f(cid:48) as per the
deﬁnitions of privacy preserving execution.

More precisely, let an application f be a 3 tuple consisting of (a)
a set of valid instruction traces S, operating on sensitive inputs (cid:126)I,
a set of public program constants C to produce sensitive outputs.
Let Σ∗ be the set of all input alphabets and W represent the set of
publicly known program constants encrypted under search scheme.
We seek a transformation procedure AutoCrypt : (S, (cid:126)I, C) (cid:55)→
(S(cid:48), (cid:126)I(cid:48), C(cid:48)), such that it satisﬁes the following three properties.
(a)Correctness : The transformed program f(cid:48) preserves the se-
mantics of f, i.e. ∀i ∈ I, S(i) = Dκ(S(cid:48)(Eκ(i))).
(b)Privacy-preserving execution: The execution of f(cid:48) under sen-
sitive inputs (cid:126)I is privacy-preserving. We provide a precise deﬁni-
tion of security achieved by our scheme as reduced indistinguisha-
bility (see below & Section 3.4) which is weaker than the strict
computational non-interference, but admits a large variety of inter-
esting web server functionality.
(c)Minimal Control Flow Leakage: The number of encrypted
program constants under search scheme W ⊆ C is minimal, i.e.,
consisting only those constant expressions that are used in condi-
tional operation in the original f.
Security Property: Privacy-preserving execution modulo W.
We aim to ensure that all executions in the untrusted VM, including
f(cid:48) and the adversarial computation, are privacy-preserving compu-
tation (modulo the parameter W necessary to support benign appli-
cations). Our goal is to enable interesting benign functionality in
the untrusted VM, without giving a malicious computation the ca-
pability to leak sensitive information beyond what is implied by its
knowledge set. For all computation in the untrusted VM, including
the AUTOCRYPT-ed program f(cid:48), computation on encrypted data
are restricted only to homomorphic operations. In addition, com-

1according the standard deﬁnitions of computationally bounded ad-
versaries

Figure 1: Trusted Hypervisor Setting. Secret Key K is present
with the client, authentication server and the trusted hyper-
visor. The attacker can only see the encrypted data and the
AUTOCRYPT-ed program.

to operate on encrypted data, into a program f(cid:48) which can operate
on encrypted sensitive data. The program f(cid:48) takes encrypted inputs
and executes to produce encrypted results. Supporting this scenario
enables, for example, several standard Unix ﬁle processing utilities
on encrypted ﬁles.

We trust the underlying hypervisor to be secure. Existing tech-
niques to ensure its integrity can be used [45]. In this design, the
hypervisor does not allow the untrusted VM to execute any unpriv-
ileged code dynamically in the privileged hypervisor mode (e.g.
DOM0 in Xen). The hypervisor permits the untrusted VM to in-
voke a set of hypervisor APIs. These APIs implement a small set
of static functionalities for decrypting data in one scheme and en-
crypting it in other scheme as detailed in Section 2.4.

2.2 Threat Model

We assume that the adversary can compromise and run arbitrary
code in the untrusted VM during the session, as shown in Figure 1.
We argue about the attacker’s capability in these cases and design
a robust solution to ensure conﬁdentiality of sensitive web content.
Exﬁltration Channels for Adversary.
In this setting, the un-
trusted main VM only sees encrypted ﬁles and computed informa-
tion from them. There are 3 channels it can utilize to exﬁltrate
data. First, it can directly send encrypted content to a remote at-
tacker — however, such an attacker would not have the legitimate
user’s encryption keys, and so would not be able to decrypt the
data. A second channel is to leak decrypted content via the client-
side code. Defenses to prevent client-side data exﬁltration have re-
cently been proposed using features in HTML5 such as temporary
origins [12]. We assume that with the help of the trusted authenti-
cation and key server, we can privilege separate the decryption and
data export channels in a secure origin on the client-side. We do
not discuss these defenses in this work. Finally, the attacker can
learn the sensitive information using the hypervisor API exposed
to the unprivileged code executing in the main VM. This threat is
the main focus of our techniques. We show that the hypervisor’s
runtime service API cannot be used to leak information about com-
puted values (see Section 3.4). That is, the untrusted VM cannot
perform undue computation on sensitive data to leak information.

HardwareAuthenti-cationAndTrustedKeyServerClientHypervisor APIsAutoCrypt-edProgramHypercallTrusted HypervisorUntrustedWeb ServerHTTPSKKKEncryptedUser DataKKK1299putation in the VM can make a small set of hypercalls.
In our
setting, the amount of information leakage in the adversarial com-
putation is lower bounded by leakage permitted in benign func-
tionality. In permitting benign executions, on one end, we could
enforce a strong non-interference property (in the computational
sense [28]) on all computation in the VM. However, many prac-
tical programs we study leak some information, via control ﬂow
channels, but the information leaked is small. We aim to admit a
limited set of such benign functionalities, but bound the adversarial
computations simultaneously. In essence, we aim to prevent com-
putation (including the adversary’s computation) from using dy-
namically computed values and checking them in conditional oper-
ations — this does not preclude computation using static encrypted
values being used in a small set of permitted conditional checks.
To this end, we enforce a conﬁdentiality property called reduced
indistinguishability, which is parameterized by a set W, on all com-
putation in the untrusted VM. Intuitively, W captures the subset of
the input alphabet Σ∗ which is permitted to leak (and necessary
to support benign functionality). For all input Σ∗ − W, reduced
indistinguishability offers IND-CPA security. We deﬁne reduced
indistinguishability along the lines of IND-CPA more formally in
Section 3.4. We term all executions which satisfy reduced indis-
tinguishability as safe. In practice, we ﬁnd that the W is a small
set — for supporting all our 25 case studies (Section 5), |W| = 12
(where Σ = 256).
Scope. In this work, we focus on preserving the conﬁdentiality of
the encrypted inputs and outputs, not the integrity or freshness of
the outputs of the executed program f(cid:48). Cryptographic techniques
to handle integrity and freshness are being investigated, but are be-
yond the goals of this work [17, 29]. In our threat model, we as-
sume that the legacy application is not designed to conceal lengths
of its inputs / outputs; our encryption techniques are assumed to
be length-revealing. Of course, techniques can be used to mitigate
the last assumption [40], which are orthogonal to our techniques.
We assume that the underlying homomorphic schemes are seman-
tically secure, and their implementations blind side-channels using
known techniques [20]. We do not aim to conceal information leak-
age through memory access pattern, which can be achieved using
oblivious RAM techniques [59].

In this work, we focus on applications that read sensitive ﬁles
and produce HTTP outputs decrypted on the client browser. For ex-
ample, web servers need to perform content snifﬁng on ﬁles types
(images, PDFs, etc.) to generate the appropriate HTTP MIME type
header. Other examples include standard Unix utilities to compute
statistics (e.g. word count, etc.)
for web ﬁles, keyword search,
checksum computation, base64 encoding, which are useful espe-
cially in cloud-hosted source code repositories (e.g. Github, Bit-
bucket). We do not support applications, outputs of which are to be
stored on the web server itself and further processed by AUTOCRYPT-
ed programs. Our evaluation is a preliminary ﬁrst step in this direc-
tion; future research is needed to improve both the expressiveness
and performance of AUTOCRYPT-ed programs.
2.4 Solution Overview

We design a new compiler—AUTOCRYPT that takes existing ap-
plications in C and transforms them automatically to work on en-
crypted data without any developer effort. In our design we com-
bine various PHE schemes to enable a subset of operations that a
general programming language supports. We develop a type sys-
tem that type checks any application before AUTOCRYPT trans-
forms it to AUTOCRYPT-ed program. An application which does
not type checks according to our system is considered ‘unsafe’ for
transformation. AUTOCRYPT identiﬁes the sensitive variables in a

Figure 2: Program Layout of AUTOCRYPT-ed Programs. The
variable ch is the sensitive variable and is assigned encryption
type as Paillier in checksum and search type in word count
program.

well-typed application and infers the right encryption type for its
content and transforms it to work on encrypted inputs.

The input ﬁle to the transformed program is pre-encrypted with
n(= 3) different homomorphic encryption schemes. A transformed
application operates on correct copy of the input ﬁle depending
on the encryption types inferred for the sensitive variables in the
program. We explain the program layout of two transformed ap-
plications that use one of 3 copies of the input ﬁle in Figure 2.
The checksum program that performs mathematical operations
fetches the sensitive input from the Paillier encrypted copy of the
input ﬁle whereas the word count program fetches its input from
the search encrypted copy of the input ﬁle. For both the programs,
word count and checksum, AUTOCRYPT identiﬁes the vari-
able ch as sensitive and infers an encryption type for it.
In the
word count program, ch is of search encryption type whereas
in the checksum program, it has Paillier encryption type. The 5
constants (shown as boldface) in the word count program are
also inferred the search encryption type, thus here |W| = 5. AU-
TOCRYPT pre-encrypts them in the search encryption scheme dur-
ing transformation of the program.
Hypervisor APIs. The checksum program shown in Figure 2
requires more than one homomorphic properties in the same pro-
gram. Thus, our system infers different encryption types to same
variable depending on the operation in which it is used. At any
given time, a program variable is encrypted in either search en-
cryption (srch), Paillier encryption of bits of integer (pal1), Pail-
lier encryption of integer (pal8) or Elgamal (egml) encryption
scheme depending on the operations performed on it. One possible
approach is to ask the client to decrypt the data in one encryption
scheme and encrypt it in another scheme. But the network latency
between the client and the server degrades the performance for ap-
plications like checksum where conversion between the encryp-
tion schemes is required for every character. To allow switching
between the encryption schemes while still executing the program
with acceptable performance, we provide a ﬁxed set of static hyper-
calls in the trusted hypervisor. The hypervisor APIs support only 6

    ch = getc(file);    if (ch == '\n')       lines++;    if (ch == '\r' || ch == '\f') {       if (linepos > linelength)          linelength = linepos;       linepos = 0;       words++;    }    if (ch == '\t') {       linepos += 8 - (linepos % 8);       words++;    }    if (ch == '\v') {       words++;    }  }    write_counts (lines, words);ELGAMALPAILLIERSEARCHsum = 0; while (ch = getc (fp))     {       total_bytes++;      sum = (sum >> 1)     + ((sum & 1) << 15);      sum += ch;      sum &= 0xffff;  }N = 3 copies of input fileChecksum Word count 1300techniques. The output of this step is a well-typed IR — that is, it
satisﬁes a formal set of type rules we deﬁne in Section 3.3.
Transformation. Finally, AUTOCRYPT transforms the well-typed
IR into target x86 code using a syntax-directed translation step.
In this step, each original computation is converted into the corre-
sponding homomorphic computation. In addition, this step handles
various features of real-world C programs, such as encoding into
machine words, handling pointers, structures, C libraries, and so
on. We detail these in Section 4.
3.2 Background on Encryption Schemes

We brieﬂy introduce the partially homomorphic schemes used in

AUTOCRYPT.
Searchable Encryption(srch). Searchable encryption scheme al-
lows the owner to outsource encrypted data while maintaining the
selectively-search capability over it. Keyword based symmetric
searchable encryption enables such remote searching on encrypted
data by an untrusted server [58]. Speciﬁcally, the untrusted server
uses an user-provided encrypted token (unique to every search key-
word) to determine whether a document contains the word, without
learning anything else.

AUTOCRYPT uses this encryption scheme to support operators
such as equal to. Previous works discuss various schemes to sup-
port similar operations [16, 58]. Among these, AUTOCRYPT uses
CryptDB implementation of searchable encryption [51], based on
cryptographic protocol of Song et al. [58]. In AUTOCRYPT, the
search keyword is mostly a character and hence both the keywords
and ﬁle encryption are at character level as opposed to word-level
encryption in CryptDB. Note that the deterministic encryption sche-
mes also support such equality checks. But it is a weaker encryp-
tion scheme revealing information about the underlying plaintext.
The search scheme AUTOCRYPT uses is randomized and is thus
CPA secure [58]. Hence, an attacker is bound to search only those
terms which are available in an encrypted form either as program
constants or as inputs and outputs for client queries.
Paillier Encryption. AUTOCRYPT uses the encryption scheme
proposed by Paillier [48], to support various arithmetic and bit-
wise operations on encrypted data. Since the operations are homo-
morphic, the result are also encrypted under Paillier scheme. The
encryption scheme is semantically secure and assures guarantees
equivalent to randomized encryption. AUTOCRYPT classiﬁes Pail-
lier scheme into two categories.

i. Paillier encryption of an integer (pal8): Integer value of a
high variable is encrypted using Paillier encryption . This
encryption is necessary for arithmetic operations such as addi-
tion, which operate on the integer representation.

ii. Paillier encryption of the bits of an integer (pal1): To handle
intermediate bitwise computations such as XOR, that rely in
an essential way on the binary representations of their input
values, AUTOCRYPT encrypts every bit in the binary represen-
tation of an integer.

Elgamal Encryption. Elgamal encryption scheme is used to ho-
momorphically multiply two encrypted operands such that the re-
sult is also encrypted under Elgamal scheme [24]. AUTOCRYPT
demonstrates the use of this scheme for homomorphic matrix mul-
tiplication in Section 5. Support for regular expression matching
and DFA can also be added to AUTOCRYPT by using this encryp-
tion scheme [62].

Figure 3: Design overview of AUTOCRYPT.

ﬁxed functionalities to switch the sensitive data between different
homomorphic encryption schemes. The hypervisor does not exe-
cute any unprivileged arbitrary code on the sensitive data, thus our
increase in hypervisor TCB only consists of the following 6 hyper-
calls for conversion between encryption schemes.

• pal8 to pal1
• egml to pal1
• egml to pal8
• pal1 to egml
• pal8 to egml
• static memory lookup
Thus, using the three encrypted copies of the sensitive input and
the hypervisor APIs, AUTOCRYPT transforms majority of the ex-
isting applications to operate on encrypted data.
3. AUTOCRYPT DESIGN

In this section we describe the end-to-end design of AUTOCRYPT

and discuss security guarantees of our system.
3.1 Overview

AUTOCRYPT takes as input a legacy application that operates
on unencrypted ﬁles and transforms it to an AUTOCRYPT-ed pro-
gram which operates on encrypted ﬁles and command-line inputs
(refer Figure 3). The developer annotates all reads from sensitive
ﬁle APIs and command line arguments in the initial program with
high information labels. AUTOCRYPT takes the annotated pro-
gram and performs the following steps:
Conversion to SSA form. In the ﬁrst step, AUTOCRYPT converts
the input program to an intermediate representation in Static Single
Assignment form (SSA). SSA form splits the lifetime of a program
variable into many smaller ones by assigning a new version every
time it is re-deﬁned. This allows AUTOCRYPT to separate out dif-
ferent operations over the lifetime of a variable, thereby increasing
the opportunity to separate out operations that are incompatible un-
der a single homomorphic encryption scheme. Every operation is
represented as a separate instruction in the Internal Representation
(IR). We refer the output of this step as the untyped IR.
Information Flow Analysis. AUTOCRYPT then analyzes the un-
typed IR for variables and constants that need encryption. In this
analysis, AUTOCRYPT tracks and propagates direct data dependen-
cies of program variables on high-labeled inputs, ﬁle inputs and
the outputs of the application. Our static data-dependency tracking
is ﬂow-sensitive. This analysis is akin to the standard variable-level
taint-tracking [27]. Information ﬂow analysis produces an anno-
tated IR, in which all the operands are marked as either high or
low.
Type Inference. AUTOCRYPT infers the precise homomorphic en-
cryption scheme to be used for each high operand in the anno-
tated IR. At the end of this step, it labels each operation with an
encryption type that signiﬁes its associated encryption scheme. To
perform this step, AUTOCRYPT uses the standard type inference

UntypedIRAnnotated IRWell TypedIRInformation Flow   AnalysisTypeInferenceTransfor­mationSSALegacyProgramAutoCrypted Code13013.3 AUTOCRYPT Type Inference

Although standard information ﬂow rules assist to infer all the
program entities that are high [53, 57], inferring the correspond-
ing encryption scheme is a non-trivial task. There are several subtle
factors such as control ﬂow, program constants, lookups using en-
crypted indexes, and complex arithmetic operations requiring con-
version from one encryption type to other. These challenges must
be carefully addressed so as to preserve the security guarantees of
a legacy application. To this end, we present AUTOCRYPT frame-
work armed with a formal type system which checks whether a C
application can be transformed to a safe application.
Main insight. An annotated IR has all operands marked high or
low. Our type system allows arbitrary computation in expressions
computed from low values, and these resulting values are not en-
crypted (either statically or at runtime). The adversary, thus, cannot
use such low-labeled values to compute or check any encrypted
data.

For high-labeled variables, we permit them to either be used
in conditional checks or in arithmetic / bitwise operations, but not
both. Speciﬁcally, high-labeled values can only be used in equal-
ity / inequality checks with other operands, and our type system
forces them both to be encrypted under the search scheme. In ef-
fect, this prevents all values used in conditional checks from be-
ing used in any arithmetic / bitwise (non-conditional operations) as
they are in different encrypted forms at runtime.

Remaining high values can be computed in arithmetic / bitwise
schemes, but these are never permitted to be converted to search-
encrypted values. This is checked by our static type rules, and
no hypercall allows to convert between searchable encryption and
other homomorphic schemes at runtime. Together, this enables a
conceptual partitioning of encrypted memory between searchable
and non-searchable values.
Language. Figure 4 shows the syntax for a simple typed language
supported by AUTOCRYPT. For brevity, we consider this simple
language to illustrate our approach. However we evaluate on vari-
ous C programs as discussed in Section 5. The simple language is
a subset of C and is expressive enough to model many programs.
Our type-based approach is general and can be enhanced further
to incorporate richer language features. We discuss the subset of
C constructs we support in Section 4. The language has two pos-
sible information-ﬂow labels low and high. Program variables
and constants are also classiﬁed based on the required encryption
types viz. no encryption i.e. plain text (ptxt), search encryption
(srch), Paillier encryption (pal8, pal1) and Elgamal encryp-
tion (egml).

Operations that can be computed with the same encryption scheme
are syntactically combined in the language. For bitwise operations
in (cid:12) and (cid:125), one or both the operands must be in bitwise Pail-
lier encryption scheme (pal1). Arithmetic operations in (cid:11) need
operands encrypted in integer Paillier scheme(pal8). For multi-
plying two encrypted variables (∗), they must be encrypted under
In conditional operations (⊗), an en-
Elgamal scheme (egml).
crypted high variable can be compared against encrypted public
program constant. Hence, both its operands must be encrypted un-
der search encryption scheme (srch). Note that known program
constants in our language are typed to be either encrypted or non-
encrypted but they are publically known and hence always low.
Type System. Each expression has a type τ, which is a tuple of
two labels: information-ﬂow label (low and high) and encryption
type label. We write Γ (cid:96) e : τ to denote that the expression e has
type τ according to the typing rules in Γ typing environment, where
τ denotes type of e. Such an assertion is called a typing judgment.

Types
τ
Type Qualiﬁers Q
Base Types
T
Plaintext
α
Encrypted
β
β1
β2
e

Expressions

Bitwise

Arithmetic
Boolean

Conditional
Logical
Commands

lval
(cid:12)
(cid:125)
(cid:11)
b
bool
⊗
(cid:9)
P

::=
::=
::=
::=
::=
::=
::=
::=

(Q, T )
high | low
α | β
ptxt
β1 | β2
srch
pal8 | pal1 | egml
e1 (cid:12) e2 | e1 (cid:125) e2 | e1 (cid:11) e2 | e1 ∗ e2
| lval | const (i:τ)
var (v:τ)
::=
::= & | ˆ | |
::= << | >>
::=
::=
::=
::=
::=
::=

+ | -
bool | e1 ⊗ e2 | b1 (cid:9) b2
true | false
== | !=
AND | OR
lval := e
| lval := ARR[var]
| if b then P else P’
| while (b) do P
| return r
| f(e1, e2, . . ., en) {P;}

Figure 4: The grammar of a simple subset of C language sup-
ported by AUTOCRYPT.
Typing rules for Expressions. The expression typing judgement
Γ (cid:96) e : τ states that at a given program location, the expression
e has a type τ. The Γ denotes the type environment that maps
variables to the target language base types.
Typing rules for Commands. The type system is ﬂow-sensitive
because it permits the mappings of variables to types in the typing
environment Γ to change from one program location to another.
Typing judgements for the commands in Figure 5 capture the ef-
fects of execution of the command on the type environments and
have the form Γ (cid:96) c =⇒ Γ(cid:48). The type environment Γ is changed
to Γ(cid:48) as a result of the execution of the command.
Type Inference. We infer ﬂow-sensitive types based on our type
rules in Figure 5 using standard techniques proposed in previous
work [27]. We omit the type rule for instructions taking all operands
with low labels.

The rules for inferring encryption types are as follows.
• SRCH : If one operand to a conditional operation (⊗) is high
searchable variable and other is a program constant, then
both the operands are typed to srch and the result is a low
boolean value.

• PAL8-A & B : For mathematical operations in (cid:11), one or
both operands can be high. For ∗ one operand is high and
other is low. Then, the high operands have type pal8 and
the result of computation is also pal8 type.

• PAL1-A & B : For bitwise operations in (cid:12) and (cid:125), the high
operand is given type pal1 while the other operand can be
low or high. The resulting value is also in pal1.

• EGML : If both the operands to a ∗ operation are high, then

the operands and result have egml type.

• The encryption type to lvalue for statements is speciﬁed in

the type rules.

Type Conversion. Figure 6 depicts the type lattice enforced by
AUTOCRYPT type system. Type conversions are non-descending
i.e. conversions only go upwards or are at the same level [23].
Our type system only supports the conversions for which there is
a corresponding runtime hypervisor API. We explain the safe up-
casting conversions below, and give examples of the unsafe down-
casting operations not supported by our hypervisor runtime.

1302SEQ
Γ0 (cid:96) P1 : Γ1

Γ1 (cid:96) P2 : Γ2

Γ0 (cid:96) P1; P2 =⇒ Γ2

COND
Γ0 (cid:96) b : (low, ptxt)

Γ0 (cid:96) P1 : Γ

Γ0 (cid:96) P2 : Γ

Γ0 (cid:96) if (b) then P1 else P2 : Γ

WHILE
Γ (cid:96) b : (low, ptxt)

Γ (cid:96) P : Γ

Γ (cid:96) while(b)do P : Γ

FUNC

Γ (cid:96) P : τ

Γ (cid:96) f (e1, e2, . . . , en){P } : τ
SRCH
Γ (cid:96) b : τ

Γ (cid:96) e : (high, srch)

PAL8-A
Γ (cid:96) e : τ

Γ (cid:96) e1 : (high, β)

opr ∈ {(cid:11), ∗}

Γ (cid:96) e2 : (low, ptxt)

Γ (cid:96) e := e1 opr e2 =⇒ Γ[e (cid:55)→ (high, pal8)]

PAL8-B
Γ (cid:96) e : τ

Γ (cid:96) e1 : (high, β)

Γ (cid:96) e2 : (high, β)

Γ (cid:96) e := e1 (cid:11) e2 =⇒ Γ[e (cid:55)→ (high, pal8)]

PAL1-A
Γ (cid:96) e : τ

Γ (cid:96) e1 : (high, β)

opr ∈ {(cid:125), (cid:12)}

Γ (cid:96) e2 : (low, ptxt)

Γ (cid:96) e := e1 opr e2 =⇒ Γ[e (cid:55)→ (high, pal1)]

PAL1-B
Γ (cid:96) e : τ

Γ (cid:96) e1 : (high, β)

Γ (cid:96) e2 : (high, β)

Γ (cid:96) e := e1 (cid:12) e2 =⇒ Γ[e (cid:55)→ (high, pal1)]

Γ (cid:96) e1 : (high, β)

Γ (cid:96) e2 : (high, β)

Γ (cid:96) e := e1 ∗ e2 =⇒ Γ[e (cid:55)→ (high, egml)]
EGML-PAL1

EGML-PAL8

q ∈ Q

q ∈ Q

VAR
{v (cid:55)→ τ} ∈ Γ

Γ (cid:96) v : τ

CONST

{c (cid:55)→ τ} ∈ Γ

Γ (cid:96) c : (low, ptxt ∨ srch)
BOOL

{b (cid:55)→ τ} ∈ Γ

Γ (cid:96) b : (low, ptxt)
ASSGN

Γ (cid:96) e : τ

Γ (cid:96) v := e =⇒ Γ[v (cid:55)→ τ ]
ARR
Γ (cid:96) arr : (high, β)
Γ (cid:96) i : (low, ptxt)
Γ (cid:96) v := arr[i] =⇒ Γ[v (cid:55)→ (high, β)]

STATIC-MEM
Γ (cid:96) arr : (low, ptxt)
Γ (cid:96) i : (high, β)
Γ (cid:96) v := arr[i] =⇒ Γ[v (cid:55)→ (high, β)]

Γ (cid:96) b := e ⊗ c =⇒ Γ[b (cid:55)→ (low, ptxt),

c (cid:55)→ (low, srch)]

Γ (cid:96) c : (low, ptxt)

EGML
Γ (cid:96) e : τ

PAL8-PAL1
q ∈ Q

PAL1-PAL8
q ∈ Q

PAL8-EGML

q ∈ Q

PAL1-EGML

q ∈ Q

(q, pal1) ≥ (q, pal8 )

(q, pal8) ≥ (q, pal1)
Γ is the typing environment that maps vari-
Figure 5: Type Rules for expressions and commands in AUTOCRYPT.
ables and constants to type qualiﬁers high or low at each program locations.
It also maps the encryption types viz.
ptxt, srch, pal8, pal1 or egml to each variable. Type qualiﬁers are ﬂow sensitive. We omit the type rule for instruc-
tions taking all operands with low labels here for brevity.

(q, egml) ≥ (q, pal8)

(q, egml) ≥ (q, pal1)

(q, pal1) ≥ (q, egml)

(q, pal8) ≥ (q, egml)

q ∈ Q

(q, (cid:62)) ≥ (q, α ∨ β)

q ∈ Q

(q, β2) ≥ (q, β1)

q ∈ Q

(q, β1) ≥ (q, ⊥)

Figure 6: Type Lattice rules for AUTOCRYPT

(a) Safe conversions (Up-casting):

Type rule PAL8-PAL1 and PAL1-PAL8 allow interconversion
of high variable encrypted under Paillier integer and Paillier
bit scheme. Similarly, PAL8-EGML, PAL1-EGML enables
conversion from Paillier (both integer and bit) encryption to
Elgamal scheme and EGML-PAL8, EGML-PAL1 from Pail-
lier to Elgamal scheme. Up-casting from searchable encryp-
tion scheme to Elgamal and Paillier schemes is safe according
to the type-lattice.

(b) Unsafe conversions (Down-casting):

AUTOCRYPT type rules do not allow conversion from Elgamal
or Paillier encryption scheme to searchable encryption scheme.
If such conversions are allowed by the type system, an adver-
sary can build a program which arbitrarily converts the results
of arithmetic homomorphic operation say x = y+10 to search-
able cipher text. Then, he can compare x to the available pro-
gram constants encrypted as searchable tokens. By such a se-
ries of instructions, an adversary can predict the initial value of
y with a non-negligible advantage, and hence win the indistin-
guishability game. Thus, to prevent such attacks, the conver-
sion to searchable encryption by down-casting is not allowed
in AUTOCRYPT.

All static program constants are marked low as these are pub-
lically known. Program constants used in the relational operations
with high operands need to be encrypted. All the other program
constants need not be encrypted, as they are used directly in the
transformed homomorphic operations (see Section 3.5). The type
rules for the remaining expressions are straight forward, except the
rule to handle lookup in a static memory using encrypted indexes.
Encrypted indexes to static memory. A lookup in a statically ini-
tialized array of public constants using a high index can reveal the
encrypted index, if the adversary can observe the lookup result. Our
type system handles this securely (rule STATIC-MEM) by forcing
the outputs of such memory lookups to be high and encrypted

under the same scheme as the encrypted index. To support this
operation at runtime, our hypervisor provides an hypervisor API
that performs the lookup obliviously. Speciﬁcally, the hypercall for
ARR[i] lookup operation ensures that ∀ m ∈ RAN GE(arr),
(E(arr[D(i)]), E(m)) are computationally indistinguishable by
the adversary.

We point out that, in principle such lookups could be supported
by using homomorphic evaluation of polynomials [62]. However,
for Σ = 256 the polynomial degree is high and the evaluation could
be slow. Alternatively, AUTOCRYPT’s hypervisor API supports
static memory lookup as follows: All statically initialized lookup
arrays are saved as plaintext in the trusted hypervisor. Every lookup
from such arrays using an encrypted index is converted to a hyper-
call. In the trusted hypervisor environment, the service API ﬁrst
decrypts the index and fetches the corresponding plaintext from the
static (unencrypted) memory. The plaintext is then encrypted under
the same randomized encryption scheme as the index, using a fresh
random nonce.
3.4 Security Guarantees

AUTOCRYPT does not rely on the type system discussed in Sec-
tion 3.3 for security. The type system only assists in checking pro-
gram’s compatibility for AUTOCRYPT conversion and for inferring
encryption types of program variables. However, even bad program
(ill-typed) can execute on the malicious web server. To this end, our
design of the hypervisor APIs together with the use of homomor-
phic encryption schemes safeguard against such ill-typed programs,
while ensuring that for all executed code in the VM (including ad-
versarial and benign code), has a speciﬁc security property which
we deﬁne below.
Privacy-preserving Executions. Any executing program in the
VM can be viewed as a sequence of selective statements from the
program depending on the input. A program trace corresponds to
one such execution sequence. More formally, we deﬁne:

DEFINITION 1. (Program Trace T ) The program trace T :
(cid:126)I → (cid:126)O is a sequence of statements (cid:104)S1, . . . , Sn(cid:105) operating on
encrypted input (cid:126)I yielding encrypted output (cid:126)O in deterministic pro-
gram P .

1303As previously mentioned, the program can only use a small set of
publicly known program constants W in conditional comparisons
(control ﬂow decisions), made available in the VM for supporting
some benign applications. We deﬁne W and a program P formally
as below.
DEFINITION 2. (Encrypted Search Constants W) For a pro-
gram P, W = {W1, . . . , Wn} such that W ⊆ Σ∗ and Wi is a pub-
lically known program constant encrypted under search scheme.

DEFINITION 3. (Program P ) A Program P = (T, W) where

W is a subset of possible input alphabets Σ∗. Speciﬁcally, all the
publically known program constants which are marked as low and
are also encrypted under search scheme belong to the set W.
T = {T1, . . . , Tn}, and W are encrypted search constants.
The execution of a program trace interleaves between the execution
in the untrusted VM and in the trusted hypervisor. Therefore, we
can deﬁne the projection of a trace visible to an entity (either the
adversary or the hypervisor) as follows: P may have other program
constants; but we ignore them in our deﬁnitions for clarity as they
are unimportant for our security reasoning.

DEFINITION 4. (Projection Pi) Projection Π of a trace T onto
E, written as ΠE(T ), is a subsequence of a program trace T visible
to an entity E.

Given a program trace, an entity can view only some statements
in the execution trace. For example, the untrusted VM (say A)
cannot see the internal hypervisor implementations of the hyper-
calls and encrypted memory lookups in an AUTOCRYPT-ed pro-
gram. Thus, these statements will not be a part of the ΠA(T ).
The following 2 security deﬁnitions constitute the conﬁdentiality
of the sensitive inputs, apart from the values which the adversary
can directly compare with W by using equality checks on search
encrypted bytes.

DEFINITION 5. (Input Reduction Function R) For an input
vector (cid:126)I for a given program P , we deﬁne the input reduction func-
tion R((cid:126)I, W) which reduces (cid:126)I by discarding all the Wj values in (cid:126)I
at positions where ∀ Wi ∈ W, Wj = Wi.

DEFINITION 6. (Reduced Indistinguishability modulo W) For
a given trace T : (cid:126)Ii → (cid:126)Oi and W, we say that T has reduced indis-
tinguishability modulo W, iff ∀ m0, m1 ∈ R((cid:126)I, W), the advantage
Adv(A) = |P r[ΠA(Tm0 ) = 1] - P r[ΠA(Tm1 ) = 1]| < ε for all
probabilistic polynomial time-bounded adversaries A, where ε is
negligible function negl(n).
Thus, along a given trace Ti in the program P , the advantage of all
adversaries is negligible and it cannot distinguish two inputs from
the reduced input vector. This reduces to standard deﬁnitions of
ciphertext indistinguishability under IND-CPA when W = 0.

DEFINITION 7. IND-CPA for Search Encryption. For a given
trace T : (cid:126)Ii → (cid:126)Oi and a set of encrypted search constants W
available to the adversary, if (cid:126)Ii is search encrypted, then ∀ m0, m1
∈ R((cid:126)I, W), the advantage Adv(A) = |P r[ΠA(Tm0 ) = 1] −
P r[ΠA(Tm1 ) = 1]| < ε for all probabilistic polynomial time-
bounded adversaries A, where ε is negligible function negl(n).
The above deﬁnition assumes the server has only the searchable
encryption copy of the user’s ﬁle. The proof of indistinguishability
under IND-CPA for search encryption follows directly from previ-
ous work [58].

DEFINITION 8. IND-CPA for Non-Search Encryption. For
Trace Ti : (cid:126)Ii → (cid:126)Oi, ∀ m0, m1 ∈ (cid:126)I, the advantage Adv(A) =
|P r[ΠA(T (m0 ) = 1] - P r[ΠA(Tm1 ) = 1]| < ε for all probabilis-
tic polynomial time-bounded adversaries A, where ε is negligible
function negl(n).

If we assume that there is only non-search encrypted copy of
the ﬁle on the server, W = 0 and hence R((cid:126)I, W) ≡ (cid:126)I. Thus,
for a purely non-search encryption the indistinguishability property
holds. The proof follows directly from the IND-CPA security of
individual homomorphic schemes [64].

Deﬁnitions 6, 7 and 8 are independently true only when a cor-
responding single copy of encrypted ﬁle(encrypted either under
searchable encryption or non-searchable encryption scheme) is avail-
able. If both copies are present simultaneously on the server, logi-
cally the deﬁnitions holds for min(I, R((cid:126)I, W)) i.e. on the reduced
input R((cid:126)I, W).

The following theorem states that interconversion between non-

search schemes preserves indistinguishability under IND-CPA.

LEMMA 1. IND-CPA for non-search Composition. For a safe
program P, if the functions f1, . . . , fn are individually secure non-
search homomorphic functions under IND-CPA, then the composi-
tion (fi ◦ fj)(x) where i, j ∈ {1, . . . , n} satisﬁes reduced indis-
tinguishability.

Our conversions between the non-search encryption schemes can
be proved using bisimulation induction on a type system proposed
in recent work [28].

Our ﬁnal theorem says that all execution traces in the hypervisor
are privacy preserving, i.e., follow reduced indistinguishability for
a given W. This stems from a critical design choice: the hypervisor
does not permit converting from non-search to search types dur-
ing execution. Let N S(T ) and S(T ) be set of runtime values en-
crypted under non-search and search encryption in T respectively.
Our hypervisor ensures that N S(T )∩S(T ) ⊆ W. This establishes
the following safety condition for any program running in the VM:
THEOREM 1. IND-CPA of all VM Executions. For a program
P = (T, W), executing on our hypervisor, reduced indistinguisha-
bility modulo W holds if ∀ T ∈ T, N S(T ) ∩ S(T ) ⊆ W.
PROOF SKETCH. Proof follows from Deﬁnition 7 and Lemma 1.
We sketch the outline below: ∀ vns ∈ N S(T ) and ∀ vs ∈ S(T )
hypervisor does not permit conversion at runtime from values vns
to corresponding vs. Thus, the only values v for which both vs
and vns are known are in set of encrypted search constants used
in conditional operations. For P, W is a set of all such encrypted
constants. From Deﬁnition 7, reduced indistinguishability holds for
the traces comprising encrypted search constants. For non-search
encryption, reduced indistinguishability follows from Lemma 1. (cid:4)
Well-Typed Programs. For benign programs, AUTOCRYPT aims
to identify if all the traces in it can be made privacy-preserving.
The type rules check this, and if well-typed, programs are trans-
formed. We show that well-typed program indeed have reduced
indistinguishability modulo W.
THEOREM 2. Well-Typed Implies IND-CPA. If P is a well-
typed program, then ∀ T ∈ P , the reduced trace indistinguisha-
bility property holds for T .

We omit a rigorous proof in this paper.

3.5 Transformation
Converting operations to homomorphic computation. We use
CryptDB implementation of the search and Pailler encryption sche-
mes and libgcrypt library for the Elgamal encryption scheme [3,
51]. Combining partially homomorphic properties of Paillier, Elga-
mal and search scheme, we transform various operations to operate
on encrypted data. We give details of subset of C operations that
AUTOCRYPT supports and the encryption type required by them
in Table 1. Operations not listed in Table 1 are either not possible
using homomorphic encryption schemes or are not safe and hence
are not allowed by AUTOCRYPT.

1304Operation

Op1 Type Op2 Type Output Type

add(+)
mul(∗)
sub(−)
shl ((cid:28))
shr ((cid:29))
or (|)

and (&)

xor (ˆ)

equal (==)

not_equal (! =)

pal8
pal8
pal8
egml
pal8
pal8
pal1
pal1
pal1
pal1
pal1
pal1
pal1
pal1
srch
srch

ptxt
pal8
ptxt
egml
ptxt
pal8
ptxt
ptxt
ptxt
pal1
ptxt
pal1
ptxt
pal1

pal8
pal8
pal8
egml
pal8
pal8
pal8
pal8
pal1
pal1
pal1
pal1
pal1
pal1

keyword true / false
keyword true / false

Table 1: Homomorphic operations supported by AUTOCRYPT.
Column 2, 3 and 4 give the encrytion type for expressions of
the form Output = Op1 operation Op2. The implemen-
tation of the operations or, and and xor comprise of hyper-
calls (shown in bold faced) when both its operands are en-
crypted. equal and not_equal operations take one operand as
a keyword which is a searchable program constant.

Encryption type conversion. Operations involving different en-
cryption types may require conversion of intermediate results to
other encryption schemes, for example converting an integer en-
crypted under Paillier encryption to Elgamal encryption. AUTOCRYPT
inserts hypercalls at appropriate program locations for permitted
convert operations. The hypervisor API in turn implements these
operations. It ﬁrst decrypts the input value using appropriate keys,
and then re-encrypts this value using the keys for target encryp-
tion scheme. At last, it responds to the hypercall by returning this
re-encrypted value to the untrusted VM.

4.

IMPLEMENTATION

We implement AUTOCRYPT to automatically transform applica-
tions written in C to operate on encrypted data. In this section, we
discuss the details of our implementation.
Analysis Pass. The sensitivity analysis phase of AUTOCRYPT is
implemented as an analysis pass in the LLVM 3.2 infrastructure
[42]. This phase comprises of conversion from LLVM IR to pure
SSA form using LLVM mem2reg pass followed by following anal-
yses.

The SSA form is then passed to the points-to analysis module
which uses algorithm proposed by Hardekopf et al. [35]. All the
virtual registers are grouped in alias sets and the information is
maintained as pragmas to be used by the consecutive phases of AU-
TOCRYPT.

All user inputs and operations on data fetched from the ﬁle are
marked as sensitive. This phase propagates the sensitivity of input
by marking the appropriate variables and constants as sensitive and
the records corresponding instructions as sensitive. AUTOCRYPT
analyses all the functions of the program to collect a set of sensitive
elements and instructions and logs the results in the form of Datalog
facts.

After identifying all the possible sensitive constants and vari-
ables, AUTOCRYPT’s inference module assigns them a type of en-
cryption scheme using the type rules discussed in Section 3. AU-
TOCRYPT implements this phase in Datalog, which takes the list
of sensitive variables, constants and corresponding instructions as
facts [1, 11]. The typing rules discussed in Section 3 are given as

Category of ﬁle operations Utilities
Basic operations
Summarizing ﬁles
Formatting ﬁle contents
Operating on characters
Operating on ﬁelds
Operating on sorted ﬁles
Output of parts of ﬁles
Output of entire ﬁles

shred, truncate
wc, sum, cksum
fmt, old, pr
expand, unexpand, tr
cut, paste, join
shuf, uniq, comm, ptx, sort
head, tail, split, csplit
cat, tac, nl, base64, od

Table 3: Classiﬁcation of 8 categories of COREUTILS used for
case study
constraints to Datalog which infers the encryption type for all the
sensitive elements.The inference results of Datalog are fed back to
the LLVM IR in the form of pragmas.
Transformation Pass. AUTOCRYPT transforms the typed IR code
to AUTOCRYPT-ed code. This phase is implemented as a transform
pass in LLVM and it involves:

(a) computing the encrypted constants pool required by the pro-

gram using the client’s key

(b) instrumentation to load the program variables with correct val-

ues of encrypted data at run time

(c) adding calls to partially homomorphic functions which operate

(d) inserting hypercalls for converting data encrypted in one en-

on encrypted parameters

cryption scheme to another.

(e) replacing the calls to C libraries (like string operations and ﬁle
operations) with AUTOCRYPT’s library calls. We analyse the
implementation of standard C libraries for character handling
and string manipulation using AUTOCRYPT and generate pre-
compiled AUTOCRYPT-ed libraries. We transformed 15 C li-
brary functions for evaluation of our case studies.

AUTOCRYPT transforms the annotated and well-typed IR to emit
transformed un-optimized AUTOCRYPT-ed code which operates on
encrypted data.

5. EVALUATION
Evaluation Goals. We aim to evaluate the effectiveness of AU-
TOCRYPT for following main goals:

• We evaluate the developer effort required to transform exist-

ing applications to operate on encrypted data.

• We evaluate applications to work on encrypted data using
combination of various partially homomorphic encryption
schemes.

• We evaluate the performance of AUTOCRYPT-ed programs
compared to the traditional ‘download-and-compute’ strat-
egy and use of existing fully-homomorphic encryption sche-
mes.

5.1 Expressiveness

We select total 30 case studies from common programs available
on the LAMP Stack which include COREUTILS, file utility and
three custom programs.
CoreUtils. The use of command line utilities is popular among
web services like SVN [60], GitHub [33], Google shell (goosh) [34],
etc. Hence, we perform evaluation on Unix ﬁle processing applica-
tions from the COREUTILS v.8.13 package [2]. Table 3 shows the
programs in 8 of total 11 categories of COREUTILS that we trans-
form to assert the effectiveness of our solution. The remaining 3

1305Execution Time(sec)

Programs

cat(simple)
split
csplit
paste
tac
expand
unexpand
truncate
shred
shuf
nl
tail
head
cut
join
tr
ptx
pr
fmt
wc
fold
sum
base64*
cksum*
ﬁle

Encrypted Variables
%
Enc
0.00
0
116
5.79
4.34
26
5.83
34
10.79
78
2.83
14
4.11
25
0.00
0
0
0.00
9.28
53
3.59
19
8.16
76
11.52
155
5.99
58
54
6.47
2.77
20
14.79
129
9.00
91
11.10
124
6.09
61
51
13.78
11.21
36
17.12
81
5.90
34
229
9.10

Tot
324
2002
598
583
723
494
608
487
1325
571
529
931
1346
968
834
721
872
1011
1117
1002
370
321
473
576
2516

Encrypted Constants
Enc
0
5
1
4
1
7
7
0
0
0
2
3
4
6
1
3
6
16
20
6
8
0
0
0
7

%
0.00
3.52
3.12
5.71
2.22
12.73
11.29
0.00
0.00
0.00
4.44
7.69
3.81
7.89
0.1
5.63
9.62
14.53
15.04
8.96
23.53
0.00
0.00
0.00
12.96

Tot
30
142
32
70
45
55
62
53
132
32
45
39
105
76
10
53
62
110
133
67
34
38
44
78
54

Changed Instructions
Enc
0
1
29
10
1
7
7
0
0
1
0
10
3
20
6
4
27
12
30
6
7
13
11
24
23

Tot
446
2712
1217
809
925
674
850
676
1767
750
648
819
1848
1385
737
592
1527
936
1546
1381
487
402
617
872
2916

%
0.00
0.04
2.30
1.24
0.11
1.04
0.82
0.00
0.00
0.13
0.00
1.22
0.16
1.44
0.81
0.67
1.76
1.28
1.94
0.43
1.44
3.23
1.78
2.75
0.07

Compilation Time(sec)
Total
Infr.
0.06
0.04
0.28
0.20
0.59
0.27
0.18
0.13
0.17
0.14
0.13
0.10
0.17
0.13
0.09
0.07
0.04
0
0.18
0.15
0.11
0.08
0.25
0.11
0.34
0.23
0.26
0.11
0.24
0.16
0.12
0.06
0.24
0.13
0.41
0.18
0.72
0.58
0.31
0.25
0.16
0.13
0.12
0.09
0.54
0.24
0.34
0.10
0.62
0.42

Trans.
0.02
0.08
0.32
0.05
0.03
0.03
0.04
0.02
0.04
0.03
0.03
0.14
0.11
0.150
0.08
0.06
0.11
0.23
0.14
0.06
0.03
0.03
0.30
0.24
0.20

1KB
0.006
0.007
0.007
0.008
0.007
0.010
0.008
0.011
0.125
0.007
0.007
0.007
0.008
0.012
0.026
0.012
0.014
0.030
0.029
0.034
0.022
0.020
0.200
0.371
0.186

10KB
0.008
0.010
0.010
0.015
0.010
0.021
0.034
0.021
0.144
0.020
0.026
0.017
0.024
0.026
0.046
0.031
0.057
0.446
0.217
0.357
0.381
0.036
1.534
1.632
0.120

100KB
0.371
0.028
0.018
0.241
0.280
0.254
0.348
0.062
0.172
0.351
0.519
0.035
0.033
0.190
0.237
0.397
0.291
1.37
1.40
2.84
2.02
.549
5.33
7.78
0.194

Comp.to
to DC
0.304
0.022
0.014
0.197
0.229
0.208
0.285
0.050
0.141
0.288
0.426
0.167
0.270
0.155
0.194
0.325
0.239
1.124
1.149
2.33
1.658
0.450
4.376
6.387
0.160

Table 2: Summary of sensitivity analysis and transform pass for 25 ﬁle processing utilities. cat(simple) is executed without
any command line options. Only sum, base64, cksum (shown bold faced) make hypercalls during execution. We annotate
base64, cksum (marked star) such that multiple calls for conversion between encryption types are combined into one hypercall.
Last column reports the execution time ratio of AUTOCRYPT-ed programs to ‘download-and-compute’ method.

categories include the programs which do not operate on the sen-
sitive contents of ﬁle and so we do not evaluate them. Our current
implementation does not support command line options involving
regular expressions to programs such as ptx, nl, tr. How-
ever, we point out that using static memory lookup hypercall or
DFA evaluation techniques, regular expression matching is possi-
ble but will require advanced analysis techniques [62]. To test the
programs, we create encrypted input ﬁles of size 1, 10, 100 KB
under search, Paillier and Elgamal encryption schemes. In Table 2,
we present the transformation and execution time for these utili-
ties. AUTOCRYPT transforms 25 out of 30 commands of various
categories to operate on pre-encrypted ﬁles of various sizes. We
conﬁrm that the transformed programs remain functional and pre-
serve the semantics of the original application.
File Utility. We select the UNIX file utility, which determines
the type of a given input ﬁle, as our benchmark. We select this
utility because of its usage in a web server for learning the MIME
type of ﬁles and determining the HTTP content header [13]. Every
ﬁle type contains a magic number at a ﬁxed position which dis-
tinguishes it from other ﬁles. A magic ﬁle is a collection of all
such magic numbers and their position for various ﬁle types. We
encrypt these magic numbers with search encryption scheme. The
transformed file command uses the encrypted magic ﬁle to de-
termine the ﬁle types of the sensitive ﬁles. The size of the input ﬁle
does not effect the performance of this application as only the bytes
at a ﬁxed position are searched to identify the ﬁle type.
Custom programs. We select three particular applications to show
the broad applicability of AUTOCRYPT for functions which are
used for various privacy preserving computations [36, 47]. Follow-
ing are the programs which we include as our case studies.

(a) Matrix multiplication : Matrix multiplication is commonly used
in AES encryption. The inputs to this program are encrypted
with Elgamal encryption scheme. The number of hypercalls is
proportional to the matrix size. We evaluate on a 5×5 matrix
which makes 25 hypercalls.

Figure 7: Pseudocode of AUTOCRYPT-ed custom programs (i)
Hamming Distance (ii) Euclidean Distance (iii) Matrix Multi-
plication

(b) Square of Euclidean distance: We evaluate a program for com-
putation of square of Euclidean distance which is used in face
recognition applications [47]. The hypercalls are directly pro-
portional to the number of points used for calculating the Eu-
clidean distance. We calculate the distance for 10 points that
require a total of 20 hypercalls.

(c) Hamming distance : We calculate the hamming distance be-
tween an encrypted and a plaintext input. No hypercalls are
required for this computation.

We transform these program using AUTOCRYPT and report the ex-
ecution time in Table 4. The transformed pseudocode for these
programs are shown in Figure 7.

# where plaintext at p[i] and q[i] #can be either 1 or 0 pai8:p[n];int :q[n];pai8:dist;for(i = 0; i < n; i++) {  tmp1 = xorpal1(p[i],q[i]); dist=addpal8(dist,tmp1); }pai8:p[n],q[n];pai8:dist; for(i = 0; i < n;i++)  {   tmp1 = subpal8(p[i],q[i]);   tmp2:egml =convert(tmp1:pai8);   tmp3 = mulegml(tmp2,tmp2);   tmp4:pai8 = convert(tmp3:egml);   dist =addpal8(dist,tmp4);   }(i)(ii)egml:first[m][p],sec[p][q];pai8:ans[m][q];  for ( c = 0 ; c < m ; c++ )    {      for ( d = 0 ; d < q ; d++ ) {        for ( k = 0 ; k < p ; k++) {         tmp1 = mulegml(first[c][k],sec[k][d]);         tmp2:pai8 = convert(tmp1:egml);         ans[c][d] = addpal8(ans[c][d],tmp2) ;        }  }  }(iii)1306Custom
Program
Matrix
Multiplication
Euclidean
distance
Hamming
distance

Encrypted
variable (%)

Changed
Instruction (%)

Time (sec)

Infr.

Trans.

12/129 (9.30)

75/154 (48.70)

15/98 (15.3)

50/138 (36.23)

17/108 (15.7)

20/124 (16.12)

0.27

0.22

0.17

0.05

0.11

0.04

Exec
(sec)

0.088

0.074

0.042

Table 4: Performance of custom programs. Last column re-
ports the execution time in seconds.
Handling FHE cases. Out of the 25 COREUTILS and 3 custom
programs which we transform using AUTOCRYPT, 5 applications
make hypercalls to switch between different homomorphic encryp-
tion schemes. If not for our design, these applications require the
capabilities of fully homomorphic encryption scheme to operate on
encrypted data. Matrix Multiplication, Euclidean Distance, sum,
cksum and base64 bold faced in Table 2 and Table 4 respec-
tively, contain operations which require switching between encryp-
tion schemes. Using our trusted hypervisor architecture and the
hypervisor APIs, AUTOCRYPT can transform these applications to
execute with a performance acceptable for practical usage. The ex-
ecution time for applications increases linearly with the number of
hypercalls. The number of hypercalls can be reduced if conver-
sion between encryption schemes is performed in groups instead
of per character. Hence, we annotate cksum and base64 such
that multiple hypercalls for conversion between encryption types
are combined into one hypercall. However, the performance is still
better as compared to requesting the client for conversion between
encryption schemes. A single hypercall takes around 2 ms in our
implementation —which is 3 times faster as compared to sending
bytes to the client.
Untransformed applications. We discuss 5 applications from the
COREUTILS which either do not type-check according to our sys-
tem or require homomorphic operations that leaks a lot of informa-
tion about the sensitive data. Hence, these are beyond our security
design.

• The cat command ( when executed with ‘show-nonprinting’
option) and od command requires a conversion from Paillier
to search encryption. According to our type-system, such
conversion leaks information (see Section 3), thus is unsafe.
Note that, AUTOCRYPT can still transform these commands,
however allowing such transformations will reduce the secu-
rity of our system.

• The sort command requires the input ﬁle encrypted under
order preserving scheme (OPE) as it performs relational op-
erations (< , >) on the sensitive inputs. OPE is a weak encryp-
tion schemes as it reveals the order of encrypted data [50].
Combining OPE with search encryption scheme leaks con-
siderable amount of information which lowers the security
guarantees of AUTOCRYPT.

• comm and uniq does an equality check operation on two
characters, both from the input ﬁle. To support this function-
ality we require the input ﬁles encrypted under deterministic
encryption scheme. However, this scheme is not semanti-
cally secure and keeping a copy of this ﬁle downgrades se-
curity.

We point that for a setting where compromising semantic secu-
rity of sensitive ﬁles is tolerable, AUTOCRYPT can transform the
above applications to run on sensitive inputs encrypted in expected
partially homomorphic encryption scheme.

5.2 Reduction in Developer Effort

We claim that AUTOCRYPT reduces the amount of developer ef-
fort required for transforming applications to operate on encrypted
data. We demonstrate the reduction in developer effort by reporting
the following evaluation

• fraction of the encrypted constants and variables
• fraction of the LOC modiﬁed
• the compilation time of the transformed applications using

AUTOCRYPT

Table 2 summaries the analysis and execution results for 25 Unix
ﬁle processing applications. For all our case studies, the number of
SSA variables range from 300 to 3000, and only 9-10% of them
are eventually encrypted. From the pool of instructions generated
in the LLVM IR only 1% of the them are changed during the trans-
form pass. The number of constants encrypted is around 7-8% of
the total constants. These ﬁgures show that only a small amount of
variables, constants and instructions are modiﬁed during the trans-
formation. However, manually analysing a particular application
and identifying exactly which sensitive variables need encryption
is a non-trivial task for developers. AUTOCRYPT relieves the de-
veloper from this task and infers all the above details within rea-
sonable time limit. Compilation measurements comprise of time
spent for LLVM analysis, inference and transformation passes to
AUTOCRYPT given application. The average time for transforma-
tion to AUTOCRYPT-ed code ranges from 40 ms to 720 ms.
5.3 Runtime Performance

We perform the evaluation on Ubuntu 12.04 as guest VM with
Xen hypervisor on a 8 GB RAM machine. Table 2 reports the ex-
ecution time of AUTOCRYPT-ed programs for input ﬁles of 1, 10,
100 KB sizes. Out of 25 applications, 19 execute within 1 sec-
ond for all the input ﬁles. Remaining 6 applications take more
than 1 second. The execution time for each command is directly
proportional to the input ﬁle size. However, this also applies to
programs that are executed in the unencrypted domain. Our re-
sults show that operating over encrypted data using AUTOCRYPT
transformed code incurs some runtime overhead over native execu-
tion which is a few milliseconds. However, native untransformed
applications do not provide any security of input data. Therefore,
we compare performance of AUTOCRYPT-ed programs to already
known techniques of ‘download-and-compute’ and fully homomor-
phic encryption scheme.
Comparison to Download-and-compute. We compare whether
AUTOCRYPT-ed programs are faster to execute than the ‘download-
and-compute’ mechanism. We measure the download and upload
time for GitHub and DropBox ﬁle systems, for ﬁles of sizes 1,
10 and 100 KB (averaged over 10 runs of each size). The ob-
served network latency is 4.88 ms/KB and 6.0 ms/KB for Drop-
box and GitHub servers respectively as measured from our campus
network. For OpenSSL AES scheme, the encryption-decryption
cycle takes 8 ms and 10 ms respectively for 100 KB ﬁle on a ma-
chine of 8 GB RAM and i7 core processor. Considering this as a
baseline for the ‘download-and-compute’ mechanism, we compare
the performance of AUTOCRYPT-ed programs. The last column
in Table 2 shows the ratio of execution time of AUTOCRYPT-ed
program on 100 KB ﬁle and execution time of ‘download-and-
compute’ mechanism. Out of 25 applications, 19 execute faster
and only 6 applications slow down by factor of 2 to 6 as compared
to ‘download-and-compute’ mechanism. Overall, AUTOCRYPT re-
sults are promising, and it is practical to execute legacy applications
on server with comparable performance to downloading encrypted
ﬁles on client device for computation. We speculate that with faster

1307cryptographic implementation and optimization, in the future we
can achieve better execution performance using AUTOCRYPT. Our
results serve as a baseline for comparison of future work in this
direction.
Comparison to FHE. Certainly, AUTOCRYPT-ed code is practi-
cally faster as opposed to impractical implementations of current
fully homomorphic encryption schemes. Publically available im-
plementations of FHE take several minutes to compute simple in-
teger operations, whereas AUTOCRYPT completes execution over
complete ﬁle in this time [5]. We do not compare the time for exe-
cuting these applications using FHE as no standard tool is available
that runs existing C applications on FHE encrypted ﬁles. Our eval-
uation shows that combining partially homomorphic encryptions
schemes to operate on encrypted data is a promising direction until
performance of fully-homomorphic computation become reason-
able for practical purposes.
6. RELATED WORK
Application of Partially Homomorphic Cryptosystems. Partially
homomorphic encryption schemes are a promising direction for
performing computations on encrypted data. SCiFI [47] and Sadeghi
et al. [54] provide secure techniques for face recognition using
homomorphic cryptosystems. Bianchi et al. [15] proposes com-
puting discrete cosine transforms in encrypted domain and Kurib-
ayashi et al. [41] proposes a secure ﬁngerprinting protocol for im-
ages; both these techniques are based on the additive homomor-
phic property of encryption schemes. These work mainly use the
homomorphic property of a particular encryption scheme to sup-
port secure evaluation of a target application. In AUTOCRYPT, we
combine the homomorphic properties supported by various encryp-
tion schemes and investigate its use on a broad scale of applica-
tions. CryptDB [51] supports privacy preserving computation on
encrypted database by combining various partially homomorphic
encryption schemes. In our work, we automatically transform ap-
plications to use multiple homomorphic schemes, thereby automat-
ing the insight provide by Popa et al. work [55].
Secure Multi-Party Computations. A different approach for pri-
vacy preserving computation on encrypted data is to use garbled
circuits, which were ﬁrst proposed in the context of secure func-
tion evaluation for two-party protocols [63]. Tools such as Fair-
play [43], FairplayMP [14], VIFF [22] support secure multi-party
computations using garbled circuits. TASTY [36] combines gar-
bled circuit and homomorphic encryption schemes to enable pri-
vacy preserving two-party computations. A recent work by Holzer
et al. achieves secure two-party computation for ANSI C [37].
The size of the garbled circuit (which increases for large functions)
dominates the performance in these multi-party computation set-
ting. Most of the above solutions (except [37]) require the users to
specify the secure function in a special-purpose high level language
whereas AUTOCRYPT directly supports a simple C language.
Type System for computation on encrypted data. Fournet et
al. [28] proposes a information ﬂow type system for homomorphic
encryptions. The type system of AUTOCRYPT is somewhat similar
to [28], with additional support for conversion from one encryption
scheme to other. We also discuss the security guarantees provided
by our type-system. Mitchell et al. proposes a Haskell based lan-
guage for secure cloud computing in muti-party computation and
fully-homomorphic encryption platforms [46]. Fletcher et al. pro-
poses a compiler for converting complex program to work on in-
puts encrypted with fully homomorphic encryption schemes [26].
In AUTOCRYPT however, we focus on partially homomorphic en-
cryptions for secure computation on encrypted data.

Computation using Fully-Homomorphic Encryption. Another
solution for privacy preserving computation on encrypted data is to
use fully-homomorphic encryption. It allows securely computing
arbitrary functions on encrypted data, with the ﬁrst such feasible
scheme proposed by Gentry [30]. The performance of such sche-
mes is too slow for practical purposes [31]; though techniques to
make it practical are of considerable interest and are being investi-
gated [19, 56].
7. CONCLUSION

In this paper we show the effectiveness and applicability of a new
tool AUTOCRYPT in enabling homomorphic computation in exist-
ing C applications. Together with a trusted hypervisor, AUTOCRYPT-
ed programs offer second line of defenses against server-side data
attacks.
8. ACKNOWLEDGEMENT

We thank the anonymous reviewers for their insightful comments
and suggestions. We thank Zhenkai Liang, Ee-Chien Chang for
their comments on an early presentation of this work and Asankhaya
Sharma for his valuable suggestions about our type system. This
work is supported by the Ministry of Education, Singapore under
Grant No. R-252-000-495-133. Any opinions, ﬁndings, and con-
clusions or recommendations expressed in this paper are those of
the authors and do not necessarily reﬂect the views of the Ministry
of Education, Singapore.
9. REFERENCES
[1] Datalog Educational System.

http://des.sourceforge.net.

[2] GNU CoreUtils.

http://www.gnu.org/software/coreutils/.

[3] GNU Libgcrypt.

www.gnu.org/software/libgcrypt.

[4] Personal Data Protection Act 2012. www.mci.gov.sg.
[5] Scarab Library.

https://hcrypt.com//scarab-library.

[6] Vaultize. www.vaultize.com.
[7] Mcafee host intrusion prevention for server.

www.mcafee.com, 2012.

[8] Standards for the protection of personal information of

residents of the commonwealth. www.mass.gov/ocabr/
docs/idtheft/201cmr1700reg.pdf, 2012.

[9] Summary of the HIPAA Privacy Rule. www.hhs.gov,

2012.

[10] What’s holding back the cloud? www.intel.com, 2012.
[11] S. Abiteboul, R. Hull, and V. Vianu. Foundations of

Databases. Addison-Wesley, 1995.

[12] D. Akhawe, F. Li, W. He, P. Saxena, and D. Song.

Data-Conﬁned HTML5 Applications. In Technical Report,
2013.

[13] A. Barth, J. Caballero, and D. Song. Secure Content Snifﬁng

for Web Browsers, or How to Stop Papers from Reviewing
Themselves. In Security and Privacy, 2009.

[14] A. Ben-david, N. Nisan, and B. Pinkas. FairplayMP: A

System for Secure Multi-party Computation. In ACM CCS,
October 2008.

[15] T. Bianchi, A. Piva, and M. Barni. Encrypted Domain DCT
Based on Homomorphic Cryptosystems. In EURASIP, 2009.
[16] D. Boneh, G. D. Crescenzo, R. Ostrovsky, and G. Persiano.

Public Key Encryption with Keyword Search. In
EUROCRYPT, 2004.

1308[17] D. Boneh, G. Segev, and B. Waters. Targeted Malleability:

Homomorphic Encryption for Restricted Computations.
2012.

[18] BoxCryptor. https://www.boxcryptor.com/.
[19] Z. Brakerski, C. Gentry, and V. Vaikuntanathan. Fully
Homomorphic Encryption without Bootstrapping. In
Electronic Colloquium on Computational Complexity, 2011.

[20] D. Brumley and D. Boneh. Remote timing attacks are

practical. In USENIX Security Symposium 2003.

[21] CloudFogger. http://www.cloudfogger.com/en/.
[22] I. Damgård, M. Geisler, M. Krøigaard, and J. B. Nielsen.

Asynchronous Multiparty Computation: Theory and
Implementation. In Public Key Cryptography(PKC), 2009.

[23] D. E. Denning. A Lattice Model of Secure Information Flow.

Commun. ACM, 1976.

[24] T. ElGamal. A Public-Key Cryptosystem and a Signature
Scheme Based on Discrete Logarithms. In CRYPTO’84.

[25] M. Fischetti. Data Theft: Hackers Attack.

http://www.scientificamerican.com, 2011.

[26] C. Fletcher, M. van Dijk, and S. Devadas. Compilation

Techniques for Efﬁcient Encrypted Computation. In
Cryptology ePrint Archive, Report 2012/266.

[27] J. S. Foster, T. Terauchi, and A. Aiken. Flow-sensitive Type

Qualiﬁers. In ACM SIGPLAN, PLDI ’02.

[28] C. Fournet, J. Planul, and T. Rezk. Information-ﬂow Types

for Homomorphic Encryptions. In CCS ’11.

[29] R. Gennaro, C. Gentry, and B. Parno. Non-interactive

veriﬁable computing: Outsourcing computation to untrusted
workers. In CRYPTO, 2010.

[30] C. Gentry. Fully Homomorphic Encryption Using Ideal
Lattices. In 41st Annual ACM Symposium on Theory of
Computing, 2009.

[31] C. Gentry and S. Halevi. A Working Implementation of Fully
[32] C. Gentry and S. Halevi. Implementing gentry(cid:48)s

Homomorphic Encryption. In EUROCRYPT, 2010.

fully-homomorphic encryption scheme. In EUROCRYPT,
2011.

[33] GitHub. https://github.com.
[34] Goosh. http://goosh.org, 2008.
[35] B. Hardekopf and C. Lin. Flow-sensitive Pointer Analysis for

Millions of Lines of Code. In CGO ’11.

[36] W. Henecka, S. Kogl, A.-R. Sadeghi, T. Schneider, and

I. Wehrenberg. TASTY: Tool for Automating Secure
Two-partY computations. In ACM CCS, 2010.

[37] A. Holzer, M. Franz, S. Katzenbeisser, and H. Veith. Secure

two-party computations in ANSI C. In CCS ’12.

[38] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster Secure
Two-Party Computation Using Garbled Circuits. In Usenix
Security Symposium, 2011.

[39] T. Kim and N. Zeldovich. Making Linux Protection

Mechanisms Egalitarian with UserFS. In Usenix Security
Symposium, 2010.

[40] B. Kopf and M. Durmuth. A Provably Secure And Efﬁcient
Countermeasure Against Timing Attacks. In IEEE Computer
Security Foundations Symposium, 2009.

[41] M. Kuribayashi and H. Tanaka. Fingerprinting Protocol for
Images Based on Additive Homomorphic Property. In IEEE
Transactions on Image Processing, 2005.

[42] LLVM. http://llvm.org.

[43] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay - A

Secure Two-Party Computation System. In USENIX Security
Symposium, 2004.

[44] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor,

and A. Perrig. TrustVisor: Efﬁcient TCB Reduction and
Attestation. In IEEE Security and Privacy, 2010.

[45] J. M. McCune, B. Parnoy, A. Perrig, M. K. Reiter, and

H. Isozaki. Flicker: An Execution Infrastructure for TCB
Minimization. In EuroSys, 2008.

[46] J. Mitchell, R. Sharma, D. Stefan, and J. Zimmerman.

Information-ﬂow Control for Programming on Encrypted
data. In IEEE Computer Security Foundations
Symposium(CSF), 2012.

[47] M. Osadchy, B. Pinkas, A. Jarrous, and B. Moskovich. SCiFI

- A System for Secure Face Identiﬁcation. In Security and
Privacy 2010.

[48] P. Paillier. Public-key Cryptosystems Based on Composite

Degree Residuosity Classes. In EUROCRYPT, 1999.

[49] B. Parno, J. M. McCune, D. Wendlandt, D. G. Andersen, and
A. Perrig. CLAMP: Practical Prevention of Large-Scale Data
Leaks. In Security and Privacy, 2009.

[50] R. A. Popa, F. H. Li, and N. Zeldovich. An Ideal-Security

Protocol for Order-Preserving Encoding. In IEEE
Symposium on Security and Privacy, 2013.

[51] R. A. Popa, C. M. S. Redﬁeld, N. Zeldovich, and

H. Balakrishnan. CryptDB: Protecting Conﬁdentiality with
Encrypted Query Processing. In SOSP, 2011.

[52] K. P. N. Puttaswamy, C. Kruegel, and B. Y. Zhao. Silverline:

Toward Data Conﬁdentiality in Storage-intensive Sloud
Applications. SOCC ’11.

[53] A. Sabelfeld and A. Myers. Language-based
Information-ﬂow Security. Selected Areas in
Communications, IEEE Journal, 2003.

[54] A.-R. Sadeghi, T. Schneider, and I. Wehrenberg. Efﬁcient

Privacy-Preserving Face Recognition. In ICISC, 2009.

[55] M. Shah, E. Stark, R. A. Popa, and N. Zeldovich. Language
Support for Efﬁcient Computation over Encrypted Data. In
Off the Beaten Track Workshop, 2012.

[56] N. Smart and F. Vercauteren. Fully Homomorphic

Encryption with Relatively Small Key and Ciphertext Sizes.
Cryptology ePrint Archive, Report 2009/571, 2009.

[57] G. Smith. Principles of Secure Information Flow Analysis. In

Malware Detection. 2007.

[58] D. X. Song, D. Wagner, and A. Perrig. Practical Techniques
for Searches on Encrypted Data . In 21st IEEE Symposium
on Security and Privacy, Oakland, CA, 2000.

[59] E. Stefanov, E. Shi, and D. Song. Towards Practical

Oblivious RAM. CoRR, 2011.

[60] SVN. http://subversion.tigris.org.
[61] A. Vasudevan, S. Chaki, L. Jia, J. M. McCune, J. Newsome,
and A. Datta. Design, Implementation and Veriﬁcation of an
eXtensible and Modular Hypervisor Framework. In IEEE
Symposium on Security and Privacy, 2013.

[62] L. Wei and M. K. Reiter. Third-Party Private DFA Evaluation

on Encrypted Files in the Cloud. In Computer Security
ESORICS 2012.

[63] A. C. Yao. Protocols for Secure Computations. In 23rd
Annual IEEE Symposium on Foundations of Computer
Science, 1982.

[64] Y. Yu, J. Leiwo, and B. Premkumar. A Study on the Security

of Privacy Homomorphism. In ITNG 2006.

1309