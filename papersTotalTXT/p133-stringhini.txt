Shady Paths: Leveraging Surﬁng Crowds to Detect

Malicious Web Pages

Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna

University of California, Santa Barbara
{gianluca, chris, vigna}@cs.ucsb.edu

ABSTRACT
The web is one of the most popular vectors to spread mal-
ware. Attackers lure victims to visit compromised web pages
or entice them to click on malicious links. These victims are
redirected to sites that exploit their browsers or trick them
into installing malicious software using social engineering.

In this paper, we tackle the problem of detecting mali-
cious web pages from a novel angle. Instead of looking at
particular features of a (malicious) web page, we analyze
how a large and diverse set of web browsers reach these
pages. That is, we use the browsers of a collection of web
users to record their interactions with websites, as well as
the redirections they go through to reach their ﬁnal desti-
nations. We then aggregate the diﬀerent redirection chains
that lead to a speciﬁc web page and analyze the character-
istics of the resulting redirection graph. As we will show,
these characteristics can be used to detect malicious pages.
We argue that our approach is less prone to evasion than
previous systems, allows us to also detect scam pages that
rely on social engineering rather than only those that exploit
browser vulnerabilities, and can be implemented eﬃciently.
We developed a system, called SpiderWeb, which imple-
ments our proposed approach. We show that this system
works well in detecting web pages that deliver malware.

Categories and Subject Descriptors
K.6.5 [Security and Protection]: Invasive software; H.3.5
[Online Information Services]: Web-based services

General Terms
Security

Keywords
HTTP redirections, detection, malware

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516682.

1.

INTRODUCTION

The world-wide web is one of the main vectors used to
spread malware. The most common way of infecting victims
with malware is to present them with a web page that per-
forms a drive-by download attack [18]. In a drive-by down-
load attack, the malicious web page tries to exploit a vul-
nerability in the victim’s browser or in a browser plugin.
If successful, the injected code instructs the victim’s com-
puter to download and install malicious software. In other
cases, attackers rely on simple social engineering scams to
infect victims. That is, the web page tricks users into down-
loading and installing malicious software without exploiting
any client-side vulnerability; an example of this are fake an-
tivirus scams [23]. In this paper, we refer to the pages used
to deliver both types of attacks as malicious web pages.

Existing systems to identify malicious web pages fall into
two main categories. The ﬁrst category uses techniques to
statically analyze web pages and embedded code (such as
JavaScript or Flash), looking for features that are typical
of malicious activity. Such features can be patterns in the
Uniform Resource Locators (URLs) of web pages [14,31], the
presence of words or other information that are associated
with malicious content [16, 25, 26], or the presence of mali-
cious JavaScript snippets that are typical for exploits [2, 3].
The second category leverages dynamic techniques; these
approaches rely on visiting websites with an instrumented
browser (often referred to as a honeyclient), and monitor-
ing the activity of the machine for signs that are typical of
a successful exploitation (e.g., the creation of a new pro-
cess) [15, 20, 21, 28].

Although existing systems help in making users safer, they
suﬀer from a number of limitations. First, attackers can ob-
fuscate their pages to make detection harder and, in many
cases, they are able to successfully evade feature-based sys-
tems [8]. Second, attackers frequently hide their exploits by
leveraging a technique called cloaking [27, 30]. This tech-
nique works by ﬁngerprinting the victim’s web browser, and
revealing the malicious content only in case the victim is us-
ing a speciﬁc version of the browser and a vulnerable plugin.
Additionally, miscreants check the IP address of their visi-
tors, and display a benign page to those IP addresses that
belong to security companies or research institutions. Cloak-
ing makes the work of dynamic analysis approaches much
harder, because defenders need to run every combination of
web browsers and plugins to ensure complete coverage (or
use special techniques to work around this requirement [9]).
Also, defenders require elaborate routing infrastructures to
hide the source of their traﬃc. A third limitation is that

133many techniques, in particular honeyclients, can only de-
tect malicious pages that exploit vulnerabilities — they can-
not identify scams that target users with social engineering.
Fourth, most dynamic techniques introduce a considerable
amount of overhead into the instrumented browser, making
these approaches diﬃcult to deploy as online detectors.

In this paper, we propose a novel approach to detect mali-
cious web pages. To this end, we leverage a large population
of web surfers as diverse, distributed “sensors” that collect
their interactions with the web pages that they visit. The in-
teractions we are interested in are HTTP redirection chains
that are followed by clients before reaching web pages. Redi-
rections are widely used by attackers, because they make
detection harder, and they give the ﬂexibility of changing
any intermediate step in the chain, without having to up-
date all the entry points (i.e., the pages containing the links
that start the redirection process). Redirection chains are an
important part of the malware delivery infrastructure and,
unlike the web page contents, they are not easy to obfus-
cate. Of course, HTTP redirections have many legitimate
uses too. For example, advertising networks make extensive
use of redirections to make sure that a suitable ad is dis-
played to the right user. The key diﬃculty is distinguishing
between chains that correspond to malicious activity and
those that are legitimate.

A few previous systems, SURF and WarningBird [10,
13], have incorporated redirection chain information into
their detection approaches. To make the distinction between
malicious and benign redirects, however, these systems all
require additional information for their analysis. For ex-
ample, WarningBird [10] analyzes features of the Twitter
proﬁle that posted a malicious URL. Unfortunately, attack-
ers can easily modify the characteristics of those Twitter
proﬁles, and make their detection ineﬀective.

In our approach, we aggregate the redirection chains from
a collection of diﬀerent users, and we build redirection graphs,
where each redirection graph shows how a number of users
have reached a speciﬁc target web page. By analyzing both
the properties of the set of visitors of a page and its cor-
responding redirection graph, we can accurately distinguish
between legitimate and malicious pages. In particular, we
show that malicious web pages have redirection graphs with
very diﬀerent characteristics than the ones shown by legit-
imate ones. No information about the destination page is
required.
It is important to note that our approach can
only detect malicious web pages that make use of redirection
chains. However, this is not a severe limitation, because, as
previous work pointed out, the use of redirection chains is
pervasive in the malware delivery process [10, 13, 23, 29].

Our approach overcomes the limitations listed previously.
We do not look at the content of web pages at all, and
therefore, we are not aﬀected by attempts to obfuscate the
elements on a page or the scripts that are executed. More-
over, we do not check for exploits, so the system can cover
a broader class of malicious pages. Also, the eﬀect of cloak-
ing is mitigated, because of the diverse population of web
surfers involved in the data collection. As a last aspect, the
data collection from the user browsers is lightweight, because
data is collected as users browse the web, without any ad-
ditional computation. Therefore, the performance penalty
experienced by the users is negligible.

We implemented our approach in a tool called Spider-
Web. We ran our system on a dataset representative of the

browsing history of a large population of users, and we show
that SpiderWeb is able to detect malicious web pages that
evade state-of-the-art systems.

In summary, this paper makes the following contributions:
• We propose a new way of detecting malicious web
pages by collecting HTTP redirection data from a large
and diverse collection of web users. The individual
redirection chains are combined into redirection graphs
that allow for the distinction between legitimate and
malicious pages.

• We developed a system, called SpiderWeb, which is
able to detect malicious web pages by looking at their
redirection graphs, and we show that the system works
well in practice, by running it on a dataset collected
from the users of a popular anti-virus tool.

• We show that SpiderWeb is a useful tool to improve
the detection provided by state-of-the-art systems, and
that a redirection-graph based detection is hard to
evade by attackers.

2. HTTP REDIRECTIONS

HTTP redirections are used by web developers to redi-
rect the user to a diﬀerent URL than the one originally ac-
cessed. Typically, this happens by sending a speciﬁc HTTP
response to the user’s browser, followed by the new page
that the client should access. The URL of this new page
is sent in the location header ﬁeld of the HTTP response.
When the browser receives a redirection response, it auto-
matically redirects the user to the target page. Modern
browsers transparently redirect their users when they re-
ceive a 301, 302, 303, 304, or 307 HTTP response [4]. Al-
though each code has a diﬀerent meaning, browsers behave
in the same way upon receiving any of them, so we do not
treat them diﬀerently either. Other types of redirections in-
clude HTML-based redirections (triggered by the META tag in
a web page), JavaScript-based redirections, or Flash-based
redirections. In our analysis, we do not diﬀerentiate between
these classes of redirections.
2.1 HTTP Redirection Graphs

In this section, we describe how we build redirection graphs.
We start with introducing HTTP redirection chains, as they
represent the building blocks of redirection graphs.
Formalizing HTTP redirection chains. To deﬁne HTTP
redirection chains, we start by deﬁning two types of entities:
users and web pages. A user is represented by a tuple

U =< I, O, B, C >,

where I is the IP address of the user, O is a string that
identiﬁes her operating system, B is a string that identiﬁes
her browser’s conﬁguration (the browser type, version, and
the diﬀerent plugins that are installed), and C is the country
corresponding to I. A web page is represented by a tuple

W =< U RL, D, L, T LD, P g, P a, I, C >,

where U RL is the URL to the web page, D is the domain of
the URL (including the Top-Level domain), L is the length
of the domain name (in characters), T LD is the Top-Level
domain of the URL (notice that we take care of special cases
such as .co.uk), P g is the name of the page in the URL

134(more precisely, the sub-string of the URL that goes from
the last “/” character to either the “?” character or the end
of the URL, whichever comes ﬁrst), P a is a set of strings
that holds the names of the parameters in the URL, I is the
IP address that hosts the web page, and C is the country
in which the web page is hosted. For example, consider the
URL http://evil.com/a/search.php?q=foo&id=bar. For
this page, the full URL is U , D is evil.com, L is 4, T LD
is .com, P g is search.php, P a is (q,id), and the IP ad-
dress returned by the DNS server for evil.com is I. C is
calculated by performing geolocation on I.
Given our notion of users and web pages, we deﬁne a redi-
rection chain as a tuple

RC =< Urc, G, Ref, Lan, Fin >,

where Urc is the user visiting the redirection chain and G is
a graph < V, E > where V is the set of web pages that are
accessed in the redirection chain and E is a set of edges that
speciﬁes the order in which the web pages in V are accessed.
Each edge is a tuple < v1, v2 > containing the starting web
page instance v1 and the destination web page instance v2.
Ref, Lan, and Fin, are three “special” web pages in the
redirection chain:

• Ref represents the referrer, which is the URL the
user was coming from when she entered the redirec-
tion chain. The referrer could be the URL of the web
page that contains the link that the user clicked on. Al-
ternatively, it could be the URL of the web page that
hosts an iframe. If the user inserted the URL manu-
ally into the browser address bar, the referrer will be
empty. In this paper, we consider the referrer to be
the ﬁrst node of a redirection chain.
• Lan is the landing page, which is the web page on
• Fin is the ﬁnal page, which is the last web page in the
redirection chain. The ﬁnal page is the web page in G
that has no outgoing edges, except for self-loops.

which the ﬁrst redirection happens.

As we will see later, referrer, landing, and ﬁnal page carry
important information about the redirection chain that is
useful to assess the maliciousness of a web page.
Building a redirection graph. As mentioned previously,
we want to combine the redirection chains directed to the
same destination into a redirection graph. A redirection
graph is deﬁned as:

RedGraph =< R, Crg, Urg, Grg, Refrg, Lanrg, Finrg >,

where R is the target node where all the chains in the graph
end.
In the basic case, R will be a single web page with
a speciﬁc URL. However, in other cases, it might be use-
ful to group together web pages that have diﬀerent URLs,
but share common characteristics. For example, in the case
of a malicious campaign that infects websites using always
the same web page name, the domain names of the infected
pages will be diﬀerent for diﬀerent URLs. However, other
parts of these URLs will be the same.

To support graphs that point to pages with diﬀerent URLs,
we allow groups in which R has certain ﬁelds that are marked
with a wildcard. We consider a web page W to match R if,
for each ﬁeld of R that is not a wildcard, W and R contain
the same value. In Section 3.2 we describe diﬀerent ways for
specifying R and, hence, for aggregating redirection chains
into a redirection graph.

In our deﬁnition of redirection graphs, Crg is a set that
contains all the individual redirection chains that make up
the graph RedGraph. Urg is a set that contains all users
in the redirection chains Crg. Grg =< Vrg, Erg > is a
graph composed of the union of all the redirection chains in
Crg. Refrg, Lanrg, and Finrg are sets that contain all the
referrers, the landing pages, and the ﬁnal pages, respectively,
of the redirection chains in Crg.
Given a set of redirection chains, and an instance of R, we
build the redirection graph RedGraph as follows:
Step 1: Initially, Urg, Grg, Rrg, Lanrg, and Finrg are
empty.
Step 2: We compare each redirection chain to R. For each
redirection chain, we compare its ﬁnal page Fin to R. If Fin
matches R, we will use the chain to build the redirection
graph. Otherwise, the redirection chain is discarded.
Step 3: For each redirection chain that matches R, we add
the user U to Urg, the referrer Ref to Refrg, the landing
page Lan to Lanrg, and the ﬁnal page Fin to Finrg.
Step 4: For each redirection chain that matches R, we
compare the graph G =< V, E > to the graph Grg =<
Vrg, Erg >. For each vertex v in V, if Vrg does not have
a vertex with the same exact values as v, we add v to Vrg.
For each edge e =< v1, v2 > in E, if Erg does not contain
an edge starting at v1 and ending at v2,we add the edge e
to Erg.
2.2 Legitimate Uses of HTTP Redirections

HTTP redirections have many legitimate uses. The most
straightforward one is to inform a visitor that a certain web-
site has moved. For example, if a user accesses a web page
under an old domain, she will be automatically redirected
to the new one. As another example, HTTP redirections
are used to perform logins on websites. If a user accesses
a page without being logged in, she is redirected to a lo-
gin page. After providing her credentials, the web page will
check them and, in case they are correct, redirect the user
back to the page she originally tried to access. Advertising
networks (ad networks) are another example for legitimate
uses of HTTP redirections. Typically, advertisements un-
dergo a series of redirections, to allow the advertiser to ﬁnd
the ad that is the right match for a user [24].

Since redirection chains are so pervasive, we cannot simply
ﬂag all of them as malicious. In certain ways, malicious and
benign redirection graphs look very similar. Fortunately,
there are some features that are characteristic of malicious
redirection graphs, and these are the ones that we can use
for detection. We describe them in detail in the next section.
2.3 Malicious Redirection Graphs

To build our system, we are interested in the character-
istics that distinguish malicious redirection graphs from the
ones generated by legitimate uses.
Uniform software conﬁguration. The exploits and/or
malicious code used by cyber-criminals target a speciﬁc (set
of) browser, plugin, or operating system versions. To avoid
giving away their exploit code, or triggering content-aware
detection systems when not needed, attackers typically use
cloaking, and serve the malicious JavaScript only when the
exploit has a chance of successfully compromising the user’s
machine. Cloaking can be performed by the malicious page
itself, by ﬁngerprinting the user’s browser on the client side.
Alternatively, it can be performed during an intermediate

135step of the redirection chain on the server side [29]. In the
latter case, the victim will be redirected to the exploit page
only in case her operating system and/or browser are vulner-
able to the exploits that the malicious web page is serving.
From the point of view of our system, cloaking performed
during the redirection process will lead to the situation where
only victims with a uniform software conﬁguration visit the
malicious web page. Users who do not run a browser that
matches a vulnerable software conﬁguration will be redi-
rected to a diﬀerent page, possibly on a diﬀerent domain.
Note that modern exploit kits target multiple browsers and
plugins versions. For this reason, in some cases, we do not
observe a single browser version accessing a malicious web
page, but a few of them. However, the diversity of browser
conﬁgurations visiting the attack page will still be lower than
the one visiting a popular legitimate web page.
Cross-domain redirections. Malicious redirection chains
typically span over multiple domains. This happens mostly
because it makes the malicious infrastructure resilient to
take-down eﬀorts.
It also makes it modular, in the sense
that a redirection step can be replaced without having to
modify all the web pages in the redirection chain. On the
other hand, benign redirection chains typically contain one
or more pages on the same domain. An example of this be-
havior is the login process on a website; a user who is not
authenticated is ﬁrst redirected to a login page, and, after
providing valid credentials, back to the original page.
Hubs to aggregate and distribute traﬃc. It is common
for victims who click on malicious links to be ﬁrst redirected
to an aggregating page, which forwards them to one of sev-
eral backend pages [28]. This behavior is similar to the one
seen with legitimate advertising networks, where the user
is ﬁrst redirected to a central distribution point. From this
point, the user will then be forwarded to one of the many
diﬀerent ads. Attackers use this type of infrastructure for
robustness. By having a hub, it is easy for them to redirect
their victims to a new, malicious web page in case the cur-
rent one is taken down. Since the aggregation point does not
serve the actual attack, it is more diﬃcult to shut it down.
Commodity exploit kits. The underground economy has
evolved to the point that exploit kits are sold to customers
like any other software, and even oﬀered as software as a ser-
vice [5]. An exploit kit is a software package that takes care
of exploiting the victims’ browsers and infecting their com-
puters with malware. After buying an exploit kit, a cyber-
criminal can customize it to suit his needs, and install it on
a number of servers. Typically, this customization includes
the selection of a speciﬁc template that is used to generate
one-time URLs on the ﬂy. Previous work showed that de-
tecting such templates is important, and can be leveraged
for malicious URL detection [31]. We assume that diﬀer-
ent groups of attackers might use the same URL-generation
templates for each server they control.
Geographically distributed victims. Cyber-criminals
often try to reach as many victims as possible, irrespective
of the country they live in. As a result, the victims of a
campaign will come from a diverse set of countries and re-
gions. On the other hand, many legitimate sites have a less
diverse user population, since a large fraction of their users
come from the country in which the website is located.

3. SYSTEM DESIGN

We leveraged the observations described in the previous
section to build a system, called SpiderWeb, which deter-
mines the maliciousness of a web page by looking at its redi-
rection graph. Our approach operates in three steps: First,
we need to obtain input data for SpiderWeb. To this end,
we collect redirection chains from a large set of diverse web
users. In the second step, SpiderWeb aggregates the redi-
rection chains leading to the same (or similar) page(s) into
redirection graphs. As a last step, SpiderWeb analyzes
each redirection graph, and decides whether it is malicious.
3.1 Collecting Input Data

SpiderWeb requires a set of redirection chains as input.
For this work, we obtained a dataset from a large anti-virus
(AV) vendor. This dataset contains redirection chain infor-
mation from a large number of their global users. The data
was generated by the users who installed a browser security
product, and voluntarily shared their data with the company
for research purposes. This data was collected according to
the company’s privacy policy. In particular, the data did not
contain any personal identiﬁable information: The source IP
of the clients was replaced with a unique identiﬁer and the
country of origin. Moreover, the parameter values in URLs
along the redirection chains were obfuscated. Thus, the data
contained only the domain, path and parameter name infor-
mation of the URLs, which is suﬃcient for our approach.
We will discuss the dataset in more detail in Section 4.

Note that SpiderWeb is not limited to this particular
dataset. Any collection of redirection data from a crowd of
diverse users would represent a suitable input.
3.2 Creating Redirection Graphs

Given a set of redirection chains, the second step is to
aggregate them into redirection graphs. To this end, the
system leverages the algorithm described in Section 2.1.

A key challenge is to determine which pages should be
considered “the same” by this algorithm. The most straight-
forward approach is to consider pages to be the same only
when their URLs (domain, path, parameter names) match
exactly. However, certain malware campaigns change their
URLs frequently to avoid detection. This can be done by
changing the domain or by varying the path and parame-
ter values. If SpiderWeb would only aggregate redirection
chains that lead to the same exact URL, it might miss cam-
paigns that obfuscate their URLs. To overcome this prob-
lem, we propose ﬁve diﬀerent ways to recognize variations of
destination pages, where all chains that lead to one of these
pages should be aggregated. In other words, there are ﬁve
diﬀerent ways to specify page similarity via R.
Domain + page name + parameters: This grouping is
the most speciﬁc one. Pages are considered the same only
when all parts of the URL (domain, path and name of the
page, and parameter names) match.
Top-level domain + page name: With this grouping,
two pages will be considered the same when they share the
same top-level domain and page name. Cyber-criminals fre-
quently register their domains in bulk, using less popular
and less vigilant domain registrars (e.g., .co.cc or .am) [7].
However, they use an automated setup for their exploit in-
frastructure, and hence, the page names remain unchanged.
Top-level domain + page name + parameters: This
grouping is similar to the previous one, but also takes into

136Domain+Page+Parameters:
TLD+Page:
TLD+Page+Parameters:
Domain length+TLD+Page+Param.:
IP:

evil.com,index.php,id
com,index.php
com,index.php,id
4,com,index.php,id
IP address for evil.com

Table 1: Diﬀerent ﬁelds used for grouping for the
URL http://evil.com/dir/index.php?id=victim.

account the name of the parameters in the URL. This group-
ing works well for campaigns that use speciﬁc URL parame-
ters. It is also useful to detect malicious campaigns in cases
where the previous grouping would be too general (according
to our popularity ﬁlter, described below).
Domain name length + Top Level Domain + page
name + parameters: For this grouping, we consider the
length of the domain name instead of the concrete name
itself. This grouping is useful to detect campaigns that cre-
ate domains based on a speciﬁc template, such as random
strings of a speciﬁc length.
IP address: This grouping leverages the observation that
even if attackers completely vary their URLs (and hence,
could bypass the previous groupings), they only use a small
set of servers to host their malicious web pages (typically, on
bulletproof hosting providers). In such cases, the IP address
grouping will allow SpiderWeb to aggregate all chains that
end at the same IP address.

To see an example of the diﬀerent parts of the URL that
are considered for each grouping, consider Table 1. In addi-
tion to groupings, SpiderWeb leverages two thresholds dur-
ing its operation. The ﬁrst threshold discards those group-
ings that are too general, while the second one discards redi-
rection graphs that have low complexity, and do not allow
an accurate decision.
Intuitively, certain ways of grouping
Popularity ﬁlter.
similar pages might be too generic and result in the combi-
nation of chains that do not belong together. For example,
grouping all chains that end in URLs that have .com as their
top-level domain and index.html as their page name would
not produce a meaningful redirection graph. The reason is
that most of the landing pages in Finrg will not be con-
trolled by the same entity, and, thus, will not share similar
properties. To exclude unwanted redirection graphs from
further analysis, we introduce a popularity metric. More
precisely, for each redirection graph, we look at its redi-
rection chains and extract all domains that belong to the
chains’ ﬁnal pages. If any domain has been accessed more
than a threshold tp times in the entire dataset, the graph
is discarded. The intuition is that one (or more) domain(s)
included in the graph are so popular that it is very unlikely
that this graph captures truly malicious activity.
In Sec-
tion 4.2, we describe how we determined a suitable value for
threshold tp for our dataset.
Complexity ﬁlter. On the other side of the spectrum (op-
posite of too generic graphs) are graphs that are too small.
That is, these graphs contain too few chains to extract mean-
ingful features. Typically, these graphs belong to legitimate
sites where one landing page redirects to one speciﬁc desti-
nation. Intuitively, this makes sense: A malicious website is
likely to be composed of redirections that start at many dif-
ferent web sites (e.g., infected web pages). For this reason,
SpiderWeb discards any redirection graph that contains

less than tc distinct redirection chains. Again, we discuss
our choice for the value of tc in Section 4.2.

3.3 Classiﬁcation Component

In the third step, SpiderWeb takes a redirection graph
as input and produces a verdict on whether the ﬁnal web
page(s) of this graph are malicious or not. This step repre-
sents the core of our detection technique. We developed a
set of 28 features that describe the characteristics of a redi-
rection graph. These features fall into ﬁve main categories:
client features, referrer features, landing page features, ﬁnal
page features, and redirection graph features. Their purpose
is to capture the typical characteristics of malicious redirec-
tion graphs as reﬂected in the discussion in Section 2.3.

An overview of our features is given in Table 2.

It can
be seen that most features (21 out of 28) have not been
used before. The reason is that many features rely on the
fact that we collect data from a distributed crowd of di-
verse users. Speciﬁcally, these include client features and
redirection graph features. In the following, we describe our
features in more detail. Then, we discuss how the features
are leveraged to build a classiﬁer.
Client features. These features analyze characteristics of
the user population Urg that followed the redirection chains
in the graph RedGraph. The Country Diversity feature is
computed by counting the number of diﬀerent countries for
the users in Urg and dividing this value by the size of Crg
(which is the number of redirection chains in RedGraph).
As discussed previously, many legitimate web pages are vis-
ited by users in a small number of countries. The Browser
Diversity and Operating Systems Diversity features reﬂect
the diversity in the software conﬁgurations of the clients that
access a certain web page. Similarly to the Country Diver-
sity feature, these two features are computed by taking the
number of distinct browsers and operating systems in Urg
and dividing it by the size of Crg. If all clients that visit a
page share a similar software conﬁguration, this is often the
result of proﬁling their browsers to deliver eﬀective exploits.
Referrer features. These features capture characteristics
of the referrers that lead users into redirection chains. Re-
ferrers provide information about the locations of the links
on which users click to reach the actual ﬁnal web page, or
information about the locations of iframes, in case iframes
are used to trigger redirections.

The Distinct Referrer URLs counts the number of diﬀer-
ent referrer URLs in Refrg, divided by the size of Crg. Ma-
licious redirection chains are typically accessed by a smaller
number of referrers than legitimate ones. For example, a ma-
licious campaign that spreads through social networks will
show only referrers from such sites (e.g., Twitter of Face-
book), while a legitimate news site will be pointed to by a
higher variety of web pages (e.g., blogs or other news sites).
The Referrer Country Ratio feature is computed similarly
to the Country Diversity described in the previous section.
This ratio characterizes how geographically distributed the
various starting points (referrers) that lead to a certain web
page are. Certain types of legitimate web pages (e.g., news
sites), are accessed mostly through links posted in speciﬁc
countries. On the other hand, malicious web pages are of-
ten linked by websites that reside in diﬀerent countries. The
Referrer Parameter Ratio feature is computed by taking the
number of distinct parameters P a in Refrg, divided by the
size of Crg. This feature provides information about the di-

137Feature Category

Client Features

Referrer Features

Landing Page Features

Feature Name
Country Diversity
Browser Diversity
Operating System Diversity
Distinct Referrer URLs
Referrer Country Ratio
Referrer Parameter Ratio
Referrer Has Parameters
Distinct Landing Page URLs
Landing Country Ratio
Landing Parameter Ratio
Landing Has Parameters
Distinct Final Page URLs
Final Parameter Ratio
Top-Level Domain
Page
Domain is an IP

Feature Domain Novel
Real
Real
Real
Integer
Real
Real
Real
Integer
Real
Real
Real
Integer
Real
String
String
Boolean
Integer
Redirection Graph Features Maximum Chain Length
Integer
Minimum Chain Length
Maximum Same Country of IP and Referrer
Boolean
Maximum Same Country Referrer and Landing Page Boolean
Boolean
Maximum Same Country Referrer and Final Page
Minimum Same Country of IP and Referrer
Boolean
Boolean
Minimum Same Country Referrer and Landing Page
Boolean
Minimum Same Country Referrer and Final Page
Boolean
Intra-domain Step
Boolean
Graph has Hub 30%
Boolean
Graph has Hub 80%
Self-loop on the Final Page
Boolean








[10]



[10]

[25]
[25]
[13]

Final Page Features

[10, 13]
[10, 13]












Table 2: Features used by SpiderWeb to detect malicious domains. It can be seen that most features used by
our system are novel. For those that have been used in the past, we included a reference to the works that
used such features.

versity of the pages that lead to the redirection chain. The
Referrer Has Parameters feature measures how many of the
web page entities in Refrg have a value for P a, divided by
the size of Crg. The last two features help in understanding
how a web page is accessed. For example, in the case of a
malicious web page that is promoted through Search Engine
Optimization (SEO), one expects to see a high number of
distinct search engine queries that lead to a malicious page.
This is not the case for legitimate pages, which will be found
with a limited number of search keywords.
Landing page features. Analyzing the landing pages of
a redirection graph provides interesting insights into the di-
versity of the URLs that are used as landing pages. The
four features in this category (Distinct Landing Page URLs,
Landing Country Ratio, Landing Parameter Ratio, and Land-
ing Has Parameters) are calculated in the same way as for
the referrer features, by dividing the distinct value of URLs,
countries, parameters, and the number of non-empty param-
eters in Lanrg by the size of Crg. Legitimate and malicious
landing pages diﬀer in a similar way to the referrer.
Final page features. Similar to the referrer and the land-
ing page analysis, examining the characteristics of the ﬁnal
pages helps us in distinguishing between legitimate and ma-
licious redirection graphs.

The Distinct Final Page URLs feature value is calculated
in the same way as the value for Distinct Referrer URLs.
Having a large number of distinct URLs for the ﬁnal page is
suspicious – it indicates that attackers are generating one-
time URLs. The Final Parameter Ratio is calculated in the
same way as for the referrer and the landing pages. Based on
our observations, benign redirection graphs exhibit a higher
variety of GET parameters than malicious ones. One rea-
son for this is that legitimate web pages often use single
pages that provide multiple services, and each diﬀerent ser-
vice is selected by a set of speciﬁc GET parameters. The

Top-Level Domain feature identiﬁes the set of top-level do-
main(s). Some top-level domains are more likely to host
malicious web pages than others, because of the cost of reg-
istering a new domain that contains such a top-level do-
main [12]. The Page feature represents the page names, if
any (e.g., index.html). As explained previously, many ex-
ploit kits use recognizable URL patterns. The Domain is an
IP feature indicates if, for any destination web page, the do-
main value is the same as the IP. Many malicious web pages
are accessed through their IP addresses directly, as previous
work noted [13].
Redirection graph features. These features characterize
the redirection graph as a whole. In Section 4.3, we show
that this category of features is critical for malicious web
page detection, because it allows us to ﬂag as malicious a
large number of malicious web pages that would look legiti-
mate otherwise.

The Maximum and Minimum Chain Length features cap-
ture the maximum and minimum number of redirection steps
observed for a single redirection chain in Crg. Previous
work showed that a long redirection chain can be a sign
of malicious activity [10,13]. We then introduce six Boolean
features that model the country distributions for important
nodes that are involved in the redirection process. The cal-
culation of these six features works as follows: For all redi-
rection chains in Crg, we examine pairs of important ele-
ments s1 and s2. The elements s1 and s2 can be either the
user and the referrer, the referrer and the landing page, or
the referrer and the ﬁnal page. For each pair s1 and s2, we
check whether the corresponding entities are located in the
same country. If this is true, we set the value V for this chain
to true, otherwise we set it to false. In the next step, for each
of the three pairs, we compute the logic AND as well as the
logic OR for the values V . We expect legitimate redirection
chains to have more geographic consistency across the dif-

138ferent steps of the chain (i.e., having multiple steps located
in the same country). On the other hand, malicious redirec-
tion chains, which are often made by compromised servers,
tend to have multiple steps located in diﬀerent countries.
A similar observation was made by Lu et al. [13]. Notice
that, for the features in this category, we only considered
the minimum and maximum values, and not the average.
The reason for this is that the average values turned out
not to be discriminative at all. We perform a more detailed
analysis of the features that we decided to use in Section 4.3.
The Intra-domain Step feature captures whether, along
any of the redirection chains in Crg, there is at least one
step where a page redirects to another page on the same
domain. If this holds, the feature is set to true, otherwise,
it is set to false. Legitimate redirection chains often contain
intra-domain steps, while malicious chains typically contain
domains that are all diﬀerent.

Two Graph has Hub features (30% and 80%) characterize
the shape of the redirection graph. More precisely, they
capture the fact that a hub is present in a redirection graph.
To locate a hub, we look for a page (other than any ﬁnal
page in Finrg) that is present in at least 30% (or 80%) of the
redirection chains, respectively. These features are based on
the assumption that malicious redirection graphs are much
more likely to contain hubs.

The Self-loop on Final Page is true when any of the redi-
rection chains in Crg has a self-loop for the ﬁnal page. A
self-loop is a redirection that forwards a user to the same
page from where she started. This behavior is often present
in benign redirection graphs, where users are redirected to
the same page but with diﬀerent parameters. On the other
hand, malicious redirection graphs typically send the victim
from a compromised (legitimate) page to a page that has
been prepared by the attacker. This is the page that serves
the actual exploit, and there is no self-loop present.
Building and using a classiﬁer. We use the features de-
scribed previously (and a labeled training set) to build a
classiﬁer. This classiﬁer takes a redirection graph as input.
If the graph does not contain at least tc distinct redirection
chains, we discard it as benign (because of the complexity
ﬁlter). If any of its domains has been visited by more than
tp distinct IP addresses, we also mark the graph as benign
(because of the popularity ﬁlter). Otherwise, we compute
values for our features and submit the resulting feature vec-
tor to a classiﬁer based on Support Vector Machines (SVM)
trained with Sequential Minimal Optimization (SMO) [17].
We used the implementation provided by the Weka machine-
learning tool to this end [6]1. When the SVM determines
that the redirection graph should be considered as malicious,
SpiderWeb marks all ﬁnal page(s) that belong to this graph
as malicious.

4. EVALUATION

In this section, we describe how we evaluated the ability
of SpiderWeb to detect malicious web pages. For our eval-
uation, we leveraged a dataset S that contains redirection
chains collected over a period of two months, from February
1, 2012 to March 31, 2012 from the customers of a browser
security tool developed by a large AV vendor.

1We deal with features of diﬀerent types as follows: we con-
vert strings to integers, by substituting each string with an
index, and we treat boolean values as 0 and 1.

The users that generated this traﬃc are representative of
the users of this security product: they are distributed across
the globe, and they use a variety of diﬀerent software con-
ﬁgurations. For each HTTP redirection chain, the company
logged a time stamp, the obfuscated IP address and coun-
try of origin of the client, the initial URL that is requested,
the referrer of this request, the ﬁnal destination URL, all the
steps along the chain, and the operating system and browser
of the user. In addition, some records are labeled as mali-
cious or benign, a verdict made by the AV tool running on
the client. This was done by applying heuristics to identify
malicious content in the ﬁnal pages. If the ﬁnal page trig-
gered a heuristics, the record is ﬂagged as malicious. On the
other hand, the AV vendor employs a whitelist of known,
good websites to ﬂag records as benign. If a page is neither
detected as bad nor good, that record remains unlabeled.

The entire dataset S was composed of 388,098 redirection
chains, which lead to 34,011 distinct URLs. To estimate the
total number of users in the dataset, we calculated the av-
erage number of distinct (obfuscated) IP addresses observed
during periods of one week (over all weeks in our dataset).
Although this number does not give us a precise number of
users, it gives us an idea of their magnitude. The average
number of distinct IP addresses per week is 13,780. The
users that generated the dataset were located in 145 coun-
tries, and therefore the produced dataset is representative
of the surﬁng behavior of diﬀerent people across the globe.

4.1 Building a Labeled Dataset

To train the classiﬁer needed by SpiderWeb to detect
malicious web pages, we need a labeled dataset of benign
and malicious redirection graphs. To this end, we look at
redirection graphs built based on the data collected during
the ﬁrst month by the AV vendor (February 2012). As a
preliminary ﬁlter, we set tc to 2, which means that we con-
sidered only redirection graphs that were composed of at
least two distinct redirection chains.

For labeling purposes, if the AV vendor ﬂagged the do-
main of Fin as malicious, we manually assessed the mali-
ciousness of the URL. For example, we considered domains
that did not exist anymore at the time of our experiment as
clearly malicious. Also, we checked the verdict given by the
AV vendor to all the redirection chains leading to the same
URL. If not all the verdicts agreed in considering the page
as malicious, we did not consider that redirection graph for
our ground truth. The detection techniques used by the AV
vendor are conservative. That is, when they ﬂag a page as
malicious, it is very likely that the page is indeed bad. The
opposite, however, is not true and, as we will show later,
they miss a non-trivial fraction of malicious pages. In total,
we picked 2,533 redirection chains ﬂagged as malicious by
the AV vendor, leading to 1,854 unique URLs.

We then selected, among the redirection chains in S whose
domain was ﬂagged explicitly as benign by the AV vendor,
those redirection chains relative to domains that we consider
reputable and legitimate. In particular, we picked both pop-
ular websites, such as Google and Facebook, as well as less
popular sites that appeared legitimate after careful man-
ual inspection (e.g., local news sites). In the end, we picked
2,466 redirection chains, redirecting to 510 legitimate URLs.
More precisely, the ﬁnal pages of the legitimate redirection
chains include all the top 10 Alexa domains [1], and 48 of
the top 100. In the remaining of the paper, we refer to the

139ground truth set, composed of the manually labeled mali-
cious and legitimate redirection chains, as Tr.

4.2 Selecting Thresholds

As discussed in Section 3, SpiderWeb relies on two thresh-
olds: a complexity threshold tc, to discard any redirection
graph that is not complex enough to guarantee an accurate
classiﬁcation, and a popularity threshold tp, to discard those
groupings that are too general. In this section, we discuss
how we selected the optimal value for these thresholds.
Calculation of the complexity threshold. We needed
to understand what is the “complexity” that allows for a reli-
able classiﬁcation for a redirection graph. With complexity,
we mean the number of distinct redirection chains in Crg.
Ideally, having graphs of a certain complexity would allow
SpiderWeb to detect all malicious redirection graphs with
no false positives.

We set up our experiment as follows. First, we built the
Domain + page + parameters groupings from Tr. Then, for
each threshold value i between 2 and 10, we removed any
redirection graph that had complexity lower than i. We call
the remaining set of groupings Gri. We then performed a
ten-fold cross validation on each of the Gri sets, by using
Support Vector Machines with SMO, and analyzed the per-
formance of the classiﬁer for each threshold value. As we in-
crease the threshold, the number of false positives decreases.
With a threshold of 6, the number of false positives ﬂagged
by SpiderWeb is zero. At this threshold, the number of
false negatives also reaches zero. This gives us conﬁdence
that, by being able to observe enough people surﬁng the
web, SpiderWeb could reliably detect any malicious redi-
rection graph.

Unfortunately, as the threshold value increases, the num-
ber of possible detections decreases. This happens because
the dataset S is limited, and the number of graphs that have
high complexity is low. For example, with a threshold tc of
6, Gr6 is composed by only 131 redirection graphs, of which
only 3 are malicious. Thus, to detect a reasonable number
of malicious web pages in our dataset, we have to use a lower
tc, and accept a certain rate of false positives. We decided
to set tc to 4. At this threshold, the number of redirection
graphs in Gr4 is 196, of which 25 are malicious. A 10-fold
cross-validation on Gr4 results in a 1.2% false positive rate,
and in a true positive rate of 83%.
Calculation of the popularity threshold. To derive a
suitable value for tp, we analyzed the Top-Level Domain +
page groupings calculated from Tr. We then ran a precision
versus recall analysis. The reason we did not use the same
grouping as for the evaluation of tc is that, as we said previ-
ously, tp aims at detecting those groupings that are too gen-
eral for our approach to perform an accurate detection. For
this reason, we used Top-Level Domain + page groupings,
which are the most general among the ones used by Spi-
derWeb. For each value of tp, we discarded any grouping
that had at least one domain that had been visited by more
than tp distinct IP addresses. For the remaining groupings,
we analyzed the URLs contained in it. If all the domains
that the URLs belonged to ever got marked as malicious
by the security company, we ﬂagged the grouping as a true
positive. Otherwise, we ﬂagged the grouping as too general
(i.e., a false positive). Note that, in this experiment, a single
domain ﬂagged as benign by the AV vendor is suﬃcient to
ﬂag the whole grouping as too general. Figure 1 shows the

Figure 1: Precision vs. Recall analysis of the popu-
larity threshold value.

outcome of the precision versus recall analysis. In the case
of our dataset, the optimal value for tp turned out to be 8.
Notice that this analysis is speciﬁc to the dataset S. In case
SpiderWeb would be run on a diﬀerent dataset, an addi-
tional analysis of tc should be performed, and the optimal
value of the threshold might be diﬀerent.
4.3 Analysis of the Classiﬁer

Given the labeled ground truth set Tr and suitable thresh-
old values for tc and tp, we wanted to understand how well
our classiﬁer works in ﬁnding malicious pages. We per-
formed this analysis for diﬀerent choices for R (which de-
termines how redirection chains are grouped into graphs).
More precisely, using the dataset Tr, we ﬁrst generated the
redirection graphs leading to the Top-Level Domain + Page,
the Top-Level Domain + Page + Parameters, the Length +
Top-Level Domain + Page + Parameters, and the Domain
+ Page + Parameters groupings, respectively2. We then
removed any redirection graph that exceeded the popularity
threshold tp, or that did not have at least complexity equal
to tc. Each set of redirection graphs (one set of graphs for
each choice of R) was used in a 10-fold cross validation ex-
periment. The results of these experiments are shown in
Table 3. As it can be seen, the false positive rate for the
diﬀerent groupings is generally low. On the other hand, the
number of false negatives could appear high. However, as we
discussed previously, being able to observe a higher number
of connections would allow SpiderWeb to use a higher value
for tc, and lower both false positives and false negatives. Ta-
ble 3 also shows how our system compares to two classiﬁers
based on previous work (SURF and WarningBird). We
describe these experiments in Section 4.5.

We then analyzed the expressiveness of our features. From
our experiments, the most eﬀective features that character-
ize a malicious redirection graph are, in order, the “Referrer
Country Ratio,” the “Graph has Hub 80%,” and the “Fi-
nal Page Domain is an IP” features. On the other hand,
the most expressive features that characterize benign redi-
rection graphs are the “Landing Page Country Ratio,” the
“Intra-domain Step,” and the “Top-Level Domain” feature.

2Note that we did not use the IP address grouping. The
reason is that when we obtained the dataset, it was already
a few weeks old. Unfortunately, many of the malicious do-
mains did no longer resolve. In those cases, it was impossible
for us to determine the IP addresses that corresponded to
malicious domains.

 0 0.2 0.4 0.6 0.8 1 0 5 10 15 20 25 30 35 40 45 50Threshold valuePrecision vs. Recall140System
TLD + Page
TLD + Page + Parameters
Length + TLD + Page + Parameters
Domain + Page + Parameters
No graph-speciﬁc features
No client-speciﬁc features
No client and graph-speciﬁc features
SURF-based classiﬁer
WarningBird-based classiﬁer

112
112
139
196
196
196
196
196
196

# of chains # of URLs False Positive rate False Negative rate F-Measure
0.881
0.88
0.857
0.863
0.43
0.844
0.113
0.319
0.492

16.1%
21.4%
20.4%
17%
67%
21%
84.78%
81%
62%

1,945
1,642
1,233
815
815
815
815
815
815

2.5%
0%
3.4%
1.2%
1.2%
1.2%
1.5%
0%
2.9%

Table 3: Summary of the classiﬁcation performance for diﬀerent groupings and systems.

Interestingly, features that would intuitively make sense
turned out not to be the most discriminating. For exam-
ple, it is commonly believed that a long redirection chain
is indicative of a malicious web page [10, 13]. As it turns
out, the redirection chain length is not among the most im-
portant features. In particular, having a short redirection
chain is the 8th most important characterizing feature for a
malicious web page, while having a long redirection chain is
the 9th most characterizing feature for a benign chain.

As an additional experiment, we also wanted to evaluate
how much the features that can only be collected by a crowd
of users, and not by a centralized collector, contribute to
the detection of malicious web pages. First, we disabled the
twelve graph-speciﬁc features in the classiﬁer, and we per-
formed another 10-fold cross validation using this feature
set. We used the Domain + Page + Parameters groupings
for this experiment. Surprisingly, the ten-fold cross vali-
dation returned the same false positive rate as the one for
the full classiﬁer (1.2%). However, the true positive rate
dropped to only 33%, compared to the 83% of the full clas-
siﬁer. Then, we ran the 10-fold cross validation with the
three client-speciﬁc features disabled. Again, we obtained
the same false positive rate than for the full classiﬁer, but
the true positive rate dropped to 79%. By disabling both the
graph-speciﬁc and the client-speciﬁc features, the true posi-
tive rate drops to 15.2%. This means that the features that
can only be collected by observing a crowd of users are im-
portant to achieve a successful classiﬁcation. Comparative
results with the full classiﬁer are shown in Table 3. These
results give us conﬁdence that SpiderWeb indeed improves
the state of the art of malicious web page detection, allowing
us to perform detection based on features that are speciﬁc of
the malicious web page ecosystem’s structure, rather than
on the web page content. Since the redirection-speciﬁc fea-
tures are harder to obfuscate than the content-speciﬁc ones,
we believe that our technique can help in performing a more
reliable malicious web page detection. To underline this,
we performed an experiment that shows that SpiderWeb
outperforms previous systems (assuming that attackers per-
fectly succeed in evading the context-speciﬁc features). We
discuss this experiment in Section 4.5.
4.4 Detection Results on Entire Dataset

In the next experiment, we evaluated SpiderWeb on the
redirection graphs built from the entire dataset S collected
by the security company. After checking for complexity and
popularity, SpiderWeb generated 3,549 redirection graphs
from this dataset, obtained with the Top-Level Domain +
page (700 graphs), the Top-Level Domain + page + parame-
ters (825 graphs), the Domain Length + Top-Level Domain
+ page + parameters (957 graphs), and the Domain + page
+ parameters (1,067 graphs) groupings.

Of the 3,549 redirection graphs built from S (using the
four groupings), 562 graphs were ﬂagged as malicious by
our detection algorithm. In total, these graphs led to 3,368
URLs. We manually identiﬁed seven large-scale campaigns,
composed of URLs that were sharing common traits.

To check how accurate the results produced by Spider-
Web are, we compared our detections with the ones per-
formed by the AV vendor on the same dataset. To this end,
we built a set Fina of analyzed URLs. For each redirection
graph in S, we added the ﬁnal URLs in Finrg to Fina. In to-
tal, the AV vendor ﬂagged 3,156 URLs in Fina as malicious.
For 2,590 URLs, SpiderWeb and the defenses deployed by
the AV vendor agreed. We then manually analyzed the re-
maining 556 URLs that the AV vendor detected, but Spi-
derWeb did not. 59 of them turned out to be legitimate web
sites that hosted malicious JavaScript, probably because of
a cross-site scripting (XSS) vulnerability. SpiderWeb was
not designed to detect this kind of web pages, whose redirec-
tion graphs, as it turns out, do not show the characteristics
that are typical of malicious redirection graphs. The redi-
rection graphs leading to the remaining 497 URLs had low
complexity (on average, they were accessed by ﬁve distinct
redirection chains). As we show in Section 4.2, SpiderWeb
needs to observe six or more distinct redirection chains to
form a graph that leads to no false positives or false nega-
tives. We are conﬁdent that, if more data were available to
us, SpiderWeb would have been able to detect also these
URLs as malicious.

On the other hand, SpiderWeb detected 778 URLs as
malicious that went undetected by the AV vendor. We man-
ually analyzed them, to assess false positives. The vast ma-
jority of URLs returned non-existing domain errors when we
tried to resolve them. Others showed clear patterns in their
URLs typical of exploit kits. For 51 (out of 778) URLs, we
could not conﬁrm the maliciousness of the page. We consider
all of them as false positives of SpiderWeb. This accounts
for 1.5% of the total.

Even if our system has false positives, we think that these
false positives are so low in number that it would be possi-
ble to whitelist such domains, and use SpiderWeb to detect
and blacklist previously-unknown malicious web pages. In
addition, SpiderWeb is able to perform more comprehen-
sive detections than existing techniques.
Interestingly, in
several cases, the software deployed by the AV vendor iden-
tiﬁed only a few of the malicious web pages that belong to a
certain campaign, because only those pages triggered their
signature-based detection. The detection of the other pages
was successfully evaded by the attackers. On the other hand,
once SpiderWeb detects a redirection graph as malicious,
it ﬂags each URL in Finrg as malicious. Because of the na-
ture of the redirection graphs, and their importance for the
attacker, evading detection by SpiderWeb is more diﬃcult.

1414.5 Comparison with Other Systems

To the best of our knowledge, SpiderWeb is the ﬁrst
system that is able to detect whether a web page is malicious
or not just by looking at the redirection chains that lead to
it, and at the characteristics of the clients that access it.

However, there are a few recent systems that do make use
of redirection information to detect malicious web pages.
Unlike SpiderWeb, these systems also leverage “context”
(domain-speciﬁc) information associated with the redirec-
tion chain itself, such as information about the page on
which links are posted. In this section, we show that pre-
vious systems depend on such contextual information, and
that their detection capability suﬀers signiﬁcantly if this in-
formation is not present. The ﬁrst problem with these ap-
proaches is that attackers can easily modify such context
information, for example by changing the way in which they
disseminate malicious links. A second problem is that the
context information leveraged by previous systems is only
available in speciﬁc situations, like in the case of a URL
posted on Twitter or of a SEO campaign. SpiderWeb, on
the other hand, can operate regardless of where the initial
URL has been posted. To show this, we compared how
SpiderWeb performs compared to two classiﬁers based on
SURF [13] and WarningBird [10].

WarningBird is a system that aims at detecting mali-
cious web pages, such as spam and malware pages, whose
links have been posted on Twitter.
It takes advantage of
redirection graphs, as well as information about the accounts
that posted the URLs on Twitter. SURF, on the other
hand, is a system that analyzes redirection chains to detect
malicious pages that use Search Engine Optimization (SEO)
to attract victims. To aid its detection, SURF looks at the
search words that attackers poisoned to make their malicious
pages appear as results on search engines. Although both
systems, to some extent, leverage redirection graphs (SURF
visits links twice to evaluate the consistency of a redirection,
and WarningBird has a notion of hubs), the analysis per-
formed by SpiderWeb is more comprehensive, and allows
one to make decisions just by looking at the graph. Both
SURF and WarningBird work very well in detecting ma-
licious web pages that use redirection chains, in the context
that they were designed to operate. For instance, SURF is
very eﬀective in detecting malicious webpages advertised by
SEO, while WarningBird is eﬀective in detecting malicious
URLs on Twitter. However, attackers can evade detection
by these systems by modifying the way in which they post
their links, or they can leverage diﬀerent methods to spread
their malicious content (other than Twitter and SEO). We
show that, in the presence of an attacker evading the con-
text information leveraged by previous systems, SpiderWeb
performs a better detection.

We developed two classiﬁers based on the redirection-
chain features of WarningBird [10] and SURF [13]. In the
case of SURF, we used the Total redirection hops, the Cross-
site redirection hops, the Landing to terminal distance, and
the IP-to-name ratio. In particular, we re-implemented the
Landing to terminal distance as follows: For each redirection
chain, we considered the country of the landing and the ter-
minal domain. If the countries resulted being the same, we
set this feature to 1. Otherwise, we set it to 0. Note that we
could not re-implement the Redirection consistency and the
Page to load/render errors features, since this information
was not available in S. In fairness, this could have impacted

the performance of our SURF-based classiﬁer in our exper-
iment, since the authors mention that these are among the
most discriminative features in their classiﬁer.

In the case of WarningBird, we used the Redirection
chain length, the Frequency of entry point URL, the Num-
ber of diﬀerent initial URLs, and the Number of diﬀerent
landing URL features. Note that, in WarningBird’s termi-
nology, an entry point is what we call a hub. Also, notice
that we did not use the Position of entry point URL fea-
ture. The reason is that WarningBird had a uniform set
of referrers (twitter.com pages), while we do not. For this
reason, it was impossible for us to calculate this feature.

We then applied a ten-fold cross validation using SMO
for the two classiﬁers, using Domain + Page + Parameter
groupings built from Tr as a training dataset. The results
are reported in Table 3. As it can be seen, SpiderWeb
has by far a better recall than both other classiﬁers, and a
comparable precision to the SURF-based classiﬁer, which is
the system that generated the least false positives. To be
fair, both SURF and WarningBird achieve better detec-
tion rates by leveraging contextual information, which our
system does not consider by design. Of course, our system
could include contextual information to enhance its detec-
tion capabilities, but this is out of the scope of this paper.
Interestingly, the SURF-based and WarningBird-based
classiﬁers detect redirection graphs as malicious that Spi-
derWeb misses, and vice versa. In particular, SpiderWeb
fails in detecting ﬁve redirection graphs in Tr4 as malicious.
However, the SURF-based classiﬁer can detect three of those
as malicious, and the WarningBird-based classiﬁer can de-
tect the other two. This means that, by using the three
systems together, one could reach a complete recall.

4.6 Possible Use Cases for SpiderWeb

We envision two possible deployments for our tool: as an
oﬄine detection system, and as an online protection system.
Oﬄine detection. SpiderWeb can be used oﬄine, to an-
alyze a dataset of historic redirection chains (similar to the
one we used for our evaluation). This allows the system to
identify a set of malicious URLs. The knowledge of these
URLs is useful in several scenarios. For example, it can help
to reveal blind spots in alternative detection tools.
Online prevention. The problem with the oﬄine approach
is that it introduces a possibly signiﬁcant delay between the
appearance of a malicious page and its detection. A bet-
ter way is to deploy SpiderWeb online, so that it receives a
real-time feed of redirection chains from users. Note that the
AV vendor already receives such a feed from its users; hence,
deployment would be relatively straightforward. Whenever
a new redirection chain is received, SpiderWeb adds it to
the current set of redirection graphs. Once a graph has
reached a suﬃcient complexity, the classiﬁer is executed.
When a page is detected as malicious, this information can
be immediately pushed out to the clients, blocking any sub-
sequent access to this page.

Of course, this approach has the limitation that users are
potentially exploited until the system observes enough dis-
tinct redirection chains to identify a malicious page. To
evaluate the extent of this problem, we set up the following
experiment: First, we took the 562 redirection graphs in our
dataset that SpiderWeb detected as malicious (as discussed
in Section 4.4). We then looked at each redirection chain in
S, in chronological order (based on the time stamp when

142the redirection chain was entered by the user). The goal
was to simulate an online deployment, checking how many
users would get compromised before SpiderWeb recognized
and blocked a malicious page. We proceeded as follows:
Step 1: We keep a list of occurrences O. Each element
in O is a tuple < Ri, Ci >, where Ri is a grouping that
identiﬁes a malicious redirection graph, and Ci is a set that
contains the distinct redirection chains that previously lead
to URLs in Ri. At the beginning, we have an entry in O for
each of the 562 malicious redirection graphs. The set Ci for
each of these graphs is empty. We also keep a value uc of
users who have possibly been compromised, and a value up
of users who have been protected by SpiderWeb. At the
beginning, both these values are set to zero.
Step 2: For each redirection graph G in S, we check its
ﬁnal page Fin against each grouping Ri in O. If G matches
Ri, we add the redirection chain C to Ci.
Step 3: If the size of Ci is lower than 6, it means that the
user visiting the page could have potentially been compro-
mised3. Therefore, we increase uc by one. Otherwise, we
consider the user as safe, because SpiderWeb would have
already blocked the page, and we increase up by one.

Running this simulation, we ﬁnd that the number of com-
promised users uc is 723, while the number of protected
users up is 10,191. This means that out of 10,914 visits of
malicious web pages, SpiderWeb would have successfully
blocked 93% of them. Note that this is a lower bound, be-
cause in many cases less than 6 distinct redirection chains are
enough to make a successful detection. Clearly, SpiderWeb
cannot provide perfect protection, but its coverage compares
favorably to existing blacklists [5]. Also, after identifying a
page as malicious, the system knows which users have been
potentially infected. These observations could be used to in-
form the host-based components (e.g., anti-virus scanners)
that are already running on those machines.
4.7 Limitations and Evasion

Although SpiderWeb is a useful tool for detecting mali-
cious web pages, it has some limitations. The ﬁrst limitation
is that SpiderWeb requires redirection graphs of a certain
complexity to perform an accurate classiﬁcation. We ac-
knowledge that this might be an issue in some cases. The
second limitation is that the groupings currently used by
SpiderWeb might miss some advanced ways of generating
URLs, such as creating a diﬀerent domain, as well as a dif-
ferent web page name, for each request. As a result, Spi-
derWeb might fail grouping such URLs together. Although
this is a problem, as we discussed in Section 3.2, we picked
such groupings because they were the only ones available to
us, given the dataset S. In a real scenario, other groupings,
such as the IP address at which a domain is hosted, could
be used. A grouping by IP addresses would be non-trivial to
evade. A third limitation is that, in principle, the attacker
might redirect its victim to a popular, legitimate page after
having infected her. By doing this, this particular redirec-
tion chain would be merged with the others going to the
popular site, and SpiderWeb would likely not detect the
threat. This is a potential concern, although we did not ob-
serve such practice in the wild. A solution to this problem
is that SpiderWeb could be modiﬁed to build redirection
graphs ending at pages other than the ﬁnal page.

3As shown in Section 4.2, with redirection graphs of com-
plexity 6 or higher, SpiderWeb reaches complete coverage.

Attackers could also evade detection by making their redi-
rection graphs look similar to the legitimate ones. However,
in case miscreants successfully evaded detection by our sys-
tem, this would make them easier to detect by previous
work. For example, attackers could stop using cloaking. By
doing this, their websites would look like regular web pages,
accessed by a diverse population of browsers and plugins.
However, this evasion would leak their malicious JavaScript
in all cases, making it easier for researchers to analyze and
block the malicious code. As another example, attackers
could stop using hubs. By doing this, they would need to
redirect their victims to multiple servers under their control
(or compromised servers). The eﬀort of setting up this type
of infrastructure raises the bar for attackers. As an alterna-
tive, miscreants could redirect their users to the ﬁnal page
directly. However, this would make their redirection chains
less complicated, and easier to be ﬂagged by previous work.

5. RELATED WORK

Detecting malicious web pages is an important problem,
and a wealth of research has been conducted on this topic.
Typically, proposed systems aim at detecting a particular
type of “malicious” page (e.g., spam or malware). Existing
approaches fall in three main categories: honeypots, intra-
page feature- and inter-page feature-based detection systems.
Honeypots. Systems based on honeypots typically visit
web pages with a virtual machine, and monitor the system
for changes that are typical of a compromise (e.g., a registry
change). HoneyC, capture-hpc, and Phoneyc are exam-
ples of such systems [15, 20, 21]. Wang et al. presented a
system that runs virtual machines with multiple combina-
tions of browsers and plugins [28]. Although this approach
has a higher chance of detecting malicious web pages than
the ones using a single browser version, it does not scale, as
the number of conﬁgurations is constantly increasing.
Intra-page features. The second category of systems looks
at features that are typical of malicious web pages in order to
detect them. Some systems leverage the observation that the
URLs used by certain cyber-criminals to point to malicious
web pages have recognizable patterns [14,31]. Other systems
analyze the actual web page content, looking for words that
are indicative of the content to be malicious (e.g., typical
of spam or SEO pages) [16, 25, 26]. Another approach is
to analyze the JavaScript code in the web page looking for
features that are typical of malicious code. This can be done
statically [3], or dynamically, by either visiting the page with
an emulated browser [2] or a real one [19].
In general, a
handful of commercial products leverage data collected in a
distributed fashion to detect malicious web pages. However,
such products look at the reputation of the pages, or at their
content. Systems based on intra-page features are prone
to evasion by obfuscation. For example, attackers might
obfuscate their malicious JavaScript, making it impossible
for an analyzer to detect it.
Inter-page features. The third category of systems looks
at features of the diﬀerent pages that are involved in the ma-
licious process, rather than just of the ﬁnal malicious page.
Zhang et al. developed a system to generate signatures that
identify URLs that deliver malware, by looking at the redi-
rection chains followed by honeypots as they are directed
to the malicious domains [32]. Stokes et al. proposed Web-
Cop, a system that, starting from known malicious domains,
traverses the web graph to ﬁnd malware landing pages [22].

143Similarly to SpiderWeb, other systems leverage HTTP
redirection chains to detect malicious domains. SURF is
designed to detect malicious SEO sites [13], while Warn-
ingBird detects malicious web pages posted on Twitter [10].
However, both systems use contextual information to make
their detection accurate. In particular, SURF looks at the
search engine results that attackers poison, while Warn-
ingBird looks at the characteristics of the social network
account that posted the link. While they make detection
easier, these features are relatively easy to evade by the
cyber-criminals. MadTracer [11] is a system that aims
at detecting malicious web advertisements by looking at the
redirection chains that the users follow. Unlike SpiderWeb,
this system uses contextual information about the web ad-
vertisement process. Since SpiderWeb does not use any
contextual information about the purpose of malicious web
pages, it is more generic, and it can detect multiple types
of malicious campaigns. To the best of our knowledge, we
are the ﬁrst ones to develop a system that is able to make a
decision about the maliciousness of a domain by looking at
HTTP redirections only.

6. CONCLUSIONS

We presented SpiderWeb, a system that is able to detect
malicious web pages by looking at the redirection chains
that lead to them. We showed that SpiderWeb can de-
tect malicious web pages in a reliable way. We believe that
SpiderWeb complements nicely previous work on detect-
ing malicious web pages, since it leverages features that are
harder to evade.

7. ACKNOWLEDGMENTS

This work was supported by the Oﬃce of Naval Research
(ONR) under grant N000140911042, the Army Research Of-
ﬁce (ARO) under grant W911NF0910553, the National Sci-
ence Foundation (NSF) under grants CNS-0845559 and CNS-
0905537, and Secure Business Austria. We would like to
thank TrendMicro for their support in the project, as well
as the anonymous reviewers for their insightful comments.

8. REFERENCES

[1] Alexa, the Web Information Company. http://www.alexa.com.
[2] M. Cova, C. Kruegel, and G. Vigna. Detection and Analysis of
Drive-by-Download Attacks and Malicious JavaScript code. In
International Conference on World Wide Web, 2010.

[3] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert. Zozzle:

Low-overhead mostly static javascript malware detection. In
USENIX Security Symposium, 2011.

[4] A. Doup`e, B. Boe, C. Kruegel, and G. Vigna. Fear the EAR:

discovering and mitigating execution after redirect
vulnerabilities. In ACM Conference on Computer and
Communications Security (CCS), 2011.

[5] Chris Grier, Lucas Ballard, Juan Caballero, Neha Chachra,

Christian J. Dietrich, Kirill Levchenko, Panayiotis
Mavrommatis, Damon McCoy, Antonio Nappa, Andreas
Pitsillidis, et al. Manufacturing compromise: The emergence of
exploit-as-a-service. In ACM Conference on Computer and
Communications Security (CCS), 2012.

[6] Hall, M. and Frank, E. and Holmes, G. and Pfahringer, B. and

Reutemann, P. and Witten, I.H. The WEKA Data Mining
Software: An Update. In SIGKDD Explorations, 2009.

[7] McAfee Inc. Mapping the Mal Web. Technical report, 2010.
[8] A. Kapravelos, Y. Shoshitaishvili, M. Cova, C. Kruegel, and

G. Vigna. Revolver: An Automated Approach to the Detection
of Evasive Web-based Malware. In USENIX Security
Symposium, 2013.

[9] C. Kolbitsch, B. Livshits, B. Zorn, and C. Seifert. Rozzle:

De-Cloaking Internet Malware. In IEEE Symposium on
Security and Privacy, 2012.

[10] S. Lee and J. Kim. WARNINGBIRD: Detecting Suspicious

URLs in Twitter Stream. In Symposium on Network and
Distributed System Security (NDSS), 2012.

[11] Z. Li, K. Zhang, Y. Xie, F. Yu, and X.F. Wang. Knowing Your

Enemy: Understanding and Detecting Malicious Web
Advertising. In ACM Conference on Computer and
Communications Security (CCS), 2012.

[12] H. Liu, K. Levchenko, M. F´elegyh´azi, C. Kreibich, G. Maier,
G.M. Voelker, and S. Savage. On the eﬀects of registrarlevel
intervention. In USENIX Workshop on Large-Scale Exploits
and Emergent Threats (LEET), 2011.

[13] L. Lu, R. Perdisci, and W. Lee. SURF: Detecting and
Measuring Search Poisoning. In ACM Conference on
Computer and Communications Security (CCS), 2011.
[14] J. Ma, L.K. Saul, S. Savage, and G.M. Voelker. Beyond
Blacklists: Learning to Detect Malicious Web Sites from
Suspicious URLs. In ACM SIGKDD international conference
on Knowledge discovery and data mining, 2009.

[15] J. Nazario. PhoneyC: a Virtual Client Honeypot. In USENIX

Workshop on Large-Scale Exploits and Emergent Threats
(LEET), 2009.

[16] A. Ntoulas, M. Najork, M. Manasse, and D. Fetterly. Detecting

Spam Web Pages Through Content Analysis. In International
Conference on World Wide Web, 2006.

[17] J. Platt et al. Sequential minimal optimization: A fast

algorithm for training support vector machines. Technical
report, 1998.

[18] N. Provos, P. Mavrommatis, M.A. Rajab, and F. Monrose. All

Your Iframes Point to Us. In USENIX Security Symposium,
2008.

[19] P. Ratanaworabhan, B. Livshits, and B. Zorn. Nozzle: A

defense against heap-spraying code injection attacks. In
USENIX Security Symposium, 2009.

[20] C. Seifert and R. Steenson. Capture-honeypot Client

(capture-hpc), 2006.

[21] C. Seifert, I. Welch, P. Komisarczuk, et al. Honeyc: the

Low-interaction Client Honeypot. Proceedings of the 2007
NZCSRCS, 2007.

[22] J.W. Stokes, R. Andersen, C. Seifert, and K. Chellapilla.

Webcop: Locating Neighborhoods of Malware on the Web. In
USENIX Workshop on Large-Scale Exploits and Emergent
Threats (LEET), 2010.

[23] B. Stone-Gross, R. Abman, R. Kemmerer, C. Kruegel,

D. Steigerwald, and G. Vigna. The Underground Economy of
Fake Antivirus Software. In Workshop on the Economics of
Information Security (WEIS), 2011.

[24] B. Stone-Gross, R. Stevens, A. Zarras, R. Kemmerer,

C. Kruegel, and G. Vigna. Understanding fraudulent activities
in online ad exchanges. In ACM SIGCOMM Conference on
Internet Measurement, 2011.

[25] K. Thomas, C. Grier, J. Ma, V. Paxson, and D. Song. Design

and Evaluation of a Real-time URL Spam Filtering Service. In
IEEE Symposium on Security and Privacy, 2011.

[26] T. Urvoy, E. Chauveau, P. Filoche, and T. Lavergne. Tracking
Web Spam with HTML Style Similarities. ACM Transactions
on the Web (TWEB), 2008.

[27] D.Y. Wang, S. Savage, and G.M. Voelker. Cloak and Dagger:

Dynamics of Web Search Cloaking. In ACM Conference on
Computer and Communications Security (CCS), 2011.

[28] Y.M. Wang, D. Beck, X. Jiang, R. Roussev, C. Verbowski,
S. Chen, and S. King. Automated Web Patrol with Strider
Honeymonkeys. In Symposium on Network and Distributed
System Security (NDSS), 2006.

[29] Y.M. Wang and M. Ma. Detecting Stealth Web Pages That Use

Click-Through Cloaking. Technical report, Microsoft Research
Technical Report, MSR-TR-2006-178, 2006.

[30] B. Wu and B.D. Davison. Detecting Semantic Cloaking on the
Web. In International Conference on World Wide Web, 2006.

[31] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and

I. Osipkov. Spamming Botnets: Signatures and Characteristics.
In ACM SIGCOMM Computer Communication Review, 2008.

[32] J. Zhang, C. Seifert, J.W. Stokes, and W. Lee. ARROW:
Generating Signatures to Detect Drive-By Downloads. In
International Conference on World Wide Web, 2011.

144