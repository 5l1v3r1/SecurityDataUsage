2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy

Revisiting Square-Root ORAM

Efﬁcient Random Access in Multi-Party Computation

Samee Zahur∗
∗University of Virginia

Xiao Wang†

Jack Doerner∗

David Evans∗

Mariana Raykova‡

Adrià Gascón§

Jonathan Katz†

†University of Maryland

‡Yale University

§University of Edinburgh

Abstract—Hiding memory access patterns is required for
secure computation, but remains prohibitively expensive
for many interesting applications. Prior work has either
developed custom algorithms that minimize the need for
data-dependant memory access, or proposed the use of
Oblivious RAM (ORAM) to provide a general-purpose
solution. However, most ORAMs are designed for client-
server scenarios, and provide only asymptotic beneﬁts in
secure computation. Even the best prior schemes show
concrete beneﬁts over naïve linear scan only for array
sizes greater than 100. This immediately implies each
ORAM access is 100 times slower than a single access
at a known location. Even then, prior evaluations ignore
the substantial initialization cost of existing schemes.

We show how the classical square-root ORAM of
Goldreich and Ostrovsky can be modiﬁed to overcome
these problems, even though it is asymptotically worse than
the best known schemes. Speciﬁcally, we show a design
that has over 100x lower initialization cost, and provides
beneﬁts over linear scan for just 8 blocks of data. For all
benchmark applications we tried, including Gale-Shapley
stable matching and the scrypt key derivation function, our
scheme outperforms alternate approaches across a wide
range of parameters, often by several orders of magnitude.

I. INTRODUCTION

Over the past decade, advances in protocol design and
implementation [2, 17, 26], cryptographic techniques [3,
20, 29, 41], and approaches for constructing smaller
circuits [19, 31] have combined to make circuit-based
secure computation efﬁcient enough for many practical
uses. Nevertheless, typical applications still exhibit an
unacceptable performance penalty when computed using
such protocols — especially those employing algorithms
that make heavy use of data-dependent memory access.
Although such accesses are constant-time operations
when performed locally, they require (in general) time
proportional to the size of the memory when performed
using circuit-based secure-computation protocols, be-
cause the access patterns must be hidden. For this reason,
researchers, beginning with Gordon et al. [15], have
investigated secure computation in the random access

2375-1207/16 $31.00 © 2016 IEEE
© 2016, Samee Zahur. Under license to IEEE.
DOI 10.1109/SP.2016.21
DOI 10.1109/SP.2016.21

218
218

machine (RAM) model of computation [7, 9, 18, 23, 24,
25, 36, 40]. A primary building block in this model is
oblivious RAM (ORAM) [12], which provides a memory
abstraction that can read and write to arbitrary locations
without leaking any information about which locations
were accessed.

ORAM protocols were originally proposed for a
client-server setting where a client stores and manipu-
lates an array of length n on an untrusted server without
revealing the data or access patterns to the server. Gordon
et al. adapted ORAM to the setting of secure computa-
tion [15], where parties collectively maintain a memory
abstraction that they can jointly access access, while
hiding the access patterns from everyone. In essence,
the parties run a secure-computation protocol to store
shares of the state of the underlying ORAM protocol,
and then use circuit-based secure computation to execute
the ORAM algorithms.

Although there is a rich literature devoted to develop-
ing ORAM protocols with improved performance [4, 13,
14, 21, 28, 30, 32, 37], most of this literature focuses on
optimizing performance in the client-server setting, and
most work on RAM-based secure computation (RAM-
SC) uses existing ORAM protocols (to a ﬁrst approx-
imation) as black boxes. We highlight, however, that
there are a number of differences between applications
of ORAM in the two settings:

1) In the client-server setting the client owns the data
and performs the accesses, so the privacy require-
ment is unilateral. In the RAM-SC setting none of
the parties should be able to learn anything about
the data or access patterns.

2) In the client-server setting the client’s state should
be sublinear in n or else the problem is trivial; for
RAM-SC, however, the linear state is stored across
both parties.

3) In the client-server setting the most important met-
ric is the total communication complexity. In the
RAM-SC setting other measures of efﬁciency be-
come more important. Speciﬁcally, the algorithmic

complexity is important because the algorithms will
be emulated using generic secure computation.

4) In the client-server setting, the initialization step
(when the client outsources its data to the server) is
“free” because it is a local action on the part of the
client. In the RAM-SC case, the parties must use
a distributed protocol for initialization and the cost
of doing so may be prohibitive.

Existing work on ORAM has focused entirely on
asymptotic performance; we are not aware of any prior
work whose aim is to improve performance for concrete
values of n. Indeed, prior work in the RAM-SC setting
has found that a linear scan over the data (i.e., a triv-
ial ORAM construction) outperforms more-complicated
ORAM constructions until n becomes quite large [15,
34, 35] (in practice, n is often small even when the
inputs are large since n may denote the length of a single
array rather than the entire memory being used by the
computation, and each memory block may contain many
individual data items). This means that for practical
sizes, the entire body of research on ORAM has had
little impact as far as RAM-SC is concerned.
Contributions. We re-visit
the classical square-root
ORAM of Goldreich and Ostrovsky [12], and propose
a number of modiﬁcations to that construction with the
goal of obtaining an ORAM scheme suitable for secure
computation in the semi-honest setting:

1) In the original scheme, the client uses a hash func-
tion to compute the position map (i.e., the mapping
from semantic addresses to physical addresses). We
replace this with a shared array storing the position
map explicitly. This is particularly beneﬁcial when
the underlying ORAM algorithms are computed
using generic circuit-based secure computation.

2) Because the position map is stored explicitly, initial-
ization and reshufﬂing (expensive operations per-
formed sporadically) can be made much more efﬁ-
cient than in the original construction, as they can
be based upon Waksman shufﬂing networks [33]
rather than oblivious sorting.

3) As observed in prior work [32] the position map is
a constant factor smaller than the original mem-
ory array. We use ORAMs recursively to enable
oblivious access to the position map, and develop a
number of optimizations in order to obtain a secure
and efﬁcient protocol.

We implement and evaluate our construction (code
available at http://oblivc.org/) and show that for small-to-
moderate values of n our scheme offers more efﬁcient

data access than Circuit ORAM [34]. In fact, our scheme
outperforms even the trivial ORAM (i.e., linear scan) for
n as small as 8 (the exact crossover point depends on
the block size used as well as the underlying network
and processor). Our construction also signiﬁcantly out-
performs prior work in terms of initialization time. To
understand how the properties of different applications
impact ORAM performance, and demonstrate the general
applicability of our design, we implement and evaluate
several benchmark application,
including secure two-
party computations of the Gale-Shapley stable matching
algorithm, breadth-ﬁrst search, binary search, and the
Scrypt hash function. The resulting protocols are more
efﬁcient than prior approaches by an order of magnitude
or more in some cases.

II. BACKGROUND

This section provides a brief introduction to multi-
party computation (MPC), oblivious RAM (ORAM),
RAM-based secure computation (RAM-SC), and closely
related protocols.

A. Multi-Party Computation

Secure multi-party computation [11, 38] enables two
or more parties to collaboratively evaluate a function
that depends on secret inputs from all parties, while
revealing nothing but only the result of the function. In
most generic constructions of multi-party computation,
the function to be evaluated is represented as a circuit
(either Boolean or arithmetic). Numerous circuit-based
multi-party computation protocols have been developed
for different scenarios. In this paper, we focus on using
our ORAM design with Yao’s garbled circuit protocol.
However, our scheme also works with other MPC pro-
tocols in general, and does not depend on any speciﬁcs
of Yao’s protocol.

Garbled circuits protocols involve parties, denoted
the generator and evaluator. Given a publicly known
function f , the generator associates each input bit with
two garbled keys k0,k1, and computes a “garbled” circuit
representation of the function f , GCf . Given garbled
keys corresponding to inputs x and y,
the evaluator
can obliviously evaluate GCf
to learn garbled keys for
f (x,y). The generator generates and sends GCf
output
and the input keys for its own input. The generator and
evaluator execute an oblivious transfer protocol to enable
the evaluator to learn the input keys corresponding to its
input without revealing that input to the generator. After
obtaining its input keys, the evaluator can obliviously

219219

evaluate GCf
coded in the ﬁnal step.

to obtain the output keys which are de-

B. Oblivious RAM

Oblivious RAM provides a memory structure that
hides access patterns [12]. An ORAM scheme consists
of two protocols: an initialization protocol that takes as
input an array of elements, initializes a new oblivious
structure in memory; and an access protocol that imple-
ments each logical access to the ORAM with a sequence
of physical accesses to the underlying structure.

To be secure, an ORAM must satisfy two proper-
ties: 1) the physical access pattern of the initialization
protocol is indistinguishable when initializing different
input arrays of the same size; 2) for any two sequences
of semantic accesses of the same length, the physical
access patterns produced by the access protocol must
be indistinguishable. Note that it is always possible to
implement a secure initialization protocol by performing
the access protocol iteratively on all input elements, and
this is the approach taken by previous ORAM designs
used in RAM-SC. It can be, however, very inefﬁcient to
initialize the ORAM through repeated accesses.

Goldreich and Ostrovsky [12] introduced two ORAM
constructions with a hierarchical layered structure: the
ﬁrst, Square-Root ORAM, provides square root access
complexity; the second, Hierarchical ORAM, requires a
logarithmic number of layers and has polylogarithmic
access complexity. A recent series of ORAM schemes,
beginning with the work of Shi et al. [30], adopted a se-
quence of binary trees as the underlying structure. While,
asymptotically,
the most bandwidth efﬁcient ORAM
constructions known use the hierarchical paradigm [21],
tree-based ORAMs are considered more efﬁcient for
practical implementations especially when used in MPC
protocols. This is primarily because classical hierarchical
constructions use hash functions or pseudorandom func-
tions (PRFs) to shufﬂe data in the oblivious memory.
In an MPC context these functions must be executed as
secure computations with large circuits.

C. RAM-Based Secure Computation

In traditional MPC, general

input-dependent array
access incurs a linear-time overhead since all elements
need to be touched to hide the position of interest. RAM-
based secure computation (RAM-SC) combines ORAMs
with circuit-based MPC protocols, to enable secure ran-
dom memory accesses [15]. In RAM-SC, the bulk of
the computation is still performed by a circuit-based
protocol as in traditional MPC, but memory accesses

is implemented
are performed using an ORAM that
within the MPC protocol. For each access, the circuit
now emulates an ORAM access step to translate a secret
logical location into multiple physical locations that must
be accessed. The physical locations are then revealed to
the two parties, which pass the requested elements back
into the circuit for use in the oblivious computation.
Finally, the circuit produces new data elements to be
written back to those physical positions, hiding which
elements were modiﬁed and how they were permuted.
One such structure is maintained for each array that
needs input-dependent general random access.

Two-party RAM-SC was ﬁrst formulated by Gordon et
al. [15] with an implementation based on a tree-based
ORAM scheme proposed by Shi et al. [30]. Subsequent
works [7, 9, 18, 36] presented improved protocols,
all based on tree-based ORAM constructions. Wang et
al. [34] proposed Circuit ORAM, which yields the best
known circuit size both in terms of asymptotic behavior
and concrete performance. In Section V, we provide per-
formance comparisons between our new ORAM scheme
and Circuit ORAM, showing orders of magnitude im-
provement for access and initialization across a wide
range of parameters and applications.

D. Variations

In addition to the RAM-SC model we focus on,
there are other uses for ORAMs in secure computation
protocols. Some of the ORAM innovations produced in
these settings have been applied to the RAM-SC designs
in Section II-C. Although it is beyond the scope of this
work, we believe our ORAM design may likewise yield
beneﬁts in other contexts.

Gentry et al. [9] proposed several optimizations for
tree-based ORAMs and considered brieﬂy how to build
a HE-over-ORAM system. A system based on Path
ORAM [32] was built in their subsequent work [10].
They showed a per-access time of 30 minutes for a
database with 4 million 120-bit records, excluding the
cost of initialization.

Lu and Ostrovsky [25] designed an ORAM algorithm
based on two non-colluding servers. When applied to a
two-party secure RAM computation setting, these servers
become parties engaging in an MPC protocol. Their con-
struction achieves O(logN) overhead, but suffers from
huge concrete costs because it requires oblivious eval-
uation of Θ(logN) cryptographic operations per access,
which is prohibitively expensive in an MPC protocol.

Afshar et al. [1] discussed how to extend RAM-SC
with malicious security, where both parties can arbitrarily

220220

deviate from the protocol. They proposed efﬁcient con-
sistency checks that avoid evaluating MAC in circuits.
In this paper, we only consider semi-honest adversaries,
and hope that future work will extend our protocol to be
secure against malicious adversaries.

III. REVISITING SQUARE-ROOT ORAM

In this section we revisit Goldreich and Ostrovsky’s
square-root ORAM design [12] and adapt it to the RAM-
SC setting. Section III-A introduces notations used to
describe ORAM algorithms; Section III-B provides a
brief description of the original scheme; Section III-C in-
troduces a basic (but inefﬁcient) construction by making
some key changes to the original scheme; Section III-D
shows how to improve its efﬁciency with a recursive
construction which is our ﬁnal design.

A. Notation

We use (cid:104)x(cid:105) to denote a variable x secretly shared by
the two parties. In our garbled circuit implementation,
(cid:104)x(cid:105) means the generator knows (k0,k1) and the evaluator
knows kx. Since the actual value of x is not known to
either party, we interchangeably use the terms “private”,
“garbled”, and “oblivious” to describe it.

The length of an array is always public, although
padding can be used to hide its exact length when nec-
essary. An array containing private elements is denoted
using angle brackets (e.g., (cid:104)Array(cid:105)). We denote the ith
element of an array using a subscript (e.g., (cid:104)Array(cid:105)i).
The index may be oblivious (e.g., (cid:104)Array(cid:105)(cid:104)i(cid:105)), in which
case the array access is performed via linear scan.
The structure blocks represents an array of block ob-
jects. Each block contains private data, block.(cid:104)data(cid:105), and
a private record of its logical index, block.(cid:104)index(cid:105). Thus,
i is the physical index of blocksi, and blocksi.(cid:104)index(cid:105) is
the logical index of the same block. Neither changing
the contents of a block nor moving it from one structure
to another alters its logical index, unless explicitly noted.
In pseudocode, ordinary conditional statements will
use the keyword if, while conditionals on secret values
will use (cid:104)if(cid:105). The bodies of secret conditionals are

deﬁne Access(Oram,(cid:104)i(cid:105),Φ):
for j from 0 to Oram.n− 1:
(cid:104)if(cid:105) (cid:104)i(cid:105) = j: Φ(Oram j)

Fig. 1: Access algorithm for the linear scan ORAM.

deﬁne Write(Oram,(cid:104)i(cid:105),(cid:104)val(cid:105)):

block.(cid:104)data(cid:105) ← (cid:104)val(cid:105)

deﬁne Φ(block):
Access(Oram,(cid:104)i(cid:105),Φ)
deﬁne Read(Oram,(cid:104)i(cid:105)):

(cid:104)val(cid:105) ← ⊥
deﬁne Φ(block):
Access(Oram,(cid:104)i(cid:105),Φ)
return (cid:104)val(cid:105)

(cid:104)val(cid:105) ← block.(cid:104)data(cid:105)

Fig. 2: Read and write wrappers deﬁned using Access()

always executed, but the statements in them are executed
conditionally, becoming no-ops if the condition is false.
$←− B to denote random choice of a secret

We use (cid:104)a(cid:105)

element a from a public set B.

Figure 1 shows how the access algorithm for a naïve
linear scan ORAM is written in our notation. The algo-
rithm Access takes three parameters as inputs:

• Oram: the main data structure storing the payload.
• (cid:104)i(cid:105): the private, logical index of the block we want
to access.

write or modify the desired block.

• Φ(): a function that is invoked during access to read,
The ORAM hides index (cid:104)i(cid:105) by performing a linear
scan over all elements. Note that we use (cid:104)if(cid:105) for the
conditional, so the body of the conditional statement will
actually be executed n times, although only one will take
effect. Both parties will see the garbled keys representing
(cid:104)val(cid:105) or (cid:104)data(cid:105) change n times inside Φ(); they just won’t
know if the associated plaintext has also changed, since
that depends on secret index (cid:104)i(cid:105).

Users will not typically use ORAMs by directly invok-
ing Access, but by using the wrapper functions shown
in Figure 2. These wrappers are exactly the same across
all ORAM constructions we consider; the essential logic
is in Access.

B. Square-Root ORAM

Figure 3 shows the original square-root ORAM pro-
posed by Goldreich and Ostrovsky [12]. The ORAM
structure consists of following components:

1) Shuﬄe: an array of blocks, also referred to as

“permuted memory” in the original paper.

2) Stash: an array of blocks, termed the “shelter” in

the original paper.

221221

deﬁne Initialize(blocks,T )

n ← |blocks|
(cid:104)π(cid:105) ← pseudorandom function
√
append
n dummy blocks to Shuﬄe
Shuﬄe ← ObliviousSort(blocks,(cid:104)π(cid:105))
Oram ← (n,t ← 0,T,(cid:104)π(cid:105), Shuﬄe, Stash ← ∅)
return Oram

deﬁne Initialize(blocks,T )

n ← |blocks|
(cid:104)π(cid:105) ← random permutation on n elements
Shuﬄe ← ObliviousPermute(blocks,(cid:104)π(cid:105))
Oram ← (n,t ← 0,T,(cid:104)π(cid:105), Shuﬄe,
Used ← ∅ , Stash ← ∅)

return Oram

deﬁne Access(Oram,(cid:104)i(cid:105),Φ)

(cid:104)found(cid:105) ← false
for j from 0 to Oram.t:
(cid:104)if(cid:105) Oram.Stash j.(cid:104)index(cid:105) = (cid:104)i(cid:105):
(cid:104)found(cid:105) ← true
Φ(Oram.Stash j)
(cid:104)k(cid:105) ← Oram.n + Oram.t

(cid:104)if(cid:105)(cid:104)found(cid:105) :

(cid:104)else(cid:105) : (cid:104)k(cid:105) ← (cid:104)i(cid:105)
p ← reveal(π((cid:104)k(cid:105)))
(cid:104)if(cid:105) not (cid:104)found(cid:105) :

Φ(Oram.Shuﬄep)
append Oram.Shuﬄep to Oram.Stash
Oram.Shuﬄep ← dummy
Oram.t ← Oram.t + 1
if Oram.t = Oram.T :

blocks ← real blocks in

Oram.Shuﬄe∪ Oram.Stash

Oram ← Initialize(blocks, Oram.T )

Fig. 3: The original square-root ORAM scheme [12].

3) π: a pseudorandom function (PRF) mapping indices
to random strings. Note that π needs to be evaluated
securely using MPC protocols, which is why pre-
vious RAM-SC designs dismissed the square-root
ORAM construction.

√
To initialize an ORAM from an array of blocks, we
√
n dummy blocks to the input array and
ﬁrst append
obliviously permute all n +
n blocks according to the
pseudorandom permutation π(i). Once the blocks are
shufﬂed, their physical locations and semantic indices
are uncorrelated, and so each block may be accessed
once (and only once) without revealing anything about
the access pattern. But, if a location in the shufﬂed array
is accessed multiple times that would leak information,

deﬁne Access(Oram,(cid:104)i(cid:105),Φ)

(cid:104)found(cid:105) ← false
for j from 0 to Oram.t:
(cid:104)if(cid:105) Oram.Stash j.(cid:104)index(cid:105) = (cid:104)i(cid:105):
(cid:104)found(cid:105) ← true
Φ(Oram.Stash j)

(cid:104)if(cid:105)(cid:104)found(cid:105) :

(cid:104)p(cid:105)

$←− {0, . . . , (Oram.n− 1)}\ Oram.Used

(cid:104)else(cid:105) : (cid:104)p(cid:105) ← Oram.(cid:104)π(cid:105)(cid:104)i(cid:105)
p ← reveal((cid:104)p(cid:105))
(cid:104)if(cid:105) not (cid:104)found(cid:105) :

Φ(Oram.Shuﬄep)

append Oram.Shuﬄep to Oram.Stash
Oram.Used ← Oram.Used∪{p}
Oram.t ← Oram.t + 1
if Oram.t = Oram.T :
for j from 0 to |Oram.Used|− 1:

p(cid:48) ← Oram.Used j
Oram.Shuﬄep(cid:48) ← Oram.Stash j

Oram ← Initialize(Oram.Shuﬄe, Oram.T )

Fig. 4: Our basic square-root ORAM scheme.

revealing that the access sequence contains a repeated
access.

To access logical index (cid:104)i(cid:105), we ﬁrst linear scan the
blocks in Stash. If the block is not found, we compute
its physical location, (cid:104)p(cid:105)← π((cid:104)i(cid:105)); otherwise, we ﬁnd the
physical location of the next unaccessed dummy blocks,
(cid:104)p(cid:105) ← π(n + Oram.t). The value (cid:104)p(cid:105) is then revealed to
both parties, but leaks no information about the logical
index. The block at the physical location referred to by
p is accessed, by doing a binary search over the π(i)
values, and moved to Stash.

222222

After T accesses have been performed, we oblivi-
ously remove all dummy blocks in Oram.Stash and
Oram.Shuﬄe and re-initialize the whole structure. The
complete protocol is shown in pseudocode in Figure 3.
√
√
In Goldreich and Ostrovsky’s original protocol, Oram.T
nlog2 n) amortized cost
n, resulting in O(
is set to
per access.

The original scheme was not designed for a RAM-SC
setting, and suffers from two key problems that make it
very expensive to implement in an MPC:

1) It evaluates the PRF π(x) for each access; in the
√
n evaluations of π(i)
initialization algorithm, n +
are needed. This is inefﬁcient, especially in MPC
protocols since evaluating each PRF requires tens
of thousands of gates.

2) It requires a Θ(nlog2 n) oblivious sort on the data
blocks in two different places: to shufﬂe data blocks
according to the PRF results, and to remove dummy
blocks before initialization.

Next, we discuss how to adapt the scheme for efﬁcient
use in RAM-SC by eliminating these problems.

C. Basic Construction

Figure 4 presents our basic construction, a step to-
wards our ﬁnal scheme. The construction is similar to
the original scheme, with a key difference: instead of
using PRF to generate a random permutation, it stores the
permutation π explicitly as a private array. This enables
several performance improvements:

1) Storing the permutation π as a private array enables
us to replace oblivious sorting during the initializa-
tion with a faster oblivious permutation. In addition,
the value p revealed during the access refers to the
real location, which avoids using binary search to
ﬁnd the location for p. Section III-D shows how to
recursively implement π for better efﬁciency.

2) We eliminate the need of dummy blocks. When
a dummy access is needed, we instead access a
random location for real blocks that is not accessed
before and append the block to the Stash.

3) By using a public set Used, we avoid the oblivious
sorting needed when moving blocks from the Stash
to Shuﬄe. This is efﬁcient since Used is maintained
in the clear and is secure because all elements in
Used have already been revealed.

Security. Assuming the MPC protocol itself is secure
and does not
leak any information about oblivious
variables, this protocol satisﬁes the ORAM requirement
that no information is revealed about the logical access

223223

indices p;

pattern. On each access, a uniform unused element
from Shuﬄe is selected, regardless of the semantic
index requested. Subsequently, the entire Stash is always
scanned. Finally, the entire structure is reshufﬂed at a
ﬁxed interval, in a manner independent of the access
pattern. The only values revealed are the permuted
physical
the set Used, which contains no
information about the semantic indices; and the counter
t, which increments deterministically.
Asymptotic cost. Now we analyze the average cost of
accessing a block in this basic scheme. We represent the
combined cost of accessing (cid:104)π(cid:105) and Used as c(n), some
value that only depends on the number of blocks, n, but
not block size. We use B to denote the cost of accessing
a single block (this could be bandwidth, time, or energy
cost). The augmented cost, B(cid:48) = B + Θ(log2 n), includes
the additional cost of accessing the metadata containing
the block’s logical index. For an ORAM of size n, each
logical index requires log2 n bits, so it incurs Θ(log2 n)
cost to retrieve or compare an index.

Since our construction is a periodic algorithm that
performs a shufﬂe every T accesses, we obtain the
amortized per-access cost by computing the average over
T accesses. This is the cost of the shufﬂe plus the cost
of B(cid:48) for each block touched thereafter until the next
shufﬂe.
The cost of shufﬂing is approximately B(cid:48)W (n) using
a Waksman network [33]. Here, W (n) = nlog2 n− n + 1
is the number of oblivious swaps required to permute n
elements. On each access, the entire Stash, comprising
t blocks, must be scanned. Thus, the total cost of the T
accesses and one shufﬂe which constitutes a full cycle
is given by

(cid:0)B(cid:48)t + c(n)(cid:1)

T

B(cid:48)W (n) +

∑
t=1
1
≤ B(cid:48)nlog2 n +
2

(cid:18) 1

= T

T
= T F(n)

B(cid:48)T (T + 1) + T c(n)

B(cid:48)nlog2 n +

B(cid:48)(T + 1) + c(n)

1
2

(cid:19)

where F(n) is the amortized per-access cost we are after.

If reshufﬂe period T = Θ((cid:112)nlog2 n), the asymptotic
cost is F(n) = Θ(B(cid:48)(cid:112)nlog2 n), assuming the block size

is large enough to make c(n) negligible compared to B.
Concrete cost. This design is less expensive than linear
scan, even for reasonably small block sizes and for block
counts as low as four. With linear scan, the cost is nB per

T ← (cid:100)(cid:112)W (n)(cid:101)

n ← |blocks|
(cid:104)π(cid:105) ← random permutation on n elements
Shuﬄe ← ObliviousPermute(blocks,(cid:104)π(cid:105))
Oram1 ← InitializePosMap((cid:104)π(cid:105),1,T )
Oram0 ← (n,t ← 0,T, Oram1, Shuﬄe,

Used ← ∅, Stash ← ∅)

deﬁne Initialize(blocks)

return Oram0

deﬁne Access (Oram0,(cid:104)i(cid:105),Φ, )
(cid:104)found(cid:105) ← false
for j from 0 to Oram.t:
(cid:104)if(cid:105) Oram0.Stash j.(cid:104)index(cid:105) = (cid:104)i(cid:105):
(cid:104)found(cid:105) ← true
Φ(Oram0.Stash j)

p ← GetPos(Oram0.Oram1,(cid:104)i(cid:105),(cid:104)found(cid:105))
(cid:104)if(cid:105) not (cid:104)found(cid:105):

Φ(Oram0.Shuﬄep)
append Oram0.Shuﬄep to Oram0.Stash
Oram0.Used ← Oram0.Used∪{p}
Oram0.t ← Oram0.t + 1
if Oram0.t = Oram0.T :
for j from 0 to Oram0.T − 1:
p(cid:48) ← Oram.Used j
Oram0.Shuﬄep(cid:48) ← Oram0.Stash j
Oram0 ← Initialize(Oram0.Shuﬄe)

Fig. 5: Our recursive square-root ORAM scheme. W (n) is the number of swaps needed in a n-sized Waksman
permutation network.

access, ignoring smaller terms that are independent of B.
With four blocks, the cost of a linear scan is 4B. Using a
shufﬂing period of T = 3, we get a cost of B(W (4) +1 +
2 + 3) = 11B for three accesses, again ignoring smaller
terms that are independent of B. This is slightly better
than the linear scan cost for three accesses, 3 × 4B =
12B. Thus, for four blocks of a large enough size, the
simpliﬁed one-level square-root ORAM is less expensive
than a linear scan, even after accounting for the cost of
initialization. However, in the case of small blocks, the
terms independent of B (which we have ignored) become
signiﬁcant enough that linear scan has a slight advantage.
In our experiments, we observed the square-root
scheme to be more efﬁcient in terms of bandwidth for
four blocks of just 36 bytes each (see Section V-B for
details). For larger block sizes, we found that the cost
ratio reaches 11 : 12, as expected.
D. Scalable Construction

So far, we have not discussed how to implement the
structure (cid:104)π(cid:105) more efﬁciently than linear scan, aside from
claiming that its costs do not depend on the block size.
For small values of n, linear scan is good enough, as in
the four-block example above. At this size, π comprises
just four records of two secret bits each. However, for
larger values of n, it may seem natural to build these
structures upon recursive ORAMs of decreasing size. As
we discuss next, however, this method is unacceptably

224224

costly. Our solution is to specialize the structure for
position maps.

The position map structure, (cid:104)π(cid:105), is common to most
existing tree-based constructions [30, 32, 34]. It is usu-
ally implemented atop recursive ORAMs of decreas-
ing size, each level packing multiple indices of the
previous into a single block, and the whole thing is
updated incrementally as elements of the main ORAM
are accessed. In these constructions, each ORAM lookup
requires a single corresponding lookup in each recursive
position maps. However, in our scheme, a naïve recursive
structure for (cid:104)π(cid:105) would require n + T position lookups
for every T accesses to the main ORAM (where T is the
number of accesses between shufﬂes) since each of the
T main accesses would require an access to the position
map, and additional n accesses would be required to
store the regenerated permutation π(cid:48) when the ORAM
is shufﬂed.

This is a serious problem: each level of the recursive
structure would need to store pack indices of the previous
level in a single block, which would be traversed by
linear scan. Thus, each subsequent level decreases in
element count by a factor of pack, but all levels require
pack time to linear scan the relevant block. We can
multiply by (n + T )/T to amortize the cost over T

accesses, where T =(cid:112)nlog2 n, the shufﬂe period (as

computed in Section III-C). If the amortized cost per

deﬁne GetPos(Oramk,(cid:104)i(cid:105),(cid:104)fake(cid:105))
if Oramk.n/pack ≤ Oramk.T :

else:

p ← GetPosBase(Oramk,(cid:104)i(cid:105),(cid:104)fake(cid:105))
(cid:104)found(cid:105) ← false
(cid:104)h(cid:105) ← (cid:104)i(cid:105)/pack
(cid:104)l(cid:105) ← ((cid:104)i(cid:105) mod pack)
for j from 0 to Oramk.t − 1:
(cid:104)if(cid:105) Oramk.Stash j.(cid:104)index(cid:105) = (cid:104)h(cid:105):
(cid:104)found(cid:105) ← true
block ← Oramk.Stash j
(cid:104)p(cid:105) ← block.(cid:104)data(cid:105)(cid:104)l(cid:105)

p(cid:48) ← GetPos(Oramk+1,(cid:104)h(cid:105),(cid:104)fake(cid:105) or (cid:104)found(cid:105))
append Oramk.Shuﬄep(cid:48) to Oramk.Stash
Oramk.t ← Oramk.t + 1
(cid:104)if(cid:105) (cid:104)fake(cid:105) or not (cid:104)found(cid:105):
block ← Oramk.Stash(Oramk.t−1)
(cid:104)p(cid:105) ← block.(cid:104)data(cid:105)(cid:104)l(cid:105)
p ← reveal((cid:104)p(cid:105))

return p

deﬁne InitializePosMap((cid:104)π(cid:105),k,T )

(cid:10)Used0···(n−1)

(cid:11) ← (false, . . . ,false)

n ← |(cid:104)π(cid:105)|
if n/pack ≤ T :
Oramk ← (n,t ← 0,T,(cid:104)π(cid:105),(cid:104)Used(cid:105))
else:
for i ∈ {0 . . .(cid:100)n/pack(cid:101)− 1}:
(cid:104)data(cid:105) ← ((cid:104)π(cid:105)pack·i, . . . ,(cid:104)π(cid:105)pack·(i+1)−1)
blocksi ← ((cid:104)data(cid:105),(cid:104)index(cid:105) ← i)
(cid:104)π(cid:48)(cid:105) ← random permutation on (cid:100)n/pack(cid:101) elements
Shuﬄe ← ObliviousPermute(blocks,(cid:104)π(cid:48)(cid:105))
Oramk+1 ← InitializePosMap((cid:104)π(cid:48)(cid:105),k + 1,T )
Oramk ← (n,t ← 0,T, Oramk+1, Shuﬄe,

Stash ← ∅)

return Oramk
deﬁne GetPosBase(Oramk,(cid:104)i(cid:105),(cid:104)fake(cid:105))
(cid:104)p(cid:105) ← ⊥
(cid:104)done(cid:105) ← false
for j from 0 to (Oramk.n− 1):
(cid:104)s1(cid:105) ← (not (cid:104)fake(cid:105) and (cid:104)i(cid:105) = j)

(cid:104)s2(cid:105) ←(cid:0)(cid:104)fake(cid:105) and not Oramk.(cid:104)Used(cid:105) j
(cid:104)p(cid:105) ←(cid:10)π j

and not (cid:104)done(cid:105)(cid:1)

(cid:104)if(cid:105) (cid:104)s1(cid:105) or (cid:104)s2(cid:105):
Oramk.(cid:104)Used(cid:105) j ← true
(cid:104)done(cid:105) ← true

(cid:11)

p ← reveal((cid:104)p(cid:105))
return p

Fig. 6: Implementation of the recursive position map.

access to level i of this map is ci(n), we have:
T (ci+1(n/pack) + pack)

ci(n) ≥ n + T

n(cid:112)nlog2 n
(cid:114) n

log2 n

≥

≥

ci+1(n/pack)

ci+1(n/pack).

This is a super-polynomial function with Θ(logn) levels
of recursion, which is unacceptable for our efﬁciency
goals. Fixing this involves three changes to our basic
construction.

The ﬁrst change is to take advantage of our ability
to initialize quickly from an oblivious array. On each
shufﬂe, we regenerate π, and,
instead of writing it
into the recursive structure element by element, we re-
initialize the recursive structure using π(cid:48) as the seed data.

This eliminates the extra n accesses to the position map
on each cycle.

to the same shufﬂe period, T =(cid:112)nlog2 n, where n is

Second, we lock all levels of the recursive structure

the number of blocks in the main ORAM (the level that
contains the original data). We terminate the recursion at
the ﬁrst level with fewer than T blocks, and access this
ﬁnal level using linear scan. Using this arrangement, we
can initialize the entire ORAM in Θ(Bnlogn) bandwidth
and time.

This second modiﬁcation has a downside. All levels
of the recursive ORAM shufﬂe in synchronization with
one another, based on a shufﬂe period determined by
the largest level. This shufﬂe period will be signiﬁcantly
suboptimal for levels with fewer blocks. We pay a
time and bandwidth cost of Θ(T ) at each level of the

225225

(a) Physical layout before shufﬂing

(d) First request: logical index 8

(b) Physical layout after shufﬂing

(e) Second request: logical index 9

(c) Temporal control ﬂow for all requests

(f) Third request: logical index 8

Fig. 7: Illustration of data ﬂow for one full cycle of an example ORAM. In subﬁgures (d), (e), and (f) we
present the logical dependencies for three sequential accesses.

(cid:112)nlog3 n). However, the linear scan

ORAM (for linearly scanning the Θ(T ) blocks in each
level’s Stash). An ORAM instantiated with n elements
will have logn levels, which brings the cost per access
to Θ(T logn) = Θ(
overhead incurred by using a global shufﬂing period is
compensated for by gains in the efﬁciency of Used which
it enables.

ready been accessed — yet, they must obliviously check
whether it contains a secret logical index (cid:104)p(cid:105). Moreover,
they must be able to sample a secret, uniform element
from S = {0, . . . ,n − 1} \ Used. The simplest method
would be to sample an integer from {0, . . . ,|S| − 1}
and then obliviously map it to the set S, an expensive
operation.

Constructing an efﬁcient mechanism for keeping track
of used and unused physical blocks poses a challenge.
Used contains inherently public data — both parties
are aware which physical locations in Shuﬄe have al-

The third change removes the need to obliviously
check Used for secret index (cid:104)p(cid:105). Instead of using an
explicit data structure, our choice of a global shufﬂe
period allows us to implicitly represent a superset of

226226

0123456789012340120123456789012340Data Block withlogical index 0123Mapping Block withlogical index 1, referencingphysical indices 2 and 3Stash (empty)Legend0123456789134012918720204312450360123456789134012918720204312450361235642012345678913401918720204312450364208LegendReal request (cid:31)owFake request (cid:31)owMovement of datafrom Shu(cid:30) to Stash4=⌊8/2⌋2=⌊8/4⌋8143878012345679130918720432450362094=⌊9/2⌋random938701234567109120245036420890360random8Used in the recursive structure (cid:104)π(cid:105), by tracking which
blocks the smallest recursive level have been used.
We use the notation Oramk.Stash, Oramk.Shuﬄe, and
Oramk.Used to represent the corresponding structures in
recursive ORAM at level k. Oram0 is the main ORAM
that holds the data blocks; Oram1 is the top level of
the position map (cid:104)π(cid:105); Oram2 and so on indicate deeper
levels of the recursive position map structure.

We maintain the invariant that if a block has already
been moved from Oramn.Shuﬄe to Oramn.Stash, the
corresponding block in Oramn+1 has also been moved
from Oramn+1.Shuﬄe to Oramn+1.Stash. The converse
is not necessarily true: it is possible for Oramn+1.Stash
to contain blocks that map to unaccessed blocks in
Oramn. This can happen, for example, if logical block
i of Oram0 has been accessed and block i + 1 has not,
but mapping information for both blocks resides in the
same block of Oram1.

Randomly sampling an unused block with this con-
struction is simple. At the smallest level the blocks are
linearly scanned, so we just pick the ﬁrst unused element.
This is guaranteed to point to a random unused position.
At the next recursive level, we can use any element
in the block referred to by the index from the ﬁrst
level, since they are all random and unused. The process
continues to ripple upward until an unused block in the
required ORAM level has been selected. This method
excludes from the set to be randomly sampled any block
referred to by a block that has been accessed at a lower
level. Nonetheless, blocks sampled randomly remain
indistinguishable from genuine accesses, as, for each top
level access, exactly one unused block is accessed at each
lower level.

The ﬁnal construction is presented in Figures 5 and 6,
and the life-cycle of the ORAM is illustrated in Figure 7.

IV. TECHNIQUES AND OPTIMIZATIONS

This section presents some of the lower-level tech-

niques used in our implementation.
Shufﬂing. We employ a Waksman network [33] for
shufﬂing. The network executes many oblivious swap
operations, each controlled by a secret bit determined
by the permutation π. Let B be the number of bytes
transferred when obliviously swapping two blocks of
data. Since a Waksman network for shufﬂing requires
W (n) = nlog2 n− n + 1 swap operations, it is expected
that the two parties will transfer BW (n) bytes during a
shufﬂe, excluding the secret control bits.

The control bits pose a problem: neither party can
learn anything about the randomly sampled permutation

227227

π, but we do not know an efﬁcient oblivious algorithm
for computing the corresponding control bits. To solve
this problem, we perform two shufﬂes: the parties lo-
cally a pick secret permutation each and compute their
corresponding control bits in the clear. Each party’s
local permutation constitutes its share in the ﬁnal secret
permutation π, which is the composition of the two
permutations. So long as at
least one party behaves
honestly, the result is a uniformly random permutation,
discoverable to neither. They can jointly shufﬂe the data
by running two consecutive shufﬂing networks, one for
each permutation.

Performing a shufﬂe in this way is quite inexpensive.
The bandwidth cost of 2W (n) swaps is comparable to
W (n) AND gates, using the oblivious shufﬂe design from
Huang et al. [16] and half-gates technique from Zahur et
al. [41]. However, each time we perform a shufﬂe, we
incur the latency of a network round-trip, since the
evaluator retrieves new garbled labels for control bits
via oblivious transfer extension [2].
Computing the permutation. Whenever the data in
Shuﬄe is shufﬂed, we must reinitialize the recursive
position map so that it contains the new secret permuta-
tion, π. The ﬁrst time we perform a shufﬂe obliviously
computing π is straightforward. Because the shufﬂe
was performed with the composition of two Waksman
networks as described previously, we can run the same
network backwards using (0, . . . ,n − 1) as inputs to
obtain π.

On subsequent shufﬂes, the process becomes compli-
cated. The blocks in Shuﬄe are no longer in logical
order because they have previously been shufﬂed and
moved from Shuﬄe to Stash and back. Obtaining the
permutation by the same method as above would require
us to run both shufﬂes (four Waksman networks in total)
in reverse, along with any other swaps that may have
happened due to ordinary ORAM access. Each additional
shufﬂe requires two more Waksman networks, and the
number continues to increase without bound.

Instead, we augment each data block with a secret
record of its logical index. When the blocks are shufﬂed,
the logical indices are shufﬂed with them through the
Waksman networks, and these indices comprise π−1, the
mapping from physical to logical index. To ﬁnd π, the
mapping from logical to physical, we simply invert π−1.
To invert π−1 efﬁciently without allowing either party
to learn anything about it, we adopt a technique from
Damgård et al. [6]. The ﬁrst party (Alice) locally sam-
ples a new random permutation πa and computes the

corresponding Waksman control bits. This is then used
to jointly permute the elements of the secret permutation
π−1, producing π−1·πa = πb. Next, πb is revealed to the
second party, Bob (but not to Alice). Bob does not learn
anything about π−1 because it is masked by πa. Bob now
locally computes π−1
b , and the two parties jointly execute
another Waksman network to compute πa · π−1

b = π.

V. EVALUATION

To evaluate our design, we implemented our Square-
Root ORAM design and Circuit ORAM,
the best-
performing previous ORAM design, using the same
state-of-the-art MPC frameworks, and measured their
performance on a set of microbenchmarks. We also
wanted to understand the impact of different ORAM
designs on application performance, and how close we
are to enabling general-purpose MPC. To this end, we
implemented several application benchmarks represent-
ing a wide range of memory behaviors and evaluated
their performance with different ORAM designs.

A. Experimental Setup

We implemented and benchmarked RAM-SC proto-
cols based on our ORAM as well as Circuit ORAM,
using the Obliv-C [40] framework executing a Yao’s
garbled circuit protocol. Obliv-C provides a C-like lan-
guage interface, and it incorporates many recent opti-
mizations [3, 17, 41].

All code was compiled using gcc version 4.8.4, with
the -O3 ﬂag enabled. Unless otherwise speciﬁed, all
reported times are wall-clock time for the entire pro-
tocol execution. Our benchmarks were performed with
commercially available computing resources from Ama-
zon Elastic Compute Cloud (EC2). We used compute-
optimized instances of type C4.2xlarge running Ama-
zon’s distribution of Ubuntu 14.04 (64 bit). These notes
provide four physical cores (capable of executing eight
simultaneous threads in total), partitioned from an In-
tel Xeon E5-2666 v3, and 15 GiB of memory Our
benchmarks are all single-threaded and cannot saturate
the processing power available. We selected C4.2xlarge
nodes on the basis of the greater bandwidth and memory
they offer. Each benchmark was executed between two
separate nodes within the same datacenter. We used iperf
to measure the inter-node bandwidth, and found it to be
about 1.03 Gbps.

In addition to square-root ORAM, we benchmarked
a simple linear scan and an implementation of Circuit
ORAM, the best previously reported ORAM construc-
tion for MPC. Our implementation of Circuit ORAM

Fig. 8: Per-access cost crossover points between
ORAM schemes. Below the green line, linear scan is
most efﬁcient. Above the red line, Circuit ORAM is most
efﬁcient. Between the two, Square-Root ORAM is most
efﬁcient.

is much more efﬁcient than the original implementa-
tion described in Wang et al. [34]. For example, while
executing benchmarks on an Amazon C4.8xlarge EC2
instance for an ORAM of one million 32-bit blocks,
they reported an access time of two seconds. On a less
powerful, more bandwidth-constrained C4.2xlarge EC2
instance, our implementation requires only 0.16 seconds
per access for an ORAM with the same parameters. This
reduction by a factor of roughly twelve is mostly due
to the efﬁciency advantages of the Obliv-C framework
over the ObliVM [24] framework used by Wang et
al.’s implementation. For all performance reported in the
following, we let Circuit ORAM and square-root ORAM
pack 8 entries in each recursive level. Circuit ORAM
stops recursion when there are fewer than 28 entries.
B. Microbenchmarks

We performed several microbenchmarks to assess the
granular performance of different ORAM designs. We
observed single-access execution time for block counts
varying from 4 to 1024 and block sizes varying from
4 to 1024 bytes. This is the region of parameter space
where the efﬁciencies of Square-Root ORAM and linear
scan overlap. Figure 8 shows the efﬁciency crossover
points derived from this data, ignoring initialization cost.
Due to the nature of the Square-Root ORAM algorithm,
each access is more expensive than the previous one,
until a shufﬂe occurs and resets the cycle. To ensure our
averages truly are representative, we collected a number
of samples for each ORAM conﬁguration equal to a

228228

2223242526272829210211212Block Size (bytes)242628210212214216218220Number of BlocksLinear Scan FasterSquare-Root ORAM FasterCircuit ORAM FasterFig. 9: Cost per access omitting initialization. Solid
lines are for block size of 16 bytes, dashed lines are for block
size of 32 bytes. We collected a number of samples for each
ORAM conﬁguration equal to a multiple of the Square-Root
ORAM shufﬂe period that is greater than thirty, except in the
case of linear scan, for which exactly thirty samples were
collected.

multiple the shufﬂe period that is greater than thirty,
except in the case of linear scan, for which exactly thirty
samples were collected.
Breakeven points. Linear scan is preferred to Square-
Root ORAM only for very small numbers of blocks.
Circuit ORAM is orders of magnitude more expensive
for similar parameters, due to its high ﬁxed access cost.
Our Square-Root ORAM implementation achieves a very
low break-even point with linear scan. When using 4096
or fewer blocks, Circuit ORAM never wins over. And
at a block size of 4 bytes, Circuit ORAM remains a
suboptimal choice until we have more than 500,000
blocks. But that, in turn, increases initialization cost.
Comparison to Circuit ORAM. In comparing our
Square-Root ORAM scheme to Circuit ORAM, we con-
sider initialization and access costs separately since the
number of accesses per initialization will vary across
applications. Figure 9 shows the per-access wall-clock
time for both designs, as well as for linear scan, ignoring
initialization.

As expected, Circuit ORAM has the best asymptotic
performance, but it also has a very high ﬁxed cost per
access, independent of the number of blocks. As a result,
Square-Root ORAM performs better than Circuit ORAM
for all block counts up to 216, even ignoring initialization
costs. In fact, for block counts less than ~211 linear
scan also outperforms Circuit ORAM. These results are

Fig. 10: Cost of initialization. Solid lines are for block
size of 16 bytes, dashed lines are for block size of 32 bytes.

consistent with our analysis in Section III-D that Square-
Root ORAM has worse asymptotic behavior, but smaller
hidden constants.

For any application where the number of accesses is
not signiﬁcantly larger than the number of blocks in the
ORAM, initialization cost must be considered. Figure 10
shows the initialization wall-clock times for Square-Root
and Circuit ORAM, with parameters matching those
in our access-time comparison. For this benchmark,
we assume each ORAM must be populated using data
already stored in an array of oblivious variables. In such
a scenario, a linear scan ORAM requires only that the
data be copied; the reported linear scan initialization
speed is therefore equivalent to the time required to copy
the data.

Initializing Square-Root ORAM is approximately 100
times faster than initializing Circuit ORAM, regardless
of block count or block size. The standard way to
populate Circuit ORAM is to insert each data element
individually, using standard ORAM access operations;
thus, the cost scales linearly with the number of blocks
to be populated. We hypothesize that most of this speed
improvement comes from having fewer network round
trips in our initialization process. Circuit ORAM there-
fore requires Θ(N logN) round trips for initialization,
while our scheme requires only Θ(logN).

C. Oblivious Binary Search

Unlike our other application benchmarks, binary
search performs very few accesses relative to the ORAM
size. An equivalent search can be performed using a sin-
gle linear scan, and if only one search is to be performed,
the linear scan is always more efﬁcient. Consequently,

229229

23252729211213215217219Number of Blocks10-410-310-210-1100101102Running Time per Access (seconds)Linear ScanCircuit ORAMSquare-Root ORAM23252729211213215217219Number of Blocks10-710-610-510-410-310-210-1100101102103104105Running Time per Init (seconds)Linear ScanCircuit ORAMSquare-Root ORAMBenchmark

Binary Search

Parameters
1 search
25 searches
210 searches

Breadth-First Search

Gale-Shapley

Scrypt

n = 22
n = 25
n = 210
23 pairs
26 pairs
29 pairs
N = 25
N = 210
N = 214
Litecoin

Linear Scan

Square-Root ORAM Circuit ORAM

1.00
31.87
1019.77

0.09
4.77
4569.31

-
-
-

10.41
26.25
824.81

0.34
4.08
679.63

0.51
145.13

3228.69
3282.40
5040.82

4.28
42.66
3750.57

6.57
1328.50

119405.

188972.

4.11
1678.16

about 7 days

210.92

3.43
293.79
1919.92
40.29

34.47
1453.85
2846.51
247.29

TABLE I: Summary of benchmark results. All benchmark results are average measured wall-clock time in seconds
for full protocol execution (see individual benchmark sections for details).

we varied the number of searches performed for this
benchmark, rather than the block size or block count.
We benchmarked binary search using a block size of
16 bytes and element counts of 210 and 215. For arrays
of 210 elements, we averaged the running time over 30
samples, and for 215 elements we use 3 samples. A few
representative combinations for 215 elements are reported
in Table I.

Initialization dominates execution time unless many
searches are performed on the same data. As a result,
Square-Root ORAM is more than two orders of magni-
tude better than Circuit ORAM when only one search is
performed. For searches of 210 elements, the linear scan
method is more efﬁcient than a binary search regardless
of the ORAM type or the number of searches performed.
Linear scan is initially faster for searches of 215 elements
as well, but Square-Root ORAM becomes more efﬁcient
than the linear scan method at 25 searches. Accesses to
a Circuit ORAM of 215 elements are more expensive
than accesses to a Square-Root ORAM of the same size,
so at this array size, Circuit ORAM will never be more
efﬁcient regardless of the number of searches performed.

D. Oblivious Breadth-First Search
formulations

Natively-oblivious

of Breadth-First
Search (BFS) and other graph algorithms have been
explored in the past [5]; however, we use a variant of
the standard algorithm optimized for use in an oblivious
context. It has complexity in Θ((V + E)CAccess), where
CAccess is the complexity of accessing an element in
the underlying ORAM construction. We allow our
ORAM implementations to apply arbitrary functions

to modify the blocks they access, as opposed to the
simple read and write functions shown in Figure 2.
This reduces the total number of ORAM accesses by,
for example, permitting combined read and update
operations. Rather than use an ORAM to house the
queue, we use the oblivious queue data structure from
Zahur and Evans [39].

We benchmarked our BFS implementation using linear
scan, Circuit ORAM, and Square-Root ORAM. We took
30 samples for experiments of n vertices and γ × n
edges, with n ranging from 4 to 1024 and γ as 8.
For each sample, a fresh set of edges were generated
randomly among the chosen number of vertices. A few
representative combinations are shown in Table I.

The results of the BFS benchmark roughly follow
the pattern established by the microbenchmarks in Sec-
tion V-B. Small numbers of vertices and edges yield
small ORAMs, and linear scan proves to be best in these
cases. As the number of vertices or edges begins to rise,
Square-Root ORAM quickly becomes more efﬁcient
than linear scan. Our BFS implementation uses blocks
of only a few bytes each; as a result, Circuit ORAM
eventually becomes more efﬁcient than linear scan, but
it does not approach the efﬁciency of Square-root ORAM
before the upper bound of our testing range is reached at
n = 210. Beyond that point the benchmarks would have
required several hours to complete.

E. Oblivious Stable Matching

To explore a benchmark representative of a com-
plex algorithm, we implemented an oblivious version
of the Gale-Shapley stable matching algorithm [8]. We

230230

followed the textbook algorithm closely. Although we
believe there are signiﬁcant optimizations available in
adapting the algorithm for use in MPC, they are beyond
the scope of this work.

As a result, our implementation requires Θ(n2) ac-
cesses of an ORAM with n2 elements. It also uses of sev-
eral ORAMs of length n. The most efﬁcient arrangement
may be to mix ORAM schemes, but we have not done
this. As in our BFS implementation, we used function
application to reduce the number of ORAM accesses.

We benchmarked our implementation of Gale-Shapley
with both Circuit and Square-Root ORAMs as the under-
lying structure, but not linear scan since it is clear linear
scan cannot be competitive for this benchmark and the
expense of executing it on non-trivial sizes would be
considerable. The number of pairs to be matched ranged
from 4 to 512. When the pair count was less than 128,
we collected 30 samples; for pair counts of 128 and 256
we collected 3 samples; for 512 pairs, we collected one
sample. Results for few representative conﬁgurations are
included in Table I.

Square-root ORAM proved more efﬁcient over the
entire range we benchmarked, although for sufﬁciently
large sizes Circuit ORAM will eventually do better. For
64 pairs, Square Root ORAM is over 9 times faster
(ﬁnishing in 145 seconds); for 512 pairs, stable matching
requires just over 33 hours using Square-Root ORAM
and 52.5 hours with Circuit ORAM.

F. Oblivious Scrypt

To explore the possibility of using ORAMs in a
challenging cryptographic application, we implemented
the key derivation function scrypt [27]. Scrypt was
originally intended to be difﬁcult
to parallelize, and
therefore difﬁcult to break by brute force, even with
custom high performance hardware. It achieves this
goal by repeatedly enciphering a single block of data,
retaining each intermediate result in memory. It then
performs a second round of encipherment, mixing the
block with an intermediate result from the ﬁrst round
selected according to the current value. In an oblivious
context, scrypt requires the use of an ORAM of some
sort, as the indices of the memory accesses in the second
phase depend upon oblivious data generated in the ﬁrst
phase. Due to its unpredictable memory access pattern,
the scrypt algorithm is designed to require sequential
execution with no signiﬁcant shortcuts.

With typical parameters, scrypt requires a relatively
small ORAM element count. For instance, Litecoin,
which uses scrypt as a cryptocurrency proof-of-work,

speciﬁes N = 210 elements [22], and Colin Percival, the
designer of scrypt, recommends a minimum of N = 214
elements for normal use [27]. On the other hand, Percival
recommends that each element be 1KB in size — much
larger than required by any of our other application
benchmarks. In the course of execution, scrypt performs
exactly one access per element.

We tested scrypt using the recommended parameters
and test vectors from the scrypt speciﬁcation [27], r = 8
and p = 1, and we varied N from 4 to 214. In addition,
we benchmarked the parameters used by Litecoin, (r = 1,
p = 1, N = 210). A few representative combinations are
presented in Table I. As in the other benchmarks, linear
scan is marginally more efﬁcient when the number of
blocks (N) is small. Otherwise, Square-Root ORAM is
preferred; it exceeds the performance of linear scan by
approximately one order of magnitude when N = 210,
and this ratio improves as N increases.

The largest parameters we benchmarked are Perci-
val’s recommended minimum parameters (r = 8, p = 1,
N = 214), which he originally chose on the basis that they
required less than 100ms to execute on contemporary
hardware, this being what he considered a reasonable
threshold for interactive use [27]. On our EC2 test node,
the reference (non-oblivious) scrypt implementation re-
quires 35ms with the same parameters. With Square-
Root ORAM as the underlying primitive, execution
took 32 minutes, compared with 47 minutes for Circuit
ORAM. The large block size required by scrypt causes
block access time to form a greater portion of the total
cost than in our other application benchmarks. As a
result, Circuit ORAM becomes competitive earlier than
in the other cases. We did not benchmark linear scan for
the recommended parameters; we estimated that it would
require roughly 7 days to complete, well beyond what
could reasonably be considered useful in practice.

Even with Square-root ORAM, scrypt requires 55,000
times longer to execute with real-world parameters as
an MPC protocol than it does to execute conventionally.
This is almost certainly too expensive to be practical
for any interactive application today, but shows that
even complex algorithms designed intentionally to be
expensive to execute are not beyond the capabilities of
general-purpose MPC today.

VI. CONCLUSION

The success of MPC depends upon enabling de-
velopers to create efﬁcient privacy-preserving applica-
tions, without requiring excessive effort, expertise, or

231231

resources. It is important that MPC protocols be com-
patible with conventional programming techniques and
data structures with depend on random access memory.
Our Square-Root ORAM design provides a general-
purpose oblivious memory that can be used anywhere
a programmer would normally use an array. We have
presented a new approach for designing ORAMs for
MPC, which demonstrates how hierarchical ORAM de-
signs can be implemented efﬁciently, and how they can
overcome the high initialization costs and parameter
restrictions of previous ORAM designs. This represents
a step towards a programing model for MPC in which
standard algorithms can be efﬁciently implemented as
MPCs, using oblivious memory just like conventional
memory is used today.

ACKNOWLEDGMENTS

We would like to thank Yilei Chen and Oxana
Poburinnaya for engaging discussions during the early
phases of this work. The Gale-Shapley benchmark was
suggested by abhi shelat.

This work was partially supported by grants from
the National Science Foundation SaTC program (Xiao
Wang and Jonathan Katz supported in part by NSF
Award CNS-1111599; Jack Doerner, David Evans, and
Samee Zahur supported in part by NSF Award CNS-
1111781), the Air Force Ofﬁce of Scientiﬁc Research,
and Google. Work of Mariana Raykova, Samee Zahur
and Xiao Wang was done in part while at SRI In-
ternational and was supported by NSF awards CNS-
1421102,1633282 and CCF-1423296. Work of Adrià
Gascón was supported by the SOCIAM project, funded
by the UK Engineering and Physical Sciences Research
Council (EPSRC) under grant EP/J017728/2, and the
NSF award CCF-1423296.

REFERENCES

[1] Arash Afshar, Zhangxiang Hu, Payman Mohassel, and Mike
Rosulek. How to Efﬁciently Evaluate RAM Programs with
Malicious Security. In EUROCRYPT, 2015.

[2] Gilad Asharov, Yehuda Lindell, Thomas Schneider, and Michael
Zohner. More Efﬁcient Oblivious Transfer and Extensions for
Faster Secure Computation. In ACM Conference on Computer
and Communications Security, 2013.

[3] Mihir Bellare, Viet Tung Hoang, Sriram Keelveedhi, and Phillip
Rogaway. Efﬁcient Garbling from a Fixed-Key Blockcipher. In
IEEE Symposium on Security and Privacy, 2013.

[4] Vincent Bindschaedler, Muhammad Naveed, Xiaorui Pan, Xi-
aoFeng Wang, and Yan Huang. Practicing Oblivious Access on
Cloud Storage: the Gap, the Fallacy, and the New Way For-
ward. In ACM Conference on Computer and Communications
Security, 2015.

[5] Marina Blanton, Aaron Steele, and Mehrdad Alisagari. Data-
oblivious Graph Algorithms for Secure Computation and Out-
sourcing. In ACM Symposium on Information, Computer and
Communications Security, 2013.

[6] Ivan Damgård, Matthias Fitzi, Eike Kiltz, Jesper Buus Nielsen,
and Tomas Toft. Unconditionally Secure Constant-rounds
Multi-Party Computation for Equality, Comparison, Bits and
Exponentiation. In Theory of Cryptography, 2006.

[7] Sky Faber, Stanislaw Jarecki, Sotirios Kentros, and Boyang Wei.
Three-Party ORAM for Secure Computation. In ASIACRYPT,
2015.

[8] David Gale and Lloyd S. Shapley. College Admissions and the
Stability of Marriage. The American Mathematical Monthly,
69(1):9–15, 1962.

[9] Craig Gentry, Kenny A Goldman, Shai Halevi, Charanjit Julta,
Mariana Raykova, and Daniel Wichs. Optimizing ORAM
In Privacy
and Using it Efﬁciently for Secure Computation.
Enhancing Technologies, 2013.

[10] Craig Gentry, Shai Halevi, Charanjit Jutla, and Mariana
Raykova. Private Database Access with HE-over-ORAM Archi-
tecture. In Applied Cryptography and Network Security, 2015.
[11] Oded Goldreich, Silvio Micali, and Avi Wigderson. How to Play
any Mental Game or A Completeness Theorem for Protocols
In ACM Symposium on the Theory of
with Honest Majority.
Computing, 1987.

[12] Oded Goldreich and Rafail Ostrovsky. Software Protection and
Simulation on Oblivious RAMs. Journal of the ACM, 43(3),
1996.

[13] Michael T. Goodrich and Michael Mitzenmacher. Privacy-
Preserving Access of Outsourced Data via Oblivious RAM Sim-
ulation. In International Colloquium on Automata, Languages
and Programming, 2011.

[14] Michael T. Goodrich, Michael Mitzenmacher, Olga Ohrimenko,
and Roberto Tamassia. Privacy-preserving Group Data Access
via Stateless Oblivious RAM Simulation. In ACM-SIAM Sym-
posium on Discrete Algorithms, 2012.

[15] S. Dov Gordon, Jonathan Katz, Vladimir Kolesnikov, Fernando
Krell, Tal Malkin, Mariana Raykova, and Yevgeniy Vahlis. Se-
cure Two-Party Computation in Sublinear (Amortized) Time. In
ACM Conference on Computer and Communications Security,
2012.

[16] Yan Huang, David Evans, and Jonathan Katz. Private Set Inter-
section: Are Garbled Circuits Better than Custom Protocols? In
Network and Distributed Systems Security Symposium, 2012.

[17] Yan Huang, David Evans, Jonathan Katz, and Lior Malka.
Faster Secure Two-Party Computation using Garbled Circuits.
In USENIX Security Symposium, 2011.

[18] Marcel Keller and Peter Scholl. Efﬁcient, Oblivious Data

Structures for MPC. In ASIACRYPT, 2014.

[19] Vladimir Kolesnikov, Ahmad-Reza Sadeghi, and Thomas
Improved garbled circuit building blocks and ap-
In Cryptology

Schneider.
plications to auctions and computing minima.
and Network Security, pages 1–20. Springer, 2009.

[20] Vladimir Kolesnikov and Thomas Schneider.

Improved Gar-
bled Circuit: Free XOR Gates and Applications. Automata,
Languages and Programming, 2008.

[21] Eyal Kushilevitz, Steve Lu, and Rafail Ostrovsky. On the
(In)security of Hash-Based Oblivious RAM and a New Bal-
In ACM-SIAM Symposium on Distributed
ancing Scheme.
Algorithms, 2012.

[22] Litecoin Project. scrypt.cpp. https://github.com/litecoin-project/

litecoin/blob/master-0.10/src/crypto/scrypt.cpp, 2015.

232232

[23] Chang Liu, Yan Huang, Elaine Shi, Jonathan Katz, and
Michael W. Hicks. Automating Efﬁcient RAM-Model Secure
In IEEE Symposium on Security and Privacy,
Computation.
2014.

[24] Chang Liu, Xiao Shaun Wang, Kartik Nayak, Yan Huang, and
Elaine Shi. ObliVM: A Programming Framework for Secure
In IEEE Symposium on Security and Privacy,
Computation.
2015.

[25] Steve Lu and Rafail Ostrovsky. Distributed Oblivious RAM
for Secure Two-Party Computation. In Theory of Cryptography
Conference, 2013.

[26] Dahlia Malkhi, Noam Nisan, Benny Pinkas, and Yaron Sella.
In

Fairplay — a Secure Two-Party Computation System.
USENIX Security Symposium, 2004.

[27] Colin Percival. Stronger key derivation via sequential memory-
hard functions. http://www.tarsnap.com/scrypt/scrypt.pdf, 2009.
[28] Benny Pinkas and Tzachy Reinman. Oblivious RAM Revisited.

In CRYPTO 2010, 2010.

[29] Benny Pinkas, Thomas Schneider, Nigel P. Smart, and
Stephen C. Williams. Secure Two-Party Computation Is Prac-
tical. In ASIACRYPT, 2009.

[30] Elaine Shi, T.-H. Hubert Chan, Emil Stefanov, and Mingfei
In

Li. Oblivious RAM with O((logN)3) Worst-Case Cost.
ASIACRYPT 2011, 2011.

[31] Ebrahim M. Songhori, Siam U. Hussain, Ahmad-Reza Sadeghi,
Thomas Schneider, and Farinaz Koushanfar. TinyGarble: Highly
Compressed and Scalable Sequential Garbled Circuits. In IEEE
Symposium on Security and Privacy, 2015.

[32] Emil Stefanov, Marten van Dijk, Elaine Shi, Christopher W.
Fletcher, Ling Ren, Xiangyao Yu, and Srinivas Devadas. Path
ORAM: An Extremely Simple Oblivious RAM Protocol.
In
ACM Conference on Computer and Communications Security,
2013.

[33] Abraham Waksman. A Permutation Network. Journal of the

ACM, 15(1), January 1968.

[34] Xiao Wang, Hubert Chan, and Elaine Shi. Circuit ORAM: On

Tightness of the Goldreich-Ostrovsky Lower Bound. In ACM
Conference on Computer and Communications Security, 2015.
[35] Xiao Shaun Wang, S. Dov Gordon, Allen McIntosh, and
Jonathan Katz. Secure Computation of MIPS Machine Code.
Cryptology ePrint Archive, Report 2015/547, 2015. http://eprint.
iacr.org/2015/547.

[36] Xiao Shaun Wang, Yan Huang, T.-H. Hubert Chan, Abhi Shelat,
and Elaine Shi. SCORAM: Oblivious RAM for Secure Compu-
tation. In ACM Conference on Computer and Communications
Security, 2014.

[37] Peter Williams and Radu Sion. Single Round Access Privacy
on Outsourced Storage. In ACM Conference on Computer and
Communications Security, 2012.

[38] Andrew Chi-Chih Yao. How to Generate and Exchange Secrets
In IEEE Symposium on Foundations of

(Extended Abstract).
Computer Science, 1986.

[39] Samee Zahur and David Evans. Circuit Structures for Improving
Efﬁciency of Security and Privacy Tools. In IEEE Symposium
on Security and Privacy, 2013.

[40] Samee Zahur and David Evans. Obliv-C: A Lightweight
Compiler for Data-Oblivious Computation. Cryptology ePrint
Archive, Report 2015/1153, 2015. http://oblivc.org.

[41] Samee Zahur, Mike Rosulek, and David Evans. Two Halves
Make a Whole - Reducing Data Transfer in Garbled Circuits
Using Half Gates. In EUROCRYPT, 2015.

APPENDIX

Figure 11 shows the actual Obliv-C source code of
our ORAM construction, copied verbatim. The obliv
keyword denotes secret variables. The variable ram→cpy
is a structure with block size and copy constructor
information. Since block size is only known at run-
time, a pointer to array[i] must be obtained by calling
element(ram→cpy, array, i). The actual Obliv-C code
closely follows the pseudocode presented in Figure 5.

233233

static void∗ element(OcCopy∗ cpy, void∗ arr, int i) obliv

{ return i ∗ cpy→eltsize + (char∗)arr; }

void ocSqrtOramAccess(OcSqrtOram∗ ram, obliv int index,

ocBlockAccessFunction fn, void∗ data)

{

int i;
obliv bool foundi = false;
// Scan through stash
for (i=0; i<ram→time; ++i) obliv if (index == ram→stashi[i])
{ fn(ram→cpy, element(ram→cpy, ram→stash, i), data);

found=true;

}

// Fake/unfake posmap lookup
int lookupIndex = ram→pos→getPos(ram→pos, index, found);

// Access one more element from shufﬂed array
ocCopy(ram→cpy, element(ram→cpy, ram→stash, ram→time),
element(ram→cpy, ram→shuff, lookupIndex));
ram→usedShuff[lookupIndex] = true;
ram→stashi[ram→time] = ram→shufﬁ[lookupIndex];
obliv if(!found)
ram→time++;
if (ram→time == ram→period) {

fn(ram→cpy, element(ram→cpy, ram→stash, ram→time), data);

ocSqrtOramRefresh(ram);

}

}

Fig. 11: Obliv-C implementation of the Access function of our ORAM construction

234234

