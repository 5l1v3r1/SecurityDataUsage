Foundations of Garbled Circuits

Mihir Bellare

Dept of CS and Engineering

UC San Diego, USA

Viet Tung Hoang

Dept of Computer Science

UC Davis, USA

Phillip Rogaway

Dept of Computer Science

UC Davis, USA

ABSTRACT
Garbled circuits, a classical idea rooted in the work of Yao,
have long been understood as a cryptographic technique, not
a cryptographic goal. Here we cull out a primitive corre-
sponding to this technique. We call it a garbling scheme. We
provide a provable-security treatment for garbling schemes,
endowing them with a versatile syntax and multiple secu-
rity deﬁnitions. The most basic of these, privacy, suﬃces
for two-party secure function evaluation (SFE) and private
function evaluation (PFE). Starting from a PRF, we provide
an eﬃcient garbling scheme achieving privacy and we ana-
lyze its concrete security. We next consider obliviousness and
authenticity , properties needed for private and veriﬁable out-
sourcing of computation. We extend our scheme to achieve
these ends. We provide highly eﬃcient blockcipher-based
instantiations of both schemes. Our treatment of garbling
schemes presages more eﬃcient garbling, more rigorous anal-
yses, and more modularly designed higher-level protocols.

Categories and Subject Descriptors
D.4.6 [Software]: Security and Protection—cryptography;
E.3 [Data]: Data Encryption—symmetric encryption

Keywords
Garbled circuits, garbling schemes, provable security, secure
function evaluation, Yao’s protocol

INTRODUCTION

1.
Overview.
This paper is about elevating garbled cir-
cuits from a cryptographic technique to a cryptographic goal.
While circuit garbling has traditionally been viewed as a
method for achieving SFE (secure function evaluation) or
some other cryptographic goal, we view it as an end goal
in its own right, deﬁning garbling schemes and formaliz-
ing several notions of security for them, these encompassing
privacy, authenticity, and obliviousness. This enables more
modular use of garbled circuits in higher-level protocols and

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

grounds follow-on work, including the development of new
and highly eﬃcient schemes.
History. The idea of a garbled circuit is due to A. Yao,
who described the technique in oral presentations [18] (p. 27)
about SFE [50, 51]. The ﬁrst written account of the method
is by Goldreich, Micali, and Wigderson [19]. The protocol
they describe, crediting Yao [50], involves associating two
tokens to each wire of a boolean circuit, these having hidden
semantics of 0 and 1. Means are then provided to propa-
gate tokens across a gate, preserving the hidden semantics.
More speciﬁcally, there’s a four-row table for each gate of
the circuit, each row employing public-key encryption to en-
crypt a pair of random strings whose xor is the token for the
outgoing wire.

The term garbled circuit is from Beaver, Micali, and Rog-
away [10], where the method was ﬁrst based on a symmetric
primitive. Garbled circuits took on a modern, PRF-based in-
stantiation in work by Naor, Pinkas, and Sumner on privacy-
preserving auctions [40].

Yao’s idea has been enormously impactful, engendering
numerous applications, implementations, and reﬁnements.
Still, there has been little deﬁnitional attention paid to gar-
bled circuits themselves. Lindell and Pinkas [35] provide the
ﬁrst proof of Yao’s protocol—to the extent one can say that
a particular scheme is Yao’s—but, even there, the authors do
not formalize garbled circuits or what it means to securely
create one.
Instead, they prove that a particular garbled-
circuit-using protocol, one based on double encryption [18],
is a secure two-party SFE. Implemented SFE methods do not
coincide with what’s in Lindell and Pinkas [35], and absence
of a good abstraction boundary makes daunting the task of
providing a full proof for what’s actually in optimized SFE
implementations.

Scattered throughout the enormous literature dealing with
garbled circuits, several papers do work to abstract out what
these provide. A ﬁrst set of such work begins with Feige,
Kilian, and Naor [15] and is followed by [8, 13, 28, 30]. Each
paper aims to modularly use garbled circuits in some intend-
ing application. To that end, they single out, deﬁnitionally,
precisely what they need, usually arriving at something close
to what we will later call “prv.sim security over Φcirc.” None
of the papers pick up deﬁnitions from any other, nor does
any prove that any particular construction satisﬁes the no-
tion given. The conceptualization of garbling as involving
a component that creates garbled circuits and another that
evaluates them is found in all of these works, and in Schnei-
der’s [47, 48]. A second line of deﬁnitions begins with Ishai
and Kushilevitz [25] and continues with [2, 3, 5, 6, 26, 27, 46].

784These works deﬁne various ﬂavors of randomized encodings.
Their authors do see randomized encodings as a general-
purpose primitive, and the deﬁnitions elegantly support a
variety of theory-centered work. However, they lack the
ﬁne-grained syntax that we shall need to investigate oblivi-
ousness, authenticity, and precise measures of eﬃciency. Fi-
nally, in concurrent work, Kamara and Wei oﬀer deﬁnitions
to support their idea of garbling structured circuits [29]. See
Appendix A for further discussion of selected related work.
Contributions. We formalize what we call a garbling
scheme. The notion is designed to support a burgeoning and
practical area: the myriad applications of garbled circuits.
Our deﬁnitions and results enable easy and widespread ap-
plications with modular, simpliﬁed, and yet more rigorous
proofs of security.
Roughly said, a garbling algorithm Gb is a randomized al-
gorithm that transforms a function f : {0, 1}n → {0, 1}m
into a triple of functions (F, e, d) ← Gb(f ). We require that
f = d ◦ F ◦ e. The encoding function e turns an initial input
x ∈ {0, 1}n into a garbled input X = e(x). Evaluating the
garbled function F on the garbled input X gives a garbled
output Y = F (X). The decoding function d turns the gar-
bled output Y into the ﬁnal output y = d(Y ), which must
coincide with f (x). Informally, one has probabilistically fac-
tored f into d◦F ◦e. Formally, it is problematic to regard Gb
as operating on functions. Thus a garbling scheme G = (Gb,
En, De, Ev, ev) is regarded as a ﬁve-tuple of algorithms, with
strings d, e, f , and F interpreted as functions under the
auspices of functions De, En, ev, and Ev. See Fig. 1.

Our syntactic framework is representation-independent;
circuits are nowhere to be found. One can garble DFAs,
OBDDs, RAMs, TMs, whatever; deﬁnitionally, this isn’t
even seen. See Section A, “Eclectic representations.”

Of course none of this says anything about the desired
security notion. We deﬁne several. The most important is
privacy: a party acquiring (F, X, d) shouldn’t learn anything
impermissible beyond that which is revealed by knowing just
the ﬁnal output y. To formalize that which it is permissi-
ble to reveal, a side-information function, Φ, parameterizes
the deﬁnition; an adversary should be able to ascertain from
(F, X, d) nothing beyond Φ(f ) and y. By varying Φ one
can encompass the customary setting for SFE (let Φ(f ) = f ;
circuit f is not concealed) and PFE (private function eval-
uation) (let Φ(f ) be the number of gates of f ; leak just the
circuit’s size). We formalize privacy in multiple ways, giving
an indistinguishability deﬁnition, prv.ind, and a simulation-
based one, prv.sim. We show that whether or not they are
equivalent depends on the side-information function Φ. For
the most important ones the notions are equivalent (in gen-
eral, they are not).

We provide a simple garbling scheme, Garble1, for achiev-
ing privacy. The scheme is conveniently described in terms
of a dual-key cipher (DKC), a notion we put forward. We
deﬁne a DKC’s security and prove privacy for Garble1 un-
der this assumption. Garble1 is described with uncustomary
precision, including a detailed and precise deﬁnition of cir-
cuits. We show how to make a DKC from a pseudorandom
function (PRF), and how to realize the PRF using a con-
ventional blockcipher, say AES128. In this way we obtain
a provably secure, blockcipher-based garbling scheme where
circuit evaluation takes two AES calls per gate.

We go on to suggest a still more eﬃcient instantiation for
the dual-key cipher, one where evaluating a garbled circuit

needs only one AES128 call per gate and all blockcipher
invocations use the same key. This is the fastest approach
now known for garbling circuits.

Beyond privacy we consider obliviousness: a party acquir-
ing F and X, but not d, shouldn’t learn anything about f , x,
or y. As with privacy, we formalize obliviousness in diﬀerent
but “usually” equivalent ways. Next we explore authenticity:
a party who learns F and X should be unable to produce a
garbled output Y
diﬀerent from F (X) that is deemed to be
) (cid:6)= ⊥. Our interest in obliviousness and authen-
valid: d(Y
ticity was sparked by Gennaro, Gentry, and Parno [17]; the
notions arise in the context of private, veriﬁable outsourcing
of computation.

∗

∗

We prove implications and separation among all security
notions we have mentioned, painting a complete picture of
deﬁnitions for this space. See Fig. 2.

We deﬁne a protocol, Garble2, to simultaneously achieve
privacy, obliviousness, and authenticity. The assumption re-
quired is the same as before. The scheme is only a bit more
complex than Garble1, the eﬃciency, only a little worse.
Discussion. Once viewed as a “theoretical” approach for
multiparty computation, a long line of work, beginning with
Fairplay [37], has made clear that circuit garbling is now
a practical technique. State-of-the-art implementations by
Huang et al. and Kreuter et al. can handle complex func-
tionalities and hundreds of millions of gates [23, 24, 32]. We
aim to support such work, and applications further aﬁeld.
With a protocol’s garbling scheme delineated, implementa-
tions can more reasonably oﬀer proofs for the actual scheme
employed, the “messy” optimizations stripped of surround-
ing interaction and protocol aims. In general, an approach
where the garbling scheme is conceptually separated from
its use seems essential for managing complexity in this do-
main. As an analog, authenticated encryption took oﬀ after
it was reconceptualized as a primitive, not a method formed
of encryption schemes and MACs.

Garble1 and Garble2 are close to numerous other protocols
(especially [40]) that incarnate Yao’s idea. Given this, one
might assume that, once good deﬁnitions are written down,
proving security would be easy, based on prior work [35].
From our experience, this is not the case; the proofs we
provide are not implicit in prior work.

One thing novel about our schemes is that they admit
eﬃcient AES-based instantiations whose quantitative secu-
rity may be inferred via the concrete security bounds as-
sociated to our theorems.
In the past, SFE schemes sup-
ported by proofs would use objects less eﬃciently realizable
in practice [35], or, for practical realizations, would aban-
don proven-secure schemes and use hash-based ones, some-
times with an unproven claim that security is maintained in
the random-oracle model. Given the increasing ubiquity of
AES hardware support, we believe that optimized, proven,
blockcipher-based schemes are a good direction.

This paper is the ﬁrst of several we envision.

In it we
aim to instill fresh, practice-oriented foundations in an area
where, historically, omitted deﬁnitions and proofs have been
the norm. The current work maintains a circumscribed fo-
cus: to investigate the deﬁnitions central to the reconceptu-
alization of garbling schemes as a sui generis cryptographic
goal. Upcoming work will explore several directions:

We can construct extremely eﬃcient garbling schemes,
like the one-call, ﬁxed-key, AES128-based scheme we men-
tioned. This can be done in a way that does not preclude

7851k

f

G b

F

e

d

x

x

En

X

Ev

Y

ev

De

y

y

Figure 1: Components of a garbling scheme G = (Gb, En, De, Ev, ev). Function Gb maps f and k to (F, e, d), strings
encoding the garbled function, the encoding function, and the decoding function. Possession of e and x lets
one compute the garbled input X = En(e, x); having F and X lets one calculate the garbled output Y = Ev(F, X);
and knowing d and Y lets one recover the ﬁnal output y = De(d, Y ), which must equal ev(f, x).

Protocol

Application

Needs

Over

prv.sim

obv.sim

aut

I
E

 
)
v
e
 
,

φ
(
 
f
i

I
E
φ

 

 
f
i

prv.ind

obv.ind

Figure 2: Relations among security notions. A solid
arrow is an implication; an if-labeled arrow, a con-
ditional implication; a hatched arrow, a separation.

the free-xor and row-elimination techniques that have
proven so eﬀective [23, 31, 44]. Proofs remain complex,
even in the random-permutation model.
Implementa-
tions are underway, these achieving about 15 nsec/gate.
We can generalize security to the adaptive (=dynamic)
setting. This is needed for one-time programs [20] and
secure outsourcing [17]. For one ﬂavor of adaptivity,
prv1/obv1/aut1, the input x may depend on the garbled
function F . For ﬁner-grained notions, prv2/obv2/aut2,
each bit of x can depend on previously acquired Xi-
values. Transformations turn prv/obv/aut schemes into
prv1/obv1/aut1 ones and these into prv2/obv2/aut2 ones.
Building on the oft-described metaphor of lockboxes and
keys (eg, [35] (pp. 163–164)), we can formulate garbling-
scheme security using a formal treatment of dual-key en-
ciphering. We choose to do this by absorbing the func-
tionality of the ideal primitive into the code-based deﬁ-
nition. Privacy, obliviousness, and authenticity become
yes/no matters—no probabilities.

For all of these directions, the framework developed here
serves as the needed starting point.

A thesis underlying our deﬁnitions is that they work —that
most (though not all) applications described as using gar-
bled circuits can be built from an arbitrary garbling scheme,
instead. To date we have surveyed 20 papers containing pro-
tocols that can be recast to use a generic garbling scheme.
See Fig. 3. In all cases we gain in simplicity and modularity.
Applications beneﬁt from the increased eﬃciency of our gar-
bling schemes. The improvement is particularly marked in
the application to KDM encryption (security with respect to

prv
2-party SFE (sh)
Y86 [18]
Φcirc
prv
PFE (sh)
AF90 [1]
Φsize
prv
server-aided SFE (sh)
FKN94 [15]
Φcirc
prv
private auctions
NPS99 [40]
Φcirc
2-party SFE (ma)
prv
KO04 [30]
Φcirc
private credit checking prv
FAZ05 [16]
Φsize
prv
2-party SFE (ma)
FM06 [38]
Φcirc
prv
2-party SFE (covert)
AL07 [7]
Φcirc
prv
LP07 [34]
2-party SFE (ma)
Φcirc
GKR08 [20] one-time programs
prv2
Φsize
prv
GMS08 [21] 2-party SFE (co)
Φcirc
BFK+09 [9] priv medical diag
obv
Φcirc
private credit checking prv
PSS09 [41]
Φtopo
BHHI10 [8] KDM encryption
prv
Φsize
aut1 + obv1 Φcirc
GGP10 [17] auth outsourcing
Φcirc
prv
HS10 [22]
Φsize
prv
SS10 [46]
Ap11 [2]
prv
Φsize
Φcirc
KMR11 [28] server-aided SFE (ma) aut + obv
LP11 [36]
Φcirc

2P guaranteed SFE
worry-free encryption
KDM encryption

2-party SFE (ma)

prv

Figure 3: Recasting protocols in more generic terms.
so = semi-honest; co = covert; ma = malicious. All
but [17] need the scheme to be projective.

key-dependent messages), where use of our abstraction leads
to substantial eﬃciency gains over the use of the abstractions
in previous work [2, 8].

2. PRELIMINARIES
Notation. We let N be the set of positive integers. A
string is a ﬁnite sequence of bits and ⊥ is a formal sym-
If A is a ﬁnite set then y (cid:2) A
bol that is not a string.
denotes selecting an element of A uniformly at random and
assigning it to y. If A is an algorithm then A(x1, . . .; r) de-
notes the output of A on inputs x1, . . . and coins r, while
y ← A(x1, . . .) means we pick r uniformly at random and let
y ← A(x1, . . .; r). We let [A(x1, . . .)] denote the set of y that
have positive probability of being output by A(x1, . . .). We

786−c for all k > K.

write Func(a, b) for {f:{0, 1}a → {0, 1}b}. Polynomial time
(PT) is always measured in the length of all inputs, not just
the ﬁrst. (But random coins, when singled out as an argu-
ment to an algorithm, are never regarded as an input.) As
usual, a function ε : N → R
+ is negligible if for every c > 0
there is a K such that ε(k) < k
Code-based games. Our deﬁnitions and proofs are ex-
pressed via code-based games [12] so we recall here the lan-
guage and specify the particular conventions we use. A
code-based game—see Fig. 4 for an example—consists of an
Initialize procedure, procedures that respond to adversary
oracle queries, and a Finalize procedure. All procedures
are optional. In an execution of game Gm with an adver-
sary A, the latter is given input 1k where k is the security
parameter, and the security parameter k used in the game is
presumed to be the same. Procedure Initialize, if present,
executes ﬁrst, and its output is input to the adversary, who
may now invoke other procedures. Each time it makes a
query, the corresponding game procedure executes, and what
it returns, if anything, is the response to A’s query. The ad-
versary’s output is the input to Finalize, and the output
of the latter, denoted Gm
(k), is called the output of the
game. Finalize may be absent in which case it is under-
stood to be the identity function, so that the output of the
(k) ⇒ c”
game is the output of the adversary. We let “Gm
denote the event that this game output takes value c and
(k) ⇒ true.” Boolean
let “Gm
ﬂags are assumed initialized to false and BAD(GmA(k)) is
the event that the execution of game Gm with adversary A
sets ﬂag bad to true.
Circuits. While our deﬁnitions for garbling schemes are
representation-independent, the garbling schemes we specify
assume a circuit-based representation. Here we specify the
conventions and deﬁnitions that make this formal.

(k)” be shorthand for “Gm

A

A

A

A

There are several reasons why it is important to cleanly
deﬁne circuits (which, for many reasons, are not just DAGs).
First, there are many “boundary cases” where only conven-
tions can decide if something is or is not a valid circuit. The
boundary cases matter; we have repeatedly found that de-
generate or under-analyzed circuit types materially impact
if a garbling scheme is correct. Beyond this, a lack of agree-
ment on what a circuit is makes even informal discourse
problematic. Finally, we have found that it is simply not
possible to properly specify a circuit-garbling algorithm or
a circuit-evaluation function, nor to carry out code-based
game-playing proofs, without circuits being formalized. As
an added payoﬀ, if one establishes good conventions for cir-
cuits, then these same conventions can be used when deﬁning
a garbled circuit and its evaluation function.
A circuit is a 6-tuple f = (n, m, q, A, B, G). Here n ≥ 2 is
the number of inputs, m ≥ 1 is the number of outputs and
q ≥ 1 is the number of gates. We let r = n+q be the number
of wires. We let Inputs = {1, . . . , n}, Wires = {1, . . . , n + q},
OutputWires = {n + q − m + 1, . . . , n + q}, and Gates =
{n + 1, . . . , n + q}. Then A : Gates → Wires\OutputWires is
a function to identify each gate’s ﬁrst incoming wire and B :
Gates → Wires\OutputWires is a function to identify each
gate’s second incoming wire. Finally G : Gates × {0, 1}2 →
{0, 1} is a function that determines the functionality of each
gate. We require A(g) < B(g) < g for all g ∈ Gates.

The conventions above embody all of the following. Gates
have two inputs, arbitrary functionality, and arbitrary fan-

out. The wires are numbered 1 to n + q. Every non-input
wire is the outgoing wire of some gate. The ith bit of input is
presented along wire i. The ith bit of output is collected oﬀ
wire n + q − m + i. The outgoing wire of each gate serves as
the name of that gate. Output wires may not be input wires
and may not be incoming wires to gates. No output wire
may be twice used in the output. Requiring Ag < Bg < g
ensures that the directed graph corresponding to f is acyclic,
and that no wire twice feeds a gate; the numbering of gates
comprise a topological sort.

We will routinely ignore the distinction between a circuit
f = (n, m, q, A, B, G) as a 6-tuple and the encoding of such
a 6-tuple as a string; formally, one assumes a ﬁxed and rea-
sonable encoding, one where |f| is O(r log r) for r = n + q.
We deﬁne a canonical evaluation function evcirc. It takes a
string f and a string x = x1x2 ·· ·x n:

01 proc evcirc(f, x)
02 (n, m, q, A, B, G) ← f
03 for g ← n + 1 to n + q do
04
05 return xn+q−m+1 . . . xn+q

a ← A(g), b ← B(g), xg ← G(xa, xb)

At line 02 we adopt the convention that any string f can be
parsed as a circuit. (If f does not encode a circuit, we view
it as some ﬁxed, default circuit.) This ensures that evcirc is
well-deﬁned for all string inputs f . At line 04, xa and xb will
always be well deﬁned because of A(g) < B(g) < g. Circuit
evaluation takes linear time.

−

−

−

We say f

is a topological circuit if f

= (n, m, q, A, B)
for some circuit f = (n, m, q, A, B, G). Thus a topological
circuit is like a conventional circuit except the functionality
of the gates is unspeciﬁed. Let Topo be the function that
expunges the ﬁnal component of its circuit-valued argument,
so f
= Topo(f ) is the topological circuit underlying con-
ventional circuit f .
3. GARBLING SCHEMES
Syntax. A garbling scheme is a ﬁve-tuple of algorithms
G = (Gb, En, De, Ev, ev). The ﬁrst of these is probabilistic;
the remaining algorithms are deterministic. A string f , the
original function, describes the function ev(f,·) : {0, 1}n →
{0, 1}m that we want to garble. The values n = f.n and m =
f.m depend on f and must be easily computable from it.
Speciﬁcally, ﬁx linear-time algorithms n and m to extract
f.n = n(f ) and f.m = m(f ). On input f and a security
parameter k ∈ N, algorithm Gb returns a triple of strings
(F, e, d) ← Gb(1k, f ). String e describes an encoding func-
tion, En(e,·), that maps an initial input x ∈ {0, 1}n to a
garbled input X = En(e, x). String F describes a garbled
function, Ev(F,·), that maps each garbled input X to a gar-
bled output Y = Ev(F, X). String d describes a decoding
function, De(d,·), that maps a garbled output Y to a ﬁnal
output y = De(d, Y ).
We levy some simple requirements on garbling schemes.
First, |F|, |e|, and |d| may depend only on k, f.n, f.m,
and |f|. Formally, if f.n = f
(cid:3)|,
(cid:3)
.n, f.m = f
(F, e, d) ∈ [Gb(1k, f )], and (F
(cid:3)
(cid:3)
, e
, d
)], then
|F| = |F
(cid:3)|, and |d| = |d
(cid:3)|. This is the length condi-
tion. Second, e and d may depend only on k, f.n, f.m, |f|
(cid:3)
and the random coins r of Gb. Formally, if f.n = f
.n, f.m =
.m, |f| = |f
(cid:3)|, (F, e, d) = Gb(1k, f ; r), and (F
(cid:3)
(cid:3)
, e
f
) =
(cid:3)
Gb(1k, f
. This is the nondegen-
eracy condition. Finally, if f ∈ {0, 1}∗
, k ∈ N, x ∈ {0, 1}f.n,

) ∈ [Gb(1k, f

.m, |f| = |f
(cid:3)

(cid:3)|, |e| = |e

; r), then e = e

and d = d

(cid:3)

(cid:3)

, d

(cid:3)

(cid:3)

(cid:3)

(cid:3)

787and (F, e, d) ∈ [Gb(1k, f )], then De(d, Ev(F, En(e, x))) =
ev(f, x). This is the correctness condition.
We say that a garbling scheme G = (Gb, En, De, Ev, ev) is
a circuit-garbling scheme if ev interprets f as a circuit: for-
mally, ev = evcirc for the canonical circuit-evaluation function
that we deﬁned in Section 2.

n, X 1

1 , X 1

1 , . . . , X 0

Projective schemes.
A common approach in exist-
ing garbling schemes is for e to encode a list of tokens,
one pair for each bit in x ∈ {0, 1}n. Encoding function
En(e,·) then uses the bits of x = x1 · ·· xn to select from e =
(X 0
1 , . . . , X xn
n ).
Formally, we say that garbling scheme G = (Gb, En, De,
(cid:3) ∈ {0, 1}f.n, k ∈ N,
Ev, ev) is projective if for all f , x, x
and i ∈ [1..n], when (F, e, d) ∈ [Gb(1k, f )], X = En(e, x)
and X
), then X = (X1, . . . , Xn) and X
=
i|, and Xi = X
(cid:3)
(cid:3)
(X
i if x
(cid:3)
and x

= En(e, x
n) are n vectors, |Xi| = |X
(cid:3)

n) the subvector X = (X x1

have the same ith bit.

(cid:3)
1, . . . , X

(cid:3)

(cid:3)

(cid:3)

Our deﬁnitions of security do not require schemes be pro-
jective. However, this property is needed for some important
applications. For example, SFE combines a projective gar-
bling scheme and a scheme for oblivious transfer.
Side-information functions. Privacy is rarely absolute;
semantically secure encryption, for example, is allowed to
reveal the length of the plaintext. Similarly, a garbled cir-
cuit might reveal the size of the circuit that was garbled, its
topology (that is, the graph of how gates are connected up),
or even the original circuit itself. The information that we
expect to be revealed is captured by a side-information func-
tion, Φ, which deterministically maps f to a stringφ = Φ(f ).
We will parameterize our advantage notions by Φ, and in
this way simultaneously deﬁne garbling schemes that may
reveal a circuit’s size, topology, identity, or more. We re-
quire that f.n and f.m be easily determined from φ = Φ(f );
formally, there must exist linear-time algorithms n(cid:3)
and m(cid:3)
that compute f.n = n(cid:3)
(φ) = m(f )
when φ = Φ(f ). We also require that |f| be easily deter-
mined from Φ(f ).

(φ) = n(f ) and f.m = m(cid:3)

Speciﬁc side-information functions are useful for circuit
garbling. Side-information function Φsize reveals the num-
ber of inputs, outputs, and gates of a circuit f ; formally,
Φsize(f ) = (n, m, q) for a circuit f = (n, m, q, A, B, G). Side-
information function Φtopo reveals the topological circuit but
not the functionality of each gate: Φtopo(f ) = (n, m, q, A, B),
with notation and conventions as above. Side-information
function Φcirc reveals the entire circuit: Φcirc(f ) = f .
Privacy. Let G = (Gb, En, De, Ev, ev) be a garbling scheme,
k ∈ N a security parameter, and Φ a side-information func-
tion. We deﬁne an indistinguishability-based notion of pri-
vacy via game PrvIndG,Φ (top-left of Fig. 4) and a simulation-
based notion of privacy via game PrvSimG,Φ,S (top-right of
Fig. 4, where S is a simulator). Executing either game with
an adversary requires one to specify the garbling scheme, ad-
versary, security parameter, and side-information function.
Executing game PrvSim additionally requires one to specify
the algorithm S.
Refer ﬁrst to game PrvIndG,Φ. Adversary A gets input 1k
and must make exactly one Garble query. That query is an-
swered as speciﬁed in the game, the security parameter used
here being the same as the one provided to the adversary.
The adversary must eventually halt, outputting a bit b
, and
the game’s Finalize procedure determines if the adversary
has won on this run, namely, if b = b
. The corresponding

(cid:3)

(cid:3)

advantage is deﬁned via

Adv

prv.ind, Φ
G

(A, k) = 2 Pr[PrvInd
G,Φ(k)] − 1,
A

the probability, normalized to [0, 1], that the adversary cor-
rectly predicts b. Protocol G is prv.ind secure over Φ if for
every PT adversary A the function Adv
(A,·) is neg-
ligible.

prv.ind, Φ
G

Explaining the deﬁnition, the adversary chooses (f0, x0)
and (f1, x1) such that Φ(f0) = Φ(f1) and, also, ev(f0, x0) =
ev(f1, x1). The game picks challenge bit b and garbles fb to
(F, e, d). It encodes xb as the garbled input X = Ene(xb).
The adversary is handed (F, X, d), which determines y =
De(d, Ev(F, En(e, xb))) = ev(fb, xb). The adversary must
guess b. In a scheme we deem secure, it should be unable to
ascertain which of (f0, x0), (f1, x1) got garbled.
Next we deﬁne prv.sim security via game PrvSimG,Φ,S as-
sociated to garbling scheme G, information function Φ and
an algorithm S called a simulator. The adversary B is run
on input 1k and must make exactly one Garble query. The
query is answered as speciﬁed in Fig. 4, with k being the
same as the input to the adversary. The adversary must
eventually output a bit, and the game’s Finalize procedure
indicates if the adversary has won—again, if the adversary
correctly predicted b. The adversary’s advantage is

prv.sim, Φ,S
G

(B, k) = 2 Pr[PrvSim
G,Φ,S (k)] − 1 ,
B

Adv

prv.sim, Φ,S
G

the probability, normalized to [0, 1], that the adversary wins.
Protocol G is prv.sim secure over Φ if for every PT adversary
B there is a PT algorithm S such that Adv
(B, k)
is negligible.
Let us again explain. For the prv.sim notion we let the
adversary choose (f, x). Either we garble it to (F, e, d) ←
Gb(1k, f ) and X ← En(e, x), handing the adversary (F, X, d),
or else we ask the simulator to devise a “fake” (F, X, d) based
solely on k, φ = Φ(f ), and y = ev(f, x). From this limited
information the simulator must produce an (F, X, d) indis-
tinguishable, to the adversary, from the ones produced using
the actual garbling scheme.

The indistinguishability deﬁnition for garbling schemes is
simpler due to the absence of the simulator, but we con-
sider this notion “wrong” when the side-information func-
tion is such that indistinguishability is inequivalent to the
simulation-based deﬁnition. See Section 4.

Obliviousness.
Informally, a garbling scheme achieves
obliviousness if possession of a garbled function F and gar-
bled input X lets one compute the garbled output Y , yet
(F, X) leaks nothing about f or x beyond Φ(f ). Contrast-
ing this with privacy, there the agent evaluating the garbled
function does learn the output; here, she learns not even
that, as a needed piece of information, d, is withheld. Pri-
vacy and obliviousness are both secrecy notions, and cut
from the same cloth. Yet they will prove incomparable: a
private scheme could divulge the output even without d; an
oblivious scheme could reveal too much once d is shown.

As with privacy, we formalize two notions, obv.ind and
obv.sim, via the games of Fig. 4. The formalizations consider
games ObvIndG,Φ and ObvSimG,Φ,S , run with adversaries
A and B, respectively. As usual the adversary gets input
1k and the security parameter used in the game is also k.
The adversary makes a single call to the game’s Garble
procedure and outputs a bit b

(cid:3)

Adv

obv.ind, Φ
G
obv.sim, Φ, S
G

Adv

. We deﬁne
(A, k) = 2 Pr[ObvInd
G,Φ(k))] − 1
A
(B, k) = 2 Pr[ObvSim
G,Φ,S (k)] − 1
B

and

788Game PrvIndG,Φ

proc Garble(f0, f1, x0, x1)
if Φ(f0) (cid:6)= Φ(f1) then return ⊥
if {x0, x1} (cid:6)⊆ {0, 1}f0.n then return ⊥
if ev(f0, x0) (cid:6)= ev(f1, x1) then return ⊥
b (cid:2){0, 1}; (F, e, d) ← Gb(1k, fb); X ← En(e, xb)
return (F, X, d)

proc Garble(f0, f1, x0, x1)
if Φ(f0) (cid:6)= Φ(f1) then return ⊥
if {x0, x1} (cid:6)⊆ {0, 1}f0.n then return ⊥
b (cid:2){0, 1};
return (F, X)

(F, e, d) ← Gb(1k, fb); X ← En(e, xb)

Game ObvIndG,Φ

proc Garble(f, x)
b (cid:2){0, 1}
if x (cid:6)∈ {0, 1}f.n then return ⊥
if b = 1 then (F, e, d) ← Gb(1k, f ); X ← En(e, x)

Game PrvSimG,Φ,S

else y ← ev(f, x); (F, X, d) ← S(1k, y,Φ( f ))

return (F, X, d)

proc Garble(f, x)
b (cid:2){0, 1}
if x (cid:6)∈ {0, 1}f.n then return ⊥
if b = 1 then (F, e, d) ← Gb(1k, f ); X ← En(e, x)

Game ObvSimG,Φ,S

else (F, X) ← S(1k, Φ(f ))

proc Garble(f, x)
(F, e, d) ← Gb(1k, f ); X ← En(e, x)
return (F, X)

return (F, X)

proc Finalize(Y )
return (De(d, Y ) (cid:6)= ⊥ and Y (cid:6)= Ev(F, X))

Game AutG

Figure 4: Games for deﬁning the prv.ind, prv.sim, obv.ind, obv.sim, and aut security of a garbling scheme
G = (Gb, En, De, Ev, ev). Here S is a simulator, Φ is an information function and k is the security parameter input
to the adversary. Procedure Finalize(b

) of the ﬁrst four games returns (b = b

).

(cid:3)

(cid:3)

as the probability, normalized to [0, 1], that adversary’s out-
put is a correct guess of the underlying bit b. Protocol G
is obv.ind secure over Φ if for every PT adversary A, we
(A, k) is negligible. It is obv.sim se-
have that Adv
cure over Φ if for every PT adversary B there exists a PT
simulator S such that Adv

(B,·) is negligible.

obv.sim, Φ, S
G

obv.ind, Φ
G

Let us explain the diﬀerence between prv.ind and obv.ind.
First, we no longer demand that ev(f, x0) = ev(f, x1): the
adversary may now name any (f0, x0) and (f1, x1) as long
as the functions have the same side information. Second,
the decoding function d is no longer provided to the adver-
sary. The adversary must guess if (F, X) stems from garbling
(f0, x0) or (f1, x1).

Similarly, the diﬀerence between prv.sim and obv.sim is
two-fold. First, in the obliviousness notion the simulator
is denied y = ev(f, x); it must create a convincing (F, X)
without that. Second, the simulator no longer returns to the
adversary the (simulated) decoding function d; the return
value is (F, X) and not (F, X, d).

Authenticity.
So far we have dealt exclusively with se-
crecy notions. One can formalize an authenticity property
as well [17], which we do via game AutG of Fig. 4. Au-
thenticity captures an adversary’s inability to create from a
garbled function F and its garbled input X a garbled out-
put Y (cid:6)= F (X) that will be deemed authentic.
Fix a garbling scheme G = (Gb, En, De, Ev, ev), adversary
A, and security parameter k ∈ N. Run adversary A on
input 1k, allowing it a single call to the Garble procedure
of the game. The adversary outputs a string Y , and, when
it does, the game’s Finalize procedure is called to decide
if the adversary has won. The adversary’s aut-advantage is
deﬁned as AdvautG (A, k) = Pr[Aut
G (k)]. Protocol G is aut-
A
secure if for all PT adversaries A, AdvautG (A,·) is negligible.
Sets of garbling schemes. To compactly and precisely
express relations between notions we will write them as con-
tainments and non-containments between sets of garbling
schemes. To this end, for xxx ∈ {prv.ind, prv.sim, obv.ind,
obv.sim} we let GS(xxx, Φ) be the set of all garbling schemes

that are xxx-secure over Φ. Similarly, we let GS(aut) be the
set of all garbling schemes that are aut-secure.
We also let GS(ev) be the set of all garbling schemes G =
(Gb, En, De, Ev, ev) whose evaluation function is ev. This
captures garbling schemes for a particular class of functions.
As per our previous notation, GS(evcirc) now denotes the set
of all circuit-garbling schemes.

4. RELATIONS

We show that prv.sim always implies prv.ind, and prv.ind
implies prv.sim under certain added conditions on the side-
information function. We show that the same holds for
obv.ind and obv.sim, under a weaker assumption on the side-
information function. The conditions on the side-information
function are relatively mild. We will also justify the non-
implications for the security notions compactly summarized
in Fig. 2. As part of this we will show that prv.ind does not
always imply prv.sim and obv.ind does not always imply
obv.sim.

Invertibility of side-information functions.
Let Φ
be a side-information function. An algorithm M is called
a Φ-inverter if on input φ in the range of Φ it returns a
preimage under Φ of that point, meaning a string f such
that Φ(f ) = φ. Such an inverter always exists, but it might
not be eﬃcient. We say that Φ is eﬃciently invertible if there
is a polynomial-time Φ-inverter. Similarly, an algorithm M
(cid:3)
is called a (Φ, ev)-inverter if on input (φ, y), where φ = Φ(f
)
and y = ev(f
.n, returns an
(f, x) satisfying Φ(f ) = φ and ev(f, x) = y. We say that
(Φ, ev) is eﬃciently invertible if there is a polynomial-time
(Φ, ev)-inverter.

and x ∈ {0, 1}f

) for some f

, x

(cid:3)

(cid:3)

(cid:3)

(cid:2)

The following theorem summarizes the invertibility at-
tributes of the circuit-related size-information functions we
deﬁned earlier. It shows that all side-information functions
Φcirc, Φtopo, and Φsize are eﬃciently invertible, and that,
(Φsize, evcirc) and (Φtopo, evcirc) are eﬃciently invertible.

789Proposition 1. For Φ ∈ {Φsize, Φtopo, Φcirc}, there is a
linear-time inverter. For Φ ∈ {Φsize, Φtopo} there is a linear-
time (Φ, evcirc)-inverter.

In contrast, there is no eﬃcient (Φcirc, evcirc)-inverter (under
a computational assumption); consider the case where f is
drawn from a family implementing a one-way function.

Equivalence of prv.ind and prv.sim.
The following
says that prv.sim implies prv.ind security, and conversely
if (Φ, ev) is eﬃciently invertible. The proof is in the full
paper [11].

Proposition 2. For any PT Φ:

(1) GS(prv.sim, Φ) ⊆
GS(prv.ind, Φ) and (2) If (Φ, ev) is eﬃciently invertible then
GS(prv.ind, Φ) ∩ GS(ev) ⊆ GS(prv.sim, Φ) ∩ GS(ev).
The ﬁrst part says that if garbling scheme G is prv.sim se-
cure over Φ then G is prv.ind secure over Φ. The second
part says that if garbling scheme G = (Gb, En, De, Ev, ev)
is prv.ind secure over Φ and (Φ, ev) is eﬃciently invertible
then G is prv.sim secure over Φ. In the full version [11], we
show that eﬃcient invertibility of (Φ, ev) is required to prove
that prv.ind implies prv.sim, so the notions are not always
equivalent.
A corollary of Propositions 1 and 2 is that prv.sim and
prv.ind are equivalent for circuit-garbling schemes over Φtopo
and Φsize, which we summarize as:

Corollary 1. For Φ ∈ {Φtopo, Φsize}, GS(prv.ind, Φ) ∩

GS(evcirc) = GS(prv.sim, Φ) ∩ GS(evcirc).

Equivalence of obv.ind and obv.sim.
The following
says that obv.sim implies obv.ind security, and conversely
if Φ is eﬃciently invertible. The invertibility condition is
thus weaker than in the privacy case.

Proposition 3. For any PT Φ: (1) GS(obv.sim, Φ) ⊆
GS(obv.ind, Φ) and (2) If Φ) is eﬃciently invertible then
GS(obv.ind, Φ) ⊆ GS(obv.sim, Φ).

In the full version of this paper [11], we show that Φ being
eﬃciently invertible is required to prove that obv.ind implies
obv.sim. But the side-information function Φ we use is arti-
ﬁcial; for any “reasonable” one we know, obv.ind and obv.sim
will be equivalent.
Again a corollary of Propositions 1 and 3 is that obv.sim
and obv.ind are equivalent for circuit-garbling schemes over
side-information functions Φcirc, Φtopo and Φsize:

Corollary 2. GS(obv.ind, Φ) = GS(obv.sim, Φ), for any

Φ ∈ {Φtopo, Φsize, Φcirc}.

5. ACHIEVING PRIVACY

We provide a simple, privacy-achieving circuit-garbling
scheme, Garble1. It is described in terms of a new primitive,
a dual-key cipher (DKC). We will prove security of Garble1
assuming the security of its DKC. We will then show how
to instantiate a DKC using a PRF. Instantiating this PRF
via AES leads to an eﬃcient garbling scheme. Diﬀerently in-
stantiating the DKC directly with AES can give even better
eﬃciency.
Dual key ciphers. Before describing Garble1 we will need
to specify the syntax of a DKC. These objects formalize a

two-key lockbox—one where you need both keys to open the
box. This has long been used as a metaphor to explain how
garbling schemes work (e.g., [35] (pp. 163–164)), but Lindell
and Pinkas also give a notion of double-encryption security
for two-key probabilistic encryption schemes [35] (pp. 170).
Dual-key ciphers provide a very diﬀerent way to formalize
an object suﬃcient to construct garbling schemes.
Formally, a dual-key cipher is a function E that asso-
ciates to any k ∈ N, any keys A, B ∈ {0, 1}k and any tweak
A,B : {0, 1}k → {0, 1}k. Let
T ∈ {0, 1}τ (k) a permutation E
A,B : {0, 1}k → {0, 1}k denote the inverse of this permuta-
tion. It is required that the maps (A, B, T, P) (cid:12)→ E
A,B(P) and
(A, B, T, C) (cid:12)→ D
A,B(C) be polynomial-time computable. We
refer to τ as the tweak length of E.

D

T

T

T

T

The deﬁnition above describes syntax alone. We postpone

giving a security deﬁnition until we’ve deﬁned Garble1.

Definition of Garble1.
Let E be a dual-key cipher
with tweak length τ . We associate to E the garbling scheme
Garble1[E] as shown in Fig. 5. Wires carry k-bit tokens. A
token X will encode a one-bit type. Rather arbitrarily, the
type is the ﬁnal bit of the token, namely its LSB. When
we write T ← g (cid:13) a(cid:13) b (line 106 and 155) where g ∈ N and
a, b ∈ {0, 1}, we mean that g mod 2τ (k)−2 is encoded as a
(τ (k) − 2)-bit string and a(cid:13) b is concatenated, yielding a
τ (k)-bit tweak. The ev function (lines 140–145) is precisely
evcirc; the code is repeated for completeness and to make
visible the commonality with Ev (lines 150–156).

1 , . . . , X xn

To garble a circuit, we begin selecting two tokens for each
wire, one of each type. One of these will represent 0—the
token is said to have semantics of 0—while the other will
represent 1. The variable X b
i names the token of wire i
with semantics (not type!) of b. Thus the encoding func-
tion e (see lines 120–123) will map x = x1 ···x n ∈ {0, 1}n to
X = (X x1
n ). For each wire i that is not an output
wire, we select, at line 102, random tokens of opposite type,
making the association between a token’s type and its se-
mantics random. For each wire i that is an output wire, we
again select random tokens of opposite types, but this time
the token’s type is the token’s semantics.
Lines 104–106 compute q garbled truth tables, one for each
gate g. Table P [g,·,·] has four rows, entry a, b the row to
use when the left incoming token is of type a and the right
incoming token is of type b. The token that gets encrypted
for this row (line 106) is the token for the outgoing-wire with
the correct semantics. At lines 154–155, given two tokens Xa
and Xb we use their types to determine which entry of the
propagation table we need to decrypt. The description of
the decoding function d (line 109) is empty because no in-
formation is needed to map an output token to its semantics,
the type being the semantics.
Security notion for dual-key ciphers. We already
A,B : {0, 1}k →
deﬁned the syntax of a DKC, a permutation E
{0, 1}k for each A, B, T. Our deﬁnition of security will allow
the adversary to select whichever of the two keys it wants to
learn. We will hand it not only that key but, also, the last of
the undisclosed key. (This corresponds to the type bit in runs
of Garble1). We consider only nonadaptive, known-plaintext
attacks. These plaintexts will be either the disclosed keys or
truly random strings. We prohibit encryption cycles. During
the adversary’s attack, the tweaks used must be nonces—
values used at most once.
More formally, the security of a DKC E : {0, 1}k×{0, 1}k×

T

790(n, m, q, A, B, G) ← f
for i ∈ {1, . . . , n + q − m} do t (cid:2){0, 1}, X 0
for i ∈ {n + q − m + 1, . . . , n + q} do X 0
for (g, i, j) ∈ {n + 1, . . . , n + q} × {0, 1} × {0, 1} do

i (cid:2){0, 1}k−1t X 1

i (cid:2){0, 1}k−10, X 1

i (cid:2) {0, 1}k−1t
i (cid:2) {0, 1}k−11

100 proc Gb(1k, f )
101
102
103
104
105
106
107 F ← (n, m, q, A, B, P )
1 , . . . , X 0
108
109 d ← ε
110

a ← A(g), b ← B(g)
A ← X i

e ← (X 0

return (F, e, d)

1 , X 1

n, X 1
n)

a, a ← lsb(A), B ← X j

b , b ← lsb(B), T ← g (cid:13) a(cid:13) b, P [g, a, b] ← E

(cid:2)
X Gg (i,j)

g

(cid:3)

T
A,B

(X 0

120 proc En(e, x)
121
122 X ← (X x1
return X
123

1 , X 1

1 , . . . , X 0

n) ← e
n, X 1
1 , . . . , X xn
n )

140 proc ev(f, x)
141
142
143
144
145

(n, m, q, A, B, G) ← f
for g ← n + 1 to n + q do

a ← A(g), b ← B(g)
x ← Gg(xa, xb)

return xn+q−m+1 . . . xn+q

130 proc De(d, Y )
131 (Y1, . . . , Ym) ← Y
132 for i ∈ {1, . . . , m} do yi ← lsb(Yi)
133 return y ← y1 ···y m
150 proc Ev(F, X)
151
152
153
154
155
156

(n, m, q, A, B, P ) ← F
for g ← n + 1 to n + q do

return (Xn+q−m+1, . . . , Xn+q)

a ← A(g), b ← B(g)
A ← Xa, a ← lsb(A), B ← Xb, b ← lsb(B)
T ← g (cid:13) a(cid:13) b, Xg ← D

(cid:2)
(cid:3)
P [g, a, b]

T
A,B

Game DKC

return lsb(K)

K2i (cid:2){0, 1}k−1 0
K2i−1 (cid:2){0, 1}k−1 1

proc Initialize()
b (cid:2){0, 1}, K (cid:2) {0, 1}k, R1, R2, . . . (cid:2){0, 1}k
for i ∈ {1, 2 . . .} do

Figure 5: Garbling scheme Garble1. Its components are (Gb, En, De, Ev, ev) where ev, shown for completeness,
is the canonical circuit evaluation. We assume a DKC E with tweak length τ and let D denote its inverse.
At line 102, we use {0, 1}k−1t and {0, 1}k−1t to refer to the sets of k-bit binary strings whose last bit is t and t
respectively.
{0, 1}τ (k) × {0, 1}k → {0, 1}k is speciﬁed using the game
of Fig. 6. The game starts by choosing a bit b (cid:2) {0, 1}
and a key K (cid:2){0, 1}k. It chooses inﬁnitely many random
strings K1, K2, . . . such that the last bit of Ki is i mod 2. It
chooses inﬁnitely many random strings R1, R2, . . .. Except
for the last bit of K, the key K shall be kept secret. The
strings K1, K2, . . . are initially secret, but the adversary A
will eventually learn them through its queries. The random
strings R1, R2, . . ., used only in the “reference game” when
b = 0, are secret. We require that the adversary A be non-
adaptive, that is, it prepares all queries before interrogating
In each query, adversary A has to spec-
the DKC oracle.
ify an integer i indicating that it wants to use {K, Ki} as
keys of the dual-key cipher for this query, and an integer j,
indicating that it wants to encrypt the string Kj . We re-
quire that i < j to avoid encryption cycles. It also speciﬁes
a boolean pos to indicate the position, left or right, of the
secret key K. Finally, it provides a tweak T, which must
be a nonce. If b = 1 then the oracle returns the encryption
of Kj to the adversary. If b = 0 then the oracle returns the
encryption of Rj . When adversary A outputs a bit b
its
(k)] − 1. We say
advantage is Advdkc
E (A, k)
that E is a secure dual-key cipher if ε(k) = Advdkc
is negligible for every nonadaptive PPT adversary A whose
input is 1k and the bit returned by Initialize.
Discussion.
By way of further explanation, ciphertexts
T1
T2
K,K1 (X1), E
K2,K(X2), . . . should be indistinguishable from
E
random strings as long as K is secret and the tweaks T1, T2, . . .
are nonces—even if random values Ki and Xj are all dis-
closed. We demand that this hold even if the last bit of K
is released to the adversary and the adversary can actively
choose the last bit of each Ki.

A subtle issue arises when the adversary happens to pos-
T2
K2,K(X). One may be tempted to
sess, say E
require that the two ciphertexts be indistinguishable from
two independent random strings. This, however, would not
T
A,B(X) = EA(EB(X)) for an ideal ci-
allow instantiations like E
pher E. Instead, we choose a secret Y (cid:2)M, where M is the
T2
K2,K (X)
message space, and demand that E
be indistinguishable from E

proc Encrypt(i, j, pos, T)
if used[T] or i ≥ j then return ⊥
used[T] ← true
if pos = 1 then (A, B) ← (K, Ki) else (A, B) ← (Ki, K)
if b = 1 then X ← Kj else X ← Rj
return (Ki, Kj , E

T
Figure 6: Security of a DKC. Cipher E
A,B has a tweak
and two keys, only one of which, K, its position cho-
sen by the adversary, is secret. The ﬁnal bit of K is
disclosed. Procedure Finalize(b

The deﬁnitional intricacies for dual-key ciphers arise from
wanting to require of a DKC little more than what is actually

T1
K1,K (X) and E
T2
K2,K (Y ).

E (A, k) = 2 Pr[DKC
A

T1
K1,K (Y ) and E

T1
K1,K (X) and E

) returns (b = b

T
A,B(X))

).

(cid:3)

(cid:3)

(cid:3)

791needed to prove Garble1. Too strong a deﬁnition for DKC
security and interesting instantiations will be lost.
Security of Garble1. Our deﬁnition of DKC security
suﬃces to prove security for Garble1. The result is stated
below and proven in the full version of this paper [11].

Theorem 1. Let E be a secure dual-key cipher. Then

G = Garble1[E] ∈ GS(prv.ind, Φtopo).

E (D, k) ≥ 1

The theorem is underlain by an explicit, blackbox, uniform
if A(1k) outputs circuits of at most r
reduction U s.t.
wires and fan-out at most ν, then D = U
A
achieves advan-
(A, k) and makes
tage Advdkc
Q ≤ 2ν oracle queries, with E[Q] < 4. It runs in time about
that of A plus the time for 4r computations of E on k-bit
keys. The small overhead implicit in the word “about” is
manifest in the proof. The above assumes that r ≤ 2τ (k)−2.
In asymptotic statements, r and ν are understood as poly-
nomials r(k) and ν(k).

prv.ind, Φtopo
G

2r Adv

We comment that Garble1 does not satisfy obliviousness
or authenticity. To defeat obliviousness, an adversary can
just make the query (AND, OR, 00, 11) to receive (F, X),
and then evaluate Y = Ev(F, X), returning 1 if De(ε, Y ) = 1
and 0 otherwise. This adversary has advantage 1. To defeat
authenticity, an adversary can query (OR, 11), and then
output (0k, 0k). Again it has advantage 1. We will soon
describe Garble2 that satisﬁes obliviousness and authenticity
in addition to privacy.

The primitive used by Lindell and Pinkas [35] as a basis for
encryption of gate entries is a randomized, IND-CPA secure
symmetric encryption scheme with an elusive and eﬃciently
veriﬁable range. Dual-key ciphers, in contrast, are deter-
ministic. Our PRF-based instantiation avoids probabilistic
encryption. Besides speed it results in shorter ciphertexts
for each row of each gate. The additional properties of en-
cryption assumed by [35] are to allow the evaluator to know
which gate entry is the “correct” one. Our solution via type
bits (the “point-and-permute” technique, which dates to Ro-
gaway [45]) is well known.
Dual-key ciphers from a PRF. Our primary interest will
be in instantiating a dual-key cipher via a PRF. Let F asso-
ciate to key K ∈ {0, 1}k−1 a map FK : {0, 1}τ (k) → {0, 1}k.
We require that the map K, T (cid:12)→ FK(T) be polynomial-time
computable. We refer to τ as the input length.
The prf-advantage of an adversary D against F is deﬁned
F (k)] − 1 where game PRFF is
D
as Adv
as follows. Initialize picks a random bit b and a random
(k − 1)-bit key K. The adversary has access to procedure Fn
that maintains a table Tbl[·] initially everywhere undeﬁned.
Given T ∈ {0, 1}τ (k), the procedure returns F(K, T) if b = 1.
Otherwise, it picks and returns Tbl[T] (cid:2){0, 1}k if Tbl[T] =
⊥, or returns Tbl[T] if Tbl[T] (cid:6)= ⊥. Finalize(b
(cid:3)
) returns
F (D,·) is
prf
). We say that F is PRF-secure if Adv
(b = b
negligible for all polynomial-time adversaries D.

F (D, k) = 2 Pr[PRF

prf

Given a PRF F as above, we deﬁne the dual-key cipher
A,B(P ) = FA[1:k−1](T) ⊕ FB[1:k−1](T) ⊕ P . This dual-
E via E
key cipher has tweak length τ and is denoted E[F]. During
evaluation, token types are revealed, but the entire key of F
remains secret.

The following result establishes that E[F] is a good DKC
when F is a good PRF. The reduction is tight and explicit.
More speciﬁcally, the proof provides a blackbox reduction
such that for any adversary A(1k) attacking E[F] there is

(cid:3)

T

an adversary B(1k) attacking F for which Adv
F (B, k) =
E[F](A, k). If A makes Q queries to Encrypt then B
0.5 Advdkc
also makes Q queries to the PRF oracle Fn. The running
time of B is about that of A, where the meaning of “about”
is manifest in the proof that appears in the full version of
this paper [11].

prf

Theorem 2. Let F be a PRF. Then E[F] is a secure dual-

key cipher.

The instantiation of a DKC E by way of E[F] is by no
means the only reasonable instantiation, nor the only one
that can be proven secure. We now investigate further in-
stantiations, going all the way to a blockcipher.
Dual-key ciphers from double encryption. We also
prove the dkc-security of the instantiation E[E] in which
T
A,B(X) = EA(EB(X)), with E being an ideal cipher.
In
E
the theorem below, we will show that if an adversary A
makes Q queries to the Encrypt oracle, and qE queries to
E[E](A, k) ≤ (10Q2 + 4Q + 8qE)/2k.
E and E
The above assumes that Q + qE ≤ 2k−3.

−1 then Advdkc

Theorem 3. Let E be an ideal cipher. Then E[E] is a

secure dual-key cipher.

The proof is found in the full version of this paper [11].

Unwinding the results.
One needs to be careful in
combining Theorems 1 and 3 to obtain a good bound on
the security of Garble1 when instantiated with a DKC made
by double encryption. Let adversary A attack Gb1[E[E]]
and assume A(1k) outputs circuits of at most r ≤ 2τ (k)−2
wires and fan-out at most ν. Suppose it makes at most qE
−1 and that 2ν + qE ≤ 2k−3. Then, from
queries to E and E
Theorems 1 and 3, there is a random variable 0 < Q ≤ 2ν
such that E[Q] < 4 and

Adv

prv.ind, Φtopo

Garble1[E[E]] (A, k)

2

≤ r
2k
≤ r
2k

· (20E[Q
] + 8E[Q] + 16qE )
· (20E[2νQ] + 8E[Q] + 16qE)
< 160rν/2k + 32r/2k + 16rqE /2k .

prv.ind, Φtopo
G

The bound is quite satisfactory. Above, the expectation
E[Q] appears in the ﬁrst inequality because our advantage
if an ad-
notion satisﬁes the following linearity condition:
versary A behaves as adversary A1 with probability p, and
behaves like A2 otherwise, then Adv
(A, k) =
prv.ind, Φtopo
G
(A2, k).
(A1, k) + (1 − p)Adv
prv.ind, Φtopo
G
p Adv
AES-based instantiations. We now consider concrete
instantiations. This means we ﬁx a value k of the security
parameter and suggest ways to realize E on k-bit keys based
on blockciphers, speciﬁcally AES. Security for these instan-
tiations can be derived via the concrete security bounds that
we stated above following Theorem 1. Diﬀerent choices of
instantiation lead to diﬀerent tradeoﬀs between assumptions
and eﬃciency. We begin with ways to instantiate F on (k−1)-
bit keys:

792Let FK(T) be the ﬁrst k bits of EK(T(cid:13) 0) (cid:13) EK(T(cid:13) 1) for
a blockcipher E having block length and key length of
(k − 1); to be concrete, E = AES128, k = 129, |K| = 128,
and τ = |T| = 127. This construction is a good PRF
under the standard assumption that E is a good PRP.
With this instantiation, evaluating a garbled gate costs
four AES operations.
Let FK(T) be EK(cid:4)0(T) for a blockcipher having a k-bit key
and block size, say E = AES128 and k = τ = |T| =
128 and |K| = 127. Assuming that E is a good PRP is
not enough to prove that F is a good PRF, as zeroing
out a bit of the key does not, in general, preserve PRF
security [42]. Still, it seems reasonable to directly assume
this F is a good PRF. Costs are halved compared to the
above; now, evaluating a garbled gate requires two AES
operations.

Next we suggest some further ways to make the dual-key ci-
pher E directly, meaning not via a PRF. The ﬁrst follows the
double-encryption realization of garbled gates attributed to
Yao by Goldreich [18] (which would have been understood
that primitive to be probabilistic, not a blockcipher). The
second method is extremely eﬃcient—the most eﬃcient ap-
proach now known. Implementation work is currently un-
derway to measure the magnitude of the gain:

T

T

A,B(P) = EA(EB(P)) (the tweak is ignored), where
Let E
E : {0, 1}k × {0, 1}k → {0, 1}k is a blockcipher, say
AES128. For a proof we would model E as an ideal ci-
pher. Composition of encryption schemes is understood
by many researchers to be Yao’s original approach, al-
though the earliest expositions make this seem doubtful.
A,B(P) = Econst(K) ⊕ K ⊕ P where K = A ⊕ B ⊕ T
Let E
and E = AES128, say, and const is a ﬁxed 128-bit string.
Here k = τ = 128. With this instantiation evaluating a
gate costs only 1 AES operation. Even more important,
all AES operations employ a single, ﬁxed key. This allows
one to take full advantage of AES-NI hardware support
to get extremely high speeds. For a proof, we would
model Econst(·) as a random permutation π, giving the
adversary access to oracles for π and its inverse.

Other one-call, ﬁxed-key schemes are possible, for oblivious-
ness, authenticity, and dynamic security, and adjustments to
allow the free-xor and row-reduction optimizations [31, 44].
Basing garbled-circuit evaluation on AES and employing
AES-NI in an implementation was also suggested by Kreuter,
Shelat, and Shen [32]. They use AES-256, rekeying with gate
evaluation.

6. AUTHENTICITY & OBLIVIOUSNESS

We now describe a scheme Garble2 that satisﬁes not only
privacy but also obliviousness and authenticity. The scheme
is like Garble1 except, ﬁrst, the last bit of a token is always
uniform, even for output wires. This will give obliviousness.
Next, the string encoding the decoding function is made to
list all the tokens for all the output wires, ordered to make
clear which tokens have what semantics. This engenders
authenticity. See Fig. 7.

Talking through some of the pseudocode, line 202 now
assigns a token with random semantics to each and every
wire. Lines 203–207 compute the garbled function F and
encoding function e exactly as with Garble1. Line 208 now
records the vector of tokens for each of the m output wires.
(Recall that, under our conventions, the last m of the r total

wires are the output wires, these providing the m output
bits, in order.) At lines 230–235 decoding procedure De,
when presented a 2m-vector d and an m-vector Y , veriﬁes
that each component of the latter is in the corresponding
set of two allowed values.
If so, we determine the correct
semantics for this output bit using our convention that Y b
i
has semantics b.

Scheme Garble2 simultaneously achieves privacy, oblivi-
ousness, and authenticity if instantiated in the same manner
as we instantiated Garble1. This is captured by the following
result; the proof appears in the full version of the paper [11].
Again, as per Corollary 2 it does not matter whether we
consider ind or sim, and for simplicity we pick the former.

Theorem 4. Let E be a secure dual-key cipher. Then
G = Garble2[E] ∈ GS(prv.ind, Φtopo) ∩ GS(obv.ind, Φtopo) ∩
GS(aut).

Again this asymptotic claim is underlain by concrete black-
box reductions and concrete bounds as follows. There are
blackbox reductions Uxxx for xxx ∈ {prv.ind, obv.ind, aut}
s.t. if A(1k) outputs circuits of at most r wires and fan-out
at most ν, and then D = U
achieves xxx-advantage of
at least ε, then D = U
A
xxx achieves dkc-advantage at least
ε/2r − 21−k, makesQ ≤ 2ν oracle queries, with E[Q] < 4.
It runs in time about that of A plus the time for 4r compu-
tations of E on k-bit keys.

A

Acknowledgments
This research was supported under NSF grant CNS 0904380;
many thanks to the NSF for their continuing support. The
paper was reﬁned and ﬁrst presented when Rogaway vis-
ited the Isaac Newton Institute for Mathematical Sciences,
a program co-arranged by Nigel Smart. Thanks to Shaﬁ
Goldwasser, Kenny Patterson, and Thomas Schneider for
comments and pleasant interactions.

7. REFERENCES
[1] M. Abadi and J. Feigenbaum. Secure circuit

evaluation. Journal of Cryptology, 2(1):1–12, 1990.

[2] B. Applebaum. Key-dependent message security:

Generic ampliﬁcation and completeness.
EUROCRYPT 2011, volume 6632 of LNCS, pages
527–546. Springer, 2011.

[3] B. Applebaum, Y. Ishai, and E. Kushilevitz.

Computationally private randomizing polynomials and
their applications. Computational Complexity,
15(2):115–162, 2006.

[4] B. Applebaum, Y. Ishai, and E. Kushilevitz.

Cryptography in NC0. SIAM J. Comput.,
36(4):845–888, 2006.

[5] B. Applebaum, Y. Ishai, and E. Kushilevitz. From

secrecy to soundness: Eﬃcient veriﬁcation via secure
computation. ICALP 2010, Part I, volume 6198 of
LNCS, pages 152–163. Springer, 2010.

[6] B. Applebaum, Y. Ishai, and E. Kushilevitz. How to

garble arithmetic circuits. 52nd FOCS, pages 120–129.
IEEE Computer Society Press, 2011.

[7] Y. Aumann and Y. Lindell. Security against covert

adversaries: Eﬃcient protocols for realistic adversaries.
TCC 2007, volume 4392 of LNCS, pages 137–156.
Springer, 2007.

793(n, m, q, A, B, G) ← f
for i ∈ {1, . . . , n + q} do t (cid:2){0, 1}, X 0
for (g, i, j) ∈ {n + 1, . . . , n + q} × {0, 1} × {0, 1} do

i (cid:2) {0, 1}k−1t, X 1

i (cid:2){0, 1}k−1t

a, a ← lsb(A), B ← X j

b , b ← lsb(B), T ← g (cid:13) a(cid:13) b, P [g, a, b] ← E

(cid:2)
X Gg (i,j)

g

(cid:3)

T
A,B

n, X 1
n)
n+q−m+1, . . . , X 0

n+q, X 1

n+q)

200 proc Gb(1k, f )
201
202
203
204
205
206 F ← (n, m, q, A, B, P )
e ← (X 0
1 , X 1
1 , . . . , X 0
207
208 d ← (X 0
n+q−m+1, X 1
209

a ← A(g), b ← B(g)
A ← X i

return (F, e, d)

(X 0

220 proc En(e, x)
221
222 X ← (X x1
return X
223

1 , X 1

1 , . . . , X 0

n) ← e
n, X 1
1 , . . . , X xn
n )

240 proc ev(f, x)
241
242
243
244
245

(n, m, q, A, B, G) ← f
for g ← n + 1 to n + q do

a ← A(g), b ← B(g)
x ← Gg(xa, xb)

return xn+q−m+1 . . . xn+q

(Y1, . . . , Ym) ← Y , (Y 0
for i ∈ {1, . . . , m} do

230 proc De(d, Y )
231
232
233
234
235

return y ← y1 ···y m

if Yi = Y 0
else if Yi = Y 1

1 , Y 1
i then yi ← 0

1 , . . . , Y 0

m, Y 1

m) ← d

i then yi ← 1 else return ⊥

250 proc Ev(F, X)
251
252
253
254
255
256

(n, m, q, A, B, P ) ← F
for g ← n + 1 to n + q do
a ← A(g), b ← B(g)
A ← Xa, a ← lsb(A), B ← Xb, b ← lsb(B)
T ← g (cid:13) a(cid:13) b, Xg ← D

return (Xn+q−m+1, . . . , Xn+q)

(cid:2)
(cid:3)
P [g, a, b]

T
A,B

Figure 7: Garbling scheme Garble2. Its components are (Gb, En, De, Ev, ev) where ev, shown for completeness, is
canonical circuit evaluation. We assume a dual-key cipher E with tweak length τ and let D denote its inverse.

[8] B. Barak, I. Haitner, D. Hofheinz, and Y. Ishai.

Bounded key-dependent message security.
EUROCRYPT 2010, volume 6110 of LNCS, pages
423–444. Springer, 2010.

[9] M. Barni, P. Failla, V. Kolesnikov, R. Lazzeretti,

A.-R. Sadeghi, and T. Schneider. Secure evaluation of
private linear branching programs with medical
applications. ESORICS 2009, volume 5789 of LNCS,
pages 424–439. Springer, 2009.

[10] D. Beaver, S. Micali, and P. Rogaway. The round
complexity of secure protocols. Proceedings of the
twenty-second annual ACM symposium on Theory of
computing, pages 503–513. ACM, 1990.

[11] M. Bellare, V. Hoang, and P. Rogaway. Foundations of

garbled circuits. Cryptology ePrint Archive, Report
2012/265, 2012.

[12] M. Bellare and P. Rogaway. The security of triple

encryption and a framework for code-based
game-playing proofs. EUROCRYPT 2006, volume
4004 of LNCS, pages 409–426. Springer, 2006.

[13] C. Cachin, J. Camenisch, J. Kilian, and J. M¨uller.

One-round secure computation and secure autonomous
mobile agents. 27th Intl. Colloquium on Automata,
Languages, and Programming — ICALP 2000, pages
512–523. Springer, 2000.

[14] M. Chase and S. Kamara. Structured encryption and

controlled disclosure. ASIACRYPT 2010, volume 6477
of LNCS, pages 577–594. Springer, 2010.

[15] U. Feige, J. Kilian, and M. Naor. A minimal model for

secure computation (extended abstract). 26th ACM
STOC, pages 554–563. ACM Press, 1994.

[16] K. Frikken, M. Atallah, and C. Zhang.

Privacy-preserving credit checking. Proceedings of the

6th ACM conference on Electronic commerce, pages
147–154. ACM, 2005.

[17] R. Gennaro, C. Gentry, and B. Parno. Non-interactive

veriﬁable computing: Outsourcing computation to
untrusted workers. CRYPTO 2010, volume 6223 of
LNCS, pages 465–482. Springer, 2010.

[18] O. Goldreich. Cryptography and cryptographic

protocols. Manuscript, 2001.

[19] O. Goldreich, S. Micali, and A. Wigderson. How to

play any mental game, or a completeness theorem for
protocols with honest majority. 19th ACM STOC,
pages 218–229. ACM Press, 1987.

[20] S. Goldwasser, Y. Kalai, and G. Rothblum. One-time

programs. CRYPTO 2008, volume 5157 of LNCS,
pages 39–56. Springer, 2008.

[21] V. Goyal, P. Mohassel, and A. Smith. Eﬃcient two
party and multi party computation against covert
adversaries. EUROCRYPT 2008, volume 4965 of
LNCS, pages 289–306. Springer, 2008.

[22] A. Herzberg and H. Shulman. Secure guaranteed
computation. Cryptology ePrint Archive, Report
2010/449, 2010.

[23] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster

secure two-party computation using garbled circuits.
USENIX Security Symposium, 2011.

[24] Y. Huang, C. Shen, D. Evans, J. Katz, and A. Shelat.

Eﬃcient secure computation with garbled circuits.
ICISS, volume 7093 of Lecture Notes in Computer
Science, pages 28–48. Springer, 2011.

[25] Y. Ishai and E. Kushilevitz. Randomizing polynomials:

A new representation with applications to
round-eﬃcient secure computation. 41st FOCS, pages
294–304. IEEE Computer Society Press, 2000.

794[26] Y. Ishai and E. Kushilevitz. Perfect constant-round

[44] B. Pinkas, T. Schneider, N. P. Smart, and S. C.

secure computation via perfect randomizing
polynomials. ICALP, volume 2380 of Lecture Notes in
Computer Science, pages 244–256. Springer, 2002.

[27] Y. Ishai, E. Kushilevitz, R. Ostrovsky, and A. Sahai.
Cryptography with constant computational overhead.
40th ACM STOC, pages 433–442. ACM Press, 2008.

[28] S. Kamara, P. Mohassel, and M. Raykova.

Outsourcing multi-party computation. Cryptology
ePrint report 2011/272, 2011.

[29] S. Kamara and L. Wei. Special-purpose garbled

circuits. Unpublished manuscript.

[30] J. Katz and R. Ostrovsky. Round-optimal secure

two-party computation. CRYPTO 2004, volume 3152
of LNCS, pages 335–354. Springer, 2004.

[31] V. Kolesnikov and T. Schneider. Improved garbled
circuit: Free XOR gates and applications. ICALP
2008, Part II, volume 5126 of LNCS, pages 486–498.
Springer, 2008.

[32] B. Kreuter, A. Shelat, and C. Shen. Billion-gate secure
computation with malicious adversaries. Proceedings of
the 21th USENIX Security Symposium (USENIX
2012), 2012.

[33] L. Kruger, S. Jha, E. Goh, and D. Boneh. Secure
function evaluation with ordered binary decision
diagrams. ACM CCS 06, pages 410–420. ACM Press,
2006.

[34] Y. Lindell and B. Pinkas. An eﬃcient protocol for

secure two-party computation in the presence of
malicious adversaries. EUROCRYPT 2007, volume
4515 of LNCS, pages 52–78. Springer, 2007.

[35] Y. Lindell and B. Pinkas. A proof of security of Yao’s

protocol for two-party computation. Journal of
Cryptology, 22(2):161–188, 2009.

[36] Y. Lindell and B. Pinkas. Secure two-party

computation via cut-and-choose oblivious transfer.
TCC 2011, volume 6597 of LNCS, pages 329–346.
Springer, 2011.

[37] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella.

Fairplay — a secure two-party computation system.
Proceedings of the 13th conference on USENIX
Security Symposium-Volume 13, pages 20–20. USENIX
Association, 2004.

[38] P. Mohassel and M. Franklin. Eﬃciency tradeoﬀs for
malicious two-party computation. PKC 2006, volume
3958 of LNCS, pages 458–473. Springer, 2006.

[39] M. Naor and K. Nissim. Communication preserving
protocols for secure function evaluation. 33rd ACM
STOC, pages 590–599. ACM Press, 2001.

[40] M. Naor, B. Pinkas, and R. Sumner. Privacy

preserving auctions and mechanism design.
Proceedings of the 1st ACM conference on Electronic
commerce, pages 129–139. ACM, 1999.

[41] A. Paus, A. Sadeghi, and T. Schneider. Practical

secure evaluation of semi-private functions. ACNS 09,
volume 5536 of LNCS, pages 89–106. Springer, 2009.

[42] K. Pietrzak. A leakage-resilient mode of operation.
EUROCRYPT 2009, volume 5479 of LNCS, pages
462–482. Springer, 2009.

[43] B. Pinkas. Cryptographic techniques for

privacy-preserving data mining. ACM SIGKDD
Explorations Newsletter, 4(2):12–19, 2002.

Williams. Secure two-party computation is practical.
ASIACRYPT 2009, volume 5912 of LNCS, pages
250–267. Springer, 2009.

[45] P. Rogaway. The round complexity of secure protocols.

MIT Ph.D. Thesis, 1991.

[46] A. Sahai and H. Seyalioglu. Worry-free encryption:

functional encryption with public keys. ACM CCS 10,
pages 463–472. ACM Press, 2010.

[47] T. Schneider. Engineering Secure Two-Party

Computation Protocols – Advances in Design,
Optimization, and Applications of Eﬃcient Secure
Function Evaluation. PhD thesis, Ruhr-University
Bochum, Germany, February 9, 2011.
http://thomaschneider.de/papers/S11Thesis.pdf.

[48] T. Schneider. Engineering Secure Two-Party

Computation Protocols. Springer, Berlin Heidelberg,
2012.

[49] J. R. Troncoso-Pastoriza, S. Katzenbeisser, and
M. Celik. Privacy preserving error resilient dna
searching through oblivious automata. ACM CCS 07,
pages 519–528. ACM Press, 2007.

[50] A. Yao. How to generate and exchange secrets.

Foundations of Computer Science, 1986., 27th Annual
Symposium on, pages 162–167. IEEE, 1986.

[51] A. C. Yao. Protocols for secure computations. 23rd

FOCS, pages 160–164. IEEE Computer Society Press,
1982.

APPENDIX
A. RELATED WORK

We do not attempt a comprehensive review of the litera-
ture (easily a monograph-length undertaking), but elaborate
on some selected prior work.

Randomized encodings.
Loosely related to garbling
schemes, randomized encodings (initially randomized polyno-
mials) begin with Ishai and Kushilevitz [25] and continue,
with many deﬁnitional variants,
in work by Applebaum,
Ishai, Kushilevitz, and others [2–6, 26, 27, 46]. The authors
function F (·,·) is
employ language like the following [3]:
a randomized encoding of f (·) if:
(correctness) there’s a
PT algorithm De such that De(F (x, r)) = f (x) for almost
all r; and (privacy) there’s a PT algorithm Sim such that
ensembles F (x,·) and Sim(f (x)) are computationally indis-
tinguishable. To be useful, encodings must have some extra
properties, for example, that every bit of F (x, r) depends on
at most one bit of x, a property that has been called decom-
posability [27]. Proven realizations meeting these require-
ments [3, 4] do not closely resemble conventional realizations
of garbled circuits [35, 40].

There is a large gap, even syntactically, between the no-
tion just given and a garbling scheme. Above, no language is
provided to speak of the algorithm that transforms f to F ;
in contrast, the thing doing this transformation is at the cen-
ter of a garbling scheme. Likewise absent from the syntax
of randomized encodings is anything to speak to the repre-
sentation of functions; for garbling schemes, representations
are explicit and central. Finally, the syntax, unlike that of
a garbling scheme, does not separate the garbling of a func-
tion and the creation of a garbled input, and indeed there is
nothing corresponding to the latter, the same input x being

795and obv.sim require one to hide both the input and the func-
tion.
Obscuring topology. We are not the ﬁrst to observe that
conventional means to garble a circuit obscure each gate’s
function but not its topology. A 2002 paper of Pinkas [43]
(Section 2.3) already remarks that “In this form the represen-
tation reveals nothing but the wiring of the circuit”. Later,
Paus, Sadeghi, and Schneider [41] use the phrase “circuit
topology” to name that which is revealed by conventional
garbled circuits. Nevertheless, the topology of a circuit is
never formalized, and nobody ever proves that that some
particular scheme reveals only the topology. We are also
the ﬁrst to explain the equivalence between the prv.sim and
prv.ind notions relative to Φtopo.

Eclectic representations.
Scattered through the lit-
erature one ﬁnds computational objects other than boolean
circuits that are being garbled; examples include arithmetic
circuits [6], branching programs [9], circuits with lookup ta-
bles [39], DFAs [49], and ordered binary decision diagrams
[33]. The range suggests, to us, that general-purpose deﬁni-
tions for garbling schemes ought not be tied to circuits.

Concurrent work.
Concurrent work by Kamara and
Wei (henceforth KW) investigates the garbling of structured
circuits [29], a computational model they put forward resem-
bling ordinary circuits except that gates perform operations
on an arbitrary data structure. As part of this work, KW
deﬁne what they too call a garbling scheme. Their syntax
is similar to ours, but without the function ev. Over this
syntax KW deﬁne Ind1 and Sim1 security. These notions,
unlike ours, ask only for input-hiding, not function hiding.
They show these deﬁnitions are equivalent for sampleable
circuits. KW go on to give dynamic versions of their deﬁni-
tions, Ind2 and Sim2, and an unforgeability notion, Unf2.
These deﬁnitions resemble the weaker form of the dynamic-
security deﬁnitions (prv1, obv1, and aut1) mentioned in our
Introduction and the subject of separate work.

Although KW speak of circuits as ﬁnitary objects de-
scribed by DAGs, they appear to have in mind families of
circuits, indexed by a security parameter (otherwise, we do
not know how to make sense of samplability, or phrases like
polynomial size circuits). Unlike our treatment, circuits are
not provided by the adversary; security notions are with re-
spect to a given circuit. A garbling scheme is provided in
KW, but not a “conventional” one:
it garbles a structured
circuit and is based on a collection of structured encryption
schemes, a notion from Chase and Kamara [14]. For the
protocol to make sense with respect to the deﬁnitions given,
the latter should be reinterpreted as applying to structured
circuits.

fed to f or F . The minimalist syntax of randomized en-
codings works well for some theory-centric applications, but
does not allow one to speak of obliviousness and authentic-
ity, to investigate the low-level eﬃciency of diﬀerent garbling
schemes, and to architect schemes to useful-in-practice ab-
straction boundaries.

1 , X 1

1 , . . . , X xm

m, X 1
1 , . . . , X xm

Given the variety of related deﬁnitions, let us sketch an-
other, the decomposable randomized encodings deﬁned and
used by Sahai and Seyalioglu [46]. (Despite identical names,
this deﬁnition is diﬀerent from that above, and diﬀerent
again from the decomposable randomized encodings of [27],
say). The object of interest can be regarded as a pair of
PT algorithms (En, De) where En maps the encoding of a
boolean circuit f : {0, 1}n → {0, 1}m to a vector of strings
m) ← En(1k, f ) for which decoding al-
(X 0
1 , . . . , X 0
m ) returns f (x1 ···x n). The au-
gorithm De(X x1
thors demand a PPT algorithm Sim for which the ensem-
m ) tuples induced by En(1k, f ) and x is
ble of (X x1
computationally indistinguishable from Sim(1k, n,| f|, f (x)).
Translating to our language, one has eﬀectively assumed a
projective scheme, a boolean circuit as input, and prv.sim
security over Φsize. The garbled function itself has been
abstracted out of existence (in a realization,
it would be
dropped in the X j
i values). Compared to a garbling scheme,
one might note the lack of representation independence, gran-
ularity inadequate to speak of obliviousness, authenticity,
garbled inputs, and low-level eﬃciency. The syntax can’t
handle the dynamic setting, where the adversary receives
the garbled circuit before it speciﬁes the input.

Obliviousness and authenticity.
Some prior papers
exploit obliviousness and authenticity of garbled circuits to
achieve desired applications: private medical diagnostics [9],
veriﬁable computation and private veriﬁable computation
[17], and correctable veriﬁable computation [5]. The no-
tions are not seen as properties of a stand-alone primitive
corresponding to a garbling scheme.

In the last of the works mentioned, Applebaum, Ishai,
Kushilevitz [5] describe the following generic transformations
from privacy to obliviousness and to authenticity. (1) Obliv-
instead of garbling a circuit f , let g be a circuit
iousness:
such that g(x (cid:13) r) = f (x) ⊕ r for every x ∈ {0, 1}n and
r ∈ {0, 1}m, where n = f.n and m = f.m. Then, choose
r (cid:2){0, 1}m, run (F, e, d) ← Gb(g) and output (F, (e, r), d).
The garbled input corresponding to x will be e(x (cid:13) r).
instead of garbling a circuit f , let g be
(2) Authenticity:
a circuit such that g(x (cid:13) K) = f (x) (cid:13) MACK (f (x)) for any
x ∈ {0, 1}n and any key K. Then, choose a random key K,
run (F, e, d) ← Gb(g), and output (F, (e, K), d). The garbled
input corresponding to x will be e(x (cid:13) K). Applied to Gar-
ble1, the transformations lead to schemes slightly (for (1))
or substantially (for (2)) less eﬃcient that Garble2; and (2)
requires a cryptographic assumption. More fundamentally,
Applebaum et al. do not formalize any deﬁnition for the
obliviousness or authenticity of a garbling scheme.

The only work that explicitly deﬁnes obliviousness and
authenticity in this domain is a recent paper of Kamara,
Mohassel, and Rakova [28]. Still, their syntax is designed
speciﬁcally for their application; for example, a circuit’s in-
put is a pair (x1, x2), a garbled circuit’s input is (X1, X2),
and the encoding function takes an input x and an index
i ∈ {1, 2} and outputs the corresponding Xi. Their notion
of obliviousness requires hiding only the input, while obv.ind

796