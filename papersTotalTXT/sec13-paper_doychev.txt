CacheAudit: A Tool for the Static Analysis  

of Cache Side Channels

Goran Doychev, IMDEA Software Institute; Dominik Feld, Saarland University;  

Boris Köpf and Laurent Mauborgne, IMDEA Software Institute;  

Jan Reineke, Saarland University

Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4CacheAudit: A Tool for the Static Analysis of Cache Side Channels

Goran Doychev1, Dominik Feld2, Boris K¨opf1, Laurent Mauborgne1, and Jan Reineke2

1IMDEA Software Institute

2Saarland University

Abstract

We present CacheAudit, a versatile framework for the
automatic, static analysis of cache side channels. Cache-
Audit takes as input a program binary and a cache con-
ﬁguration, and it derives formal, quantitative security
guarantees for a comprehensive set of side-channel ad-
versaries, namely those based on observing cache states,
traces of hits and misses, and execution times.

Our technical contributions include novel abstractions
to efﬁciently compute precise overapproximations of the
possible side-channel observations for each of these ad-
versaries. These approximations then yield upper bounds
on the information that is revealed. In case studies we ap-
ply CacheAudit to binary executables of algorithms for
symmetric encryption and sorting, obtaining the ﬁrst for-
mal proofs of security for implementations with counter-
measures such as preloading and data-independent mem-
ory access patterns.

1

Introduction

Side-channel attacks recover secret inputs to programs
from non-functional characteristics of computations,
such as time [31], power [32], or memory consump-
tion [27]. Typical goals of side-channel attacks are the
recovery of cryptographic keys and private information
about users.

Processor caches are a particularly rich source of side-
channels because their behavior can be monitored in var-
ious ways, which is demonstrated by three documented
classes of side-channel attacks:
(1) In time-based at-
tacks [31, 10] the adversary monitors the overall execu-
tion time of a victim, which is correlated with the number
of cache hits and misses during execution. Time-based
attacks are especially daunting because they can be car-
ried out remotely over the network [6]. (2) In access-
based attacks [40, 39, 23] the adversary probes the cache
state by timing its own accesses to memory. Access-
based attacks require that attacker and victim share the

same hardware platform, which is common in the cloud
and has already been exploited [41, 49]. (3) In trace-
based attacks [5] the adversary monitors the sequence
of cache hits and misses. This can be achieved, e.g., by
monitoring the CPU’s power consumption and is partic-
ularly relevant for embedded systems.

A number of proposals have been made for countering
cache-based side-channel attacks. Some proposals fo-
cus entirely on modiﬁcations of the hardware platform;
they either solve the problem for speciﬁc algorithms such
as AES [2] or require modiﬁcations to the platform [46]
that are so signiﬁcant that their rapid adoption seems un-
likely. The bulk of proposals rely on controlling the in-
teractions between the software and the hardware layers,
either through the operating system [23, 48], the client
application [10, 39, 15], or both [29]. Reasoning about
these interactions can be tricky and error-prone because
it relies on the speciﬁcs of the binary code and the mi-
croarchitecture.

In this paper we present CacheAudit, a tool for the
automatic, static exploration of the interactions of a pro-
gram with the cache. CacheAudit takes as input a pro-
gram binary and a cache conﬁguration and delivers for-
mal security guarantees that cover all possible executions
of the corresponding system. The security guarantees
are quantitative upper bounds on the amount of infor-
mation that is contained in the side-channel observations
of timing-, access-, and trace-based adversaries, respec-
tively. CacheAudit can be used to formally analyze the
effect on the leakage of software countermeasures and
cache conﬁgurations, such as preloading of tables or in-
creasing the cache’s line size. The design of Cache-
Audit is modular and facilitates extension with any cache
model for which efﬁcient abstractions are in place. The
current implementation of CacheAudit supports caches
with LRU, FIFO, and PLRU replacement strategies.

We demonstrate the scope of CacheAudit in case stud-
ies where we analyze the side-channel leakage of repre-
sentative algorithms for symmetric encryption and sort-

USENIX Association  

22nd USENIX Security Symposium  431

ing. We highlight the following two results: (1) For the
reference implementation of the Salsa20 [11] stream ci-
pher (which was designed to be resilient to cache side-
channel attacks) CacheAudit can formally prove non-
leakage on the basis of the binary executable, for all
adversary models and replacement strategies.
(2) For
a library implementation of AES 128 [3], CacheAudit
conﬁrms that the preloading of tables signiﬁcantly im-
proves the security of the executable: for most adversary
models and replacement strategies, we can in fact prove
non-leakage of the executable, whenever the tables ﬁt
entirely in the cache. However, for access-based adver-
saries and LRU caches, CacheAudit reports small, non-
zero bounds. And indeed, with LRU (in contrast to, e.g.,
FIFO), the ordering of blocks within a cache set reveals
information about the victim’s ﬁnal memory accesses.

On a technical level, we build on the fact that the
amount of leaked information corresponds to the num-
ber of possible side-channel observations, which can be
over-approximated by abstract interpretation1 and count-
ing techniques [35, 34]. To realize CacheAudit based on
this insight, we propose three novel abstract domains (i.e.
data structures that approximate properties of the pro-
gram semantics) that keep track of the observations of
access-based, time-based, and trace-based adversaries,
respectively. In particular:

1. We propose an abstract domain that tracks rela-
tional information about the memory blocks that may be
cached. In contrast to existing abstract domains used in
worst-case execution time analysis [21], our novel do-
main can retain analysis precision in the presence of ar-
ray accesses to unknown positions.

2. We propose an abstract domain that tracks the
traces of cache hits and misses that may occur during
execution. We use a technique based on preﬁx trees and
hash consing to compactly represent such sets of traces,
and to count their number.

3. We propose an abstract domain that tracks the pos-
sible execution times of a program. This domain captures
timing variations due to control ﬂow and caches by asso-
ciating hits and misses with their respective latencies and
adding the execution time of the respective commands.
We formalize the connection of these domains in an ab-
stract interpretation framework that captures the relation-
ship between microarchitectural state and program code.
We use this framework to formally prove the correctness
of the derived upper bounds on the leakage to the corre-
sponding side-channel adversaries.

In summary, our main contributions are both theo-
retical and practical: On a theoretical level, we deﬁne
novel abstract domains that are suitable for the analy-
sis of cache side channels, for a comprehensive set of

1A theory of sound approximation of program semantics [16]

adversaries. On a practical level, we build CacheAudit,
the ﬁrst tool for the automatic, quantitative information-
ﬂow analysis of cache side-channels, and we show how
it can be used to derive formal security guarantees from
binary executables of sorting algorithms and state-of-the-
art cryptosystems.

Outline The remainder of the paper is structured as fol-
lows. In Section 2, we illustrate the power of CacheAudit
on a simple example program. In Section 3 we deﬁne the
semantics and side channels of programs. We describe
the analysis framework, the design of CacheAudit, and
the novel abstract domains in Sections 4, 5 and 6, re-
spectively. We present experimental results in Section 7,
before we discuss prior work and conclude in Sections 8
and 9. The source code and documentation of Cache-
Audit are available at

http://software.imdea.org/cacheaudit

2

Illustrative Example

In this section, we illustrate on a simple example pro-
gram the kind of guarantees CacheAudit can derive.
Namely, we consider an implementation of BubbleSort
that receives its input in an array a of length n. We as-
sume that the contents of a are secret and we aim to de-
duce how much information a cache side-channel adver-
sary can learn about the relative ordering of the elements
of a.

1
2
3
4
5
6
7
8
9
10
11
12

void BubbleSort(int a[], int n)
{

int i, j, temp;
for (i = 0; i < n - 1; ++i)

for (j = 0; j < n - 1 - i; ++j)

if (a[j] > a[j+1])
{

temp = a[j+1];
a[j+1] = a[j];
a[j] = temp;

}

}

To begin with, observe that the conditional swap in
lines 6–11 is executed exactly n(n−1)
times. A trace-
based adversary that can observe, for each instruction,
whether it corresponds to a cache hit or a miss is likely to
be able to distinguish between the two alternative paths
in the conditional swap, hence we expect this adversary
to be able to distinguish between 2
execution traces.
A timing-based adversary who can observe the overall
execution time is likely to be able to distinguish between
n(n−1)
2 +1 possible execution times, corresponding to the
number of times the swap has been carried out. For an

n(n−1)

2

2

432  22nd USENIX Security Symposium 

USENIX Association

access-based adversary who can probe the ﬁnal cache
state upon termination, the situation is more subtle: eval-
uating the guard in line 6 requires accessing both a[j]
and a[j+1], which implies that both will be present in
the cache when the swap in lines 8–10 is carried out. As-
suming we begin with an empty cache, we expect that
there is only one possible ﬁnal cache state.

CacheAudit enables us to perform such analyses (for a
particular n) formally and automatically, based on actual
x86 binary executables and different cache types. Cache-
Audit achieves this by tracking compact representations
of supersets of possible cache states and traces of hits and
misses, and by counting the corresponding number of el-
ements. For the above example, CacheAudit was able to
precisely conﬁrm the intuitive bounds, for a selection of
several n in {2, . . . ,64}.
In terms of security, the number of possible observa-
tions corresponds to the factor by which the cache obser-
vation increases the probability of correctly guessing the
secret ordering of inputs. Hence, for n = 32 and a uni-
form distribution on this order (i.e. an initial probability
of 1
32! = 3.8· 10−36), the bounds derived by CacheAudit
imply that the probability of determining the correct in-
put order from the side-channel observation is 1 for a
trace-based adversary, 3.7 · 10−33 for a time-based ad-
versary, and remains 1
32! for an access-based adversary.

3 Caches, Programs, and Side Channels

3.1 A Primer on Caches
Caches are fast but small memories that store a subset of
the main memory’s contents to bridge the latency gap be-
tween the CPU and main memory. To proﬁt from spatial
locality and to reduce management overhead, main mem-
ory is logically partitioned into a set of memory blocks B.
Each block is cached as a whole in a cache line of the
same size.

When accessing a memory block, the cache logic has
to determine whether the block is stored in the cache
(“cache hit”) or not (“cache miss”). To enable an efﬁ-
cient look-up, each block can only be stored in a small
number of cache lines. For this purpose, caches are parti-
tioned into equally-sized cache sets. The size of a cache
set is called the associativity k of the cache. There is
a function set that determines the cache set a memory
block maps to.

Since the cache is much smaller than main mem-
ory, a replacement policy must decide which mem-
ory block to replace upon a cache miss. Usually, re-
placement policies treat sets independently, so that ac-
cesses to one set do not inﬂuence replacement deci-
sions in other sets. Well-known replacement policies
in this class are least-recently used (LRU), used in vari-

ous Freescale processors such as the MPC603E and the
TriCore17xx; pseudo-LRU (PLRU), a cost-efﬁcient vari-
ant of LRU, used in the Freescale MPC750 family and
multiple Intel microarchitectures; and ﬁrst-in ﬁrst-out
(FIFO), also known as ROUND ROBIN, used in several
ARM and Freescale processors such as the ARM922 and
the Freescale MPC7450 family. A more comprehensive
overview can be found in [22].

3.2 Programs and Computations
A program P = (Σ,I,F,E,T ) consists of the following
components:

• Σ - a set of states
• I ⊆ Σ - a set of initial states
• F ⊆ Σ - a set of ﬁnal states
• E - a set of events
• T ⊆ Σ×E ×Σ - atransition relation
A computation of P is an alternating sequence of states
and events σ0e0σ1e1 . . .σ n such that σ0 ∈ I and that
for all i ∈ {0, . . . ,n − 1}, (σi,ei,σi+1) ∈ T . The set of
all computations of P is its trace collecting semantics
Col(P) ⊆ Traces, where Traces denotes the set of all al-
ternating sequences of states and events. When consider-
ing terminating programs, the trace collecting semantics
can be formally deﬁned as the least ﬁxpoint of the next
operator containing I:

Col(P) = I ∪ next(I)∪ next2(I)∪ . . . ,

where next describes the effect of one computation step:
next(S) = {t.σnenσn+1 | t.σn ∈ S∧ (σn,en,σn+1) ∈ T }
In the rest of the paper, we assume that P is ﬁxed and
abbreviate its trace collecting semantics by Col.

3.3 Cache Updates and Cache Effects
For reasoning about cache side channels, we consider
a semantics in which the cache is part of the program
state. Namely, the state will consist of logical memories
in M (representing the values of main memory locations
and CPU registers, including the program counter) and a
cache state in C, i.e., Σ = M×C.
: M→
M that is determined solely by the instruction set seman-
tics. The memory update has effects on the cache that
: M→EM. The mem-
are described by a function eff
ory effect is an argument to the cache update function
upd

The memory update upd

is a function upd

M

M

M

: C ×EM → C.

C
In the setting of this paper, eff

determines which
M
block of main memory is accessed, which is required
, i.e., EM = B ∪{⊥},
to compute the cache update upd
where ⊥ denotes that no memory block is accessed.

C

USENIX Association  

22nd USENIX Security Symposium  433

C

We formally describe upd

only for the LRU strategy.
For formalizations of other strategies, see [22]. Upon a
cache miss, LRU replaces the least-recently-used mem-
ory block. To this end, it tracks the ages of memory
blocks within each cache set, where the youngest block
has age 0 and the oldest cached block has age k − 1.
Thus, the state of the cache can be modeled as a func-
tion that assigns an age to each memory block, where
non-cached blocks are assigned age k:

C := {c ∈ B →A | ∀a,b ∈ B : a (cid:23)= b ⇒
((set(a) =set (b)) ⇒ (c(a) (cid:23)= c(b)∨ c(a) =c(b) =k ))},
where A := {0, ...,k − 1,k} is the set of ages. The con-
straint encodes that no two blocks in the same cache set
can have the same age. For readability we omit the ad-
ditional constraint that blocks of non-zero age are pre-
ceded by other blocks, i.e. that cache sets do not contain
“holes”.

The cache update for LRU is then given by

upd

C(c,b) := λ b(cid:19) ∈ B.

: b(cid:19) = b
: set(b(cid:19)) (cid:23)= set(b)

0
c(b(cid:19))
c(b(cid:19)) +1 : set(b(cid:19)) =set (b)∧ c(b(cid:19)) < c(b)
: set(b(cid:19)) =set (b)∧ c(b(cid:19)) ≥ c(b)
c(b(cid:19))




In the setting of this paper, the events E consist of
cache hits and misses, which are described by the cache
effect eff

: C ×B → E:

C

We model an adversary’s view on the computations
of P as a function view: Col → O that maps computa-
tions to a ﬁnite set of observations O. The composition

C = (view◦ P): I → O

deﬁnes a function from initial states to observations,
which we call a channel of P. Whenever view is deter-
mined by the cache and event components of traces, we
call C a side channel of P.

We next deﬁne views corresponding to the obser-
vations of access-based, trace-based, and timing-based
side-channel adversaries.

The view of an access-based adversary that shares the

memory space with the victim is deﬁned by

viewacc : (m0,c0)e0 . . .e n−1(mn,cn) (cid:10)→ cn

and captures that the adversary can determine (by prob-
ing) which memory blocks are contained in the cache
upon termination of the victim. An adversary that does
not share the memory space with the victim can only ob-
serve how many blocks the victim has loaded in each
cache set (by probing how many of its own blocks have
been evicted), but not which. We denote this view by
viewaccd. The view of a trace-based adversary is deﬁned
by

viewtr : σ0e0 . . .e n−1σn (cid:10)→ e0 . . .e n−1

and captures that the adversary can determine for each
instruction whether it results in a hit, miss, or does not
access memory. The view of a time-based adversary is
deﬁned by

eff

C(c,m) :=(cid:27)hit

miss

: c(m) < k
: else

C

C

and eff

are naturally extended to the case
Both upd
where no memory access occurs. Then, the cache state
remains unchanged and the cache effect is ⊥, so E =
{hit,miss,⊥}.
With this, we can now connect the components and
obtain the global transition relation T ⊆ Σ×E ×Σ by
M(m1)

T = {((m1,c1), e , (m2,c2)) | m2 = upd

∧ c2 = upd
∧ e = eff

C(c1,eff
C(c1,eff

M(m1))
M(m1))} ,

which formally captures the asymmetric relationship be-
tween caches, logical memories, and events.

viewtime : σ0e0 . . .e n−1σn (cid:10)→

thit ·|{i | ei = hit}| +tmiss ·|{i | ei = miss}| +
t⊥ ·|{i | ei = ⊥}|

and captures that the adversary can determine the overall
execution time of the program. Here, thit, tmiss, and t⊥ are
the execution times (e.g. in clock cycles) of instructions
that imply cache hits, cache misses, or no memory ac-
cesses at all. While the view of the time-based adversary
as deﬁned above is rather simplistic, e.g. disregarding ef-
fects of pipelining and out-of-order execution, notice that
our semantics and our tool can be extended to cater for
a more ﬁne-grained, instruction- and context-dependent
modeling of execution times. We denote the side chan-
nels corresponding to the four views by Cacc, Caccd, Ctr,
and Ctime, respectively. Figure 1 gives an overview.

3.4 Side Channels
For a deterministic, terminating program P, the transition
relation is a function, and the program can be modeled as
a mapping P: I → Col.

3.5 Quantiﬁcation of Side Channels
We characterize the security of a channel C : I → O as the
difﬁculty of guessing the secret input from the channel
output.

434  22nd USENIX Security Symposium 

USENIX Association

Cacc

Ctr

Access-based adversary whose memory
space is shared with the victim’s.

Caccd Access-based adversary whose memory

space is disjoint from the victim’s.
Adversary who observes the trace of cache
hits and misses.

Ctime Adversary who observes the overall execu-

tion time.

Figure 1: Channels corresponding to different adversary
models.

Formally, we model the choice of a secret input by
a random variable X with ran(X) ⊆ I and the corre-
sponding observation by a random variable C(X) with
ran(C(X)) ⊆ O. We model the attacker as another ran-
dom variable ˆX. The goal of the attacker is to esti-
mate the value of X, i.e. it is successful if ˆX = X. We
make the assumption that the attacker does not have in-
formation about the value of X beyond what is contained
in C(X), which we formalize as the requirement that
X → C(X)→ ˆX form a Markov chain. The following the-
orem expresses a security guarantee as an upper bound
on the attacker’s success probability in terms of the size
of the range of C.

Theorem 1. Let X → C(X) → ˆX be a Markov chain.
Then

P(X = ˆX) ≤ max
σ∈I

P(X = σ )·|ran(C)|

For the interpretation of the statement observe that if
the adversary has no information about the value of X
(i.e., if ˆX and X are statistically independent), its suc-
cess probability is bounded by the probability of the most
likely value of X, i.e. P(X = ˆX) ≤ maxσ∈I P(X = σ ),
where equality can be achieved. Theorem 1 hence states
that the size of the range of C is an upper bound on the
factor by which this probability is increased when the at-
tacker sees C(X) and is, in that sense, an upper bound
for the amount of information leaked by C. We will of-
ten give bounds on |ran(C)| on a log-scale, in which case
they represent upper bounds on the number of leaked
bits. Notice that the guarantees of Theorem 1 fundamen-
tally rely on assumptions about the initial distribution of
X: if X is easy to guess to begin with, Theorem 1 does
not imply meaningful security guarantees.

For more discussion on the interpretation of the secu-
rity guarantees, see Section 7.4. For a formal connection
to traditional (entropy-based) presentations of quantita-
tive information-ﬂow analysis [43] and a proof of Theo-
rem 1, see the extended version [19].

3.6 Adversarially Chosen Cache States
We sometimes assume that initial states are pairs consist-
ing of high and low components, i.e. I = Ihi × Ilo, where
only the high component is meant to be kept secret and
the low component may be provided by the adversary,
a common setting in information-ﬂow analysis [42]. In
this case, a program and a view deﬁne a family of chan-
nels Cσlo : Ihi → O, one for each low component σlo ∈ Ilo.
A particularly interesting instance is the decomposi-
tion into secret memory Ihi = M and adversarially cho-
sen cache Ilo = C. While bounds for the corresponding
channel can be derived by considering all possible ini-
tial cache states, corresponding analyses suffer from poor
precision. The following lemma enables us to derive
bounds for the general case, based on the empty cache
state.
Lemma 1. For all initial cache states c ∈ C, adversaries
adv ∈ {acc,accd,time,tr}, and LRU, FIFO, or PLRU re-
placement: If no block in c is accessed during program
execution, then

where /0 is a shorthand for the empty cache state. For

ran(Cadv

/0

ran(Cadv

c

(1)

)(cid:31)(cid:31)

ran(Cadv

c

/0

(cid:31)(cid:31)(cid:31)

ran(Cadv

=(cid:31)(cid:31)(cid:31)
adv ∈ {acc,accd} and LRU, (cid:31)(cid:31)

)(cid:31)(cid:31)(cid:31)

,

)(cid:31)(cid:31)(cid:31)
)(cid:31)(cid:31) ≥ (cid:31)(cid:31)

holds without any constraints on the initial cache state c.
This lemma was proved in [34] for acc, accd and the
LRU case with the initial cache state not containing any
block of the victim. The proof is based on the fact that
memory blocks in the cache do not affect the position
of memory blocks that are accessed during computation
whenever the two sets of memory blocks are disjoint,
which allows us to construct a bijective function from
ran(Cadv
). The argument immediately ex-
tends to FIFO, PLRU, and all adv. For LRU and access-
based adversaries, the function remains surjective even
without the disjointness requirement.

) to ran(Cadv

/0

c

4 Automatic Quantiﬁcation of Cache Side

Channels

Theorem 1 enables the quantiﬁcation of side channels
by determining their range. As channels are deﬁned in
terms of views on computations, their range can be de-
termined by computing Col and applying view. However,
this entails computing a ﬁxpoint of the next operator and
is practically infeasible in most cases. Abstract inter-
pretation [16] overcomes this fundamental problem by
computing a ﬁxpoint with respect to an efﬁciently com-
putable over-approximation of next. This new ﬁxpoint
represents a superset of all computations, which is suf-
ﬁcient for deriving an upper bound on the range of the
channel and thus on the leaked information.

USENIX Association  

22nd USENIX Security Symposium  435

In this section, we describe the interplay of the abstrac-
tions used for over-approximating next in CacheAudit
(namely, those for memory, cache, and events), and we
explain how the global soundness of CacheAudit can be
established from local soundness conditions. This mod-
ularity is key for the future extension of CacheAudit us-
ing more advanced abstractions. Our results hold for all
adversaries introduced in Section 3.4 and we omit the
superscript adv from channels and views for readability.

4.1 Sound Abstraction of Leakage

We frame a static analysis by deﬁning a set of abstract
elements Traces(cid:31) together with an abstract transfer func-
tion next(cid:31) : Traces(cid:31) → Traces(cid:31). Here, the elements a ∈
Traces(cid:31) represent subsets of Traces, which is formalized
by a concretization function

γ : Traces(cid:31)→P(Traces) .

The key requirements for next(cid:31) are (1) that it be efﬁ-
ciently computable, and (2) that it over-approximates the
effect of next on sets of computations, which is formal-
ized as the following local soundness condition:

∀a ∈ Traces(cid:31) : next (γ(a)) ⊆ γ(next(cid:31)(a)) .

(2)

Intuitively, if we maintain a superset of the set of compu-
tations during each step of the transfer function as in (2),
then this inclusion must also hold for the correspond-
ing ﬁxpoints. More formally, any post-ﬁxpoint of next(cid:31)
that is greater than an abstraction of the initial states I is
a sound over-approximation of the collecting semantics.
We use Col(cid:31) to denote any such post-ﬁxpoint.

Theorem 2 (Local soundness implies global soundness,
from [16]). If (2) holds then

Col ⊆ γ(cid:31)Col(cid:31)(cid:30) .

The following theorem is an immediate consequence
of Theorem 2 and the fact that view (Col) =ran( C). It
states that a sound abstract analysis can be used for de-
riving bounds on the size of the range of a channel.

Theorem 3 (Upper bounds on leakage).

|ran(C)| ≤(cid:29)(cid:29)(cid:29)

view(cid:31)γ(cid:31)Col(cid:31)(cid:30)(cid:30)(cid:29)(cid:29)(cid:29)

.

With the help of Theorem 1, these bounds immediately
translate into security guarantees. The relationship of all
steps leading to these guarantees is depicted in Figure 2.

4.2 Abstraction Using a Control Flow

Graph

In order to come up with a tractable and modular analy-
sis, we design independent abstractions for cache states,
memory, and sequences of events.

malizes its meaning.

formalizes its meaning.

• M(cid:31) abstracts memory and γM : M(cid:31) →P(M) for-
• C(cid:31) abstracts cache conﬁgurations and γC :C(cid:31)→P(C)
• E (cid:31) abstracts sequences of events and γE : E (cid:31) →
But, since cache updates and events depend on memory
state, independent analyses would be too imprecise. In
order to maintain some of the relations, we link the three
abstract domains for memory state, caches, and events
through a ﬁnite set of labels L so that our abstract domain
is

P(E∗) formalizes its meaning.

Traces(cid:31) = L→M(cid:31) ×C(cid:31) ×E (cid:31) ,

where we write aM(l), aC(l) and aE (l) for the ﬁrst, sec-
ond, and third components of an abstract element a(l).

Labels roughly correspond to nodes in a control ﬂow
graph in classical data-ﬂow analyses. One could sim-
ply use program locations as labels. But in our setting,
we use more general labels, allowing for a more ﬁne-
grained analysis in which we can distinguish values of
ﬂags or results of previous tests [36]. To capture that,
we associate a meaning with each label via a function
γL : L→P(Traces). If the labels are program locations,
then γL(l) is the set of traces ending in a state in lo-
cation l. The analogy with control ﬂow graphs can be
extended to edges of that graph: using the next opera-
tor, we deﬁne the successors and predecessors of a lo-
cation l as: succ(l) = {k | next(γL(l))∩ γL(k) (cid:16)= /0}, and
pred(l) = {k | next(γL(k))∩ γL(l) (cid:16)= /0}.
Then we can describe the meaning of an element a ∈
Traces(cid:31) with:

γ(a) = {σ0e0σ1 . . .σ n ∈ Traces| ∀i ≤ n, ∀l ∈ L :

σ0e0σ1 . . .σ i ∈ γL(l) ⇒

σMi ∈ γM(aM(l))∧ σCi ∈ γC(aC(l))
∧e0 . . .e i−1 ∈ γE (aE (l))(cid:28)

(3)

That is, the meaning of an a ∈ Traces(cid:31) is the set of
traces, such that for every preﬁx of a trace, if it “ends” at
program location l, then the memory state, cache state,
and the event sequence satisfy the respective abstract el-
ements for that location.

The abstract transfer function next(cid:31) will be decom-

posed into:

next(cid:31)(a) =λ l. (next

M(cid:31)(a,l),next

C(cid:31)(a,l),next

E(cid:31) (a,l)) ,
(4)

436  22nd USENIX Security Symposium 

USENIX Association

Col

⊆

γ(cid:31)Col(cid:31)(cid:30)

Meaning

Col(cid:31)

Leakage

≤

|ran(C)| = |view (Col)|

≤

view(cid:31)γ(cid:31)Col(cid:31)(cid:30)(cid:30)(cid:29)(cid:29)

(cid:29)(cid:29)

Figure 2: Relationship of collecting semantics Col, abstract ﬁxpoint Col(cid:31), side channels C, and leakage bounds.

where each next function over-approximates the corre-
sponding concrete update function deﬁned in the previ-
ous section. The effects used for deﬁning the concrete
updates are reﬂected as information ﬂow between other-
wise independent abstract domains, which is formalized
as a partial reduction in the abstract interpretation litera-
ture [18].

4.3 Local Soundness
The products and powers of sound abstract domains with
partial reductions are again sound abstract domains [17].
The soundness of Traces(cid:31) hence immediately follows
from the local soundness of the memory, cache and event
domains. Below we describe those soundness conditions
for each domain.

and

The abstract next(cid:31) operation is implemented using lo-
cal update functions for the memory, cache, and event
components. For the memory domain we have, for each
label k ∈ L and each l ∈ succ(k):

• an abstract memory update upd
• an abstract memory effect eff

M(cid:31),(k,l):M(cid:31) →M(cid:31),
M(cid:31),(k,l) : M(cid:31) →
For the cache domain, there is no need for separate func-
tions for each pair (k,l), because the cache update only
depends on the accessed block which is delivered by the
abstract memory effect. Likewise, the update of the event
domain only depends on the abstract cache effect. Thus,
we further have:

P(EM).

P(EC), and

C(cid:31) : C(cid:31) ×P(EM)→C(cid:31),
C(cid:31) : C(cid:31) × P(EM) →

• an abstract cache update upd
• an abstract cache effect eff
• an abstract event upd
With these functions, we can approximate the effect
of next on each label l, using the abstract values associ-
ated with the labels that can lead to l, pred(l). For the
example of the cache domain, this yields

E(cid:31) : E (cid:31) ×P(EC)→E (cid:31).

next

C(cid:31)(a,l) =

C(cid:31)

(cid:28)k∈pred(l)

upd

C(cid:31)(cid:27)aC(k),eff

M(cid:31),(k,l)(aM(k))(cid:26) ,

where (cid:25)C(cid:31) refers to the join function and can be thought
C(cid:31) (a,l) collects all cache
of as set union. That is, next
states that can reach l within one transition when updated
with an over-approximation of the corresponding mem-
ory blocks. See the full version [19] for a description
of the corresponding update functions for memory and
effects.

Now from Equations 2, 3, and 4, we can derive con-
ditions for each domain that are sufﬁcient to guarantee
local soundness for the whole analysis:
Deﬁnition 1 (Local soundness of abstract domains). The
abstract domains are locally sound if the abstract joins
are over-approximations of unions, and if for any func-
C(cid:31),eff
tion f (cid:31) ∈ {upd
E(cid:31)}
approximating
∈
corresponding
M,upd
{upd
meaning function γ f , we have for any abstract value x:

M(cid:31),(k,l),eff
concrete
C,eff
C,next}

M(cid:31),(k,l),upd
function
and

C(cid:31),upd
f

M,eff

γ f (cid:27) f (cid:31)(x)(cid:26) ⊇ f (cid:31)γ f (x)(cid:30) .

For example, for the cache abstract domain, we have

the following local soundness conditions:

∀c(cid:31) ∈ C(cid:31),M ∈ P(EM):

γC(upd
C(cid:31) (c(cid:31),M)) ⊇ upd
C(cid:31) (c(cid:31),M) ⊇ eff
eff

C(γC(c(cid:31)),M),
C(γC(c(cid:31)),M),

∀G(cid:31) ⊆ C(cid:31) : γC


C(cid:31)

(cid:28)G(cid:31)

 ⊇ (cid:20)G(cid:31)∈G(cid:31)

γC(cid:27)G(cid:31)(cid:26) .

Lemma 2 (Local Soundness Conditions). If local sound-
ness holds on the abstract memory, cache, and events
domains, then the corresponding next(cid:31) function satisﬁes
local soundness.

Due to the above lemma, abstract domains for the
memory, cache, and events can be separately developed
and proven correct. We exploit this fact in this paper, and
we plan to develop further abstractions in the future, tar-
geting different classes of adversaries or improving pre-
cision.

USENIX Association  

22nd USENIX Security Symposium  437

Theorem2MonotonicityTheorem14.4 Soundness of Delivered Bounds
We implemented the framework described above in a
tool named CacheAudit. Thanks to the previous results,
CacheAudit provides the following guarantees.
Theorem 4. The bounds derived by CacheAudit
soundly over-approximate (cid:31)(cid:31)
for adv ∈
{acc,accd,tr,time}, and hence correspond to upper
bounds on the maximal amount of leaked information.

ran(Cadv)(cid:31)(cid:31)

,

The statement is an immediate consequence of com-
bining Lemma 2 with Theorems 2 and 3, under the as-
sumption that all involved abstract domains satisfy local
soundness conditions, and that the corresponding count-
ing procedures are correct. We formally prove the valid-
ity of these assumptions only for our novel relational and
trace domains (see Section 6). For the other domains,
corresponding proofs are either standard (e.g. the value
domain) or out of scope of this submission.

5 Tool Design and Implementation

In this section we describe the architecture and imple-
mentation of CacheAudit.

We take advantage of the compositionality of the
framework described in Section 4 and use a generic it-
erator module to compute ﬁxpoints, where we rely on
independent modules for the abstract domains that corre-
spond to the components of the next(cid:30) operation. Figure 3
depicts the overall architecture of CacheAudit, with the
individual modules described below.

5.1 Control Flow Reconstruction
The ﬁrst stage of the analysis is similar to a compiler
front end. The main challenge is that we directly ana-
lyze x86 executables with no explicit control ﬂow graph,
which we need for guiding the ﬁxpoint computation.

For the parsing phase, we rely on Chlipala’s parser for
x86 executables [13], which we extend to a set of in-
structions that is sufﬁcient for our case studies (but not
yet complete). For the control-ﬂow reconstruction, we
consider only programs without dynamically computed
jump and call targets, which is why it sufﬁces to iden-
tify the basic blocks and link them according to the cor-
responding branching conditions and (static) branch tar-
gets. We plan to integrate more sophisticated techniques
for control-ﬂow reconstruction [30] in the future.

Iterator

5.2
The iterator module is responsible for the computation
of the next(cid:30) operator and of the approximation of its ﬁx-
point using adequate iteration strategies [17]. Our analy-
sis uses an iterative strategy, i.e., it stabilizes components

CacheAudit

x86 parser

Iterator

Stack AD

abstract
domains

Interval AD
FiniteSet AD
Octagon AD
RelSet AD

Flag AD

Memory AD

Value AD

Trace AD
Timing AD

Cache AD

Figure 3: The architecture of CacheAudit. The solid
boxes represent modules. Black-headed arrows mean
that the module at the head is an argument of the module
at the tail. White-headed arrows represent is-a relation-
ships.

of the abstract control ﬂow graph according to a weak
topological ordering, which we compute using Bourdon-
cle’s algorithm [12].

The iterator also implements parts of the reduced car-
dinal power, based on the labels computed according to
the control-ﬂow graph: Each label is associated with an
initial abstract state. The analysis computes the effect of
the commands executed from that label to its successors
on the initial abstract state, and propagates the resulting
ﬁnal states using the abstract domains described below.
In order to increase precision, we expand locations us-
ing loop unfolding, so that we have a number of differ-
ent initial and ﬁnal abstract states for each label inside
loops, depending on a parameter describing the number
of loop unfoldings we want to perform. Most of our
examples (such as the cryptographic algorithms) require
only a small, constant number of loop iterations, so that
we can choose unfolding parameters that avoid joining
states stemming from different iterations.

5.3 Abstract Domains
As described in Section 4, we decompose the abstract
domain used by the iterator into mostly independent ab-
stract domains describing different aspects of the con-
crete semantics.

Value Abstract Domains A value abstract domain
represents sets of mappings from variables to (integer)

438  22nd USENIX Security Symposium 

USENIX Association

values. Value abstract domains are used by the cache
abstract domain to represent ages of blocks in the cache,
and by the ﬂag abstract domain to represent values stored
at the addresses used in the program. We have imple-
mented different value abstract domains, such as the in-
terval domain, an exact ﬁnite sets domain (where the sets
become intervals when they are growing too large) and a
relational set domain (as described in Section 6.1).

Flag Abstract Domain In x86 binaries, there are no
high level guards: instead, most operations modify ﬂags
which are then queried in conditional branches. In or-
der to deal precisely with such branches, we need to
record relational information between the values of vari-
ables and the values of these ﬂags. To that end, for each
operation that modiﬁes the ﬂags, we compute an over-
approximation of the values of the arguments that may
lead to a particular ﬂag combination. The ﬂag abstract
domain represents an abstract state as a mapping from
values of ﬂags to elements of the value abstract domain.
When the analysis reaches a conditional branch, it can
identify which combination of ﬂag values corresponds to
the branch and propagate the appropriate abstract values.

Memory Abstract Domain The memory abstract do-
main associates memory addresses and registers with
variables and translates machine instructions into the cor-
responding operations on those variables, which are rep-
resented using ﬂag abstract domains as described above.
One important aspect for efﬁciency is that variables cor-
responding to addresses are created dynamically during
the analysis whenever they are needed. The memory ab-
stract domain further records all accesses to main mem-
ory using a cache abstract domain, as described below.

Stack Abstract Domain Operations on the stack are
handled by a dedicated stack abstract domain.
In this
way the memory abstract domain does not have to deal
with stack operations such as procedure calls, for which
special techniques can be implemented to achieve precise
interprocedural analysis.

Cache Abstract Domain The cache abstract domain
only tracks information about the cache state. We rep-
resent this state by sets of mappings from blocks to
ages in the cache, which we implement using an in-
stance of value abstract domains. Effects from the mem-
ory domain are passed to the cache domain through
the trace domain. The cache abstract domain tracks
which addresses are touched during computation and re-
turns information about the presence or absence of cache
hits and misses to the trace abstract domain, which we

present in Section 6.2. The timings are then obtained as
an abstraction from the traces.

6 Abstract Domains for Cache Adversaries

6.1 Cache State Domains
Abstractions of cache states are at the heart of analyses
for all three cache adversaries considered in this paper.
Thus, precise abstraction of cache states is crucial to de-
termine tight leakage bounds.

The current state-of-the-art abstraction for LRU re-
placement by Ferdinand et al. [21] maintains an upper
and a lower bound on the age of every memory block.
This abstraction was developed with the sole goal of clas-
sifying memory accesses as cache hits or cache misses.
In contrast, our goal is to develop abstractions that yield
tight bounds on the maximal leakage of a channel. For
access-based adversaries the leakage is bounded by the
size of the concretization of an abstract cache state, i.e.
the size of the set of concrete cache states represented by
the abstract state.

Intuition behind Relational Sets To derive tighter
leakage bounds, we propose a new domain called rela-
tional sets that improves previous work along two dimen-
sions:

1. Instead of intervals of ages of memory blocks, we

maintain sets of ages of memory blocks.

2. Instead of maintaining independent

information
about the age of each memory blocks, we record the
relation between ages of different memory blocks.

In addition to increasing precision, moving from in-
tervals to sets allows us to analyze caches with FIFO and
PLRU replacement. Interval-based analysis of FIFO and
PLRU has been shown to be rather imprecise in the con-
text of worst-case execution time analysis [24].

Motivating Example Consider the following method,
which performs a table lookup based on a secret input, as
it may occur in e.g. an AES implementation:

unsigned int A[size];

int getElement(int secret) {

if (secret < size)

return A[secret];

}

Assume we want to determine the possible cache
states after one invocation of getElement. As the value
of secret is unknown to the analysis, every memory lo-
cation of the array might be accessed.

USENIX Association  

22nd USENIX Security Symposium  439

size
LRU/IV
LRU/Set
LRU/Rel

8
1
1
1

16
2
2
1.58

32
4
4
2.32

64
8
8
3.17

128
16
16
4.01

256
32
32
5.04

Figure 4: Bounds on the number of leaked bits about
the parameter secret for varying array sizes. The cache
parameters are ﬁxed, with a block size of 32 bytes, asso-
ciativity 4 and cache size 4 KB.

Assuming the array was not cached before the invoca-
tion of getElement, the interval-based domain by Fer-
dinand et al. [21] determines a lower bound of 0 and an
upper bound of k on the age of each array element.

By tracking sets instead of intervals of ages for each
memory block, we would get 0 and k as possible ages of
each array element.

Both non-relational domains, however, are not power-
ful enough to infer or even express the fact, that only one
of the array’s memory blocks has been accessed, and can
thus be cached. Therefore, the number of possible cache
states represented by non-relational abstractions grows
exponentially in the size of the array, while the actual
number of possible cache states only grows linearly.

A relational domain, tracking the possible ages of,
e.g., pairs of memory blocks, would indeed yield a lin-
ear growth in the number of possible cache states. For
each pair of array elements, it would be able to infer that
only one of the two blocks may be cached. From this, it
follows that only one of all of the array elements may be
cached.

Figure 4 shows experimental results for the example
program with three domains: the interval domain (IV),
and two instances of the relational sets domain, tracking
sets of ages of individual blocks (Set) and sets of ages of
pairs of blocks (Rel), respectively.

We do not see an improvement of sets over intervals
in this particular example, as the information that a block
has either age 0 or age k can be inferred from the intervals
in the counting procedure. This is because the considered
arrays are small and thus no two array elements map to
the same cache set. We have, however, observed in case
studies that sets alone often improve over intervals.

A detailed formalization of relational sets and their im-
plementation, including efﬁcient counting, is provided in
the extended version of this paper [19]. There, we also
show that the domain is locally sound according to Deﬁ-
nition 1:

Lemma 3. The relational sets domain is locally sound.

6.2 A Trace Domain
We devise an abstract domain for keeping track of the
sets of event traces that may occur during the execution
of a program. Following the way events are computed
in the concrete, namely as a function from cache states
and memory effects (see Section 3.3), the abstract cache
domain provides abstract cache effects.

In our current implementation of CacheAudit, we use
an exact representation for sets of event traces: we can
represent any ﬁnite set of event traces, and assuming an
incoming set of traces S and a set of cache effects E, we
compute the resulting event set precisely as follows:

upd

E(cid:31) (S,E) = {σ .e | σ ∈ S ∧ e ∈ E }

Then soundness is obvious, since the abstract opera-
tion is the same as its concrete counterpart. Due to loop
unfolding, we do not require widenings, even though
the domain contains inﬁnite ascending chains (see Sec-
tion 5.2).
Lemma 4. The trace domain is locally sound.

i=1 γ(ui).

i=1 γ(ui)}

Representation for Sets of Event Traces We repre-
sent sets of ﬁnite event traces corresponding to a partic-
ular program location by a directed acyclic graph (DAG)
with vertices V , a dedicated root r ∈ V , and a node label-
ing (cid:28): V → P(E)∪{(cid:21)}. In this graph, every node v ∈ V
represents a set of traces γ(v) ∈ P(E∗) in the following
way:
1. For the root r, γ(r) ={ε }
2. For v with L(v) =(cid:21) and predecessors u1, . . . ,u n,
γ(v) = (cid:31)n
3. For v with L(v) (cid:19)= (cid:21) and predecessors u1, . . . ,u n,
γ(v) = {t.u | u ∈ L(v)∧t ∈ (cid:31)n

Intuitively, every v ∈ V represents a set of event traces,
namely the sequences of labels of paths from r to v.
In the context of CacheAudit, we need to implement
two operations on this data structure, namely (1) the join
(cid:21)E(cid:31) of two sets of traces and the (2) addition upd
E(cid:31)(S,E)
of a cache event to a particular set of traces.
For the join of two sets of traces represented by v and
w, we add a new vertex u with label (cid:21) and add edges
from v and w to u.
For the extension of a set of traces represented by
a vertex v by a set of cache events E, we ﬁrst check
whether v already has a child w labeled with E. If so, we
use w as a representation of the extended set of traces. If
not, we add a new vertex u with label E and add an edge
(u,v). In this way we make maximal use of sharing and
obtain a preﬁx DAG. The correctness of the representa-
tion follows by construction. In CacheAudit, we use hash
consing for efﬁciently building the preﬁx DAG.

440  22nd USENIX Security Symposium 

USENIX Association

Counting Sets of Traces The following algorithm
counttr overapproximates the number of traces that are
represented by a given graph.

1. For the root r, counttr(r) =1

2. For v with L(v) =(cid:31) and predecessors u1, . . . ,u n,

counttr(v) = ∑n

i=1 countτ (ui)

3. For v with L(v) (cid:30)= (cid:31) and predecessors u1, . . . ,u n,

counttr(v) = |L(v)|· ∑n

i=1 counttr(ui)

The soundness of this counting, i.e. the fact that |γ(v)| ≤
counttr(v), follows by construction. Notice that the pre-
cision dramatically decreases with larger sets of labels.
In our case, labels contain at most three events and the
counting is sufﬁciently precise.

Counting Timing Variations We currently model ex-
ecution time as a simple abstraction of traces, see Sec-
tion 3. In particular, timing is computed from a trace over
E = {hit,miss,⊥} by multiplying the number of occur-
rences of each event by the time they consume: thit, tmiss,
and t⊥, respectively. The following algorithm counttime
over-approximates the set of timing behaviors that are
represented by a given graph.

1. For the root r, counttime(r) ={0}
2. For v with L(v) =(cid:31) and predecessors u1, . . . ,u n,
counttime(v) = (cid:31)n
3. For v with L(v) (cid:30)= (cid:31) and predecessors u1 . . . ,u n,

i=1 counttime(ui)

counttime(v) =

x ∈ L(v)∧t ∈

counttime(ui)(cid:27)

n

(cid:28)i=1

(cid:30)tx +t (cid:29)(cid:29)(cid:29)(cid:29)(cid:29)

The soundness of counttime, i.e. the fact that it delivers
a superset of the number of possible timing behaviors,
follows by construction.

7 Case Studies

In this section we demonstrate the capabilities of Cache-
Audit in case studies where we use it to analyze the cache
side channels of algorithms for sorting and symmetric
encryption. All results are based on the automatic anal-
ysis of corresponding 32-bit x86 Linux executables that
we compiled using gcc.

200

150

100

50

]
t
i
b
[

e
g
a
k
a
e
L

0

4

8

16

32

Cache Size [KB]

64

128

256

Figure 5: Effect of the attacker model and preloading
(PL) on the security guarantee, for varying cache sizes.
The results are given for a 4-way set associative cache
with a line size of 64B and the LRU replacement strategy.

200

150

100

]
t
i
b
[

e
g
a
k
a
e
L

50

4

8

16

32

Cache Size [KB]

64

128

256

Figure 6: Effect of the cache line size on the security
guarantee, for Cacc and Caccd, for varying cache sizes.
The results are given for a 4-way set associative cache
with the LRU replacement strategy.

7.1 AES 128
We analyze the AES implementation from the PolarSSL
library [3] with keys of 128 bits, where we consider the
implementation with and without preloading of tables,
for all attacker models, different replacement strategies,
associativities, and line sizes. All results are presented as
upper bounds of the leakage in bits; for their interpreta-
tion see Theorem 1. In some cases, CacheAudit reports
upper bounds that exceed the key size (128 bits), which
corresponds to an imprecision of the static analysis. We
opted against truncating to 128 bits to illustrate the de-
gree of imprecision. The full data of our analysis are
given in the extended version of this paper [19]. Here,
we highlight some of our ﬁndings.

• Preloading almost consistently leads to better secu-
rity guarantees in all scenarios (see e.g. Figure 5). How-
ever, the effect becomes clearly more apparent for cache
sizes beyond 8KB, which is explained by the PolarSSL
AES tables exceeding the size of the 4KB cache by 256B.
For cache sizes that are larger than the preloaded ta-
bles, we can prove noninterference for Cacc and FIFO,
Caccd and LRU, and for Ctr and Ctime on LRU, FIFO, and
PLRU. For Cacc with shared memory spaces and LRU,

USENIX Association  

22nd USENIX Security Symposium  441

CtrCaccCaccdCtimeCtr/PLCacc/PLCaccd/PLCtime/PLCacc/32BCaccd/32BCacc/64BCaccd/64BCacc/128BCaccd/128B100

]
t
i
b
[

e
g
a
k
a
e
L

50

0

4

8

16

32

Cache Size [KB]

64

128

256

Figure 7: Effect of the replacement strategy on the se-
curity guarantee for Cacc, with and without preloading
(PL), for varying cache sizes. The results are given for a
4-way set associative cache with a line size of 64B.

100

]
t
i
b
[

e
g
a
k
a
e
L

50

4

8

16
32
Cache Size [KB]

64

128

Figure 8: Effect of the associativity on the security guar-
antee, for Cacc and Caccd, without preloading, for varying
cache sizes. The results are given for a cache with a line
size of 64B and the LRU replacement strategy.

this result does not hold because the adversary can ob-
tain information about the order of memory blocks in the
cache.

• A larger line size consistently leads to better se-
curity guarantees for access-based adversaries (see e.g.
Figure 6). This follows because more array indices map
to a line which decreases the resolution of the attacker’s
observations.

• In terms of replacement strategies, we consistently
derive the lowest bounds for LRU, followed by PLRU
and FIFO (see the extended version [19]), where the only
exception is the case of Cacc and preloading (see Fig-
ure 7). In this case FIFO is more secure because with
LRU the adversary can obtain information about the or-
dering of memory blocks in the cache.

• In terms of cache size, we consistently derive bet-
ter bounds for larger caches, with the exception of Caccd.
For this adversary model the bounds increase because
larger caches correspond to distributing the table to more
sets, which increases its possibilities to observe varia-
tions. The guarantees we obtain for Caccd and Cacc con-
verge for caches of 4 ways and sizes beyond 16KB (see
e.g. Figure 6). This is due to the fact that each cache

set can contain at most one unique block of the 4KB ta-
ble. In that way, the ability to observe ordering of blocks
within a set does not give Cacc any advantage.

• When increasing associativity, we observe oppos-
ing effects on the leakage of Cacc and Caccd (see Fig-
ure 8). This is explained by the fact that, for a ﬁxed
cache size, increasing associativity means decreasing the
number of sets. For Caccd which can only observe the
number of blocks that have been loaded into each set,
this corresponds to a decrease in observational capabil-
ity; for Cacc which can observe the ordering of blocks,
this corresponds to an increase. This difference vanishes
for larger cache sizes because then each set contains at
most one unique block of the AES tables.

Comparison to [34]:
In a recent study [34] we ana-
lyzed the PolarSSL AES implementation with respect
to access-based adversaries and LRU replacement, using
the cache component of a closed-source tool for worst-
case execution time analysis [1]. The results we obtain
using CacheAudit go beyond that analysis in that we de-
rive bounds w.r.t. access-based, trace-based, and time-
based adversaries, for LRU, FIFO, and PLRU strategies.
For access-based adversaries and LRU, the bounds we
derive are lower than those in [34]; in particular, for
Caccd we derive bounds of zero for implementations with
preloading for all caches sizes that are larger than the
AES tables—which is obtained in [34] only for caches
of 128KB. While these results are obtained for differ-
ent platforms (x86 vs. ARM) and are hence not directly
comparable, they do suggest a signiﬁcant increase in pre-
cision. In contrast to [34], this is achieved without any
code instrumentation.

7.2 Salsa20

Salsa20 is a stream cipher by Bernstein [11]. Internally,
the cipher uses XOR, addition mod 232, and constant-
distance rotation operations on an internal state of 16 32-
bit words. The lack of key-dependent memory lookups
intends to avoid cache side channels in software imple-
mentations of the cipher. With CacheAudit we could for-
mally conﬁrm this intuition by automated analysis of the
reference implementation of Salsa20 encryption, which
includes a function call to a hash function. Speciﬁcally,
we analyze the leakage of the encryption operation on
an arbitrary 512-byte message for Cacc, Ctr, and Ctime,
FIFO and LRU strategies, on 4KB caches with line size
of 32B, where we consistently obtain upper bounds of 0
for the leakage. The time required for analyzing each of
the cases was below 11s.

442  22nd USENIX Security Symposium 

USENIX Association

LRUFIFOLRU/PLFIFO/PLCacc/1-wayCacc/2-wayCacc/4-wayCacc/8-wayCaccd/1-wayCaccd/2-wayCaccd/4-wayCaccd/8-way7.3 Sorting Algorithms
In this section we use CacheAudit to establish bounds on
the cache side channels of different sorting algorithms.
This case study is inspired by an early investigation of se-
cure sorting algorithms [8]. While the authors of [8] con-
sider only time-based adversaries and noninterference as
a security property, CacheAudit allows us to give quanti-
tative answers for a comprehensive set of side-channel
adversaries, based on the binary executables and con-
crete cache models.

As examples, we use the implementations of Bubble-
Sort, InsertionSort, and SelectionSort from [4], which
are given in Section 2 and Appendix A, respectively,
where we use integer arrays of lengths from 8 to 64.

The results of our analysis are summarized in Figure 9.

In the following we highlight some of our ﬁndings.

• We obtain the same bounds for BubbleSort and Se-
lectionSort, which is explained by the similar structure
of their control ﬂow. A detailed explanation of those
bounds is given in Section 2. InsertionSort has a differ-
ent control ﬂow structure, which is reﬂected by our data.
In particular InsertionSort has only n! possible execution
traces due to the possibility of leaving the inner loop,
which leads to better bounds w.r.t.
trace-based adver-
saries. However, InsertionSort leaks more information
to timing-based adversaries, because the number of iter-
ations in the inner loop varies and thus fewer executions
have the same timing.

• For access-based adversaries we obtain zero bounds
for all algorithms. For trace-based adversaries, the de-
rived bounds do not imply meaningful security guaran-
tees: the bounds reported for InsertionSort are in the or-
der of log2(n!), which corresponds to the maximum in-
formation contained in the ordering of the elements; the
bounds reported for the other sorting algorithms exceed
this maximum, which is caused by the imprecision of the
static analysis.

• We performed an analysis of the sorting algorithms
for smaller (256B) and larger (64KB) cache sizes and
obtained the exact same bounds as in Figure 9, with the
exception of the case of arrays of 64 entries and 256B
caches: there the leakage increases because the arrays do
not ﬁt entirely into the cache due to their misalignment
with the memory blocks.

7.4 Discussion and Outlook
A number of comments are in order when interpreting
the bounds delivered by CacheAudit. First, we obtained
all of the bounds for an empty initial cache. As described
in Section 3.6, they immediately extend to bounds for ar-
bitrary initial cache states, as long as the victim does not
access any block that is contained in it. This is relevant,

e.g. for an adversary who can ﬁll the initial cache state
only with lines from its own disjoint memory space. For
LRU and access-based adversaries, our bounds extend to
arbitrary initial cache states without further restriction.

Second, while CacheAudit relies on more accurate
models of cache and timing than any information-ﬂow
analysis we are aware of,
timing-
relevant features of hardware it does not capture (and
make assertions about) yet, including out-of-order exe-
cution, which may reorder memory accesses, TLBs, and
multiple levels of caches.

there are several

Third, for the case of AES and Salsa20, the derived
bounds hold for the leakage about the key in one execu-
tion, with respect to any payload. For the case of zero
leakage (i.e., noninterference), the bounds trivially ex-
tend to bounds for multiple executions and imply strong
security guarantees. For the case of non-zero leakage, the
bounds can add up when repeatedly running the victim
process with a ﬁxed key and varying payload, leading to
a decrease in security guarantees. One of our prime tar-
gets for future work is to derive security guarantees that
hold for multiple executions of the victim process. One
possibility to achieve this is to employ leakage-resilient
cryptosystems [20, 47], where our work can be used to
bound the range of the leakage functions.

Finally, note that the bounds delivered by CacheAudit
can only be used for certifying that a system is se-
cure;
they cannot be used for proving that it is not.
There are two reasons why the bounds may be overly
pessimistic: First, CacheAudit may over-estimate the
amount of leaked information due to imprecision of the
static analysis. Second, the secret input may not be ef-
fectively recoverable from the leaked information by an
adversary that is computationally bounded.

8 Related Work

The work most closely related to ours is [34]. There,
the authors quantify cache side channels by connecting a
commercial, closed-source tool for the static analysis of
worst-case execution times [1] to an algorithm for count-
ing concretizations of abstract cache states. The appli-
cation of the tool to side-channel analysis is limited to
access-based adversaries and requires heavy code instru-
mentation. In contrast, CacheAudit provides tailored ab-
stract domains for all kinds of cache side-channel ad-
versaries, different replacement strategies, and is mod-
ular and open for further extensions. Furthermore, the
bounds delivered by CacheAudit are signiﬁcantly tighter
than those reported in [34]; see Section 7.

Zhang et al. [48] propose an approach for mitigating
timing side channels that is based on contracts betweens
software and hardware. The contract is enforced on the
software side using a type system, and on the hardware

USENIX Association  

22nd USENIX Security Symposium  443

array length

BubbleSort
InsertionSort
SelectionSort

Ctr
28

15.23

28

8

Ctime Cacc
0
4.86
0
6.91
4.86
0

16
Ctime
6.92
10.15
6.92

Ctr
120
44.3
120

Cacc
0
0
0

Ctr
496
117.7
496

32
Ctime Cacc
0
8.96
0
13.3
8.96
0

64
Ctime Cacc
0
11
0
15.8
11
0

Ctr
2016
296
2016

Figure 9: The table illustrates the security guarantees derived by CacheAudit for the implementations of BubbleSort, SelectionSort,
and InsertionSort, for trace-based, timing-based, and access-based adversaries, for LRU caches of 4KB and line sizes of 32B.

side, e.g., by using dedicated hardware such as parti-
tioned caches. The analysis ensures that an adversary
cannot obtain any information by observing public parts
of the memory; any conﬁdential information the adver-
sary obtains must be via timing, which is controlled using
dedicated mitigate commands. Tiwari et al. [45] sketch a
novel microarchitecture that faciliates information-ﬂow
tracking by design, where they use noninterference as
a baseline conﬁdentiality property. Other mitigation
techniques include coding guidelines [15] for thwarting
cache attacks on x86 CPUs, or novel cache architectures
that are resistant to cache side-channel attacks [46]. The
goal of our approach is orthogonal to those approaches
in that we focus on the analysis of microarchitectural
side channels rather than on their mitigation. Our ap-
proach does not rely on a speciﬁc platform; rather it can
be applied to any language and hardware architecture, for
which abstractions are in place.

Kim et al. put forward StealthMem [29], a system-
level defense against cache-timing attacks in virtualized
environments. The core of StealthMem is a software-
based mechanism that locks pages of a virtual machine
into the cache and prevents their eviction by other VMs.
StealthMem can be seen as a lightweight variant of ﬂush-
ing/preloading countermeasures. As future work, we
plan to use our tool to derive formal, quantitative guar-
antees for programs using StealthMem.

For the case of AES, there are efﬁcient software im-
plementations that avoid the use of data caches by bit-
slicing [28]. Furthermore, a model for statistical estima-
tion of the effectiveness of AES cache attacks based on
sizes of cache lines and lookup tables has been presented
in [44]. In contrast, our analysis technique applies to ar-
bitrary programs.

Technically, our work builds on methods from quan-
titative information-ﬂow analysis (QIF) [14], where the
automation by reduction to counting problems appears
in [9, 38, 26, 37], the connection to abstract interpreta-
tion in [35], and the application to side channel analysis
in [33]. Finally, our work goes beyond language-based
approaches that consider caching [7, 25] in that we rely
on more realistic models of caches and aim for more per-
missive, quantitative guarantees.

9 Conclusions

We presented CacheAudit, the ﬁrst automatic tool for the
static derivation of formal, quantitative security guaran-
tees against cache side-channel attacks. We demonstrate
the usefulness of CacheAudit by establishing the ﬁrst
formal proofs of security of software-based countermea-
sures for a comprehensive set of adversaries and based
on executable code.

The open architecture of CacheAudit makes it an ideal
platform for future research on microarchitectural side
channels.
In particular, we are currently investigating
the derivation of security guarantees for concurrent ad-
versaries. Progress along those lines will provide a han-
dle for extending our security guarantees to the operating
system level. We will further investigate abstractions for
hardware features such as pipelines, out-of-order execu-
tion, and leakage-resilient cache designs, with the goal
of providing broad tool support for reasoning about side-
channels arising at the hardware/software interface.

Acknowledgments We thank Adam Chlipala and the
anonymous reviewers for the constructive feedback, and
Ignacio Echeverr´ıa and Guillermo Guridi for helping
with the implementation.

This work was partially funded by European Projects
FP7-256980 NESSoS and FP7-229599 AMAROUT, by
the Spanish Project TIN2012-39391-C04-01 Strong-
Soft, by the Madrid Regional Project S2009TIC-1465
PROMETIDOS, and by the German Research Council
(DFG) as part of the Transregional Collaborative Re-
search Center AVACS.

References

[1] AbsInt aiT Worst-Case Execution Time Analyzers.

http://www.absint.com/a3/.

[2] Intel Advanced Encryption Standard (AES) In-
structions Set. http://software.intel.com/
file/24917.

[3] PolarSSL. http://polarssl.org/.
[4] Sorting algorithms.

http://www.codebeach.

com/2008/09/sorting-algorithms-in-c.
html.

444  22nd USENIX Security Symposium 

USENIX Association

[5] O. Aciic¸mez and C¸ . K. Koc¸. Trace-driven cache at-
tacks on AES. In ICICS, pages 112–121. Springer,
2006.

[6] O. Aciic¸mez, W. Schindler, and C¸ . K. Koc¸. Cache
based remote timing attack on the AES. In CT-RSA,
pages 271–286. Springer, 2007.

[7] J. Agat. Transforming out timing leaks. In POPL

2000, pages 40–53. ACM, 2000.

[8] J. Agat and D. Sands. On conﬁdentiality and algo-

rithms. In SSP, pages 64–77. IEEE, 2001.

[9] M. Backes, B. K¨opf, and A. Rybalchenko. Auto-
matic discovery and quantiﬁcation of information
leaks. In SSP, pages 141–153. IEEE, 2009.

[10] D. Bernstein.

attacks

Cache-timing

on
http://cr.yp.to/antiforgery/

AES.
cachetiming-20050414.pdf.

[11] D. Bernstein.

snuffle.html.

Salsa20.

http://cr.yp.to/

[12] F. Bourdoncle. Efﬁcient chaotic iteration strate-
In FMPA, pages 128–141.

gies with widenings.
Springer, 1993.

[13] A. Chlipala. Modular development of certiﬁed pro-
In ICFP,

gram veriﬁers with a proof assistant.
pages 160–171. ACM, 2006.

[14] D. Clark, S. Hunt, and P. Malacaria. A static anal-
ysis for quantifying information ﬂow in a simple
imperative language. JCS, 15(3):321–371, 2007.

[15] B. Coppens, I. Verbauwhede, K. D. Bosschere, and
B. D. Sutter. Practical mitigations for timing-based
side-channel attacks on modern x86 processors. In
SSP, pages 45–60. IEEE, 2009.

[16] P. Cousot and R. Cousot. Abstract interpretation: a
uniﬁed lattice model for static analysis of programs
by construction of approximation of ﬁxpoints. In
POPL, pages 238–252, 1977.

[17] P. Cousot and R. Cousot. Systematic design of pro-
gram analysis frameworks. In POPL, pages 269–
282, 1979.

[18] P. Cousot, R. Cousot, and L. Mauborgne. Theo-
ries, solvers and static analysis by abstract interpre-
tation. Journal of the ACM, 59(6):31, 2012.

[19] G. Doychev, D. Feld, B. K¨opf, L. Mauborgne, and
J. Reineke. CacheAudit: A tool for the static anal-
ysis of cache side channels.
http://eprint.
iacr.org/2013/253.

[20] S. Dziembowski and K. Pietrzak. Leakage-resilient
In FOCS, pages 293–302. IEEE,

cryptography.
2008.

[21] C. Ferdinand, F. Martin, R. Wilhelm, and M. Alt.
Cache behavior prediction by abstract interpreta-

tion. Science of Computer Programming, 35(2):163
– 189, 1999.

[22] D. Grund. Static Cache Analysis for Real-Time Sys-
tems – LRU, FIFO, PLRU. PhD thesis, Saarland
University, 2012.

[23] D. Gullasch, E. Bangerter, and S. Krenn. Cache
games - bringing access-based cache attacks on
AES to practice.
In SSP, pages 490–505. IEEE,
2011.

[24] R. Heckmann, M. Langenbach, S. Thesing, and
R. Wilhelm. The inﬂuence of processor architecture
on the design and the results of WCET tools. IEEE
Proceedings on Real-Time Systems, 91(7):1038–
1054, 2003.

[25] D. Hedin and D. Sands. Timing aware information
ﬂow security for a JavaCard-like bytecode. ENTCS,
141(1):163–182, 2005.

[26] J. Heusser and P. Malacaria. Quantifying informa-
tion leaks in software. In ACSAC, pages 261–269.
ACM, 2010.

[27] S. Jana and V. Shmatikov. Memento: Learning se-
crets from process footprints. In SSP, pages 143–
157. IEEE, 2012.

[28] E. K¨asper and P. Schwabe. Faster and timing-attack
resistant AES-GCM. In CHES, pages 1–17, 2009.
[29] T. Kim, M. Peinado, and G. Mainar-Ruiz. Stealth-
Mem: System-level protection against cache-based
side channel attacks in the cloud. In 19th USENIX
Security Symposium. USENIX, 2012.

[30] J. Kinder, F. Zuleger, and H. Veith. An abstract
interpretation-based framework for control ﬂow re-
construction from binaries. In VMCAI, pages 214–
228. Springer, 2009.

[31] P. Kocher. Timing attacks on implementations of
Difﬁe-Hellman, RSA, DSS, and other systems. In
CRYPTO, pages 104–113. Springer, 1996.

[32] P. Kocher, J. Jaffe, and B. Jun. Differential power
In CRYPTO, pages 388–397. Springer,

analysis.
1999.

[33] B. K¨opf and D. Basin. An Information-Theoretic
Model for Adaptive Side-Channel Attacks. In CCS,
pages 286–296. ACM, 2007.

[34] B. K¨opf, L. Mauborgne, and M. Ochoa. Auto-
In

matic quantiﬁcation of cache side-channels.
CAV, pages 564–580. Springer, 2012.

[35] B. K¨opf and A. Rybalchenko. Approximation
and randomization for quantitative information-
ﬂow analysis. In CSF, pages 3–14. IEEE, 2010.

[36] L. Mauborgne and X. Rival.

Trace partition-
ing in abstract interpretation based static analyz-

USENIX Association  

22nd USENIX Security Symposium  445

A Example Code
Selection Sort

void SelectionSort(int a[], int array_size){

int i;
for (i = 0; i < array_size - 1; ++i){

int j, min, temp;
min = i;
for (j = i+1; j < array_size; ++j){

if (a[j] < a[min])

min = j;

}
temp = a[i];
a[i] = a[min];
a[min] = temp;

}

}

Insertion Sort

void InsertionSort(int a[], int array_size){

int i, j, index;
for (i = 1; i < array_size; ++i){

index = a[i];
for (j = i; j > 0 && a[j-1] > index; j--)

a[j] = a[j-1];

a[j] = index;

}

}

ers. In ESOP, volume 3444 of LNCS, pages 5–20.
Springer, 2005.

[37] Z. Meng and G. Smith. Calculating bounds on in-
formation leakage using two-bit patterns. In PLAS.
ACM, 2011.

[38] J. Newsome, S. McCamant, and D. Song. Measur-
ing channel capacity to distinguish undue inﬂuence.
In PLAS, pages 73–85. ACM, 2009.

[39] D. A. Osvik, A. Shamir, and E. Tromer. Cache at-
tacks and countermeasures: the case of AES. In CT-
RSA, volume 3860 of LNCS, pages 1–20. Springer,
2006.

[40] C. Percival. Cache missing for fun and proﬁt. In

BSDCan, 2005.

[41] T. Ristenpart, E. Tromer, H. Shacham, and S. Sav-
age. Hey, you, get off of my cloud: exploring infor-
mation leakage in third-party compute clouds. In
CCS, pages 199–212. ACM, 2009.

[42] A. Sabelfeld and A. C. Myers. Language-based
IEEE Journal on Se-
information-ﬂow security.
lected Areas in Communications, 21(1):5–19, 2003.
[43] G. Smith. On the foundations of quantitative infor-
mation ﬂow. In FoSSaCS, pages 288–302. Springer,
2009.

[44] K. Tiri, O. Aciic¸mez, M. Neve, and F. Andersen.
An analytical model for time-driven cache attacks.
In FSE, volume 4593 of LNCS, pages 399–413.
Springer, 2007.

[45] M. Tiwari, J. Oberg, X. Li, J. Valamehr, T. E. Levin,
B. Hardekopf, R. Kastner, F. T. Chong, and T. Sher-
wood. Crafting a usable microkernel, processor,
and I/O system with strict and provable informa-
tion ﬂow security. In ISCA, pages 189–200. ACM,
2011.

[46] Z. Wang and R. B. Lee. New cache designs for
thwarting software cache-based side channel at-
tacks. In ISCA, pages 494–505. ACM, 2007.

[47] Y. Yu, F.-X. Standaert, O. Pereira, and M. Yung.
Practical leakage-resilient pseudorandom genera-
tors. In CCS, pages 141–151. ACM, 2010.

[48] D. Zhang, A. Askarov, and A. C. Myers. Language-
based control and mitigation of timing channels. In
PLDI, pages 99–110. ACM, 2012.

[49] Y. Zhang, A. Juels, M. K. Reiter, and T. Ristenpart.
Cross-VM side channels and their use to extract pri-
vate keys. In CCS. ACM, 2012.

446  22nd USENIX Security Symposium 

USENIX Association

