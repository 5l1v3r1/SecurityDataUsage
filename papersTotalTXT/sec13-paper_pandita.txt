WHYPER: Towards Automating Risk Assessment  

of Mobile Applications

Rahul Pandita, Xusheng Xiao, Wei Yang, William Enck, and Tao Xie,  

North Carolina State University

Open access to the Proceedings of the 22nd USENIX Security Symposium is sponsored by USENIXThis paper is included in the Proceedings of the 22nd USENIX Security Symposium.August 14–16, 2013 • Washington, D.C., USAISBN 978-1-931971-03-4WHYPER: Towards Automating Risk Assessment of Mobile Applications

Rahul Pandita, Xusheng Xiao, Wei Yang, William Enck, Tao Xie

North Carolina State University, Raleigh, NC, USA

{rpandit, xxiao2, wei.yang}@ncsu.edu {enck, xie}@csc.ncsu.edu

Abstract

Application markets such as Apple’s App Store and
Google’s Play Store have played an important role in the
popularity of smartphones and mobile devices. However,
keeping malware out of application markets is an ongo-
ing challenge. While recent work has developed various
techniques to determine what applications do, no work
has provided a technical approach to answer, what do
users expect? In this paper, we present the ﬁrst step in
addressing this challenge. Speciﬁcally, we focus on per-
missions for a given application and examine whether the
application description provides any indication for why
the application needs a permission. We present WHY-
PER, a framework using Natural Language Processing
(NLP) techniques to identify sentences that describe the
need for a given permission in an application description.
WHYPER achieves an average precision of 82.8%, and
an average recall of 81.5% for three permissions (address
book, calendar, and record audio) that protect frequently-
used security and privacy sensitive resources. These re-
sults demonstrate great promise in using NLP techniques
to bridge the semantic gap between user expectations and
application functionality, further aiding the risk assess-
ment of mobile applications.

1

Introduction

Application markets such as Apple’s App Store and
Google’s Play Store have become the de facto mech-
anism of delivering software to consumer smartphones
and mobile devices. Markets have enabled a vibrant soft-
ware ecosystem that beneﬁts both consumers and devel-
opers. Markets provide a central location for users to
discover, purchase, download, and install software with
only a few clicks within on-device market interfaces. Si-
multaneously, they also provide a mechanism for devel-
opers to advertise, sell, and distribute their applications.
Unfortunately, these characteristics also provide an easy

distribution mechanism for developers with malicious in-
tent to distribute malware.

To address market-security issues, the two predom-
inant smartphone platforms (Apple and Google) use
starkly contrasting approaches. On one hand, Apple
forces all applications submitted to its App Store to un-
dergo some level of manual inspection and analysis be-
fore they are published. This manual intervention allows
an Apple employee to read an application’s description
and determine whether the different information and re-
sources used by the application are appropriate. On the
other hand, Google performs no such checking before
publishing an application. While Bouncer [1] provides
static and dynamic malware analysis of published appli-
cations, Google primarily relies on permissions for se-
curity. Application developers must request permissions
to access security and privacy sensitive information and
resources. This permission list is presented to the user at
the time of installation with the implicit assumption that
the user is able to determine whether the listed permis-
sions are appropriate.

However, it is non-trivial to classify an application as
malicious, privacy infringing, or benign. Previous work
has looked at permissions [2–5], code [6–10], and run-
time behavior [11–13]. However, underlying all of this
work is a caveat: what does the user expect? Clearly, an
application such as a GPS Tracker is expected to record
and send the phone’s geographic location to the network;
an application such as a Phone-Call Recorder is expected
to record audio during a phone call; and an application
such as One-Click Root is expected to exploit a privilege-
escalation vulnerability. Other cases are more subtle.
The Apple and Google approaches fundamentally differ
in who determines whether an application’s permission,
code, or runtime behavior is appropriate. For Apple, it is
an employee; for Google, it is the end user.

We are motivated by the vision of bridging the seman-
tic gap between what the user expects an application to
do and what it actually does. This work is a ﬁrst step in

USENIX Association  

22nd USENIX Security Symposium  527

this direction. Speciﬁcally, we focus on permissions and
ask the question, does the application description pro-
vide any indication for the application’s use of a permis-
sion? Clearly, this hypothesis will work better for some
permissions than others. For example, permissions that
protect a user-understandable resource such as the ad-
dress book, calendar, or microphone should be discussed
in the application description. However, other low-level
system permissions such as accessing network state and
controlling vibration are not likely to be mentioned. We
note that while this work primarily focuses on permis-
sions in the Android platform and relieving the strain on
end users, it is equally applicable to other platforms (e.g.,
Apple) by aiding the employee performing manual in-
spection.

With this vision,

in this paper, we present WHY-
PER, a framework that uses Natural Language Processing
(NLP) techniques to determine why an application uses
a permission. WHYPER takes as input an application’s
description from the market and a semantic model of a
permission, and determines which sentence (if any) in
the description indicates the use of the permission. Fur-
thermore, we show that for some permissions, the per-
mission semantic model can be automatically generated
from platform API documents. We evaluate WHYPER
against three popularly-used permissions (address book,
calendar, and record audio) and a dataset of 581 popular
applications. These three frequently-used permissions
protect security and privacy sensitive resources. Our re-
sults demonstrate that WHYPER effectively identiﬁes the
sentences that describe needs of permissions with an av-
erage precision of 82.8% and an average recall of 81.5%.
We further investigate the sources of inaccuracies and
discuss techniques of improvement.

This paper makes the following main contributions:
• We propose the use of NLP techniques to help
bridge the semantic gap between what mobile ap-
plications do and what users expect them to do. To
the best of our knowledge, this work is the ﬁrst at-
tempt to automate this inference.

• We evaluate our framework on 581 popular An-
droid application descriptions containing nearly
10,000 natural-language sentences. Our evaluation
demonstrates substantial improvement over a basic
keyword-based searching.

• We provide a publicly available prototype imple-
mentation of our approach on the project web-
site [14].

WHYPER is merely the ﬁrst step in bridging the se-
mantic gap of user expectations. There are many ways
in which we see this work developing. Application de-
scriptions are only one form of input. We foresee pos-

2

sibility in also incorporating the application name, user
reviews, and potentially even screen-shots. Furthermore,
permissions could potentially be replaced with speciﬁc
API calls, or even the results of dynamic analysis. We
also see great potential in developing automatic or par-
tially manual techniques of creating and ﬁne-tuning per-
mission semantic models.

Finally, this work dovetails nicely with recent dis-
course concerning the appropriateness of Android per-
missions to protect user security [15–18]. The over-
whelming evidence indicates that most users do not un-
derstand what permissions mean, even if they are in-
clined to look at the permission list [18]. On the other
hand, permission lists provide a necessary foundation for
security. Markets cannot simultaneously cater to the se-
curity and privacy requirements of all users [19], and per-
mission lists allow researchers and expert users to be-
come “whistle blowers” for security and privacy con-
cerns [11].
In fact, a recent comparison [20] of the
Android and iOS versions of applications showed that
iOS applications overwhelmingly more frequently use
privacy-sensitive APIs. Tools such as WHYPER can help
raise awareness of security and privacy problems and
lower the sophistication required for concerned users to
take control of their devices.

The remainder of this paper proceeds as follows. Sec-
tion 2 presents the overview of the WHYPER framework
along with background on NLP techniques used in this
work. Section 3 presents our framework and implemen-
tation. Section 4 presents evaluation of our framework.
Section 6 discusses related work. Finally, Section 7 con-
cludes.

2 WHYPER Overview

We next present a brief overview of the WHYPER frame-
work. The name WHYPER itself is a word-play on phrase
why permissions. We envision WHYPER to operate be-
tween the application market and end users, either as a
part of the application market or a standalone system as
shown in Figure 1.

The primary goal of the WHYPER framework is to
bridge the semantic gap of user expectations by deter-
mining why an application requires a permission.
In
particular, we use application descriptions to get this in-
formation. Thus, the WHYPER framework operates be-
tween the application market and end users. Further-
more, our framework could also serve to help developers
with the feedback to improve their applications, as shown
by the dotted arrows between developers and WHYPER
in Figure 1.

A straightforward way of realizing the WHYPER
framework is to perform a keyword-based search on ap-
plication descriptions to annotate sentences describing

528  22nd USENIX Security Symposium 

USENIX Association

ous speciﬁcations that can be processed and understood
by computers. With recent research advances in the area
of NLP, existing NLP techniques have been shown to be
fairly accurate in highlighting grammatical structure of a
natural language sentence. We next brieﬂy introduce the
key NLP techniques used in this work.

Parts Of Speech (POS) Tagging [21, 22]. Also
known as ‘word tagging’, ‘grammatical tagging’ and
‘word-sense disambiguation’, these techniques aim to
identify the part of speech (such as nouns and verbs)
a particular word in a sentence belongs to. Current
state-of-the-art approaches have been shown to achieve
97% [23] accuracy in classifying POS tags for well-
written news articles.

Phrase and Clause Parsing. Also known as chunk-
ing, this technique further enhances the syntax of a sen-
tence by dividing it into a constituent set of words (or
phrases) that logically belong together (such as a Noun
Phrase and Verb Phrase). Current state-of-the-art ap-
proaches can achieve around 90% [23] accuracy in clas-
sifying phrases and clauses over well-written news arti-
cles.

Typed Dependencies [24,25]. The Stanford-typed de-
pendencies representation provides a hierarchical seman-
tic structure for a sentence using dependencies with pre-
cise deﬁnitions of what each dependency means.

Named Entity Recognition [26]. Also known as
‘entity identiﬁcation’ and ‘entity extraction’, these tech-
niques are a subtask of information extraction that aims
to classify words in a sentence into predeﬁned categories
such as names, quantities, and expressions of time.

We next describe the threat model that we considered

while designing our WHYPER framework.

2.2 Use Cases and Threat Model
WHYPER is an enabling technology for a number of use
cases.
In its simplest form, WHYPER could enable an
enhanced user experience for installing applications. For
example, the market interface could highlight the sen-
tences that correspond to a speciﬁc permission, or raise
warnings when it cannot ﬁnd any sentence for a permis-
sion. WHYPER could also be used by market providers
to help force developers to disclose functionality to users.
In its primitive form, market providers could use WHY-
PER to ensure permission requests have justiﬁcations in
the description. More advanced versions of WHYPER
could also incorporate the results of static and dynamic
application analysis to ensure more semantically appro-
priate justiﬁcations. Such requirements could be placed
on all new applications, or iteratively applied to exist-
ing applications by automatically emailing developers
of applications with unjustiﬁed permissions. Alterna-
tively, market providers and security researchers could

Figure 1: Overview of WHYPER

sensitive operations pertinent to a permission. However,
we demonstrate in our evaluation that such an approach
is limited by producing many false positives. We pro-
pose Natural Language Processing (NLP) as a means
to alleviate the shortcomings of keyword-based search-
ing. In particular, we address the following limitations
of keyword-based searching:

1. Confounding Effects. Certain keywords such as
“contact” have a confounding meaning. For in-
stance, ‘... displays user contacts, ...’ vs ‘... contact
me at abc@xyz.com’. The ﬁrst sentence fragment
refers to a sensitive operation while the second frag-
ment does not. However, both fragments include the
keyword “contact”.
To address this limitation, we propose NLP as a
means to infer semantics such as whether the word
refers to a resource or a generic action.

2. Semantic Inference. Sentences often describe a
sensitive operation such as reading contacts with-
out actually referring to keyword “contact”. For in-
stance, “share... with your friends via email, sms”.
The sentence fragment describes the need for read-
ing contacts; however the “contact” keyword is not
used.
To address this limitation, we propose to use API
documents as a source of semantic information for
identifying actions and resources related to a sensi-
tive operation.

To the best of our knowledge, ours is the ﬁrst frame-
work in this direction. We next present the key NLP tech-
niques used in this work.

2.1 NLP Preliminaries
Although well suited for human communication, it is
very difﬁcult to convert natural language into unambigu-

USENIX Association  

22nd USENIX Security Symposium  529

3

use WHYPER to help triage markets [5] for dangerous
and privacy infringing applications. Finally, WHYPER
could be used in concert with existing crowd-sourcing
techniques [27] designed to assess user expectations of
application functionality. All of these use cases have
unique threat models.

For the purposes of this paper, we consider the generic
use scenario where a human is notiﬁed by WHYPER if
speciﬁc permissions requested by an application are not
justiﬁed by the application’s textual description. WHY-
PER is primarily designed to help identify privacy in-
fringements in relatively benign applications. How-
ever, WHYPER can also help highlight malware that at-
tempts to sneak past consumers by adding additional per-
missions (e.g., to send premium-rate SMS messages).
Clearly, a developer can lie when writing the applica-
tion’s description. WHYPER does not attempt to detect
such lies.
Instead, we assume that statements describ-
ing unexpected functionality will appear out-of-place for
consumers reading an application description before in-
stalling it. We note that malware may still hide malicious
functionality (e.g., eavesdropping) within an application
designed to use the corresponding permission (e.g., an
application to take voice notes). However, false claims
in an application’s description can provide justiﬁcation
for removal from the market or potentially even criminal
prosecution. WHYPER does, however, provide defense
against developers that simply include a list of keywords
in the application description (e.g., to aid search rank-
ings).

Fundamentally, WHYPER identiﬁes if there a possible
implementation need for a permission based on the ap-
plication’s description. In a platform such as Android,
there are many ways to accomplish the same implemen-
tation goals. Some implementation options require per-
missions, while others do not. For example, an appli-
cation can make a call that starts Android’s address book
application to allow the user to select a contact (requiring
no permission), or it can access the address book directly
(requiring a permission). From WHYPER’s perspective,
it only matters that privileged functionality may work ex-
pectedly when using the application, and that functional-
ity is disclosed in the application’s description. Other
techniques (e.g., Stowaway [28]) can be used to deter-
mine if an application’s code actually requires a permis-
sion.

3 WHYPER Design
We next present our framework for annotating the sen-
tences that describe the needs for permissions in ap-
plication descriptions. Figure 2 gives an overview of
our framework. Our framework consists of ﬁve compo-
nents: a preprocessor, an NLP Parser, an intermediate-

Figure 2: Overview of WHYPER framework

representation generator, a semantic engine (SE), and an
analyzer.

The pre-processor accepts application descriptions
and preprocesses the sentences in the descriptions, such
as annotating sentence boundaries and reducing lexical
tokens. The intermediate-representation generator ac-
cepts the pre-processed sentences and parses them us-
ing an NLP parser. The parsed sentences are then trans-
formed into the ﬁrst-order-logic (FOL) representation.
SE accepts the FOL representation of a sentence and an-
notates the sentence based on the semantic graphs of per-
missions. Our semantic graphs are derived by analyzing
Android API documents. We next describe each compo-
nent in detail.

3.1 Preprocessor
The preprocessor accepts natural-language application
descriptions and preprocesses the sentences, to be fur-
ther analyzed by the intermediate-representation gener-
ator. The preprocessor annotates sentence boundaries,
and reduces the number of lexical tokens using seman-
tic information. The reduction of lexical tokens greatly
increases the accuracy of the analysis in the subsequent
components of our framework. In particular, the prepro-
cessor performs following preprocessing tasks:

1. Period Handling. In simplistic English, the char-
acter period (‘.’) marks the end of a sentence. However,
there are other legal usages of the period such as: (1)
decimal (periods between numbers), (2) ellipsis (three
continuous periods ‘...’), (3) shorthand notations (“Mr.”,
“Dr.”, “e.g.”). While these are legal usages, they hinder
detection of sentence boundaries, thus forcing the sub-

530  22nd USENIX Security Symposium 

USENIX Association

4

sequent components to return incorrect or imprecise re-
sults.

We pre-process the sentences by annotating these us-
ages for accurate detection of sentence boundaries. We
achieve so by looking up known shorthand words from
WordNet [29] and detecting decimals, which are also the
period character, by using regular expressions. From an
implementation perspective, we have maintained a static
lookup table of shorthand words observed in WordNet.
2. Sentence Boundaries. Furthermore, there are in-
stances where an enumeration list is used to describe
functionality, such as “The app provides the following
functionality: a) abc..., b) xyz... ”. While easy for a
human to understand the meaning, it is difﬁcult from a
machine to ﬁnd appropriate boundaries.

We leverage the structural (positional) information:
(1) placements of tabs, (2) bullet points (numbers, char-
acters, roman numerals, and symbols), and (3) delimiters
such as “:” to detect appropriate boundaries. We further
improve the boundary detection using the following pat-
terns we observe in application descriptions:

• We remove the leading and trailing ‘*’ and ‘-’ char-

acters in a sentence.

• We consider the following characters as sentence
separators: ‘–’, ‘- ’, ‘ø’, ‘§’, ‘†’, ‘(cid:30)’, ‘♦’, ‘♣’, ‘♥’,
‘♠’ ... A comprehensive list can be found on the
project website [14].

• For an enumeration sentence that contains at least
one enumeration phrase (longer than 5 words), we
break down the sentence to short sentences for each
enumerated item.

3. Named Entity Handling. Sometimes a sequence
of words correspond to the name of entities that have
a speciﬁc meaning collectively. For instance, consider
the phrases “Pandora internet radio”, “Google maps”,
which are the names of applications. Further resolution
of these phrases using grammatical syntax is unnecessary
and would not bring forth any semantic value. Thus, we
identify such phrases and annotate them as single lexi-
cal units. We achieve so by maintaining a static lookup
table.

4. Abbreviation Handling. Natural-language sen-
tences often consist of abbreviations mixed with text.
This can result in subsequent components to incorrectly
parse a sentence. We ﬁnd such instances and annotate
them as a single entity. For example, text followed by
abbreviations such as “Instant Message (IM)” is treated
as single lexical unit. Detecting such abbreviations is
achieved by using the common structure of abbreviations
and encoding such structures into regular expressions.
Typically, regular expressions provide a reasonable ap-
proximation for handling abbreviations.

Figure 3: Sentence annotated with Stanford dependen-
cies

3.2 NLP Parser
The NLP parser accepts the pre-processed documents
and annotates every sentence within each document us-
ing standard NLP techniques. From an implementation
perspective, we chose the Stanford Parser [30]. However,
this component can be implemented using any other ex-
isting NLP libraries or frameworks:

1. Named Entity Recognition: NLP parser identiﬁes
the named entities in the document and annotates
them. Additionally, these entities are further added
to the lookup table, so that the preprocessor use the
entities for processing subsequent sentences.

further

annotates

2. Stanford-Typed Dependencies:
[24, 25] NLP
sentences with
parser
the
Stanford-typed
Stanford-typed dependencies.
dependencies is a simple description of the gram-
matical relationships in a sentence, and targeted
towards extraction of textual relationships.
In
particular, we use standford-typed dependencies
as an input
intermediate-representation
generator.

to our

Next we use an example to illustrate the annotations
added by the NLP Parser. Consider the example sen-
tence “Also you can share the yoga exercise to your
friends via Email and SMS.”, that indirectly refers to the
READ CONTACTS permission. Figure 3 shows the sen-
tence annotated with Stanford-typed dependencies. The
words in red are the names of dependencies connecting
the actual words of the sentence (in black). Each word
is followed by the Part-Of-Speech (POS) tag of the word
(in green). For more details on Stanford-typed depen-
dencies and POS tags, please refer to [24, 25].

3.3

Intermediate-Representation Genera-
tor

The intermediate-representation generator accepts the
annotated documents and builds a relational represen-

USENIX Association  

22nd USENIX Security Symposium  531

5

the numbers following them. For instance, “you” ←
“share” → “yoga exercise” forms one tuple. Notice
the additional predicate “owned” annotated 6 in the Fig-
ure 4, does not appear in actual sentence. The additional
predicate “owned” is inserted when our intermediate-
representation generator encounters the possession mod-
iﬁer relation (annotated “poss” in Figure 3).

The FOL representation helps us effectively deal with
the problem of confounding effects of keywords as de-
scribed in Section 2.
In particular, the FOL assists in
distinguishing between a resource that would be a leaf
node and an action that would be a predicate node in the
intermediate representation of a sentence. The generated
FOL representation of the sentence is then provided as
an input to the semantic engine for further processing.

3.4 Semantic Engine (SE)
The Semantic Engine (SE) accepts the FOL representa-
tion of a sentence and based on the semantic graphs of
Android permissions annotates a sentence if it matches
the criteria. A semantic graph is basically a semantic
representation of the resources which are governed by a
permission. For instance, the READ CONTACTS per-
mission governs the resource “CONTACTS” in Android
system.

Figure 5 shows the semantic graph for the permission
READ CONTACTS. A semantic graph primarily con-
stitutes of subordinate resources of a permission (repre-
sented in rectangular boxes) and a set of available actions
on the resource itself (represented in curved boxes). Sec-
tion 3.5 elaborates on how we build such graphs system-
atically.

Our SE accepts the semantic graph pertaining to a
permission and annotates a sentence based on the algo-
rithm shown in Algorithm 1. The Algorithm accepts
the FOL representation of a sentence rep, the seman-
tic graph associated with the resource of a permission
g and a boolean value recursion that governs the recur-
sion. The algorithm outputs a boolean value isPStmt,
which is true if the statement describes the permission
associated with a semantic graph (g), otherwise false.
Our algorithm systematically explores the FOL rep-
resentation of the sentence to determine if a sentence
describes the need for a permission.
First, our al-
gorithm attempts to locate the occurrence of associ-
ated resource name within the leaf node of the FOL
representation of the sentence (Line 3). The method
findLeafContaining(name) explores the FOL rep-
resentation to ﬁnd a leaf node that contains term name.
Furthermore, we use WordNet and Lemmatisation [37]
to deal with synonyms of a word in question to ﬁnd ap-
propriate matches. Once a leaf node is found, we system-
atically traverse the tree from the leaf node to the root,

Figure 4: First-order logic representation of annotated
sentence in Figure 3

tation of the document. We deﬁne our representa-
tion as a tree structure that is essentially a First-Order-
Logic (FOL) expression. Recent research has shown
the adequacy of using FOL for NLP related analysis
tasks [31–33]. In our representation, every node in the
tree except for the leaf nodes is a predicate node. The leaf
nodes represent the entities. The children of the predicate
nodes are the participating entities in the relationship rep-
resented by the predicate. The ﬁrst or the only child of
a predicate node is the governing entity and the second
child is the dependent entity. Together the governing en-
tity, predicate and the dependent entity node form a tuple.
We implemented our intermediate-representation gen-
erator based on the principle shallow parsing [34] tech-
niques. A typical shallow parser attempts to parse a
sentence based on the function of POS tags. However,
we implemented our parser as a function of Stanford-
typed dependencies [22, 24, 25, 30]. We chose Stanford-
typed dependencies for parsing over POS tags because
Stanford-typed dependencies annotate the grammatical
relationships between words in a sentence, thus provide
more semantic information than POS tags that merely
highlight the syntax of a sentence.

In particular, our intermediate-representation genera-
tor is implemented as a series of cascading ﬁnite state
machines (FSM). Earlier research [31,33–36] has shown
the effectiveness and efﬁciency of using FSM in linguis-
tics analysis such as morphological lookup, POS tagging,
phrase parsing, and lexical lookup. We wrote semantic
templates for each of the typed dependencies provided
by the Stanford Parser.

Table 1 shows a few of these semantic templates. Col-
umn “Dependency” lists the name of the Stanford-typed
dependency, Column “Example” lists an example sen-
tence containing the dependency, and Column “Descrip-
tion” describes the formulation of tuple from the depen-
dency. All of these semantic templates are publicly avail-
able on our project website [14]. Figure 4 shows the
FOL representation of the sentence in Figure 3. For
ease of understanding, read the words in the order of

532  22nd USENIX Security Symposium 

USENIX Association

6

S. No. Dependency
1

conj

2

3

iobj

nsubj

Table 1: Semantic Templates for Stanford Typed Dependencies
Example
“Send via SMS and email.”
conj and(email, SMS)
“This App provides you with beautiful Governor (you) is treated as dependent entity of
wallpapers.” iobj(provides, you)

Description
Governor (SMS) and dependent (email) are
connected by a relationship of conjunction type(and)

relationship resolved by parsing the
dependent’s (provides) typed dependencies
Governor (This) is treated as governing entity of
relationship resolved by parsing the
dependent’s (widget) typed dependencies

“This is a scrollable widget.”
nsubj(widget, This)

matching all parent predicates as well as immediate child
predicates [Lines 5-16].

Our algorithm matches each of the traversed predicate
with the actions associated with the resource deﬁned in
semantic graph. Similar to matching entities, we also
employ WordNet and Lemmatisation [37] to deal with
synonyms to ﬁnd appropriate matches.
If a match is
found, then the value isPStmt is set to true, indicat-
ing that the statement describes a permission.

In case no match is found, our algorithms recursively
search all the associated subordinate resources in the se-
mantic graph of current resource. A subordinate resource
may further have its own subordinate resources. Cur-
rently, our algorithm considers only immediate subordi-
nate resources of a resource to limit the false positives.

In the context of the FOL representation shown in Fig-
ure 4, we invoke Algorithm 1 with the semantic graph
shown in Figure 5. Our algorithm attempts to ﬁnd a
leaf node containing term “CONTACT” or some of its
synonym. Since the FOL representation does not con-
tain such a leaf node, algorithm calls itself with se-
mantic graphs of subordinate resources (Line 17-25),
namely ‘NUMBER’, ‘EMAIL’, ‘LOCATION’, ‘BIRTH-
DAY’, ‘ANNIVERSARY’.

The subsequent invocation will ﬁnd the leaf-node
“email” (annotated 9 in Figure 4). Our algorithm
then explores the preceding predicates and ﬁnds pred-
icate “share” (annotated 2 in Figure 4). The Algo-
rithm matches the word “share” with action “send”
(using Lemmatisation and WordNet similarity), one of
the actions available in the semantic graph of resource
‘EMAIL’ and returns true. Thus, the sentence is appro-
priately identiﬁed as describing the need for permission
READ CONTACT.

3.5 Semantic-Graph Generator
A key aspect of our proposed framework is the employ-
ment of a semantic graph of a permission to perform deep
semantic inference of sentences. In particular, we pro-
pose to initially infer such graphs from API documents.

if actionList.contains(r(cid:31).parent.predicate) then

isPStmt = true
break

else

if actionList.contains(r(cid:31).le f tSibling.predicate) then

Algorithm 1 Sentence Annotator
Input: K Graph g, FOL rep rep, Boolean recursion
Output: Boolean isPStmt

isPStmt = true
break

1: Boolean isPStmt = f alse
2: String r name = g.resource Name
3: FOL rep r(cid:31) = rep. f indLea fContaining(r name)
4: List actionList = g.actionList
5: while (r(cid:31).hasParent) do
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16: end while
17:
18:
19:
20:
21:
22:
23:
24:
25: end if
26: return isPStmt

List resourceList = g.resourceList
for all (Resource res in resourceList) do

if ((NOT (isPStmt)) AND recursion) then

end if

end if
r(cid:31) = r(cid:31).parent

break

end if

end for

isPStmt = Sentence Annotator(getKGraph(res), rep, f alse)
if isPStmt then

For third-party applications in mobile devices, the rela-
tively limited resources (memory and computation power
compared to desktops and servers) encourage develop-
ment of thin clients. The key insight to leverage API
documents is that mobile applications are predominantly
thin clients, and actions and resources provided by API
documents can cover most of the functionality performed
by these thin clients.

Manually creating a semantic graph is prohibitively
time consuming and may be error prone. We thus came
up with a systematic methodology to infer such seman-
tic graphs from API documents that can potentially be
automated. First, we leverage Au et al.’s work [38]
to ﬁnd the API document of the class/interface pertain-
ing to a particular permission. Second, we identify
the corresponding resource associated with the permis-
sion from the API class name. For instance, we iden-
tify ‘CONTACTS’ and ‘ADDRESS BOOK’ from the

7

USENIX Association  

22nd USENIX Security Symposium  533

tic gap between user expectations and the permissions
it requests.
It does this by identifying in the applica-
tion description the sentences that describe the need for a
given permission. We refer to these sentences as permis-
sion sentences. To evaluate the effectiveness of WHY-
PER, we compare the permission sentences identiﬁed by
WHYPER to a manual annotation of all sentences in the
application descriptions. This comparison provides a
quantitative assessment of the effectiveness of WHYPER.
Speciﬁcally, we seek to answer the following research
questions:

• RQ1: What are the precision, recall and F-Score of
WHYPER in identifying permission sentences (i.e.,
sentences that describe need for a permission)?

• RQ2: How effective WHYPER is in identifying
permission sentences, compared to keyword-based
searching ?

4.1 Subjects
We evaluated WHYPER using a snapshot of popular ap-
plication descriptions. This snapshot was downloaded in
January 2012 and contained the top 500 free applications
in each category of the Google Play Store (16,001 total
unique applications). We then identiﬁed the applications
that contained speciﬁc permissions of interest.

we

our

For

evaluation,

consider
READ CALENDAR,

the
READ CONTACTS,
and
RECORD AUDIO permissions.
We chose these
permissions because they protect tangible resources that
users understand and have signiﬁcant enough security
and privacy implications that developers should provide
justiﬁcation in the application’s description. We found
that 2327 applications had at least one of these three
permissions. Since our evaluation requires manual effort
to classify each sentence in the application description,
we further reduced this set of applications by randomly
choosing 200 applications for each permission. This
resulted in a total of 600 unique applications for these
permissions. The set was further reduced by only con-
sidering applications that had an English description).
Overall, we analysed 581 application descriptions, which
contained 9,953 sentences (as parsed by WHYPER).

4.2 Evaluation Setup
We ﬁrst manually annotated the sentences in the appli-
cation descriptions. We had three authors independently
annotate sentences in our corpus, ensuring that each sen-
tence was annotated by at least two authors. The individ-
ual annotations were then discussed by all three authors
to reach to a consensus. In our evaluation, we annotated

Figure 5: Semantic Graph for the READ CONTACT
permission

ContactsContract.Contacts1 class that is associ-
ated with READ CONTACT permission. Third, we sys-
tematically inspect the member variables and member
methods to identify actions and subordinate resources.

For

From the name of member variables, we ex-
tract noun phrases and then investigate their types
for deciding whether
these noun phrases describe
resources.
instance, one of member vari-
ables of ContactsContract.Contracts class leads
us
to its member variable “email” (whose type
is ContactsContract.CommonDataKinds.Email).
From this variable, we extract noun phrase “EMAIL” and
classify the phrase as a resource.

From the name of an Android API public method
(describing a possible action on a resource), we ex-
tract both noun phrases and their related verb phrases.
The noun phrases are used as resources and the verb
phrases are used as the associated actions. For instance,
ContactsContract.Contacts deﬁnes operations In-
sert, Update, Delete, and so on. We consider those opera-
tions as individual actions associated with ‘CONTACTS’
resource.

The process is iteratively applied to the individual sub-
ordinate resources that are discovered for an API. For in-
stance, “EMAIL” is identiﬁed as a subordinate resource
in “CONTACT” resource. Figure 5 shows a sub-graph of
graph for READ CONTACT permission.

4 Evaluation

We now present the evaluation of WHYPER. Given an
application, the WHYPER framework bridges the seman-

1http://developer.android.com/reference/

android/provider/ContactsContract.Contacts.html

8

534  22nd USENIX Security Symposium 

USENIX Association

Table 2: Statistics of Subject permissions

SP
Permission
235
READ CONTACTS
283
READ CALENDAR
245
RECORD AUDIO
TOTAL
763
#N: Number of applications that requests the permission; #S: Total
number of sentences in the application descriptions; SP: Number of
sentences manually identiﬁed as permission sentences.

#S
3379
2752
3822
9953

#N
190
191
200
581

a sentence as a permission sentence if at least two au-
thors agreed that the sentence described the need for a
permission. Otherwise we annotated the sentence as a
permission-irrelevant sentence.

We applied WHYPER on the application descrip-
tions and manually measured the number of true
positives (T P), false positives (FP), true
negatives (T N) and false negatives (FN) pro-
duced by WHYPER as follows:

1. T P: A sentence that WHYPER correctly identiﬁes

as a permission sentence.

2. FP: A sentence that WHYPER incorrectly identiﬁes

as a permission sentence.

3. T N: A sentence that WHYPER correctly identiﬁes

as not a permission sentence.

4. FN: A sentence that WHYPER incorrectly identiﬁes

as not a permission sentence.

Table 2 shows the statistics of the subjects used in the
evaluations of WHYPER. Column “Permission” lists the
names of the permissions. Column “#N” lists the number
of applications that requests the permissions used in our
evaluations. Column “#S” lists the total number of sen-
tences in application descriptions. Finally, Column “SP”
lists the number of sentences that are manually identi-
ﬁed as permission sentences by authors. We used this
manual identiﬁcation (Column “SP”) to quantify the ef-
fectiveness of WHYPER in identifying permission sen-
tences by answering RQ1. The results of Column “SP”
is also used to compare WHYPER with keyword-based
searching to answer RQ2 described next.

For RQ2, we applied keyword-based searching on the
same subjects. We consider a word as a keyword in
the context of a permission if it is a synonym of the
word in the permission. To minimize manual efforts, we
used words present in Manifest.permission class
from Android API. Table 4 shows the keywords used in
our evaluation. We then measured the number of true
positives (T P(cid:31)), false positives (FP(cid:31)), true
negatives (T N(cid:31)), and false negatives (FN(cid:31)) pro-
duced by the keyword-based searching as follows:

1. T P(cid:31):- A sentence that is a permission sentence and

contains the keywords.

2. FP(cid:31):- A sentence that is not a permission sentence

but contains the keywords.

3. T N(cid:31):- A sentence that is not a permission sentence

and does not contain the keywords.

4. FN(cid:31):- A sentence that is a permission sentence but

does not contain the keywords.

In statistical classiﬁcation [39], Precision is deﬁned as
the ratio of the number of true positives to the total num-
ber of items reported to be true, and Recall is deﬁned
as the ratio of the number of true positives to the total
number of items that are true. F-score is deﬁned as the
weighted harmonic mean of Precision and Recall. Accu-
racy is deﬁned as the ratio of sum of true positives and
true negatives to the total number of items. Higher val-
ues of precision, recall, F-Score, and accuracy indicate
higher quality of the permission sentences inferred us-
ing WHYPER. Based on the total number of TPs, FPs,
TNs, and FNs, we computed the precision, recall, F-
score, and accuracy of WHYPER in identifying permis-
sion sentences as follows:

Precision = T P
Recall = T P

T P + FP

T P + FN

F-score = 2 X Precision X Recall
Precision + Recall
Accuracy =

T P + FP+T N + FN

T P+T N

4.3 Results
We next describe our evaluation results to demonstrate
the effectiveness of WHYPER in identifying contract sen-
tences.

4.3.1 RQ1: Effectiveness in identifying permission

sentences

In this section, we quantify the effectiveness of WHY-
PER in identifying permission sentences by answer-
ing RQ1. Table 3 shows the effectiveness of WHY-
PER in identifying permission sentences. Column “Per-
mission” lists the names of the permissions. Col-
umn “SI” lists the number of sentences identiﬁed by
WHYPER as permission sentences. Columns “TP”,
“FP”, “TN”, and “FN” represent the number of true
positives, false positives, true negatives,
and false negatives, respectively. Columns “P(%)”,
“R(%)”, “FS(%)”, and “Acc(%)” list percentage values
of precision, recall, F-score, and accurary re-
spectively. Our results show that, out of 9,953 sen-
tences, WHYPER effectively identiﬁes permission sen-
tences with the average precision, recall, F-score, and

USENIX Association  

22nd USENIX Security Symposium  535

9

Table 3: Evaluation results
TP
186
241
195
622

2930
2422
3470
9061

FP
18
47
64
129

FN
49
42
50
141

SI
204
288
259
751

Permission
READ CONTACTS
READ CALENDAR
RECORD AUDIO
TOTAL
∗ Column average; SI: Number of sentences identiﬁed by WHYPER as permission sentences; TP: Total number of True
Positives; FP: Total number of False Positives; FN: Total number of False Negatives; TN: Total number of True Negatives;
P: Precision; R: Recall; FS: F-Score; and Acc: Accuracy

TN P (%) R (%)
79.1
85.1
79.7
81.5∗

FS (%)
84.7
84.4
77.4
82.2∗

Acc (%)
97.9
96.8
97.0
97.3∗

91.2
83.7
75.9
82.8∗

accuracy of 82.8%, 81.5%, 82.2%, and 97.3%, respec-
tively.

We also observed that out of 581 applications whose
descriptions we used in our experiments, there were only
86 applications that contained at least one false negative
statement that were annotated by WHYPER. Similarly,
among 581 applications whose descriptions we used in
our experiments, there were only 109 applications that
contained at least one false positive statement that were
annotated by WHYPER.

We next present an example to illustrate how WHYPER
incorrectly identiﬁes a sentence as a permission sentence
(producing false positives). False positives are particu-
larly undesirable in the context of our problem domain,
because they can mislead the users of WHYPER into be-
lieving that a description actually describes the need for
a permission. Furthermore, an overwhelming number of
false positives may result in user fatigue, and thus de-
value the usefulness of WHYPER.

Consider the sentence “You can now turn recordings
into ringtones.”. The sentence describes the application
functionality that allows users to create ringtones from
previously recorded sounds. However, the described
functionality does not require the permission to record
audio. WHYPER identiﬁes this sentence as a permis-
sion sentence. WHYPER correctly identiﬁes the word
recordings as a resource associated with the record au-
dio permission. Furthermore, our intermediate represen-
tation also correctly constructs that action turn is being
performed on the resource recordings. However, our se-
mantic engine incorrectly matches the action turn with
the action start. The later being a valid semantic action
that is permitted by the API on the resource recording.
In particular, the general purpose WordNet-based Simi-
larity Metric [37] shows 93.3% similarity. We observed
that a majority of false positives resulted from incorrect
matching of semantic actions against a resources. Such
instances can be addressed by using domain-speciﬁc dic-
tionaries for synonym analysis.

Another major source of FPs is the incorrect pars-
ing of sentences by the underlying NLP infrastructure.
For instance, consider the sentence “MyLink Advanced
provides full synchronization of all Microsoft Outlook

emails (inbox, sent, outbox and drafts), contacts, calen-
dar, tasks and notes with all Android phones via USB.”.
The sentence describes the users calendar will be syn-
chronized. However, the underlying Stanford parser [30]
is not able to accurately annotate the dependencies. Our
intermediate-representation generator uses shallow pars-
ing that is a function of these dependencies. An inaccu-
rate dependency annotation causes an incorrect construc-
tion of intermediate representation and eventually causes
an incorrect classiﬁcation. Such instances will be ad-
dressed with the advancement in underlying NLP infras-
tructure. Overall, a signiﬁcant number of false positives
will be reduced by as the current NLP research advances
the underlying NLP infrastructure.

We next present an example to illustrate how WHY-
PER fails to identify a valid permission sentence (false
negatives). Consider the sentence “Blow into the mic to
extinguish the ﬂame like a real candle”. The sentence
describes a semantic action of blowing into the micro-
phone. The noise created by blowing will be captured by
the microphone, thus implying the need for record audio
permission. WHYPER correctly identiﬁes the word mic
as a resource associated with the record audio permis-
sion. Furthermore, our intermediate representation also
correctly shows that the action blow into is performed on
the resource mic. However, from API documents, there
is no way for WHYPER framework to infer the knowl-
edge that blowing into microphone semantically implies
recording of the sound. Thus, WHYPER fails to identify
the sentence as a permission sentence. We can reduce
a signiﬁcant number of false negatives by constructing
better semantic graphs.

Similar to reasons for false positives, a major source
of false negatives is the incorrect parsing of sentences
by the underlying NLP infrastructure. For instance, con-
sider the sentence “Pregnancy calendar is an application
that,not only allows, after entering date of last period
menstrual,to calculate the presumed (or estimated) date
of birth; but, offering prospects to show,week to week,all
appointments which must to undergo every mother,ad a
rule,for a correct and healthy pregnancy.” 2 The sen-

2Note that the incorrect grammar, punctuation, and spacing are a

536  22nd USENIX Security Symposium 

USENIX Association

10

tence describes that the users calendar will be used to
display weekly appointments. However, the length and
complexity in terms of number of clauses causes the un-
derlying Stanford parser [30] to inaccurately annotate
the dependencies, which eventually results into incorrect
classiﬁcation.

We also observed that in a few cases, the process fol-
lowed to identify sentence boundaries resulted in ex-
tremely long and possibly incorrect sentences. Consider
a sentence that our preprocessor did not identify as a per-
mission sentence for READ CALENDER permission:

Daily Brief “How does my day look like today” “Any meetings today” “My
reminders” “Add reminder” Essentials Email, Text, Voice dial, Maps, Directions,
Web Search “Email John Subject Hello Message Looking forward to meeting
with you tomorrow” “Text Lisa Message I will be home in an hour” “Map of
Chicago downtown” “Navigate to Millenium Park” “Web Search Green Bean
Casserole” “Open Calculator” “Opean Alarm Clock” “Launch Phone book” Per-
sonal Health Planner ... “How many days until Christmas” Travel Planner “Show
airline directory” “Find hotels” “Rent a car” “Check ﬂight status” “Currency con-
verter” Cluzee Car Mode Access Daily Brief, Personal Radio, Search, Maps, Di-
rections etc..

A few fragments (sub-sentences) of this incorrectly
marked sentence describe the need for read calender per-
mission (“...My reminder ... Add reminder ...”). How-
ever,
inaccurate identiﬁcation of sentence boundaries
causes the underlying NLP infrastructure produces a in-
correct annotation. Such incorrect annotation is propa-
gated to subsequent phases of WHYPER, ultimately re-
sulting in inaccurate identiﬁcation of a permission sen-
tence. Overall, as the current research in the ﬁled of NLP
advances the underlying NLP infrastructure, a signiﬁcant
number of false negatives will be reduced.

4.3.2 RQ2: Comparison to keyword-based search-

ing

In this section, we answer RQ2 by comparing WHY-
PER to a keyword-based searching approach in identify-
ing permission sentences. As described in Section 4.2,
we manually measured the number of permission sen-
tences in the application descriptions. Furthermore, we
also manually computed the precision (P), recall (R),
f-score (FS), and accuracy (Acc) of WHYPER as well
as precision (P(cid:31)), recall (R(cid:31)), f-score (F(cid:31)S), and accuracy
(Acc(cid:31)) of keyword-based searching in identifying per-
mission sentences. We then calculated the improvement
in using WHYPER against keyword-based searching as
∆P = P− P(cid:31), ∆R = R− R(cid:31), ∆FS = FS − F(cid:31)S, and ∆Acc =
Acc − Acc(cid:31). Higher values of ∆P, ∆R, ∆FS, and ∆Acc
are indicative of better performance of WHYPER against
keyword-based search.

Table 5 shows the comparison of WHYPER in identi-
fying permission sentences to keyword-based searching

reproduction of the original description.

Table 4: Keywords for Permissions

S. No

Permission

Keywords

1

2

3

READ CONTACTS

contact, data, number,

name, email

READ CALENDAR

calendar, event, date,

RECORD AUDIO

month, day, year

record, audio, voice,
capture, microphone

Table 5: Comparison with keyword-based search

∆P% ∆R% ∆FS% ∆Acc%
7.3
50.4
39.3
9.2
6.8
36.9
41.6
7.7

31.2
26.4
24.3
27.2

Permission
READ CONTACTS
READ CALENDAR
RECORD AUDIO
Average

1.3
1.5
-6.6
-1.2

approach. Columns “∆P”, “∆R”, “∆FS”, and “∆Acc” list
percentage values of increase in the precision, recall, f-
scores, and accuracy respectively. Our results show that,
in comparison to keyword-based searching, WHYPER ef-
fectively identiﬁes permission sentences with the average
increase in precision, F-score, and accuracy of 41.6%,
27.2%, and 7.7% respectively. We indeed observed a de-
crease in average recall by 1.2%, primarily due to poor
performance of WHYPER for RECORD AUDIO permis-
sion.

However, it is interesting to note that there is a sub-
stantial increase in precision (average 46.0%) in com-
parison to keyword-based searching. This increase is
attributed to a large false positive rate of keyword-
based searching.
In particular, for descriptions related
to READ CONTACTS permission, WHYPER resulted
in only 18 false positives compared to 265 false posi-
tives resulted by keyword-based search. Similarly, for
descriptions related to RECORD AUDIO, WHYPER re-
sulted in 64 false positives while keyword-based search-
ing produces 338 false positives.

We next present illustrative examples of how WHY-
PER performs better than keyword-based search in con-
text of false positives. One major source of false posi-
tives in keyword-based search is confounding effects of
certain keywords such as contact. Consider the sentence
“contact me if there is a bad translation or you’d like
your language added!”. The sentence describes that de-
veloper is open to feedback about his application. A
keyword-based searching incorrectly identiﬁes this sen-
tence as a permission sentence for READ CONTACTS
permission. However, the word contact here refers to an
action rather than a resource. In contrast, WHYPER cor-
rectly identiﬁes the word contact as an action applicable
to pronoun me. Our framework thus correctly classiﬁes
the sentences as a permission-irrelevant sentence.

USENIX Association  

22nd USENIX Security Symposium  537

11

Consider another sentence “To learn more, please
visit our Checkmark Calendar web site:
calen-
dar.greenbeansoft.com” as an instance of confounding
effect of keywords. The sentence is incorrectly identiﬁed
as a permission sentence for READ CALENDAR per-
mission because it contains keyword calendar. In con-
trast, WHYPER correctly identiﬁes “Checkmark Calen-
dar” as a named entity rather than resource calendar. Our
framework thus correctly identiﬁes the sentences as not
a permission sentence.

Another common source of false positives in keyword-
based searching is lack of semantic context around a
keyword. For instance, consider the sentence “That’s
what this app brings to you in addition to learning
numbers!”. A keyword-based search classiﬁes this
sentence as an permission sentence because it con-
tains the keyword number, which is one of the key-
words for READ CONTACTS permission as listed in
Table 4. However, the sentence is actually describing
the generic numbers rather than phone numbers. Simi-
lar to keyword-based search, our framework also identi-
ﬁes word number as a candidate match for subordinat-
ing resource number in READ CONTACTS permission
(Figure 5). However, the identiﬁed semantic action on
candidate resource number for this sentence is learning.
Since learning is not an applicable action to phone num-
ber resource in our semantic graphs, WHYPER correctly
classiﬁes the sentences as not a permission sentence.

The ﬁnal category, where WHYPER performed better
than keyword-based search, is due to the use of syn-
onyms. For instance, address book is a synonym for con-
tact resource. Similarly mic is synonym for microphone
resource. Our framework, leverages this synonym infor-
mation in identifying the resources in a sentence. Syn-
onyms could potentially be used to augment the list of
keywords in keyword-based search. However, given that
keyword-based search already suffers from a very high
false positive rate, we believe synonym augmentation to
keywords would further worsen the problem.

We next present discussions on why WHYPER caused
a decline in recall
in comparison to keyword-based
search. We do observe a small increase in recall for
READ CONTACTS (1.3%) and READ CALENDAR
(1.5%) permission related sentences,
indicating that
WHYPER performs slightly better than keyword-based
search. However, WHYPER performs particularly worse
in RECORD AUDIO permission related descriptions,
which results in overall decrease in the recall compared
to keyword-based search.

One of the reasons for such decline in the recall is an
outcome of the false negatives produced by our frame-
work. As described in Section 4.3.1 incorrect identiﬁca-
tion of sentence boundaries and limitations of underlying
NLP infrastructure caused a signiﬁcant number of false

negatives in WHYPER. Thus, improvement in these ar-
eas will signiﬁcantly decrease the false negative rate of
WHYPER and in turn, make the existing gap negligible.
Another cause of false negatives in our approach is in-
ability to infer knowledge for some ‘resource’-‘semantic
action’ pairs, for instance, ‘microphone’-‘blow into’. We
further observed, that with a small manual effort in aug-
menting semantic graphs for a permission, we could
signiﬁcantly bring down the false negatives of our ap-
proach. For instance, after a precursory observation of
false negative sentences for RECORD AUDIO permis-
sion manually, we augmented the semantic graphs with
just two resource-action pairs (1. microphone-blow into
and 2. call-record). We then applied WHYPER with the
augmented semantic graph on READ CONTACTS per-
mission sentences.

The outcome increased ∆R value from -6.6% to 0.6%
for RECORD AUDIO permission and an average in-
crease of 1.1% in ∆R across all three permissions, with-
out affecting values for ∆P. We refrained from including
such modiﬁcations for reporting the results in Table 5
to stay true to our proposed framework. In the future,
we plan to investigate techniques to construct better se-
mantic graphs for permissions, such as mining user com-
ments and forums.

4.4 Summary
In summary, we demonstrate that WHYPER effectively
identiﬁes permission sentences with the average preci-
sion, recall, F-score, and accuracy of 80.1%, 78.6%,
79.3%, and 97.3% respectively. Furthermore, we also
show that WHYPER performs better than keyword-based
search with an average increase in precision of 40% with
a relatively small decrease in average recall (1.2%). We
also provide discussion that such gap in recall can be al-
leviated by improving the underlying NLP infrastructure
and a little manual effort. We next present discussions on
threats to validity.

4.5 Threats to Validity
Threats to external validity primarily include the degree
to which the subject permissions used in our evaluations
were representative permissions. To minimize the threat,
we used permissions that guard against the resources that
can be subjected to privacy and security sensitive opera-
tions. The threat can be further reduced by evaluating
WHYPER on more permissions. Another threat to ex-
ternal validity is the representativeness of the descrip-
tion sentences we used in our experiments. To minimize
the threat we randomly selected actual Android appli-
cation descriptions from a snapshot of the meta-data of

538  22nd USENIX Security Symposium 

USENIX Association

12

16001 applications from Google Play store (dated Jan-
uary 2012).

Threats to internal validity include the correctness of
our implementation in inferring mapping between natu-
ral language description sentences and application per-
missions. To reduce the threat, we manually inspected
all the sentences annotated by our system. Furthermore,
we ensured that the results were individually veriﬁed and
agreed upon by at least two authors. The results of our
experiments are publicly available on the project web-
site [14].

5 Discussions and Future work

Our framework currently only takes into account appli-
cation descriptions and Android API documents to high-
light permission sentences. Thus, our framework can
semi-formally enumerate the uses of a permission. This
information can be leveraged in the future to enhance
searching for desired applications.

Furthermore, the outputs from our framework could be
used in conjunction with program analysis techniques to
facilitate effective code reuse. For instance, our frame-
work outputs the reasons of why a permission is needed
for an application. These reasons are usually the func-
tionalities provided by the application. In future work,
we plan to locate the code fragments that implement the
described functionalities. Such mapping can be used as
indexes to existing code searching approaches [40,41] to
facilitate effective reuse.

Modular Applications: In our evaluations, we en-
countered cases where a description referring to another
application where the permission sentences were de-
scribed. For instance, consider the following descrip-
tion sentence “Navigation2GO is an application to eas-
ily launch Google Maps Navigation.”.

The description states that the current application will
launch another application “Google Maps Navigation”,
and thus requires the permissions required by that ap-
plication. Currently, our framework does not deal with
such cases. We plan to implement deeper semantic anal-
ysis of description sentences to identify such permission
sentences.

Generalization to Other Permissions: WHYPER is
designed to identify the textual justiﬁcation for permis-
sions that protect “user understandable” information and
resources. That is, the permission must protect an infor-
mation source or resource that is in the domain of knowl-
edge of general smartphone users, as opposed to a low-
level API only known to developers. The permissions
studied in this paper (i.e., address book, calendar, micro-
phone) fall within this domain. Based on our studies,
we expect similar permissions, such as those that protect
SMS interfaces and data stores, the ability to make and

receive phone calls, read call logs and browser history,
operate and administer Bluetooth and NFC, and access
and use phone accounts will have similar success with
WHYPER.

Due to current developer trends and practices, there
is class of permissions that we expect will raise alarms
for many applications when evaluated with WHYPER.
Recent work [7, 11] has shown that many applications
leak geographic location and phone identiﬁers without
the users knowledge. We recommend that deployments
of WHYPER ﬁrst focus on other permissions to better
gauge and account for developer response. Once general
deployment experience with WHYPER has been gained,
these more contentious permissions should be tackled.
We believe that adding justiﬁcation for access to geo-
graphic location and phone identiﬁers in the application’s
textual description will beneﬁt users. For example, if an
application uses location for ads or analytics, the devel-
oper should state this in the application description.

Finally, there are some permissions that are implicitly
used by applications and therefore will have poor results
with WHYPER. In particular, we do not expect the Inter-
net permission to work well with WHYPER. Nearly all
smartphone applications access the Internet, and we ex-
pect attempts to build a semantic graph for the Internet
permission will be largely ineffective.

Results Presentation: A potential after-effect of us-
ing WHYPER on existing application descriptions might
be more verbose application descriptions. One can argue
that it would lead to additional burden on end users to
read a lengthy description. However, such additional de-
scription provides an opportunity for the users to make
informed decisions instead of making assumptions. In
future work, we plan to implement and evaluate inter-
faces to present users with information in a more efﬁcient
way, countering user fatigue in case of lengthy descrip-
tions. For example, we may consider using icons in dif-
ferent colors to represent permissions with and without
explanation.

6 Related Work

Our proposed framework touches quiet a few research
areas such as mining Mobile Application Stores, NLP on
software engineering artifacts, program comprehension
and software veriﬁcation. We next discuss relevant work
pertinent to our proposed framework in these areas.

Harman et al. [42], ﬁrst used mining approaches on
the application description, pricing, and customer rat-
ings in Blackberry App Store.
In particular, they use
light-weight text analytics to extract feature information,
which is then combined with pricing and customer rat-
ing to analyze applications’ business aspects.
In con-
trast, WHYPER uses deep semantic analysis of sentences

USENIX Association  

22nd USENIX Security Symposium  539

13

in application descriptions, which can be used as a com-
plimentary approach to their feature extraction.

The use of NLP techniques is not new in the software
engineering domain. NLP has been used previously in
requirements engineering [31, 32, 43]. NLP has even
been used to assess the usability of API docs [44].

There are existing approaches [33, 45–47] that apply
either NLP or a mix of NLP and machine learning algo-
rithms to infer speciﬁcations from the natural-language
elements such as code comments, API descriptions, and
formal requirements documents. The semi-formal struc-
ture of natural-language documents used in these ap-
proaches facilitate the application of NLP techniques
required for these problem areas. Furthermore, these
approaches often rely on some meta-information from
source code as well. In contrast, our proposed framework
targets a relatively more unconstrained natural-language
text and is independent of the source code of the applica-
tion under analysis.

With respect to program comprehension there are
existing techniques that assist
in building domain-
speciﬁc ontologies [48]. Furthermore, there are exist-
ing approaches [49, 50] that automatically infer natural-
language documentation from source code. These ap-
proaches would immensely help in comprehension of the
functionality of a mobile application. However, the in-
herent dependency on source code to generate such doc-
uments poses a problem in cases, where source code is
not available. In contrast, WHYPER relies on application
description and API documents that are readily available
artifact for mobile applications.

In the realm of mobile software veriﬁcation, there is
existing work on permissions [2–5, 15], code [6–10],
and runtime behavior [11–13] to detect malicious ap-
plications. In particular, Zhou et al. [3] propose an ap-
proach that leverages the permission information in the
manifest of the applications as a criteria to ﬁlter mali-
cious applications. They further employed static analy-
sis to identify the malicious applications by forming be-
havioral patterns in terms of sequences of API calls of
known malicious applications. They also propose the use
of heuristics-based dynamic analysis to detect previously
unknown applications. Furthermore, Enck et al. [11] also
use dynamic analysis techniques (dynamic taint analysis)
to detect misuse of users private information.

These previously described techniques are primarily
targeted towards ﬁnding malicious applications in mo-
bile applications. However, these approaches do little for
bridging the semantic gap between what the user expects
an application to do and what it actually does. In con-
trast, WHYPER is the ﬁrst step targeted towards bridging
this gap. Furthermore, WHYPER can be used in conjunc-
tion with these approaches for an improved experience
while interacting with mobile ecosystem.

In addition, Felt et al. [28] apply automated testing
techniques to ﬁnd permission required to invoke each
method in the Android 2.2 API. They use this informa-
tion to detect over-privilege in Android Applications, by
generating a maximum set of permissions required by
an applications and comparing them to the permissions
requested by the application. Although it is important
from a developer perspective to minimize the set of per-
missions requested, the information does not empower
an end user to decide what the requested permissions are
being used for. In contrast, WHYPER leverages some of
the results provided by Felt et al. [28] to highlight the
sentences describing the need for a permission, in turn
enabling end users to make informed decision while in-
stalling and application

Finally, Lin et al. [27] introduce a new model for pri-
vacy, namely privacy as expectations for mobile appli-
cations. In particular, they use crowd-sourcing as means
to capture users expectations of sensitive resources used
by a mobile applications. We believe the sentences high-
lighted by WHYPER, can be used as supporting evidence
to formulate such user expectations at the ﬁrst place.

7 Conclusion

In this paper, we have presented WHYPER, a frame-
work that uses Natural Language Processing (NLP) tech-
niques to determine why an application uses a permis-
sion. We evaluated our prototype implementation of
WHYPER on real-world application descriptions that in-
volve three permissions (address book, calendar, and
record audio). These are frequently-used permissions
that protect privacy and security sensitive resources. Our
evaluation results show that WHYPER achieves an aver-
age precision of 82.8%, and an average recall of 81.5%
for three permissions. In summary, our results demon-
strate great promise in using NLP techniques to bridge
the semantic gap of user expectations to aid the risk as-
sessment of mobile applications.

8 Acknowledgments

This work was supported in part by an NSA Science
of Security Lablet grant at North Carolina State Uni-
versity, NSF grants CCF-0845272, CCF-0915400, CNS-
0958235, CNS-1160603, CNS-1222680, and CNS-
1253346. Any opinions, ﬁndings, and conclusions or
recommendations expressed in this material are those of
the authors and do not necessarily reﬂect the views of
the funding agencies. We would also like to thank the
conference reviewers and shepherds for their feedback
in ﬁnalizing this paper.

540  22nd USENIX Security Symposium 

USENIX Association

14

References

[1] H. Lockheimer, “Android and security,” Google
Mobile Blog, Feb. 2012, http://googlemobile.
blogspot.com/2012/02/android-and-security.html.

[2] A. P. Felt, M. Finifter, E. Chin, S. Hanna, and
D. Wagner, “A survey of mobile malware in the
wild,” in Proc. 1st ACM SPSM Workshop, 2011, pp.
3–14.

[3] Y. Zhou, Z. Wang, W. Zhou, and X. Jiang, “Hey,
you, get off of my market: Detecting malicious
Apps in ofﬁcial and alternative Android markets,”
in Proc. of 19th NDSS, 2012.

[12] P. Hornyack, S. Han, J. Jung, S. Schechter, and
D. Wetherall, “These aren’t the droids you’re look-
ing for: Retroﬁtting Android to protect data from
imperious applications,” in Proc. 18th ACM CCS,
2011, pp. 639–652.

[13] L. K. Yan and H. Yin, “DroidScope: Seamlessly
reconstructing the OS and Dalvik semantic views
for dynamic Android malware analysis,” in Proc.
of 21st USENIX Security Symposium, 2012, p. 29.

[14] “Whyper,” https://sites.google.com/site/whypermission/.

[15] W. Enck, M. Ongtang, and P. McDaniel, “On
lightweight mobile phone application certiﬁcation,”
in Proc. of 16th ACM CCS, 2009, pp. 235–245.

[4] H. Peng, C. Gates, B. Sarma, N. Li, Y. Qi,
R. Potharaju, C. Nita-Rotaru, and I. Molloy, “Using
probabilistic generative models for ranking risks of
Android Apps,” in Proc. of 19th ACM CCS, 2012,
pp. 241–252.

[16] D. Barrera, H. G. Kayacik, P. C. van Oorshot, and
A. Somayaji, “A methodology for empirical analy-
sis of permission-based security models and its ap-
plication to Android,” in Proc. of 7th ACM CCD,
2010, pp. 73–84.

[5] S. Chakradeo, B. Reaves, P. Traynor, and W. Enck,
“MAST: Triage for market-scale mobile malware
analysis,” in Proc. 6th of ACM WiSec, 2013, pp.
13–24.

[6] M. Egele, C. Kruegel, E. Kirda, and G. Vigna,
“PiOS: Detecting privacy leaks in iOS applica-
tions.”

[7] W. Enck, D. Octeau, P. McDaniel, and S. Chaud-
huri, “A study of Android application security,”
in Proc. 20th USENIX Security Symposium, 2011,
p. 21.

[8] Y. Zhou and X. Jiang, “Dissecting Android mal-
ware: Characterization and evolution,” in Proc. of
IEEE Symposium on Security and Privacy, 2012,
pp. 95–109.

[9] M. Grace, Y. Zhou, Q. Zhang, S. Zou, and X. Jiang,
“RiskRanker: Scalable and accurate zero-day An-
droid malware detection,” in Proc. of 10th MobiSys,
2012, pp. 281–294.

[10] C. Gibler, J. Crussell, J. Erickson, and H. Chen,
“AndroidLeaks: Automatically detecting potential
privacy leaks in Android applications on a large
scale,” in Proc. of 5th TRUST, 2012, pp. 291–307.

[11] W. Enck, P. Gilbert, B. Chun, L. Cox, J. Jung,
P. McDaniel, and A. Sheth, “TaintDroid:
an
information-ﬂow tracking system for realtime pri-
vacy monitoring on smartphones,” in Proc. of 9th
USENIX OSDI, 2010, pp. 1–6.

[17] A. P. Felt, K. Greenwood, and D. Wagner, “The ef-
fectiveness of application permissions,” in Proc. of
2nd USENIX WebApps, 2011, pp. 7–7.

[18] A. P. Felt, E. Ha, S. Egelman, A. Haney, E. Chin,
and D. Wagner, “Android permissions: User atten-
tion, comprehension and behavior,” in Proc. of 8th
SOUPS, 2012, p. 3.

[19] P. McDaniel and W. Enck, “Not so great expecta-
tions: Why application markets haven’t failed se-
curity,” IEEE Security & Privacy Magazine, vol. 8,
no. 5, pp. 76–78, 2010.

[20] J. Han, Q. Yan, D. Gao, J. Zhou, and R. Deng,
“Comparing mobile privacy protection through
cross-platform applications,” in Proc. of 20th
NDSS, 2013.

[21] K. Toutanova, D. Klein, C. D. Manning, and
Y. Singer, “Feature-rich part-of-speech tagging
with a cyclic dependency network.” in Proc. HLT-
NAACL, 2003, pp. 252–259.

[22] D. Klein and D. Manning, Christopher, “Fast ex-
act inference with a factored model for natural lan-
guage parsing,” in Proc. 15th NIPS, 2003, pp. 3 –
10.

[23] “The Stanford Natural Language Processing

Group,” 1999, http://nlp.stanford.edu/.

[24] M. C. de Marneffe, B. MacCartney, and C. D. Man-
ning, “Generating typed dependency parses from
phrase structure parses,” in Proc. 5th LREC, 2006,
pp. 449–454.

USENIX Association  

22nd USENIX Security Symposium  541

15

[25] M. C. de Marneffe and C. D. Manning, “The stan-
ford typed dependencies representation,” in Proc.
Workshop COLING, 2008, pp. 1–8.

[38] K. W. Y. Au, Y. F. Zhou, Z. Huang, and D. Lie,
“PScout: analyzing the Android permission speci-
ﬁcation,” in Proc. 19th CCS, 2012, pp. 217–228.

[26] J. R. Finkel, T. Grenager, and C. Manning., “Incor-
porating non-local information into information ex-
traction systems by gibbs sampling,” in Proc. 43nd
ACL, 2005, pp. 363–370.

[27] J. Lin, N. Sadeh, S. Amini, J. Lindqvist, J. I. Hong,
and J. Zhang, “Expectation and purpose: under-
standing users’ mental models of mobile App pri-
vacy through crowdsourcing,” in Proc. 14th ACM
Ubicomp, 2012, pp. 501–510.

[28] A. Felt, E. Chin, S. Hanna, D. Song, and D. Wag-
ner, “Android permissions demystiﬁed,” in Proc. of
18th ACM CCS, 2011, pp. 627–638.

[29] Fellbaum et al., WordNet: an electronic lexical

database. Cambridge, Mass: MIT Press, 1998.

[30] D. Klein and C. D. Manning, “Accurate unlexical-
ized parsing.” in Proc. 41st ACL, 2003, pp. 423–
430.

[31] A. Sinha, A. M. Paradkar, P. Kumanan, and
B. Boguraev, “A linguistic analysis engine for natu-
ral language use case description and its application
to dependability analysis in industrial use cases.” in
Proc. 39th DSN, 2009, pp. 327–336.

[32] A. Sinha, S. M. SuttonJr., and A. Paradkar,
“Text2Test: Automated inspection of natural lan-
guage use cases,” in Proc. 3rd ICST, 2010, pp. 155–
164.

[33] R. Pandita, X. Xiao, H. Zhong, T. Xie, S. Oney, and
A. Paradkar, “Inferring method speciﬁcations from
natural language API descriptions,” in Proc. 34th
ICSE, 2012, pp. 815–825.

[34] B. K. Boguraev, “Towards ﬁnite-state analysis of

lexical cohesion.” in Proc. 3rd FSMNLP, 2000.

[35] M. Stickel and M. Tyson, FASTUS: A Cascaded
Finite-state Transducer for Extracting Information
from Natural-language Text. MIT Press, 1997.

[36] G. Gregory, Light Parsing as Finite State Filtering.

Cambridge University Press, 1999.

[37] Q. Do, D. Roth, M. Sammons, Y. Tu, and V. Vydis-
waran, “Robust, light-weight approaches to com-
pute lexical similarity,” University of Illinois, Com-
puter Science Research and Technical Reports,
2009.

[39] D. Olson, Advanced Data Mining Techniques.

Springer Verlag, 2008.

[40] S. Thummalapenta and T. Xie, “PARSEWeb: A
programmer assistant for reusing open source code
on the web,” in Proc. 22nd ASE, 2007, pp. 204–213.

[41] S. P. Reiss, “Semantics-based code search,” in

Proc. 31st ICSE, 2009, pp. 243–253.

[42] M. Harman, Y. Jia, and Y. Zhang, “App store min-
ing and analysis: MSR for app stores,” in Proc. 9th
IEEE MSR, 2012, pp. 108–111.

[43] V. Gervasi and D. Zowghi, “Reasoning about in-
consistencies in natural language requirements,”
ACM Transactions Software Engineering Method-
ologies, vol. 14, pp. 277–330, 2005.

[44] U. Dekel and J. D. Herbsleb, “Improving API doc-
umentation usability with knowledge pushing,” in
Proc. 31st ICSE, 2009, pp. 320–330.

[45] L. Tan, D. Yuan, G. Krishna, and Y. Zhou,
“/*iComment: Bugs or bad comments?*/,” in Proc.
21st SOSP, 2007, pp. 145–158.

[46] H. Zhong, L. Zhang, T. Xie, and H. Mei, “Infer-
ring resource speciﬁcations from natural language
API documentation,” in Proc. 24th ASE, November
2009, pp. 307–318.

[47] X. Xiao, A. Paradkar, S. Thummalapenta, and
T. Xie, “Automated extraction of security poli-
cies from natural-language software documents,” in
Proc. 20th FSE, 2012, pp. 12:1–12:11.

[48] H. Zhou, F. Chen, and H. Yang, “Developing ap-
plication speciﬁc ontology for program comprehen-
sion by combining domain ontology with code on-
tology,” in Proc. 8th QSIC, 2008, pp. 225 –234.

[49] G. Sridhara, L. Pollock, and K. Vijay-Shanker,
“Generating parameter comments and integrating
with method summaries,” in Proc. 19th ICPC,
2011, pp. 71–80.

[50] P. Robillard, “Schematic pseudocode for program
constructs and its computer automation by schema-
code,” Comm. of the ACM, vol. 29, no. 11, pp.
1072–1089, 1986.

542  22nd USENIX Security Symposium 

USENIX Association

16

