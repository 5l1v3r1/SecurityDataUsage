Benchmarking Personal Cloud Storage

Idilio Drago

University of Twente

i.drago@utwente.nl

Enrico Bocchi

Politecnico di Torino

enrico.bocchi@studenti.polito.it

Marco Mellia

Politecnico di Torino
mellia@tlc.polito.it

Herman Slatman
University of Twente

h.slatman@utwente.nl

Aiko Pras

University of Twente
a.pras@utwente.nl

ABSTRACT
Personal cloud storage services are data-intensive applica-
tions already producing a signiﬁcant share of Internet traf-
ﬁc. Several solutions oﬀered by diﬀerent companies attract
more and more people. However, little is known about each
service capabilities, architecture and – most of all – perfor-
mance implications of design choices. This paper presents a
methodology to study cloud storage services. We apply our
methodology to compare 5 popular oﬀers, revealing diﬀer-
ent system architectures and capabilities. The implications
on performance of diﬀerent designs are assessed executing
a series of benchmarks. Our results show no clear winner,
with all services suﬀering from some limitations or having
potential for improvement. In some scenarios, the upload of
the same ﬁle set can take seven times more, wasting twice
as much capacity. Our methodology and results are useful
thus as both benchmark and guideline for system design.1

Categories and Subject Descriptors
C.2 [Computer-Communication Networks]: Miscella-
neous; C.4 [Performance of Systems]: Measurement
Techniques

Keywords
Measurements; Performance; Comparison; Dropbox

1.

INTRODUCTION

Personal cloud storage services allow to synchronize local
folders with servers in the cloud. They have gained popular-
ity, with companies oﬀering signiﬁcant amounts of remote
storage for free or reduced prices. More and more people

1Our benchmarking tool and the measurements used in our
analyses are available at the SimpleWeb trace repository:
http://www.simpleweb.org/wiki/cloud_benchmarks

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
IMC’13, October 23–25, 2013, Barcelona, Spain.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-1953-9/13/10 ...$15.00.
http://dx.doi.org/10.1145/2504730.2504762.

are being attracted by these oﬀers, saving personal ﬁles,
synchronizing devices and sharing content with great sim-
plicity. This high public interest pushed various providers
to enter the cloud storage market. Services like Dropbox,
SkyDrive and Google Drive are becoming pervasive in peo-
ple’s routine. Such applications are data-intensive and their
increasing usage already produces a signiﬁcant share of In-
ternet traﬃc [3].

Previous results about Dropbox [3] indicate that design
and architectural choices strongly inﬂuence service perfor-
mance and network usage. However, very little is known
about how other providers implement their services and the
implications of diﬀerent designs. This understanding is valu-
able as a guideline for building well-performing services that
wisely use network resources.

The goal of this paper is twofold. Firstly, we investigate
how diﬀerent providers tackle the problem of synchronizing
people’s ﬁles. For answering this question, we develop a
methodology that helps to understand both system archi-
tecture and client capabilities. We apply our methodology
to compare 5 services, revealing diﬀerences on client soft-
ware, synchronization protocols and data center placement.
Secondly, we investigate the consequences of such designs on
performance. We answer this question by deﬁning a series of
benchmarks. Taking the perspective of users connected from
a single location in Europe, we benchmark each selected
service under the same conditions, highlighting diﬀerences
manifested in various usage scenarios and emphasizing the
relevance of design choices for both users and the Internet.
Our results extend [3], where Dropbox usage is analyzed
from passive measurements.
In contrast to the previous
work and [12, 16] that focus on a speciﬁc service, this paper
compares several solutions using active measurements. The
results in [3] are used to guide our benchmarking deﬁnition.
The authors of [11] benchmark cloud providers, but focusing
only on server infrastructure. Similarly to our goal, [9] eval-
uates Dropbox, Mozy, Carbonite and CrashPlan. Motivated
by the extensive list of providers, we ﬁrst propose a method-
ology to automate the benchmarking. Then, we analyze sev-
eral synchronization scenarios and providers, shedding light
on the impact of design choices on performance.

Our results reveal interesting insights, such as unexpected
drops in performance in common scenarios because of both
the lack of client capabilities and architectural diﬀerences
in the services. Overall, the lessons learned are useful as
guidelines to improve personal cloud storage services.

2050: Parameters

Test computer

FTP server

App-under-test

1: Send ﬁles

2: Upload ﬁles

Testing

application

Provider

3: Statistics

Figure 1: Testbed to study personal storage services.

2. METHODOLOGY AND SERVICES

This section describes the methodology we follow to de-
sign benchmarks to check capabilities and performance of
personal storage services. We use active measurements re-
lying on a testbed (Fig. 1) composed of two parts: (i) a test
computer that runs the application-under-test in the desired
operating system; and (ii) our testing application. The com-
plete environment can run either in a single machine, or in
separate machines provided that the testing application can
intercept traﬃc from the test computer.

We build the testbed in a single Linux server for our ex-
periments. The Linux server both controls the experiments
and hosts a virtual machine that runs the test computer
(Windows 7 Enterprise).2 Our testbed is connected to a
1 GB/s Ethernet network at the University of Twente, in
which Internet connectivity is not a bottleneck.

Our testing application receives as input benchmarking
parameters (step 0 in Fig. 1) describing the sequence of op-
erations to be performed. The testing application acts re-
motely on the test computer, generating speciﬁc workloads
in the form of ﬁle batches, which are manipulated using
a FTP client (step 1). Files of diﬀerent types are created
or modiﬁed at run-time, e.g., text ﬁles composed of ran-
dom words from a dictionary, images with random pixels,
or random binary ﬁles. Generated ﬁles are synchronized to
the cloud by the application-under-test (step 2) and the ex-
changed traﬃc is monitored to compute performance metrics
(step 3). These include the amount of traﬃc seen during the
experiments, the time before actual synchronization starts
and the time to complete synchronization.

2.1 Architecture and Data Centers

The used architecture, data center locations and data cen-
ter owner are important aspects of personal cloud storage,
having both legal and performance implications. To iden-
tify how the analyzed services operate, we observe the DNS
name of contacted servers when (i) starting the application;
(ii) immediately after ﬁles are manipulated; and (iii) when
the application is in idle state. For each service, a list of
contacted DNS names is compiled.

To reveal all IP addresses of the front-end nodes used by a
service, DNS names are resolved to IP addresses by contact-
ing more than 2,000 open DNS resolvers spread around the
world.3 In fact, cloud services rely on the DNS to distribute

2OS X and Linux clients have also been checked whether
available and show no diﬀerences.
3The list has been manually compiled from various sources
and covers more than 100 countries and 500 ISPs.

Table 1: Benchmarks to assess client performance.

Random bytes

Plain text

Set
1
2
3
4

Files

1
1
10
100

Size

100 kB
1 MB
100 kB
10 kB

Set
5
6
7
8

Files

1
1
10
100

Size

100 kB
1 MB
100 kB
10 kB

workload, returning diﬀerent IP addresses according to the
originating DNS resolver [2].

The owners of the IP addresses are identiﬁed using the
whois service. For each IP address, we look for the geo-
graphic location of the server. Since popular geolocation
databases are known to have serious limitations regarding
cloud providers [14], we rely on a hybrid methodology that
makes use of: (i) informative strings (i.e., International Air-
port Codes) revealed by reverse DNS lookup; (ii) the short-
est Round Trip Time (RTT) to PlanetLab nodes [15]; and
(iii) active traceroute to spot the closest well-known loca-
tion of a router. Previous works [2, 5] indicate that these
methodologies provide an estimation with about a hundred
of kilometers of precision, which is suﬃcient for our goals.

2.2 Checking Capabilities

Previous work [3] shows that personal storage applications
can implement several capabilities to optimize storage usage
and to speed up transfers. These capabilities include the
adoption of chunking (i.e., splitting content into a maximum
size data unit), bundling (i.e., the transmission of multiple
small ﬁles as a single object), deduplication (i.e., avoiding
re-transmitting content already available on servers), delta
encoding (i.e., transmission of only modiﬁed portions of a
ﬁle) and compression.

For each case, a speciﬁc test has been designed to observe
if the given capability is implemented. We describe each
test directly in Sect. 4. In summary, our testing application
produces speciﬁc batches of ﬁles that would beneﬁt from a
capability. The exchanged traﬃc is analyzed to determine
how the service operates.

2.3 Benchmarking Performance

After knowing how the services are designed in terms of
both data center locations and system capabilities, we check
how such choices inﬂuence synchronization performance and
the amount of overhead traﬃc.

Results in [3] show that up to 90 % of Dropbox users’
uploads carry less than 1 MB. While 50 % of the batches
carry only a single ﬁle, a signiﬁcant portion (around 10 %)
involves at least 100 ﬁles. Based on these results, we design
8 benchmarks varying (i) number of ﬁles; (ii) ﬁle sizes and
(iii) ﬁle types, therefore covering a variety of synchroniza-
tion scenarios. Tab. 1 lists our benchmark sets. All ﬁles in
the sets are created at run-time by our testing application.
Other types of ﬁles, used in Sect. 4 for checking capabilities,
are not included in the benchmarks for the sake of space.

Each experiment is repeated 24 times per service, allow-
ing at least 5 min between experiments to avoid creating
abnormal workloads to servers. The benchmark of a sin-
gle storage service lasts for about 1 day. Synchronization
startup, upload time and protocol overhead are discussed in
Sect. 5. It is important to reinforce that all measurements

206Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

)

B
k
(
 
c
i
f
f
a
r
T

 900

 600

 300

 0

 0

 2

 4

 6

 8

 10

 12

 14

 16

Time (min)

Figure 2: Background traﬃc while idle.

have been taken from a single location, in the same con-
trolled environment. While results for each service may vary
when measuring from other locations or longer intervals, our
conclusions in the following are independent of that. Re-
peating the experiments from diﬀerent locations is planned
to future works.

2.4 Tested Storage Services

We focus on 5 services for the sake of space, although
our methodology is generic and can be applied to any other
service. We restrict our analysis to native clients, since pre-
vious results [3] show that this is the largely preferred means
to use personal cloud storage services.

Tab. 2 lists the analyzed services. Dropbox [4], Google
Drive [6] and SkyDrive [13] are selected because they are
among the most popular oﬀers, according to the volume of
search queries containing names of cloud storage services on
Google Trends [8]. Wuala [10] is considered because it is a
system that oﬀers encryption at the client-side. We want to
verify the impact of such privacy layer on synchronization
performance. Finally, we include Cloud Drive [1] to com-
pare its performance to Dropbox, since both services rely on
Amazon Web Services (AWS) data centers.

Table 2: Analyzed personal cloud storage services.

Name

Version

Dropbox
Microsoft SkyDrive
Google Drive
LaCie Wuala
Amazon Cloud Drive 2.0.2013.841

2.0.8
1.8.4357.4863
17.0.2006.0314
Strasbourg

3. SYSTEM ARCHITECTURE

3.1 Protocols

All clients exchange traﬃc using HTTPS, with the excep-
tion of Dropbox notiﬁcation protocol, which relies on plain
HTTP. Interestingly, some Wuala storage operations also
use HTTP, since users’ privacy has already been secured by
local encryption.

All services but Wuala use separate servers for control
and storage. Their identiﬁcation is trivial by monitoring the
traﬃc exchanged when the client (i) starts; (ii) is idle; and
(iii) synchronizes ﬁles. Both server names and IP addresses
can be used to identify diﬀerent operations during our tests.
For Wuala, we use ﬂow sizes and connection sequences to
identify storage ﬂows.

Figure 3: Google Drive’s edge nodes.

We notice some relevant diﬀerences among applications
during login and idle phases. Fig. 2 reports the cumulative
number of bytes exchanged with control servers considering
an initial 16 min in idle state. Two considerations hold.
Firstly, the applications authenticate the user and check if
any content has to be updated. Note how SkyDrive requires
about 150 kB in total, 4 times more than others. This hap-
pens because the application contacts many Microsoft Live
servers during login (13 in this example). Secondly, once
login is completed, the applications keep exchanging data
with the cloud. Wuala is the most silent, polling servers ev-
ery 5 min on average – i.e., equivalent background traﬃc of
about 60 b/s. Google Drive follows close, with a lightweight
40 s polling interval (42 b/s). Dropbox and SkyDrive use
intervals close to 1 min (82 b/s and 32 b/s, respectively).

Amazon Cloud Drive is completely diﬀerent: polling is
done every 15 s, each time opening a new HTTPS con-
nection. This notiﬁcation strategy consumes 6 kb/s – i.e.,
about 65 MB per day. This information is relevant to users
with bandwidth constraints (e.g., in 3G/4G networks) and
to the system: 1 million users would generate approximately
6 Gb/s of signaling traﬃc alone! As the results for other
providers demonstrate, such design is not optimal and seems
indeed possible to be improved.

3.2 Data Centers

Next, we analyze data center locations. Dropbox uses own
servers (in the San Jose area) for client management, while
storage servers are committed to Amazon in Northern Vir-
ginia. Cloud Drive uses three AWS data centers: two are
used for both storage and control (in Ireland and Northern
Virginia); a third one is used for storage only (in Oregon).
SkyDrive relies on Microsoft’s data centers in the Seattle
area (for storage) and Southern Virginia (for storage and
control). We also identiﬁed a destination in Singapore (for
control only). Not surprisingly, most data centers are lo-
cated in the U.S. Wuala data centers instead are located in
Europe: two in the Nuremberg area, one in Zurich and a
fourth in Northern France. None is owned by Wuala. All
these services follow a centralized design where clients con-
tact the servers using the public Internet, as expected.

Google Drive follows a diﬀerent approach: TCP connec-
tions are terminated at the closest Google’s edge node, from
where the traﬃc is routed to the actual storage/control data
center using the private Google’s network. Fig. 3 shows the

207Cloud Drive
Google Drive

 

s
N
Y
S
P
C
T
 
e
v
i
t
a
l
u
m
u
C

 400

 300

 200

 100

 0

 0

 10

 20

 30

 40

 50

 60

Time (s)

Figure 4: Uploading 100 ﬁles of 10 kB.

locations identiﬁed in our experiments.4 Overall, more than
100 diﬀerent entry points have been located. Such archi-
tecture allows to reduce client-server RTT and to oﬄoad
storage traﬃc from the public Internet. Performance impli-
cations are discussed in Sect. 5.

4. CLOUD SERVICE CAPABILITIES

4.1 Chunking

Our ﬁrst test aims at understanding how the services pro-
cess large ﬁles. By monitoring throughput during the upload
of ﬁles diﬀering in size, we determine whether ﬁles are ex-
changed as single objects (no pause during the upload), or
split into chunks, each delimited by a pause. Our experi-
ments show that only Cloud Drive does not perform chunk-
ing. In fact, Google Drive uses 8 MB chunks while Dropbox
uses 4 MB chunks. SkyDrive and Wuala apparently use
variable chunk sizes.

Chunking seems advantageous because it simpliﬁes upload
recovery in case of failures: partial submission becomes eas-
ier to be implemented, beneﬁting users connected to slow
networks, for example.

4.2 Bundling

When a batch of ﬁles needs to be transferred, ﬁles could
be bundled and pipelined so that both transmission latency
and control overhead impact are reduced. Our tests to check
how services handle batches of ﬁles consist of 4 upload sets,
each containing exactly the same number of bytes (1 MB),
which are split into 1, 10, 100 or 1000 ﬁles, respectively.

These experiments reveal a variety of synchronization
strategies. Google Drive and Cloud Drive open one sepa-
rate TCP (and SSL) connection for each ﬁle. Considering
management, Cloud Drive opens 3 TCP/SSL control con-
nections per ﬁle operation. Fig. 4 shows the number of TCP
SYN packets observed when Google Drive and Cloud Drive
have to store 100 ﬁles of 10 kB each: 100 and 400 connections
are opened respectively, requiring 30 s and 55 s to complete
the upload. Sect. 5 will conﬁrm that such design strongly
limits the client performance when several ﬁles have to be
exchanged, owing to TCP and SSL negotiations.

Other

services

However,
SkyDrive and Wuala submit ﬁles sequentially, waiting for ap-
plication layer acknowledgments between each upload. This

reuse TCP connections.

4Our results match with Google’s points of presence [7]. Un-
derstanding how Google manages traﬃc inside its network
is outside the scope of this paper.

Append

Random

Dropbox
SkyDrive
Wuala
Cloud Drive
Google Drive

)

B
M

(
 

d
a
o
l
p
U

 3

 2

 1

 0

 15

 10

 

 5

 0

 0.1

 0.5

 1

 1.5

 2

 1  2

 4

 6

 8

 10

File size (MB)

File size (MB)

Figure 5: Delta encoding tests. Note the x-axes.

can be determined by counting packet bursts, which are pro-
portional to the number of ﬁles in our experiments. We con-
clude that only Dropbox implements a ﬁle-bundling strategy.

4.3 Client-Side Deduplication

Server data deduplication eliminates replicas on the stor-
age server. In case the same content is already present on
the storage, replicas in the client folder can be identiﬁed to
save upload capacity too.

To check whether this feature is implemented, we design
the following test: (i) a random ﬁle is inserted in an arbitrary
folder; (ii) the same random payload is used to create a
replica with a diﬀerent name in a second folder; (iii) the
original ﬁle is copied to a third folder; and (iv) after all
copies are deleted, the original ﬁle is placed back. The last
step determines whether deduplication fails after ﬁles are
deleted from the local folder.

Results allow to conclude that only Dropbox and Wuala
implement deduplication. All other services have to upload
the same data even if it is readily available at the storage
server. Interestingly, Dropbox and Wuala can identify copies
of users’ ﬁles even after they are deleted and later restored.
In the case of Wuala, deduplication is compatible with lo-
cal encryption, i.e., two identical ﬁles generate two identical
encrypted versions.

4.4 Delta Encoding

Delta encoding is a specialized compression technique that
calculates ﬁle diﬀerences among two copies, allowing the
transmission of only the modiﬁcations between revisions. To
verify which services implement delta encoding, a sequence
of changes are generated on a ﬁle so that a portion of content
is added/changed at each iteration. Three cases are consid-
ered: new data added/changed at the end, at the beginning,
or at a random position within the ﬁle. This allows us to
check whether rolling hash mechanisms are implemented. In
all cases, the modiﬁed ﬁle replaces its old copy.

Fig. 5 shows that only Dropbox fully implements delta
encoding, i.e., the volume of uploaded data corresponds to
the actual part that has been modiﬁed. Results in which
bytes are inserted at the end and at random positions are
shown on the left and right plots, respectively. In the former
case, ﬁle sizes have been chosen up to 2 MB. Larger ﬁles are
instead considered in the latter case to highlight the com-
bined eﬀects with chunking and deduplication. Focusing on
Dropbox, observe that the amount of sent traﬃc increases
when ﬁles are bigger than Dropbox 4 MB-long chunk. This
happens because the original content may be shifted, chang-

208Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

 3

)

B
M

(
 

d
a
o
l
p
U

 2

 1

 0

 3

)

B
M

(
 

d
a
o
l
p
U

 2

 1

 0

Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

 3

)

B
M

(
 

d
a
o
l
p
U

 2

 1

 0

 0.1

 0.5

 1

 1.5

 2

 0.1

 0.5

 1

 1.5

 2

 0.1

 0.5

 1

 1.5

 2

File size (MB)

(a) Random readable text

File size (MB)

(b) Random bytes

File size (MB)

(c) Fake JPEGs

Figure 6: Bytes uploaded during the compression test.

ing two or more chunks at once. As such, the volume of data
to be transmitted is larger than the added data.

Wuala does not implement delta encoding. However,
deduplication prevents the client from uploading those
chunks not aﬀected by the change. This can be seen in
Fig. 5, when data is added at a random oﬀset, forming a
10 MB ﬁle.
In this case, only two chunks (among 3) are
modiﬁed, and thus uploaded.

4.5 Data Compression

We next verify whether data is compressed before a trans-
fer. Compression could, in general, reduce traﬃc and stor-
age requirements at the expense of processing time. The
compression capability is checked with two distinct ﬁle sets.
The ﬁrst set (Fig. 6(a)) is made of highly compressible text
ﬁles (sizes from 100 kB to 2 MB). Files in the second set
(Fig. 6(b)) contain pure random bytes so that no compres-
sion is possible. Fig. 6(a) reveals that Dropbox and Google
Drive compress data before transmission, with the latter im-
plementing a more eﬃcient scheme. Fig. 6(b) conﬁrms that
Dropbox has the highest overhead in this scenario.

Naturally, compression is advantageous only for some ﬁle
types. Compression has a negligible or negative impact when
already compressed ﬁles are going to be transmitted. A pos-
sible approach would be to verify the ﬁle format before try-
ing to compress it (e.g., using magic numbers). We check
whether Google Drive and Dropbox implement smart poli-
cies by creating fake JPEGs – i.e., ﬁles with JPEG extension
and JPEG headers, but actually ﬁlled with text. Fig. 6(c)
shows that Google Drive identiﬁes JPEG content and avoids
compression. Dropbox instead compresses all ﬁles indepen-
dently of their content.

4.6 Summary

Tab. 3 summarizes the capabilities of each service.

It
shows that Dropbox has the most sophisticated client from
the point of view of features to enhance synchronization
speed. Wuala, Google Drive and SkyDrive come next, im-
plementing some capabilities. Finally, Cloud Drive is the
simplest client, as none of the capabilities are implemented.

5. CLIENT PERFORMANCE

5.1 Synchronization Startup

creases initial synchronization delay. The metric is com-
puted from the moment when ﬁles start being modiﬁed in
the test computer until the ﬁrst storage ﬂow is observed.5

Fig. 7(a) shows average delays over 24 repetitions. Only
4 scenarios using binary ﬁles are shown, since similar con-
clusions are obtained with plain text ﬁles. Dropbox is
the fastest service to start synchronizing single ﬁles.
Its
bundling strategy, however, slightly delays start up with
multiple ﬁles. As we will show next, such strategy pays
back in total upload time. SkyDrive is by far the slowest,
waiting at least 9 s before starting submitting ﬁles. The root
cause of this delay is unclear, since SkyDrive client does not
report any activity during this period. Moreover, SkyDrive
gets slower as batches increase, taking more than 20 s to
start sending 100 ﬁles of 10 kB. Wuala also increases its
startup time when multiple ﬁles are submitted.

5.2 Completion Time

Next, we test how long each service takes to complete up-
load tasks. This is measured as the diﬀerence between the
ﬁrst and the last packet with payload seen in any storage
ﬂow. We ignore TCP tear-down delays, and control mes-
sages sent after the upload is complete.

Fig. 7(b) summarizes our results (note the logarithmic
scale on the y-axis). A mixed ﬁgure emerges. When syn-
chronizing single ﬁles of 100 kB or 1 MB, the distance be-
tween our testbed and the data centers dominates the met-
ric. Google Drive (26,49 Mb/s) and Wuala (33,34 Mb/s)
are the fastest, since each TCP connection is terminated at
data centers nearby our testbed. Dropbox and SkyDrive, on
the other hand, are the most impacted services. SkyDrive
(160 ms of RTT) needs almost 4 s to upload a 1 MB ﬁle,
whereas Google Drive requires only 300 ms (15 ms of RTT).
When multiple ﬁles are stored, the client capabilities be-
come central. The rightmost bars on Fig. 7(b) show a strik-
ing diﬀerence on completion time when 100 ﬁles of 10 kB are
used. Dropbox wins by a factor of 2 because of bundling,
topping to 0,8 Mb/s of upload rate. Interestingly, Google
Drive’s advantage due to its distributed topology is canceled
by the usage of separate TCP/SSL connections per ﬁle. It
takes 42 s on average – i.e., 189 kb/s. Other services are
also penalized by their lack of bundling, with Cloud Drive
taking about 60 s (132 kb/s) to complete some tests.

We ﬁrst evaluate how much time each service needs be-
fore synchronization starts. This metric could reveal, for
instance, whether implementing advanced capabilities in-

5This includes delays of our testing application to send ﬁles
to the test computer. The artifact, however, does not aﬀect
our conclusions, since all experiments are equally aﬀected.

209Table 3: Summary of the capabilities implemented in each service.

Dropbox

SkyDrive

Wuala

Google Drive

Cloud Drive

Chunking
Bundling

Compression
Deduplication
Delta-encoding

4 MB
yes

always

yes
yes

var.
no
no
no
no

var.
no
no
yes
no

Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

)
s
(
 
e
m
T

i

 25

 20

 15

 10

 5

 0

Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

 100

)
s
(
 
e
m
T

i

 10

 1

 0.1

 0.01

8 MB

no

smart

no
no

 10

n
o
i
t
c
a
r
F

 1

 0.1

no
no
no
no
no

Dropbox
SkyDrive
Wuala

Cloud Drive
Google Drive

1x100kB

1x1MB 10x100kB 100x10kB

1x100kB 1x1MB 10x100kB 100x10kB

1x100kB

1x1MB 10x100kB 100x10kB

Benchmark set

Benchmark set

Benchmark set

(a) Synchronization start up time

(b) Duration (note log y-axis)

(c) Overhead (note log y-axis)

Figure 7: Average benchmarking results when uploading binary ﬁles.

Results with plain text ﬁles are not shown for the sake of
space, but similar conclusions can be drawn. Dropbox has
a small improvement in its upload time because of compres-
sion, although network latency still dominates the metric.
Google Drive proﬁts from its smart compression when send-
ing single plain text ﬁles of moderate sizes. However, the
service is again among the slowest when multiple small text
ﬁles are synchronized, showing that its smart compression
advantage is also canceled by the lack of bundling.

5.3 Protocol Overhead

Finally, we evaluate protocol overhead as the total storage
and control traﬃc over the benchmark size. Fig. 7(c) shows
that all services have a moderate to high overhead when
small binary ﬁles are synchronized. Cloud Drive presents
a very high overhead because of its high number of control
ﬂows opened for every ﬁle transfer (see Fig. 2). Dropbox
exhibits the highest overhead among the remaining services
(47 % for 100 kB ﬁles and 22 % for 1 MB ﬁles), possibly
owing to the signaling cost of implementing its advanced
capabilities.

The lack of bundling dramatically increases overhead
when multiple small ﬁles are sent. Google Drive, for in-
stance, exchanges twice as much traﬃc as the actual data
size when sending 100 binary ﬁles of 10 kB. Cloud Drive
shows even more overhead – i.e., more than 5 MB of data
are exchanged to commit 1 MB of content. A similar pat-
tern is generally seen in the experiments with plain text
ﬁles. Dropbox and Google Drive are the exceptions, ow-
ing to their compression strategies, which naturally reduce
network overhead.

6. CONCLUSIONS

In this paper we presented a methodology to check both
capabilities and system design of personal cloud storage ser-
vices. We then evaluated the implications of design choices
on performance by analyzing 5 services.

Our analysis shows the relevance of client capabilities and
protocol design to personal cloud storage services. Dropbox
implements most of the checked capabilities, and its so-
phisticated client clearly boosts performance, although some
protocol tweaks seem possible to reduce network overhead.
On the other extreme, Cloud Drive bandwidth wastage is
an order of magnitude higher than other oﬀerings, and its
lack of client capabilities results in performance bottlenecks.
SkyDrive shows some performance limitations, while Wuala
generally performs well. More importantly, Wuala deploys
client side encryption, and this feature does not seem to
aﬀect Wuala synchronization performance.

These 4 examples conﬁrm the role played by data center
placement in a centralized approach: taking the perspective
of European users only, network latency is still an important
limitation for U.S. centric services, such as Dropbox and
SkyDrive. Services deploying data centers nearby our test
location, such as Wuala, have therefore an advantage.

Google Drive follows a diﬀerent approach resulting in a
mixed picture: it enjoys the beneﬁts of using Google’s capil-
lary infrastructure and private backbone, which reduce net-
work latency and speed up the system. However, protocols
and client features limit performance, especially when mul-
tiple ﬁles are considered.

As future work, we intend to extend our analysis with
measurements from other locations and longer time inter-
vals. This will allow us to quantify long-term eﬀects of de-
sign choices for users connected in diﬀerent geographic ar-
eas. Moreover, we plan to deﬁne new benchmarks by collect-
ing data from volunteers, thus creating realistic benchmarks
that mix ﬁles of diﬀerent types in a single set.

7. ACKNOWLEDGMENTS

This work was partly funded by the Network of Excel-
lence project Flamingo (ICT-318488) and the EU-IP project
mPlane (n-318627). Both projects are supported by the
European Commission under its Seventh Framework Pro-
gramme.

2108. REFERENCES
[1] Amazon. Cloud Drive v. 2.0.2013.841. http://www.
amazon.com/gp/feature.html?docId=1000828861.
[2] I. N. Bermudez, S. Traverso, M. Mellia, and M. M.

Munaf`o. Exploring the Cloud from Passive
Measurements: the Amazon AWS case. In The 32nd
Annual IEEE International Conference on Computer
Communications, INFOCOM’13, 2013.

[3] I. Drago, M. Mellia, M. M. Munaf`o, A. Sperotto,

R. Sadre, and A. Pras. Inside Dropbox:
Understanding Personal Cloud Storage Services. In
Proceedings of the 12th ACM Internet Measurement
Conference, IMC’12, pages 481–494, 2012.

[4] Dropbox. v. 2.0.8. https://www.dropbox.com/

release_notes.

[5] B. Eriksson and M. Crovella. Understanding

Geolocation Accuracy using Network Geometry. In
The 32nd Annual IEEE International Conference on
Computer Communications, INFOCOM’13, 2013.

[6] Google. Drive v. 1.9.4536.8202. https://tools.

google.com/dlpage/drive.

[7] Google. Network Introduction. https://peering.

google.com/about/delivery_ecosystem.html.

[8] Google. Trends. http://www.google.com/trends/.
[9] W. Hu, T. Yang, and J. N. Matthews. The Good, the
Bad and the Ugly of Consumer Cloud Storage. ACM
SIGOPS Operating Systems Review, 44(3):110–115,
2010.

[10] LaCie. Wuala v. Strasbourg. http://www.wuala.com/.
[11] A. Li, X. Yang, S. Kandula, and M. Zhang.

CloudCmp: Comparing Public Cloud Providers. In
Proceedings of the 10th ACM SIGCOMM Conference
on Internet Measurement, IMC’10, pages 1–14, 2010.

[12] T. Mager, E. Biersack, and P. Michiardi. A

Measurement Study of the Wuala On-line Storage
Service. In Proceedings of the IEEE 12th International
Conference on Peer-to-Peer Computing, P2P’12, pages
237–248, 2012.

[13] Microsoft. SkyDrive v. 17.0.2006.0314. https://

skydrive.live.com/.

[14] I. Poese, S. Uhlig, M. A. Kaafar, B. Donnet, and
B. Gueye. IP Geolocation Databases: Unreliable?
SIGCOMM Comput. Commun. Rev., 41(2):53–56,
2011.

[15] R. Torres, A. Finamore, J. R. Kim, M. Mellia, M. M.

Munaf`o, and S. Rao. Dissecting Video Server Selection
Strategies in the YouTube CDN. In Proceedings of the
31st International Conference on Distributed
Computing Systems, ICDCS’11, pages 248–257, 2011.

[16] H. Wang, R. Shea, F. Wang, and J. Liu. On the

Impact of Virtualization on Dropbox-like Cloud File
Storage/Synchronization Services. In Proceedings of
the IEEE 20th International Workshop on Quality of
Service, IWQoS ’12, pages 11:1–11:9, 2012.

211