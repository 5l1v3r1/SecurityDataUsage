2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy

A Method for Verifying Privacy-Type Properties:

The Unbounded Case

Lucca Hirschi, David Baelde and St´ephanie Delaune
LSV, CNRS & ENS Cachan, Universit´e Paris-Saclay, France

Abstract—In this paper, we consider the problem of verifying
anonymity and unlinkability in the symbolic model, where
protocols are represented as processes in a variant of the applied
pi calculus notably used in the ProVerif tool. Existing tools and
techniques do not allow one to verify directly these properties,
expressed as behavioral equivalences. We propose a different
approach: we design two conditions on protocols which are
sufﬁcient to ensure anonymity and unlinkability, and which can
then be effectively checked automatically using ProVerif. Our
two conditions correspond to two broad classes of attacks on
unlinkability, corresponding to data and control-ﬂow leaks.

This theoretical result is general enough to apply to a wide class
of protocols. In particular, we apply our techniques to provide the
ﬁrst formal security proof of the BAC protocol (e-passport). Our
work has also lead to the discovery of new attacks, including one
on the LAK protocol (RFID authentication) which was previously
claimed to be unlinkable (in a weak sense) and one on the PACE
protocol (e-passport).

I. INTRODUCTION

Security protocols aim at securing communications over
various types of insecure networks (e.g. web, wireless devices)
where dishonest users may listen to communications and
interfere with them. A secure communication has a different
meaning depending on the underlying application. It ranges
from the conﬁdentiality of data (medical ﬁles, secret keys,
etc.) to, e.g. veriﬁability in electronic voting systems. Another
example of a security notion is privacy. In this paper, we focus
on two privacy-related properties, namely unlinkability (some-
times called untraceability), and anonymity. These two notions
are informally deﬁned in the ISO/IEC standard 15408 [1] as
follows:

● Unlinkability aims at ensuring that a user may make
multiple uses of a service or resource without others being
able to link these uses together.

● Anonymity aims at ensuring that a user may use a service

or resource without disclosing its identity.

Both are critical for instance for Radio-Frequency Identiﬁca-
tion Devices (RFID) and are thus extensively studied in that
context (see, e.g. [2] for a survey of attacks on this type of
protocols), but they are obviously not limited to it.

One extremely successful approach when designing and
analyzing security protocols is the use of formal veriﬁcation,
i.e. the development of rigorous frameworks and techniques
to analyze protocols. This approach has notably lead to the
discovery of a ﬂaw in the Single-Sign-On protocol used

This work has been partially supported by the project JCJC VIP ANR-11-

JS02-006 and the ANR project Sequoia ANR-14-CE28-0030-01.

e.g. by Google Apps. It has been shown that a malicious
application could very easily access to any other application
(e.g. Gmail or Google Calendar) of their users [3]. This ﬂaw
has been found when analyzing the protocol using formal
methods, abstracting messages by a term algebra and using the
Avantssar validation platform. Another example is a ﬂaw on
vote-privacy discovered during the formal and manual analysis
of an electronic voting protocol [4]. All these results have been
obtained using formal symbolic models, where most of the
cryptographic details are ignored using abstract structures. The
techniques used in symbolic models have become mature and
several tools for protocol veriﬁcation are nowadays available,
e.g. the Avantssar platform [5], the Tamarin prover [6], and
the ProVerif tool [7].

if, for any execution,

Unfortunately, most of these results and tools focus on
trace properties, that is, statements that something bad never
occurs on any execution trace of a protocol. Secrecy and
authentication are typical examples of trace properties: a data
remains conﬁdential
the attacker is
not able to produce the data. But privacy properties like
unlinkability and anonymity typically cannot be deﬁned as
trace properties. Instead, they are usually deﬁned as the fact
that an observer cannot distinguish between two situations,
which requires a notion of behavioral equivalence. Roughly,
two protocols are equivalent if an attacker cannot observe
any difference between them. Based on such a notion of
equivalence, several deﬁnitions of privacy-type properties have
been proposed (e.g. [8], [9] for unlinkability, and [10], [11] for
vote-privacy). In this paper, we consider the well-established
deﬁnitions of strong unlinkability and anonymity as deﬁned
in [8]. They have notably been used to establish privacy for
various protocols either by hand or using ad hoc encodings
(e.g. eHealth protocol [12], mobile telephony [13], [14]). We
provide a brief comparison with alternative deﬁnitions in
Section III-B.

Considering an unbounded number of sessions, the prob-
lem of deciding whether a protocol satisﬁes an equivalence
property is undecidable even for a very limited fragment of
protocols (see, e.g. [15]). Bounding the number of sessions
sufﬁces to retrieve decidability for standard primitives (see,
e.g. [16], [17]). However, analyzing a protocol for a ﬁxed
(often low) number of sessions does not allow to prove
security. Moreover,
in the case of equivalence properties,
existing tools scale badly and can only analyze protocols for
a very limited number of sessions, typically 2 or 3. Another

2375-1207/16 $31.00 © 2016 IEEE
© 2016, Lucca Hirschi. Under license to IEEE.
DOI 10.1109/SP.2016.40
DOI 10.1109/SP.2016.40

564
564

approach consists in implementing a procedure that is not
guaranteed to terminate. This is in particular the case of
ProVerif, a well-established tool for checking security of pro-
tocols. ProVerif is able to check a strong notion of equivalence
(called diff-equivalence) between processes that share the same
structure. Despite recent
improvements on diff-equivalence
checking [18] intended to prove unlinkability of the BAC
protocol (used in e-passport), ProVerif still cannot be used
off-the-shelf to establish unlinkability properties, and therefore
cannot conclude on the case studies presented in Section VII.
Recently, similar approaches have been implemented in two

other tools, namely Tamarin [19] and Maude−NPA [20]. They

are based on a notion of diff-equivalence, and therefore suffer
from the same drawbacks.

In this paper, we follow a different approach. We aim
at proposing sufﬁcient conditions that can be automatically
checked, and that imply unlinkability and anonymity of the
protocol under study. This approach is in the same spirit as
the one presented in [9]. However, [9] only considers a very
restricted class of protocols (single-step protocols that only
use hash functions), while we target more complex protocols.
The success of our solution will be measured by confronting
it to many case studies.

Our contribution: We identify a large class of 2-party
protocols (simple else branches, arbitrary cryptographic prim-
itives) and we devise two conditions that imply unlinkability
and anonymity for an unbounded number of sessions. We
show how these two conditions can be automatically checked
using the ProVerif
tool, and we provide tool support for
that. We have analyzed several protocols, among them the
Basic Access Control (BAC) protocol as well as the Password
Authenticated Connection Establishment (PACE) protocol that
are both used in e-passports. We notably establish the ﬁrst
proof of unlinkability for the BAC protocol followed by the
Passive Authentication (PA) and Active Authentication (AA)
protocols. We also report on an attack that we found on the
PACE protocol, and another one that we found on the LAK
protocol whereas it is claimed untraceable in [2]. It happens
that our conditions are rather tight: we provide an attack every
time one of them is not satisﬁed.

We now give an intuitive overview of these two conditions.
In order to do this, assume that we want to design a mutual
authentication protocol between a tag T and a reader R based
on symmetric encryption, and we want this protocol to be

unlinkable. We note {m}k the symmetric encryption of a

message m with a key k and we assume that k is a symmetric
key shared between T and R.

A ﬁrst attempt to design such a protocol is presented using

Alice & Bob notation as follows (nR is a fresh nonce):

1. R → T ∶ nR
2. T → R ∶ {nR}k

This ﬁrst attempt based on a challenge-response scheme is
actually linkable. Indeed, an active attacker who systematically
intercepts the nonce nR and replaces it by a constant will be

565565

able to infer whether the same tag has been used in different
sessions or not by comparing the answers he receives. Here,
the tag is linkable because, for a certain behavior (possibly
malicious) of the attacker, some relations between messages
leak information about the agents that are involved in the
execution. Our ﬁrst condition, namely frame opacity, actually
checks that all outputted messages have only trivial relations
that can therefore not be exploited by the attacker.

Our second attempt takes the previous attack into account
and randomizes the tag’s response and should achieve mutual
authentication by requiring that the reader must answer to the
challenge nT . This protocol can be as follows:

1. R → T ∶ nR
2. T → R ∶ {nR, nT}k
3. R → T ∶ {nT}k

Here, Alice & Bob notation shows its limit. It does not specify
how the reader and the tag are supposed to check that the
messages they received are of the expected form, and how they
should react when the messages are not well formed. This has
to be precisely deﬁned, since unlinkability depends on it. For
instance, assume the tag does not check that the message he
receives at step 3 contains nT , and aborts the session if the
received message in not encrypted with its own k. In such an
implementation, an active attacker can eavesdrop a message

{nT}k sent by R to a tag T , and try to inject this message at

the third step of another session played by T ′. The tag T ′ will
react by either aborting or by continuing the execution of this
protocol. Depending on the reaction of the tag, the attacker
will be able to infer if T and T ′ are the same tag or not.

In this example, the attacker adopts a malicious behavior
that is not detected immediately by the tag who keeps exe-
cuting the protocol. The fact that the tag passes successfully
a conditional reveals crucial information about the agents that
are involved in the execution. Our second condition, namely
well-authentication, basically requires that when an execution
deviates from the honest one, the agents that are involved
cannot successfully pass a conditional.

Our main theorem states that these two conditions, frame
opacity and well-authentication, are actually sufﬁcient to en-
sure both unlinkability and anonymity. This theorem is of
interest as our two conditions are fundamentally simpler than
the targeted properties: frame opacity can be expressed using
diff-equivalence and well-authentication is a trace property.
In fact,
they are both in the scope of existing automatic
veriﬁcation tools like ProVerif.

Outline: In Section II, we present our model inspired
from the applied pi calculus as well as the notion of trace
equivalence. We then deﬁne in Section III the class of proto-
cols and the formal deﬁnitions of unlinkability and anonymity
we study in this paper. Our two conditions (frame opacity
and well-authentication) and our main theorem are presented
in Section IV. Section V is dedicated to the proof of that
result. Finally, we discuss how to mechanize the veriﬁcation

of our conditions in Section VI and present our case studies
in Section VII, before concluding in Section VIII.

II. MODEL

We shall model security protocols using a process algebra
inspired from the applied pi calculus [21]. More speciﬁcally,
we consider the calculus of Blanchet et al. [22], which is used
in the ProVerif tool. Participants are modeled as processes, and
the communication between them is modeled by means of the
exchange of messages that are represented by a term algebra.

A. Term algebra

We now present term algebras, which will be used to model
messages built and manipulated using various cryptographic

primitives. We consider an inﬁnite set N of names which
and disjoint sets of variables, denoted X and W. Variables
in X will typically be used to refer to unknown parts of
messages expected by participants, while variables in W will

are used to represent keys, and nonces; and two inﬁnite

be used to store messages learned by the attacker. We assume
a signature Σ, i.e. a set of function symbols together with
their arity. The elements of Σ are split into constructor and

destructor symbols, i.e. Σ= Σc⊔ Σd.
Given a signatureF, and a set of initial data A, we denote by
T (F, A) the set of terms built from elements of A by applying
function symbols in F. Terms of T (Σc,N∪X) will be called
constructor terms. We denote vars(u) the set of variables that
is ground, i.e. such that vars(u) = ∅. We denote by x, n, u
written uσ, and we denote dom(σ) its domain. The positions

a (possibly empty) sequence of variables, names, and terms
respectively. The application of a substitution σ to a term u is

occur in a term u. A message is a constructor term u that

of a term are deﬁned as usual.

Example 1: Consider the signature

Σ={enc, dec, ⟨⟩, π1, π2, ⊕, 0, eq, ok}.

The symbols enc and dec of arity 2 represent symmetric

encryption and decryption. Pairing is modeled using ⟨ ⟩ of
both of arity 1. The function symbol ⊕ of arity 2 and the

arity 2, whereas projection functions are denoted π1 and π2,

constant 0 are used to model the exclusive or operator. Finally,
we consider the symbol eq of arity 2 to model equality test,
as well as the constant symbol ok. This signature is split into

two parts: Σc ={enc,⟨⟩,⊕, 0, ok}, and Σd ={dec, π1, π2, eq}.

As in the process calculus presented in [22], constructor
terms are subject to an equational theory; this has proved
very useful for modeling algebraic properties of cryptographic
primitives (see e.g. [23] for a survey). Formally, we consider

a congruence =E on T (Σc,N ∪ X), generated from a set
of equations E over T (Σc,X). Thus, =E is closed under
that there exist u, v such that u≠E v.

substitutions and under bijective renaming. We ﬁnally assume

Example 2: To reﬂect

the algebraic properties of the
exclusive or operator, we may consider the equational theory
generated by the following equations:

566566

x⊕ 0 = x
x⊕ x = 0

(x⊕ y)⊕ z = x⊕(y⊕ z)

(x⊕ y) = (y⊕ x)

In such a case, we have that enc(a⊕(b⊕ a), k)=E enc(b, k).

We may also want to give a meaning to destructor symbols.

For this, we consider the notion of computation relation.

Deﬁnition 1: A computation relation is a relation over

● for any term t, messages u and v, and context t′ (i.e.

T (Σ,N)×T (Σc,N), denoted ⇓, such that:
● n⇓ n for any n∈N ;
● f(t1, . . . , tk)⇓ f(u1, . . . , uk) for f ∈ Σc of arity k and
ti ⇓ ui for all 1≤ i≤ k,
● if t⇓ u then tρ⇓ uρ for any bijective ρ∶N →N ;
a term with a hole) built from Σ and N , if t ⇓ u and
t′[u]⇓ v then t′[t]⇓ v;
● if t′ is a context built from Σ and N , and t1, t2 are
terms such that t1 =E t2 and t′[t1] ⇓ u1 for some u1,
then t′[t2]⇓ u2 for some u2 such that u1 =E u2.
The relation ⇓ associates, to any ground term t, at most one
exists, we say that the computation fails; this is noted t⇓̸. As
a slight abuse of notation, we may sometimes use directly t⇓

message up to the equational theory E. When no such message

as a message, when we know that the computation succeeds
and the choice of representative is irrelevant.

A computation relation is often obtained from a rewriting

system, i.e. a set of rewriting rules g(u1, . . . , un)→ u where g
is a destructor, and u, u1, . . . , un ∈T (Σc,X). A ground term t
rewriting rule g(u1, . . . , un)→ u such that t∣p = g(v1, . . . , vn)
and v1 =E u1θ, . . . , vn =E unθ for some substitution θ, and
t′ = t[uθ]p (i.e. t in which the sub-term at position p has been

can be rewritten into t′ if there is a position p in t and a

replaced by uθ). Moreover, we assume that u1θ, . . . , unθ as
well as uθ are messages.

Example 3: The properties of symbols in Σd (see Exam-

ple 1) are reﬂected through the following rewriting rules:

dec(enc(x, y), y)→ x
πi(⟨x1, x2⟩)→ xi

eq(x, x)→ ok
for i∈{1, 2}.

This rewriting system is convergent modulo the equational the-
ory E given in Example 2, and therefore induces a computation
relation as deﬁned in Deﬁnition 1. For instance, we have that

dec(enc(c, a⊕ b), b⊕ a)⇓ c, whereas dec(enc(c, a⊕ b), b)⇓̸,
and dec(a, b)⊕ dec(a, b)⇓̸.
neq(u, v) ⇓ ok if, and only if, u and v can be reduced to

Our generic notion of computation relation gives us enough
ﬂexibility to deﬁne a destructor symbol neq, and consider that

messages that are not equal modulo E.

For modeling purposes, we split the signature Σ into two
parts, namely Σpub and Σpriv. An attacker builds his own
messages by applying public function symbols to terms he

already knows and that are available through variables in W.
a term in T (Σpub,W). Recipes will be denoted by R, M, N.

Formally, a computation done by the attacker is a recipe, i.e.

Note that, although we do not give the attacker the ability to
generate fresh names to use in recipes, we obtain essentially
the same capability by assuming an inﬁnite supply of public

constants in Σc∩ Σpub.

B. Process algebra

We consider a set C of channel names that are assumed to

be public. Protocols are modeled through processes using the
grammar in Figure 1.

P, Q ∶= 0

in(c, x).P
out(c, u).P
let x= v in P else Q

∣
∣
∣
∣ P ∣ Q
∣
∣

!P
νn.P

null
input
output
evaluation
parallel
replication
restriction

where c∈C, x∈X , n∈N , u∈T (Σc,N ∪X) is a constructor
term, x (resp. v) is a sequence of variables in X (resp. terms
in T (Σ,N ∪X)) both of the same length.

Fig. 1. Syntax of processes

Most of the constructions are rather standard. We may note

the special construct let x = v in P else Q that combines
the sequence of terms v and in case of success, i.e. when v ⇓ u

several standard constructions, allowing to write computations
and conditionals compactly. Such a process tries to evaluate

for some messages u, the process P in which x are replaced
by u is executed; otherwise the process Q is executed. The goal
of this construct is to avoid nested let instructions to be able to
deﬁne our class of protocols in a simple way later on. Note also
that the let instruction together with the eq theory as deﬁned
in Example 3 can encode the usual conditional construction.

Indeed, “let x = eq(u, v) in P else Q” will execute P only if
the computation succeeds on eq(u, v), that is only if u ⇓ u′,
v ⇓ v′, and u′ =E v′ for some messages u′ and v′.
after outputs. We write fv(P) for the set of free variables
input or a let construct. A process P is ground if fv(P)=∅.

of P , i.e. the set of variables that are not in the scope of an

For brevity, we sometimes omit “else 0” and null processes

Example 4: We consider the RFID protocol due to Feld-
hofer et al. as described in [24] and which can be presented
using Alice & Bob notation as follows:

1.

I → R ∶ nI
2. R → I ∶ {nI , nR}k
I → R ∶ {nR, nI}k

3.

∶= νk.(νnI .PI ∣ νnR.PR)

The protocol is between an initiator I (the reader) and a
responder R (the tag) that share a symmetric key k. We con-
sider the term algebra introduced in Example 3. The protocol
is modeled by the parallel composition of the processes PI
and PR, corresponding respectively to the roles I and R.

PI

PFh

where PI and PR are deﬁned as follows, with u= dec(x1, k):

∶= out(cI , nI).in(cI , x1).
let x2, x3 = eq(nI , π1(u)), π2(u) in
out(cI , enc(⟨x3, nI⟩, k))
let y3 = eq(y2, enc(⟨nR, y1⟩, k)) in 0

PR ∶= in(cR, y1).out(cR, enc(⟨y1, nR⟩, k)).in(cR, y2).

C. Semantics

are implicitly removed;

The operational semantics of processes is given by a labeled
transition system over conﬁgurations (denoted by K) which

are pairs (P; φ) where:
● P is a multiset of ground processes where null processes
● φ = {w1 ↦ u1, . . . , wn ↦ un} is a frame,
substitution where w1, . . . , wn are variables in W, and
We often write P ∪ P instead of {P} ∪ P. The terms
Given a conﬁguration K, φ(K) denotes its second component.
cases, the corresponding frame is ∅.

in φ represent the messages that are known by the attacker.

Sometimes, we consider processes as conﬁgurations, in such

u1, . . . , un are messages.

i.e. a

The operational semantics of a process is given by the

α(cid:18)→ deﬁned in Figure 2. The rules are quite standard

relation
and correspond to the intuitive meaning of the syntax given
in the previous section. The ﬁrst rule allows the attacker to
send on channel c a message as soon as it is the result of
a computation done by applying public function symbols on
messages that are in his current knowledge. The second rule
corresponds to the output of a term: the corresponding term
is added to the frame of the current conﬁguration, which
means that the attacker gains access to it. The third and fourth
rules correspond to the evaluation of a sequence of terms

v = v1, . . . , vn; if this succeeds, i.e. if there exist messages
u1, . . . un such that v1 ⇓ u1, . . . vn ⇓ un then variables x are

bound to those messages, and P is executed; otherwise the
process will continue with Q. The three remaining rules allow
one to execute a restriction, unfold a replication, and split a
parallel composition. The two ﬁrst rules are the only observ-
able actions. However, for reasons that will become clear later
on, we make a distinction when a process evolves using LET
or LET-FAIL. The relation
(where α1 . . . αn is a sequence of actions) is deﬁned as the
transitive closure of

α1...αn(cid:18)(cid:18)(cid:18)(cid:18)→ between conﬁgurations

α(cid:18)→.

Example 5: Continuing Example 4. We have that:

tr(cid:18)→(∅; φ0)

PFh

where tr and φ0 are as follows, for fresh names k′, n′

tr ={ τ.τ.τ.τ.out(cI , w1).in(cR, w1).out(cR, w2)
φ0 ={w1 ↦ n′

in(cI , w2).τthen.out(cI , w3).in(cR, w3).τthen
I , w2 ↦ enc(⟨n′
I⟩, k′)}.

R⟩, k′),
w3 ↦ enc(⟨n′

I and n′

R, n′

I , n′

R:

This execution corresponds to a normal execution of one
session of the protocol.

D. Trace equivalence

We are concerned with trace equivalence, which is com-
monly used [9], [25] to express many privacy-type properties
such as anonymity, unlinkability, strong secrecy, etc. Intu-
itively, two conﬁgurations are trace equivalent if an attacker

567567

IN
OUT
LET
LET-FAIL
NEW
REPL
PAR

(in(c, x).P ∪P; φ) in(c,R)(cid:18)(cid:18)(cid:18)(cid:18)→ (P{x↦ u}∪P; φ) where R is a recipe such that Rφ⇓ u for some message u
with w a fresh variable in W
(out(c, u).P ∪P; φ) out(c,w)
(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)→ (P ∪P; φ∪{w ↦ u})
(let x= v in P else Q∪P; φ) τthen(cid:18)(cid:18)→ (P{x↦ u}∪P; φ)
when v ⇓ u for some u
(let x= v in P else Q∪P; φ) τelse(cid:18)(cid:18)→ (Q∪P; φ)
when vi ⇓̸ for some vi ∈ v
(νn.P ∪P; φ) τ(cid:18)→ (P ∪P; φ)
where n is a fresh name from N
(!P ∪P; φ) τ(cid:18)→ (P ∪ !P ∪P; φ)
({P1 ∣ P2}∪P; φ) τ(cid:18)→ ({P1, P2}∪P; φ)

Fig. 2. Semantics for processes

cannot tell whether he is interacting with one or the other. Be-
fore deﬁning formally this notion, we ﬁrst introduce a notion
of equivalence between frames, called static equivalence.

Deﬁnition 2: A frame φ is statically included in φ′ when

dom(φ)= dom(φ′), and
● for any recipe R such that Rφ ⇓ u for some u, we have
that Rφ′ ⇓ u′ for some u′;
● for any recipes R1, R2 such that R1φ ⇓ u1, R2φ ⇓ u2,
and u1 =E u2, we have that R1φ′ ⇓=E R2φ′ ⇓, i.e. there
exist v1, v2 such that R1φ′ ⇓ v1, R2φ′ ⇓ v2, and v1 =E v2.
Two frames φ and φ′ are in static equivalence, written φ∼ φ′,

if the two static inclusions hold.

Intuitively, an attacker can distinguish two frames if he is
able to perform some computation (or a test) that succeeds
in φ and fails in φ′ (or the converse).

Example 6: Consider the frame φ0 as given in Example 5,

we have that φ0 ⊔{w4 ↦ k′} /∼ φ0 ⊔{w4 ↦ k′′}. Indeed, the
attacker may observe that the computation R = dec(w2, w4)
succeeds in φ⊔{w4 ↦ k′} but fails in φ⊔{w4 ↦ k′′}.

that

the fact

Then, trace equivalence is the active counterpart of static
equivalence taking into account
the attacker
may interfere during the execution of the process in order
to distinguish between the two situations.

Given a conﬁguration K =(P; φ), we deﬁne trace(K):
trace(K)={(tr, φ′) ∣ (P, φ) tr(cid:18)→(P ′; φ′)
for some conﬁguration (P ′; φ′)}.
We deﬁne obs(tr) to be the subsequence of tr obtained by
that K is trace included in K ′, written K ⊑ K ′, when, for any
(tr, φ) ∈ trace(K) there exists (tr′, φ′) ∈ trace(K ′) such that
obs(tr) = obs(tr′) and φ ∼ φ′. They are in trace equivalence,
written K ≈ K ′, when K ⊑ K ′ and K ′ ⊑ K.
K =(!PFh;∅) and K ′ = (!νk.(!νnI .PI ∣ !νnR.PR);∅) are in

Deﬁnition 3: Let K and K ′ be two conﬁgurations. We say

Example 7: We may be interested in checking whether

erasing all the τ actions (i.e. τ, τthen, τelse).

trace equivalence. Intuitively, this equivalence models the fact
that PFh is unlinkable: each session of the protocol appears to
an attacker as if it has been initiated by a different tag, since
a given tag can perform at most one session in the idealized
scenario K. This equivalence actually holds. It is non-trivial,

and cannot be established using existing veriﬁcation tools such
as ProVerif or Tamarin. The technique developed in this paper
will notably allow one to establish it automatically.

III. OUR CLASS OF PROTOCOLS AND PROPERTIES

We aim to propose sufﬁcient conditions to ensure unlinka-
bility and anonymity for a generic class of 2-party protocols.
In this section, we deﬁne formally the class of protocols and
the security properties we are interested in.

A. A generic class of 2- party protocols

As already mentioned, we consider 2-party protocols that
are therefore made of two roles called the initiator and

responder role respectively. We assume a set L of labels that

will be used to name output actions in these roles, allowing
us to identify outputs that are performed by a same syntactic
output action. These labels have no effect on the semantics.
Deﬁnition 4: An initiator role is a ground process obtained

using the following grammar:

PI ∶∶= 0 ∣ (cid:10)∶ out(c, u).PR

where c ∈ C, u ∈ T (Σc,N ∪X), (cid:10) ∈ L, and PR is obtained

PR ∶∶= 0

from the grammar of responder roles:

∣
∣

in(c, y).let x= v in PI else 0
in(c, y).let x= v in PI else (cid:10)∶ out(c′, u′)

where c, c′ ∈ C, y ∈ X , x (resp. v) is a (possibly empty)
sequence of variables in X (resp. terms in T (Σ,N ∪ X)),
u′ ∈T (Σc,N ∪X), and (cid:10)∈L.

Intuitively, a role describes the actions performed by an
agent. A responder role consists of waiting for an input
and, depending on the outcome of a number of tests, the
process will continue by sending a message, or stop possibly
outputting an error message. An initiator behaves similarly but
begins with an output. The grammar forces to add a conditional
after each input. This is not a real restriction as it is always
possible to add trivial conditionals with empty x, and v.

Example 8: Continuing our running example, PI (resp. PR)
as deﬁned in Example 4 is an initiator (resp. responder) role,
up to the addition of trivial conditionals and distinct labels (cid:10)1,
(cid:10)2, and (cid:10)3 to decorate output actions.

568568

Then, a protocol consists of an initiator role and a responder
role that can interact together. This is formally stated through
the notion of honest trace.

Deﬁnition 5: A trace tr (i.e. a sequence of actions) is honest

for a frame φ if τelse ∉ tr and obs(tr) is of the form
out( , w0).in( , R0).out( , w1).in( , R1). . . .
for arbitrary channel names, and such that Riφ⇓=E wiφ⇓ for
any action in( , Ri) occurring in tr.

An honest trace is a trace in which the attacker does not
really interfere, and that allows the execution to progress
without going into an else branch that intuitively correspond
to a way to abort the protocol.

Now, among the names that occur in the roles, we need to
distinguish those that correspond to long-term data e.g. keys
(called identity names) from others that are freshly generated at
each session (called session names). We also need to introduce

if it is equal modulo E to a term that is built using public
symbols only.

the notion of public messages. A message u is public if u=E v
for some v ∈T (Σc∩ Σpub,∅). Intuitively, a message is public
Deﬁnition 6: A protocol Π is a tuple (k, nI , nR,I,R)
where k, nI, nR are three disjoint sets of names, I (resp. R)
is an initiator (resp. responder) role such that fn(I) ⊆ k⊔ nI
(resp. fn(R)⊆ k⊔ nR). Labels of I and R must be pairwise
distinct. Names k (resp. nI ⊔ nR) are called identity names
Let PΠ = νk.(νnI .I ∣ νnR.R). We assume that PΠ
trh(cid:18)→
(∅; φh) for some frame φh that does not contain any public
Example 9: Let Π = (k, nI , nR, PI , PR) with PI and PR
PΠ = ν k.(ν nI .PI ∣ ν nR.PR). Let trh = tr, and φh = φ0

as deﬁned in Example 4. We have already seen that PI
is an initiator role whereas PR is a responder role. Let

message, and some trace trh that is honest for φh.

(resp. session names).

as deﬁned in Example 5. They satisfy the requirements stated
in Deﬁnition 6, and therefore Π is a protocol according to our
deﬁnition.

B. Security properties under study

We consider both anonymity and unlinkability as deﬁned
in [8]. Before recalling the formal deﬁnition of these two
notions, we ﬁrst introduce some useful notation.

Given a protocol Π, as deﬁned above, we denote MΠ the
possibly execute an arbitrary number of sessions, whereas SΠ

process that represents an arbitrary number of agents that may

represents an arbitrary number of agents that can at most
execute one session each. Formally, we deﬁne:

MΠ ∶= !νk.(!νnI .I ∣ !νnR.R); and
SΠ ∶= !νk.(νnI .I ∣ νnR.R).

a) Unlinkability: Informally, a protocol preserves unlink-

ability w.r.t. the roles I and R if each session of these roles
the protocol with respect to unlinkability, allows the roles I

looks to an outside observer as if it has been executed with
different identity names. In other words, an ideal version of

andR to be executed at most once for each identity names. An

outside observer should then not be able to tell the difference
between the original protocol and the ideal version of this
protocol as formally stated below.

Deﬁnition 7: Let Π = (k, nI , nR,I,R) be a protocol. We
say that Π preserves unlinkability if MΠ ≈SΠ.

Although unlinkability of only one role (e.g. the tag for
RFID protocols) is often considered in the literature, we
consider a stronger notion where both roles are treated sym-
metrically. We believe this is needed to not miss practical
attacks (see Sections VII-C,VII-E for a discussion).

b) Anonymity: In order to express anonymity w.r.t. some

addition to the arbitrary number of agents that may execute an

identities id⊆ k, we introduce the following process:
Π ∶= MΠ ∣ νk.(!νnI .I0 ∣ !νnR.R0)
Mid
where I0 =I{id↦ id0}, R0 =R{id↦ id0}, and id0 are fresh
constants from Σc∩Σpub (i.e. not used in Π). In this process, in
arbitrary number of sessions, there are two agents I0 and R0
Deﬁnition 8: Let Π=(k, nI , nR,I,R) be a protocol, id⊆ k.
We say that Π preserves anonymity w.r.t. id if MΠ ≈Mid
does not see the difference between the system Mid
id0 is present) and the original system MΠ (in which id0 is
not present). Since id0 is not present in the system MΠ, his

that have disclosed (part of) their identity id0 to the attacker,
and that may also execute an arbitrary number of sessions.

Deﬁned in this way, anonymity ensures that an attacker
Π (in which

Π.

anonymity is trivially preserved.

c) Discussion: A ﬂurry of alternative deﬁnitions of un-
linkability have been proposed in the literature (see, e.g. [26],
[27] for a comparison). Among the strongest ones, various
game-based formulations have been considered, both in the
computational and symbolic models. Some of these deﬁni-
tions, unlike strong unlinkability, can be veriﬁed directly in
ProVerif using diff-equivalence [28]. However, such game-
based deﬁnitions do not imply strong unlinkability (see Ap-
pendix C for a counter-example) which leaves open the
problem of automatically verifying it.

IV. OUR APPROACH

We now deﬁne our two conditions, namely frame opacity
and well-authentication, and our result which states that these
conditions are sufﬁcient to ensure unlinkability and anonymity.
Before doing that, we shall
introduce annotations in the
semantics of our processes, in order to ease their analysis.
After having stated our conditions and result, we will illustrate
that our conditions are realistic on various case studies.
A. Annotations

We shall now deﬁne an annotated semantics whose transi-
tions are equipped with more informative actions. The anno-
tated actions will feature labels identifying which concurrent
process has performed the action. This will allow us to identify
which speciﬁc agent (with some speciﬁc identity and session
names) performed some action.

569569

an action other than τ (possibly τthen or τelse) and a is an

Formally, an annotation is of the form A(k, n) where A ∈
{I, R}. An annotated action is either τ or α[a] where α is
annotation. Finally, an annotated process is of the form P[a]
Given a protocol Π = (k, nI , nR,I,R), consider any exe-
Π, MΠ or SΠ. In such an execution, τ actions
cution of Mid

where P is a role process and a is an annotation.

are solely used to instantiate new agents, by unfolding a
replication, breaking a parallel and choosing fresh names.
Performing these actions results in the creation of agents, that

is, instances of I and R with fresh names. Actions other

than τ (that is, input, output and conditionals) are then only
performed by those agents.

This allows us to deﬁne an annotated semantics for our
processes of interest. In that semantics, agents in the multiset
of processes are annotated by their identity (i.e. identity and
session names that have been created for them), and actions
other than τ are annotated with the identity of the agent
responsible for that action. Traces of the annotated semantics
will be denoted by ta. We also assume that labels used to
decorate output actions are added into the frame together with
the outputted term so that we can refer to them when needed.
Example 10: Considering the protocol of Example 9,

Example 5. The annotated execution has the trace ta given
below, where k′, n′

process SΠ can essentially perform the execution seen in
R are fresh names, aI = I(k′, n′
I)
and aR = R(k′, n′
R):
ta = τ.τ.τ.τ.τ.out(cI , w1)[aI].in(cR, w1)[aR].
out(cR, w2)[aR].in(cI , w2)[aI].τthen[aI].
out(cI , w3)[aI].in(cR, w3)[aR].τthen[aR]
({IσI[aI], RσR[aR], SΠ)}; φ0).

After the initial τ actions, the annotated conﬁguration is

I and n′

where σI ={k ↦ k′, nI ↦ n′

I}, and σR ={k ↦ k′, nR ↦ n′
R}.

The structure is preserved for the rest of the execution of ta,
with three processes in the multiset (until they become null),
two of which remaining annotated with aI and aR. The three
terms in φ0 are decorated with (cid:10)1, (cid:10)2 and (cid:10)3 respectively.

Note that annotations of the speciﬁc agents whose identity
contains constants id0 will contain those constants (i.e. they

are of the form A(k, n) with id0 ⊆ k).

B. Frame opacity

In light of attacks based on leakage from messages where
relations between outputted messages are exploited by the
attacker to trace an agent, our ﬁrst condition will basically
require that, in any execution, outputs are indistinguishable
from pure randomness and therefore do not reveal anything to
the attacker. Formally, we deﬁne this notion by comparing a
frame with an ideal version of it, which is essentially obtained
by replacing each message of a frame by a fresh name.
However, in order to obtain a reasonable condition, we must
make an exception there for constructors which can be inverted
(e.g. pairs, lists, XML data) which we call transparent and are
often used in protocols without any inherent risk.

570570

to be transparent if it satisﬁes the following conditions:

Deﬁnition 9: A set of constructors Σt ⊆ Σc ∩ Σpub is said
● for all f ∈ Σt of arity n, and for all 1≤ i≤ n, there exists
a recipe Ri ∈ T (Σpub,{w}) such that for any message
u = f(u1, . . . , un) ∈ T (Σc,N), one has Ri{w ↦ u} ⇓ vi
for some vi such that vi =E ui;

● symbols of Σt do not occur in the equations of E.
In the rest of our theoretical development, we assume an
arbitrary transparent set Σt. Note that our results hold even if
some constructors satisfying the previous two conditions are
not part of the chosen Σt.

Example 11: In the signature of Example 1, the largest set

of transparent constructors is {⟨⟩, 0, ok}.
terms by holes (denoted by ◻), and then ﬁll-in these holes

We now deﬁne the idealization of (the observable parts of)
messages and frames: we ﬁrst replace non-transparent sub-

using distinct fresh names. The technical details of the ﬁrst
step may be found in Appendix A.

Proposition 1: There exists a function

[⋅]ideal ∶ T (Σc,N)→T (Σt,{◻})

such that [u]ideal = f([u1]ideal, . . . ,[un]ideal) whenever u =E
f(u1, . . . , un) for f ∈ Σt, and [u]ideal = ◻ otherwise. Further-
more, we have that [u]ideal =[v]ideal whenever u=E v.
Deﬁnition 10: A concretization of ut ∈ T (Σt,{◻}) is any
We denote by inst(ut) the set of all concretizations of ut, and
by [u]nonce the set inst([u]ideal).
Example 12: Let u be ⟨nP , enc(⟨ok, nP⟩, k)⟩. We have that
[u]ideal =⟨◻,◻⟩ and [u]nonce ={⟨n1, n2⟩ ∣ n1 ≠ n2 ∈N}.

term obtained by replacing each hole of ut by a fresh nonce.

Those deﬁnitions are extended to frames in a natural way,
with the freshness condition on nonces being understood at
the level of frame and not of individual messages. As a result,

we immediately have that, for any u′ ∈ [u]nonce (resp. φ′ ∈
[φ]nonce), no nonce appears twice in u′ (resp. φ′), and therefore
for all frames ψ and φ1, φ2 ∈[ψ]nonce, one has φ1 ∼ φ2.

We are now ready to state our ﬁrst condition:

Deﬁnition 11: The protocol Π ensures frame-opacity if, for

any execution (Mid
1) φ∼ ψ for some ψ ∈[φ]nonce, and
2) for any wi, wj in dom(φ) that carry the same label

Π;∅) ta(cid:18)→(Q; φ), we have that:
(cid:10)∈L, we have that [wiφ]ideal =[wjφ]ideal.

Example 13: Consider the frame φ0 as deﬁned in Exam-

ple 5. We have that

[φ0]ideal ={w1 ↦◻, w2 ↦◻, w3 ↦◻}.

We have that φ0 ∼ φ for any φ∈[φ0]nonce.
and its idealized version [φ0]nonce does not hold, and therefore

I, static equivalence between φ0

However, in case, n′

R = n′

any protocol that generates such a frame is not frame opaque.

C. Well-authentication

Our second condition will prevent the attacker to obtain
some information about agents through the outcome of condi-
tionals. To do so, we will essentially require that conditionals

of I and R can only be executed successfully in honest,

intended interactions. It
is unnecessary to impose such a
condition on conditionals that never leak any information,
which are found in several security protocols. We characterize
below a simple class of such conditionals, for which the
attacker will always know the outcome of the conditional
based on the past interaction.

Deﬁnition 12: A conditional let x = v in P else Q
occurring in A∈{I,R} is safe if v ∈T (Σpub,{x1, . . . , xn}∪
{u1, . . . , un}), where the xi are the variables bound by the

previous inputs of that role, and ui are the messages used in
the previous outputs of that role.

Example 14: Consider the process given below:

out(c, u).in(c, x).let z = neq(x, u) in P else Q

The conditional is used to ensure that the agent will not accept
as input the message he sent at the previous step. Such a
conditional is safe according to our deﬁnition.

Note that trivial conditionals required by the grammar are

safe and will thus not get in the way of our analysis.

two agents are having an honest,

We can now formalize the notion of association, which
expresses that
intended
interaction (i.e. the attacker essentially did not interfere in their
communications). For an annotated trace ta and annotations a

and a′, we denote by ta∣a,a′ the subsequence of ta that consists
of actions of the form α[a] or α[a′].
Deﬁnition 13: Two agents A1(k1, n1) and A2(k2, n2) are
associated in (ta, φ) if:
● the agents are dual, i.e. A1 ≠ A2 and k1 = k2;
● the interaction ta∣A1(k1,n1),A2(k2,n2) is honest for φ.
Example 15: Continuing Example 10, the agents I(k′, n′
I)
and R(k′, n′

R) are associated in (ta, φ0).

We can ﬁnally state our second condition:

Deﬁnition 14: The protocol Π is well-authenticating if, for

Π;∅) ta.τthen[A(k,n1)]

(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)→(P; φ)

either the last action corresponds to a safe conditional, or there

any execution (Mid
exists A′ and n2 such that (i) A(k, n1) and A′(k, n2) are
associated in (ta, φ), and (ii) A′(k, n2) is only associated with
A(k, n1) in (ta, φ).

Intuitively, this condition does not require anything for safe
conditional as we already know that they cannot leak new
information to the attacker (he already knows their outcome).
For unsafe conditionals, condition (i) requires that whenever
an agent a evaluates them positively (i.e. he does not abort the
protocol), it must be the case that this agent a is so far having
an honest interaction with a dual agent a′. Indeed, as discussed
in introduction, it is crucial to avoid such unsafe conditionals
to be evaluated positively when the attacker is interfering

571571

because this could leak crucial information. Condition (ii) is
needed to prevent from having executions where an agent is
associated to several agents, which would break unlinkability.

D. Soundness w.r.t. unlinkability and anonymity

Our main theorem establishes that the previous two condi-

tions are sufﬁcient to ensure unlinkability and anonymity.

Theorem 1: Consider a protocol Π = (k, nI , nR,I,R)
and some identity names id ⊆ k. If the protocol is well-
Note that, when id = ∅, we have Mid
Π ≈ MΠ and our
conditions coincide on Mid
Π and MΠ. We thus have as a
corollary that if MΠ ensures well-authentication and frame

authenticating and ensures frame opacity,
unlinkability and anonymity w.r.t. id.

then Π ensures

opacity, then Π is unlinkable.

Before establishing this theorem in the next section, let us
comment on its practical impact. We summarize the result
of the confrontation of our method to our case studies in
Figure 3, focusing on unlinkability. Detailed descriptions of
those protocols and discussions are in Section VII. We remark
that our conditions have proven to be tight enough for all our
case studies: when a condition fails to hold, we could always
discover a real attack on unlinkability. Most of the positive
results (when unlinkability holds) and all attacks are new. Note
that all positive results were established automatically using
our tool UKano (which is based on ProVerif).

Protocol

Feldhofer
Hash-Lock
LAK (stateless)
Fixed LAK
BAC
BAC/PA/AA
PACE (faillible dec)
PACE (as in [29])
PACE
PACE with tags

Frame
opacity

Well-
auth.




−





−
−
−














Unlinkability

safe
safe
attack
safe
safe
safe
attack
attack
attack
safe

Fig. 3. Summary of our case studies. We note  for a condition automatically
checked using UKano and  when the condition does not hold.

V. PROOFS

We provide in this section the proof of Theorem 1. Our
main argument consists in showing that, for any execution of

Π, there is an indistinguishable execution of SΠ.
Mid
Π, MΠ and SΠ, it will be more
Instead of working with Mid
of I and R. Intuitively, ground conﬁgurations correspond to
Π, MΠ or SΠ by
the annotated multisets obtained from Mid

convenient to work with ground conﬁgurations of the protocol
under consideration, which are annotated multisets of instances

launching a few sessions (performing τ actions corresponding
to replication and names creations) and then removing the
initial replicated process to keep only the instantiated agents.

We ﬁrst deﬁne ground conﬁguration annotations as sets of

annotations satisfying the following conditions:

● in all annotations A(k, n), the session parameters n are

names and the identity parameters k are made of names
or constants id0;

● no name appears both as identity and session parameter

in any two annotations;

● no two annotations share a session parameter;
● two annotations either have the same identity parameters,

or do not share any identity parameter at all.

annotation.

Then, a ground conﬁguration is any annotated multiset of the

PI ={I{k ↦ l, nI ↦ m}[I(l, m)] ∣ I(l, m)∈ S }

form PI ⊔PR where
and similarly for PR, where S is a ground conﬁguration
We shall say that a ground conﬁguration P is single-session
A(k, n) and A(k, m) occur in P then n = m) and id0 does
Mid
also be obtained from SΠ.

not occur in it. Any ground conﬁguration can be reached from
Π; single-session ground conﬁgurations are those which can

if there is at most one agent per identity and role (i.e. if

We now introduce formally the notion of renaming of agents
that we shall use in the proof, before presenting a few key
results that will ﬁnally allow us to prove our theorem.

Deﬁnition 15: A renaming of agents (denoted by ρ) is
an injective mapping from annotations to annotations which
preserves roles (i.e. initiator (resp. responder) annotations are
mapped to initiator (resp. responder) annotations) such that the
image of a ground conﬁguration annotation is still a ground
conﬁguration annotation.

actions of the trace.

If ta is an annotated trace whose annotations are all in

dom(ρ), we deﬁne taρ as the annotated trace obtained from ta
by replacing any annotation a by ρ(a), without changing the
If ρ(A(k, n)) = A(k′, n′), the renaming σ induced by ρ
on A(k, n) is the (injective) mapping such that σ(k)= k′ and
σ(n)= n′. Given a ground conﬁgurationP ={Ai[ai]}i whose
annotations are in dom(ρ), we deﬁne Pρ = {Aiσi[ρ(ai)]}i

where σi is the renaming induced by ρ on ai.

Note that the renaming on parameters induced by a renam-
ing of agents may conﬂict: this happens, for example, when

ρ(A(k, n)) = A(k1, n) and ρ(A(k, m)) = A(k2, m). This
each handle w ∈ dom(φ) is uniquely associated in ta to an

means, in particular, that we cannot meaningfully deﬁne φρ
for a frame φ. However, given an execution ta that yields φ,

output, and thus an agent aw. We can then deﬁne φρ (omitting
the mention of ta as a slight abuse of notation) as

{ w ↦ uσ ∣ w ∈ dom(φ), σ induced by ρ on aw }.

A. Control is determined by associations

We show that the outcome of tests is entirely determined by
associations. This will be useful to show that, if we modify
an execution (by renaming agents) while preserving enough
associations, then the control ﬂow is left unchanged.

572572

Proposition 2: Let Π be a well-authenticating protocol,

and P a ground conﬁguration of Π such that
(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)(cid:18)→(P ′; φ)

(P;∅) ta.τx[A(k,n1)]

and the last action is performed by an unsafe conditional.

We have τx = τthen iff there exists n2 such that A(k, n2) is
associated to A(k, n1) in (ta, φ).
Proof. The ⇒ direction is a direct consequence of well-

authentication. For the other direction, we observe that (up
to changes of recipes that do not affect the resulting mes-
sages) if two agents are associated then they are execut-
trace of Π modulo a renaming of param-
ing the honest
eters, thus the considered test must be successful. Assum-

ing that a1 = A(k, n1) and a2 = A(k, n2) are associ-
ated in (ta, φ), we shall prove that τx = τthen. By hy-
pothesis, ta∣a1,a2
the form out(c1, w1).in(c′
n, Mn)
Miφ⇓=E wiφ for all 1≤ i≤ n. Consider ta′ obtained from ta
trace can still be executed by (P;∅) and yields the same
conﬁguration (P ′; φ). But now ta′∣a1,a2 is a self-contained
annotated a1 and a2 in P, we have

by replacing each recipe Mi by wi. Since this change of
recipes does not affect the resulting messages, the modiﬁed

1, M1) . . . out(cn, wn).in(c′

with possibly an extra output at the end, and are such that

if P and Q are the processes respectively

its observable actions are of

is honest:

execution,

i.e.

({P[a1], Q[a2]};∅) ta′∣a1 ,a2

(cid:18)(cid:18)(cid:18)(cid:18)→(P ′′; φ′′).

In that execution, everything is deterministic (up to the equa-
tional theory) and thus the execution is actually a preﬁx of
the honest execution of Π, up to a bijective renaming of pa-
rameters (note that P and Q do not share session parameters).
Thus the next action, i.e. the conditional performed by a1, is
a τthen.

◻

B. Invariance of frame idealizations

In general, a renaming of agents can break executability;
typically, mapping two dual agents to agents of different iden-
tities breaks the ability of these two agents to communicate
successfully. Even when executability is preserved, parameters
change (so do names) and thus frames are modiﬁed. However,
frame opacity immediately implies that a renaming of agents
has no effect on the resulting idealized frames, because the
renaming has no effect on the labels associated to the agent
outputs. Therefore, we have the following result (proof in
Appendix B).

Proposition 3: Let Π be a protocol ensuring frame opacity.

Let P be a ground conﬁguration of Π, ta an annotated trace,
and ρ an arbitrary renaming of agents. If (P;∅) ta(cid:18)→(P1; φ1)
and (Pρ;∅) taρ(cid:18)→(P2; φ2), then [φ1]ideal =[φ2]ideal.

C. A sufﬁcient condition for preserving executability

We can now state a key lemma, identifying a class of

renamings which yields indistinguishable executions.

Deﬁnition 16: Agents a and a′ are connected in (ta, φ)
if they are associated in (ta0, φ) for some preﬁx ta0 of ta

that contains at least one τthen action of an unsafe conditional
annotated with either a or a′.

Lemma 1: Let Π be a well-authenticating protocol ensuring
frame opacity, and ta be an annotated trace executed by some

ground conﬁguration P:(P;∅) ta(cid:18)→ K
annotations of P, and such that ρ(a) and ρ(a′) are dual iff a
and a′ are connected in (ta, φ(K)). Then we have:
φ(K)∼ φ(Kρ).

Let ρ be a renaming of agents whose domain contains the

(Pρ;∅) taρ(cid:18)→ Kρ

and

Proof. We shall focus on establishing that taρ is executable;
once this is known, static equivalence is a direct consequence
of Proposition 3. For any preﬁx ta0 of ta, we prove that:

(Pρ;∅) ta0ρ(cid:18)(cid:18)→ K0ρ

with an additional invariant: ρ(a) and ρ(a′) are associated in
(ta0ρ, φ(K0ρ)) iff a and a′ are associated in(ta0, φ(K0)) and
connected in(ta, φ(K)). We proceed by induction on ta0. If it

induction hypothesis, we have K0 (resp. K0ρ) resulting from

is empty, then ta0ρ can also obviously be executed. For empty
traces, association coincides with duality, thus the hypothesis
on ρ implies our invariant.

Consider now a preﬁx of ta of the form ta0.α[a]. By
the execution of ta0 by P (resp. ta0ρ by Pρ) and our invariant
φ(K0) ∼ φ(K0ρ). The action α performed by the process
annotated a in P may be an input, an output, or a test. In any
case, the corresponding process in Pρ can perform an action

satisﬁed for ta0. Moreover, by Proposition 3, we know that

of the same nature. To conclude, we distinguish the three kinds
of actions:
Case 1: α is an output. We only have to check our invariant for

ta0.α[a]. It essentially follows from the fact that association
is not affected by the execution of an output: ρ(a) and ρ(a′)
are associated in (ta0.α[a])ρ iff they are associated in ta0ρ,

and similarly without ρ.
Case 2: α is a conditional. We ﬁrst need to make sure that the
outcome of the test is the same for a and aρ. We distinguish
two cases, whether the conditional is safe or not.

● If the conditional is safe, then its outcome only depends
on the inputs and outputs of a that are statically equivalent

to those of ρ(a). Hence, outcome of that test is the same

for a and aρ.

● If the conditional is unsafe, we make use of Proposition 2
to show that the outcome of the conditional is the same
on both sides. We can do it because our invariant, in this

case, implies that a and a′ are associated in ta0 iff ρ(a)
and ρ(a′) are associated in ta0ρ. This is simply because,

if a and a′ are associated in ta0, then they are having an
honest interaction, thus the outcome of the test will be
positive, and a and a′ are connected in ta.

In both cases (safe or unsafe) we need to make sure that
our invariant is preserved. This is because the association
between a and a′ is preserved iff the outcome of the test is
positive, which is the same before and after the renaming.

573573

Case 3: α is an input. We immediately have that aρ can
perform α, on the same channel and with the same recipe. Let
us now check that our invariant is preserved. We only check

are also associated in ta0, thus a and a′ are connected in ta and
associated in ta0. Now, because α did not break the association

one direction, the other being very similar. Assume that ρ(a)
and ρ(a′) are associated in ta0ρ.α[ρ(a)]. The renamed agents
of ρ(a) and ρ(a′) in ta0ρ, it must be that the input message
in α = in(c, M) corresponds to the last output of ρ(a′) in
in φ(K0ρ), we have M φ(K0ρ) ⇓=E wφ(K0ρ). But, because
φ(K0)∼ φ(K0ρ), we then also have M φ(K0)⇓=E wφ(K0).
The association of a and a′ in ta0 carries over to ta0.α[a]. ◻
Thanks to our lemma, we can change any execution of Mid
into an indistinguishable execution of SΠ, provided that an

ta0ρ. Formally, if that last output corresponds to the handle w

D. Proof of Theorem 1

Π

appropriate renaming of agents exists. This is our last step
before the ﬁnal proof:

Proposition 4: For any protocol and any ground conﬁgu-

ration P of the protocol such that
(P;∅) ta(cid:18)→ K,

there exists an agent renaming ρ satisfying the hypothesis of

Lemma 1 and such that Pρ is single-session.

Proof sketch. The renaming maps all session (resp. iden-
tity) parameters to new distinct, fresh session (resp. identity)
parameters, with the only constraint that connected agents are
sent to dual agents (and thus share identity parameters). The
precise deﬁnition of the renaming as well as the complete
proof of this proposition can be found in Section B.

◻
Proof of Theorem 1. It is easy to see that SΠ ⊑MΠ ⊑Mid
Π ⊑ SΠ. Consider an
so it only remains to establish that Mid
ta(cid:18)→ K. We can assume w.l.o.g. that session
execution Mid

We now have all the ingredients to prove our main result.
Π,

creations are all performed at the beginning of ta, i.e. it is of
the form τ ∗.ta′ with no occurrence of τ in ta′: otherwise we
can modify ta to satisfy this condition, without changing its
observable actions and the resulting frame. Thus we have a

Π

ground conﬁguration P of Π, such that:
(P;∅) ta′(cid:18)→ K.

Let ρ be the renaming obtained in Proposition 4 for ta′. By
Lemma 1, ta′ρ remains executable and is indistinguishable

from ta′. Moreover, since Pρ is single-session, we have that:

(SΠ;∅) τ ∗(cid:18)→(Pρ∪SΠ;∅) ta′ρ(cid:18)(cid:18)→ Kρ.

This execution allows us to conclude:

observables as ta, and yields a statically equivalent frame. ◻

it has the same

VI. MECHANISATION

We now discuss how to delegate the veriﬁcation of frame-
opacity and well-authentication to a fully automatic tool. In
this section, we show that appropriate encodings can be used
to leverage ProVerif [30] to do so. These encodings have been
implemented in our tool UKano [31]. This tool basically takes

as inputs a speciﬁcation of a protocol in our class and, by
applying translations described in this section and by calling
ProVerif, it automatically checks our two conditions and thus
unlinkability and anonymity.

A. Frame Opacity

We ﬁrst explain how to check frame opacity using the diff-
equivalence feature of ProVerif [32]. Diff-equivalence is a
property of bi-processes. A bi-process is a process in which

some terms are replaced by bi-terms, denoted choice[u1, u2].

Intuitively, a bi-process represents two processes. The ﬁrst
(resp. second) process is obtained by considering terms occur-
ring on the left-hand side (resp. right-hand side) of the choice
operators. Checking the diff-equivalence of a bi-process boils
down to checking that when the two processes are executed
simultaneously, the resulting frames are in static equivalence.
Our notion of frame opacity requires that for any execution

ta(cid:18)→(P ; φ), one has (1) φ∼ ψ for some ψ ∈[φ]nonce; and

Mid
ing the diff-equivalence between Mid

(2) outputs carrying the same label produce messages with the
same idealization. It is possible to verify both points by check-
Π and a modiﬁed version
of this process where each syntactical output u (identiﬁed by
a label) has been replaced by a static idealization, i.e. the
idealization of some message that this output may produce.

Π

(cid:5)

We assume that all syntactical outputs of the protocol can
be executed. This is obviously not a restriction in practice as
dead code should be removed and can be detected very easily
using, e.g. ProVerif. Under this assumption we shall compute,

: knowing that there is at least one execution where this
uideal
(cid:5)
output is triggered, producing some message m, we simply set
uideal
(cid:5)
is justiﬁed since all possible messages that this output may
produce must have the same idealization anyway.

for each syntactical output (cid:10)∶ out(c, u), its static idealization
= [m]ideal. Choosing an arbitrary execution in this way
Let us now describe the bi-process biproc(Mid
Π) whose
tion, the bi-process is deﬁned from Mid
]) where unonce
(cid:10) ∶ out(c, u(cid:5)) by (cid:10) ∶ out(c, choice[u(cid:5), unonce

diff-equivalence implies frame opacity. As a ﬁrst approxima-
Π by replacing each
(cid:5)

is obtained from uideal
by ﬁlling its holes with fresh names.
A crucial point is to consider fresh names from messages
as new session names of the bi-process so that they
unonce
(cid:5)
will be different for each session. The only remaining issue at
this stage is that diff-equivalence in ProVerif forces the left-
hand and right-hand processes to execute exactly the same
kind of actions at the same time. This might be a problem
for conditionals that have no real meaning for the right-
hand part. We overcome this difﬁculty in the actual deﬁnition

Π) by pushing conditionals into messages and

of biproc(Mid

putting else branches in parallel. We do not formally explain
how to do so as it heavily depends on speciﬁcities of ProVerif,
but just give an example to illustrate the pushing of condi-
tionals: we show in Figure 4 (part of) the bi-process resulting
from the application of our transformation to our running
example. One can see that the computation of merge never
fails (neither on the left, nor on the right) because catchFail
always returns a message. More examples can be found in

(cid:5)

! new k;
! new nI; new nR; new n1; new n2; new n3;

(

(* Initiator role: *)
out(cI,choice[nI, n1]);
in(cI,x);
let merge = choice[

let catchFail =

let yt,ynR = eq(pi1(dec(x,k)),nI),

pi2(dec(x,k)) in

enc((ynR,nI),k)

else n2,
n2] in

out(cI,merge))

|(

(*

Responder role: *)

in(cR,z);
out(cR,choice[enc((nI,nR),k), n3]); ...)

Fig. 4. Example of ProVerif ﬁle checking frame opacity (Feldhofer)

Π

the ProVerif ﬁles produced by UKano for our case studies,
available online [31].

Assuming that diff-equivalence holds for biproc(Mid
Π), we
Mid
Π) tr(cid:18)→
tr(cid:18)→ (P ; φ), there exists some execution biproc(Mid
(Q,[φ, φr]) with φ ∼ φr. By construction of the bi-process
we have that φr ∈ [φ]nonce, which implies item (1) of frame

have that frame opacity holds too. Indeed, for any execution

opacity. Moreover, idealizations only depends on output labels,
which implies item (2).
B. Well-authentication

We ﬁrst explain how to check condition (i) of well-
authentication. It is basically a conjunction of reachability
properties, which can be checked in ProVerif using correspon-

dence properties [33]. For each role A∈{I,R}, we associate
events of the form OutAi(k, n, m) and InAj(k, n, m), whose

to each syntactical output (resp. input) of the role an event
which uniquely identiﬁes the action. More formally, we use

arguments contain:

● identity parameters k and session parameters n;
● the message m that is inputted or outputted.
In the same fashion, we also add events of

TestAk(k, n) at the beginning of each then branch.

the form

For each conditional of the protocol, we ﬁrst check if the
simple syntactical criterion of safe conditionals holds. If it
is the case we do nothing for this conditional. Otherwise,
we need to check condition (i). It can be expressed as a
correspondence property using events as explained next. Given

a role A ∈ {I,R} and a conditional of this role whose event
is TestAi(k, n), the fact that if the conditional is positively

evaluated, then the involved agent must be associated to a
dual agent, can be expressed by the following correspondence
property:

1) when the event TestAi(k, n) is ﬁred,
2) there must be a previous event InAj(k, n, m) (InAj

corresponding to the input just before the conditional),

574574

sponding to the output that fed the input InAj in the
honest execution),

, m) (OutBk corre-
3) and a previous event OutBk(k, n
4) and a previous event InBl(k, n
, m′) (InBl correspond-
5) and a previous event OutAm(k, n, m′) (OutAm corre-

ing to the ﬁrst input before OutBk),

′

′

sponding to the output that fed the input InBl in the
honest execution), etc.

Note that by using the same messages m and m′ for inputs
and outputs, we express that the messages that are outputted
and inputted are equal modulo the equational theory E.

Example 16: Those kinds of correspondence properties are
better explained by showing the ProVerif code we produce.
We depict in Figure 5 the query we produce for checking
condition (i) on the ﬁrst conditional of PI from our running
example.

VII. CASE STUDIES

In this section we apply our proof technique to several case
studies. We rely on our tool UKano to check automatically
whether the protocol under study satisﬁes frame opacity and
well-authentication as deﬁned in Section IV. We also discuss
some variations of the protocols to examine how privacy
is affected. As explained in Section VI, UKano relies on
ProVerif;
the source code of our tool, and all produced
ProVerif ﬁles can be found in [31].

A. Feldhofer’s protocol

As already mentioned, this protocol falls into our generic
class of 2-party protocols. We succeeded in establishing au-
tomatically frame opacity and well-authentication. For both
requirements, UKano concludes in less than 1 second.

query k:key, n1:bitstring, n2:bitstring,

B. Hash-Lock protocol

nt:bitstring, nr:bitstring,
mP:bitstring, mR:bitstring;
event(TestI1(k,n1)) ==>

(event(InI1(k,n1,mR)) ==>

(event(OutR1(k,n2,mR)) ==>

(event(InR1(k,n2,mP)) ==>
(event(OutI1(k,n1,mP)))

) ) ).

Fig. 5. Example of ProVerif query for checking condition (i)

Finally, checking that condition (ii) of well-authentication
is satisﬁed is rather trivial once we know that the the other
two conditions hold. Indeed, as shown in the following lemma,
condition (ii) holds as soon as the ﬁrst conditional occurring
in the responder role has been identiﬁed as safe. Remark that
if the latter does not hold then unlinkability most likely fails
to hold.

Lemma 2: Let Π=(k, nI , nR,I,R) be a protocol that sat-
If the ﬁrst conditional that occurs in R is safe, then condition

isﬁes condition (i) of well-authentication, and frame opacity.

(ii) of well-authentication holds.

Proof. Consider an execution where two agents a and a′ are
associated and a′ has performed a τthen. If this test corresponds
to a safe conditional, there is nothing to prove. Otherwise,
we shall prove that a is only associated to a′. Thanks to our
hypothesis, a has performed at least one input even if it is
an initiator. Let m be that input message. We know that it is
equal (modulo E) to the previous output of a′, and want to
show that it cannot be equal to any output of another agent.
Let (cid:10) be the label of the previous output of a′. By deﬁnition
of a protocol, that output label cannot correspond to a public
message in the honest trace. Thus the idealization of the output
message associated to (cid:10) in the honest trace contains at least
one hole. By condition (2) of frame opacity, the same holds
for the idealization of m. Therefore, if m had been outputted
twice, it would have lead to two different messages in the
idealized frames, violating frame opacity.

◻

We consider the Hash-Lock protocol as described in [34].
This is an RFID protocol that has been designed to achieve
privacy even if no formal proof is given. The protocol relies on
a hash function, and can be informally described as follows.

Reader → Tag ∶
Tag → Reader ∶ nT , h(nR, nT , k)

nR

This protocol falls into our generic class of 2-party protocols,
and frame opacity and well-authentication can be automat-
ically established in less than 1 second. We can therefore
conclude that the protocol preserves unlinkability.

C. LAK protocol

We present an RFID protocol ﬁrst introduced in [35], and
we refer to the description given in [2]. To avoid traceability
attacks, the main idea is to ask the tag to generate a nonce
and to use it to send a different message at each session. We
suppose that initially, each tag has his own key k and the
reader maintains a database containing those keys.

The protocol is informally described below (h models an
hash function). In the original version (see e.g. [2]), in case
of a successful execution, both parties update the key k with

h(k) (they always store the two last keys). Our framework

does not allow one to model protocol that rely on a mutable
state. Therefore, we consider here a version where the key is
not updated at the end of a successful execution allowing the
key k to be reuse from one session to another.

Reader → Tag ∶
Tag → Reader ∶
Reader → Tag ∶

r1

r2, h(r1⊕ r2⊕ k)
h(h(r1⊕ r2⊕ k)⊕ k⊕ r1)

Actually, this protocol suffers from an authentication attack.
The protocol does not allow the reader to authenticate the
tag. This attack can be informally described as follows (and
already exists on the original version of this protocol). By

using algebraic properties of ⊕, an attacker can impersonate

575575

a tag by injecting previously eavesdropped messages. Below,

I(A) means that the attacker plays the role A.
I(Reader) → Tag ∶
r2, h(r1⊕ r2⊕ k)
Tag → Reader ∶
Reader → Tag ∶
I(Tag) → Reader ∶
2, h(r0⊕ r1⊕ k)
1)
h(h(r0⊕ r1⊕ k)⊕ k⊕ r′
Reader → Tag ∶
1⊕ r1⊕ r2, thus h(r1⊕ r2⊕ k)=E h(r′
2 = r′
1⊕ rI
2⊕ k).

where rI

r′
1
rI

r1

Due to this,

the protocol does not satisfy our well-
authentication requirement. Indeed,
the reader can end a
session with a tag whereas the tag has not really participated
to this session. In other words, the reader passes a test (which
does not correspond to a safe conditional) with success, and
therefore performs a τthen action whereas it has not interact
honestly with a tag.

Actually, this trace can be turned into an attack against
the unlinkability property. Indeed, by continuing the previous
trace, the reader can send a new request to the tag generating
a fresh nonce r′′
to this new request choosing his nonce r′′
r′′
the reader talking to the same tag, cannot be mimicked in the
single session scenario, and corresponds to an attack trace.

1 . The attacker I(Tag) can again answer
1 ⊕ r1 ⊕ r2. This execution, involving two sessions of

2 accordingly, i.e.

2 = r′′

More importantly, this scenario can be seen as a traceability
attack on the original version of the protocol (the stateful
version) leading to a practical attack. The attacker will ﬁrst
start a session with the targeted tag by sending it a nonce r0
and storing its answer. Then, later on, he will interact with the
reader as described in the second part of the attack scenario.
Two situations may occur: either the interaction is successful
meaning that the targeted tag has not been used since its last
interaction with the attacker; or the interaction fails meaning
that the key has been updated on the reader’s side, and thus
the targeted tag has performed a session with the reader since
its last interaction with the attacker. This attack shows that the
reader may be the source of leaks exploited by the attacker
to trace a tag. This is why we advocate for the strong notion
of unlinkability we used, taking into account the reader and
considering it as important as the tag.

We may note that the same protocol was declared untrace-
able in [2] due to the fact that they have in mind a weaker
notion of unlinkability.

To avoid the algebraic attack due to the properties of the
xor operator, we may replace this operator using the pairing
operator. The resulting protocol
that
falls into our class, and for which frame opacity and well-
authentication can be established using UKano, again in less
than 1 second. Therefore, Theorem 1 allows us to conclude
that it preserves unlinkability.

is a 2-party protocol

D. BAC protocol and some others

An e-passport is a paper passport with an RFID chip that
stores the critical information printed on the passport. The
International Civil Aviation Organization (ICAO) standard [36]

)
)

The BAC protocol using Alice & Bob notation between Tag
(i.e. passport) and Reader is depicted above. A process

Tag → Reader ∶ nT
({nR, nT , kR}kE
Reader → Tag ∶ {nR, nT , kR}kE , mackM
({nT , nR, kT}kE
Tag → Reader ∶ {nT , nR, kT}kE , mackM
modeling Tag more precisely is deﬁned below, where m =
enc(⟨nT ,⟨π1(dec(xE, kE)), kT⟩⟩, kE).
T(kE, kM) = νnT .νkT .out(cT , nT).in(cT , x).
let xE = π1(x), xM = π2(x), ztest = eq(xM , mac(xE, kM)) in
= eq(nT , π1(π2(dec(xE, kE)))) in
out(cT ,⟨m, mac(m, kM)⟩)
else out(errorNonce)

let z′

test

else out(errorMac)

We consider the signature given in Example 1 augmented
with a function symbol mac of arity 2. This is a public
constructor whose purpose is to model message authentication
code, taking as arguments the message to authenticate and the
mac key. There is no rewriting rule and no equation regarding
this symbol. We also assume public constants to model error
messages. The UK version of the protocol does not distinguish
the two cases of failure, i.e. errorMac and errorNonce are the
same constant, whereas the French version does.

Fig. 6. Description of the BAC protocol

speciﬁes several protocols through which this information
can be accessed. Before executing the Basic Access Control
(BAC) protocol, the reader optically scans a weak secret from
which it derives two keys kE and kM that are then shared
between the passport and the reader. Then, the BAC protocol
establishes a key seed from which two sessions keys are
derived. The session keys are then used to prevent skimming
and eavesdropping on the subsequent communication with the
e-passport.

In [8], two variants of the BAC protocol are described and
analyzed w.r.t. the unlinkability property as formally stated
in this paper. We refer below to these two variants as the
French version and the UK version. The UK version is claimed
unlinkable (with no formal proof) whereas an attack is reported
on the French version. To explain the difference between the
two versions, we give a description of the passport’s role in
Figure 6. The relevant point is the fact that, in case of failure,
the French version sends a different error message indicating
whether the failure occurs due to a problem when checking the
mac, or when checking the nonce. This allows the attacker to
exploit this conditional to learn if the mac key of a Tag is the

one used in a given message ⟨m, mac(m, k)⟩. Using this, he

can very easily trace a tag T by ﬁrst eavesdropping an honest
interaction between the tag T and a reader.

The UK version of the BAC protocol is a 2-party protocol

576576

according to our deﬁnition1. Note that since the two error
messages are actually identical, we can merge the two let
instructions, and therefore satisfy our deﬁnition of being
a responder role. Then, we established frame opacity and
well-authentication using UKano. It took less than 1 minute.
Therefore, Theorem 1 allows us to conclude that unlinkability
is indeed satisﬁed.

Regarding the French version of this protocol, it happens
that
the passport’s role is neither an initiator role, nor a
responder role according to our formal deﬁnition. Indeed, our
deﬁnition of a role, and therefore of a 2-party protocol does not
allow to model two sequences of tests that will output different
error messages in case of failure. As illustrated by the attack
on the French version of the BAC protocol, imposing this
syntactic condition is actually a good design principle w.r.t.
unlinkability.

Once the BAC protocol has been successfully executed, the
reader gains access to the information stored in the RFID tag
through the Passive and Active Authentication protocols (PA
and AA). They are respectively used to prove authenticity of
the stored information and prevent cloning attacks, and may be
executed in any order. A formal description of these protocols
is available in [37]. These two protocols also fall into our
class and our conditions can be checked automatically both
for unlinkability and anonymity properties. We can also use
our technique to analyze directly the three protocols together
(i.e. the UK version of the BAC together with the PA and
AA protocols in any order). We thus prove unlinkability and
anonymity w.r.t. all private data stored in the RFID chip (name,
picture, etc.). UKano concludes within 7 minutes to establish
both well-authentication and frame opacity.
E. PACE protocol

The Password Authenticated Connection Establishment pro-
tocol [38] (PACE) has been proposed by the German Federal
Ofﬁce for Information Security (BSI) to replace the BAC
protocol. It has been studied in the literature [29], [39], [40] but
to the best of our knowledge, no formal proofs about privacy
have been given. Similarly to BAC, the purpose of PACE is
to establish a secure channel based on an optically-scanned
key k. The protocol comprises four main steps (see Figure 7):
● The tag randomly chooses a random number sT , encrypts
it with the shared key k and sends the encrypted random
number to the reader (message 1).

● Both the tag and the reader perform a Difﬁe-Hellman
exchange (messages 2 & 3), and derive G from sT and
gnRnT .

● The tag and the reader perform a Difﬁe-Hellman ex-
change based on the parameter G computed at the previ-
ous step (messages 5 & 6).

● The tag and the reader derive a session key k′ which are
conﬁrmed by exchanging and checking the authentication
tokens (messages 8 & 9).

1.

3.
4.

gnR
gnT

Tag → Reader ∶ {sT}k
2. Reader → Tag ∶
Tag → Reader ∶
Both parties compute G= gen(sT , gnRnT).
5. Reader → Tag ∶
Tag → Reader ∶ Gn′
7. Both parties compute k′ = Gn′
8. Reader → Tag ∶
mac(Gn′
Tag → Reader ∶ mac(Gn′

T , k′)
R , k′)

Gn′

Rn′
T

6.

9.

R

T

Fig. 7. PACE in Alice & Bob notation

A description in Alice & Bob notation is given in Figure 7.
Moreover, at step 6, the reader will not accept as input a
message which is equal to the previous message that it has
just sent.

To formalize such a protocol, we consider the following

signature:

Σc ={enc, dec, dh, mac, gen, g, ok} and Σd ={neq}.

Except g and ok which are public constants, all these function
symbols are public constructor symbols of arity 2. The de-
structor neq has already be deﬁned in Section II. The symbol
dh is used to model modular exponentiation whereas mac will
be used to model message authentication code. We consider
the equational theory E deﬁned by the following equations:

dec(enc(x, y), y) = x
dh(dh(x, y), z) = dh(dh(x, z), y)

This protocol falls into our generic class of 2-party protocols.
We take

ΠPACE =(k,{sT , nT , n′

T},{nR, n′

R},IPACE,RPACE)

a responder role (we do not detail the continuation R′ and
we omit trivial conditionals). The process modeling the role

where the RPACE process (reader), described in Figure 8, is
IPACE can be obtained in a similar way.
RPACE ∶= in(cR, y1).

out(cR, dh(g, nR)).in(cR, y2).
out(cR, dh(G, n′
R)).in(cR, y3).
let ytest = neq(y3, dh(G, n′
R)) in
out(cR, mac(y3, k′));
in(cR, y4).
let y5 = eq(y4, mac(dh(G, n′

R), k′)) in R′.
where G= gen(dec(y1, k), dh(y2, nR)) and k′ = dh(y3, n′
R).

Fig. 8. Process RPACE

Unfortunately, ProVerif cannot handle the equation above
on the dh operator (due to some termination issues). Instead
of that single equation, we consider the following equational
theory that is more suitable for ProVerif:

dh(dh(g, y), z) = dh(dh(g, z), y)

dh(dh(gen(x1, x2), y), z) = dh(dh(gen(x1, x2), z), y)

1We do not model the getChallenge constant message that is used to initiate
the protocol but it is clear this message does not play any role regarding the
security of the protocol.

This is sufﬁcient for the protocol to work properly but it
obviously lacks equations that the attacker may exploit.

577577

First, we would like to highlight an imprecision in the
ofﬁcial speciﬁcation [38] that may lead to practical attacks
on unlinkability. As the speciﬁcation seems to not forbid
it, we could have assumed that the decryption operation in

way that it may fail when the key k does not match with
the key of the ciphertext y1. In that case, an attacker could

G = gen(dec(y1, k), dh(y2, nR)) is implemented in such a
eavesdrop a ﬁrst message c0 = enc(s0
T , k0) of a certain tag T 0
scan a tag T but replace its challenge enc(sT , k) by c0 and
the decryption did not fail and thus k = k0: the tag T is
dec(⋅,⋅) as a destructor (that may fail) and the computation of

actually T 0. We discovered this attack using our method since
in our ﬁrst attempt to modelize the protocol, we modelized

wait for an answer of the reader. If it answers, he learns that

and then, in a future session, it would let the reader optically

G as an evaluation:

let G= gen(dec(y1, k), dh(y2, nR)) in[...]

This test has to satisfy our requirement in order to declare
the protocol well-authenticating. But this conditional com-
puting G is not safe and does not satisfy the requirements
of Deﬁnition 14 (the attack scenario described is a counter
example). The same attack scenario shows that the protocol
does not ensure unlinkability (this scenario cannot be observed

when interacting with SΠ). Similarly to the attack on LAK, we

highlight here the importance to take the reader into account
and give it as much importance as the tag in the deﬁnition of
unlinkability. Indeed, it is actually a leakage from the reader
that allows an attacker to trace a speciﬁc tag.

Second, we report on an attack2 that that we discovered
using our method on some modelizations of PACE found in
the literature [29], [39], [40]. Indeed, in all those papers, the
ﬁrst conditional of the reader

let ytest = neq(y3, dh(G, n′

R)) in

resulting protocol

is omitted. Then the
is not well-
authenticating. To see this, we simply have to consider a
scenario where the attacker will send to the reader the message
it has outputted at the previous step. Such an execution will
allow the reader to execute its role until the end, and therefore
execute τthen, but the resulting trace is not an honest one.
Again,
this scenario can be turned into an attack against
unlinkability as explained next. As before, an attacker could

eavesdrop a ﬁrst message c0 = enc(s0
T , k0) of a certain tag T 0.
a tag T but replace its challenge enc(sT , k) by c0. Whatever k

Then, in a future session, it would let the reader optically scans

is equal or k0, the reader answers gnR. The attacker then
plays the two rounds of Difﬁe-Hellman by reusing messages
from the reader (he actually performs a reﬂection attack).
R and

More precisely, he replies with gnT = gnR, Gn′
mac(Gn′

T , k′). The crucial point is that the

R , k′) = mac(Gn′

T = Gn′

attacker did not prove he knows k (he supposed to do so to
generate G at step 4) thanks to the reﬂection attack that is not
detected. Now, the attacker waits for the reader’s answer. If it

2For that different attack, we obviously consider that decryption is a

constructor, and thus cannot fail.

578578

is positive (the process R′ is executed), he learns that k = k0:

the tag T is actually the same as T 0.

Third, we turn to PACE as properly understood from the
ofﬁcial speciﬁcation: when the latter test is present and the
decryption may not fail. In that case, we report on a new attack.
UKano found that the last test of the reader violates well-
authentication. This is the case for the following scenario: the

message enc(sT , k) from a tag T(k, nT) is fed to two readers
R) of same identity name. Then, the attacker
R(k, n1

R), R(k, n2

just forwards messages from one reader to the other. They can
thus complete the two rounds of Difﬁe-Hellman (note that the
test avoiding reﬂection attacks holds). More importantly, the
mac-key veriﬁcation phase (messages 8 and 9 from Figure 7)
goes well and the attacker observes that the last conditional
of the two readers holds. This violates well-authentication
but also unlinkability because the latter scenario cannot be

observed at all in SΠ: if the attacker makes two readers talk
to each other in SΠ they cannot complete a session because

they must have different identity names. In practice, this ﬂaw
seems hard to exploit but it could be a real privacy concern: if a
tag initiates multiple readers, an attacker may learn which ones
it had initiated by forwarding messages from one to another.
It does not seem to be realistic in the e-passport scenario, but
could be harmful in other contexts.

Finally, we propose a simple ﬁx to the above attack
by adding tags avoiding confusions between reader’s mes-
sages and tag’s messages. It sufﬁces to replace messages 8

and 9 from Figure 7 by respectively mac(⟨cr, Gn′
mac(⟨ct, Gn′

T⟩, k′) and
R⟩, k′) where cr, ct are public constants, and

adding the corresponding checks. Frame opacity and well-
authentication can be automatically established using UKano,
in around 20 minutes. Therefore, PACE with tags preserves
unlinkability in the model considered here.

VIII. CONCLUSION

We

two

have

identiﬁed

conditions,

tool ProVerif,

namely well-
authentication and frame opacity, which imply anonymity and
unlinkability for a wide class of protocols. Additionally, we
these two conditions can be checked
have shown that
automatically using the
and we have
mechanized the veriﬁcation of our conditions in a tool
called UKano. This yields a new veriﬁcation technique to
check anonymity and unlinkability for an unbounded number
of sessions. It has proved quite effective on various case
studies. In particular, it has brought ﬁrst-time unlinkability
proofs for the BAC protocol (e-passport). Our case studies
also illustrated that our methodology is useful to discover
attacks against unlinkability and anonymity as illustrated by
the new attacks we found on PACE and LAK.

In the future, we plan to develop a mature implementation
of our tool in order to make it widely accessible for the design
and study of privacy-preserving 2-party protocols. We could
also try to translate our conditions into more comprehensive
guidelines helping the design of new privacy-enhancing pro-
tocols.

We also identify a number of research problems aimed at in-
creasing the scope of our technique. Currently, our conditions
are checked using ProVerif which, despite its great ﬂexibility,
supports only a limited kind of equational theory. In particular,
full Difﬁe-Hellman theory or associative-commutative theories
needed for xor (widely used in RFID protocols) are not sup-
ported. It seems likely that frame opacity can be checked using
ad-hoc methods rather than ProVerif, which could support
wider classes of theories. Concerning well-authentication, we
could consider various extensions of ProVerif with partial
support for xor [41], or other tools such as Tamarin and

Maude−NPA. We would also like to investigate the extension

of our main theorem to the case of protocols with state. This is
certainly technically challenging, but would make it possible to
model more protocols, or at least model them more faithfully.
Finally, we would like to investigate whether our frame opacity
condition could be relaxed to allow one to deal more precisely
with primitives that are neither transparent, nor totally opaque
in general (e.g. zero-knowledge proofs, signatures).

REFERENCES

[1] “Iso 15408-2: Common criteria for information technology security

evaluation - part 2: Security functional components,” July 2009.

[2] T. Van Deursen and S. Radomirovic, “Attacks on RFID protocols.” IACR

Cryptology ePrint Archive, vol. 2008, p. 310, 2008.

[3] A. Armando, R. Carbone, L. Compagna, J. Cu´ellar, and M. L. Tobarra,
“Formal analysis of SAML 2.0 web browser single sign-on: breaking
the SAML-based single sign-on for Google apps,” in Proc. 6th ACM
Workshop on Formal Methods in Security Engineering (FMSE’08).
ACM, 2008, pp. 1–10.

[4] V. Cortier and B. Smyth, “Attacking and ﬁxing Helios: An analysis of
ballot secrecy,” Journal of Computer Security, vol. 21, no. 1, pp. 89–148,
2013.

[5] A. Armando et al., “The AVANTSSAR platform for the automated
validation of trust and security of service-oriented architectures,” in
Proc. 18th International Conference on Tools and Algorithms for the
Construction and Analysis of Systems (TACAS’12), vol. 7214. Springer,
2012, pp. 267–282.

[6] S. Meier, B. Schmidt, C. Cremers, and D. Basin, “The Tamarin Prover
for the Symbolic Analysis of Security Protocols,” in Proc. 25th Interna-
tional Conference on Computer Aided Veriﬁcation (CAV’13), ser. LNCS,
vol. 8044. Springer, 2013, pp. 696–701.

[7] B. Blanchet, “An Efﬁcient Cryptographic Protocol Veriﬁer Based on
IEEE Comp. Soc. Press,

Prolog Rules,” in Proceedings of CSFW’01.
2001, pp. 82–96.

[8] M. Arapinis, T. Chothia, E. Ritter, and M. Ryan, “Analysing unlinka-
bility and anonymity using the applied pi calculus,” in Proceedings of
CSF’10.

IEEE Comp. Soc. Press, 2010.

[9] M. Bruso, K. Chatzikokolakis, and J. den Hartog, “Formal veriﬁcation

of privacy for RFID systems,” in Proceedings of CSF’10, 2010.

[10] S. Delaune, S. Kremer, and M. D. Ryan, “Verifying privacy-type
properties of electronic voting protocols,” Journal of Computer Security,
no. 4, 2008.

[11] M. Backes, C. Hritcu, and M. Maffei, “Automated veriﬁcation of remote
electronic voting protocols in the applied pi-calculus,” in Proceedings of
the 21st IEEE Computer Security Foundations Symposium, CSF 2008,
Pittsburgh, Pennsylvania, 23-25 June 2008.
IEEE Computer Society,
2008, pp. 195–209.

[12] N. Dong, H. Jonker, and J. Pang, “Formal analysis of privacy in an
Springer,

ehealth protocol,” in Computer Security–ESORICS 2012.
2012, pp. 325–342.

[13] M. Arapinis, L. Mancini, E. Ritter, M. Ryan, N. Golde, K. Redon,
and R. Borgaonkar, “New privacy issues in mobile telephony: ﬁx and
veriﬁcation,” in Proceedings of the 2012 ACM conference on Computer
and communications security. ACM, 2012, pp. 205–216.

[14] M. Arapinis, L. I. Mancini, E. Ritter, and M. Ryan, “Privacy through

pseudonymity in mobile telephony systems.” in NDSS, 2014.

579579

[15] R. Chr´etien, V. Cortier, and S. Delaune, “From security protocols
to pushdown automata,” ACM Transactions on Computational Logic,
vol. 17, no. 1:3, Sep. 2015.

[16] M. Baudet, “Deciding security of protocols against off-line guessing
attacks,” in Proc. 12th Conference on Computer and Communications
Security. ACM, 2005.

[17] V. Cheval, H. Comon-Lundh, and S. Delaune, “Trace equivalence deci-
sion: Negative tests and non-determinism,” in Proceedings of CCS’11.
ACM Press, 2011.

[18] V. Cheval and B. Blanchet, “Proving more observational equivalences
with proverif,” in Principles of Security and Trust. Springer, 2013, pp.
226–246.

[19] D. Basin, J. Dreier, and R. Sasse, “Automated symbolic proofs of
observational equivalence,” in Proceedings of the 22nd ACM SIGSAC
Conference on Computer and Communications Security. ACM, 2015,
pp. 1144–1155.

[20] S. Santiago, S. Escobar, C. Meadows, and J. Meseguer, “A formal
indistinguishability and its veriﬁcation using
Springer, 2014, pp.

deﬁnition of protocol
maude-npa,” in Security and Trust Management.
162–177.

[21] M. Abadi and C. Fournet, “Mobile values, new names, and secure

communication,” in Proceedings of POPL’01. ACM Press, 2001.

[22] B. Blanchet, M. Abadi, and C. Fournet, “Automated veriﬁcation of
selected equivalences for security protocols,” Journal of Logic and
Algebraic Programming, 2008.

[23] V. Cortier, S. Delaune, and P. Lafourcade, “A survey of algebraic prop-
erties used in cryptographic protocols,” Journal of Computer Security,
vol. 14, no. 1, pp. 1–43, 2006.

[24] M. Feldhofer, S. Dominikus, and J. Wolkerstorfer, “Strong authentication
for RFID systems using the AES algorithm,” in Cryptographic Hardware
and Embedded Systems-CHES 2004. Springer, 2004, pp. 357–370.

[25] S. Delaune, S. Kremer, and M. D. Ryan, “Verifying privacy-type prop-
erties of electronic voting protocols: A taster,” in Towards Trustworthy
Elections – New Directions in Electronic Voting. Springer, 2010, vol.
6000.

[26] M. Brus´o, K. Chatzikokolakis, S. Etalle, and J. Den Hartog, “Linking
unlinkability,” in Trustworthy Global Computing. Springer, 2012, pp.
129–144.

[27] M. Brus´o, “Dissecting unlinkability,” Ph.D. dissertation, Technische

Universiteit Eindhoven, 2014.

[32] B. Blanchet, M. Abadi, and C. Fournet, “Automated veriﬁcation of
selected equivalences for security protocols,” in Logic in Computer
Science, 2005. LICS 2005. Proceedings. 20th Annual IEEE Symposium
on.

IEEE, 2005, pp. 331–340.

[33] M. Abadi and B. Blanchet, “Computer-assisted veriﬁcation of a protocol
for certiﬁed email,” in Static Analysis. Springer, 2003, pp. 316–335.
[34] A. Juels and S. A. Weis, “Deﬁning strong privacy for RFID,” ACM
Transactions on Information and System Security (TISSEC), vol. 13,
no. 1, p. 7, 2009.

[35] S. Lee, T. Asano, and K. Kim, “RFID mutual authentication scheme
based on synchronized secret information,” in Symposium on cryptog-
raphy and information security, 2006.

[36] “PKI for machine readable travel documents offering ICC read-only

access,” International Civil Aviation Organization, Tech. Rep., 2004.

[37] M. Arapinis, V. Cheval, and S. Delaune, “Verifying privacy-type prop-
erties in a modular way,” in Proceedings of the 25th IEEE Computer
Security Foundations Symposium (CSF’12). Cambridge Massachusetts,
USA: IEEE Computer Society Press, Jun. 2012, pp. 95–109.

[38] “Technical

advisory group on machine

travel docu-
ments (tag/mrtd).” [Online]. Available: http://www.icao.int/Meetings/
TAG-MRTD/TagMrtd22/TAG-MRTD-22 WP05.pdf

readable

[28] M. Backes, M. Maffei, and D. Unruh, “Zero-knowledge in the applied pi-
calculus and automated veriﬁcation of the direct anonymous attestation
protocol,” in Security and Privacy, 2008. SP 2008. IEEE Symposium on.
IEEE, 2008, pp. 202–215.

[29] J. Bender, M. Fischlin, and D. K¨ugler, “Security analysis of the pace
key-agreement protocol,” in Information Security. Springer, 2009, pp.
33–48.

[30] “Proverif: Cryptographic protocol veriﬁer

in the formal model.”
[Online]. Available: http://prosecco.gforge.inria.fr/personal/bblanche/
proverif/

[31] “UKano tool and case studies.” [Online]. Available: http://projects.lsv.

ens-cachan.fr/ukano/

[39] J. Bender,

¨O. Dagdelen, M. Fischlin, and D. K¨ugler, “The pace aa
protocol for machine readable travel documents, and its security,” in
Financial Cryptography and Data Security. Springer, 2012, pp. 344–
358.

[40] L. Cheikhrouhou, W. Stephan, ¨O. Dagdelen, M. Fischlin, and M. Ull-
mann, “Merging the cryptographic security analysis and the algebraic-
logic security proof of pace.” in Sicherheit, 2012, pp. 83–94.

[41] R. K¨usters and T. Truderung, “Reducing protocol analysis with XOR
to the xor-free case in the horn theory based approach,” J. Autom.
Reasoning, vol. 46, no. 3-4, pp. 325–352, 2011.

APPENDIX A

PROOFS OF SECTION IV

is the least relation such that:

We detail below how to obtain Proposition 1.

maximum number of nested transparent function symbols in u.

Deﬁnition 17: Let u ∈ T (Σc,N). We deﬁne h0(u) as the
Then, ht(u) is the minimum of all h0(v) for u=E v.
Proposition 5: For any u =E f(u1, . . . , un) with f ∈ Σt, we
have ht(u)> ht(ui) for all i.
Proof. We show that, for all v =E u, h0(v)> ht(ui). Since
v =E f(u1, . . . , un), and since the equational theory cannot
involve f by deﬁnition of Σt, we have v = f(v1, . . . , vn) with
vi =E ui. We conclude: ht(ui)= ht(vi)≤ h0(vi)< h0(v). ◻
Deﬁnition 18: The relation Rideal∶T (Σc,N)×T (Σt,{◻})
● u Rideal f(t1, . . . , tn) if there exist f ∈ Σt and messages
ui for 1≤ i≤ n= ar(f), such that u=E f(u1, . . . , un) and
ui Rideal ti for all 1≤ i≤ n;
● uRideal ◻ otherwise.
uRideal v. Furthermore, whenever u =E u′, u Rideal v and
u′ Rideal v′, then we have that v = v′.
Proof. We proceed by induction over ht(u). If u cannot
at toplevel, then the result is obvious with v = ◻. Otherwise,
assume u=E f(u1, . . . , un). By induction hypothesis we obtain
ui Rideal vi for all i, and thus uRideal f(v1, . . . , vn). Consider
now u′, v and v′ such that u=E u′, uRideal v and u′ Rideal v′.
Observe that u′ =E f′(u′
m) is only possible if f = f′,
n = m and ui =E u′
i for all i. Thus v = f(v1, . . . , vn) and
v′ = f(v′
◻
by deﬁning[u]ideal to be the unique v such that uRideal v. The
last point is an easy consequence of the deﬁnition of [⋅]nonce.

be equated to a message with a transparent function symbol

Proposition 6: For all message u there exists a v such that

The above results immediately allow to show Proposition 1,

n). Moreover, vi = v′

on ui, which concludes the proof.

i by induction hypothesis

1, . . . , u′

1, . . . , v′

APPENDIX B

PROOFS OF SECTION V

Proposition 3: Let Π be a protocol ensuring frame opacity.

Let P be a ground conﬁguration of Π, ta an annotated trace,
and ρ an arbitrary renaming of agents. If (P;∅) ta(cid:18)→(P1; φ1)
and (Pρ;∅) taρ(cid:18)→(P2; φ2), then [φ1]ideal =[φ2]ideal.

Proof. Intuitively, this is a consequence of the second point
(ii) of frame opacity for the execution where ta and taρ are

580580

we consider a bijective renaming of names (instead of agents)

still a ground conﬁguration. We also consider a bijection θ over

executed in sequence, because any handle w in dom(φ1) =
dom(φ2) must carry the same label in φ1 and φ2. Formally,
σ such that no agent is both inP andPρσ, so thatP∪(Pρσ) is
W such that dom(φ1)∩ dom(φ2θ) = ∅ and θ is the identity
on dom(φ1). Let ρ′ be ρσ and ta′ = taρ′θ. We can deduce
from the execution of taρ by Pρ that (Pρ′;∅) ta′(cid:18)→ (P ′
2)
with P ′
2 = θ−1φ2σ. By concatenating the above
′);∅) ta.ta′(cid:18)(cid:18)(cid:18)→(P1∪P ′
Further, we have (Mid
Π;∅) ta0(cid:18)→ (P ∪(Pρ′);∅) for some ta0
because P∪(Pρ′) is a ground conﬁguration. Applying frame
2) that carry the same label (cid:10) ∈ L, one
w, w′ ∈ dom(φ1 ∪ φ′
has [w(φ1 ∪ φ′
2)]ideal. In particular, for
all w ∈ dom(φ1) carrying a label (cid:10) ∈ L, since wθ ∈ dom(φ′
2)

2 =P2σ and φ′
(P ∪(Pρ

opacity on the execution of ta0.ta.ta′, we obtain that for all

2)]ideal = [w′(φ1 ∪ φ′

executions, we obtain

2; φ1∪ φ

2).

2; φ′

′

must carry the same label (cid:10),

w[φ1]ideal =(wθ)[φ

2]ideal = w[φ2σ]ideal.

′

Finally, since σ is a bijection on names, we have [φ2]ideal =
[φ2σ]ideal and thus w[φ1]ideal = w[φ2]ideal as expected.
◻
ration P of the protocol such that
(P;∅) ta(cid:18)→ K,

Proposition 4: For any protocol and any ground conﬁgu-

there exists an agent renaming ρ satisfying the hypothesis of

Lemma 1 and such that Pρ is single-session.
Proof. We ﬁrst deﬁne Co(k) as the set of all (n1, n2)
such that I(k, n1) and R(k, n2) are connected in (ta, φ(K)).
Next, we assume for each (k, n1, n2) a vector of names
kc(k, n1, n2) of the length of identity parameters of Π. These
any name already occurring in the annotations of P. This
combination of k, n1, n2 taken from the annotations of P.
We also assume name vectors k1(k, n1) which are again
disjoint and not overlapping with annotations of P and any
kc(k′, n′
2), and similarly for k2(k, n2) which should also

name vectors are assumed to be all disjoint and not containing

gives us a mean to pick fresh identity parameters for each

not overlap with k1 vectors. These last two collections of
identity parameters will be used to give fresh identities to
initiator and responder agents, independently. We then deﬁne
ρ as follows:

1, n′

I(k, n1) ↦ I(kc(k, n1, n2), n1)
R(k, n2) ↦ R(kc(k, n1, n2), n2)

↦ I(k1(k, n1), n1)
↦ R(k2(k, n2), n2)

if (n1, n2)∈Co(k)
if (n1, n2)∈Co(k)

otherwise

otherwise

By construction, agents that were connected in ta are renamed

into agents sharing same identity names kc(k, n1, n2). Other
◻

agents have distinct, fresh identities. Finally, we have not used
id0, and the image of ρ obviously has at most one session per
identity and role: our renaming is single-session.

two identities id1 and id2, and the attacker is allowed
to interact again with x (an arbitrary number of times).
It may also interact with tags and readers of identities
different from id1 and id2.

The attacker wins the game if he can infer whether x is id1 or
id2, i.e. if he is able to distinguish between these two scenarios.
This is typically the kind of scenario that can be checked
relying on the diff-equivalence notion implemented in several
automatic tool (e.g. ProVerif, Tamarin). However, here we

failed to prove it using ProVerif due to the ⊕ operator that

ProVerif can not handle. The attack scenario described in the
previous paragraph can be done in the guessing phase with tag
id1, and can be mimicked on the other side using two sessions
of the tag with identity id2. Actually, we believe that these two
scenarios are indistinguishable, i.e. the resulting processes are
in trace equivalence.

This example shows that game-based variants of unlink-
ability that are amenable to automation relying on the diff-
equivalence notion is rather weak.

APPENDIX C

EXAMPLE

In this section, we give a protocol that does not preserve
unlinkability according to the deﬁnition we used in this paper
(see Deﬁnition 7). However,
this protocol
would be considered secure w.r.t. a game-based deﬁnition
of unlinkability suitable for direct veriﬁcation using diff-
equivalence.

it appears that

Description of the protocol: The protocol can be pre-

sented in Alice & Bob notation as follows:

1. T → R ∶ {nT}k
2. R → T ∶ {nR}k
3. T → R ∶ {nR⊕ nT}k

The protocol is between a tag T and a reader R that share a
symmetric key k. Moreover, we assume that T aborts in case
the nonce nR he receives is equal to the nonce nT he sent
previously (in the same session). We consider the term algebra
introduced in Example 1, and the equational theory introduced
in Example 2 with in addition the following equation:

dec(enc(x, y), y) = x

Attack against unlinkability (Deﬁnition 7): To show that
the property formally stated in Deﬁnition 7 does not hold,
consider the following scenario.

1. T → R ∶ {nT}k
1′. T ′ → R ∶ {n′
T}k
2. I(R)→ T ∶ {n′
T}k
2′. I(R)→ T ′ ∶ {nT}k
3. T → R ∶ {n′
T ⊕ nT}k
3′. T ′ → R ∶ {nT ⊕ n′
T}k

A same tag starts two sessions and therefore generates two
nonces nT and n′
T . The attacker answers to these requests
by sending back the two encrypted messages to the tag who
will accept both of them, and sends on the network two
messages that are actually equal (the exclusive or operator
is commutative). Therefore the attacker observes a test (the
equality between the two last messages), and this equality
has no counterpart in the single session scenario. In practice,
this can be very harmful when e.g. tags are distributed among
distinct groups (e.g. for access control policies) sharing each
the same key k. By interacting with two tags, the attacker
would then be able to know if they belong to the same group.
Game-based deﬁnition: We will not give any formal
deﬁnition but instead brieﬂy give its general idea. In such a
deﬁnition, the two scenarios under study will be made of two
phases:

1) Learning phase: During this phase, the attacker can
trigger an arbitrary number of sessions of the two roles
(namely tag and reader) with the identity of his choice.
This allows him to gain some knowledge.

2) Guessing phase: This phase starts once the previous one
is ﬁnished. The challenger chooses an identity x among

581581

