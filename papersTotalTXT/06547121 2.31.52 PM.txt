2013 IEEE Symposium on Security and Privacy

Caveat Coercitor: coercion-evidence in electronic voting

Gurchetan S. Grewal and Mark D. Ryan

School of Computer Science,
University of Birmingham, UK

research@gurchetan.com,
m.d.ryan@cs.bham.ac.uk

Sergiu Bursuc
Centre for Secure

Peter Y. A. Ryan

Facult´e des Sciences, de la T´echnologie

Information Technologies,

Queen’s University of Belfast, UK

s.bursuc@qub.ac.uk

et de la Communication,
Universit´e du Luxembourg

peter.ryan@uni.lu

Abstract—The balance between coercion-resistance, election
veriﬁability and usability remains unresolved in remote elec-
tronic voting despite signiﬁcant research over the last few years.
We propose a change of perspective, replacing the requirement
of coercion-resistance with a new requirement of coercion-
evidence: there should be public evidence of the amount of
coercion that has taken place during a particular execution of
the voting system.

We provide a formal deﬁnition of coercion-evidence that
has two parts. Firstly, there should be a coercion-evidence test
that can be performed against the bulletin board to accurately
determine the degree of coercion that has taken place in any
given run. Secondly, we require coercer independence, that is
the ability of the voter to follow the protocol without being
detected by the coercer.

To show how coercion-evidence can be achieved, we propose
a new remote voting scheme, Caveat Coercitor, and we prove
that it satisﬁes coercion-evidence. Moreover, Caveat Coercitor
makes weaker trust assumptions than other remote voting
systems, such as JCJ/Civitas and Helios, and has better
usability properties.

Keywords-Coercion resistance; coercion evidence; electronic
voting; veriﬁable elections; security protocols; security models;
usability

I. INTRODUCTION

A. Background and motivation

Current research in electronic voting focuses on trying
to design usable voting systems that satisfy the properties
of coercion-resistance and veriﬁability. Coercion-resistance
is a fundamental, and strong, property of electronic voting
systems. It states that a voter should be able to cast his
vote as intended, even in presence of a coercer that may
try to force him to cast a different vote. On the other hand,
veriﬁability allows to verify that the outcome of the election
reﬂects correctly the voters choice. A voter can verify that
the ballot has been correctly recorded on the bulletin board,
and anyone can verify that the recorded ballots from eligible
voters are tallied correctly.

Especially in remote voting, coercion-resistance and veri-
ﬁability are extremely hard to achieve together and this leads
to schemes of questionable usability or to trust assumptions
that are difﬁcult to meet in practice. Perhaps the system that
comes closest to satisfying both those properties in their

1081-6011/13 $26.00 © 2013 IEEE
DOI 10.1109/SP.2013.32

367

strongest form is JCJ/Civitas [16], [12]. However, it does so
at the cost of usability:

• the voters are required to run a multi-party protocol
with registrars in order to construct their credentials.
• to avoid coercion, the voters must be capable of creating

and passing off fake credentials and fake proofs.

• a trusted registrar and an untappable channel for that

registrar are necessary.

Another prominent system is Helios [2], [3], which is very
usable but is for low-coercion elections, and has only very
weak methods to resist coercion. For example, in some vari-
ants of Helios (and also in the Estonian system), only the last
vote counts. This is supposed to help a voter resist coercion
by re-voting. However, if the voting credentials have been
leaked, an attacker can always override a legitimate vote.

Moreover, in any E-voting system, there may be cases
where the voter is subject to silent coercion, which means
being coerced without noticing. This can happen when the
voting credentials are leaked for various reasons: dishonest
registrars, insecure communication channels, malware on
the voting machine. In that case, the voter can be subject
to an impersonation attack and the intended vote may be
replaced by a vote chosen by the attacker. This is a more
general form of coercion which is not addressed even in
a strong system like JCJ/Civitas, because there is no way
for the voter to ﬁnd out that the voting credentials have
been compromised. Variations of JCJ/Civitas [11], [4] aim
to improve the usability of voter strategies for achieving
coercion-resistance, but they do not consider the problem of
silent coercion explicitly. In Helios as well, if the credentials
of a voter have been leaked, they can be used to cast a vote
on voter’s behalf.
B. Coercion-evidence

This paper takes as its starting point

the observation
that it has been impossible to achieve all the requirements
simultaneously. Since result veriﬁability and usability may
be considered “non-negotiable”, we consider a setting in
which coercion-resistance may be relaxed. Nevertheless, to
defend against coercion (both explicit coercion and silent
coercion), we propose the property of coercion-evidence.
This means that unforgeable evidence about the degree of

coercion that took place is included in the election output.
Authorities, observers and voters can examine this evidence
and use it to determine whether the election result carries a
mandate for the winning candidate. Thus, election authorities
can decide to consider the election as valid or not, leading
to disincentivisation of coercion.

In some situations, dishonest voters could try to disrupt
the election by faking being coerced. Since an individual
voter can only fake his or her own coercion, this strategy
would be effective only if the winning margin is low.
Although this doesn’t prevent coercion evidence, it could
lower the attractiveness of our system. We will discuss
practical mitigations as well as research perspectives to
address this challenge.

C. Caveat Coercitor

We propose Caveat Coercitor, an electronic voting scheme
intended to support remote (e.g. internet) voting and to be
practically deployable. By shifting away from the conven-
tional wisdom of coercion-resistance in favour of coercion-
evidence, it tries to ﬁnd a “sweet spot” between security
and usability. Coercion-evidence also means that the system
disincentivises coercion. In Caveat Coercitor, the most the
coercer can achieve is to cancel a voter’s vote. This is rather
weaker than the usual notion of forced abstention, because
the number of such cancelled votes is revealed as part of the
election output. Since the election result will be considered
valid only if those cancelled votes would not have affected
it, this means that the coercer cannot signiﬁcantly affect the
outcome of the election.

Caveat Coercitor borrows some ideas from JCJ/Civitas, in
particular the notion of private and public credentials, but at
the same time it is designed such that, unlike JCJ/Civitas:
• The generation of credentials does not have to be

distributed, making it simpler and more usable.

• The registration phase needs to be secured only with
“best effort” conﬁdentiality of credentials. If this se-
curity is broken, coercion may be possible, but it will
be evident. Credentials can be sent by post, SMS or
email. Effort should be made to keep the credentials
conﬁdential, but even if this does not succeed the core
property of coercion evidence is not broken.

• This property does not rely on trustworthiness of any
registrar, and does not require untappable channels
during registration. We require the channel to be re-
silient: voters will receive their credentials, perhaps
after multiple attempts.

• Voters can directly verify that their private credential
matches the public one on the bulletin board (voters can
be given the randoms used in the encryption). There is
no need for zero-knowledge proofs.

• The system does not require the use of fake creden-
tials. If a voter is coerced, he can give away his real

368

credential and vote normally. Coercion will be evident
in that case.

• The system addresses the problem of silent coercion. If
a voting credential has been leaked and misused by an
intruder, this will be evident to any external observer.
Our contributions. 1) We introduce the property of
coercion-evidence and we propose a general formal def-
inition (section III). 2) We propose a new remote voting
scheme, Caveat Coercitor, that achieves coercion-evidence
(section IV). 3) We weaken the trust assumptions for remote
electronic voting and we discuss how coercion-evidence
is useful in practice. We also hint how Caveat Coercitor
could be adapted to address the long-standing problem of
an untrusted voting device (section V). 4) We perform a
rigorous analysis of the fact that Caveat Coercitor satisﬁes
coercion-evidence (section VI).

II. CRYPTOGRAPHIC PRIMITIVES

We will rely on the following cryptographic primitives in

this paper:

Distributed El-Gamal [8]: We will consider the El-
Gamal encryption scheme, where the secret key can be
distributed (relying on e.g. [20]) among a set of trustees
T1, . . . , Tn. In that case, the private key is split as x =
x1 + . . . + xn and each of Ti holds a secret share xi.

The El-Gamal encryption of a plaintext m with a public
key k and random r will be denoted in the following by
k, or simply by {m}k when r is not important or is
{m}r
clear from the context. The private part of a public key k
will be denoted by priv(k). The decryption of a ciphertext
m with a private key x will be denoted by dec(m, x).

k

k

.

k ∗ {m2}r2

We consider an exponential version of El-Gamal where
ciphertexts can be homomorphically combined to compute
the addition of plaintexts: we have {m1}r1
k =
{m1 + m2}r1+r2
Re-encryption and mix nets [10], [15]: Given a cipher-
text {m}r
k constructed using the public key k any party can
compute another ciphertext {m}r+r(cid:2)
that encrypts the same
plaintext using the same key k, by using a new random r(cid:2).
We will denote the re-encryption of a ciphertext m with a
given random r(cid:2) by renc(m, r(cid:2)).
A re-encryption mix net is a set of agents M that takes
as input a sequence of ciphertexts S = m1, . . . , mk and
outputs a sequence of ciphertexts S(cid:2) = m(cid:2)
k that is
a re-encryption mix of S. Speciﬁcally, S(cid:2) is a formed by
re-encryption of elements in a permutation of S: there is
a permutation σ of {1, . . . , k} and a sequence of randoms
r1, . . . , rk such that m(cid:2)
k =
renc(mσ(k), rk). Moreover, if at least one element of M
is not to be controlled by an adversary C, the permutation
σ remains secret to C.
Plaintext equivalence test [14]: Given two ciphertexts
{m1}r1
k and respectively {m2}r2
k , encrypted with the same
key k, whose plaintexts are m1 and respectively m2, a

1 = renc(mσ(1), r1), . . . , m(cid:2)

1, . . . , m(cid:2)

plaintext equivalence test (pet) allows the holders of the
decryption key to demonstrate that m1 = m2, without
revealing the decryption key or any information about m1
or m2. For two ciphertexts c1 and c2, we will denote by
pet(c1, c2) = ok iff the plaintext equivalence test holds for
c1 and c2. Key holders only provide pets as indicated by the
protocol.

that

Zero-knowledge proofs for veriﬁability: Decryption,
re-encryption mixnets and plaintext equivalence tests can
be accompanied by non-interactive zero-knowledge proofs
that attest of the fact
these operations have been
correctly performed, without revealing sensitive information
like the decryption key. Zero-knowledge proofs are crucial
in order to ensure universal veriﬁability of the election,
while preserving user privacy. We will see that they are
essential for coercion-evidence as well. We will denote by
petproof(c1, c2, res) a zero-knowledge proof that the result
of the plaintext equivalence test applied to c1 and c2 is res.

III. COERCION-EVIDENCE

it

In this section we do not ﬁx the model that is used to
specify security protocols. The deﬁnition can be instantiated
in any computational or symbolic model. We assume that
the model deﬁnes the notion of a run and of a bulletin
board for an e-voting system. As usual, we assume that
there is an attacker (or coercer, intruder) that controls the
communication network. When a message is sent to the
is assumed to be in the control of the
environment,
attacker.
We assume that each eligible voter A has a unique voting
credential sA. There is a registration phase where the voters
can obtain their correct voting credentials. In other words,
we assume a registration protocol that ensures availability
and integrity of voting credentials. We do not assume that
this protocol ensures the secrecy of voting credentials. In
particular, the voting credentials of several voters may have
been leaked during registration.
The voting phase allows a voter with voting credentials
s and the intended vote v to execute a program V(s, v),
whose deﬁnition depends on the protocol. V(s, v) may
allow a voter to cast one or multiple ballots, abstain or
report coercion. We say that a voter A, with credential
sA and intended vote vA, follows the speciﬁcation of the
protocol
if its interaction with the protocol consists in
executing V(sA, vA).

Deﬁnition 1 (coerced, dishonest, free voters): Let τ be
a run of an electronic voting system and A be a voter with
credential sA who intends to vote vA. We say that the voter
A is:

• coerced (to vote for vC), if

– a ballot with credential sA and vote vC, with vC (cid:3)=
vA, is present on the bulletin board in the voting
phase

369

– A follows the speciﬁcation of the protocol
in the run τ.

• dishonest, if A does not follow the speciﬁcation of the
• free, if A is not coerced in the run τ

protocol in the run τ.

From our deﬁnitions, it follows that honest voters always
cast a vote for their intended choice, and they do not cast a
vote for a different candidate. If a voter A is coerced (resp.
dishonest), we let sA ∈ δc(τ ) (resp. sA ∈ δd(τ )) and we
will sometimes say that sA is a coerced (resp. dishonest)
credential. Thus,

• δc(τ ) is the set of credentials for coerced voters.
• δd(τ ) is the set of credentials for dishonest voters.
The number |δc(τ )| is called the degree of coercion in the

run τ.

A coerced voter is one whose credentials have been leaked
and misused by an intruder. This may have happened by
explicit coercion or by silent coercion. We assume that an
honest voter would nevertheless obtain the voting credentials
and cast a vote normally for the intended choice. We
consider voters to be coerced only if their credentials have
been used to cast a vote for a candidate that is different from
their intended choice.

A dishonest voter can misbehave in arbitrary ways, and
appear to be coerced even when he is not. It is also possible
that a voter did not follow the protocol due to a genuine
mistake, but for simplicity we will consider such voters
dishonest. Note that a free voter can also be dishonest.

We consider an equivalence relation on runs, called
indistinguishability, that models the inability of an observer
to tell the difference between two runs that differ on some
private data. For two runs τ and τ(cid:2), we denote by τ ∼ τ(cid:2)
if
they are in the indistinguishability relation (deﬁned
in section VI). A run τ is by deﬁnition complete if its
corresponding bulletin board contains the outcome of the
election.

Deﬁnition 2 (coercion-evidence): An electronic voting

system EVS satisﬁes coercion-evidence if:
1) Coercion-evidence test: there exists a test ce( ) that
takes as input data on the bulletin board and outputs a
number such that, for every complete run τ of EVS,
we have

|δc(τ )| ≤ ce(τ ) ≤ |δc(τ )| + |δd(τ )|

2) Coercer independence: Let A be a voter with creden-
tial sA who intends to vote for vA. Then, for every run
τ of EVS where
• the voter A follows the protocol by executing
V(sA, vA)
• for every candidate vi,
there is a free honest
voter Ai that follows the protocol by executing
V(sAi

, vi)

there exists a run τ(cid:2), where A does not execute
V(sA, vA), such that τ ∼ τ(cid:2).

The ﬁrst part of coercion-evidence requires the existence
of a test that can be applied to data that is available on the
bulletin board in order to determine the degree of coercion
in a given run. Note however that we do not require the
test to return the exact degree of coercion, but allow for an
over-aproximation. Indeed, for an external party, there is no
way of telling the difference between a coerced voter and a
dishonest voter who simulates being coerced. That is why
we have to allow an upper bound of |δc(τ )| + |δd(τ )|.

The second part of coercion-evidence requires that the
coercer can not make a distinction between a run τ where
the voter has followed the protocol normally and has cast
a vote for the desired candidate, in spite of being coerced,
and a run τ(cid:2) where the voter has followed the coercer’s
instructions. We require that for each coerced voter there
exists a free honest voter, so that in each case there is at
least one vote for the coerced choice, otherwise the coercer
would trivially detect that the coerced voter did not obey the
instructions.

Note that our deﬁnition also counters vote buying and
achieves effective receipt-freeness. A receipt for a ballot with
valid credentials and a certain candidate, even if that ballot is
cast, is not useful to a coercer because it does not guarantee
that the vote will be counted.

One might imagine a system that allows voters to declare
that they are being coerced, perhaps with a tick-box on
the ballot form, or a separate channel by which to report
coercion later. This may work if a voter knows they are
being coerced. But such a system does not satisfy coercion-
evidence according to our deﬁnition, since our deﬁnition
requires evidence even in the case of silent coercion.

IV. CAVEAT COERCITOR

Caveat Coercitor is a variation of JCJ/Civitas[16], [12].
We ﬁrst recall JCJ/Civitas and then describe how Caveat
Coercitor deviates from it.

A. Overview of JCJ/Civitas

JCJ/Civitas is designed around the notion of credentials
(with a private and a public part), that allow eligible voters
to authenticate their ballots. To allow coercion-resistance,
JCJ/Civitas distributes credential generation among a set of
parties called registrars. To resist coercion, the voter has the
ability to generate a fake credential and a fake proof, that
look as real to the coercer. To ensure this, it is assumed that
at least one of the registrars is not corrupted by the coercer
and that the voter can communicate with this registrar using
an untappable channel.

The participants of the protocol are
• the set of registrars R, whose role is to authenticate

eligible voters and help generate their credentials.

• the set of talliers T , whose role is to generate and
publish the public key of the election. Each of them
holds a secret share of the corresponding private key,
that will be used for distributed decryption and plaintext
equivalence tests.

• the set of eligible voters A1, . . . ,An.
• a re-encryption mix net M, whose role is to anonymize
the set of cast ballots before veriﬁcation of their eligi-
bility and their decryption.
• the bulletin board B, whose role is to record the
manipulation of ballots at all stages of the election,
from their recording to their tallying. It also records
proofs of correct ballot handling submitted by R,T
and M, that can be checked by external auditors.

Trust assumptions. A coercer may control some of
A1, . . . ,An, some of R, some of T and some of M.
For a voter Ai to achieve coercion-resistance, at least one
Aj, j (cid:3)= i, one of R, one of T , one of M and the
voting machines must be outside the control of the coercer.
Moreover, there must be an untappable channel from Ai to
the trusted registrar, so that the coercer can not get hold of
the real credential, and an anonymous channel for the voter
to submit the ballot. The voter must also trust the voting
machine to correctly construct the voting ballot and to verify
the zero-knowledge proofs provided by registrars.

A summary of the protocol is as follows:
Initialisation. The election starts with talliers T generat-
ing the public key pk of the election in a distributed manner,
such that no minority of talliers can recover the private
key priv(pk ) [20] and the decryption is distributed [8]. The
public part of the key is published on the bulletin board.

Voting credentials. In order to cast

their vote, every
eligible voter has a private credential. Private credentials will
be denoted by the letter s (decorated with various indices).
For a given private credential s, there exists a corresponding
public credential {s}r
pk , which will be published on the
electoral roll. We will denote public credentials (and their
re-encryptions) by the letter S (decorated with indices).
Registration. By running a separate protocol with each
of the registrars, the voter A obtains a private share siA
of her voting credential. Let m = |R|. The private voting
credential of the voter is the sum of all private credential
shares, i.e. sA = s1A + . . . + smA, and the public credential is
the homomorphic combination of all public credential shares
registered on the electoral roll, i.e. {sA}r
pk ∗ . . .∗
{smA}rm
Validity of voter credentials. Each registrar also provides
the voter with a non-transferable proof Pcorr of the fact that
the public share {siA}ri
pk , that is published on the electoral
roll ER, correctly encodes the private part siA. The proof can
be veriﬁed on the voting machine of the voter.

pk = {s1A + . . . + smA}r1+...+rm

pk = {s1A}r1

pk

.

Resisting coercion. The voter has the ability to construct
a fake credential by replacing the credential share siA of a

370

corr showing that {siA}ri
pk ,{v}rv

trusted registrar with a fake credential share s(cid:2)iA. The voter
also has the ability (with the help of the voting machine)
to construct a fake proof P (cid:2)
pk is an
encryption of s(cid:2)iA.
Voting. The ballot ({sA}rs
pk , Psv, Pcorr), from the
voter A, contains the encryption of the private credential
sA (with the key pk and with a different random than in
the electoral roll) and the encryption of the intended vote
v (with the key pk). To prevent the re-use of the same
credential by a party that does not hold the private part,
the ballot contains additionally a zero-knowledge proof Psv
of the fact that its creator knows both s and v. Additionally,
a zero-knowledge proof Pcorr proves that v is a valid vote,
according to the speciﬁcation decided by election authorities.
The ballot ({sA}rs
pk , Psv, Pcorr) is constructed by the
voting machine and submitted to the bulletin board.

pk ,{v}rv

Veriﬁcation of proofs and mixing. Before tabulation
starts, the zero-knowledge proofs Psv and Pcorr of cast ballots
are veriﬁed (e.g. by the talliers) and ballots with invalid
proofs are discarded. The valid ballots (without the proofs)
and the electoral roll are then sent to the re-encryption mix
net M for anonymization.

Tallying. Credentials from anonymized ballots are com-
pared, using plaintext equivalence tests, to credentials from
the anonymized electoral roll, to ensure that votes to be
counted are cast by eligible voters only. If multiple ballots
are submitted with the same credentials, only one copy is
kept according to a predeﬁned policy, e.g. only the last
vote counts. Finally, the decided set of countable votes is
decrypted.

The re-encryption mix, the plaintext equivalence tests and
the decrypted votes are accompanied by zero-knowledge
proofs that ensure the operations have been correctly per-
formed.

B. Caveat Coercitor: registration, voting and mixing

Caveat Coercitor follows the same scheme as JCJ/Civitas

with the following differences.
Trust assumptions. We assume that one mix server in
M, one tallier in T and the voting machines are honest.
However, to achieve coercion-evidence, Caveat Coercitor
does not have to assume that any of the registrars are trusted,
and neither does it require any untappable channel between
voters and registrars. The registration channel is assumed
only to allow the voters to obtain their credentials, and it
may allow the coercer to read honest messages and inject
fake messages. We discuss our trust assumptions in more
detail in section V.

The initialisation phase and the structure of the voting

ballots are exactly the same as in JCJ/Civitas.

Registration. The voters can simply receive their private
credentials by email or by post. Their creation does not have
to be distributed.

Validity of voter credentials. Because the voter is not
required to keep the private credential secret at all cost, the
proofs that the public share {s}r
pk of the credential is a
correct encryption of the private share s can be signiﬁcantly
simpliﬁed. In fact, the voter can simply obtain from the
registrar the random number r that has been used in the
encryption algorithm. Then, the voter can use any device to
verify that the encryption has been correctly performed.

Resisting coercion. In Caveat Coercitor voters do not have
to “resist” coercion. To make coercion “evident” a voter does
not need to perform any additional task other than to cast a
vote for the desired candidate. He can give away the voting
credential to the coercer, if asked.

Voting. The construction of voting ballots is similar to
the one used in JCJ/Civitas. The fundamental difference is
in how Caveat Coercitor handles multiple ballots from the
same voter: a voter may submit multiple ballots, constructed
on possibly different voting devices, provided they are all
for the same candidate. At most one vote for one candidate
will be counted for each credential. Precisely one vote
will be counted if all the ballots for a given credential
contain a vote for the same candidate. No votes will be
counted for a credential if there are ballots for that credential
corresponding to at least two distinct candidates. Instead,
that credential will be detected by the coercion-evidence test.
Veriﬁcation of proofs and mixing. The zero-knowledge
proofs of cast ballots are veriﬁed. Before mixing, the ballots
with invalid proofs are eliminated.

C. Caveat Coercitor: coercion-evidence and tallying

We have at this stage a set of anonymized ballots to
be tallied and an anonymized electoral roll. In addition to
eliminating ballots with fake credentials, now we need to
determine the coerced credentials, remove the corresponding
ballots from the ballots to be tallied and output evidence of
coercion.

Coercion-evidence. Let τ be a run of Caveat Coercitor

up to this phase. We let

• BBaer(τ ) be the anonymized electoral roll with each
pk , for some private credential
pk are re-encryptions of public credentials and

element of the form {s}r
s. {s}r
we denote them by (decorations of) the letter S.

• BBcast(τ ) be the set of cast ballots with valid zero-
knowledge proofs of correctness. Each element of
BBcast(τ ) is of the form ({s}r1
pk , Psv, Pcorr), for
some private credential s and vote v. Encrypted votes
will be denoted by (decorations of) the letter V .

pk ,{v}r1(cid:2)

• BBtally(τ ) be the set of anonymized ballots to be
authorized relying on BBaer(τ ) and then tallied. Each
element of BBtally(τ ) is of the form ({s}r2
pk ,{v}r2(cid:2)
pk ),
for some private credential s and vote v.

The talliers will execute an algorithm whose output can
be used by any external observer to determine the amount

371

the same time allowing coercer-
of coercion, while at
independence. Speciﬁcally, the talliers will compute the set
of credentials in BBaer(τ ) for which there are at least two
ballots with two different votes in BBtally(τ ), i.e. the set
BBce(τ ) = {S ∈ BBaer(τ )| ∃(S1, V1), (S2, V2) ∈ BBtally(τ ).

pet(S, S1) = pet(S, S2) = ok, pet(V1, V2) (cid:3)= ok}

There is a simple way to compute BBce(τ ), shown in
the
algorithm 1. The idea is to ﬁrst group together all
ballots that correspond to a given credential, relying on
plaintext equivalence tests, and then detect if among these
there are two ballots representing distinct votes. At the end
of algorithm 1, the set cecred
cc (τ ) should be equal to BBce(τ )
(we will prove this in section VI) and the zero-knowledge
proofs in cezkp
cc (τ ) should allow anyone to verify that the set
cecred

cc (τ ) has been correctly computed.

cc (τ ), cezkp

cc (τ )
cc (τ ) := ∅

Algorithm 1 Coercion-evidence: algorithm that reveals too much
Input: BBaer(τ ), BBtally(τ ) (taken from the bulletin board)
Output: cecred
cc (τ ) := ∅; cezkp
cecred
for S ∈ BBaer(τ ) do
BS := ∅ // BS is the set of ballots corresponding to S
for (S(cid:2), V ) ∈ BBtally(τ ) do
if pet(S, S(cid:2)) = ok then
BS := BS ∪ {(S(cid:2), V )}
cc (τ ) := cezkp
cezkp

cc (τ ) ∪ petproof(S, S(cid:2), yes)

if pet(V1, V2) (cid:3)= ok then

for (S1, V1) ∈ BS, (S2, V2) ∈ BS do
cc (τ ) ∪ {S}
cc (τ ) ∪ petproof(V1, V2, no)

cc (τ ) := cecred
cc (τ ) := cezkp

cecred
cezkp
cc (τ ), cezkp

return cecred

cc (τ ) (to the bulletin board)

Now,

the coercion-evidence test cecc(τ )

in Caveat
Coercitor, described in Algorithm 2, consists in verifying
that cccred
ce (τ ) has been correctly computed (basically, this
means verifying the zero-knowledge proofs for the plaintext
ce (τ )| as the observed
equivalence tests) and outputting |cccred
degree of coercion.

Algorithm 2 Coercion-evidence test

cc (τ ), cezkp

cc (τ ) (taken from the bulletin board)

Input: cecred
Output: cecc(τ )
for zkp ∈ cezkp

cc (τ ) do

if verify (zkp) (cid:3)= ok then

fail

cecc(τ ) := count(cecred
return cecc(τ ) (to the bulletin board)

cc (τ ))

The algorithm 1 provides data for the coercion-evidence
test and allows coercer independence, but let us see at what

372

cost coercer independence is achieved. Indeed, note that the
number of ballots that correspond to every credential in
BBaer(τ ) is revealed. Now, assume the following coercion
strategy: the coercer instructs the voter A to abstain and then
casts a very large number nA of ballots using sA. Therefore,
if the voter disobeyed and has cast a vote using sA, the
output of the algorithm 1 will allow the coercer to observe
that for some credential nA + 1 ballots have been cast. Now,
to obtain coercer-independence, there should be some free
voter A(cid:2) that has cast nA ballots using s(cid:2)
A: the coercer will
see nA ballots for some credential, and will not be able to
tell whether that credential is sA or not.

Although in theory coercer independence can be achieved
in this way, the practical aspect of this approach is question-
able. Therefore, we propose another algorithm to compute
BBce(τ ), which outputs less information about the set of
tallied ballots (Algorithm 3). Instead of computing the set
of all ballots that have been cast with every credential sA,
we carefully guide the computation to determine if there are
two distinct votes for sA. In particular, if there are multiple
ballots with credential sA for the same candidate, only one
of them will be determined. We do the minimal amount of
computations required to determine if a credential is coerced
or not, and then go to the next credential.

We assume there are l candidates and that a list
can1, . . . , canl of candidate names encrypted with pk has
been computed and passed through a mixnet. These en-
crypted candidate names are part of the input for Algorithm
3. The algorithm ﬁrst groups the ballots according to the
candidate that they represent and then for every credential
it checks whether it belongs to at least two groups.
To achieve coercer independence for a voter A in the
context of Algorithm 3, all we need is the presence of a
free voter A(cid:2) that can either cast a normal vote or cancel
his ballots by casting two different votes: the coercer can
not tell the difference between the ballots of A and those
of A(cid:2). If the coercer has cast a large number of ballots nA
with sA and the voter A has cast a different vote with sA,
the free voter A(cid:2) just needs to cast a vote for the candidate
desired by the coercer: there is no way for the coercer to
detect that there are nA + 1 ballots with credential sA and
that they have been discarded as coercion-evidence.
Tallying. For a ciphertext c and a set of ciphertexts M,
we will denote by c ∈pet M the fact ∃c(cid:2) ∈ M.pet(c, c(cid:2)) =
ok. Let BBvalid(τ ) = BBaer(τ ) (cid:2) BBce(τ ) be the set of
anonymized credentials that are not coerced. Now, for every
(S, V ) ∈ BBtally(τ ),
• either S ∈pet BBvalid(τ ). In this case, since S /∈pet
BBce(τ ), we are certain that all ballots that correspond
to S contain a vote for the same candidate. Only one
of them should be counted.
• or else S ∈pet BBce(τ ). In this case, S corresponds to
a coerced credential and no ballot should be counted
for S.

Algorithm 3 Coercion-evidence: algorithm that reveals enough

Input: BBaer(τ ), BBtally(τ ), can1 . . . canl
(taken from the bulletin board)
Output: cecred
cc (τ )
cc (τ ) := ∅; cezkp
cc (τ ) := ∅
cecred
// Step 1: group ballots according to the vote that they encode
for i := 1 to l do

cc (τ ), cezkp

Bi := ∅
for (S, V ) ∈ BBtally(τ ) do
if pet(cani, V ) = ok then
Bi := Bi ∪ {(S, V )}
cc (τ ) ∪ petproof(cani, V, yes)
cc (τ ) := cezkp
cezkp
// Step 2: for each S, check if it occurs in Bi,Bj, i (cid:2)= j
for S ∈ BBaer(τ ) (*) do
for (S1, V1) ∈ Bi do

for i := 1 to l do

if pet(S, S1) = ok then

cc (τ ) := cezkp
cezkp
for j := i + 1 to l do
for (S2, V2) ∈ Bj do

cc (τ ) ∪ petproof(S, S1, yes)

if pet(S, S2) = ok then

cc (τ ) := cecred
cc (τ ) := cezkp

cecred
cezkp
go to next credential in BBaer(τ ) at (*)

cc (τ ) ∪ {S}
cc (τ ) ∪ petproof(S, S2, yes)

return cecred

cc (τ ), cezkp

cc (τ ) (to the bulletin board)

• or else S /∈pet BBaer(τ ). In this case, S corresponds to a
non-eligible credential and no ballot should be counted
for S

Therefore, we have the following simple algorithm for
tallying: for all credential S ∈ BBvalid(τ ), ﬁnd the ﬁrst
ballot (S(cid:2), V ) ∈ BBtally(τ ) such that pet(S, S(cid:2)) = ok; then,
decrypt V .

V. COERCION-EVIDENCE IN CAVEAT COERCITOR

A. Trust assumptions.

We will show in section VI that coercion-evidence holds

in caveat coercitor under the following trust assumptions:

• The voting machines of coerced voters and of some

free voters are not compromised.

• The registration channel allows voters to obtain their
voting credentials, and voters verify them to ensure that
they are correct. In particular, this implies that voters
can cast a valid ballot for their intended choice.

their vote as intended.

• There is an anonymous channel that allow voters to cast
• There exists at least one honest mix server M
• There exists at least one honest tallier T
The trust assumptions about one honest mix server and
one honest tallier are standard and probably necessary in any
system based on mixnets and on public-key cryptography.
We explain later in this section how Caveat Coercitor may

be adapted to relax the ﬁrst assumption about the trusted
voting machine.

A big novelty of our trust assumptions, in contrast with
Helios and JCJ/Civitas, is that voting credentials need to be
secured only with “best effort”. Thus, even if the voting
channel where the voter obtains his credential
is com-
promised, or if the voter is coerced to reveal the private
credential, coercion-evidence still holds. (However, if the
security is insufﬁcient, a lot of coercion will be detected.)
This also means we do not have to trust the registrars to
keep the credential secret. More generally, this addresses
the problem of silent coercion discussed in the introduction,
which is common to Helios, JCJ/Civitas and the Estonian
internet voting system.

Informally, coercion-evidence holds given these trust as-

sumptions because:

• The coerced voters follow the instruction to cast a vote
for their intended candidate. Since they have access to
a trusted voting device, this ensures that, for all coerced
voters, coercion-evidence is input in the system during
the voting phase. It will be detected later.

• Additionally, a trusted voting device means that the
coercer can not observe that a voter has cast a ballot,
and this is essential for coercer-independence.

• The voter veriﬁes that his ballot has reached the
bulletin board and zero-knowledge proofs for mixnets
and plaintext equivalence tests are publicly checked.
This ensures that coercion-evidence that is input in
the system during the voting phase is not
lost on
the way from the voters to the talliers. The role of
zero-knowledge proofs is also to ensure that coercion-
evidence in ballots to be tallied corresponds indeed to
ballots cast in the voting phase, and not introduced in
the system during mixing.

• Voters receive and verify that their credentials are valid.
This ensures that their ballots are not discarded before
the ﬁnal tally, and will result either in a counted vote,
or in coercion-evidence.

• The honest mixer and the honest tallier will help in
achieving coercer-independence: the honest mixer will
ensure that the ballots cast by the coercer or the coerced
voter can not be tracked to determine how they have
been handled in the tallying phase; the honest tallier
ensures that
the ballots are decrypted and plaintext
equivalence tests are performed only as speciﬁed by
the protocol.

B. Example.

Suppose that events unfold as depicted in Table I. Among
48M voters, about 44M voters submit ballots with vote
for only one candidate, while about 4.2M voters (or their
coercers) submit ballots containing votes for different can-
didates. Thus, most voters have not been coerced, and have
cast possibly multiple ballots for a single candidate. They

373

No. of credentials %age of credentials

Total number of eligible
credentials
Number of credentials that
have voted for a single
candidate
Number of credentials that
have voted for at least two
candidates

48,783,530

44,539,363

4,244,167

100%

91.3%

8.7%

AN EXAMPLE DISTRIBUTION OF BALLOTS. A TABLE IN THIS FORMAT IS

OUTPUT BY THE SYSTEM AT THE END OF THE ELECTION.

Table I

account for 91.3% of voters. The rest 8.7% of voters have
cast ballots for different candidates. These may be voters
that have been forced to release their credentials, forced to
cast vote to a candidate but they also managed to cast vote
to their intended candidate or they may simply have decided
to submit two ballots for different candidates. So either
they were coerced or they did not follow the speciﬁcations
of the protocol and thus were dishonest. The ballots from
these 8.7% of voters will all be discarded and 91.3% of
the ballots are taken to determine the outcome. The system
counts one vote for the (single) candidate represented by
each of the set of ballots that corresponds to each credential.
The margins by which the winner beats the other candidates
can be considered in order to determine whether the election
result should carry.

To understand the reason for this way of counting, let us

distinguish the following two cases:

• If a credential has been used once or more times, but
each time to vote for the same candidate, a vote for that
candidate is counted. Indeed, there are three subcases:
– The voter has cast multiple ballots for the same

candidate;

– The attacker obtained voter’s credentials and has
cast a ballot for the same candidate as the voter;
or

– The voter knowingly abstained and the attacker
obtained her credentials and cast ballots for one
candidate.

The output of the system does not allow any voter,
coercer or observer to distinguish between these sub-
cases, but if the voter behaved correctly and cast a
ballot(the third case is eliminated), then his vote is
counted.

• If a credential has been used to cast votes for multiple
candidates, none of its votes is counted. The following
sub-cases are indistinguishable:

– The voter has cast multiple ballots for several

different candidates;

– The voter has cast multiple ballots for one candi-
date, the attacker obtained her credentials and has

cast a vote for a different candidate;

– The voter and the attacker each have cast votes for

several different candidates; or

– The voter knowingly abstained and the attacker
cast votes on her behalf for multiple different
candidates.

In each of these cases, either the voter is dishonest or the
voter is coerced. The corresponding votes are therefore not
counted and the evidence is recorded for the authorities to
make a decision.

C. Discussion

Disincentivisation of coercion: As demonstrated, a
coercer that wishes to achieve a particular outcome is faced
with a dilemma. Assuming the security of the cryptography,
and assuming that the voter is not dissuaded from casting
her own ballot by invalid threats, the best the coercer can do
is try to force a large number of annulled votes. However,
the number of annulled votes he forces will be detected
and announced, and an analysis will be performed to check
whether those votes will materially affect
the outcome.
If not, the election will be considered a success and the
declared outcome will have been shown to be robust against
the degree of coercion attempted.

Since annulled votes in Caveat Coercitor are evident, they
do not have the power that forced abstentions have in other
systems. If the coercer has a strategy of annulling votes that
he believes would be votes for a particular candidate, it won’t
work, because the ﬁnal results will be interpreted as meaning
‘there was a lot of coercion’ rather than ‘there were a lot of
abstentions’.

Disruption of the election: In the deﬁnition of coercion-
evidence, we have taken into account the fact that dishonest
voters may pretend to be coerced, and therefore the coercion-
evidence test may overestimate the actual degree of coercion.
In some situations, a set of dishonest voters could rely on this
in order to challenge the validity of the election. Especially
when the difference between the winner and the runner-up
of the election is small, a minority of voters would sufﬁce
to cause a disruption.

To deter voters from disrupting the election in practice,
one option could be making voluntarily voting for two
different candidates an offence. Both technical and admin-
istrative measures should be carefully designed to ﬁnd an
acceptable balance between discouraging dishonest behavior
and encouraging resistance to coercion.

Another option is to have a probabilistic interpretation
of coercion-evidence, depending on various data that can be
gathered about the election (voter intentions, audit logs, etc.).
This approach would allow to separate coercion-evidence
into different threads, one of which would be evidence of
actual coercion. More research on this idea is needed.

Individual and universal veriﬁability: Individuals can
is present on the bulletin board,

their ballot

verify that

374

and will be counted. If the voter was coerced, their ballot
will be included in the coercion evidence test. Observers
can perform universal and eligibility veriﬁcation, because
the computations of algorithm 3 are publicly veriﬁable.
Additionally, observers can verify the ﬁgures given in the
table.

Towards untrusted voting machines: Although in this
paper we assume for simplicity that a voter has access to a
trusted voting machine, Caveat Coercitor has the potential
to be adapted to provide coercion evidence in the context of
untrusted machines, and this is our main topic for future
research. We give some hints about directions here. For
instance, assume a voter has access to n voting devices and
the voter is unsure which one can be trusted for integrity.
That is not a problem for Caveat Coercitor: the instruction
for the voter is to simply cast his vote on any number of
available devices. As long as one out of n devices is not
integrity-compromised (the voter does not need to know
which one),

• either the vote will be counted for the preferred candi-

date;

• or coercion will be recorded.

This deals with integrity. For voting clients that are privacy-
corrupted,
the situation is more difﬁcult. A voter needs
to take whatever steps are necessary to prevent the client
communicating with the coercer. This may involve using the
client in a Faraday cage, and resetting it or even destroying
it afterwards, depending on the coercer’s power.

Systems like JCJ/Civitas and Helios are not as well
adapted to the untrusted client, because they are not designed
to be as tolerant of coercion as Caveat Coercer. Our system
allows coercion (but makes it evident).

VI. ANALYSIS

According to deﬁnition 2, we prove that the coercion-
evidence test of Caveat Coercitor is adequate (section VI-A)
and that Caveat Coercitor allows coercer independence
(section VI-B). We give proof sketches in this section and
complete proofs in the appendix.

A. Coercion-evidence test

If cecc(τ ) is the result of applying the coercion-evidence
test in Caveat Coercitor for a run τ, we have to show that
|δc(τ )| ≤ cecc(τ ) ≤ |δc(τ )| + |δd(τ )|.
For a credential s and a vote v, we will denote by B(s, v)
the set of possible ballots (including the zero-knowledge
proofs) with credential s and vote v. Thus, B(s, v) is the set
of tuples of the form ({s}r
pk , Psv, Pcorr), where r, r(cid:2)
are random numbers and Psv, Pcorr are the corresponding
zero-knowledge proofs for this ballot. We denote by B0(s, v)
the set of possible ballots with credential s and vote v,
without the zero-knowledge proofs.

pk ,{v}r(cid:2)

For a run τ of Caveat Coercitor, recall that BBcast(τ ) is
the set of cast ballots with valid zero-knowledge proofs and

& B(s, v(cid:2)) ∩ BBcast(τ ) (cid:3)= ∅}
& B0(s, v(cid:2)) ∩ BBtally(τ ) (cid:3)= ∅}

BBtally(τ ) is the set of ballots to be tallied in the run τ. Let
us denote by E(τ ) the set of private credentials for eligible
voters in a run τ. We deﬁne
Icast(τ ) = {s | ∃v, v(cid:2).v (cid:3)= v(cid:2),B(s, v) ∩ BBcast(τ ) (cid:3)= ∅
Itally(τ ) = {s | ∃v, v(cid:2).v (cid:3)= v(cid:2),B0(s, v) ∩ BBtally(τ ) (cid:3)= ∅
Fcast(τ ) = {s | ∃v.B(s, v) ∩ BBcast(τ ) (cid:3)= ∅} (cid:2) E(τ )
Ftally(τ ) = {s | ∃v.B0(s, v) ∩ BBtally(τ ) (cid:3)= ∅} (cid:2) E(τ )
In words, Icast(τ ) and respectively Itally(τ ) represent
the set of (inconsistent) credentials that have at least two
corresponding ballots on the bulletin board in the voting
phase and in the tallying phase respectively. The set Fcast(τ )
represents fake (i.e. invalid) credentials that have been used
to cast a vote, while the set Ftally(τ ) is formed of fake
credentials that correspond to ballots that are to be tallied.
A ﬁrst lemma shows that all the coerced credentials are
contained in the set I(τ ) and that, additionally, the set I(τ )
may only contain fake or dishonest credentials:

Lemma 1: For all run τ of Caveat Coercitor, we have

δc(τ ) ⊆ Icast(τ ) ⊆ δc(τ ) ∪ δd(τ ) ∪ Fcast(τ )

The proof of the ﬁrst inclusion relies on the deﬁnition
of coerced voters and on the trust assumption that
the
coerced voters have access to an honest machine to cast
their vote. Thus, at least two different votes are present for
each coerced credential on the bulletin board: one coming
from the voter and another one coming from the coercer. The
second inclusion can be shown by a simple case analysis.
Secondly, we show that the set of fake credentials and
the set of inconsistent credentials can not be changed in the
mixnet.

Lemma 2: For all run τ of Caveat Coercitor in which

the mixnet proofs are valid, we have

Itally(τ ) = Icast(τ ) and Ftally(τ ) = Fcast(τ )

The proof is an easy consequence of the fact that veriﬁable
mixnets can not modify the content of ballots. Another easy
observation is that the set BBce(τ ), deﬁned in section IV-C,
has the same cardinality as the set of inconsistent credentials
that are not fake:

Lemma 3: For all run τ of Caveat Coercitor, we have

|BBce(τ )| = |Itally(τ ) (cid:2) Ftally(τ )|

Finally, we show that the coercion-evidence test provided
by Caveat Coercitor captures exactly |BBce(τ )|, i.e. we show
the Algorithm 3 from section IV-C is correct. Let
that
cecred
cc (τ ) be the set of credentials output by the Algorithm
3 for a run τ.

Lemma 4: For all run τ of Caveat Coercitor, we have

cecred

cc (τ ) = BBce(τ )

375

To prove this lemma, we show that every credential in
BBce(τ ) will be detected in the step 2 of the Algorithm 3
and added to the set ceτ
cc. Moreover, we observe that every
credential that has been used to cast a vote for a single
candidate will not be part of cecc(τ ), and therefore cecc(τ ) ⊆
BBce(τ ).
cc (τ )|.
Putting all the lemmas together, we obtain the ﬁrst part
of coercion-evidence according to deﬁnition 2. Corollary 1
shows that the output of the coercion-evidence test in Caveat
Coercitor is a correct estimate of the degree of coercion in
any run, up to the number of dishonest voters:

Recall that, by deﬁnition, we have cecc(τ ) = |cecred

Corollary 1: For all run τ of Caveat Coercitor, we have

|δc(τ )| ≤ cecc(τ ) ≤ |δc(τ )| + |δd(τ )|

Proof: From lemma 1 and lemma 2, we have δc(τ ) ⊆
Icast(τ ) and Icast(τ ) = Itally(τ ). Therefore, we deduce
δc(τ ) ⊆ Itally(τ ). By deﬁnition, all credentials in δc(τ ) are
valid, i.e. δc(τ ) ⊆ E(τ ), and thus δc(τ ) ∩ Ftally(τ ) = ∅.
Hence, we obtain δc(τ ) ⊆ Itally(τ ) (cid:2) Ftally(τ ). Considering
the cardinality of these sets, we obtain |δc(τ )| ≤ |Itally(τ ) (cid:2)
Ftally(τ )| = |BBce(τ )| = |cecred
cc (τ )| = cecc(τ ), where we
have used lemma 3 for the ﬁrst equality and lemma 4 for
the second equality. This way we get |δc(τ )| ≤ cecc(τ ).
From lemma 1, we have Icast(τ ) ⊆ δc(τ ) ∪ δd(τ ) ∪
Fcast(τ ). Using lemma 2, we get Itally(τ ) ⊆ δc(τ ) ∪
δd(τ ) ∪ Ftally(τ ). Subtracting Ftally(τ ) from both sides,
we have Itally(τ ) (cid:2) Ftally(τ ) ⊆ δc(τ ) ∪ δd(τ ) (cid:2) Ftally(τ ).
Furthermore, by deﬁnition we have δc(τ ) ∪ δd(τ ) ⊆ E(τ )
and therefore δc(τ )∪δd(τ )(cid:2)Ftally(τ ) = δc(τ )∪δd(τ ). Thus,
we have Itally(τ )(cid:2)Ftally(τ ) ⊆ δc(τ )∪δd(τ ). Considering the
cardinality of these sets and applying lemma 3 and lemma 4,
we deduce cecc(τ ) ≤ |δc(τ )| +|δd(τ )| and we can conclude
the proof.

B. Coercer independence

Let A be a voter with credential sA who intends to vote
for vA. We have to show that, for every run τ of Caveat
Coercitor where
V(sA, vA)

• the voter A follows
the protocol by executing
• for every candidate vi, there is a free honest voter Ai
there exists a run τ(cid:2), where A does not execute V(sA, vA),
such that τ ∼ τ(cid:2).
First we show how τ(cid:2) can be constructed given τ and then
we show that τ ∼ τ(cid:2).

that follows the protocol by executing V (sAi

, vi)

A run τ can be characterized by the sequence of messages
that have been sent over the network in τ. For every message
in a run τ, either the message is sent by the attacker (or
by a party under the control of the attacker), or else it is
sent by an honest agent, and all the attacker can do is to
learn that message. A run τ can be seen as a sequence of
(partial) runs τ = τ1 . . . τn. In Caveat Coercitor, we split a

run in a sequence corresponding to the phases of the system:
τ = τvote.τer.τmix.τtally, where τvote is the list of ballots with
valid zero-knowledge proofs that are cast on the bulletin
board in the voting phase, τer is the electoral roll, τmix is the
output of the re-encryption mix net and τtally is the output
that talliers compute in the tallying phase, which includes
data for the coercion-evidence test and the ﬁnal outcome
Construction of the run τ(cid:2). There are four possible cases

for the run τ:

• the coercer cast a vote with credential sA for a candi-

date vC, with vC (cid:3)= vA

• the coercer did not cast a vote with credential sA
• the coercer cast a vote with credential sA for the

• the coercer cast at least two different votes with cre-

candidate vA

dential sA

For simplicity, we only consider the ﬁrst case, which is
also the most likely. The other three cases can be handled in
a similar way. We sketch the main ideas of the construction
in the following and we give a complete description in the
appendix.
Assume the coercer has cast a ballot bsA,vC ∈ B(sA, vC).
By deﬁnition of the run τ, we know that the voter A has
cast a ballot bsA,vA ∈ B(sA, vA) and that there is a free
honest voter A(cid:2) that has cast a ballot bsA(cid:2) ,vC ∈ B(sA(cid:2) , vC).
Thus, the ballots corresponding to sA are canceled because
they are counted as coercion-evidence, while there is a vote
counted for vC that corresponds to sA(cid:2).
On the other hand, a requirement of the deﬁnition is that
the voter A abstains from voting in the run τ(cid:2). Therefore, a
vote for vC corresponding to sA is counted in the ﬁnal tally.
In order to obtain τ ∼ τ(cid:2), we need at least to have the same
outcome in the runs τ and τ(cid:2). Hence, we need the free voter
A(cid:2) to cancel his vote in the run τ(cid:2): we assume A(cid:2) casts a
ballot bsA(cid:2) ,vC ∈ B(sA(cid:2) , vC), as in the run τ, and in addition
a ballot bsA(cid:2) ,vA ∈ B(sA(cid:2) , vA). The rest of the cast ballots
in τ(cid:2) are assumed to be exactly the same as in τ.
the amount of coercion-evidence and the ﬁnal
outcome of τ(cid:2) are exactly the same as in τ. What we need
in addition in order to achieve coercer independence is that:
• the coercer is not able to trace any of the cast ballots
and detect that they where handled as coercion evidence
• the coercer is not able to decrypt the ballots before they

Thus,

are mixed

The ﬁrst point is achieved by our trust assumptions that
the voter A can cast his ballot on an anonymous channel
and that at least one mix server is honest. The anonymous
channel ensures that the coercer can not distinguish the two
runs during the voting phase. Later, in the run τ(cid:2), the honest
mix server will permute the ballots so that coercion-evidence
and the votes for vC show up in the same places as in τ.
The second point is achieved by out trust assumption that
at least one tallier is honest. Therefore, the ballots will be

376

• τ(cid:2)

mix.τ(cid:2)

• τ(cid:2)
• τ(cid:2)

tally, where

decrypted only as speciﬁed by the protocol, after the mixing
occurs.
In conclusion, if τ = τvote.τer.τmix.τtally, then we let τ(cid:2) =
er.τ(cid:2)
vote.τ(cid:2)
τ(cid:2)
vote is as τvote, with the difference that the voter A
• τ(cid:2)
abstains from voting and the free voter A(cid:2) cancels his
vote.
er = τer
mix is as τmix, with the difference that
the honest
mixer swaps some ballots corresponding to sA with
some ballots corresponding to sA(cid:2), and also swaps the
credentials of A and of A(cid:2) while anonymizing the
electoral roll.
tally = τtally. This is possible because, by construction
of the runs τvote and τ(cid:2)
vote, it is the case that they
determine the same outcome. Since there is one tallier
that is not under the control of the coercer, all the
coercer can do is to observe the ﬁnal outcome computed
according to the speciﬁcation of the protocol.
Indistinguishability of τ and τ(cid:2). Although the actions
performed and observed by the coercer are the same in
τ and in τ(cid:2), it may be the case that the coercer could
distinguish τ from τ(cid:2) by performing various computations
on the messages that where sent in τ and τ(cid:2): encryption,
re-encryption, checking zero-knowledge proofs, combining
messages, etc. In order to reason about the knowledge of the
attacker, we therefore need a formal model of messages and
of all possible computations that an attacker may perform.
We adopt a variant of the applied pi-calculus [1], used by
the protocol veriﬁer ProVerif [6], [7].

We specify for ProVerif the messages that can be built
in Caveat Coercitor, the cryptographic primitives and the
possible actions of the attacker. Then, ProVerif allows us
to verify that all the pairs of runs of a bi-process are in
observational equivalence. Observational equivalence mod-
els the indistinguishability relation between runs that we are
interested in: τ ∼ τ(cid:2) if and only if any computations applied
to τ and to τ(cid:2) lead to the same observations. A bi-process is
a pair of applied pi-calculus processes (P, P (cid:2)), see e.g. [1],
that share the same structure and differ only on the messages
that they handle. A bi-process (P, P (cid:2)) generates pairs of runs
(τ, τ(cid:2)), where τ is a run of P , τ(cid:2) is a run of P (cid:2) and τ and
τ(cid:2) have been generated by executing the same actions in P
and in P (cid:2).
We observe that the runs τ and τ(cid:2) constructed in section
VI-A are of the form τ = τ0.τtally and τ(cid:2) = τ(cid:2)
0.τtally, i.e.
the tally in the two runs is exactly the same. Therefore,
in order to show that τ ∼ τ(cid:2), it is sufﬁcient to show that
τ0 ∼ τ(cid:2)
vote.τ(cid:2)
0 = τ(cid:2)
mix.
Accordingly, we specify two process Pcc and P (cid:2)
cc such that
the bi-process (Pcc, P (cid:2)
cc) generates all the pairs of runs of
the form (τvote.τer.τmix) and (τ(cid:2)
mix) as constructed
in section VI-A. We show with ProVerif that observational
equivalence holds for the given bi-process (Pcc, P (cid:2)
cc) (the

0, where τ0 = τvote.τer.τmix and τ(cid:2)

vote.τ(cid:2)

er.τ(cid:2)

er.τ(cid:2)

ProVerif code is available online 1), and therefore we can
conclude the indistinguishability of any pair of runs (τ, τ(cid:2)):
Corollary 2: For any pair of runs (τ, τ(cid:2)) of Caveat Co-
ercitor constructed as described in section VI-A, we have
τ ∼ τ(cid:2).

From corollary 1 and corollary 2, we can conclude:
Theorem 1: Caveat Coercitor satisﬁes coercion-evidence

under the trust assumptions from section V-A.

VII. RELATED WORK

Formal deﬁnitions: A formal deﬁnition of coercion-
resitance based on observational equivalence is proposed
in [13]. They prove that the Lee protocol [19] satisﬁes it.
Another deﬁnition based on observational equivalence is
proposed in [5], where an automated proof with ProVerif
has been carried out for JCJ/Civitas. A more detailed,
but not automated, analysis of JCJ/Civitas based on an
epistemic approach is performed in [18]. In a computational
model, coercion-resistance has been deﬁned and proved for
JCJ/Civitas in [16], [12].

Caveat Coercitor can readily be compared with other
systems that allow Internet voting, such as JCJ/Civitas and
Helios.

JCJ/Civitas [16], [12]: The system makes a strong
assumption that there is an untappable channel for regis-
tration. It also assumes that the voter can run a multiparty
protocols and keep real credentials secret all the time. Under
these assumptions, it is strongly resistant to coercion, and is
fully veriﬁable by voters and observers. Several variants of
JCJ/Civitas improve the usability of the aspects related to
veriﬁability [9], [21] and coercion-resistance [11].

On the other hand, coercion-evidence in Caveat Coerci-
tor is not dependent on the secrecy of voting credentials,
leading to more realistic assumption about the distribution
of credentials. The registration phase, the voting phase and
the resistance to coercion become simpler and more usable.
Helios 2.0 [2], [3]: This system is designed for low-
coercion elections. It makes a few efforts to resist potential
coercion, for example by keeping secret from voters the
randoms in their ballots, but these efforts are easily defeated.
On the positive side, Helios 2.0 enjoys individual and
universal veriﬁability (but not eligibility veriﬁability). The
most interesting feature of Helios is its high usability, which
has been demonstrated by running large elections without
failure. Caveat Coercitor is designed to be as usable as
Helios (indeed, it can have the same front end and voter
experience). Moreover, Caveat Coercitor does not have the
restriction to low-coercion elections of Helios.

VIII. CONCLUSION

We propose coercion-evidence - a new property for e-
voting systems that can replace coercion-resistance and

1markryan.eu/research/caveat-coercitor/

377

improve usability of electronic voting systems. Our formal
deﬁnition is general enough to permit the veriﬁcation of
coercion-evidence in various systems and different security
models. We also propose Caveat Coercitor - a voting system
in which coercion is only weakly resisted, but made evident.
The ability of a coercer is limited, because the best the
coercer can achieve is the annulment of a voter’s vote. A
major feature of the system is that the degree of coercion
that actually took place is publicly veriﬁable, provided the
coerced voters follow the instructions of the protocol and
cast votes for their desired candidate. This means that the
coercer has only little incentive to coerce. Any observer can
check if the coercion (that is, the annulled votes) could have
made a material difference to the outcome.

To the best of our knowledge, our work is the ﬁrst to pro-
pose a remote voting system with incoercibility properties
that does not rely on an untappable channel. It is also the
ﬁrst paper to realise the importance of considering “silent”
coercion (coercion unknown to the voter being coerced, for
example by leaked credentials) together with coercion that
is known to the voter.

Future work: As already indicated, the idea of coercion
tolerance (with evidence) seems well-suited to addressing
the problem of how to vote on untrusted machines. We
speculated a bit about this in our discussion section, and
intend to work on it further. We would also like to de-
velop implementations, perhaps based on those of Helios
or JCJ/Civitas, and see how they work in practice. It would
also be interesting to explore how the concept of coercion
evidence could be applied in other contexts than E-voting.

IX. ACKNOWLEDGEMENTS

We thank Jeremy Clark, Miriam Paiola and the anony-
mous reviewers for very useful comments. This work has
been partially funded by the UK Engineering and Physical
Sciences Research Council (EPSRC), under the project
“TVS: Trustworthy Voting Systems” (EP/G02684X/1), and
the Luxembourg National Research Fund (FNR), under the
project SeRTVS-C09/IS/06.

REFERENCES

[1] Mart´ın Abadi and C´edric Fournet. Mobile values, new names,
and secure communication.
the 28th
ACM Symposium on Principles of Programming Languages
(POPL’01), pages 104–115, January 2001.

In Proceedings of

[2] Ben Adida. Helios: Web-based open-audit voting. In Paul C.
van Oorschot, editor, USENIX Security Symposium, pages
335–348. USENIX Association, 2008.

[3] Ben Adida, Olivier Pereira, Olivier De Marneffe, and Jean-
Jacques Quisquater. Electing a university president using
open-audit voting: Analysis of real-world use of helios.
In
In Electronic Voting Technology/Workshop on Trustworthy
Elections (EVT/WOTE), 2009.

[4] Roberto Araujo, S´ebastien Foulle, and Jacques Traor´e. A
practical and secure coercion-resistant scheme for internet
voting.
In David Chaum, Markus Jakobsson, Ronald L.
Rivest, Peter Y. A. Ryan, Josh Benaloh, Miroslaw Kuty-
lowski, and Ben Adida, editors, Towards Trustworthy Elec-
tions, volume 6000 of Lecture Notes in Computer Science,
pages 330–342. Springer, 2010.

[5] Michael Backes, Catalin Hritcu, and Matteo Maffei. Auto-
mated veriﬁcation of remote electronic voting protocols in the
applied pi-calculus. In CSF, pages 195–209, 2008.

[6] Bruno Blanchet. Automatic proof of strong secrecy for
In IEEE Symposium on Security and

security protocols.
Privacy, pages 86–100, 2004.

[7] Bruno Blanchet, Mart´ın Abadi, and C´edric Fournet. Au-
tomated veriﬁcation of selected equivalences for security
protocols.
Journal of Logic and Algebraic Programming,
75(1):3–51, 2008.

[8] Felix Brandt. Efﬁcient cryptographic protocol design based
on distributed el gamal encryption.
In Dongho Won and
Seungjoo Kim, editors, ICISC, volume 3935 of Lecture Notes
in Computer Science, pages 32–47. Springer, 2005.

[9] Sergiu Bursuc, Gurchetan S. Grewal, and Mark D. Ryan.
In Kiayias and

Trivitas: Voters directly verifying votes.
Lipmaa [17], pages 190–207.

[10] David Chaum. Untraceable electronic mail, return addresses
and digital pseudonyms. In Dimitris Gritzalis, editor, Secure
Electronic Voting, volume 7 of Advances in Information
Security, pages 211–219. Springer, 2003.

[11] Jeremy Clark and Urs Hengartner. Selections: Internet vot-
In George
ing with over-the-shoulder coercion-resistance.
Danezis, editor, Financial Cryptography, volume 7035 of
Lecture Notes in Computer Science, pages 47–61. Springer,
2011.

[12] Michael R. Clarkson, Stephen Chong, and Andrew C. Myers.
Civitas: Toward a secure voting system. In IEEE Symposium
on Security and Privacy, pages 354–368. IEEE Computer
Society, 2008.

[13] St´ephanie Delaune, Steve Kremer, and Mark D. Ryan. Ver-
ifying privacy-type properties of electronic voting protocols.
Journal of Computer Security, 17(4):435–487, July 2009.

[14] Markus Jakobsson and Ari Juels. Mix and match: Secure
function evaluation via ciphertexts. In Tatsuaki Okamoto, ed-
itor, ASIACRYPT, volume 1976 of Lecture Notes in Computer
Science, pages 162–177. Springer, 2000.

[15] Markus Jakobsson, Ari Juels, and Ronald L. Rivest. Making
mix nets robust for electronic voting by randomized partial
checking. In Proceedings of the 11th USENIX Security Sym-
posium, pages 339–353, Berkeley, CA, USA, 2002. USENIX
Association.

[16] Ari Juels, Dario Catalano, and Markus Jakobsson. Coercion-
resistant electronic elections. In Vijay Atluri, Sabrina De Cap-
itani di Vimercati, and Roger Dingledine, editors, WPES,
pages 61–70. ACM, 2005.

378

[17] Aggelos Kiayias and Helger Lipmaa, editors.

E-Voting
and Identity - Third International Conference, VoteID 2011,
Tallinn, Estonia, September 28-30, 2011, Revised Selected
Papers, volume 7187 of Lecture Notes in Computer Science.
Springer, 2012.

[18] Ralf K¨usters and Thomasz Truderung. An Epistemic Ap-
proach to Coercion-Resistance for Electronic Voting Proto-
cols. In 2009 IEEE Symposium on Security and Privacy (S&P
2009), pages 251–266. IEEE Computer Society, 2009.

[19] Byoungcheon Lee, Colin Boyd, Ed Dawson, Kwangjo Kim,
Jeongmo Yang, and Seungjae Yoo. Providing receipt-freeness
in mixnet-based voting protocols.
In Jong In Lim and
Dong Hoon Lee, editors, ICISC, volume 2971 of Lecture
Notes in Computer Science, pages 245–258. Springer, 2003.

[20] Torben P. Pedersen. Non-interactive and information-theoretic
secure veriﬁable secret sharing. In Joan Feigenbaum, editor,
CRYPTO, volume 576 of Lecture Notes in Computer Science,
pages 129–140. Springer, 1991.

[21] Michael Schl¨apfer, Rolf Haenni, Reto E. Koenig, and Oliver
Spycher. Efﬁcient vote authorization in coercion-resistant
internet voting. In Kiayias and Lipmaa [17], pages 71–88.

APPENDIX A.

PROOFS FOR SECTION VI-A

Lemma 1: For all run τ of Caveat Coercitor, we have

δc(τ ) ⊆ Icast(τ ) ⊆ δc(τ ) ∪ δd(τ ) ∪ Fcast(τ )

Proof: First we prove that δc(τ ) ⊆ Icast(τ ). Let
s ∈ δc(τ ) be the credential of coerced voter A in a run τ. By
deﬁnition of coerced voters and since by our assumptions
A has access to a trusted voting device, there exist two
ballots in BBcast(τ ) corresponding to s and two different
votes v, v(cid:2): B(s, v) ∩ BBcast(τ ), B(s, v(cid:2)) ∩ BBcast(τ ) and
v (cid:3)= v(cid:2). Therefore, we have s ∈ Icast(τ ).
Let us now prove that Icast(τ ) ⊆ δc(τ )∪ δd(τ )∪Fcast(τ ).
Let s ∈ Icast(τ ) and assume that s /∈ Fcast(τ ). We
show that s ∈ δc(τ ) ∪ δd(τ ). By deﬁnition of Icast(τ ),
(cid:3)= vj and
there exist v1, . . . , vn, such that n > 1, vi
B(s, vi) ∩ BBcast(τ ) (cid:3)= ∅, for all 1 ≤ i, j ≤ n. By deﬁnition
of coerced and dishonest voters, we have
• if all ballots that are cast by A belong to B(s, vi), for a
unique i, 1 ≤ i ≤ n, then A is coerced and s ∈ δc(τ ).
• otherwise, either A has cast two different votes or A
did not cast a vote, and we have s ∈ δd(τ ).
Hence we can conclude that s ∈ δc(τ ) ∪ δd(τ ) ∪ Fcast(τ ).

Lemma 2: For all run τ of Caveat Coercitor in which the

mixnet proofs are valid, we have

Itally(τ ) = Icast(τ ) and Ftally(τ ) = Fcast(τ )

Proof:

From deﬁnitions, we observe that to conclude the lemma
it is sufﬁcient to show that for all credential s and all vote

379

v, we have |B(s, v)∩BBcast(τ )| = |B0(s, v)∩BBtally(τ )|. In
words, this means that no ballots have been lost or added to
the tally during the mixing phase. This follows immediately
from the validity of mixnet proofs.

Lemma 3: For all run τ of Caveat Coercitor, we have

|BBce(τ )| = |Itally(τ ) (cid:2) Ftally(τ )|

ce

ce

|BBpriv

Proof: Let BBpriv

We have s ∈ BBpriv

(τ )| = |BBce(τ )| and therefore it
(τ ) = Itally(τ ) (cid:2) Ftally(τ ).

(τ ) be the set of private credentials
that corresponds to the public credentials in BBce(τ ). We
is
note that
sufﬁcient to show that BBpriv
pk ∈ BBaer(τ )
and ({s}r1
such that
pet(V1, V2) (cid:3)= ok ⇔ s ∈ E(τ ) and ∃v1 (cid:3)= v2 such that
B0(s, v1) ∩ BBtally(τ ) (cid:3)= ∅ and B0(s, v2) ∩ BBtally(τ ) (cid:3)= ∅
⇔ s ∈ Itally(τ ) (cid:2) F(τ ).

pk , V2) ∈ BBtally(τ )

pk , V1), ({s}r2

(τ ) ⇔ ∃{s}r

ce

ce

Lemma 4: For all run τ of Caveat Coercitor, we have

cecred

cc (τ ) = BBce(τ )

2 , V 0

1 ), (S0

Proof: We prove ﬁrst that BBce(τ ) ⊆ cecred

cc (τ ). If S0 ∈
2 ) ∈ BBtally(τ )
1 , V 0
BBce(τ ), then there exist (S0
2 ) (cid:3)=
1 ) = pet(S0, S0
such that pet(S0, S0
2 )) (cid:3)= ok there exist cani, canj with 1 ≤
ok. As pet(V 0
i, j ≤ such that pet(cani, V 0
2 ) =
1 ) ∈
ok. After the Step 1 of the Algorithm 3, we have (S0
2 ) ∈ Bj. Without loss of generality, let us
Bi and (S0
suppose that i < j and that i, j are the smallest indices with
these properties.

1 ) = ok and pet(canj, V 0
1 , V 0

2 ) = ok, pet(V 0

1 , V 0

1 , V 0

2 , V 0

2 ,V 0

1 ,V 0

1 ) ∈ Bi and (S0

To prove the inverse inclusion, consider S ∈ cccred

Therefore, during the step 2 of the Algorithm 3, when S0
2 ) ∈
is considered for the role of S, (S0
Bj can be considered for the role of (S1, V1) and (S2, V2).
Thus, we have S ∈ cecred
ce (τ ).
This means there exist Bi,Bj such that there are (S1, V1) ∈
Bi, (S2, V2) ∈ Bj and pet(cani, V1) = ok, pet(canj, V2) =
ok and pet(S1, S) = ok = pet(S, S2). Therefore, we can
conclude S ∈ BBce(τ ).

cc (τ ).

APPENDIX B.

PROOFS FOR SECTION VI-B

Construction of

the run τ(cid:2). The main idea in the
construction of τ(cid:2) is to rely on the free voter A(cid:2) in the
voting phase so that the ballots of A(cid:2) in the run τ(cid:2) look like
the ballots of A in the run τ, and the other way around.
Furthermore, we rely on an honest re-encryption mix server
to ensure that the coercer can not track the ballots back to A
or to A(cid:2). The honest mix server swaps the ballots of A and
A(cid:2) and also their credentials in the anonymized electoral
roll. An honest tabulation tallier ensures that the tallying
is performed according to the speciﬁcation of the protocol,
both in τ and in τ(cid:2).

For a run τ = τvote.τer.τmix.τtally as the one in section
mix

tally, where τ(cid:2)

vote.τer.τ(cid:2)

vote, τ(cid:2)

mix.τ(cid:2)

VI-B, we let τ(cid:2) = τ(cid:2)
and τ(cid:2)

tally are deﬁned in the following.

Voting phase. We have by deﬁnition at least three par-
ticular ballots present in τvote (recall that we consider the
case when the coercer has cast a vote for vC, vC (cid:3)= vA,
using the credential sA): two with credential sA and one
with credential sA(cid:2). Without loss of generality, we ﬁx an
order for these three ballots on the bulletin board. Then, we
have:

τvote = L1.bsA,vC .L2.bsA,vA .L3.bsA(cid:2) ,vC .L4

where bsA,vC ∈ B(sA, vC), bsA,vA ∈ B(sA, vA),
bsA(cid:2) ,vC ∈ B(sA(cid:2) , vC) and L1,L2,L3,L4 are lists of ballots.
Furthermore, for any 1 ≤ (cid:5) ≤ 4, if there is a ballot in Li that
corresponds to the credential sA(cid:2), then the corresponding
vote is vC.

Let cA and respectively cA(cid:2) be the public credentials that
correspond to the private credentials sA and sA(cid:2). Then,
without loss of generality, we can assume that the electoral
roll is

τer = S1.cA.S2.cA(cid:2) .S3

where S1, S2 and S3 are the public credentials of other
voters. Now, for some bsA(cid:2) ,vA ∈ BsA(cid:2) ,vA, let us consider
τ(cid:2)
vote deﬁned as follows

τ(cid:2)
vote = L1.bsA,vC .L2.bsA(cid:2) ,vA .L3.bsA(cid:2) ,vC .L4
Hence, τ(cid:2)

vote is the same as τvote, with the difference that
A now follows the instructions of the coercer and does not
cast a vote for the intended candidate, while the free voter
A(cid:2) becomes dishonest, and casts an additional ballot for the
candidate intended by A.

mix

mix.τ 1

i.e. τ 0

mix, where:

mix.τ h
is the input

mix is the output of (dishonest) mix servers that are present

Mixing phase. According to our trust assumptions, there is
at least one mix server that is not controlled by the coercer.
mix.τ 2
Let τmix = τ 0
• τ 0
mix =
to the mix network,
vote.τer.τcand, where τ 0
τ 0
vote contains the ballots from τvote,
but not their corresponding zero-knowledge proofs, and τcand
is a list of encrypted candidate names (to be used in the
coercion-evidence test, cf Algorithm 2).
• τ 1
in the mixnet before the honest mix server.
• τ h
mix is the output of the honest mix server.
• τ 2
mix is the output of (dishonest) mix servers that are present
in the mixnet after the honest mix server.
mix.τ(cid:2)h
Now, we consider τ(cid:2)
mix = τ(cid:2)0
mix.τ(cid:2)1
• τ(cid:2)0
mix = τ(cid:2)0
er.τ(cid:2)
cand, where τ(cid:2)0
vote contains the ballots
from τ(cid:2)
their corresponding zero-knowledge
vote, but not
proofs,, and τ(cid:2)
• τ(cid:2)1
same operations as for constructing τ 1

mix by applying exactly the
mix. This

mix is constructed from τ(cid:2)0

er = τer, τ(cid:2)

mix from τ 0

cand = τcand.

mix, where:

mix.τ(cid:2)2

vote.τ(cid:2)

380

possible because these operations consist only in perform-
ing re-encryptions and applying permutations to the set of
ballots: they do not depend on the content of ballots.
• τ(cid:2)h
that τ 0
τ 0
vote.τer.τcand, where τ 0
knowledge proofs of correctness, i.e. we have

is constructed as follows. Recall

mix =
the zero-

is τvote without

vote

mix

τ 0
vote = L0

1.b0

sA,vC .L0

2.b0

sA,vA .L0

3.b0
A,vC .L0
s(cid:2)

4

where we denote by b0 (resp. L0) a ballot b (resp. a list
of ballots L) stripped of its proofs. Let τ ih
mix be the input
for the honest mix server in τmix, i.e. the output of the
last dishonest server in τ 1
mix. Relying on the zero-knowledge
proofs that have to be provided by any mix server (including
the dishonest ones), we deduce that τ ih
mix = ρ1.ρ2.ρ3 where
ρ1, ρ2 and respectively ρ3 are re-encryption mixes of τ 0
vote,
τer and respectively τcand, with some permutations chosen
by the coercer. Thus, we have

ρ1 = L1.w1.L2.w2.L3.w3.L4
ρ2 = S1.t1.S2.t2.S3

is

where w1.w2.w3
a
sA,vA .b0
b0
sA,vC .b0
A,vC and t1.t2
s(cid:2)
of cA.cA(cid:2). Furthermore, τ h
1 ≤ i ≤ 3, ρh
permutation chosen by the honest mix server. Let:

re-encryption mix
of
is a re-encryption mix
1 .ρh
3, where, for every
is a re-encryption mix of ρi, with some

mix = ρh

2 .ρh

i

1 .wh
1 .th

1 .Lh
1 .Sh

2 .wh
2 .th

2 .Lh
2 .Sh
3

3 .wh

3 .Lh
4

ρh
1 = Lh
2 = Sh
ρh
2 .wh

3

3.L4

1 .wh

mix = ρ(cid:2)

mix is τ(cid:2)ih

mix,
1.ρ2.ρ3,

1.L2.w(cid:2)
a

3 is a re-encryption mix of w1.w2.w3 and

where wh
th
1 .th
2 is a re-encryption mix of t1.t2.
On the other hand, according to our construction of τ(cid:2)1
the input to the honest mix server in τ(cid:2)
where

ρ(cid:2)
2.L3.w(cid:2)
1 = L1.w(cid:2)
w(cid:2)
2.w(cid:2)
1.w(cid:2)
is
and
re-encryption
of
sA(cid:2) ,vC such that, for every 1 ≤ i ≤ 3, if
sA(cid:2) ,vA .b0
sA,vC .b0
b0
i ∈ B0(sA, vC) or w(cid:2)
i ∈ B0(sA(cid:2) , vC), then w(cid:2)
w(cid:2)
i = wi. Thus,
as in the case of the pair (τvote, τ(cid:2)
vote), the only difference
mix is that, for some 1 ≤ i ≤ 3, we
between τ(cid:2)ih
have w(cid:2)
In the run τ(cid:2) the output of the honest mix server must
be τ(cid:2)h
h.ρ(cid:2)h
3, corresponding to re-encryption
mixes of ρ(cid:2)
1, ρ2 and ρ3. Relying on the fact that the mix
server producing τ(cid:2)h
mix is honest, we can choose particular
permutations and particular randoms for the re-encryption
mixes that produce τ(cid:2)h
mix. We choose these such that we
have the following:

i ∈ B0(sA(cid:2) , vA) and wi ∈ B0(sA, vA).
mix = ρ(cid:2)

mix and τ ih

2 .ρ(cid:2)h

mix

1

1 .w(cid:2)h
1 .t(cid:2)h

2 .w(cid:2)h
2 .Lh
2 .t(cid:2)h
2 .Sh
3

1 .Lh
1 .Sh

3 .w(cid:2)h

3 .L

ρ(cid:2)h
1 = Lh
ρ(cid:2)h
2 = Sh
2 .w(cid:2)h
1 .w(cid:2)h

where w(cid:2)h
t(cid:2)h
1 .t(cid:2)h

3 is a re-encryption mix of w(cid:2)
2 is a re-encryption mix of t1.t2 such that:

1.w(cid:2)

2.w(cid:2)

3 and

c .τ(cid:2)

c . . . τ(cid:2)n

tally = τ(cid:2)

buckets.τ(cid:2)1

been coerced or dishonest.
valid.τ(cid:2)

Then, we let τ(cid:2)
dec, where:
• because sA and sA(cid:2) are valid credentials by assumption,
we note that the set of ballots with ineligible credentials
vote and τ(cid:2)out
is exactly the same in τ out
vote. Therefore, if
valid = τ(cid:2)out
vote (cid:2)S, then we can choose τ(cid:2)
τvalid = τ out
vote (cid:2)S.
vote, τ(cid:2)out
• from our
(τ out
vote)
and
, τ(cid:2)out
(τ out
er ), it follows that the plaintext equivalence
tests from algorithm 2 and the decryption of the
ﬁnal outcome give exactly the same results
for
(τvalid, τ out
er ). Therefore, we can
c, for all 1 ≤ i ≤ n,
choose τ(cid:2)
c = τ i
and τ(cid:2)

er ) and (τ(cid:2)
valid, τ(cid:2)out
buckets = τbuckets, τ(cid:2)i

observation

dec = τdec.

about

er

This way we ﬁnish the construction of τ(cid:2).
Indistinguishability of τ and τ(cid:2).
The

available

code

online

veriﬁes

runs of

ProVerif

(Pcc, P (cid:2)

a bi-process

equivalence of

at
the
markryan.eu/research/caveat-coercitor
cc),
observational
the form (τ, τ(cid:2)), as
which generates pairs of
described in section VI-B. Pcc and P (cid:2)
cc share the same
structure and differ only on some (internal) messages. This
difference can be expressed in ProVerif with the construct
choice[u, v]: the process Pcc (also called the left process)
uses the term u, whereas the process P (cid:2)
cc (the right process)
uses the term v. To model the difference between the runs
τ and τ(cid:2) from Caveat Coercitor all we need is to make sure
that the ballots that are cast are as expected. Then, ProVerif
explores all the possible runs starting from that.

i ∈ B0(sA, vC).
i ∈ B0(sA, vA)
i ∈ B0(sA(cid:2) , vC)
1 , cA(cid:2) ) = ok
2 , cA) = ok

i ∈ B0(sA(cid:2) , vC) ⇔ wh
i ∈ B0(sA(cid:2) , vA) ⇔ wh
i ∈ B0(sA, vC) ⇔ wh
1 , cA) = ok ⇔ pet(th
2 , cA(cid:2) ) = ok ⇔ pet(th

• w(cid:2)h
• w(cid:2)h
• w(cid:2)h
• pet(t(cid:2)h
• pet(t(cid:2)h
Intuitively, the two ballots from A(cid:2) and the ballot from A
are re-arranged in the run τ(cid:2)
mix by the honest mix server so
that the plaintext equivalence tests performed for coercion-
evidence will succeed for the same positions in τ(cid:2) as in τ,
and also the vote for vC is revealed in the same position.
Furthermore, the credentials of A and A(cid:2) are swapped on
the electoral roll, so that the credential that is marked as
coerced is at the same position in both runs.

mix is constructed from τ(cid:2)h

mix by performing exactly
the same operations as for constructing τ 2
mix from τmixh.
This is possible because the operations performed by a re-
encryption mix server do not depend on the content of
ballots.

mix and respectively τ(cid:2)out

Tallying phase. Let τ out

mix be the
outcome of the re-encryption mix net after the (partial) runs
τvote.τmix and τ(cid:2)
mix. Note that τ out
cand and
cand, where for all a ∈ {vote, er, out},
τ(cid:2)out
mix = τ(cid:2)out
τ out
is a re-enncryption mix of τa and
a
respectively τ(cid:2)

a. Furthermore, by construction we have:

mix = τ out

vote.τ out
er

• τ(cid:2)2

.τ out

a

er = t(cid:2)

1 . . . t(cid:2)

n such that for every

• τ out
• τ out

cand

vote.τ(cid:2)
vote.τ(cid:2)out
er .τ(cid:2)out
and respectively τ(cid:2)out
cand = τ(cid:2)out
er = t1 . . . tn and τ(cid:2)out
1 ≤ i ≤ n, we have
– either t(cid:2)
i = ti
– or else pet(t(cid:2)
– or else pet(t(cid:2)
vote = w1 . . . wm and τ(cid:2)out
every 1 ≤ i ≤ m, we have
– either w(cid:2)
– or else w(cid:2)
– or else w(cid:2)
– or else w(cid:2)

• τ out

i, cA) = ok and pet(ti, cA(cid:2) ) = ok
i, cA) = ok and pet(ti, cA(cid:2) ) = ok

vote = w(cid:2)

1 . . . w(cid:2)

m such that for

i = wi
i ∈ B0(sA(cid:2) , vC) and wi ∈ B0(sA, vC)
i ∈ B0(sA(cid:2) , vA) and wi ∈ B0(sA, vA)
i ∈ B0(sA, vC) and wi ∈ B0(sA(cid:2) , vC)

The trust assumptions for Caveat Coercitor ensure that
there is at least one honest tallier. The honest tallier will
follow the protocol and will not reveal his share of the
decryption key to the coercer. Therefore, the only way to
complete any run in the tallying phase for the coercer is
to obey the speciﬁcation of the protocol. Thus, we have
τtally = τvalid.τbuckets.τ 1

c .τdec, where

c . . . τ n

• τvalid are the ballots from τ out
vote with eligible credentials
• τbuckets is the outcome of plaintext equivalence tests that
are performed to group the ballots according to the vote
that they contain (step 1 of algorithm 2)

• for every 1 ≤ i ≤ n, τ i

c represents the outcome of
plaintext equivalence tests performed to determine if the
voter with credential ti is coerced (step 2 of algorithm
2)

• τdec represents the result of decrypting ballots with
valid credentials whose corresponding voters have not

381

