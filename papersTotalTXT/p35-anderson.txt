Identifying Encrypted Malware Traffic 

with Contextual Flow Data

Blake Anderson

Cisco

David McGrew

Cisco

blake.anderson@cisco.com

mcgrew@cisco.com

ABSTRACT
Identifying threats contained within encrypted network traf-
ﬁc poses a unique set of challenges. It is important to mon-
itor this traﬃc for threats and malware, but do so in a way
that maintains the integrity of the encryption. Because pat-
tern matching cannot operate on encrypted data, previous
approaches have leveraged observable metadata gathered
from the ﬂow, e.g., the ﬂow’s packet lengths and inter-arrival
times. In this work, we extend the current state-of-the-art
by considering a data omnia approach. To this end, we
develop supervised machine learning models that take ad-
vantage of a unique and diverse set of network ﬂow data
features. These data features include TLS handshake meta-
data, DNS contextual ﬂows linked to the encrypted ﬂow,
and the HTTP headers of HTTP contextual ﬂows from the
same source IP address within a 5 minute window.

We begin by exhibiting the diﬀerences between malicious
and benign traﬃc’s use of TLS, DNS, and HTTP on millions
of unique ﬂows. This study is used to design the feature sets
that have the most discriminatory power. We then show
that incorporating this contextual information into a super-
vised learning system signiﬁcantly increases performance at
a 0.00% false discovery rate for the problem of classifying
encrypted, malicious ﬂows. We further validate our false
positive rate on an independent, real-world dataset.

Keywords
Encryption; Malware; Machine Learning; Transport Layer
Security; Network Monitoring

1.

INTRODUCTION

With an increasing amount of encrypted network traﬃc,
the burden of determining its trustworthiness is becoming
too onerous a task for most incident response teams. Tradi-
tional approaches of identifying threats, such as deep packet
inspection and signatures, are not applicable on encrypted
traﬃc. Solutions that decrypt network traﬃc weaken the
privacy of the users, do not work for all encryption, and are

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
AISec’16, October 28 2016, Vienna, Austria
c(cid:13) 2016 ACM. ISBN 978-1-4503-4573-6/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2996758.2996768

computationally intensive. Furthermore, these solutions’ re-
liance on the conﬁguration of a cooperating endpoint makes
it challenging to deploy, and limits its applicability.

In this paper, we do not propose decrypting the network
traﬃc. We instead focus on identifying malware communi-
cation in encrypted traﬃc through passive monitoring, the
extraction of relevant data features, and supervised machine
learning based on a large set of sandbox malware samples
and data collected at a large enterprise network. We make
the following novel contributions:

1. We provide the ﬁrst results that leverage contextual
information, i.e., DNS responses and HTTP headers,
to identify threats in encrypted traﬃc.

2. We demonstrate highly accurate, with respect to a
0.00% false discovery rate, machine learning algorithms
that operate on this data.

3. Finally, we provide a real-world validation of the meth-
ods we develop, demonstrating that our results are not
simply due to overﬁtting.

Given the unique set of challenges that threat detection on
encrypted traﬃc presents, and our desire to develop machine
learning models that are as robust as possible, it is natural
to consider including all possible data views associated with
an encrypted ﬂow. We term this viewpoint the data omnia
approach. Conceptually, this can be achieved by extending
ﬂow records to contain all metadata about a ﬂow, such as
the unencrypted TLS handshake information, and pointers
to “contextual” ﬂows. We deﬁne DNS contextual ﬂows to be
DNS responses correlated with the TLS ﬂow based on desti-
nation IP address, and contextual HTTP ﬂows to be HTTP
ﬂows originating from the same source IP address within a
5 minute window. This approach is distinct from existing
multiple ﬂow techniques because it uses detailed information
about the ﬂow and contextual ﬂows, and not simply the ﬂow
metadata. For example, Figure 1 demonstrates how we can
link a DNS ﬂow with a TLS ﬂow, and the type of additional
information that this approach makes available.

We provide an in-depth analysis of the TLS handshake
metadata and two contextual ﬂow types that we found to
be particularly relevant for identifying threats in encrypted
traﬃc. Unlike previous work, we present a detailed analysis
of the protocol feature values that diﬀer between malicious
and benign traﬃc. Our motivation for making these obser-
vations public was that any motivated threat actor, given
the feature type, which in most cases has been published in
the open literature, could observe benign traﬃc and attempt
to modify their servers and clients to mimic the observed

35work’s DMZ for a 5 day period in April 2016. This process
resulted in tens-of-millions of malicious and benign ﬂows.
We realize that the DMZ traﬃc does contain a small amount
of malware traﬃc, but for the purpose of this paper, we refer
to this traﬃc as benign. Our analysis tools were based on
Python and Scikit-learn [32].

In this paper, we show that the data omnia approach is
both practical and valuable. For our machine learning appli-
cations, we take a bottom-up approach. From the data that
we collected, we ﬁrst identify data features of TLS, DNS,
and HTTP that have discriminatory power. We then show
that machine learning algorithms can be deﬁned using these
data features that can correctly classify their respective ﬂow
types. Finally, we leverage the context that the HTTP and
DNS ﬂows provide to help classify TLS encrypted network
ﬂows. When processing tens-of-millions of ﬂows each day,
high total accuracy with even a modest false discovery rate
can overwhelm an analyst. For this reason, instead of total
accuracy, we focus our results on an accuracy at a 0.00% false
discovery rate, that is, an FDR of zero with four signiﬁcant
ﬁgures. To further defend the false positive rates presented
in this paper, and to conﬁrm that our results were not sim-
ply due to overﬁtting on the initial datasets and feature sets,
we also ran experiments on an additional validation dataset
collected ∼4 weeks after the initial benign dataset.

We embrace supervised machine learning as the best way
to use previously observed malware communications to de-
tect encrypted malware communications. A machine learn-
ing classiﬁer provides the most direct way to build a de-
tector, and it can also provide a probability estimate. Su-
pervised learning provides grounded and easily interpretable
results, unlike anomaly detection [36]. Importantly, regular-
ization can be used during classiﬁer training to select the
data features that have the most discriminatory power [21],
which is essential to our data omnia approach. Lastly, there
are classiﬁers that are robust against overﬁtting [23]; by us-
ing these, we avoid that pitfall. In Section 6, we further de-
fend these claims by demonstrating that eﬃcient algorithms,
whose results can be easily interpreted, have equivalent per-
formance to ineﬃcient, black-box models on this data.

The remainder of this paper is organized as follows: Sec-
tion 2 details our in-depth TLS study, Section 3 details
our in-depth DNS study, and Section 4 details our in-depth
HTTP study. Section 5 reviews our datasets and extracted
features, and Section 6 presents our classiﬁcation results.
Finally, Section 7 reviews background material and related
work, and we conclude in Section 8.

2. MALWARE AND TLS

Malware and benign traﬃcs’ usage of TLS is quite dis-
tinct. In this section, we detail these diﬀerences from the
perspective of the client by examining the oﬀered cipher-
suites, the advertised TLS extensions, and the client’s pub-
lic key length. We also look at the diﬀerences in the server’s
TLS implementation by examining the selected ciphersuite
and information gathered from the server certiﬁcates. We
collected 21,417 malicious TLS ﬂows that had the full TLS
handshake from ThreatGRID [2] between January 2016 and
April 2016, and 1,130,386 benign TLS ﬂows using the same
criteria during a 5 day period in April 2016. Our tool was
used to parse the TLS ﬂows. It collected all of the informa-
tion contained in the unencrypted TLS handshake messages.

Figure 1: An illustration of a TLS ﬂow and a DNS contex-
tual ﬂow, showing the data elements used to link the ﬂows
(in red), the data elements brought in as context (in green),
and the TLS unencrypted header information collected as
metadata (unmarked).

behavior. On the other hand, by obfuscating the feature
values, we increase the diﬃculty for incident responders to
write and deploy indicators of compromise.

The ﬁrst type of contextual ﬂow that we analyze is the
DNS response that provides the address used by an en-
crypted ﬂow, and the TTL associated with the name. Hav-
ing the domain name for an IP address provides a lot of
meaningful information on its own. Among TLS ﬂows, this
information can sometimes be gathered from the server name
indication extension or the subject of the server certiﬁcate.
But, the SNI extension is optional and there will be no server
certiﬁcate in the case of TLS resumption. In these cases, the
contextual DNS ﬂow has the potential to provide informa-
tion which would otherwise be unavailable. Additionally,
as we outline in this paper, malicious DNS responses have
characteristics that can distinguish them from benign DNS
responses, and we can use this information to more accu-
rately classify the corresponding TLS encrypted ﬂow.

In addition to DNS ﬂows, which can be directly corre-
lated with the TLS encrypted ﬂows, we analyze the HTTP
headers of HTTP contextual ﬂows. There have been sev-
eral rule-based systems and machine learning classiﬁers that
have been based on HTTP data [29, 33], and we build on
these studies by taking advantage of HTTP header informa-
tion to help classify encrypted ﬂows. There are also several
interesting rule-based inferences that can be made by cor-
relating HTTP data with the unencrypted TLS handshake
metadata. For instance, the TLS oﬀered ciphersuite list and
extensions can be used to infer the cryptographic library and
version in use, which in turn can be used to infer the user-
agent that initiated the ﬂow. Finding discrepancies between
the user-agent that a ﬂow advertises in its HTTP ﬁelds and
the user-agent inferred from the adjacent, encrypted ﬂow’s
TLS parameters is a useful indicator of compromise.

We wrote a custom libpcap-based tool [25, 26] to cap-
ture our data features from live traﬃc, and to process mal-
ware packet capture ﬁles. This tool was run on malicious
packet capture ﬁles collected from ThreatGRID [2], a com-
mercial sandbox environment, between January 2016 and
April 2016. This tool was also run on a large enterprise net-

36Figure 2: TLS Statistics, revealing the diﬀerent prevalence of feature values for malware (red) and benign (blue).

The unencrypted TLS metadata contained in the clien-
tHello and clientKeyExchange messages contains valuable
information that can be used to make inferences about the
client’s TLS library. We have also observed that these fea-
tures are quite diﬀerent in our malware and benign datasets;
the implication being that malware authors use a distinct set
of TLS libraries and/or conﬁgurations. Figure 2 illustrates
diﬀerences in two client-side TLS features: the oﬀered ci-
phersuites and the advertised extensions. Using standard
guidelines and industry recommendations [39], TLS cipher-
suites can be segmented into acceptable and obsolete cate-
gories. We can see that malware usually oﬀers a set of three
obsolete ciphersuites in the clientHello message including
0x0004 (TLS_RSA_WITH_RC4_128_MD5). In the benign traﬃc
we collected, the 0x002f (TLS_RSA_WITH_AES_128_CBC_SHA)
ciphersuite was the most oﬀered. Malware also seems to
have comparatively little diversity in the client-supported
TLS extensions. 0x000d (signature_algorithms) was the
only TLS extension supported in the majority of TLS ﬂows.
∼50% of the DMZ traﬃc also advertised the following ex-
tensions, which were rarely seen in the malware dataset:

• 0x0005 (status request)
• 0x3374 (next protocol negotiation)
• 0xff01 (renegotiation info)
Although not shown, the client’s public key length was
another client-based data feature that had signiﬁcant diﬀer-
ences. Most of the DMZ traﬃc used 256-bit elliptic curve

cryptography for the public keys, but most of the malicious
traﬃc used 2048-bit RSA public keys.

The serverHello and certificate messages can be used
to gain information about the server. The serverHello mes-
sage contains the selected ciphersuite and supported exten-
sions. As one would expect given the type and diversity of
the oﬀered ciphersuites and the advertised extensions, the
malicious traﬃc most often selected obsolete ciphersuites.
The DMZ traﬃc contained a wider variety of supported TLS
extensions by the servers.

The certificate message passes the server’s certiﬁcate
chain to the client. We observed that the number of cer-
tiﬁcates in the chain for the malware and DMZ data were
roughly the same. But, if we restrict our focus on the length-
1 chains, ∼70% were self-signed for malware and ∼.1% were
self-signed for the DMZ traﬃc. The number of names in
the SubjectAltName (SAN) X.509 extension also diﬀered in
the two datasets. For the DMZ traﬃc, the length of the list
was 1 ∼45% of the time. This is in part because a num-
ber of Content Distribution Network (CDN) providers, e.g.,
Akamai, only have one entry. Length-10/12 lists were also
common in the DMZ traﬃc due to some ad services.

Figure 2 also shows the distribution of the validity of the
certiﬁcates rounded to the nearest day. Similar to the other
data features, the period of validity for a server certiﬁcate
has notable diﬀerences in the malicious and DMZ traﬃc.
Combining the certiﬁcate information with information from

37Figure 3: Statistics of DNS ﬂows linked to TLS ﬂows, revealing the diﬀerent prevalence of feature values for malware (red)
and benign (blue).

the client can help improve classiﬁer performance, and help
attributed encrypted ﬂows to speciﬁc malware families [6].

3. MALWARE AND DNS

In this section, we systemically compare malware’s use of
DNS to that of benign’s. Using the same data sources as
the previous section, we collected 6,906,627 malicious and
8,060,064 benign DNS responses. Our tool was used to per-
form the DNS parsing of the malware packet capture ﬁles
and live DMZ data.

From a signature perspective, domain names provided by
DNS are less dynamic than the associated IP addresses,
which allows for more robust blacklists. This information
also provides visibility into encrypted ﬂows that is missing
in many cases. In some cases, the server name indication
(SNI) TLS extension and the subject / subject alternative
names (SANs) in the server certiﬁcate can provide this in-
formation. In the case of TLS session resumption, the cer-
tiﬁcate will not be present, and with the release of TLS 1.3,
the server certiﬁcate will most likely be encrypted. Also, in
our studies, we found that malware only took advantage of
the SNI extension in ∼27% of the observed TLS ﬂows. On
the other hand, DNS responses were available for ∼78% of
the malicious TLS ﬂows in our dataset, and were available
for ∼73% of the malicious TLS ﬂows that lacked the SNI
extension.

Domain Generation Algorithms (DGA) generate a large
number of domains for the malware to try to communicate
with. This process gives malware a more robust method of
contacting its command and control server. It is often the
case that these algorithms have implicit or explicit biases
that make detecting a DGA domain possible. We examined
some simple statistics about the domain name and the fully
qualiﬁed domain name (FQDN) to aid in these inferences,
and more generally, to determine the diﬀerences in benign
and malicious domain names.

Figure 3 illustrates a histogram of the number of char-
acters in the domain names in our dataset. This analysis
was also done on the FQDN. For the domain name lengths,
the benign domain names had a roughly Gaussian shape cen-
tered around 6/7. The malicious domain names and FQDNs
had a sharp peak at 6 and 10, respectively. After manual in-
spection of the names and the associated pcaps, it was clear
that this phenomena was due to DGA activity, i.e., there
were many such random-looking DNS responses per sample
with the same length. Contrary to our initial intuition, it
seems that benign domains have a longer tail for the num-
ber of characters in the FQDN. This was because of how
cloud-based services structure their FQDNs.

We examined two more metrics on the FQDNs: the per-
centage of numerical characters and the percentage of non-
alphanumeric characters. In contrast to previous work [9],
we found that the benign DNS responses had a higher per-

38Figure 4: Statistics of HTTP ﬂows contextual to TLS ﬂows, revealing the diﬀerent prevalence of feature values for malware
(red) and benign (blue).

centage of numerical characters, 13.44% versus 0.85%, and
a higher percentage of non-alphanumeric characters, 16.36%
versus 9.61%. Non-alphanumeric characters include wild-
cards and periods. We observed a signiﬁcant amount of
benign traﬃc visiting cloud services and CDNs which could
have caused this discrepancy between prior work.

In addition to the FQDN, the DNS response provides
other interesting data elements. Figure 3 shows the num-
ber of distinct IP addresses returned. The majority of DNS
responses return 1 IP address for both malicious and benign
responses. Beyond those cases, there is some interesting
structure where we see signiﬁcantly more benign responses
returning 2 and 8 IP addresses and signiﬁcantly more mal-
ware responses returning 4 and 11 IP addresses.

Figure 3 also shows the prevalence of diﬀerent TTL val-
ues between malware and benign DNS responses. The four
most common TTL values for benign DNS responses are 60,
300, 20, and 30, in order. TTL value 300 is malware’s sec-
ond most common, but TTL values 20 and 30 are rarely
observed. It is also interesting to note that ∼22% of mal-
ware DNS responses used a TTL value of 100, a value that
was not observed in our DMZ data.

Alexa [1] ranks websites based on the number of page
views and the number of unique IP addresses. We recorded
the top-1,000,000 websites from Alexa in April 2016. We
used this list to create 6 categories for the domain names:
whether the target domain name was in the top-100, top-

1,000, top-10,000, top-100,000, top-1,000,000 or not found
in the Alexa list. The most prestigious category was chosen
for each domain name, i.e., a domain name would belong
to top-100 but not top-100 and top-1,000. Figure 3 shows
the distributions of domain names with respect to the Alexa
lists for the malware and DMZ traﬃc. As expected, roughly
∼86% of the domain names that the malware samples looked
up were not found in the Alexa top-1,000,000 list. On the
other hand, Figure 3 shows that the DMZ traﬃc had the
majority of its domain names in the top-1,000,000.

Given the results presented in Figure 3, it is clear that
DNS provides valuable, discriminatory information that can
be correlated with encrypted ﬂows to provide additional con-
text for increased visibility, and can be used to create highly
accurate machine learning classiﬁers.

4. MALWARE AND HTTP

Finally, we present the diﬀerences we found in the DMZ
and malware traﬃc with respect to the HTTP headers. We
again used the same data sources, and ﬁltered on port 80
HTTP traﬃc. We collected 1,743,842 HTTP ﬂows from the
DMZ and 1,004,798 HTTP ﬂows from ThreatGRID [2]. Our
tool parsed all available header ﬁelds and values from the
ﬂows, thus leaving intact information that would be dis-
carded by web proxy logs. Those logs only report on a ﬁxed
subset of all headers, and they normalize the values that are

39reported, discarding valuable data. For instance, the only
HTTP-speciﬁc data features available in the exported IIS
6.0 web server logs are the Method, URI, code, User-Agent,
Referer, Cookie, and Host. Of these, only the ﬁrst four are
enabled by default [4]. Our tool also maintains the capital-
ization and ordering of the HTTP ﬁelds.

The appearance of an HTTP ﬁeld or set of HTTP ﬁelds
can be a good indicator for malicious activity. Figure 4 lists
the prevalence of some interesting inbound HTTP ﬁelds. For
instance, malicious HTTP is more likely to make use of the
Server, Set-Cookie, and Location ﬁelds, while the DMZ
HTTP traﬃc was more likely to make use of the Connec-
tion, Expires, and Last-Modified ﬁelds. For outbound
HTTP ﬁelds, the DMZ HTTP was more likely to make use
of the User-Agent, Accept-Encoding, and Accept-Language
ﬁelds.

As Figure 4 demonstrates, the dominant HTTP Content-
Type for the DMZ traﬃc was image/*, and the malware
traﬃc was mostly text/*. Content-Type also serves as an
example of why you should not normalize the values of these
ﬁelds. The second and third most common content types
for malware are text/html;charset=UTF-8 and text/html;
charset=utf-8. These subtle diﬀerences have an incredible
amount of value in terms of detection and attribution, and
should not be discarded.

Figure 4 also shows the value of the Server and code in-
bound HTTP ﬁelds. Malware most often says that it is using
a version-less nginx server, and the benign traﬃc most of-
ten says that it is using either the version-less Apache or
nginx server. In terms of interesting servers, AmazonS3 and
nginx/1.4.7 were announced almost exclusively by the be-
nign servers, and LiteSpeed and gws were announced almost
exclusively by the malicious servers.

The outbound User-Agent ﬁeld had a very long tail, sev-
eral thousand unique strings in both datasets. For the mal-
ware data, the most common advertised User-Agent string
was Opera/9.50(WindowsNT6.0;U;en), followed by several
variations of Mozilla/5.0 and Mozilla/4.0. All of the top
User-Agent strings in the DMZ data were Windows and OS
X variants of Mozilla/5.0. This ﬁeld also had the most
diverse set of capitalizations that we observed:

• User-Agent
• user-agent
• User-agent
• USER-AGENT
• User-AgEnt

The User-Agent ﬁeld is also another interesting example
of the power of these ﬁelds in the context of encrypted traﬃc.
Finding a discrepancy between what software is being used
on an endpoint and what software is being advertised by an
endpoint is an interesting indicator of compromise. By cor-
relating HTTP and TLS data, speciﬁcally the User-Agent
ﬁeld with the TLS library, we can make useful inferences.

For instance, we can get a reasonable estimate of the
browser in use by observing the TLS metadata, inferring
the TLS library, and then correlating the TLS library with
the probable browser, or set of browsers. As we will show
in Section 6, it is quite interesting when the TLS browser
estimate is diﬀerent from what is being advertised in the
HTTP User-Agent ﬁeld.

Figure 5: The prevalence of diﬀerent contextual data, show-
ing the percentage of TLS ﬂows that had DNS and/or HTTP
context, for both benign (DMZ) and malware ﬂows.

5. DATA

In this section, we reiterate our strategy for data collec-
tion. We also describe how each of the data features we
explored in the previous sections are represented to the ma-
chine learning algorithms. Joy [26] was used to transform
all of the data, either from packet capture ﬁles or collected
live, into a convenient JSON format.

5.1 Malware Data

The malicious dataset was collected from January to April
2016 from a commercial sandbox environment that receives
user submissions. Each submission is allowed to run for 5
minutes, and all network activity is collected for analysis.
From this set, there were 21,417 successful TLS ﬂows. Each
ﬂow completed the full handshake, and the TLS data from
the clientHello, serverHello, certificate, and clien-
tKeyExchange messages was collected.

Figure 5 gives the percentages of the other contextual data
features that were also present. 16,691 of the TLS ﬂows had
an associated DNS lookup, and 18,144 had an active HTTP
session during the sandbox detonation. 13,542, or ∼63%, of
the malicious TLS ﬂows had all available data. To accurately
compare the classiﬁers based on the diﬀerent data views, this
set of 13,542 ﬂows was used in the results for Section 6.

5.2 Benign Data

The benign dataset was collected during a 5-day period
in April 2016 from a large enterprise network’s DMZ. We
again collected all TLS ﬂows that successfully completed
the TLS handshake and had all relevant messages. There
were 1,130,386 such ﬂows.
As shown in Figure 5, 746,723, or ∼66%, of the TLS
ﬂows had an associated DNS response. But, only 60,285,
or ∼5%, of the TLS ﬂows had any HTTP ﬂows from the
same source IP address within a 5 minute window of the
TLS ﬂow. HTTP context by itself is an interesting indica-
tor, and should remain interesting as more of the Alexa top-
1,000,000 websites transition to HTTPS. There were 42,927
TLS ﬂows that had both DNS and HTTP context, and these
ﬂows were used for the results of Section 6.

40As an additional validation of our results, we collected an-
other dataset from the same enterprise DMZ in May 2016:
∼4 weeks after the initial dataset was collected. The same
data collection and ﬁltering strategy was employed. There
were 35,699 TLS ﬂows that had both DNS and HTTP con-
text during this time period.
5.3 Data Features

5.3.1 Observable Metadata
Features based on observable metadata, such as the se-
quence of packet lengths and inter-arrival times, were used,
and were modeled as Markov chains. We exclude TCP re-
transmissions from our data by having our tool track the
TCP sequence number. The packet lengths were taken to
be the sizes of the UDP, TCP, or ICMP packet payloads. If
the packet was not one of those three types, then the length
was set to the size of the IP packet. The inter-arrival times
had a millisecond resolution.

For both the lengths and times, the values were discretized
into equally sized bins. The length data Markov chain had
10 bins of 150 bytes each. A 1500 byte MTU was assumed,
and any packets observed with a size greater than 1350 bytes
were put into the same bin. The timing data Markov chain
used 50 millisecond bins and 10 bins for 100 total features.
Any inter-packet time greater than 450ms fell into the same
bin. The transition probabilities were used as features for
the machine learning algorithm.

Another form of observable metadata, the byte distribu-
tion, was represented as a length-256 array that keeps a
count for each byte value encountered in the payloads of the
packets of the ﬂow being analyzed. The byte value prob-
abilities of a ﬂow can be easily computed given the byte
distribution by dividing the byte distribution counts by the
total number of bytes found in the packet payloads. The
features used by the machine learning algorithms are the
256 byte distribution probabilities.

5.3.2 TLS Data
The client-based TLS-speciﬁc features used in our classiﬁ-
cation algorithm were the list of oﬀered ciphersuites, the list
of advertised extensions, and the client’s public key length.
We observed 176 unique hex codes advertised in the lists of
oﬀered ciphersuites, and created a binary vector of length
176 where a one is assigned to each hex code in the sample’s
list of oﬀered ciphersuites. More advanced representations
taking the order of the list into account were considered, but
did not lead to signiﬁcantly improved results and were there-
fore not pursued in favor of simplicity. Similarly, a length-21
binary vector was used to represent the TLS extensions. Fi-
nally, a single integer value was used to represent the public
key length.

The server-based TLS-speciﬁc features included the se-
lected ciphersuite, supported extensions, number of certiﬁ-
cates, number of SAN names, validity in days, and whether
there was a self-signed certiﬁcate.

5.3.3 DNS Data
From the associated DNS response of the TLS ﬂow, we
collect the lengths of both the domain name and the FQDN.
We also harvested a list of the 40 most common suﬃxes, and
have a binary feature for each suﬃx and a binary feature for
“other”. Similarly, we harvested a list of the 32 most com-

mon TTL values and an “other” option. We also had features
for the number of numerical characters, the number of non-
alphanumeric characters, and the number of IP addresses
returned by the DNS response. Finally, we had six binary
features representing whether the domain name was in the
top-100, top-1,000, top-10,000, top-100,000, top-1,000,000 or
not found in the Alexa list. The most prestigious category
was chosen for each domain name, i.e., the top-100 feature
would be a one, but not the top-1,000 feature.
5.3.4 HTTP Data
For each TLS ﬂow, we collect all HTTP ﬂows from the
same source address within a 5 minute window of the TLS
ﬂow. There is a single feature vector of binary variables
representing all of the observed HTTP headers. If any of the
HTTP ﬂows have a speciﬁc header value, then that feature
will be a 1 regardless of the other HTTP ﬂows.

We used seven types of features from the HTTP data. For
each feature, we selected all speciﬁc values used by at least
1% of either the malware or benign samples and an “other”
category. The types were the presence of outbound and
inbound HTTP ﬁelds, Content-Type, User-Agent, Accept-
Language, Server, and code.

6. CLASSIFYING ENCRYPTED TRAFFIC
In this section, we outline the type of results that can be
achieved when looking at encrypted data from a data omnia
perspective. Not only do we show that using all available
data leads to incredibly accurate classiﬁers at a 0.00% false
discovery rate, we also show how these machine learning
models are interpretable. We provide evidence for the claim
that correlating unencrypted metadata can lead to useful
and interesting indicators of compromise for encrypted ﬂows.
Finally, we validate our methods on more real-world data -
data that was held out from the initial training and tuning
of the models and features.
6.1 Classiﬁcation Results

For these results, we used the set of 13,542 malicious and
42,927 benign TLS ﬂows that contained DNS and HTTP
context, as explained in Section 5. All results used 10-fold
cross-validation and l1-logistic regression. We will show that
this classiﬁer performed extremely well for our task, and
has the added beneﬁt of being easily interpretable. This
model also reports a probabilistic output, allowing one to
easy change the threshold of the classiﬁer. We did compare
l1-logistic regression with a support vector machine (Gaus-
sian kernel, width adjusted through CV), and found no
statistically-signiﬁcant improvement using a 10-fold paired
t-test at a 5% signiﬁcance level [14]. Because of the added
computational resources needed to train the SVM and the
loss of interpretability, we emphasis only the l1-logistic re-
gression results. Finally, all data features were normalized
to zero-mean and unit variance.

Table 1 gives 10-fold, l1-logistic regression classiﬁcation
results for diﬀerent combinations of feature sets. SPLT/BD
are the sequence of packet lengths and times and byte dis-
tribution. TLS, HTTP, and DNS are self-explanatory. Only
using information from the encrypted ﬂow itself, SPLT+BD
+TLS, we were able to achieve a total accuracy of 99.933%.
Given the amount of encrypted ﬂows seen on even modestly
sized networks, total accuracy means very little because even
a classiﬁer with 99.99% total accuracy could have tens of

41Dataset

Total Accuracy

0.00% FDR Avg # of Model Parameters

SPLT+BD+TLS+HTTP+DNS

99.993%

99.978%

SPLT+BD+TLS+HTTP

99.983%

99.956%

SPLT+BD+TLS+DNS

TLS+HTTP+DNS

SPLT+BD+TLS

HTTP+DNS

TLS+HTTP

TLS+DNS

HTTP

DNS

TLS

99.968%

99.988%

99.933%

98.666%

99.889%

77.881%

99.985%

99.956%

99.955%

99.883%

99.945%

99.496%

96.335%

99.660%

96.849%

98.996%

94.654%

62.857%

189.7

209.8

197.1

129.3

250.7

109.2

109.3

89.4

87.5

50.2

51.6

Table 1: Classiﬁcation results for for diﬀerent combinations of data features.

thousands of false positives. For this reason, we focus on a
0.00% false discovery rate.
With ∼55,000 samples in our dataset, it is impossible to
give a true, robust 0% false discovery rate. With that caveat,
we do report a 0%, or 0.00%, false discovery rate for our clas-
siﬁers. Comparatively, the performance of the SPLT+BD+
TLS classiﬁer suﬀers under this metric with 77.881% accu-
racy. But, once we take advantage of the additional HTTP
and DNS context, the 0.00% false discovery rate becomes
99.978%, a signiﬁcant improvement. We further defend the
false positives when we analyze a real-world, validation set.
The results presented in Table 1 clearly show the beneﬁt of
utilizing contextual DNS and HTTP information to classify
TLS encrypted ﬂows. And while HTTP context is absent in
many of the TLS ﬂows collected from the DMZ, 66% of the
TLS ﬂows did have DNS information. Only TLS and DNS
data still provided a 98.666% accuracy at a 0.00% FDR.
6.2 Model Interpretability

In an operational setting, having a black box classiﬁer
that returns a 0/1 response is suboptimal. Having the abil-
ity to add context to the classiﬁcation decision is invaluable
in terms of performing the appropriate response. The l1-
logistic regression classiﬁer we use is highly accurate, and has
easily interpretable parameters that can be used to help ex-
plain the classiﬁer’s decision to an incident responder. Fur-
thermore, the l1 penalty shrinks most of the parameters to 0,
creating sparser models that are even more interpretable and
generalize better. The number of parameters of each learned
model, averaged over the cross-validation folds, is shown in
Table 1. It is interesting to note, that the model with all
possible data features actually has less model parameters
than some other models with fewer data features, e.g., all
features has an average of 189.7 and SPLT+BD+TLS has
an average of 250.7 parameters.

Table 2 presents the top-5 parameters that inﬂuence a
positive malware conviction and the top-5 parameters that
inﬂuence a negative malware conviction. This l1-logistic re-
gression classiﬁer was built using all available data sources.
Interestingly, data features from TLS, DNS and HTTP all
show up in one or both of the top-5 lists.

The majority of these values are easily understood. For
instance, the DNS feature Alexa: None was one of the top-

Weight

Feature

3.38

2.99

2.62

2.28

1.95

1.78

1.38

1.21

1.12

1.11

-2.16

-1.65

-1.61

-1.35

-1.10

-0.97

-0.95

-0.91

-0.88

DNS Suﬃx org

DNS TTL 3600

TLS Ciphersuite TLS_RSA_WITH_RC4_128_SHA

HTTP Field accept-encoding

TLS Ciphersuite

SSL_RSA_FIPS_WITH_3DES_EDE_CBC_SHA

HTTP Field location

DNS Alexa: None

TLS Ciphersuite TLS_RSA_WITH_RC4_128_MD5

HTTP Server nginx

HTTP Code 404

TLS Extension extended_master_secret

HTTP Content Type application/octet-stream

HTTP Accept Language en-US,en;q=0.5

TLS Ciphersuite TLS_DHE_RSA_WITH_DES_CBC_SHA

HTTP Content Type text/plain;charset=UTF-8

HTTP Server Microsoft-IIS/8.5

DNS Alexa: top-1,000,000

HTTP User-Agent Microsoft-CryptoAPI/6.1

TLS Ciphersuite

TLS_ECDHE_ECDSA_WITH_RC4_128_SHA

-0.85

HTTP Content Type application/x-gzip

Table 2:
TLS/DNS/HTTP classiﬁer.

The data features most

relevant

to the

ten contributors to a malicious conviction, and the major-
ity of the malicious samples that we processed did not talk
to a domain in the Alexa top-1,000,000. Interestingly, the
DNS feature Alexa: top-1,000,000 was the only Alexa-
based feature that contributed to a benign classiﬁcation, i.e.,
Alexa: top-100, etc. had a weight of 0. This can be ex-

42All

TLS

TLS

TLS

All

+HTTP +DNS

Available

0.0

35,699

51,113

655,906

988,105

988,105

.5

.9

.95

.99

86

25

18

4

312

130

97

67

4,207

20,186

982

855

621

4,718

3,014

465

4,602

2,004

1,644

1,056

Table 3: Alarms generated based on diﬀerent feature sets
and thresholds on a real-world validation dataset.

plained by a non-trivial percentage of the malware samples
performing connectivity checks to popular websites such as
www.google.com, but comparatively fewer malware samples
connecting to websites in the 100,00-1,000,000 range.

The TLS ciphersuite TLS_RSA_WITH_RC4_128_SHA was cor-
related with malicious convictions. It has been observed that
there are signiﬁcantly more malware ﬂows that oﬀer this ci-
phersuite than enterprise ﬂows [6]. Again, these model pa-
rameters and the feature vectors of the samples can be used
to easily explain why the classiﬁer classiﬁed a ﬂow as mali-
cious or benign.
6.3 Second-Order Correlations

In addition to creating machine learning models, the data
that we collect is useful for rule-based indicators of com-
promise. When detecting malicious behavior, it is useful to
identify unexpected discrepancies. The server name indi-
cation (SNI) TLS extension [16] is available in the clien-
tHello message and indicates the hostname of the server
that the client is trying to connect to. The subjectAltName
(SAN) X.509 extension [35] is available in the certificate
message and allows a server to list additional names includ-
ing additional DNS names.

We analyzed the 21,417 malicious and 1,130,386 benign
TLS sessions that had server certiﬁcates looking for instances
where the SAN and SNI were present, had relevant informa-
tion, and disagreed. ∼0.01% of the benign ﬂows and ∼8.25%
of the malicious ﬂows had a discrepancy. The benign cases
were mostly IP addresses listed in the SNI and *.what-
sapp.net and variations listed as SANs. Not only was this
discrepancy more prominent in the malicious dataset,
in
many cases it was also a very diﬀerent type of discrepancy
than the benign cases. The format of most of the malware
diﬀerences included DGA-like behavior in the SNI and SAN,
e.g., SNI: ‘bbostybfmaa.org’ and SAN: ‘giviklorted.at’.
More advanced diﬀerences can also be analyzed with the
data sources that we have collected. Finding discrepancies
between the User-Agent that a TLS-adjacent HTTP ﬂow
advertises and the User-Agent inferred from the TLS oﬀered
ciphersuites and advertised extensions is a another useful
indicator of compromise. As an example, we observed 125
malicious TLS ﬂows that had associated HTTP ﬂows with
a User-Agent string = Firefox/31.0. All TLS ﬂows in this
set oﬀered the prototypical Windows XP ciphersuite list [27].
We also found 97 DMZ TLS ﬂows that had an associated
HTTP context with a User-Agent string = Firefox/31.0.
These TLS ﬂows oﬀered an ordered ciphersuite list that
matches what is oﬀered by real versions of Firefox/31.0

[34]. This line of thinking is not immune to false positives,
but it does oﬀer a unique way to identify indicators of com-
promise that arise when correlating disparate types of data.
6.4 Real-World Results

In a research setting with limited data, it is often diﬃcult
to avoid overﬁtting machine learning algorithms to a speciﬁc
dataset. Even with a proper cross-validation methodology,
implicit biases can occur in the meta-parameters such as the
choice of machine learning algorithm or data features [15].
In addition to the cross-validated results, we now present
results on an additional validation dataset. This data was
collected over a 4 day period from the same enterprise DMZ
∼4 weeks after the initial dataset. The machine learning
algorithms were trained only on the original dataset, and
then applied to this new data. No changes to the algorithms
or features were made. There were 35,699 TLS ﬂows with
DNS/HTTP context, 51,113 TLS ﬂows with only HTTP
context, 655,906 TLS ﬂows with only DNS context, and
988,105 total TLS ﬂows in this validation set.

Table 3 lists the number of alarms for each set of data fea-
tures at diﬀerent thresholds. The “All” classiﬁer classiﬁed
TLS ﬂows that had HTTP and DNS contextual informa-
tion. The “All Available” classiﬁer classiﬁed all TLS ﬂows,
but used any contextual ﬂow information that was available.
The l1-logistic regression classiﬁer reports a probability of
maliciousness, and we can use this probability to easily ad-
just how many alarms are raised. For instance, at the default
0.5 threshold, the TLS-only classiﬁer had 20,186 alarms.
Adjusting the threshold to 0.99, there were only 465 alarms
during this 4-day period.

Unsurprisingly, the classiﬁer that used DNS and HTTP
contextual information performed the best on the validation
dataset. This classiﬁer had 86 total alarms with 29 unique
destination IP addresses and 47 unique source IP addresses.
42 of these alarms appeared to be false positives. In nearly
all of these 42 cases, the TLS ﬂow was communicating with
either a Google or Akamai server, but had contextual HTTP
ﬂows that communicated with suspicious domains. “Suspi-
cious” was determined by extracting the Host HTTP ﬁeld,
and checking whether VirusTotal [3] found convicted exe-
cutables with that domain name embedded in their source
code. In this context, convicted means more than 50% of
the VirusTotal detectors ﬂagged the executable as malicious.
These Host HTTP ﬁelds did not show up in the Alexa lists.
Adjusting the TLS+HTTP+DNS classiﬁer’s threshold to
0.95 reduced the number of alarms during this four day
period to 18, and the number of unique destination IP ad-
dresses to 7. We manually checked each of the IP addresses.
These encrypted ﬂows were considered to be true positives
if executables, convicted by VirusTotal, communicated with
the destination IP address during the same dates that we
collected our data. 16/18 of the TLS+HTTP+DNS classi-
ﬁer’s alarms at a threshold of 0.95 were conﬁrmed to be
malicious using this method. Again, we could not correlate
these IP addresses with domain names listed in the Alexa
top-1,000,000, e.g., no IP address resolved to google.com.

7. RELATED WORK

Research in network-based malware detection has two main
directions. The ﬁrst, vertical correlation, uses the network
traﬃc of a single host to ﬁnd evidence of a malware infection.
The second, horizontal correlation, uses the traﬃc of two

43or more hosts to ﬁnd malicious communication. Horizontal
correlation can, in some cases, detect large-scale, malicious
communication graphs. Some techniques are content agnos-
tic, while others rely on content inspection. Our approach
uses vertical correlation, and it is not fully content-agnostic
because of its use of DNS, TLS, and HTTP metadata, but
it does not rely on the inspection of the encrypted payload.
7.1 Flow Metadata

Traditionally, ﬂow-monitoring systems have been used to
collect metadata about network communications such as the
IP addresses, ports, number of bytes exchanged and number
of packets. This data is then exported to a collector using
a protocol such as IPFIX [12] or NetFlow [11]. This data is
especially valuable when traﬃc is encrypted because deep-
packet inspection is no longer viable. The simplest type of
analysis on ﬂow data takes advantage of the IP address in the
ﬂow records and blacklists. This type of data fusion is widely
deployed, but is fragile and diﬃcult to maintain. Additional
protocol-agnostic features have also been studied, such as
the packet lengths and distribution of byte values [19].

This data has also been used to perform application or
malware detection [18, 19, 30, 40, 41, 42, 43, 44]. BotFinder
[38] is an important vertical correlation technique that uses
only NetFlow features. Unsupervised machine learning is
used to identify clusters that are characteristic of malware
communications collected from malware sandboxes. It de-
tects periodic components in malware communications, and
achieved a detection rate of 0.8 with a 0.0001 false positive
rate. Because BotFinder is content agnostic, it can operate
on encrypted traﬃc. By utilizing more data features, our
approach achieves a signiﬁcantly higher detection rate, and
is robust against evasion techniques in which the malware
is not periodic and does not have communication charac-
teristics that show up in NetFlow data. Additionally, our
approach works even when each malware instance is only
observed for a short, e.g., 5 minute, time window. This is
an important strength, because large-scale, labeled malware
datasets are often limited by sandbox resources. The pe-
riodic behavior exploited by BotFinder, in contrast, would
not show up in these short windows.

Another important vertical technique is BotHunter [19].
This algorithm tracks the communication between internal
assets and external entities, and develops an evidence trail
of communication events that match a state-based infection
sequence model. BotHunter recognizes the infection and
coordination dialog that occurs during a malware infection.
It is content-dependent, and uses both Snort signatures and
anomaly detection based on content inspection, the latter
utilizing a sophisticated n-gram based Statistical payLoad
Anomaly Detection Engine (SLADE).

One important horizontal correlation technique is Bot-
Sniﬀer [20], which detects spatial-temporal correlations and
similarity patterns in network traﬃc that are characteristic
of botnet command and control traﬃc. Other interesting
horizontal correlation techniques include BotMiner [18] and
[37]. These techniques have the limitation that they cannot
detect single infected hosts with high eﬃcacy.
7.2 DNS

The Domain Name System (DNS) [28] is a hierarchical,
decentralized means to provide additional information about
domain names, notably a domain name to IP address map-

ping. More recently, malware has taken advantage of DNS
and domain generation algorithms (DGA) [8] to provide a
robust way to operate its command and control channels.
There have been many previous results on classifying DNS
data as malicious or benign [7, 9, 24]. None of this work
leverages the DNS data to make inferences about encrypted
traﬃc. Our work also diﬀers in that we illustrate the distri-
butions of diﬀerent data features of DNS, e.g., TTL values.
7.3 HTTP

The Hypertext Transfer Protocol (HTTP) [17] is an ap-
plication level protocol used to communicate data on the
World Wide Web. Similar to DNS, HTTP has also been
used by threat actors as a command and control channel
[29, 33]. There has been some work speciﬁcally targeting
features present in HTTP data.
In [33], the authors use
statistics, e.g., the average length of the URL, and string
matching methods on the URL to cluster malware. Again,
concrete diﬀerences in malware and benign HTTP sessions
are not highlighted.
[22] speciﬁcally analyzed User-Agent
ﬁeld values. We give a detailed description of more HTTP
ﬁelds, and use this information to create machine learning
classiﬁers for encrypted traﬃc.
7.4 TLS

Transport Layer Security (TLS) [13] is a cryptographic
protocol that provides privacy for applications. TLS is usu-
ally implemented on top of common protocols such as HTTP
for web browsing or SMTP for email. HTTPS is the usage
of TLS over HTTP, which is the most popular way of se-
curing communication between a web server and client and
is supported by most major web servers. We have observed
malware increasing its usage of TLS for the past 10 months,
from ∼7% of samples with active network communications
in June 2015 to ∼18% in April 2016.

The features of certiﬁcates used by malware have been
studied [5], but this work does not examine benign certiﬁ-
cates or their diﬀerences from the certiﬁcates used by mal-
ware. While there has been little work analyzing malware’s
use of TLS, work analyzing only the ﬂow metadata would
be equally eﬀective on encrypted ﬂows. Man in the Mid-
dle (MITM) solutions [10] have also been proposed to ﬁnd
threats in encrypted traﬃc.
In MITM, an enterprise will
decrypt network traﬃc passing through a security appliance
and typically apply signatures to the unencrypted traﬃc.
This method does not respect the privacy of the users on
the network, it is not always eﬀective, and it requires a lot
of resources to eﬀectively deploy and maintain. For these
reasons, ﬂow-based solutions are generally preferred.

8. CONCLUSIONS

Identifying threats in encrypted network traﬃc, and do-
ing so in a way that does not compromise the integrity of
the encryption, is an important problem. In this paper, we
have shown that the data omnia approach, speciﬁcally col-
lecting and correlating TLS, DNS, and HTTP metadata, can
be used to accurately classify malicious, TLS network ﬂows
without resorting to crippling the TLS protocol.

We began by identifying features of the TLS protocol, as
well as DNS and HTTP features of contextual ﬂows, that
have interesting discriminatory information. We showed
how ﬁnding discrepancies in the unencrypted metadata can
be used to ﬁnd interesting indicators of compromise, such as

44mismatched SNI and SAN ﬁelds. We presented an l1-logistic
regression model that was able to achieve an accuracy of
99.978% at a 0.00% FDR. This model also oﬀers easily in-
terpretable results that generalized extremely well to a new
dataset collected ∼4 weeks after the initial dataset.

There are several research directions that could extend
and improve on our work. Longer-term behavior could be
observed, making it possible to use an FFT data feature to
detect periodic communication patterns [38]. Training data
could be extended to include honeypots and malware ob-
served in the wild. Utilizing additional content-aware data
features, such as SLADE [19], could be useful on non-TLS
ﬂows that are encrypted at the application layer. Like all
vertical correlation systems, it could be extended by hy-
bridizing it with a horizontal correlation system, such as
one that analyzes the communication graph [31].

9. ACKNOWLEDGMENTS

We would like to thank the anonymous reviewers for their
constructive feedback. We would also like to thank Greg
Akers for supporting this work. Finally, we would like to
thank Rich West, Dave Schwartzburg, Brandon Enright,
Craig Brozefsky, and the ThreatGRID team for their di-
rection, insightful comments, and support in facilitating the
data collection.

10. REFERENCES
[1] Alexa. http://www.alexa.com/, 2016.
[2] ThreatGRID. http://www.threatgrid.com, 2016.
[3] Virus Total. https://www.virustotal.com/, 2016.
[4] W3C Extended Log File Format (IIS 6.0).

https://www.microsoft.com/technet/prodtechnol/
WindowsServer2003/Library/IIS/
676400bc-8969-4aa7-851a-9319490a9bbb, 2016.
[5] O. Alrawi and A. Mohaisen. Chains of Distrust:

Towards Understanding Certiﬁcates Used for Signing
Malicious Applications. In Proceedings of the 25th
International Conference Companion on World Wide
Web, pages 451–456. International World Wide Web
Conferences Steering Committee, 2016.

[6] B. Anderson, S. Paul, and D. McGrew. Deciphering
Malware’s use of TLS (without Decryption). ArXiv
e-prints, July 2016.

[7] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou II,

and D. Dagon. Detecting Malware Domains at the
Upper DNS Hierarchy. In USENIX security
symposium, page 16, 2011.

[8] M. Antonakakis, R. Perdisci, Y. Nadji, N. Vasiloglou,

S. Abu-Nimeh, W. Lee, and D. Dagon. From
Throw-Away Traﬃc to Bots: Detecting the Rise of
DGA-Based Malware. In USENIX security
symposium, pages 491–506, 2012.

[9] L. Bilge, E. Kirda, C. Kruegel, and M. Balduzzi.
EXPOSURE: Finding Malicious Domains Using
Passive DNS Analysis. In Network and Distributed
System Security Symposium (NDSS), 2011.

[10] F. Callegati, W. Cerroni, and M. Ramilli.

Man-in-the-Middle Attack to the HTTPS Protocol.
IEEE Security & Privacy, 7(1):78–81, 2009.

[11] B. Claise. Cisco Systems NetFlow Services Export

Version 9, 2013. RFC 3954.

[12] B. Claise, B. Trammell, and P. Aitken. Speciﬁcation of
the IP Flow Information Export (IPFIX) Protocol for
the Exchange of Flow Information, 2013. RFC 7011.

[13] T. Dierks and E. Rescorla. The Transport Layer

Security (TLS) Protocol Version 1.2. 2008. RFC 5246.

[14] T. G. Dietterich. Approximate Statistical Tests for

Comparing Supervised Classiﬁcation Learning
Algorithms. Neural computation, 10(7), 1998.
[15] C. Dwork, V. Feldman, M. Hardt, T. Pitassi,

O. Reingold, and A. Roth. The Reusable Holdout:
Preserving Validity in Adaptive Data Analysis.
Science, 349(6248):636–638, 2015.

[16] D. Eastlake. Transport Layer Security (TLS)

Extensions: Extension Deﬁnitions. 2011. RFC 6125.

[17] R. Fielding, J. Gettys, J. Mogul, H. Frystyk,

L. Masinter, P. Leach, and T. Berners-Lee. Hypertext
Transfer Protocol – HTTP/1.1. 1999. RFC 2616.

[18] G. Gu, R. Perdisci, J. Zhang, and W. Lee. BotMiner:

Clustering Analysis of Network Traﬃc for
Protocol-and Structure-Independent Botnet Detection.
In USENIX Security Symposium, volume 5, pages
139–154, 2008.

[19] G. Gu, P. A. Porras, V. Yegneswaran, M. W. Fong,

and W. Lee. Bothunter: Detecting Malware Infection
through IDS-Driven Dialog Correlation. In USENIX
Security Symposium, volume 7, pages 1–16, 2007.

[20] G. Gu, J. Zhang, and W. Lee. BotSniﬀer: Detecting
Botnet Command and Control Channels in Network
Traﬃc. 2008.

[21] T. Hastie, R. Tibshirani, J. Friedman, and J. Franklin.

The Elements of Statistical Learning: Data Mining,
Inference and Prediction. 27(2):83–85, 2005.

[22] N. Kheir. Behavioral Classiﬁcation and Detection of

Malware through HTTP User Agent Anomalies.
Journal of Information Security and Applications,
18(1):2–13, 2013.

[23] K. Koh, S.-J. Kim, and S. P. Boyd. An Interior-Point

Method for Large-Scale l1-Regularized Logistic
Regression. JMLR, 8(8):1519–1555, 2007.

[24] J. Ma, L. K. Saul, S. Savage, and G. M. Voelker.

Beyond Blacklists: Learning to Detect Malicious Web
Sites from Suspicious URLs. In Proceedings of the 15th
ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining, pages
1245–1254. ACM, 2009.

[25] D. McGrew and B. Anderson. Enhanced Telemetry for

Encrypted Threat Analytics. In ICNP Workshop on
Machine Learning in Computer Networks
(NetworkML). IEEE, 2016.

[26] D. McGrew and B. Anderson. Joy.

https://github.com/davidmcgrew/joy, 2016.

[27] Microsoft. Choose the right ciphersuites in SChannel.

https://www.ssl.com/how-to/
choose-the-right-cipher-suites-in-schannel-dll/, 2016.

[28] P. Mockapetris. Domain Names - Concepts and

Facilities. 1987. RFC 1034.

[29] A. Mohaisen. Towards Automatic and Lightweight

Detection and Classiﬁcation of Malicious Web
Contents. In Hot Topics in Web Systems and
Technologies (HotWeb), pages 67–72. IEEE, 2015.

45[30] A. W. Moore and D. Zuev. Internet Traﬃc

Classiﬁcation Using Bayesian Analysis Techniques. In
ACM SIGMETRICS Performance Evaluation Review,
volume 33, pages 50–60. ACM, 2005.

[31] S. Nagaraja, P. Mittal, C.-Y. Hong, M. Caesar, and

N. Borisov. BotGrep: Finding P2P Bots with
Structured Graph Analysis. In USENIX Security
Symposium, pages 95–110, 2010.

[32] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,

B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,
R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,
D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. Scikit-learn: Machine Learning in
Python. JMLR, 12:2825–2830, 2011.

[33] R. Perdisci, W. Lee, and N. Feamster. Behavioral

Clustering of HTTP-Based Malware and Signature
Generation using Malicious Network Traces. In NSDI,
pages 391–404, 2010.

[34] Qualys. Qualys SSL Labs.

https://www.ssllabs.com/ssltest/clients.html, 2016.
[35] P. Saint-Andre and J. Hodges. Representation and
Veriﬁcation of Domain-Based Application Service
Identity within Internet Public Key Infrastructure
Using X.509 (PKIX) Certiﬁcates in the Context of
Transport Layer Security (TLS), 2011. RFC 6125.

[36] R. Sommer and V. Paxson. Outside the Closed World:

On using Machine Learning for Network Intrusion
Detection. In 2010 IEEE Symposium on Security and
Privacy, pages 305–316. IEEE, 2010.

[37] W. T. Strayer, R. Walsh, C. Livadas, and D. Lapsley.
Detecting Botnets with Tight Command and Control.
In Local Computer Networks, Proceedings 2006 31st
IEEE Conference on, pages 195–202. IEEE, 2006.

[38] F. Tegeler, X. Fu, G. Vigna, and C. Kruegel.

Botﬁnder: Finding Bots in Network Traﬃc without
Deep Packet Inspection. In The 8th international
conference on Emerging networking experiments and
technologies, pages 349–360. ACM, 2012.

[39] A. Vassilev. Annex A: Approved Security Functions

for FIPS PUB 140-2, Security Requirements for
Cryptographic Modules. http://csrc.nist.gov/
publications/ﬁps/ﬁps140-2/ﬁps1402annexa.pdf, 2016.

[40] K. Wang, G. Cretu, and S. J. Stolfo. Anomalous

Payload-Based Worm Detection and Signature
Generation. In Recent Advances in Intrusion
Detection, pages 227–246. Springer, 2006.

[41] L. Wang, K. P. Dyer, A. Akella, T. Ristenpart, and

T. Shrimpton. Seeing through Network-Protocol
Obfuscation. In 22nd ACM Conference on Computer
and Communications Security, pages 57–69, 2015.

[42] N. Williams, S. Zander, and G. Armitage. A

Preliminary Performance Comparison of Five Machine
Learning Algorithms for Practical IP Traﬃc Flow
Classiﬁcation. Computer Comm. Review, 30, 2006.

[43] P. Wurzinger, L. Bilge, T. Holz, J. Goebel, C. Kruegel,

and E. Kirda. Automatically Generating Models for
Botnet Detection. In Computer Security–ESORICS
2009, pages 232–249. Springer, 2009.

[44] S. Zander, T. Nguyen, and G. Armitage. Automated

Traﬃc Classiﬁcation and Application Identiﬁcation
using Machine Learning. In The 30th IEEE

Conference on Local Computer Networks, pages
250–257. IEEE, 2005.

APPENDIX
A. CIPHERSUITE AND EXTENSION HEX

CODES

Hex Code

Ciphersuite

0x0004

0x0005

0x000a

0x0013

0x0015

0x002f

0x0035

0x0064

0xc007

0xc009

0xc00a

0xc013

0xc014

0xc02b

0xc02f

TLS_RSA_WITH_RC4_128_MD5

TLS_RSA_WITH_RC4_128_SHA

TLS_RSA_WITH_3DES_EDE_CBC_SHA

TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA

TLS_DHE_RSA_WITH_DES_CBC_SHA

TLS_RSA_WITH_AES_128_CBC_SHA

TLS_RSA_WITH_AES_256_CBC_SHA

SSL_RSA_EXPORT1024_WITH_RC4_56_SHA

TLS_ECDHE_ECDSA_WITH_RC4_128_SHA

TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA

TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA

TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA

TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA

TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256

TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256

Table 4: Hex code to ciphersuite mapping for ciphersuites
used in ﬁgures.

Hex Code

0x0000

0x0005

0x000a

0x000b

0x000d

0x000f

0x0015

0x0017

0x0023

0x3374

0xff01

Ciphersuite

server_name

status_request

supported_groups

ec_point_formats

signature_algorithms

heartbeat

padding

extended_master_secret

SessionTicket TLS

next_protocol_negotiation

renegotiation_info

Table 5: Hex code to extension mapping for extensions used
in ﬁgures.

46