Membership Privacy in MicroRNA-based Studies

Michael Backes

CISPA, Saarland University &

MPI-SWS

Saarland Informatics Campus

Pascal Berrang

CISPA, Saarland University
Saarland Informatics Campus

Mathias Humbert

CISPA, Saarland University
Saarland Informatics Campus

Praveen Manoharan
CISPA, Saarland University
Saarland Informatics Campus

ABSTRACT
The continuous decrease in cost of molecular proﬁling tests
is revolutionizing medical research and practice, but it also
raises new privacy concerns. One of the ﬁrst attacks against
privacy of biological data, proposed by Homer et al. in 2008,
showed that, by knowing parts of the genome of a given in-
dividual and summary statistics of a genome-based study,
it is possible to detect if this individual participated in the
study. Since then, a lot of work has been carried out to fur-
ther study the theoretical limits and to counter the genome-
based membership inference attack. However, genomic data
are by no means the only or the most inﬂuential biological
data threatening personal privacy. For instance, whereas
the genome informs us about the risk of developing some
diseases in the future, epigenetic biomarkers, such as mi-
croRNAs, are directly and deterministically aﬀected by our
health condition including most common severe diseases.

In this paper, we show that the membership inference at-
tack also threatens the privacy of individuals contributing
their microRNA expressions to scientiﬁc studies. Our results
on real and public microRNA expression data demonstrate
that disease-speciﬁc datasets are especially prone to mem-
bership detection, oﬀering a true-positive rate of up to 77%
at a false-negative rate of less than 1%. We present two at-
tacks: one relying on the L1 distance and the other based on
the likelihood-ratio test. We show that the likelihood-ratio
test provides the highest adversarial success and we derive
a theoretical limit on this success. In order to mitigate the
membership inference, we propose and evaluate both a dif-
ferentially private mechanism and a hiding mechanism. We
also consider two types of adversarial prior knowledge for
the diﬀerentially private mechanism and show that, for rel-
atively large datasets, this mechanism can protect the pri-
vacy of participants in miRNA-based studies against strong
adversaries without degrading the data utility too much.
Based on our ﬁndings and given the current number of miR-
NAs, we recommend to only release summary statistics of
datasets containing at least a couple of hundred individuals.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24 - 28, 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978355

Keywords
Health privacy; Membership privacy; Diﬀerential privacy

1.

INTRODUCTION

During the last decade, the cost of molecular proﬁling
tests, such as DNA sequencing, has signiﬁcantly dropped,
enabling a new breakthrough in biomedical science and the
subsequent advent of personalized medicine. A necessary
condition for such a scientiﬁc breakthrough is the availabil-
ity of large amounts of biological data. However, this avail-
ability imposes severe privacy risks for individuals who con-
tribute their biological samples towards improving medicine.
One of the ﬁrst attacks showing the extent of this threat
was proposed by Homer et al. back in 2008 [19]. Speciﬁ-
cally, the authors demonstrated that, given (some parts of)
the genomic data of an individual and summary statistics
of a genome-wide association study (GWAS [4]), it is pos-
sible to determine whether this individual participated in
the GWAS. Such a membership attack can have disastrous
privacy implications if the individual happens to be part of
the case group (e.g., carrying a sensitive disease). This ﬁrst
attack led to substantial follow-up work aiming to identify
the theoretical bounds on the attack’s success more precisely
and to propose defense mechanisms for countering it.

The genome is, however, not the only element correlated
with human health that can have a detrimental eﬀect on pri-
vacy. A variety of new biomarkers, such as epigenomic and
transcriptomic data, are currently being studied by biomed-
ical researchers towards a more precise and personalized
medicine. One class of these biomarkers is the microRNA
(miRNA). MiRNAs are small RNA molecules that regulate
the majority of human genes. Even though biomedical re-
search on miRNAs is far from complete, studies of miRNA
expression proﬁles have already shown that dysregulation of
miRNA is linked to neurodegenerative diseases, heart dis-
ease, diabetes, and the majority of cancers [27, 35, 21, 29,
15]. Therefore, miRNA expression proﬁling promises to en-
able a more accurate and minimally invasive diagnosis of ma-
jor severe diseases. On the downside, this also implies that
miRNA expressions can tell us much more about whether
someone is aﬀected by a disease at a given point in time than
the genome, which only informs about the risk of getting
certain diseases.1 However, despite the disease-leakage risk
stemming from miRNAs, their growing importance and pub-

1The only exception are Mendelian disorders, such as cystic
ﬁbrosis, which are largely determined by our genes.

319lic availability in biomedical databases,2 privacy of miRNA
data has been largely overlooked by the research commu-
nity. Moreover, as miRNAs might not be strictly deﬁned as
genetic information, it is still unclear if the current genetic
nondiscrimination laws, such as the US Genetic Information
Nondiscrimination Act, would apply to them [30, 14].

Contributions.

In this paper, we ﬁrst study whether, and to what ex-
tent, membership inference can be successfully carried out
against miRNA expression datasets. Notable challenges we
needed to overcome are that miRNA expressions are real-
valued rather than discrete, but of several orders of mag-
nitude lower dimension and more noisy than genomic data.
Indeed, whereas a genome typically contains tens of mil-
lions of single nucleotide polymorphisms (SNPs), there are
currently only around ﬁve thousand identiﬁed miRNAs.

We present two attacks, one based on the L1 distance, as
proposed by Homer et al. in their seminal work, and another
based on the likelihood-ratio (LR) test, which is optimal,
in the sense that it achieves maximum attack true-positive
rate at a given false-positive level. For the latter attack,
we also derive the theoretical relation between true-positive
rate, false-positive rate, number of miRNAs and number of
individuals in the dataset. This relation is especially valu-
able as it is independent of the actual individual miRNA
expression values and of any population-wide statistics.

Our experimental results demonstrate that, in general, the
L1 distance attack performs a bit worse than the LR attack,
as expected, and that the LR theoretical relation provides
bounds that are slightly lower than the power of the empir-
ical LR test (i.e., the LR attack with actual miRNA expres-
sion data). Finally, we show that the membership inference
attack is a lot more successful against datasets composed of
participants carrying a speciﬁc disease than randomly gener-
ated datasets. This is essentially due to the fact that miRNA
expressions are highly aﬀected by the health status of their
owner, much more than genomic data. The latter result
tells us that the theoretical relation on the LR test has to
be taken very cautiously regarding the privacy levels it pro-
vides to miRNA-based studies in practice.

Second, given the extent of the threat to membership
privacy, we propose and evaluate both a perturbative, dif-
ferentially private mechanism and a hiding mechanism for
countering the membership attack. More precisely, we ﬁrst
study two variants of the perturbative algorithm assuming
diﬀerent prior knowledge of the attacker. We show that,
in our context, it does not make a substantial diﬀerence to
the membership of a victim whether to assume an attacker
knowing bounded or unbounded priors. Then, we evalu-
ate the impact of both protection mechanisms (perturbative
and hiding) on mitigating the success of the attacks. For the
perturbative noise mechanism, we also thoroughly study the
evolution of noise and its impact on utility, as it can lead
to prohibitive loss for research and medical utility. One key
observation is that the diﬀerentially private mechanism is
able to reduce the attacks’ power to nearly random guess-
ing, whereas the hiding method is not. Moreover, the attack
is in general very robust to hiding miRNA means. Finally,
we notice that the attack and diﬀerentially private mecha-

2The current most prominent examples are the Gene Ex-
pression Omnibus (GEO) [3] and the ArrayExpress [1]
databases.

nism are inﬂuenced mostly by the number of individuals in
the dataset. Based on our analytical and experimental re-
sults, given the current number of miRNAs, we recommend
to only release summary statistics of datasets including at
least a couple of hundred individuals.

Organization.

In Section 2, we introduce the required background and
the adversarial model. In Section 3, we present analytical
and experimental results of the membership inference attack
against miRNA-based studies.
In Section 4, we introduce
defense mechanisms for countering the attack, and evaluate
the privacy and utility they provide. We present the related
work in Section 5 before concluding in Section 6.
2. PRELIMINARIES

In this section, we brieﬂy present the required background
on microRNA expressions, then describe our threat model,
and ﬁnally review the basic deﬁnitions of diﬀerential privacy
and membership privacy, which will be used in this work.
2.1 MicroRNA Expressions

MicroRNAs (abbreviated miRNAs) are small non-coding
RNA molecules that regulate gene expression in plants and
animals. These molecules notably regulate 60% of the genes
coding human proteins [17]. Currently, there are more than
5,000 miRNAs known in human beings [8], and this number
will certainly keep increasing [26].

A miRNA expression is a (positive) real value quantiﬁed
in a two-step polymerase chain reaction (PCR) process that
measures how much the miRNA is active in a given cell or
tissue. A miRNA expression proﬁle represents the set of
miRNA expressions of an individual at one point in time.

Biomedical research is especially interested in discovering
how miRNA expressions aﬀect human pathologies. Recent
studies of miRNA expression proﬁling have already demon-
strated that dysregulation of miRNA is linked to neurode-
generative diseases (Alzheimer’s and Parkinson’s), heart dis-
eases, diabetes, and the majority of cancers [27, 35, 21, 29,
15]. Hence, miRNA expression proﬁling promises to enable
a more accurate, earlier and minimally invasive diagnosis of
severe diseases.

Especially when taken from blood samples, miRNAs rep-
resent a non-invasive diagnosis and have been shown to help
identify severe diseases such as cancers or Alzheimer’s [22,
24]. In this work, we focus on membership privacy in the
context of blood-based miRNAs. A summary of the relation
between miRNA and human pathologies can be found in the
Human miRNA Disease Database [6].
2.2 Threat Model

The adversary’s goal is to determine whether a speciﬁc
person (referred to as victim) is a member of a group of
study, that we will refer to as a pool.
First, we assume the adversary has access to the exact
miRNA expression proﬁle xv ∈ Rm of the victim v. Such
data can be easily extracted from a blood sample of the vic-
tim, for a few hundreds dollars (and the cost will certainly
decrease over time). Full individual miRNA expression data
are also increasingly available in public research databases,
such as the Gene Expression Omnibus (GEO) [3] or Ar-
rayExpress [1] databases. Furthermore, this data could be
collected by hacking a healthcare provider server, e.g., a

320hospital server. Indeed, healthcare companies are facing an
increasing number of cyber attacks [7] such as the Anthem’s
breach, in which the medical records of around 80 million
patients were leaked [5].

Also note that we will assume that the victim’s proﬁle to
which the adversary has access and the proﬁle the victim
contributed to the pool were collected at the same time. Al-
though miRNA expressions can vary in time, previous work
has shown that miRNA expression proﬁles can be eﬃciently
linked over time frames of up to one year [9].

Second, we assume the adversary has access to some sum-
mary statistics released for the pool. Formally, the pool is
deﬁned as a set T ∈ Rn×m containing the miRNA expression
proﬁles of n entities gathered from an underlying population
U, where each proﬁle is a vector of m real values represent-
ing the expression of every miRNA. Such pools of individu-
als are typically used by biomedical researchers in order to
infer associations between miRNAs and diseases. If signiﬁ-
cant associations exist, the researchers publish their results
in articles (typically available online) along with summary
statistics about their pool, such as mean values of miRNA
expressions.
In this work, we assume mean statistics are
available to the adversary, but other statistics could also be
accessed, even further increasing the adversary’s power.
Finally, we assume the adversary has also access to general
miRNA expression statistics of the underlying population U,
the so-called reference population. Currently, these statis-
tics have to be estimated by the adversary using a subset of
U, but we expect that population-wide statistics will soon
become publicly available, as for genomic data.
2.3 Differential and Membership Privacy
In this work, beyond presenting attacks against membership
privacy in miRNA-based studies, we also propose counter-
measures, notably relying on diﬀerential privacy [10]. We
review here the deﬁnitions and results on diﬀerential privacy
and positive membership privacy relevant to this paper.

Definition 1

(Differential Privacy [10]). A mech-
anism A provides -diﬀerential privacy if and only if for any
two datasets T1 and T2 diﬀering in one element, and any
S ⊆ range(A), it holds that

Pr[A(T1) ∈ S] ≤ e · Pr[A(T2) ∈ S]

In this paper, we will also discuss a relaxed version of dif-
ferential privacy, membership privacy, that ideally allows for
smaller utility loss and at the same time satisfactory privacy
guarantees under relaxed adversarial assumptions. Positive
membership privacy, proposed by Li et al. [25], potentially
allows to bound the change in the adversary’s belief regard-
ing an entity’s membership in a database after observing
some statistics of the database.

Definition 2

(Positive Membership Privacy [25]).
A mechanism A provides (γ, D)-positive membership privacy
(PMP) under a distribution family D, where γ ≥ 1 if and
only if for any S ⊆ range(A), any distribution D ∈ D and
any entity t ∈ U, it holds that

Pr

D,A [t ∈ T | A(T ) ∈ S] ≤ γ · Pr
· Pr
D,A [t /∈ T | A(T ) ∈ S] ≥ 1

D

[t ∈ T ]
[t /∈ T ]

Pr

(2)
In general, (e, D)-membership privacy and -diﬀerential pri-
vacy are equivalent for arbitrary distribution families D, and

γ

D

(1)

thus require the same amount of noise. However, the re-
quired amount of noise can be reduced by restricting the
distribution families, assuming prior bounds on the prob-
ability of membership.
In particular, if the membership
probability pt of an entity t to a database is restricted to
pt ∈ [a, b] ∪ {0, 1}, for 0 < a ≤ b < 1, then achieving weaker
diﬀerential privacy is suﬃcient to achieve (positive) mem-
bership privacy, as shown by Tram`er et al. [32].

Theorem 1

provides (γ, D[a,b]
satisﬁes -diﬀerential privacy for

(Tram`er et al. [32]). A mechanism A
B )-PMP for some 0 < a ≤ b < 1, if A
(cid:40)

) if aγ < 1,

e =

min( (1−a)γ
γ+b−1

1−aγ , γ+b−1
otherwise.

b

b

(3)

3. MEMBERSHIP INFERENCE ATTACK

In this section, we ﬁrst introduce the two test statistics
used in our attack, one that is based on the approach pro-
posed by Homer et al. [19] and another that relies on the
likelihood ratio test. Then, we evaluate both approaches
using a real dataset containing more than 1,000 miRNA ex-
pression proﬁles [23] and compare their performance.
3.1 Analytical Results

The mean of miRNA expression values is one of the most
frequently released summary statistics in miRNA-based stud-
ies. Indeed, for studies which aim to discover associations
between dysregulated miRNAs and diseases, it is crucial to
disclose the mean of miRNA expression values over all case
samples (individuals carrying the disease of interest to the
study) and, separately, over all control samples. Another
statistic used for the same purpose is the p-value of the t-
test. We show, in the following, that, in many cases, the
average values of miRNAs are already suﬃcient to identify
participation of a victim in a miRNA-based pool.

The expression value of the miRNA j of the individual i
j ∈ R. xi ∈ Rm is the vector of all miRNA
is denoted by xi
expression values of the individual i. Further, µj denotes
the average expression value of miRNA j in the reference
population, while ˆµj denotes the average of miRNA j’s ex-
pression value in the pool.
3.1.1 L1 Distances Difference
In order to determine whether a victim v is part of the
pool, extending Homer et al.’s idea to real-valued miRNA
expression proﬁles, one can simply compare the distances
between (i) xv
j and ˆµj. By computing the
diﬀerence between these distances we obtain the following
statistic:

j and µj, and (ii) xv

D(xv

j ) = |xv

j − µj| − |xv

j − ˆµj|

(4)

Under the null hypothesis, if xv
j is not part of the pool,
D(xv
j ) should approach zero. Under the alternative hypoth-
esis, where xv
j is member of the pool, it should be greater
than zero because the victim’s contribution xv
j to ˆµj will
shift ˆµj away from µj. When D(xv
j is fur-
ther away from the pool than from the reference population,
and thus even less likely to be part of the pool.

j ) is negative, xv

Following from the central limit theorem, if the number
of miRNAs is suﬃciently high, the sum of D(xv
j ) over all
miRNAs j will converge to the normal distribution. Hence,
we use the one-sample t-test to determine whether the per-
son of interest v is part of the pool: If the test is strictly

321greater than a threshold, we assume v is part of the pool
and, otherwise, that v is not in the pool.

written as:

3.1.2 Likelihood-Ratio Test
Although the aforementioned test can be very accurate,
there is no known theoretical guarantee on the power3 of de-
tection it can achieve. Thus, it is possible that another ap-
proach could provide better attack power. We therefore also
propose and evaluate a test statistic based on the likelihood-
ratio test (LR test).

This method has the non-negligible advantage of attain-
ing the maximum achievable power for a given false-positive
level and thus, provides a theoretical limit on the maximum
detection power of the adversary, according to the Neyman-
Pearson lemma. This lemma states that the exact LR test
achieves the maximum power at a given false-positive level in
binary hypothesis testing [28]. Furthermore, in the context
of genomic privacy, the LR test has been empirically shown
to be more powerful than Homer et al.’s attack, especially
for small false-positive levels [31]. Before deriving the exact
likelihood-ratio statistic for miRNA expression proﬁles, we
have to impose some assumptions on their characteristics.

First, we assume that miRNAs are independent4 and that
the expression value of each miRNA j is distributed accord-
ing to a normal distribution (with diﬀerent parameters for
the reference population and the pool). Note that the nor-
mal distribution is the distribution that best ﬁts the distri-
butions observed from our miRNA expression dataset. For
the reference population, we denote the mean by µj and the
standard deviation by σj. For the pool, we denote them
by ˆµj and ˆσj respectively. Note that a deviation from the
Neyman-Pearson lemma might occur if, for example, the
miRNAs are only approximately normally distributed.

Under the null hypothesis that the victim is not part of
the pool, this victim’s miRNA expressions are drawn from
the reference population as deﬁned above, i.e., each miRNA
expression j of individual v is drawn with the probability
density:

f (xv

j ) =

1√
2πσj

e

− xv

j −µj
2σ2
j

(5)

Similarly, under the alternative hypothesis, following a
similar reasoning as in the theoretical analysis of [31], we
consider the miRNA expressions of the victim to be drawn
according to the probability distribution of the pool:

ˆf (xv

j ) =

1√
2πˆσj

e

− xv

j − ˆµj
2ˆσ2
j

(6)

We can then derive the following likelihood ratio between

the alternative and the null hypotheses:

j −µj
xv
2σ2
j

− xv

j − ˆµj
2ˆσ2
j

LR =

σ
ˆσ

e

(7)

Hence, the log-likelihood ratio over all miRNAs can then be

3Power refers to the true-positive rate, also called sensitivity.
4We make this assumption for tractability reasons, noting
that about 60% of miRNAs are independent. Moreover, such
assumption leads us to an upper bound on the adversary’s
power in inferring membership of the victim.

m(cid:88)

j=1

(xv

j − µj)2
2σ2
j

− (xv

j − ˆµj)2
2ˆσ2
j

+ log

σj
ˆσj

(8)

LLR =

If the adversary has access to the average values ˆµj of
miRNA expressions in the pool, as assumed in this paper,
he still has to derive µj, σj, and ˆσj. The reference popula-
tion’s parameters µj and σj can be approximated by relying
on publicly available datasets of miRNA expression levels.
In Subsection 3.2, we approximate these parameters with
our dataset of miRNA expressions. Finally, the adversary
still needs to estimate ˆσj. For large n, the standard de-
viation should be very close to the standard deviation in
the reference population because participants in the pool
are supposed to come from the same reference population.
Hence, ˆσj ≈ σj is the best approximation the adversary can
make about ˆσj. In our evaluation, we will compute both the
LR with the exact standard deviation ˆσj and with ˆσj = σj,
and compare the outcomes.

We now present the theoretical approximation on the max-
imum achievable power given the false-positive rate, the
number of miRNAs, and the number of individuals in the
pool.

Theorem 2. Assuming ∀j : σj ≈ ˆσj, the relation between
the power β, the false-positive rate α, the number of miRNAs
m, and the number of individuals n in the pool is

(cid:114)

zα + z1−β ≈

2m
n2 ,

(9)

where zx is the 100(1-x)th percentile of the standard normal
distribution.

Proof. First of all, we need to compute the statistics
of the LLR deﬁned in (8) under the null and the alternative
hypotheses. Focusing on a single miRNA j’s expression (i.e.,
one term of the LLR sum), we have the following mean µj,0
under the null hypothesis:
µj,0 := E[LLRj | H0] =

(xj − µj)2f (xj)dxj (10)

(cid:90) ∞

1
2σ2
j

−∞

(xj − ˆµj)2f (xj)dxj + log

σj
ˆσj

f (xj)dxj

(cid:90) ∞

−∞

− 1
2ˆσ2
j

(cid:90) ∞
(cid:90) ∞

−∞

−∞

− 1
2ˆσ2
j
− 1
2ˆσ2
j

=

=

=

1
2

1
2

1
2

(xj − ˆµj)2f (xj)dxj + log
(xj − µj − xj − µj

n

)2f (xj)dxj + log

(cid:90) ∞

−∞

σj
ˆσj

(11)

(12)

σj
ˆσj
(13)

(14)

− σ2
j
2ˆσ2
j

+

σ2
j
nˆσ2
j

j

− σ2
2n2 ˆσ2
j

+ log

σj
ˆσj

.

From (12) to (13), we assume that the pool is constituted of
the victim v and n − 1 individuals drawn as under the null,
i.e., ˆµj = (n−1)µj +xj
. Using our assumption ∀j : ˆσj = σj,
we obtain

n

µj,0 =

1
n

− 1

2n2 =

2n − 1
2n2

.

(15)

Following the same reasoning, replacing µj by n ˆµj−xj
n−1
get the following mean under the alternative hypothesis:

, we

µj,1 := E[LLRj | H1] =

2n − 1
2(n − 1)2 ,∀j

(16)

322The variances of the LLR under the null and the alternative
hypotheses are equal to:

j | Hk] − µ2

j,k, k ∈ {0, 1}

j,k := E[LLR2
σ2

(17)
j | Hk] can be derived similarly to the means, by
E[LLR2
using the central moments (E[(X − E(X))c]) of the normal
distribution up to order c = 4. We obtain the following
standard deviations:

σj,0 =

σj,1 =

√

,

2n − 1√
2n2
2n − 1
2(n − 1)2

Note that the mean and variance statistics do not depend on
miRNA j’s values. Then, for moderately large m, it is known
that the exact LLR statistics are approximately Gaussian,
mσj,0 =
which allows us to use the relationship mµj,0 + zα
mµj,1 − z1−β
mσj,1, where zα and z1−β are the quantiles
of level 1 − α and β of the normal distribution. Thus, we
obtain the following relations:

√

√

(18)

(19)

(cid:19)

(20)

σj,0zα + σj,0z1−β =
1√
2(n − 1)2

z1−β =

zα +

1√
2n2

(n − 1)2zα + n2z1−β =

zα + z1−β ≈

√
√

√

(cid:114)

(cid:18)

m(µj,1 − µj,0)

m

1

2(n − 1)2 − 1

2n2

)

(21)

(22)

(23)

2m(n − 1
2

2m
n2

The theoretical relation does not depend on the average
values µj, ˆµj of the miRNA expressions, nor does it make
any assumptions about their values. It only requires m to
be relatively large. Theorem 2 shows us that, for a suc-
cessful attack, the number of exposed miRNAs m has to
scale with the square of the number of participants in the
study (n2), which is better from a privacy point of view
than with genomic data where it has to scale linearly with
n [31]. Nevertheless, this does not imply that participants in
miRNA-based studies are fully protected against member-
ship inference attacks: First, as we will see in our dataset,
the number of participants in pools can be lower than 20 in
current practice. Second, biomedical researchers constantly
keep discovering new miRNAs and, thereby, implicitly in-
crease the number m of available statistics [8]. Finally, real
case groups can have expression means that are further away
from reference population means than what we assume in
our theoretical analysis. This can be explained by the fact
that miRNA expressions are highly aﬀected by diseases.
3.2 Experimental Results

In this section, we evaluate the two aforementioned at-
tacks and compare their respective performances. Before
that, we provide details on the dataset we use for our eval-
uations (including those in Section 4.2).
3.2.1 Dataset Description
The dataset was ﬁrst presented and used by Keller et al.
in [23], and is publicly available in the gene expression om-
nibus (GEO) database under reference GSE61741. It con-
tains the miRNA expression proﬁles of 1,049 individuals and,

hence, can be considered a very rich dataset in the biomedi-
cal ﬁeld. Every proﬁle contains a set of 848 miRNA expres-
sions. 94 of the 1,049 individuals are healthy people whereas
the others are aﬀected by one out of 19 diseases: 124 people
have Wilms tumor (D1), 73 lung cancer (D2), 65 prostate
cancer (D3), 62 myocardial infarction (D4), 47 chronic ob-
structive pulmonary disease (COPD) (D5), 45 sarcoidosis
(D6), 45 ductal adenocarcinoma (D7), 43 psoriasis (D8),
37 pancreatitis (D9), 35 benign prostate hyperplasia (D10),
35 melanoma (D11), 33 non-ischaemic systolic heart failure
(D12), 29 colon cancer (D13), 24 ovarian cancer (D14), 23
multiple sclerosis (D15), 20 glioma (D16), 20 renal cancer
(D17), 18 periodontitis (D18), and 13 stomach tumor (D19).
Before running our experiments, we ﬁlter out non-expressed
miRNAs, i.e., those with a median level of expressions over
all individuals smaller than 50, which leaves us with 466 ex-
pressed miRNAs. This preprocessing phase is standard in
the biomedical research ﬁeld.

3.2.2 Results
We evaluate our attacks on the aforementioned dataset in
two diﬀerent settings: (i) we randomly pick a varying num-
ber n of individuals from the dataset to form a pool, and (ii)
we consider every case group (carrying a disease) desribed
above as a pool. The reference population is estimated using
the entire dataset, i.e., all 1,049 individuals.

While the ﬁrst setting allows us to evaluate the attack’s
success independent of any eﬀects that might be caused by
diseases, the second setting is actually more realistic.
In-
deed, biomedical publications usually include the mean val-
ues of cases carrying speciﬁc diseases.

We evaluate each attack on aforementioned pools, using
each of the 1,049 individuals as a potential victim. Given
an attack and a pool, we obtain a test statistic Tv for every
victim v. We then say v is more likely to be part of the
pool than to be part of the reference population if the test
statistic is greater than a given threshold t, i.e., Tv > t.
Depending on whether v is part of the pool or not, we classify
the result as true-positive (v is part of the pool and Tv > t),
false-positive (v is not part of the pool and Tv > t), true-
negative (v is not part of the pool and Tv ≤ t) or false-
negative (v is part of the pool and Tv ≤ t). These metrics
are then used to compute the true-positive and false-positive
rates for varying thresholds.

Random Pools.

In the ﬁrst setting, we randomly select 50 subsets of n
diﬀerent individuals among the 1,049 in our dataset, and
average the results.

All ﬁgures in this section will depict the receiver operating
characteristic (ROC) curves that compare the false-positive
rate, on the x-axis, with the power of the attack, on the y-
axis. We show four diﬀerent ROC curves for (i) the attack
based on the L1 distances’ diﬀerence, (ii) the likelihood-
ratio attack knowing all the population and pool statistical
parameters, i.e., µ, ˆµ, σ, ˆσ (referred to as LR exact), (iii) the
LR attack not knowing ˆσ, and approximating it as ˆσ ≈ σ
(corresponding to our assumed threat model), and (iv) the
theoretical LR relation derived in Theorem 2 also assuming
ˆσ ≈ σ. The ﬁgures are shown with a logarithmic x-axis,
representing the false-positive rate in the range [10−3, 1].
In Fig. 1, we depict three diagrams of randomly con-
structed pools for n ∈ {35, 65, 124}. We select these num-

323(a)

(b)

(c)

Figure 1: ROC curves for pools of n randomly chosen individuals: (a) n = 35, (b) n = 65, (c) n = 124.

bers because they are representative for our dataset and also
correspond to the numbers of cases of three disease-speciﬁc
groups shown in Fig. 2. For n = 35, the power of the LR
test is more than 40% for a false-positive rate of 10%. As
expected, increasing the size of the pool results in a loss
of power. The more participants contribute to the pool’s
statistics, the more challenging it is to identify whether the
victim participated in this pool.

In all cases, the exact LR test performs best, most likely
due to the availability of all statistical parameters, followed
by the LR test corresponding to our threat model. The L1
distance test achieves the worst power of the empirical tests.
Finally, we observe that the theoretical LR curve is quite
close to the empirically evaluated LR curve when n = 35,
but also that it degrades faster when n increases. This dis-
crepancy is probably due to the fact that the reference pop-
ulation is supposed to be inﬁnite, whereas in practice it is
approximated by a ﬁnite group of samples.

Case Groups.

Fig. 2 depicts ROC curves for six diﬀerent case groups
of individuals carrying a speciﬁc disease. Speciﬁcally, we
select six case groups ranging from the smallest (stomach
tumor) to the largest (Wilms tumor) number of individuals,
and use them as pools. Note that these groups are fairly
representative for all of the 19 case groups.

We ﬁrst observe that, as previously, the exact LR test per-
forms best, followed by the realistic LR test and L1 distance
test in most cases. We also notice that the empirically evalu-
ated attacks perform signiﬁcantly better than the theoretical
approximation of the LR test for almost all case groups.

If we compare the performance on randomly constructed
pools in Fig. 1 and on case groups in Fig. 2 for the same
number of individuals n, the attack on case groups yields
higher power for the same false-positive level. For instance,
we observe a power of around 60% at a false-positive rate of
10% for Wilms tumor (Fig. 2(f)) against a power of around
25% at the same false-positive rate when the individuals are
randomly picked to be part of the pool (Fig. 1(c)).

Furthermore, as shown by our dataset, it often happens
that the case group is very small. Then, in the case of stom-
ach tumor, for example, the power reaches 100% at a small
false-positive rate of 3.5%, and 77% at a false-positive rate
of 0.9% (Fig. 2(a)). This demonstrates that one should
be very careful when releasing summary statistics about
disease-related case groups in miRNA studies, as attacks

against such pools clearly outperform the theoretical LR
power. This is certainly due to the fact that miRNA ex-
pressions are highly correlated with the overall health sta-
tus of their owners, and more precisely with their disease
status. Note that while case groups aﬀect the inference’s
success, it cannot be used to classify individuals as healthy
or diseased. Bioinformaticians usually carry out such clas-
siﬁcations using more advanced techniques such as support
vector machines [24].

In any case, we strongly discourage researchers from pub-
lishing the exact statistics of disease-speciﬁc case groups,
at least for pools smaller than a few hundred participants
(which we have shown not to be resistant to membership in-
ference attacks). Instead, we suggest to apply probabilistic
sanitization before disclosing the summary statistics, or to
drastically reduce the number of released means.

Finally, note that an attack aiming at discriminating be-
tween two diﬀerent pools, i.e., classifying whether an indi-
vidual is part of one of two pools, would be even more suc-
cessful than ours, as shown in the context of genomic privacy
in [31]. For instance, the authors of this paper showed that,
if the sizes of both pools were equivalent, then the number of
genomic variants needed to achieve a given power and false-
positive rate dropped by four compared to the more complex
membership attack in which there is no information about
the presence of the victim in any of the pools.

4. MEMBERSHIP PROTECTION

In this section, we discuss and evaluate the sanitization of
miRNA expression statistics, aiming at protecting the mem-
bership of any entity in the pool. To this end, we employ two
diﬀerent techniques, namely (1) adding noise to achieve dif-
ferential privacy, and (2) publishing only a subset of miRNA
expression statistics.

In particular, we ﬁrst analytically examine the technique
based on adding noise, before we empirically evaluate the
eﬀect of both our techniques on the privacy of pool’s con-
tributors and on the utility for research.
4.1 Analytical Results

For the analytical examination of the diﬀerential privacy
approach, we ﬁrst determine a suitable noise distribution for
the mean statistic, then present utility bounds based on this
noise distribution, and ﬁnally evaluate the discrepancy be-
tween noise magnitudes under two adversarial assumptions
and diﬀerent parameters.

324(a)

(b)

(c)

(d)

(e)

(f)

Figure 2: ROC curves for case groups of n individuals carrying: (a) stomach tumor (n = 13), (b) renal cancer
(n = 20), (c) benign prostate hyperplasia (n = 35), (d) ductal adenocarcinoma (n = 45), (e) prostate cancer
(n = 65), and (f ) Wilms tumor (n = 124).

A standard method to achieve diﬀerential privacy for real-
valued functions is to add Laplace noise: we replace the orig-
inal mechanism favg : T → Rm by the sanitized mechanism
f(cid:48)
avg = favg + (Y1, . . . , Ym) that adds noise Yi to each miRNA
expression mean distributed by a suitably scaled Laplace dis-
tribution L(b). As shown by Dwork et al. [11], we achieve
-diﬀerential privacy for favg by adding Laplace noise scaled
with b = ∆(favg)
where ∆(favg) is the global sensitivity of
favg, deﬁned as follows.



Definition 3. For the statistic favg : T → Rm that re-
leases the means of m miRNA expression values over n sam-
ples, where the expression value of miRNA i has range δi,
the global sensitivity ∆(favg) is determined by

∆(favg) = max

T1,T2∈T (cid:107)favg(T1) − favg(T2)(cid:107)1

= max
T1,T2∈T

|favg,i(T1) − favg,i(T2)| =

m(cid:88)

i

m(cid:88)

i

δi
n

,

where T1 and T2 are two datasets diﬀering in one element.
Applying this deﬁnition, for every miRNA i in {1, ..., m} and
pool containing n individual samples, the noise Yi added
(cid:80)m
to the mean to achieve -diﬀerential privacy is drawn from
L(

).

k=1 δk
n

Note that the range δk of miRNA k’s expression is the
global range of its expression values, not the range within
the pool only. In our evaluations, we approximate this range
by the diﬀerence between the minimum and maximum ex-
pression values found in our whole dataset.

One of the main criticisms of diﬀerential privacy is that
adding noise to the original statistics negates its utility. We
now derive a bound for the probability that the most noise
added to any element favg,i of favg exceeds a value y. Note
that, as shown by Ghosh et al. [18], using a geometric noise
mechanism can lead to slightly better utility bounds. How-
ever, in our speciﬁc use case, the high sensitivity of our
release mechanism will dominate any practical utility con-
cerns, and we thus stick to the simpler Laplacian mechanism.

avg = favg +

Theorem 3. Let f : T → Rm and let f(cid:48)

(Y1, . . . , Ym), Yi ∼ L( ∆(favg)
(cid:48)

Pr(cid:2)|favg,i(T ) − f
(cid:20)

). Then, ∀y ≥ 0

avg,i(T )| ≥ y(cid:3) ≤ e
− ny(cid:80)m
(cid:19)(cid:21)
(cid:19)(cid:18) ∆(f )

(cid:18) 1

Proof. By Theorem 3.8 in [12], it holds that

k=1



|fi(T ) − f

i (T )| ≥ ln
(cid:48)

Pr

α



δk

≤ α

for some probability α ∈ (0, 1]. Note that, instead of con-
sidering the L∞ norm of the whole output of f as in the
original result we bound the diﬀerence for anyone of the
output values fi.

By setting y = ln(cid:0) 1

, replacing ∆(f ) by the for-
mula derived in Deﬁnition 3, and solving for α, we get our
upper bound.

α



(cid:1)(cid:16) ∆(f )

(cid:17)

Given that the range of some of the miRNA expressions in
of
our dataset is very high, the sensitivity ∆(favg) =
the mean statistic will be very high too. Fig. 3(a), which

i δi
n

(cid:80)m

3251

0.8

0.6

η

0.4

0.2

γ = 5, n = 100

γ = 5, n = 100, bounded

γ = 1.5, n = 1000

γ = 1.5, n = 1000, bounded

γ = 5, n = 1000

γ = 5, n = 1000, bounded

1

0.8

0.6

η

0.4

0.2

 = 1, n = 100
 = 10, n = 100
 = 50, n = 100
 = 100, n = 100

(a)

0.2

0.4

0.6

0.8

1

1.2

Noise y

(b)

1.4
·104

0.2

0.4

0.6

0.8

1

1.2

Noise y

(c)

1.4
·104

Figure 3: Comparison of initial miRNA expression means and typical noise distributions with and without
bounded priors.
(a) Empirical complementary cumulative distribution function (CCDF), (b) Probability
upper bound η that the noise added to our statistic favg is greater than or equal to y, given the membership-
privacy parameter γ1 = 1.5 and γ2 = 5 and the pool sizes n1 = 100 and n2 = 1000, (c) Probability upper bound
η given the diﬀerential-privacy parameter  ∈ {1, 10, 50, 100} and the pool size n = 100.

represents the miRNA expression means’ empirical comple-
mentary cumulative distribution function, helps to under-
stand this behavior. Indeed, it shows that the majority of
expression values’ means are smaller than 200, but also that
some are higher than 10,000. Similar substantial discrepan-
cies occur for the expression ranges δi’s. As the sensitivity
is, for every miRNA, by deﬁnition, the sum over all miR-
NAs’ ranges, it aﬀects the noise distribution added to every
miRNA similarly. The probability bound on the maximum
noise added to favg,i is thus large unless the pool contains a
large number n of samples, or  is large.

We now evaluate whether providing (γ, D[a,b]

B )-positive mem-

bership privacy by considering a weaker adversary can help
reduce the amount of noise in our context. To achieve mem-
bership privacy for bounded prior membership probabilities,
we can derive  according to Theorem 1 from γ and the pri-
ors a and b. Contrary to the application example in [32],
in which the adversary aims to distinguish the membership
between a case group of size n and a control group of size
N −n, our adversary has to determine membership in a pool
without knowing a priori that the victim is either in the case
group or in the control group. Therefore, our priors are not
the probabilities of being in the case group or in the control
group knowing that the victim is part of the N individuals
contributing their data to the study,5 but rather the proba-
bility that an individual contributed his data to a pool, given
that he is part of a given population, much larger than N .
Here, we assume the adversary only knows the country
in which the victim lives, and relies on the nation-wide
disease-prevalence statistics as background knowledge. Ta-
ble 1 presents the prior probabilities, for a victim living in
the US and for three cancers present in our dataset, and the
resulting values of the privacy parameter  for each disease
and typical values of γ. We notice that, for these values of
γ, the resulting  values do not diﬀer a lot between diﬀerent
diseases, even though the prevalence rate, or prior, of D3
is 30 times higher than D19’s rate/prior. This can be ex-
plained by the relatively small absolute priors given by the
prevalence rates.

5Under this assumption, the probability of being in the case
or control group is typically 0.5 [32].



D

D19
D17
D3

a, b

γ = 1.3

γ = 1.5

γ = 5

0.0003
0.0013
0.009

0.2624
0.2627
0.2651

0.4056
0.4061

0.41

1.6104
1.6145
1.6464

Table 1: Privacy parameters for the diseases
D19 (stomach tumor), D17 (renal cancer) and
D3 (prostate cancer – male only) achieving γ-
membership privacy under prior probability deter-
mined from disease prevalence rate in the US (col-
lected on [2]).

Fig. 3(b) illustrates the dependence of the utility bound
provided in Theorem 3 on the number of individuals in the
pool, and on the values of membership privacy parameter
γ. We depict the probability upper bound from Theorem 3
(referred to as η in the ﬁgure) for the general diﬀerential
privacy case (i.e.,  = ln(γ)) and for the case with bounded
priors, given membership-privacy parameters γ1 = 1.5 and
γ2 = 5, and pools of sizes n1 = 100 and n2 = 1000. For the
case with bounded priors (so-called “bounded” in the ﬁgure),
the privacy parameter  corresponding to the membership-
privacy parameter γ has been derived from the priors of
disease D3, as provided in Table 1.

We make the following observations from Fig. 3(b). First,
for prior membership probabilities that are relevant for our
use case, using the privacy parameter with bounded pri-
ors determined by Theorem 1 does not make a noticeable
diﬀerence to using traditional diﬀerential privacy (with un-
bounded priors). Using the privacy parameter determined
for the other two diseases (D19 or D17) in Table 1 leads
us to the same conclusion. Therefore, we suggest to make
use of traditional diﬀerential privacy as it provides privacy
guarantees against a stronger adversary. For this reason,
we focus on traditional diﬀerential privacy in our empirical
evaluations in the next subsection.

Second, the accuracy of the noised summary statistic in-
creases exponentially with the sample size n. This is con-
sistent with the result of Theorem 2. In other words, the

326(a)

(b)

(c)

Figure 4: Membership inference attacks in the presence of a diﬀerentially private mechanism. AUCs and
noise-to-mean ratios for three case groups: (a) stomach tumor, (b) renal cancer, (c) prostate cancer.

higher n is, the less powerful is the membership attack and
the less noise needs to be added to the summary statistics
for guaranteeing diﬀerential privacy. We can therefore only
encourage biomedical researchers to increase the size of their
miRNA pools, which will beneﬁt both privacy, accuracy, and
signiﬁcance of their results.
Finally, for the pool sizes we observe in our dataset, the
expected accuracy of our noisy summary statistic f(cid:48)
avg will
be very bad unless we signiﬁcantly increase the privacy pa-
rameter . Fig. 3(c) shows how our utility bound evolves
depending on the parameter . By comparing the noise val-
ues y with the means’ CCDF of Fig. 3(a), we clearly notice
that the noise is too large with respect to most of the miR-
NAs’ means with the chosen (low) privacy parameters. Since
 is a parameter that can be freely chosen by the designer of
the sanitization mechanism, we will, in our evaluation in the
following section, examine how far we can increase  while
at the same time ensuring that the attacks presented in Sec-
tion 3 are countered. In any case, given the sensitivity of the
mean statistics of miRNA expressions, we can expect that 
will have to be large to reach a level of noise that is not too
high. Then, if  is large (and consequently γ is very large),
there is again almost no utility diﬀerence between provid-
ing membership privacy with bounded or unbounded priors
(i.e., diﬀerential privacy).

4.2 Experimental Results

In this section, we evaluate ﬁrst the impact of the diﬀeren-
tially private mechanism on the membership attack, and on
the utility. Then, we evaluate the eﬀect of hiding a certain
number of released miRNA expression means.

Differentially Private Mechanism.

We follow the approach presented above for ensuring -
diﬀerential privacy. That is, we generate the noise vector
Y from m randomly generated Laplacian samples drawn
) and add its value to the vector of miRNA
from L(
expression means: ˆµ(cid:48) = ˆµ + Y.

k=1 δk
n

(cid:80)m

We repeat this process 1000 times, evaluate each run as
presented in Section 3.2, and derive the average ROC curve
and its resulting area under the curve (AUC) for  between
1 and 104. Note that an AUC of 0.5 represents a similar per-
formance as randomly guessing whether the victim is part
of the pool or not, meaning best privacy. On the contrary,

an AUC of 1 represents the worst outcome from a privacy
perspective: 100% power at any false-positive level.

(cid:80)m

In this subsection, we focus on three case groups related
to cancer that represent the groups for which the member-
ship attack was most successful (see Fig. 2). Figures 4(a)–
(c) show the AUC of the L1 distance and LR attacks, and
the noise-to-mean ratio 1
resulting from the noise
m
mechanism. This ratio can be viewed as an indicator of
the utility of the published statistics: A ratio of 0 means
that all utility is preserved whereas a ratio of 1 means that,
on average (over all runs and miRNAs), the added noise is
equivalent to the initial mean.

|Yi|
ˆµi

i=1

First of all, we observe that, for all three depicted case
groups, when noise is added to the actual means, the L1
distance test can perform better than the LR test. In other
words, the L1 distance test is more robust to noise than
the LR test. While this observation might seem counter-
intuitive at ﬁrst glance, especially because of the Neyman-
Pearson lemma, it becomes more apparent when revisiting
the impact of the noise on the tests: The L1 distance test
is inﬂuenced by the noise in a linear shift of the distance
between the victim and the pool’s mean values. However, for
the LR test, this distance is scaled quadratically. Hence, the
LR test is more sensitive to noise than the L1 distance test.
Moreover, this observation does not invalidate the Neyman-
Pearson lemma, but changes the assumptions imposed on
the data.

In general, the ﬁgures show that there is no ideal  value
bringing both membership privacy and full utility. In order
to achieve perfect privacy against the membership attack
with the L1 distance,  must be smaller than 10. Choos-
ing the privacy parameter  = 10, however, can signiﬁcantly
decrease the utility of the miRNA expression means, from
approximately 100% added noise (compared to the mean)
for stomach tumor (Fig. 4(a)) to around 10% added noise
for prostate cancer (Fig. 4(c)). We clearly observe that the
number n of participants in the pool plays a positive role on
the privacy-utility trade-oﬀ, conﬁrming our analytical ﬁnd-
ings. Indeed, as already mentioned, a higher value of n re-
duces the noise for the same  value, and reduces the success
of the membership attack in general.

Hiding Mechanism.

Considering that the diﬀerentially private method adds
too much noise when n is relatively small (typically smaller

327(a)

(b)

(c)

Figure 5: Membership inference attacks in the presence of a hiding mechanism. AUCs for three case groups:
(a) stomach tumor, (b) renal cancer, (c) prostate cancer.

than 50, like for the stomach tumor and renal cancer case
groups), we also propose a non-perturbative mechanism that
discloses only a subset of miRNA expression means. Ideally,
this protection mechanism could obfuscate miRNA means
irrelevant to the research study, such as miRNAs that are
found not to be associated with the disease of interest.

In our experiments, we randomly select the subset of miR-
NAs to be hidden, in order to have a general idea on the
impact of hiding miRNA means. To this end, we ﬁrst ran-
domly sample 50 diﬀerent orders of the 466 miRNAs. Then,
for each of these 50 ordered sequences, we decrease the num-
ber of released miRNA expression means from all miRNAs
(m = 466) to m = 1. Finally, we average the attack results
over the 50 samples for every number m. Figures 5(a)–(c)
show the AUCs of the attacks presented in Section 3.

In contrast to the diﬀerentially private mechanism, the
hiding of miRNA expression means preserves the guarantees
of the Neyman-Pearson lemma and the assumptions of our
data model, yielding the LR attack to always outperform
the L1 distance attack. We also observe that the theoretical
LR’s AUC slightly underestimates the success of the attack,
as already noticed in Subsection 3.2, due to the disease-
√
speciﬁc pool. Moreover, we notice that theoretical AUC
m, as expected from relation (9)
curves are shaped like
of Theorem 2. This decreasing success of the attack is also
observed in both empirical curves, but in a sharper manner
and with a signiﬁcant decrease with very few miRNAs. The
empirical LR curve especially shows almost maximal AUC
for m = 50. This demonstrates that, in practice, due to
the type and behavior of miRNA data, the LR attack is
very robust against a decreasing number of released miRNA
means. This should again warn privacy designers about the
theoretical relation that underestimates the actual attack
success, with disease-speciﬁc pools.

Concerning the general impact of the hiding mechanism
on privacy, we notice that it does not substantially improve
the situation if more than 50 miRNA means are disclosed.
The number of published miRNA expressions has to be very
small in order to achieve low AUCs, typically smaller than
10. In comparison to the diﬀerentially private mechanism,
the AUCs with hiding never reach a point near random
guessing (i.e., 0.5). Hence, while this protection mechanism
might be more desirable for biomedical researchers, because
it does not perturb the released data, it is not able to fully
protect membership privacy.

5. RELATED WORK

Here, we present the previous work on membership pri-
vacy in genome-wide association studies (GWAS) and how
it relates to our work.

Homer et al. were the ﬁrst to present a membership attack
by relying upon allele frequencies (i.e., means of genomic
variants’ values) and the L1 distance between those and the
actual genomic data of the victim [19]. Wang et al. extend
this attack by making use of the correlations among the dif-
ferent positions in the genome [34]. This improvement on
the attack allows them to use the statistics related to only
a few hundreds genetic variants. Zhou et al. further ana-
lyze the theoretical complexity of membership and recovery
attacks based on summary statistics [38]. Sankararaman et
al. show empirically that the likelihood-ratio test is more
powerful than the L1 distance attack proposed by Homer
et al. [31]. Moreover, they derive a theoretical bound on
the LR test that provides a very good approximation of the
empirical LR test. Our work conﬁrms that, for miRNA ex-
pression data, the empirical LR test is better than the L1
distance attack. In contrast, our theoretical relation shows
that, in the miRNA case, for a successful attack, the number
of miRNAs m has to scale with the square of the number
n of participants in the pool. However, our relation is less
accurate than theirs with respect to the empirical evalua-
tion, especially when the pools contain individuals carrying
a speciﬁc disease. This discrepancy can be explained by two
facts: (i) the dimensions of both m and n are relatively small
compared to those in the genomic setting considered in [31],
typically an order of magnitude smaller for both, and (ii)
miRNAs are certainly more aﬀected by diseases than the
genome is (as the latter is very stable and only has a few
out of millions of variants associated with a given disease).
On the defense side, various papers have studied how to
properly apply noise on summary statistics for protecting
the privacy of GWAS participants. Johnson and Shmatikov
propose and implement algorithms for accurate and diﬀer-
entially private computation of various statistics of interest,
such as the location of the most signiﬁcant genomic vari-
ants, or the p-values of statistical tests between a given vari-
ant and the associated diseases [20]. Uhler et al. have also
proposed to rely on diﬀerential privacy for sharing GWAS
results privately.
In [33], they present methods for pri-
vately disclosing allele frequencies, chi-square statistics, and
p-values. In [36], Yu et al. extend these methods by allowing

328for an arbitrary number of cases and controls, assess their
performance and compare it with the mechanism proposed
by Johnson and Shmatikov. In [37], Yu et al. present a diﬀer-
entially private mechanism for logistic regression and show
how it can be applied to the analysis of GWAS data. In the
pharmacogenetics context, Fredrikson et al. show that diﬀer-
ential privacy mechanisms can induce bad warfarin dosing,
thus expose patients to an increased risk of stroke, bleeding
events, and mortality [16]. Many of these previous works
also highlight that the amount of noise to be added to the
summary statistics is non-negligible, and thus can lead to
an unacceptable loss for research utility.

Tram`er et al. [32] investigate how a relaxation of diﬀeren-
tial privacy that considers weaker adversary can help reach
a better privacy-utility trade-oﬀ for releasing diﬀerentially
private chi-square statistics in GWAS. We show that, given
the structure of miRNA expression data, the same relaxation
does not help much to improve utility in our context, and we
thus deduce that the traditional diﬀerential privacy model
can rather be used to release miRNA expression statistics.
Finally, Dwork et al. analyze the robustness of the member-
ship attack on noisy summary statistics, and brieﬂy present
a generalization to real-valued data [13]. Contrary to their
work, we have fewer restricting assumptions (such as the
range of the means bounded between -1 and 1 in their work),
we consider a reference population containing a substantially
greater number of individuals than in the pool, and we pro-
vide an experimental validation of our analytical results with
real data. Our theoretical relation conﬁrms their result, i.e.,
that the dimensionality of the data (referred to as m in this
work, d in theirs) for a successful attack scales with n2.
However, our empirical results demonstrate that these the-
oretical bounds should be taken very cautiously depending
on the application context.

6. CONCLUSION AND FUTURE WORK

This work sheds light on privacy risks stemming from
miRNA expression data, showing that it is possible to detect
membership in miRNA-based studies’ datasets by relying on
their published mean statistics.
In particular, we present
two attacks, one based on the L1 distance and the other
based on the likelihood-ratio test known to be optimal. The
theoretical limit derived for the latter attack has neverthe-
less to be taken very cautiously: Indeed, miRNA expressions
are substantially more aﬀected by the health status than ge-
nomic data. Therefore, as miRNA-based studies very often
contain individuals carrying speciﬁc diseases, their statistics
are further away from healthy general population’s statis-
tics, which in turn increases the adversary’s power to detect
membership of a given individual. Our experimental results
conﬁrm this by clearly showing that membership is much
easier to detect in disease-speciﬁc datasets than in random
ones.

Moreover, we propose and thoroughly study two protec-
tion mechanisms: The ﬁrst protection mechanism is based
on the notion of diﬀerential privacy, perturbing the released
miRNA expression means, whereas the second technique
only releases a subset of the miRNA expression means. We
observe that the diﬀerentially private mechanism is able to
protect the privacy, eﬀectively decreasing the attacks’ suc-
cess to nearly random guessing. However, the amount of
noise introduced by this protection mechanism might ren-
der the released statistics useless, in particular for small

datasets. In general, we recommend the following approach
for ensuring membership privacy for study participants and
preserving the biomedical utility of the data: Having a large
number of participants, at least a couple of hundreds and,
if necessary, slightly perturbing the summary statistics in a
diﬀerentially private manner.

Possible future directions include the derivations of theo-
retical bounds on the attack power with noisy statistics. It
would also be important to evaluate the impact of correlated
miRNAs. Finally, it could be interesting to formally quan-
tify the increased power of the attack when the adversary
does not aim to detect membership in one pool, but rather
wants to detect membership between two pools.

7. ACKNOWLEDGEMENTS

This work was supported by the German Federal Ministry
of Education and Research (BMBF) through funding for the
Center for IT-Security, Privacy and Accountability (CISPA)
(FKZ: 16KIS0656) and by the German Research Founda-
tion (DFG) via the collaborative research center “Methods
and Tools for Understanding and Controlling Privacy” (SFB
1223), project A5.

8. REFERENCES
[1] Arrayexpress. https://www.ebi.ac.uk/arrayexpress.

Accessed: 2016-02-12.

[2] Cancer statistics.

http://seer.cancer.gov/statfacts/html/all.html.
Accessed: 2016-05-18.

[3] Gene expression omnibus.

http://www.ncbi.nlm.nih.gov/geo. Accessed:
2016-02-12.

[4] Genome-wide association studies.

https://www.genome.gov/20019523/genomewide-
association-studies-fact-sheet/. Accessed: 2016-04-29.

[5] Health insurer anthem discloses customer and

employee data breach.
http://www.computerworld.com/article/2879649/
health-insurer-anthem-discloses-customer-and-
employee-data-breach.html. Accessed: 2016-02-03.

[6] Human miRNA disease database.

http://www.cuilab.cn/hmdd. Accessed: 2016-05-15.

[7] Medical data - a new target for hackers.

https://www.logpoint.com/se/about-us/blog/249-
medical-data-a-new-target-for-hackers. Accessed:
2016-02-03.

[8] Number of microRNAs in human genome skyrockets.

http://www.genengnews.com/gen-news-highlights/
number-of-micrornas-in-human-genome-skyrockets/
81250958/. Accessed: 2016-04-29.

[9] M. Backes, P. Berrang, A. Hecksteden, M. Humbert,

A. Keller, and T. Meyer. Privacy in epigenetics:
Temporal linkability of microRNA expression proﬁles.
In Proceedings of the 25th USENIX Security
Symposium, 2016.

[10] C. Dwork. Diﬀerential privacy: A survey of results. In

Proceedings of the 5th International Conference on
Theory and Applications of Models of Computation
(TAMC), pages 1–19, 2008.

[11] C. Dwork, F. McSherry, K. Nissim, and A. Smith.

Calibrating noise to sensitivity in private data

329analysis. In Proceedings of the Third Conference on
Theory of Cryptography (TCC), pages 265–284, 2006.
[12] C. Dwork and A. Roth. The algorithmic foundations

of diﬀerential privacy. Foundations and Trends in
Theoretical Computer Science, 9(3-4):211–407, 2014.

[13] C. Dwork, A. Smith, T. Steinke, J. Ullman, and

S. Vadhan. Robust traceability from trace amounts. In
Proceedings of the 56th IEEE Annual Symposium on
Foundations of Computer Science (FOCS), pages
650–669, 2015.

[14] S. O. Dyke, W. A. Cheung, Y. Joly, O. Ammerpohl,

P. Lutsik, M. A. Rothstein, M. Caron, S. Busche,
G. Bourque, L. R¨onnblom, et al. Epigenome data
release: a participant-centered approach to privacy
protection. Genome biology, 16:1–12, 2015.

[15] A. P. Feinberg and M. D. Fallin. Epigenetics at the

crossroads of genes and the environment. JAMA,
314:1129–1130, 2015.

[16] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and

T. Ristenpart. Privacy in pharmacogenetics: An
end-to-end case study of personalized warfarin dosing.
In Proceedings of the 23rd USENIX Security
Symposium, pages 17–32, 2014.

[17] R. C. Friedman, K. K.-H. Farh, C. B. Burge, and D. P.
Bartel. Most mammalian mrnas are conserved targets
of microRNAs. Genome research, 19(1):92–105, 2009.

[18] A. Ghosh, T. Roughgarden, and M. Sundararajan.
Universally utility-maximizing privacy mechanisms.
SIAM Journal on Computing, 41(6):1673–1693, 2012.

[19] N. Homer, S. Szelinger, M. Redman, D. Duggan,

W. Tembe, J. Muehling, J. V. Pearson, D. A. Stephan,
S. F. Nelson, and D. W. Craig. Resolving individuals
contributing trace amounts of dna to highly complex
mixtures using high-density snp genotyping
microarrays. PLoS Genet, 4(8):e1000167, 2008.

[20] A. Johnson and V. Shmatikov. Privacy-preserving

data exploration in genome-wide association studies.
In Proceedings of the 19th ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining (KDD), pages 1079–1087, 2013.

[21] P. A. Jones and S. B. Baylin. The epigenomics of

cancer. Cell, 128:683–692, 2007.

[22] A. Keller, P. Leidinger, A. Bauer, A. ElSharawy,

J. Haas, C. Backes, A. Wendschlag, N. Giese,
C. Tjaden, K. Ott, et al. Toward the blood-borne
mirnome of human diseases. Nature methods,
8:841–843, 2011.

[23] A. Keller, P. Leidinger, B. Vogel, C. Backes,

A. ElSharawy, V. Galata, S. C. Mueller, S. Marquart,
M. G. Schrauder, R. Strick, et al. mirnas can be
generally associated with human pathologies as
exempliﬁed for mir-144*. BMC medicine, 12(1):224,
2014.

[24] P. Leidinger, C. Backes, S. Deutscher, K. Schmitt,

S. C. Mueller, K. Frese, J. Haas, K. Ruprecht, F. Paul,
C. Stahler, et al. A blood based 12-mirna signature of
alzheimer disease patients. Genome Biol, 14, 2013.

[25] N. Li, W. Qardaji, D. Su, Y. Wu, and W. Yang.
Membership privacy: A unifying framework for
privacy deﬁnitions. In Proceedings of the 2013 ACM
SIGSAC Conference on Computer and
Communications Security (CCS), pages 889–900, 2013.

[26] E. Londin, P. Loher, A. G. Telonis, K. Quann,
P. Clark, Y. Jing, E. Hatzimichael, Y. Kirino,
S. Honda, M. Lally, et al. Analysis of 13 cell types
reveals evidence for the expression of numerous novel
primate-and tissue-speciﬁc microRNAs. Proceedings of
the National Academy of Sciences,
112(10):E1106–E1115, 2015.

[27] J. Lu, G. Getz, E. A. Miska, E. Alvarez-Saavedra,
J. Lamb, D. Peck, A. Sweet-Cordero, B. L. Ebert,
R. H. Mak, A. A. Ferrando, et al. MicroRNA
expression proﬁles classify human cancers. nature,
435(7043):834–838, 2005.

[28] J. Neyman and E. S. Pearson. On the problem of the

most eﬃcient tests of statistical hypotheses. 1992.

[29] I. A. Qureshi and M. F. Mehler. Advances in

epigenetics and epigenomics for neurodegenerative
diseases. Current neurology and neuroscience reports,
11:464–473, 2011.

[30] M. A. Rothstein, Y. Cai, and G. E. Marchant. The
ghost in our genes: legal and ethical implications of
epigenetics. Health matrix (Cleveland, Ohio: 1991),
19:1, 2009.

[31] S. Sankararaman, G. Obozinski, M. I. Jordan, and

E. Halperin. Genomic privacy and limits of individual
detection in a pool. Nature genetics, 41(9):965–967,
2009.

[32] F. Tram`er, Z. Huang, J.-P. Hubaux, and E. Ayday.

Diﬀerential privacy with bounded priors: reconciling
utility and privacy in genome-wide association studies.
In Proceedings of the 22nd ACM SIGSAC Conference
on Computer and Communications Security (CCS),
pages 1286–1297, 2015.

[33] C. Uhler, A. Slavkovi´c, and S. E. Fienberg.

Privacy-preserving data sharing for genome-wide
association studies. The Journal of Privacy and
Conﬁdentiality, 5(1):137, 2013.

[34] R. Wang, Y. F. Li, X. Wang, H. Tang, and X. Zhou.

Learning your identity and disease from research
papers: information leaks in genome wide association
study. In Proceedings of the 16th ACM Conference on
Computer and Communications Security (CCS), pages
534–544, 2009.

[35] L. D. Wood, D. W. Parsons, S. Jones, J. Lin,
T. Sj¨oblom, R. J. Leary, D. Shen, S. M. Boca,
T. Barber, J. Ptak, et al. The genomic landscapes of
human breast and colorectal cancers. Science,
318:1108–1113, 2007.

[36] F. Yu, S. E. Fienberg, A. B. Slavkovi´c, and C. Uhler.
Scalable privacy-preserving data sharing methodology
for genome-wide association studies. Journal of
Biomedical Informatics, 50:133–141, 2014.

[37] F. Yu, M. Rybar, C. Uhler, and S. E. Fienberg.

Diﬀerentially-private logistic regression for detecting
multiple-snp association in gwas databases. In Privacy
in Statistical Databases, pages 170–184, 2014.

[38] X. Zhou, B. Peng, Y. F. Li, Y. Chen, H. Tang, and

X. Wang. To release or not to release: evaluating
information leaks in aggregate human-genome data. In
Proceedings of the 16th European Symposium on
Research in Computer Security (ESORICS), pages
607–627, 2011.

330