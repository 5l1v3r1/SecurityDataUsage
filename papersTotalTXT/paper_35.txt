Privacy-Preserving Stream Aggregation with Fault

Tolerance

T-H. Hubert Chan1, Elaine Shi2, and Dawn Song2

1 The University of Hong Kong

2 UC Berkeley

Abstract. We consider applications where an untrusted aggregator would like
to collect privacy sensitive data from users, and compute aggregate statistics pe-
riodically. For example, imagine a smart grid operator who wishes to aggregate
the total power consumption of a neighborhood every ten minutes; or a market
researcher who wishes to track the fraction of population watching ESPN on an
hourly basis.
We design novel mechanisms that allow an aggregator to accurately estimate such
statistics, while offering provable guarantees of user privacy against the untrusted
aggregator. Our constructions are resilient to user failure and compromise, and
can efﬁciently support dynamic joins and leaves. Our constructions also exem-
plify the clear advantage of combining applied cryptography and differential pri-
vacy techniques.

1

Introduction

Many real-world applications have beneﬁtted tremendously from the ability to collect
and mine data coming from multiple individuals and organizations. These applications
have also spurred numerous concerns over the privacy of user data. In this paper, we
study how an untrusted aggregator can gather information and learn aggregate statis-
tics from a population without harming individual privacy. For example, consider a
smart grid operator who wishes to track the total electricity consumption of a neigh-
borhood every 15 minutes, for scheduling and optimization purposes. Since such power
consumption data can reveal sensitive information about individual’s presence and ac-
tivities, we wish to perform such aggregation in a privacy-preserving manner.

More generally, we consider the periodic distributed stream aggregation model.
Imagine a group of n users. In every time period, each user has some data point within
a certain range (−∆, +∆). An untrusted aggregator wishes to compute the sum of all
users’ values in each time period. Each user considers her data as sensitive, and does
not want to reveal the bit to the untrusted aggregator. How can we allow an untrusted
aggregator to periodically learn aggregate information about a group of users, while
preserving each individual’s privacy?

The problem of privacy-preserving stream aggregation was ﬁrst studied by Rastogi
et al. [13] and Shi et al. [14]. These two works demonstrate how to combine cryptog-

√
raphy with differential privacy and achieve O(1) error, while using differential privacy
techniques alone would result in at least Ω(

N) error [3] in this setting3.

Speciﬁcally, these two works [13, 14] both employ special encryption schemes
which work as follows: in each aggregation period, each user encrypts its (perturbed)
data value and sends the encrypted value to the aggregator. The aggregator has a crypto-
graphic capability allowing it to decrypt the sum of all users’ values, but learn nothing
else. In constructing such encryptions schemes, both works [13, 14] rely on the follow-
ing key idea: each user would incorporate a random value into their ciphertext; and the
aggregator’s capability also incorporates a random value. All of these random values
sum up to 0, and would cancel out in the decryption step, such that the aggregator can
recover the sum of all users’ values, but learn nothing else.

One major drawback of these earlier works [13, 14] is that these schemes are not
tolerant of user failures. Even if a single user fails to respond in a certain aggregation
round, the server would not be able to learn anything. This can be a big concern in real-
world applications where failures may be unavoidable. For example, in a smart sensing
applications, where data is collected from multiple distributed sensors, it is quite likely
that some sensor might be malfunctioning at some point, and fails to respond. Failure
tolerance is an important challenge left open by Shi et al. [14] and Rastogi et al. [13].
Summary of contributions. Our main contribution is to introduce a novel technique
to achieve fault tolerance, while incurring only a very small (logarithmic or poly-
logarithmic) penalty in terms of communication overhead and estimation error (see
Table 1). In our construction, the aggregator is still able to estimate the sum over the
remaining users when an arbitrary subset of users (unknown in advance) fail.

As a by-product of the fault tolerance technique, our scheme also supports dynamic
joins and leaves, which is another problem left open by previous work [13,14]. Specif-
ically, our scheme supports dynamic joins and leaves without having to perform costly
rekeying operations with every join and leave.

Apart from failure tolerance and dynamic joins/leaves, our scheme has another de-
sirable feature in that it requires only a single round of client-to-server communication.
On a very high level, our construction works as follows: in every time period, each user
uploads an encrypted and perturbed version of her data, and then the aggregator can
compute the noisy sum by using a cryptographic capability obtained during an initial
one-time setup phase.
Techniques. Our main technique for achieving failure tolerance may be of independent
interest. Speciﬁcally, we build a binary interval tree over n users, and allow the aggre-
gator to estimate the sum of contiguous intervals of users as represented by nodes in
the interval tree. In comparison with Shi et al. [14], the binary-tree technique allows us
to handle user failures, joins and leaves, with a small logarithmic (or polylog) cost in
terms of communication and estimation error.
More applications. Apart from the smart grid example mentioned earlier, the dis-
tributed stream aggregation problem is also widely applicable in a variety of problem

3 The lower bound holds when the aggregator sees all the messages in the protocol, for example,
in the case where each user communicates only with the aggregator.

Scheme

Naive

Rastogi et al.

[13]

Total
comm.
O(n)

O(n)

Shi et al. [14]

O(n)

Avg comm.
per user

O(1)

O(1)

O(1)

Error
√
n)

O(

O(1)

O(1)

This paper:

Yes

Fail-safe/Dynamic Security Comm.
joins & leaves Model model
C → S
C ⇔ S
C → S

DP
CDP
AO
CDP
AO

No

No

Sampling
(Online TR)

O( 1

ρ2 )

O( 1

ρ2n )

O(ρn)

Binary

O(n log n) O(log n)

˜O((log n)

3
2 )

Yes

Yes

DP

CDP

C ⇔ S
C→ S

DP: Differential Privacy

Obliviousness (explanations in Section 1.1)

CDP: Computational Differential Privacy

AO: Aggregator
C → S: client-to-server uni-directional

C ⇔ S: interactive between client and server

Table 1. Comparison between existing schemes and our contributions. The asympototic
bounds hide the privacy parameters  and δ. The parameter ρ denotes any constant between 0
and 1. The ˜O(·) notation hides a log log n factor.
In our full online technical report [2], we also propose two variants of sampling-based construc-
tions, in which a random subset of users respond by sending a perturbed version of their data.
The sampling constructions can be useful in applications where bandwidth efﬁciency is a major
concern. In particular, for arbitrarily small ρ between 0 and 1, we can achieve error O(ρn) with
O( 1

ρ2 ) words of total communication.

domains, such as distributed hot item identiﬁcation, sensing and monitoring, as well as
medical research. We elaborate more on these applications in the online full version [2].

1.1 Related Work

Differential privacy [1, 5, 6, 8] was traditionally studied in a setting where a trusted cu-
rator, with access to the entire database in the clear, wishes to release statistics in a way
that preserves each individual’s privacy. The trusted curator is responsible for introduc-
ing appropriate perturbations prior to releasing any statistic. This setting is particularly
useful when a company or a government agency, in the possession of a dataset, would
like to share it with the public.

In real-world applications, however, users may not trust the aggregator. A recent
survey by Microsoft [15] found that “...58% of the public and 86% of business leaders
are excited about the possibilities of cloud computing. But, more than 90% of them are
worried about security, availability, and privacy of their data as it rests in the cloud.”

Recently, the research community has started to consider how to guarantee differ-
ential privacy in the presence of an untrusted aggregator [13,14]. Rastogi et al. [13] and
Shi et al. [14] proposed novel algorithms that allow an untrusted aggregator to period-
ically estimate the sum of n users’ values, without harming each individual’s privacy.
In addition to (computational) differential privacy, these two schemes also provide ag-

gregator obliviousness, meaning that the aggregator only learns the noisy sum, but no
intermediate results.

Both of these schemes [13, 14], however, would suffer in the face of user failures,
thereby leaving resilience to node failure as one of the most important open challenges
in this area. Our Binary Protocol utilizes Shi et al.’s encryption scheme as a building
block, and we successfully solve the node failure problem.

Dwork et al. [7] study distributed noise generation, however, their scheme requires

interactions among all users.

The use of a binary tree in our construction may be reminiscent of Dwork et al. [9]
and Chan et al. [4], where they use a binary-tree-like construction for a completely
different purpose, i.e., to achieve high utility when releasing statistics continually in a
trusted aggregator setting.

2 Problem Deﬁnition and Assumptions
For simplicity, consider a group of n users each holding a private bit xi ∈ {0, 1} –
although our approach can be trivially adapted to the case where each user has a data
point within a certain discrete range. We use the notation x := (x1, x2, . . . , xn) ∈
{0, 1}n to denote the vector of all users’ bits, also referred to as an input conﬁguration.

An aggregator A wishes to estimate the count, denoted sum(x) :=(cid:80)

i∈[n] xi.

currently watching ESPN. The aggregator wishes to evaluate sum(x(t)) :=(cid:80)

Periodic aggregation. We are particularly interested in the case of periodic aggrega-
tion. For example, a market researcher may wish to track the fraction of the population
watching ESPN during different hours of the day. In general, in each time period t ∈ N,
we have a vector x(t) ∈ {0, 1}n, e.g., indicating whether each of the surveyed users is
i∈[n] x(t)
in every time period. For ease of exposition, we often focus our attention on the aggre-
gation algorithm in one time step, and as a result, omit the superscript t.
Failure tolerance. When a user fails, it stops participating in the protocol. A protocol
is failure tolerant, if for any subset of failed users, the aggregator can still make an
estimate on the sum of the bits from the remaining functioning users.
Communication model. In real-world applications, peer-to-peer communication is un-
desirable as it requires all users to be online simultaneously and interact with each other.
This paper will focus on schemes that requires no user-to-user communication, i.e., all
communication takes place between an aggregator and a user.

i

2.1 Assumptions and Privacy Deﬁnitions

Trust Model. We consider the scenario when the aggregator is untrusted. We think
of the aggregator as the adversary from whom we wish to protect the users’ privacy.
The aggregator does not have access to the users’ bits directly, but may have arbitrary
auxiliary information a priori. Such auxiliary information can be harvested in a vari-
ety of ways, e.g., from public datasets online, or through personal knowledge about a
user. Our constructions ensure individual privacy even when the aggregator may have
arbitrary auxiliary information.

Compromise. We assume a semi-honest model, where compromised users can collude
with the aggregator by revealing their input bits or random noises to the aggregator.
However, we assume that all users honestly use their inputs in the aggregation. The data
pollution attack, where users inﬂate or deﬂate their input values, is out of the scope of
this paper, and can be solved using orthogonal techniques such as [12]. In this paper,
we assume a slightly relaxed model of compromise, where the compromised nodes
are chosen independently from the randomness used in the algorithm (more details in
Section 4).
Key distribution. We assume that any cryptographic keys or privacy parameters re-
quired are already distributed to the aggregator and users in a separate setup phase ahead
of time. The setup phase needs to be performed only once at system initialization, and
need not be repeated during the periodic aggregation rounds.

We deﬁne a transcript π to be the sequence of all messages sent by the users and
the aggregator at the end of the protocol. As we consider protocols with no peer-to-
peer communication, i.e., all communication takes place between the users and the
aggregator, the view of the aggregator during the protocol is essentially the transcript
π.

Users (and the aggregator) may contribute randomness to the protocol, for example,
users will add noise to perturb their input bits. Therefore, we can deﬁne a distribution
on the transcripts. Formally, we use the notation Π to denote a randomized protocol,
and use Π(x) to denote the random transcript when the input conﬁguration is x.

In this paper, we consider the computational version of differential privacy, as in
practice it sufﬁces to secure the protocol against computationally-bounded adversaries.
We now deﬁne computational differential privacy (CDP), similar to the CDP notion
originally proposed by Mironov et al. [11].

In addition to the users’ data x, the protocol Π also takes a security parameter
λ ∈ N. We use the notation Π(λ, x) to denote the distribution of the transcript when
the security parameter is λ and the input conﬁguration is x.

Deﬁnition 1 (Computational Differential Privacy Against Compromise). Suppose
the users are compromised by some underlying randomized process C, and we use C
to denote the information obtained by the adversary from the compromised users. Let
, δ > 0. A (randomized) protocol Π preserves computational (, δ)-differential privacy
(against the compromise process C) if there exists a negligible function η : N → R+
such that for all λ ∈ N, for all i ∈ [n], for all vectors x and y in {0, 1}n that differ only
at position i, for all probabilistic polynomial-time Turing machines A, for any output
b ∈ {0, 1},
PrCi [A(Π(λ, x), C) = b] ≤ e · PrCi [A(Π(λ, y), C) = b] + δ + η(λ),
where the probability is taken over the randomness of A, Π and Ci, which denotes the
underlying compromise process conditioning on the event that user i is uncompromised.
A protocol Π preserves computational -differential privacy if it preserves compu-

tational (, 0)-differential privacy.

3 Preliminaries

3.1 Tool: Geometric Distribution

Two noise distributions are commonly used to perturb the data and ensure differential
privacy, the Laplace distribution [8], and the Geometric distribution [10]. The advantage
of using the geometric distribution over the Laplace distribution is that we can keep
working in the domain of integers. The geometric distribution is particularly useful
when used in combination with a crypto-system, e.g., our Binary Protocol described in
Section 4. Most crypto-systems work in discrete mathematical structures, and are not
designed to work with (truly) real numbers.

We now deﬁne the symmetric geometric distribution.

Deﬁnition 2 (Geometric Distribution). Let α > 1. We denote by Geom(α) the sym-
metric geometric distribution that takes integer values such that the probability mass
function at k is α−1

α+1 · α−|k|.

The following property of Geom distribution is useful for designing differentially

private mechanisms that output integer values.
Fact 1 Let  > 0. Suppose u and v are two integers such that |u − v| ≤ ∆. Let
r be a random variable having distribution Geom(exp( 
∆)). Then, for any integer k,
P r[u + r = k] ≤ exp() · P r[v + r = k].

α

2α

ln α = 1

In our setting, changing 1 bit can only affect the sum by at most 1. Hence, it sufﬁces
(α−1)2 . Since
 ). The following diluted

to consider Geom(α) with α = e. Observe that Geom(α) has variance
√
α−1 ≤ 1
geometric distributions is useful in the description of our protocols.
Deﬁnition 3 (Diluted Geometric Distribution). Let 0 < β ≤ 1, α > 1. A random
variable has β-diluted Geometric distribution Geomβ(α) if with probability β it is sam-
pled from Geom(α), and with probability 1 − β is set to 0.

 , the magnitude of the error added is O( 1

3.2 Naive Scheme

We describe a simple scheme as a warm-up, and as a baseline of comparison. In the
Naive Scheme, each user generates an independent Geom(e) noise, which is added to
her bit. Each user sends her perturbed bit to the aggregator, who computes the sum of all
the noisy bits. As each user adds one copy of independent noise to her data, n copies of
noises would accumulate in the sum. As some positive and negative noises may cancel
√
 ) with high probability. Notice that if we employs
out, the accumulated noise is O(
the information-theoretic (as opposed to computational) differential privacy notion, the
naive scheme is in some sense the best one can do. Chan et al. [3] show in a recent
work that in a setting with n users and one aggregator, any (information theoretically)
differential private summation protocol with no peer-to-peer interaction must result in
an error of Ω(

N).

√

n

(a) The aggregator obtains block esti-
mates corresponding to all nodes appear-
ing in the binary interval tree.

(b) When user 5 fails, the aggregator sums up
the block estimates corresponding to the black
nodes.

Fig. 1. Intuition for the Binary Protocol.
4 Binary Protocol: Achieving Failure Tolerance

4.1

Intuition

Consider the periodic aggregation scheme proposed by Shi et al. [14], henceforth re-
ferred to as the Block Aggregation (BA) scheme. In the BA scheme, every time period,
each user sends a perturbed and encrypted version of her data to the aggregator. The ag-
gregator has a cryptographic capability to decrypt the sum of all encrypted values, but
can learn nothing else. The BA scheme achieves O(1) error. and guarantees all users’
differential privacy against polynomial-time adversaries.

Unfortunately, the use of cryptography in the BA scheme introduces the all-or-
nothing decryption model. Therefore, the aggregator learns nothing if a single user fails.
√
The challenge. On one hand, we have the naive scheme which achieves O(
n) error,
and is failure tolerant On the other hand, we have the BA Scheme which achieves O(1)
error (by combining cryptography with differential privacy), but is unfortunately not
failure tolerant. Can we seek middle-ground between these approaches, such that we
can obtain the best of both worlds, i.e., achieve both fault tolerance and small error?
Binary tree idea. One idea is to form user groups (henceforth referred to as blocks),
and run the BA Scheme for each block. The aggregator is then able to estimate the sum
for each block. If a subset of the users fail, we must be able to ﬁnd a set of disjoint
blocks to cover the functioning users. In this way, the aggregator can estimate the sum
of the functioning users. The challenge is how to achieve this with only a small number
of groups.

As depicted in Figure 1, our construction is based on a binary interval tree, hence
the name Binary Protocol. For ease of exposition, assume for now that n is a power of 2.
Each leaf node is tagged with a number in [n]. Each internal node in the tree represents
a contiguous interval covering all leaf nodes in its subtree. As a special case, we can
think of the leaf nodes as representing intervals of size 1. For each node in the tree, we
also use the term block to refer to the contiguous interval represented by the node.

Intuitively, the aggregator and users would simultaneously perform the BA Scheme
for every interval (or block) appearing in the binary tree. Hence, the aggregator would

 14735628[1,4][3,4][5,6][7,8][1,2][5,8][1,8][1,4][3,4][5,6][7,8][1,2][5,8][1,8] 475628F13obtain an estimated sum for each of these blocks. Normally, when n is a power of
2, the aggregator could simply output the block estimate for the entire range [1, n].
However, imagine if a user i fails to respond, the aggregator would then fail to obtain
block estimates for any block containing i, including the block estimate for the entire
range [1, n].

Fortunately, observe that any contiguous interval within [n] can be covered by
O(log n) nodes in the binary interval tree. If κ users have failed, the numbers 1 through
n would be divided into κ + 1 contiguous intervals, each of which can be covered by
O(log n) nodes. This means that the aggregator can estimate the sum of the remaining
users by summing up O((κ + 1) log n) block estimates.
Example. For convenience, we use the notation sum[i..j] (where 1 ≤ i ≤ j ≤ n)
to denote the estimated sum for the block xi, xi+1, . . . , xj of user inputs. Figure 1
depicts a binary tree of size n = 8. When all users are active, the aggregator can obtain
block estimates corresponding to all nodes in the tree. Therefore, the aggregator can
simply output block estimate sum[1..8]. Figure 1 illustrates the case when user 5 has
failed. When this happens, the aggregator fails to obtain the block estimates sum[5..5],
sum[5..6], sum[5..8], and sum[1..8], since these blocks contain user 5. However, the
aggregator can still estimate the sum of the remaining users by summing up the block
estimates corresponding to the black nodes in the tree, namely, sum[1..4], sum[6..6],
and sum[7..8].
Privacy-utility tradeoff. We now give a quick and informal analysis of the privacy-
utility tradeoff. It is not hard to see that each user is contained in at most O(log n)
blocks. This means that if a user’s bit is ﬂipped, O(log n) blocks would be inﬂuenced.
Roughly speaking, to satisfy -differential privacy, it sufﬁces to add noise proportional
to O( log n

) to each block.



If κ users fail, we would be left with κ + 1 intervals. Each interval can be covered
by O(log n) nodes in the binary tree. Therefore, the ﬁnal estimate would consist of
O((κ + 1) log n) block estimates. Since each block estimate contains O( log n
) noise,
the ﬁnal estimate would contain O((κ + 1) log n) copies of such noises. As some pos-
itive and negative noises cancel out, the ﬁnal estimate would contain noise of roughly
O( (log n)1.5√

) magnitude.

κ+1





In the remainder of the section, we ﬁrst give a formal description of the BA Scheme [14]

used as a building block of the Binary Protocol. Then we formally describe the Binary
Protocol and state the theorems on the privacy and utility tradeoff.

4.2 Background: Basic Block Construction

We will use the BA Scheme [14] as a building block to aggregate the sum for each block
(or subset) B ⊆ [n] of users. We now explain at a high level how the BA scheme works.
Note that in place of the BA scheme by Shi et al. [14], the binary tree framework also
readily applies on top of the scheme by Rastogi et al. [13]. The tradeoffs are discussed
later in Section 5.
Encryption scheme. The BA Scheme leverages an encryption scheme that allows an
aggregator to decrypt the sum of all users’ encrypted values (with an appropriate cryp-

tographic capability), but learn nothing more. The encryption scheme has three (possi-
bly randomized) algorithms.

– Setup(m, λ): A one-time setup algorithm, run by a trusted dealer, takes the number

of users m, and a security parameter λ as inputs. It outputs the following:

(params, cap,{ski}i∈[m]),

where params are system parameters, e.g., a description of the selected algebraic
group. Capability cap is distributed to the aggregator, and ski (i ∈ [m]) is a secret
key distributed to user i. The users will later use their secret keys to encrypt, and
the aggregator will use its capability to decrypt the sum, in each aggregation period.
The setup algorithm is performed only once at system initialization, and need not
be repeated for each periodic aggregation round.

– Encrypt(ski, xi, t): During time step t, user i uses ski to encrypt its (possibly per-
turbed) data xi. The user uploads the outcome ciphertext ci to the aggregator.
– Decrypt(cap,{ci}i∈[m], t): During time step t, after the aggregator collects all users’
ciphertexts {ci}i∈[m], it calls the decryption algorithm Decrypt to retrieve the sum

i∈[m] xi. Apart from this sum, the aggregator is unable to learn anything else.

(cid:80)
condition r +(cid:80)m

The BA scheme relies on the following key idea. In the Setup phase, each user
i (1 ≤ i ≤ m) obtains a secret-key which incorporates a random value ri. The ag-
gregator obtains a capability which incorporates a random value r. Furthermore, the
i=1 ri = 0 is satisﬁed. In every aggregation period, each user incorpo-
rates its random value ri into its ciphertext. After collecting all ciphertexts from users,
the aggregator can homomorphically “sum up” all ciphertexts, such that the random
values r, r1, . . . , rm cancel out, and the aggregator can thus decrypt the sum of all
users’ encrypted values. The above is a grossly simplied view of the BA scheme in-
tended to capture the intuition. The full construction is more sophisticated, and requires
additional techniques to allow the random values distributed in the Setup phase to be
reusable in multiple aggregation phases, while still maintaining security.
Input perturbation. Revealing the exact sum to the aggregator can still harm an in-
dividual’s differential privacy. To guarantee differential privacy, each user adds some
noise to her data before encrypting it.

Recall that in the naive scheme, each user must add one copy of geometric noise to
guarantee its own differential privacy. In the BA Scheme, however, the aggregator can
only decrypt the sum, and cannot learn each individual’s perturbed values. Therefore,
as long as the all users’ noises sum up to roughly one copy of geometric noise, each
user’s differential privacy can be guaranteed. This is why the BA Scheme construction
can guarantee O(1) error.

Let , δ denote the privacy parameters. In every time step t, each user i generates
(cid:98)xi := xi + ri. In other words, with probability β, the noise ri is generated from the
an independent ri from the diluted geometric distribution Geomβ(α) and computes
geometric distribution Geom(α), and with probability 1 − β, ri is set to 0. Speciﬁcally,
δ , 1}. This ensures that with high probability,
we choose α := e, and β := min{ 1
at least one user has added Geom(e) noise. More generally, if 1 − γ fraction of the
users are compromised, then we set β := min( 1

m ln 1

γm ln 1

δ , 1).

# run by a trusted dealer

SETUP(n, λ, , δ):
1: K ← (cid:98)log2 n(cid:99) + 1
2: 0 ← 
K , δ0 ← δ
3: Give 0 and δ0 to all users.
4: for B ∈ T (n) do
5:
BA.Setup(|B|, λ)

(params, capB,{ski,B}i∈B)

K

←

Give params to aggregator and all users.
Give capB to the aggregator.
Give ski,B and |B| to each user i ∈ B.

6:
7:
8:
9: end for

ALGAGGR`S,{capB}B∈T (n),{ci,B}i∈S,B∈B(i)

´:

Periodic aggregation – the aggregator’s

#
algorthm
1: Find a set of blocks B to uniquely cover S.
2: s ← 0
3: for B ∈ B do
sB ← BA.Decrypt(capB,{ci,B}i∈B)
4:
s ← s + sB
5:
6: end for
7: return the estimated sum s

ALGUSER`xi, t,B(i),{ski,B}i∈B(i), 0, δ0

´:

# Periodic aggregation – user i’s algorithm
1: for B ∈ B(i) do
2:
3:
4:
5:
6:
7: end for

β ← min( 1|B| ln 1
bxi,B ← xi + r
r ← Geomβ(e0 )
ci,B ← BA.Encrypt(ski,B,bxi,B, t)

Send ci,B to aggregator.

, 1)

δ0

λ
n
t
xi
T (n)

, δ
ski,B

security parameter
total number of users

current round

user i’s data in current round

set of all blocks corresponding to
nodes in a binary tree of size n

privacy parameters

user i’s secret key for block B

where i ∈ B

capB aggregator’s capability for block B

S

B(i)

set of functioning users

in current round

B(i) := {B|B ∈ T (n) and i ∈ B}

set of blocks containing user i

The user then computes the ciphertext ci := Encrypt(ski,(cid:98)xi, t), where (cid:98)xi is the

Fig. 2. The Binary Protocol.

purtubed data, and uploads the ciphertext to the aggregator.
Theorem 1 (Computational Differential Privacy of BA). Let  > 0, 0 < δ < 1 and
β := min{ 1
δ , 1}, where γ is the probability that each user remains uncompro-
mised. If each user adds diluted Geometric noise Geomβ(α) (where α = e), then at
each time step, the Block Aggregation Scheme is computationally (, δ)-differentially
private against compromised users.

γm ln 1

4.3 Binary Protocol: Construction

The Binary Protocol consists of running the BA Scheme over a collection of blocks
simultaneously. Speciﬁcally, if n is a power of 2, then one can build a binary interval
tree of the n users such as in Figure 1(a). Each node in the tree represents a contiguous
interval, which we call a block. The aggregator and users would run the BA Scheme for
all blocks depicted in the interval tree. It is not hard to see that each user i is contained
in at most K := (cid:98)log2 n(cid:99) + 1 blocks, represented by nodes on the path from the i-th
leaf node to the root of the tree.

We now state the above description more formally. Given integers k ≥ 0 and j ≥ 1,
j := {2k(j − 1) + l : 1 ≤ l ≤ 2k} of integers. If
j ⊆ [n]. Deﬁne

the jth block of rank k is the subset Bk
there are n users, we only need to consider the blocks Bk
T (n) to be the set of all relevant blocks when there are n users.
j ⊆ [n]}

j |k ≥ 0, j ≥ 1, Bk

T (n) := {Bk

j such that Bk

Speciﬁcally, when n is a power of 2, T (n) basically corresponds to the collection of
all nodes in the binary interval tree with n leaf nodes. It is not hard to see that the total
number of blocks is at most 2n. The following observations will be important in the
design of the Binary Protocol.
Observation 1 Each user i ∈ [n] is contained in at most K := (cid:98)log2 n(cid:99) + 1 blocks. In
particular, each user is in at most one block of rank k.

Setup phase. Like in the BA Scheme, a one-time trusted setup is performed at system
initialization. A trusted dealer distributes O(log n) secret keys to each user. In partic-
ular, each user i ∈ [n] obtains one secret key corresponding to each block containing
the user (i.e., the path from the i-th leaf node to the root). We use the notation ski,B to
denote user i’s secret key corresponding to the block B.
For each block B ∈ T (n), the trusted dealer issues a capability capB to the aggre-
gator. The aggregator thus receives O(n) capabilities. The parties also agree on other
system parameters including the privacy parameters (, δ).
Periodic aggregation: user algorithm. In each time step t ∈ [n], each user i performs
the following:

For each block B containing the user i, the user generates a fresh random noise r
from the diluted geometric distribution Geomβ(e0), where the choice of parameters
β and 0 will be explained later. The user adds the noise ri,B to her input bit xi, and

obtains(cid:98)xi,B := xi + ri,B. The user then encrypts(cid:98)xi,B using ski,B, i.e., her secret key

corresponding to the block B. Speciﬁcally, user i computes

ci,B := BA.Encrypt(ski,B,(cid:98)xi,B, t)

The ﬁnal ciphertext ci uploaded to the aggregator is the collection of all ciphertexts,

one corresponding to each block containing the user i.

ci := {ci,B|B ∈ T (n), i ∈ B}

As each user is contained in O(log n) blocks, the ciphertext size is also O(log n).
Parameter choices. Suppose we wish to guarantee computational (, δ)-differential
privacy for the Binary Protocol, where (, δ) are parameters agreed upon by all parties
in the setup phase. Each user needs to determine the parameters 0 and β when generat-
ing a noise from the diluted geometric distribution Geomβ(e0). Speciﬁcally, each user
K , where K := (cid:98)log2 n(cid:99)+1. When selecting noise for a block B of size
chooses 0 := 
|B|, the user selects an appropriate β := min{ 1|B| ln 1
K . Notice that
due to Theorem 1, the above choice of 0 and β ensures that each separate copy of the
BA Scheme satisﬁes computational (0, δ0)-differential privacy. This fact is used later
to analyze the differential privacy of the entire Binary Protocol.

, 1}, where δ0 = δ

δ0

More generally, if each user may be compromised with independent probability
γ|B| ln 1
δ0

Intuitively, using the diluted geometric distribution, each user effectively adds a
geometric noise with probability β, and adds 0 noise with probability 1− β. Notice that
β is smaller if the block size is bigger, since we wish to guarantee that at least one user
added a real geometric noise.
1 − γ, then each (uncompromised) user would choose 0 := 
for a block B whose size is |B|, where δ0 := δ
K .
Periodic aggregation: aggregator algorithm. Suppose 0 ≤ κ < n users have failed to
respond. Then the entire range [n] would be divided up into κ + 1 contiguous interval.
The aggregator will recover the noisy sum for each of these intervals, and the sum of
these will be the estimate of the total sum.

K , and β := 1

It sufﬁces to describe how to recover the noisy sum for each of these contiguous
intervals. An important observation is that each contiguous interval within [n] can be
covered uniquely by O(log2 n) blocks. This is stated more formally in the following
observation.

Observation 2 (Unique cover for a contiguous interval.) Let [s, t] denote a contigu-
ous interval of integers within [n], where 1 ≤ s ≤ t ≤ n. We say that [s, t] can be
covered uniquely by a set of blocks B ⊆ T (n), if every integer in [s, t] appears in ex-
actly one block in B. For any interval [s, t] ⊆ [n], it is computationally easy to ﬁnd set
of at most 2(cid:100)log2 n(cid:101) + 1 blocks that uniquely cover [s, t].
Therefore, to recover the noisy sum for an interval [s, t] ⊆ [n], the aggregator ﬁrst
ﬁnds a set of blocks B to uniquely cover [s, t]. Then, the aggregator decrypts the noisy
sum for each block B ∈ B by calling the decryption algorithm: BA.Decrypt(capB,{ci,B}i∈B).
The sum of all these block estimates is an estimate of the total sum.

One possible optimization for decryption is to leverage the homomorphic property
of the BA Scheme [14]. Instead of decrypting each individual block estimates, the ag-
gregator can rely on the homomorphic property to compute an encryption of the sum
of all block estimates. In this way, only one decryption operation is required to decrypt
√
the estimated sum. As mentioned in Section 4.7 decryption takes O(n) time using the
brute-force approach, and O(

n) time using Pollard’s Rho method.

This concludes the description of our Binary Protocol. Earlier in Section 4.1, we
explained the intuition of the above Binary Protocol with a small-sized example. In the
remainder of this section, we will focus on the privacy and utility analysis.

4.4 Theoretic Guarantees

(cid:113) κ+1

Theorem 2 below states that our Binary Protocol satisﬁes computational (, δ)-differential
privacy, and achieves an error bound of ˜O( (log n)1.5
γ ) with high probability (hid-
ing a log log n factor and δ, η parameters). Here κ is the number of failed users, and γ
is the fraction of users that remain uncompromised.



The intuition behind the proof was explained earlier in Section 4.1. Due to space

constraint, we defer the full proof of this theorem to the online full version [2].

Theorem 2 (Error Bound with κ-Failed Users). Let  > 0 and 0 < δ < 1. Sup-
pose each of the n users remains uncompromised independently with probability γ.
Then, the Binary Protocol can be run such that it is computationally (, δ)-differentially
private. Moreover, when there are κ failed users, for 0 < η < 1 subject to some
technical condition4, with probability at least 1 − η, the aggregator can estimate the
·
sum of the participating users’ bits with additive error at most O( (log n)1.5

·(cid:113) κ+1



γ

(cid:113)

(log log n + log 1

δ ) log 1

η ).

4.5 Dynamic Joins

First, imagine that the system knows beforehand an upper-bound n = 2K on the total
number of users – if n is not a power of 2, assume we round it up to the nearest power of
2. We will later discuss the case when more than n users actually join. In this case, when
a new user i joins, it needs to contact the trusted dealer and obtain a secret key ski,B for
every block B ∈ T (n) that contains i. However, existing users need not be notiﬁed. In
this case, the trusted dealer must be available to register newly joined users, but need
not be online for the periodic aggregation phases. The trusted dealer may permanently
erase a user’s secret key (or the aggregator’s capability) after its issuance.

What happens if more users join than the anticipated number n = 2K? We propose

2 strategies below.
Key updates at every power of two. When the number of users exceeds the budget n =
2K, the trusted dealer sets the new budget to be n(cid:48) := 2K+1, and issues new keys and
capabilities to the users and aggregator as follows. For every new block B that forms in
T (n(cid:48)) but is not in T (n), a new secret key (or capaiblity) needs to be issued to every user
contained in B (and the aggregator). Notice that the secret keys for existing blocks in
T (n) need not be updated. In this way, each existing user obtains one additional secret
key, the newly joined user obtains O(log n) secret keys, and the aggregator obtains
O(n) capabilities. Notice that such key updates happen fairly infrequently, i.e., every
time the number of users reach the next power of 2.
Allocate a new tree. When the number of users reach the next power 2K of two, the
trusted dealer allocates a new tree of size 2K. For every block in the new tree, the trusted
dealer issues a capability to the aggregator corresponding to that block. For the next 2K
users that join the system, each user is issued O(K) secret keys corresponding to blocks
in the new tree. Hence, the sizes of the trees are 1, 1, 2, 4, 8, ... and so on.

When the aggregator estimates the sum, it will simply sum up the estimate cor-
responding to each tree. Suppose the number of current users is n. Then, there are
O(log n) such trees. A straightforward calculation shows that the additive error made
by the aggregator will be ˜O( (log n)3

) with high probability.

The advantage of this approach is that only the aggregator needs to be notiﬁed when
the number of users changes. The existing users need not be notiﬁed. Therefore, this
δ ≥

4 The following condition is satisﬁed certainly when n is large enough: (κ+1) log2 n
exp(

ln log2 n

γ





η .
log2 n ) ln 2

approach is particularly suited when making push notiﬁcations to users may be difﬁcult
(e.g., when users are frequently ofﬂine).

4.6 Dynamic Leaves
When a user leaves, that user can be treated as permanently failed. As mentioned in
Theorem 2, the estimation error grows only sub-linearly in the number of absent users.
For reduced error and higher utility, sometimes we may consider repeating the setup
phase when too many users have left. The application designer can make this choice to
ﬁt the characteristics and requirements of the speciﬁc application.

4.7 Practical Performance
Consider a scenario with n (cid:39) 10, 000 users. The Binary Protocol leverages the BA
Scheme scheme proposed by Shi et al. [14]. According to their performance estimates [14],
each encryption takes about 0.6 ms on a modern computer, when we use high-speed el-
liptic curves such as “curve25519”. When n (cid:39) 10, 000, each user needs to perform
roughly (cid:98)log2 n(cid:99) + 1 = 14 encryptions. Therefore, a user’s computation overhead is
roughly 8 ∼ 9 ms on a modern computer.

Decryption of the underlying BA Scheme requires taking a discrete logarithm. The
brute-force method involves enumerating the plaintext space. It takes one modular ex-
ponentiation, roughly 0.3 ms to try each possible plaintext. With n = 10, 000 users, our
simulation shows that the additive error is under 500 with > 99% probability (when
 = 0.5, δ = 0.05, and in the absence of failures). Therefore, the brute-force method
takes on average 1.5 seconds to decrypt the sum. We can speed up decryption signiﬁ-
cantly using one of the following methods: 1) Use Pollard’s Rho method, which reduces

the decryption overhead to about(cid:112)n + o(n). 2) Exploit parallelism. The brute-force

method is trivially parallelizable, and particularly suited for modern clusters such as
MapReduce or Hadoop.

5 Discussions

Faster decryption. One limitation of the proposed scheme is that the decryption time
√
is O(
n) using Pollard’s Rho method. As a result, we need the plaintext space to be
polynomially sized. While Sections 4.3 and 4.7 have proposed some methods to make
decryption faster in practice, we also point out that another method would be to replace
the encryption scheme entirely with the encryption scheme used by Rastogi et al. [13].
Basically, the binary tree method can be regarded as a generic approach which can
be applied on top of both the works by Rastogi et al. [13] and Shi et al. [14]. If we
use the scheme by Rastogi et al. [13] as a building block, we remove the constraint of
polynomially-sized plaintext space, at the cost of introducing interactions between the
users and the server (however, still, no peer-to-peer interaction would be needed).
Operations in an algebraic group. Due to the use of cryptography, integer additions
are in fact performed in a discrete mathematical group of prime order p, which is needed
by the encryption algorithm in the BA Scheme. Our error analysis also guarantees that
with high probability, no integer overﬂow or underﬂow will happen.

6 Conclusion

We investigated how an untrusted aggregator can learn aggregate statistics about a group
of users without harming each individual’s privacy. Our construction addresses fault tol-
erance, a question left open by earlier works in this area [13,14]. Our construction is de-
sirable in the sense that it requires no peer-to-peer communication (unlike the traditional
approach of Secure Multi-Party Computation), and achieves high utility guarantees.

Acknowledgments

This work is partially supported by the National Science Foundation under Grants
No. 0716230, 0448452 and CCF-0424422, and by the Ofﬁce of Naval Research under
MURI Grant No. N000140911081. Any opinions, ﬁndings, and conclusions or recom-
mendations expressed in this material are those of the authors and do not necessarily
reﬂect the views of the National Science Foundation, or the Ofﬁce of Naval Research.

References

1. A. Blum, K. Ligett, and A. Roth. A learning theory approach to non-interactive database

privacy. In STOC, 2008.

2. H. Chan, E. Shi, and D. Song. Privacy-preserving stream aggregation with fault tolerance.

Full online technical report, http://eprint.iacr.org/2011/722.pdf, 2011.

3. H. Chan, E. Shi, and D. Song. Tight lower bounds for distributed private data analysis. In

submission, 2011.

4. T.-H. H. Chan, E. Shi, and D. Song. Private and continual release of statistics. In ICALP,

2010.

5. C. Dwork. Differential privacy. Invited talk at ICALP, 2006.
6. C. Dwork. A ﬁrm foundation for private data analysis.

In Communications of the ACM,

2010.

7. C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves:

Privacy via distributed noise generation. In EUROCRYPT, 2006.

8. C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private

data analysis. In TCC, 2006.

9. C. Dwork, M. Naor, T. Pitassi, and G. N. Rothblum. Differential privacy under continual

observation. In STOC, 2010.

10. A. Ghosh, T. Roughgarden, and M. Sundararajan. Universally utility-maximizing privacy

mechanisms. In STOC, 2009.

11. I. Mironov, O. Pandey, O. Reingold, and S. Vadhan. Computational differential privacy. In

CRYPTO, 2009.

12. B. Przydatek, D. Song, and A. Perrig. Sia: secure information aggregation in sensor net-

works. In ACM Sensys, 2003.

13. V. Rastogi and S. Nath. Differentially private aggregation of distributed time-series with

transformation and encryption. In SIGMOD 2010, pages 735–746, 2010.

14. E. Shi, H. Chan, E. Rieffel, R. Chow, and D. Song. Privacy-preserving aggregation of time-

series data. In NDSS, 2011.

15. L. Whitney. Microsoft urges laws to boost trust in the cloud. http://news.cnet.com/

8301-1009_3-10437844-83.html.

