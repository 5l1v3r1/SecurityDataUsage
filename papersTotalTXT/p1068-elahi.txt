PrivEx: Private Collection of Trafﬁc Statistics for

Anonymous Communication Networks∗

Tariq Elahi

Cheriton School of
Computer Science

University of Waterloo,
Waterloo, ON, Canada

tariq.elahi@uwaterloo.ca

George Danezis

Dept. of Computer Science
University College London
London, United Kingdom
g.danezis@ucl.ac.uk

Ian Goldberg
Cheriton School of
Computer Science

University of Waterloo,
Waterloo, ON, Canada

iang@cs.uwaterloo.ca

ABSTRACT
In addition to their common use for private online communication,
anonymous communication networks can also be used to circum-
vent censorship. However, it is difﬁcult to determine the extent to
which they are actually used for this purpose without violating the
privacy of the networks’ users. Knowing this extent can be useful
to designers and researchers who would like to improve the perfor-
mance and privacy properties of the network. To address this issue,
we propose a statistical data collection system, PrivEx, for collect-
ing egress trafﬁc statistics from anonymous communication net-
works in a secure and privacy-preserving manner. Our solution is
based on distributed differential privacy and secure multiparty com-
putation; it preserves the security and privacy properties of anony-
mous communication networks, even in the face of adversaries that
can compromise data collection nodes or coerce operators to reveal
cryptographic secrets and keys.

Categories and Subject Descriptors
K.4.1 [Computing Milieux]: Computers and Society—Privacy;
C.2.0 [Computer-Communication Networks]: General—Security
and protection

General Terms
Security

Keywords
Distributed Networks; Differential Privacy; Secure Multiparty Com-
putation; Anonymity

1.

INTRODUCTION

Anonymity on the Internet provides the means to dissociate one’s
network identity from one’s online activities and communications.
Anonymity is not offered by default on today’s Internet and re-
quires the use of overlay anonymity networks. The most popular
∗An extended version of this paper is available. [12].
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11...$15.00.
http://dx.doi.org/10.1145/2660267.2660280.

such service today is Tor [8], but others include JAP [19] (com-
mercially offered as JonDonym [16]), i2p [17] and Anonymizer
Universal (AU) [2].

All those designs employ relays to form a communication path
between a client and a destination that hides information about who
is connecting to whom from network observers, and from the desti-
nation itself. While they have been improved upon and have grown
in popularity, anonymity networks remain notorious for being dif-
ﬁcult to study [21, 36]. This is partly due to their inherent privacy
properties, but also due to ethical considerations: they are live sys-
tems, and any data collection about their use may put in danger real
users by compromising their anonymity.

Data collection systems, in this context, must be mindful of four

main risks:

1. The network is run by volunteers and anyone with resources
may join the network by contributing nodes with bandwidth
or computation cycles to relay trafﬁc. This limits the trust-
worthiness of nodes.

2. The data that may be collected at nodes is sensitive and di-
rectly publishing it may break the non-collusion assumption
required by relay-based anonymity networks to maintain user
anonymity.

3. The nodes that collect or process statistical information should
not become targets of compulsion attacks by making them
more attractive targets of miscreants and authorities.

4. Low-latency anonymity networks are vulnerable to correla-
tion attacks [26,27] that observe trafﬁc volumes entering and
leaving the network. Published statistics must hide informa-
tion that would allow a client-side adversary with a partial
view of the network (an ISP, for example) to mount such at-
tacks.

To mitigate these risks, we propose PrivEx, a system for collect-
ing aggregated anonymity network statistics in a privacy-preserving
manner.

PrivEx collects aggregated statistics to provide insights about
user behaviour trends by recording aggregate usage of the anonymity
network. To further reduce the risk of inadvertent disclosures, it
collects only information about destinations that appear in a list of
known censored websites. The aggregate statistics are themselves
collected and collated in a privacy-friendly manner using secure
multiparty computation primitives, enhanced and tuned to resist a
variety of compulsion attacks and compromises. Finally, the gran-
ularity of the statistics is reduced, through a noise addition method
providing (,δ)-differential privacy, to foil correlation attacks.

The novel contributions in PrivEx are:
1. A safe mechanism to collect client statistics from anonymity

network egress nodes;

10682. Two secure multiparty protocols that protect the intermediate
values of a distributed differential privacy (DDP) computa-
tion, optimized for the problem at hand;

3. Reduced noise in the results of the DDP computation leading
to higher utility while still maintaining the desired level of
privacy, both as tunable parameters;

4. A security analysis detailing the resistance to compulsion,

compromise and correlation attacks; and

5. An evaluation of the overhead and performance of a proof-

of-concept implementation of PrivEx.

There are three main motivations behind PrivEx. The ﬁrst is
that developers of anonymity networks have so far been unable
to inspect egress trends. This information can guide designs that
enhance performance and provide features that better address the
needs of users. For example, network designers would like to be
able to determine how much of the network’s trafﬁc is for the pur-
pose of protecting the user’s identity from the website she visits,
and how much is for the purpose of censorship circumvention—
protecting the identity of the website she visits from the censor.
These different user bases have different security and privacy re-
quirements, and knowledge of the prevalence of each set can help
tune the network appropriately. The second motivation is to in-
form the research community with realistic information about us-
age trends to guide research in censorship resistance mechanisms,
performance tuning, and resource allocation, to name a few. Fi-
nally, one of the important open questions in any anonymity net-
work is how to model client behaviour since this is exactly the in-
formation that needs to remain conﬁdential. With realistic statistics
we can shed light not only on client behaviour but also use it to
ensure that when we test novel designs or system changes we can
model their effects on clients in a more realistic manner, leading to
more ecologically valid results.

Unfortunately, previous research on client behaviour [22] led to
controversy due to private client information being gathered—even
though it was destroyed and never exposed [33]. This set a prece-
dent that client information, no matter how it is collected, is off-
limits for legitimate research, which had a chilling effect on re-
search in this area. Mindful of the risks to clients and respecting
the fears of the privacy research community, PrivEx is a proposal
that aims at resolving this deadlock by providing a means of safely
collecting client trafﬁc statistics in anonymity networks.
2. BACKGROUND

Anonymous Communication Networks.

Anonymous communication networks (ACNs) allow clients to
hide their accesses to web pages and other Internet destinations
from certain network observers (typically ones who can view net-
work trafﬁc on at most a small portion of the Internet).

Low-latency networks, such as Tor, JAP/JonDonym, or i2p ob-
fuscate network trafﬁc by routing it through multiple nodes: an
ingress node, some number of middle nodes, and an egress node.
The routing can be predetermined by the network, as in JAP/JonDo-
nym, or source-routed subject to some constraints, as in Tor and
i2p. To achieve security against network observers, trafﬁc is en-
crypted so that the contents and metadata, including the destination,
are only seen by the egress node and the client.

Simpler anonymizing networks, such as AU use only a single
node and as a result are extremely susceptible to legal compulsion
attacks (through court orders, for example) [29, 32]; hence, they
will not feature in our discussions further.
Tor. Tor [8] is a popular ACN that provides anonymity by de-
coupling the routing information between the client and the desti-

Figure 1: An overview of the Tor network and typical trafﬁc
ﬂow (dotted line), highlighting Tor circuits, which use telescop-
ing nested encryption.

nation. Clients use three intermediary nodes to route their trafﬁc
using onion routing. This prevents the destination from learning
who the client is, and it also prevents an observer local to the client
from learning which destination the client has connected to.

Tor, by default, uses three intermediate nodes in a connection
between a client and destination (Figure 1). The client uses a tele-
scoping mechanism to construct a circuit between herself and the
last node, known as the exit node, which is the egress point of the
client’s trafﬁc. As this is the location where PrivEx will perform
its privacy-preserving data collection, we will refer to this node as
the data collector (DC) in the remainder of the paper. Each client
circuit has a unique identiﬁer to help the DC manage the ﬂow of
trafﬁc for multiple clients at once. The default behaviour is for the
Tor client software to switch to a new circuit every 10 minutes.

The DC node knows the destination but not the originator of a
connection. This is necessary to prevent it from relating the ob-
served destination to any client and hence learn about her habits, ac-
tivities or interests. Traditionally, exit nodes are required to delete
any information about the connections that exit the Tor network
through them. Publishing such information may be combined by
an adversary (such as an ISP or national ﬁrewall) with a client-side
view of the network to correlate exit activity with client activity to
deanonymize the network trafﬁc.

Thus, to not introduce any new attack vectors, any effort to col-
lect trafﬁc data at exit nodes, even in aggregate, will have to mini-
mize the information leaked to the adversary. This must hold even
in the case that the adversary is able to compromise the node or
compel the node operator to reveal the state of the node.

We will use Tor as a model ACN in which to integrate PrivEx
in the discussions that follow. This should aid in clarifying the de-
scriptions and to help the reader relate PrivEx to real-world ACNs,
but does not restrict the generality and applicability of PrivEx to
other systems.

Differential Privacy.

Traditional differential privacy [9] protects a central database—a
table where rows hold sensitive data about individuals—that is to
be kept private. This central database holds raw records that are
only to be released to the public in noisy or aggregated form. The
database allows multiple queries from clients who spend from a
privacy budget for each query.

Established differential privacy mechanisms add noise to the re-
sults of client queries to ensure that personal information—i.e., in-

ClientDestinationCircuit with Telescoping Nested EncryptionData1069formation about a particular entity that contributes to the results of
a query—cannot be gleaned from those results. Intuitively, given
any two “neighbouring” databases, one containing an entity’s data
and another without that entity’s data, but otherwise equal, then the
probability of observing any particular output to a given query will
be close for the two databases.

PrivEx implements a privacy mechanism based on adding noise
from a Gaussian distribution.1 Adding an appropriate amount of
Gaussian noise to the results of queries produces (, δ)-differential
privacy: if D and D(cid:48) are two neighbouring databases (as described
above), then the probabilities PD(x) and PD(cid:48) (x) that a given query
outputs x when using the databases D and D(cid:48) respectively, are re-
lated by PD(x) ≤ e · PD(cid:48) (x) + δ. [10].

In our setting, the database consists of one row for each censored
website whose visits we wish to count, and queries will simply be
of the form “output the counts in each row of the database (plus
noise)”.

3. THREAT MODEL

PrivEx maintains its security properties against an adversary that
is local to the client or the website servers they visit. The adversary
is able to monitor trafﬁc between the client and the ingress of the
anonymity network, or trafﬁc between the egress of the network
and the client’s destination, but not both at the same time. This
assumption is similar to the one required to argue Tor is secure.
As a result, this adversary is presumed to be unable to defeat the
anonymity system. However, if any information is also revealed by
the DC node, such as client usage statistics, that data could possibly
be used to correlate trafﬁc. A secure statistics gathering system,
like PrivEx, should prevent any such attacks.

We allow the adversary to operate nodes in PrivEx; i.e., deploy
or compromise ingress nodes in the network and be part of the ag-
gregation service itself. The adversary may also use the anonymity
network to relay its own trafﬁc in order to induce desired statistics
into the aggregation process. Malicious nodes can report spurious
data without generating or processing the corresponding trafﬁc.

PrivEx is secure when there is at least one honest data collector
and at least one honest-but-curious tally key server (described in
§4). While dishonest data collectors can report “junk” statistics and
malicious servers can disrupt the protocol, the security requirement
in PrivEx is that no client trafﬁc pattern information from honest
data collectors is ever exposed: neither while it is stored on the data
collectors, while it is in transit in the network, nor while it is being
processed by the aggregating service. That is, malicious parties can
disrupt the statistics reported by PrivEx, but cannot expose private
data. In the distributed-decryption variant of PrivEx (see §4.2), we
can further detect misbehaving servers. We discuss the security
implications of malicious actors and publishing client statistics in
further detail later in §5.1.

4. THE PrivEx SCHEMES

The goal of PrivEx is to count how many clients are visiting
each of a list of particular known censored websites.2 These statis-
tics are gathered and reported in a privacy-sensitive manner so that
the outputs of PrivEx cannot be used to perform trafﬁc correlation
attacks. Note that it is trivial to adapt PrivEx to collect statistics for
any type of event that the egress nodes can count, such as the trafﬁc
volume per circuit, variance in circuit-management statistics, client
navigation behaviour, and so on.
1We discuss later why we use Gaussian instead of Laplacian noise.
2This list can optionally have an “Other” entry to count the total
number of visits to non-censored websites as well.

Figure 2: PrivEx variant based on secret sharing

The DC nodes in PrivEx run on the same machines as the egress
nodes of the underlying ACN. The DC listens for events of interest
from the egress node, and securely aggregates them. In our setting,
an event will consist of the ACN egress node reporting that a par-
ticular circuit has asked to perform a DNS lookup of a particular
website.

PrivEx collects and aggregates statistics over a ﬁxed period of
time, called an epoch. We pick an epoch according to the granular-
ity of the statistics we wish to collect—for our example ACN, Tor,
we have chosen one hour as the epoch.

We introduce two PrivEx scheme variants that provide secure
and private aggregate statistics of events collected by the DCs. They
differ in the cryptographic primitives used to protect the data while
it is in storage and in the protection that they offer against malicious
actors.

The ﬁrst scheme, based on secret sharing (PrivEx-S2), is secure
in the honest-but-curious setting but can be disrupted by a misbe-
having actor.

The second scheme, based on distributed decryption (PrivEx-
D2), is secure in the covert adversary setting in that misbehaving
servers can be identiﬁed. Most importantly, however, in both sche-
mes, the disruption of the protocol by malicious parties does not
result in information leakage.

4.1 PrivEx based on Secret Sharing

There are three types of participants in PrivEx-S2: Data Collec-
tors (DCs), Tally Key Servers (TKSs), and a Tally Server (TS). The
DCs relay trafﬁc between the ACN and the destination; they col-
lect the statistics we are interested in. TKSs are third parties who
combine and store the secret shares received from DCs and relay
aggregates of those secret shares to the TS. The TS simply adds up
the secret shares provided by the DCs and the TKSs to produce the
aggregated results. Figure 2 depicts an overview of our scheme.

Setup. At the beginning of every epoch, each pair of DC (i) and
TKS (j) share a secret key (Kij). This key can be the result of
an ephemeral Difﬁe-Hellman exchange, or more simply, each DC
i can seed each TKS j with a shared key through a secure channel
(e.g., TLS 1.2 using a ciphersuite that provides forward secrecy).

Each DC maintains a number of secure counters, each crypto-
graphically storing the count of accesses to a speciﬁc destination
(wID). The DC cryptographically initializes a database of records,
each representing a secure counter, with the following schema:

TallyServerDataCollectorDataCollectorTally KeyServerDC 1TKS jTKS 2TKS 1DC iDC 2Tally KeyServerDC 1DC 2DC iTKS 1TKS 2TKS j1070[wID, CwID] where

(cid:32)

CwID =

nwID −(cid:88)

j

(cid:33)

PRF(Kij; wID)

mod p

Here, nwID is the noise for this counter (see §4.4), PRF is a keyed
pseudorandom function, and p is a smallish prime (such as p =
231 − 1). After this step, the DCs securely delete their shared keys
Kij and the noise nwID.

Each TKS (j) also uses Kij to compute its contribution to the

count for each wID as:

(cid:32)(cid:88)

i

(cid:33)

SwID =

PRF(Ki,j; wID)

mod p

Figure 3: PrivEx, distributed decryption variant

and then securely deletes its copy of the Kij. Alternatively, in order
to mitigate failing DCs, the TKSs can store the keys until the tally
phase but this opens up the TKSs to compulsion attacks to reveal
the keys, and hence the individual DC statistics.
Counting. Upon a DNS lookup event, the DC simply adds 1 to
the appropriate secure counter as follows: [wID, C(cid:48)
wID = (CwID +
1) mod p]. We choose p large enough to expect no overﬂow of
counting events—we can only reliably aggregate up to p events per
counter.
Aggregation. At the end of every epoch, all the DCs and all the
TKSs send their databases of secure counters to the TS.

The TS simply adds up all the shares received from the DCs and
TKSs and publishes the results, which are the aggregated destina-
tion visit totals from all the DCs plus the total of the noise added
by each DC at the setup stage in each counter. Once the results are
published for the current epoch the tally server deletes the received
data and awaits the next epoch’s data to tally.

After sending their data for the epoch to the tally server, all
the DCs and TKSs securely delete their databases and reinitialize
through the setup phase, starting the cycle again.
4.2 PrivEx based on Distributed Decryption
We now describe PrivEx-D2, depicted in Figure 3. PrivEx-D2
utilizes the Benaloh encryption scheme [5]—a distributed addi-
tive homomorphic encryption scheme. This scheme is a variant
on ElGamal: a (private,public) key pair is (a, A = ga) and an
encryption of a message m ∈ Zq with randomness r ∈ Zq is
EA(r; m) = (gr, Ar·hm), where g and h are generators of a cryp-
tographic group G of order q. Note the additive homomorphism:
EA(r1; m1) · EA(r2; m2) = EA(r1 + r2; m1 + m2), where the
multiplication is componentwise. Decryption is Da(C1, C2) =
1 ). Note that decryption requires the taking of a dis-
DLh(C2/C a
crete log, but if the message space M is small (as is the case for
counts of website visits, or in Benaloh’s original application, counts
of votes), this can be done with the kangaroo [28] or baby-step-

giant-step [30] methods in time O((cid:112)|M|), or even faster if more

space is consumed by a pre-computation table.

Note that PrivEx-D2 uses a public bulletin board (PBB) instead
of a Tally Server; the PBB is used as a repository of results and
public keys from the DCs and TKSs. We can instantiate it with
a database server which maintains tables for the TKS public keys
and intermediate decryption results, and the ﬁnal statistics of the
epoch. To mitigate misbehaviour by an untrusted PBB, the mes-
sages stored thereon should be digitally signed by their authors us-
ing long-term authentication keys.
Setup. At the beginning of every epoch, each TKS (j) picks a
random (ephemeral) private key aj ∈ Zq and computes its pub-
lic key Aj = gaj . They publish the public keys to the PBB,

taking the product of all the published keys: A = (cid:81)

along with a non-interactive zero-knowledge proof of knowledge
(using the Fiat-Shamir heuristic) of the private key aj. Each DC
then checks each proof, and calculates the compound key A by
j Aj. Now
each DC, for each secure counter for website w in its table, com-
putes the amount of noise nw to be added (see §4.4), and stores
EA(rw; nw) = (grw , Arw · hnw ). Note that the randomness rw
will be freshly chosen for each counter, and discarded immediately
after encryption, along with the plaintext nw.

Counting. When the DC observes a visit to a website under ob-
servation, it multiplies (component wise) the appropriate encrypted
counter by EA(r; 1) = (gr, Ar · h) where r is random.3 After
cw visits, the secure counter will hold (gr, Ar · hcw +nw ) for some
r. It can optionally also re-randomize the all the other counters to
ensure that two subsequent snapshots of the database do not reveal
which counter has been incremented.

Aggregation. At the end of the epoch, each DC (i) publishes to
the PBB a commitment to its encrypted counters for each website

(w) under observation: C(cid:0)(cid:104)(gr

i,w, Ari,w · hci,w +ni,w )(cid:105)w

(cid:1), where

w , TKS j’s share of the decryption, as α(j)

dates the openings by computing αw =(cid:81)

C is an appropriate commitment function. After all DCs have
posted their commitments to the PBB, each posts the opening of
its commitment (the list of encrypted counters (cid:104)(αi,w, βi,w)(cid:105)w =
(cid:104)(gr
i,w, Ari,w · hci,w +ni,w )(cid:105)w). Each TKS j then checks that the
DCs’ openings are consistent with their commitments, and consoli-
i αi,w. It then computes
α(j)
w = (αw)aj , and posts
that back to the PBB, along with a non-interactive zero-knowledge
proof of equality of discrete logarithms to (g, Aj) to show that
the computation was correct. Everyone can then check the proofs
, where
i ni,w. From here, cw + nw can
be computed using one of the discrete logarithm algorithms men-
tioned above. A proof of security for PrivEx-D2 can be found in
the extended version of this paper [12, Appendix A].

and compute the value hcw +nw =(cid:0)(cid:81)
cw = (cid:80)

i ci,w and nw = (cid:80)

(cid:16)(cid:81)

(cid:1) /

j α(j)

i βi,w

(cid:17)

w

4.2.1 Filtering Statistics by Client Origin
So far, we have assumed there is a single list of censored web-
sites whose visits we are interested in counting. However, different
websites are censored in different countries, and we may wish to
count a visit to, say, Wikipedia if the user is in China, but not in

3For a slight efﬁciency gain, r can be 0, so that the multiplica-
tion is by (1, h). The downside is that this can leak information to
an attacker that can observe the internal state of a DC at two dif-
ferent times within one epoch, yet cannot observe that DC’s DNS
lookups.

TKS 1TKS jTKS 2TKS 1TKS 2TKS jDataCollectorDataCollectorDC 1DC iDC 2DC 1DC 2DC iTally Key ServerTally KeyServer1071the UK, a visit to the Pirate Bay if the user is in the UK, but not in
Sweden, etc.

In this section, we present an extension to the PrivEx-D2 pro-
tocol that allows us to maintain per-country lists of censored web-
sites, and only count a visit by an ACN user to a given website if
that website appears on that user’s country’s list.

To do this, we of course need to determine what country the user
is in. This is best done at the ingress point to the ACN, where the
true IP address of the user is visible. Indeed, Tor already collects
this information so that it can display per-country counts of num-
bers of users. [35] It is of course vital that the DC not learn this po-
tentially identifying information about the client. The ingress node
will therefore forward to the DC an encrypted vector encoding the
country. The length of the vector is the number of countries NC for
which we are monitoring accesses to censored websites, plus one
for “Other”. The vector is then V = (cid:104)EA(rc; δc,c∗ )(cid:105)NC
c=0 where c∗
is the country the user is in and δc,c∗ is 1 if c = c∗ and 0 otherwise.
The rc are uniform random elements of Zq. The ingress node also
provides a zero-knowledge proof that each element of the vector is
an encryption of either 0 or 1, and that the sum of the plaintexts
is 1. We note this is the same proof as used in electronic voting
schemes, for example. [5]

not EA(r; 1), as above, but rather(cid:81)

The DC will check the zero-knowledge proof, and when it ob-
serves a connection to, say, Wikipedia, will multiply into its count
c Vc, where the product is over
those countries c that censor Wikipedia. The remainder of the pro-
tocol is unchanged. Each vector V is associated to a circuit at cir-
cuit construction time and the DC knows which circuit requested
the website.
4.3 PrivEx Scheme Comparison

Both schemes provide the security features we desire, but in

some settings one may be preferable over the other.

In volunteer-resourced ACNs, such as Tor, some nodes will in-
evitably have low computation and bandwidth resources and it is
best to minimize their computational, memory, and bandwidth over-
head. In such cases, PrivEx-S2 is preferable since some messages
are overall shorter and the computational overhead of frequent op-
erations is smaller.

The length of the epoch can affect our choice of scheme since
the relative time to set up and process the statistics increases for
shorter epochs. While it is not a current requirement, if we wanted
more near-real-time statistics, say every 5 seconds, then we would
prefer PrivEx-S2 since the overhead is nearly negligible compared
to PrivEx-D2. There are limits to how short the epoch can be, how-
ever, due to network latency affecting protocol communication.

On the other hand, PrivEx-D2 provides traitor detection of the
TKSs and Denial of Service (DoS) resistance. In PrivEx-S2, any
DC or TKS can DoS the system for the epoch if it does not report
its statistics, whereas in PrivEx-D2 only DCs that report statistics
for the epoch are included in the aggregation process and misbe-
having TKSs (traitors) can be detected using cryptographic proofs
ensuring that the computations were done correctly. Furthermore,
PrivEx-D2 can optionally enjoy stronger perfect forward secrecy—
against node seizure and adversaries that can view the memory con-
tents multiple times in an epoch—by re-randomizing even those
counters that have not been changed with every increment opera-
tion.
4.4 Calculating and Applying Noise

We introduce noise to our results to mitigate the risk of the cor-
relation attack that reporting exact results may introduce. A more
thorough discussion of the correlation issue is found in §5.2. In

Figure 4: The advantage is 0.5% (shaded area) of the adversary
in guessing the correct value of the statistic. Note the almost
total overlap of the two probability distributions.

this section, we present the details of how the appropriate amount
of noise is computed and added to the tallies.

4.4.1 How Much Noise?
We add noise to protect the privacy of users, but at the same
time, if we add too much noise, it will hamper the utility of PrivEx;
after all, we are deploying PrivEx to answer certain questions about
ACN usage. We adopt a principled approach to adding noise to
our statistics—one that allows the level of privacy and utility to be
set to desired levels. For this purpose we have selected the model
of differential privacy that can provide (, δ)-differential privacy
through the addition of noise using a Gaussian mechanism with
mean 0 and a standard deviation σ selected for the level of privacy
and utility we require.

We wish to protect information about whether any individual
user’s information is in the published data set, or is not in it. To do
this, we need to set an upper bound—called the sensitivity (S)—
on the maximum contribution one user can make to the count in
any epoch. For Tor, we use the fact that, by default, one circuit
is created every ten minutes, so that if our epoch length is, say,
one hour, and we always ignore repeated visits to the same website
by the same circuit, we can set S = 6—the security implications
of implementing this are discussed in §5.1.1. For other ACNs, an
appropriate sensitivity can be similarly selected.

As we are interested in practical applications of PrivEx, we pro-
vide the means to calculate the exact values of  and δ through the
lens of the privacy and utility levels we desire.

What we are interested in controlling is the advantage (over ran-
dom guessing) of an adversary in guessing whether a particular
user’s data is contained in the published (noisy) statistics, even if
the adversary knows all the other inputs to the statistics. That is,
discounting the known information, the adversary is trying to deter-
mine whether the published statistics are more likely to represent
a true measurement of 0 (the user is not present) or S (the user is
present).

Therefore, the adversary’s task is to tell if a given statistic is
drawn from the distribution N (0, σ) or N (S, σ). Given a reported
2 , the adversary’s best guess is that the true
statistic, if it is less then S
statistic is 0, and S otherwise. It is easy to see that the advantage of
the adversary is then given by the area under the N (0, σ) normal
curve between 0 and S

2 , as depicted in Figure 4.

The adversary’s advantage can then be minimized by selecting
2 ] = P r[0 <

σ large enough such that P r[0 < N (0, σ) < S

00.0010.0020.0030SS/2σPrivacy Loss (S=6)N(µ=0,σ=240)N(µ=6,σ=240)Adversary's Advantage1072the expense of requiring an increase in λ by a factor of H−2 (an
increase of about 56% for H = 0.8) to achieve the same level of
utility as before.
A Worked Example. Using Tor as our ACN, and one-hour epochs,
so S = 6, we want to ﬁnd σ given a desired privacy adversary
advantage of at most 0.005. Consulting a z-table, we ﬁnd that we
2σ ≤ 0.0125, so σ ≥ 240. Then, if we want utility error
want S
√
2σ ≥ 2.33, so for σ = 240,
√
U = 0.01, the z-table says we need K
λ
λ ≥= 1120 will sufﬁce. Then if K = 1000, λ can be as low
K
as 2 epochs, if K = 100, then λ = 126 epochs (or 5.25 days), but
to get an average number of visits per epoch to within K = 1, we
would need over 140 years.

We now analyze the case where some fraction of DCs may be
malicious. Assume that we expect that the total honest weight is at
√
H = 240/0.8 = 300. Then, for
least 80%. We adjust σ to σH = σ
λ ≥ 1400 will sufﬁce. For the
the same utility error as above, K
same values of K we would now need 2 epochs, 8.2 days, and over
224 years respectively.

In the preceding analysis we only need consider the amount of
noise to add in terms of the standard deviation σ of the distribution
we sample from. We can link this back to (, δ)-differential privacy
by observing the parameters’ relation to σ as follows [14]:

(cid:18) 1.25

(cid:19)

ln

δ

(cid:115)

σ =

·

S


Thus, rather than, as in previous works [10, 14], having the system
designer select not-very-meaningful values of  and δ, and comput-
ing σ as above to determine how much noise to add, we instead
determine σ directly using parameters speciﬁcally pertinent to the
system and to the questions it is trying to answer.4
4.4.2 Distributed Noise Application
The DCs independently apply the noise as we never want the raw
(un-noisy) data to be divulged. We can distribute the application
of noise since we know from Dwork et al. [11] that if individual
databases are differentially private then so is their sum.

A naive way to go about this, and one that avoids the use of third
parties, is for the DCs to publish their noisy data directly to the
public. The consequence of this is that each DC would need to add
enough noise so that its individual statistics provided the desired
bound on the advantage of the privacy adversary. This would make
the total noise considerably larger (by a factor of the square root
of the number of DCs), and so the number of periods λ to average
over must increase by a factor of the number of DCs in order to
keep the desired bound on the utility error.

This is why PrivEx works with global noise instead of local
noise: each DC adds some amount of noise, whose total is dis-
tributed as N (0, σ) for the desired σ, but does so using secure
multiparty computation so that the individual noise components are
never revealed.

We then need to calculate how much noise each DC should add.
What we want is for each DC i to add noise from N (0, σi), where
σi is proportional to the probability wi that the DC will get used.
In Tor, for example, high-bandwidth nodes get used with higher
probability, so they will see more usage, and add more noise, while
more impoverished nodes will have less usage and less noise.
Then, given the desired σ, we want to solve for the σi such
that σi ∝ wi (so σi = wi · φ for some φ independent of i) and
4Since we only ever make one query we do not need to calculate
how much privacy budget we have left after publishing our aggre-
gated statistics.

Figure 5: The probability of error is 0.1% (dark shaded area)
when the reported statistic (averaged over λ = 126 epochs)
appears closer to K than to 0. Compare this to the much larger
error of 41.75% (lighter shaded area) when λ = 1.

λ

λ

N (0, 1) < S
too large will hamper utility, as we discuss next.

2σ ] is as close to 0 as desired. However, choosing σ

To address our utility needs, we must ﬁrst decide on a question
to ask. A typical question would be, “On average, how many visits
are there to a given censored website per epoch?”, and we may be
content to know the answer to within some resolution K, say 100
or 1000. This gives us two beneﬁts over the privacy adversary:
we only care about average behaviour over many epochs, and not
speciﬁc users at speciﬁc times (in order to carry out a correlation
attack); and we only care about results to within K, not to within
single users’ contributions.

If we average over λ epochs, the standard deviation of our noise
becomes σ√
. Then, if we want to distinguish two hypotheses that
differ by K (e.g., does this website see closer to 0 visits per epoch
or closer to K = 1000 visits per epoch over the ACN—a ques-
tion we cannot answer today), our utility error—the probability
we answer incorrectly—is P r[N (0, σ√
2 ] = P r[N (0, 1) >
√
2σ ], as depicted in Figure 5. Slightly different questions would
K
λ
produce slightly different formulas for the utility error, but they will
be computable in the same vein.

) > K

Therefore, for a given sensitivity S and tolerance P on the ad-
vantage of the privacy adversary, we can work out the desired stan-
dard deviation σ for our noise by solving for P r[0 < N (0, 1) <
2σ ] ≤ P using a standard normal curve z-table. Then, given a tol-
S
erance U on the utility error, and a resolution K for our question,
we can determine the number of epochs λ we will need to average
over by solving for P r[N (0, 1) > K

√
2σ ] ≤ U similarly.
λ

In the presence of possibly malicious DCs, the situation is only
slightly more complicated. Malicious DCs (who do not immedi-
ately forget the amounts of noise with which they initialized the se-
cure counters) know the amount of noise they added. By removing
that from the reported tally, the remaining amount of noise (con-
tributed by the honest DCs) is less than expected.

As we will see in §4.4.2, each DC i adds noise selected from a
normal distribution whose standard deviation is proportional to its
weight—the probability wi that that DC will be selected by a user.
If we can assume a lower bound H on the total weight of honest
DCs, we can adjust the above calculations in a simple manner. (In
§5.1.2 we will argue that H = 0.8 is a reasonable lower bound
for Tor.) Honest DCs tune the amount of noise to add by adjusting
H . This has the effect that honest DCs
the value of σ to σH = σ
add more noise so that it maintains the desired privacy level, at

00.0020.0030SK/2KS/2σ/√λσUtility Loss (S=6, K=100, λ=126)N(µ=0,σ=240)Utility Error aggregating over 1 epochN(µ=0,σ/√λ=21.38)Utility Error aggregating over λ epochs1073i

(cid:80)
i N (0, σi) ∼ N (0, σ). Since(cid:80)
(cid:0)(wi · φ)2(cid:1), so solving for φ, we ﬁnd that
we have that σ2 =(cid:80)
wi√(cid:80)

i N (0, σi) ∼ N (0,(cid:112)(cid:80)

. In PrivEx, the values of φ and σ are

σi = wi · φ = σ ·
made available to the DCs from the PBB or TKSs.

i(w2
i )

i σ2

i ),

That we are adding together a potentially large number of inde-
pendent noise sources is the reason we target Gaussian rather than
Laplacian noise: while adding many Gaussians yields a Gaussian,
a Laplacian distribution cannot be decomposed into sums of other
independent random variables.

We note that, when adding noise, it is important for each DC to
preserve non-integral and negative values for the noisy count, so
that, when added together, extra biases are not introduced. As the
encryption used in our counters takes integer plaintexts, we must
use a ﬁxed-point representation where all of our values are ex-
pressed as multiples of some small number γ. If there are N DCs,
then in order that adding N values of resolution γ together will be
unlikely to produce an error of more than 1, we set γ ≤ 1
√
For N ≈ 1000, as in the current Tor network, γ = 0.01 will suf-
2
ﬁce.5 Note, however, that this ﬁxed-point representation expands
γ , and so increases the time to
the plaintext space by a factor of 1
compute the discrete logarithm in the ﬁnal step of the PrivEx-D2
protocol by a factor of 1√

.

N

γ .

4.4.3 Targeted Temporal Queries
PrivEx publishes the noisy total statistics for each epoch. The
amount of noise is computed to protect privacy, and a number of
epochs’ statistics must be averaged to gain utility. However, these
epochs do not need to be consecutive, so, for example, one could
ask questions like, “Is Wikipedia visited via this ACN more often
on weekends or weekdays?”. The number of epochs to average will
not change, however, so if the epochs of interest are spread out in
time, the total time to answer such a question will increase.

5. SECURITY ANALYSIS
5.1 Resistance to Attacks

We now address the attacks that are of the most concern. Re-
call that our requirement for security is that PrivEx should not re-
veal private information to an adversary, even if it fails to produce
meaningful answers to the system designers’ questions.
5.1.1 Legal or Other Compulsion
A DC can be compelled to reveal its database of collected statis-
tics through a legal order or extra-legal compulsion. If this database
is stored in the clear then privacy would be violated. PrivEx miti-
gates this threat by storing an encrypted database with the property
that the DC cannot decrypt the database on its own. Recall that at
the setup stage in PrivEx, all DC databases were encrypted using
shared keys with, or public keys of, the tally key servers.

The adversary can also compel the servers to comply in the de-
cryption of individual DCs’ measurements (with less noise than
the aggregate). This would indeed be troublesome, but we mitigate
this by ensuring that the PrivEx servers are distributed across di-
verse legal boundaries making compulsion infeasible. Indeed, as
long as at least one server is uncompromised then all DC data is
safe. Furthermore, since we start with fresh keys for each epoch,
this compulsion could not occur retroactively.

PrivEx requires that we bound the sensitivity—the maximum
number of times one client can access a particular website in one

5This also deals with an issue with rounding and differential pri-
vacy identiﬁed by Mironov. [24]

epoch. We do this by maintaining, in plaintext, a list of websites
visited during the lifetime of a circuit, which is 10 minutes in Tor.
This introduces a potential information leak if the adversary is able
to compromise an honest DC while circuits are being served; this
would reveal the censored websites visited by each circuit. While
this in itself does not link a client to a destination an adversary may
use this information to correlate trafﬁc patterns it can record at the
client side of the circuit. However, if the adversary can compromise
an ACN relay while it is actively serving an open circuit, then the
encryption keys it could recover could compromise those circuits
anyway even without access to the plaintext list.
5.1.2 Malicious Actors
Data Collector. The DC can behave maliciously by reporting un-
true statistics. While there is no safeguard to an attack on the in-
tegrity of the statistics we are interested in, the conﬁdentiality of
the statistics collected at other DCs and the aggregate statistics that
are output by PrivEx are safe from the actions of a misbehaving
DC as long as the security of the encryption schemes that we use
remains intact. We may mitigate the impact of this attack by using
range proofs at additional computation and communication costs,
but this still does not remove the threat entirely. In §4.4.1 we sug-
gested that H = .8 is a reasonable lower bound on the amount of
honest DC weight for Tor. The reason we give this value is that if
more than 20% of the exit weight of Tor is compromised, then Tor
is sufﬁciently susceptible to circuit linking attacks [1], and could
more easily compromise clients without using the less-noisy statis-
tics provided by the degraded PrivEx.

Finally, we note that if a DC is compromised, the adversary can
also perform a correlation attack, and can likely read the mem-
ory, including encryption keys protecting any active circuits, thus
retroactively deanonymizing them. This is a shortcoming of the
underlying ACN; PrivEx does not exacerbate this problem.
Tally Key Server. The tally key servers collectively play a critical
role in the PrivEx schemes and hence are vectors of attack. A bad
actor may try to gain access to the statistics in a less secure manner
or an insecure intermediate form (i.e. without noise).

We guard against this in both variants of PrivEx by ensuring that
in the setup stage all DCs initialize their databases by encrypting
each secure counter using the key material provided by, or shared
with, all the participating TKS servers. This ensures that even if
all but one TKS try to decrypt the data in an information-leaking
manner, a single honest server’s key material and noise added by
the DCs prevents any information from being revealed.

In PrivEx-S2, a single DC or TKS can launch a denial of ser-
vice attack by not sending its share, which would mean that for
that epoch no results could be determined. In PrivEx-D2, we can
identify the misbehaving TKS, which introduces consequences to
DoSing. In either case, no private information is leaked.
Tally Server and Public Bulletin Board. The TS and PBB are
unable to learn anything extra by misbehaving since none of the
intermediate data is ever in the clear and their inputs and outputs
are public, making veriﬁcation possible.
5.2 Correlation Attack with Auxiliary Infor-

mation

Data Collector trafﬁc information may not reveal anything on its
own, but there is a danger that an attacker could fruitfully combine
it with auxiliary information, such as observations of a target user’s,
or indeed of many users’, network trafﬁc.

For example, if we did not add noise, but simply released accu-
rate counts only if they were in excess of some threshold, then an

1074adversary could generate its own network trafﬁc to push the counts
above the threshold, and then subtract its own trafﬁc (for which
it knows the true counts) to yield accurate counts of potentially a
single user’s trafﬁc.

The differential privacy mechanism proposed adequately addresses

this threat. It ensures that, for any adversary, the response of PrivEx
if the target user did visit a target website in a given epoch will be
hard to distinguish from the response if the user did not.

We also note that since there is only one question PrivEx answers
(How many visits were made via the ACN to each of this list of
websites in this epoch?), and it can be asked only once per epoch,
differential privacy’s notion of a “privacy budget” is not required in
our setting.

6.

IMPLEMENTATION

We have built proof-of-concept implementations for both vari-
ants of PrivEx. They are implemented in Python using the Twisted
library for asynchronous networking between the parties of the sys-
tem.

Each PrivEx scheme uses a few hundred lines of python code.
The code is available for download from our PrivEx website.6 Both
schemes use TLS 1.2 with ECDHE for communication between
endpoints to ensure that the key material remains conﬁdential dur-
ing transit and beneﬁts from perfect forward secrecy. We set up
long-lived TLS connections when PrivEx ﬁrst comes online; their
communication and computational costs are amortized over many
epochs.

We have not implemented the Country of Origin feature at this
time since we would like to see PrivEx deployed in the Tor network
with the core feature set before expanding on it. The core imple-
mentation above is ACN agnostic, and we aim to integrate it with
Tor in the near future.

In the tables in this section, the “Per node” column is calculated
by taking the total cost for each type of PrivEx node and dividing
it by the count of that type of node, to ﬁnd the cost at each type of
node. This helps identify potential bottlenecks.

Computational Overhead.

We present PrivEx overhead statistics to show that both schemes
have low computation requirements. The hardware for our experi-
ments is a 3 GHz quad-core AMD desktop computer with 4 GiB of
RAM running stock Ubuntu 14.04.

Using a test harness we measure the time the core components
of each PrivEx scheme take under parameters typically found in the
Tor network. We simulate a network of 10 TKSs and 1000 DCs; the
latter reﬂects the number of exits in the current Tor network. The
number of censored websites to collect statistics for is 1000 and
each website is “visited” one million times. No actual website con-
nections are made by the DCs since we are interested in capturing
the overhead of the PrivEx schemes.
PrivEx-S2. From Table 1, we note that the setup phase of PrivEx-
S2 takes 4.1 s on average and that the tally phase takes 470 ms on
average (adding the “per node” times, as the nodes act in parallel).
Without any ACN trafﬁc (i.e. no DC increment operations), the
total overhead wall-clock time per epoch is 4.6 s. The key ﬁgure to
note is that the addition operations at the DC nodes take less then
1 µs each (900 µs for 1000 visits per DC) on average. This low cost
is important, as this operation will be called the most often and the
impact on DC nodes must be negligible so that they can service
ACN requests without undue overhead.

6https://crysp.uwaterloo.ca/software/privex/

Operation
TKS initialize
TKS register
DC initialize
DC register
DC increment
DC publish
TKS publish
TS sum
Epoch Total

Total per epoch (ms)
0.012±0.004
41000±3000
40000±3000

312±8
900±90
1.7±0.1
0.56±0.06
470±20

83000±6000

Per node (ms)
0.0012±0.0004
4100±300
0.312±0.008
0.90±0.09

40±3

0.0017±0.0001
0.056±0.006
470±20
—

Table 1: The overhead per epoch (with 95% conﬁdence inter-
vals) incurred by participants in the PrivEx-S2 scheme for 10
TKSs and 1000 DCs with 1000 websites with one million visits
per epoch.

Operation
TKS initialize
DC combine key
DC initialize
DC increment
PBB productize
TKS decrypt
PBB DL Lookup
Epoch Total

Total per epoch (ms)

10.9±0.2
4.05±0.02
295000±600
3.9±0.1
50400±400
448000±3000
6293±40

800000±3000

Per node (ms)
1.09±0.02
295±0.6

0.00405±0.00002

0.0039±0.0001
50400±400
44800±300
6290±40

—

Table 2: The overhead per epoch (with 95% conﬁdence inter-
val) incurred by participants in the PrivEx-D2 scheme for 10
TKSs and 1000 DCs with 1000 websites with one million visits
per epoch.

PrivEx-D2. From Table 2, we note that the setup phase of PrivEx-
D2 takes 297 ms on average with the DC nodes bearing the most
cost. The entire tally phase takes 1.69 m on average per epoch
(adding the “per node” numbers, as these operations occur in paral-
lel). Combining the overhead for both phases, the epoch overhead
wall-clock time is 1.7 m on average. We see in PrivEx-D2 that the
addition operation takes 3.9 µs on average and again, like PrivEx-
S2 above, this is desirable since it is the most frequent operation.
Discussion. PrivEx-S2 has lower computational cost than PrivEx-
D2, by a factor of almost 10 in our example. Yet, it is clear from
these results that the computational overhead at each type of node
in PrivEx is low and that the time requirements are a small frac-
tion of the duration of an epoch. Indeed, even if there are applica-
tions where statistics need to be gathered for shorter epochs, PrivEx
can still be useful; as we saw earlier, for each setup-tally cycle
the PrivEx-S2 scheme incurs less than 4.6 s of overhead while the
PrivEx-D2 scheme incurs less than 1.7 m of overhead, meaning the
statistics collection frequency can be as low as 5 s and 2 m respec-
tively. This ﬂexibility allows one to match the appropriate PrivEx
scheme to the application’s statistics frequency and threat model
requirements.

Communication Overhead.

We now give a closed-form analysis of the communication costs
of the two PrivEx schemes. In the following description, DCN ,
T KSN , and WN represent the number of DC nodes, TKS nodes,
and websites for which we are collecting statistics respectively.

An overhead in common for both schemes is the list of websites
and the constants for DDP calculations σ, φ, and γ. We make the

1075Setup
156.25
0
0
156.25

Tally
3906.25
39.07
0
3945.32

Total
4062.50
39.07
0
4101.56

Per node
4.06
3.91
0
—

DC
TKS
TS
Total

Table 3: Communication cost (in KiB) of PrivEx-S2 for 1000
websites, 10 TKSs and 1000 DCs per epoch, using closed-form
analysis.

Setup
(KiB)
0
0.94
937.5
938.44

Tally
(MiB)
61.07
0.31
641.17
702.55

Total
(MiB)
61.07
0.31
642.09
703.47

Per node
(KiB)
62.54
31.74
657500
—

DC
TKS
PBB
Total

Table 4: Communication cost of PrivEx-D2 for 1000 websites,
10 TKSs and 1000 DCs per epoch, using closed-form analysis.
Note the units in the column headings.

conservative assumption that the website domain name in the URL
will not be more than 255 characters long, therefore the maximum
length of the URL list is 255 · WN bytes. The constants require
8 bytes in total. In the experimental setting above this overhead is
∼249 KiB, the overwhelming majority of it being the website list.
While it is not as signiﬁcant, we note that the website lists and val-
ues for the constants need not be transmitted every epoch, instead
only being sent when there is a drastic change in the network con-
ditions or the website lists are updated.
PrivEx-S2.
material to each TKS for a total of 16DCN · T KSN bytes.
In the tally phase, each DC sends 4 bytes to the TS for each
website in the database for a total of 4WN · DCN bytes. Similarly,
each TKS also sends the same amount to the TS for each website
for a total of 4WN · T KSN bytes.

In the setup phase, each DC sends 16 bytes of key

In each epoch, the total communication cost, in bytes, is

16DCN · T KSN + 4WN (DCN + T KSN )

For 10 TKSs and 1000 DCs tracking 1000 websites we see from
Table 3 that the total communication cost for every epoch is ∼4 MiB,
but the cost for each type of node is far lower at only ∼4 KiB.
PrivEx-D2.
In the setup phase, each TKS sends 96 bytes of
key material and zero-knowledge proof to the PBB for a total of
96T KSN bytes. Then, each DC retrieves the key material and the
proofs from the PBB for a total of 96T KSN · DCN bytes.

In the tally phase, each DC sends a 32-byte commitment to the
PBB for a total of 32DCN bytes. After all DCs have sent their
commitments, the PBB sends each DC the commitments of the
other DCs for a total of 32DC 2
N bytes. Then, each DC sends a
64-byte opening of the commitment for each website to the PBB
for a total of 64WN · DCN bytes. The PBB then sends, in parallel,
the opening of the DC’s commitments to each TKS for a total of
T KSN (DCN (64WN + 32)) bytes. In response each TKS sends
the results of the partial decryption for each website in the database,
along with a zero-knowledge proof of equality of discrete logs for
a total of T KSN (32WN + 64) bytes.

In each epoch, the total communication cost, in bytes, is

32 (WN (2DN · T KSN + 2DN + T KSN )
N + 4DN · T KSN + 5T KSN + DN
+ D2

(cid:1)

From Table 4 we see that, in our experimental setting, the total
communication cost for each epoch is ∼703 MiB, while each of the
TKS and DC nodes send only ∼32 KiB and ∼63 KiB respectively.
The bulk of the communication cost is borne by the PBB node.
Discussion. Both schemes scale linearly with the number of web-
sites and TKSs. PrivEx-D2 scales quadratically with the number
of DCs while PrivEx-S2 remains linear. While it is true that the
PrivEx-D2 scheme is generally more expensive, we note that each
DC and TKS transmits only tens of KiB of trafﬁc per epoch, which
is comparable to PrivEx-S2. However, the PBB transmits hundreds
of mebibytes due to the higher security and privacy guarentees it
allows. To mitigate the impact of this load, it is expected that the
PBB will be well resourced for this task. Indeed, we expect that in
real deployments the number of TKSs would be closer to three and
the number of websites would be closer to 100. In that scenario,
the total communication cost would be approximately 55 MiB per
epoch.

The PrivEx-S2 scheme is relatively lightweight, enjoying very
low overhead and perhaps a better choice in low-bandwidth envi-
ronments or where the size of the website list will be very large.

Even so, in absolute terms, both PrivEx schemes have low over-
head for DC and TKS nodes. We note that in the Tor network, even
relays in the 1st percentile by bandwidth (18.4 KBps)—which are
also the least likely to be chosen in circuits in any event—can man-
age the load easily. [34]

From the perspective of the DC, which is also a node in the ACN,
PrivEx does not signiﬁcantly impact bandwidth usage which can
be better used to service ACN trafﬁc. From the perspective of the
TKS, TS, and PBB, even though we expect that the servers would
be well provisioned for the task of aggregating statistics, the re-
source requirements are low enough that they would also not be
signiﬁcantly impacted by participating in PrivEx.

7. RELATED WORK
Differential Privacy. While PrivEx utilizes differential privacy
(DP), there are many key differences in the setting in which it is
traditionally applied and the PrivEx setting.

In classical DP there is a trusted centralized database—who is
usually a third party host—which can see the real data and is con-
sidered secure.
Instead, in PrivEx the data is distributed across
nodes in the network where no entity has access to all of the real
data from all of the nodes. The only data that is revealed to anyone
is the aggregated statistics with noise added. An adversary would
have to compromise a large fraction of the DCs, or all of the TKSs,
in order to access the private data of the honest parties.

In the usual DP setting the database is static across epochs and
clients use up their privacy budget to make a number of database
queries—the results of which are usually private unless they choose
to make them public. As discussed at the end of §5.2, in PrivEx,
the database is completely refreshed at the start of every epoch and
only a single constant query is ever made every epoch, the result of
which is then made public.

A number of works consider the problem of securely computing

functions in a distributed differential privacy setting.

Dwork et al. [10] provide a method for generating shares of ran-
dom Gaussian noise in a multiparty setting mirroring the distribu-
tion of noise in our setting. The key difference is that the parties
work together to ﬁrst produce noise shares which are then used to
perturb the data in their individual databases where as in PrivEx
the noise is calculated independently using network state and does
3 of the
not incur extra protocol rounds. Also, they assume that 2
participants will be honest while PrivEx makes no such explicit re-
striction, i.e. a lone honest DC may enjoy the same level of privacy

1076as the designer intended, albeit with longer aggregation periods to
gain the same level of utility as designed.

In the two-party setting of distributed differential privacy, Goyal
et al. [13] explicitly evaluate the accuracy-privacy tradeoffs for
computing Boolean functions. Mironov et al. [25] investigate cal-
culating the distance between two vectors while McGregor et al. [23]
do the same for Hamming distance. All these works explore the
limits of DDP in the two-party setting. We contrast our work by
noting that we consider a different type of problem (the summa-
tion of integral inputs) and we evaluate the tradeoff between the
accuracy and privacy in the multiparty setting.

The closest related work is by Beimel et al. [4]. The inputs in that
setting are binary, while those in ours are integral. While the binary
inputs can indeed be adapted to integers, there remain three key
differences. Their protocol requires more rounds of communication
than ours, while we also allow for malicious parties, making PrivEx
a more practical solution in our setting. Finally, in their setting,
to preserve DP, the database of each DC is kept private and only
binary outputs are released, whereas in our setting all DCs release
their private data, albeit with noise added to preserve DP.

Also of interest is work by Kasiviswanathan et al. [18] where
network graphs are analyzed to investigate how the removal and
addition of nodes in the graph affect the privacy of the information
about the structure of the graph. While they also consider differ-
ential privacy in the network setting, the key difference is that they
investigate ways to safely reveal information about the nodes of the
network themselves, whereas we are interested in the information
that can be revealed by studying the trafﬁc ﬂowing through the net-
work; i.e., the network users’ information.

A general key difference to the previous literature is that PrivEx
provides a way to reason about the privacy and utility that the sys-
tem provides whereas these previous works leave it up to the sys-
tem designer to work out. We provide an explicit statement of, and
relationship between, privacy and utility that are pertinent to data
collection in ACNs—this provides an easier-to-analyze system and
potentially an easier path to deployment.
Secure Multiparty Computation. Secure multiparty computa-
tions have been used in scenarios where the parties that perform
the operations are not trustworthy. This means that they should not
learn the inputs of the calculations, should provide (implicit or ex-
plicit) proofs that the calculations were performed correctly, and
should not learn anything more than the output of the calculation.
A closely related work is SEPIA [6] by Burkhart et al. where
networks collect data and wish to learn aggregate information about
their networks without revealing their individual inputs. It develops
a number of operations that can be performed on network data that
can be evaluated by a pool of servers in a secure multiparty compu-
tation. While both PrivEx and SEPIA try to achieve similar goals
in the collection of network statistics and use similar secret sharing
schemes, there are a number of differences. First, while the authors
of SEPIA brieﬂy mention differential privacy as a possible defence,
PrivEx provides a thorough treatment of how to use differential pri-
vacy to protect the aggregated statistics in a principled manner. Re-
lated to that is that SEPIA also requires that honest DCs sanitize
their inputs, i.e. remove sensitive information, whereas PrivEx ac-
complishes the same with the addition of DP-noise. Second, PrivEx
is secure as long as there is one honest data collector—adding the
appropriate level of noise, as outlined in §4.4.1—and one honest
TKS. This is in contrast to the SEPIA requirement that at least half
of the aggregators be honest. This is especially useful since PrivEx
collects data from an anonymity network where the stakes for in-
formation leakage are potentially higher and hence require greater
robustness to bad actors. Finally, we note that the data collectors in

SEPIA are provisioned for processing large quantities of trafﬁc and
data as they are part of the ISP infrastructure, but these conditions
may not apply in a volunteer-resourced network like Tor. PrivEx
has low overhead for the DCs.

The secret sharing scheme is an adaption of the scheme pre-
sented by Barthe et al. [3] which itself is an extension of previous
works by Kursawe et al. [20], Jawurek et al. [15] and Shi et al. [31].
The novelty of PrivEx is that it introduces addition using additive
secret shares for coercion resistance and perfect forward secrecy
which these previous works do not address.
Anonymity Network Data Collection. The work by McCoy et
al. [22] provided many insights about Tor client behaviour. Un-
fortunately, the method of safeguarding the privacy of the collected
data was considered by the community at large to be insufﬁcient. [33]
Similarly, Diaz and Sassaman [7] provided insights about mix in-
put trafﬁc in Mix-stlye anonymous email networks by using actual
trafﬁc obtained from a public node. Here too, the use of actual
trafﬁc data had the potential to deanonymize clients. PrivEx ame-
liorates this state of affairs by providing researchers the means to
collect statistical data about clients of anonymous networks in a
privacy-preserving and compulsion-resistant manner.

Anonymity networks have to be careful about how they collect
data about their network and users since they are in a position of
power and can potentially expose the entire network. The opera-
tors of Tor currently collect network-wide bandwidth data but this
data is independent of client data. They also collect client-speciﬁc
network usage data from their guard and bridge nodes but not the
exit nodes. The reason why it is considered safer to do the former
and not the latter—in the context of protecting client anonymity—is
that the guards/bridges already know who the clients that connect
through them are so an adversary who compromises those nodes
would not learn any extra information.

A key difference between PrivEx and the present Tor data col-
lection environment is that in that latter, the true client statistics
(aggregated at a per-country level, for example) are stored in a cen-
tralized database. PrivEx does not allow any entity to learn any real
client data expect the nodes that originally collected the data.

8. FUTURE WORK

In the near future we aim to integrate PrivEx with the Tor code-
base. Once this is done we hope to achieve acceptance from the
Tor community and deploy PrivEx on the live Tor network and be-
gin collecting statistics about website visits at exit nodes. We note
that PrivEx is incrementally deployable: even if only a fraction
of Tor exit nodes become DCs for PrivEx, we can still collect data
about Tor trafﬁc exiting through those particular nodes. Then, since
we know the probabilities of each exit node being chosen, we can
extrapolate to statistics for the whole network, albeit with some-
what larger error. Only exit nodes would have to change to support
PrivEx, except for the optional enhancement of §4.2.1, which also
requires the cooperation of entry nodes.

As a potential additional application of PrivEx, we note that
while the Tor network does not typically try to hide the fact that
a client is using Tor, there may be risks to revealing statistics gath-
ered through widespread ingress data collection similar to those
addressed by PrivEx of egress data collection. To address these po-
tential risks, PrivEx can be applied to the present guard/bridge data
collection process, and provide the same beneﬁts as those that have
been shown here for exit nodes.

An open question is whether PrivEx-like systems can be ex-
tended to collect data across subsets of the network. The risks are
that this will give the adversary the ability to partition the data and
perhaps learn something from the statistics that he should not have.

1077If this can be done safely, one direct beneﬁt is that we could, in
a privacy-preserving manner, troubleshoot speciﬁc issues that are
localized.

A limitation of PrivEx, since it is not needed for the scenarios we
study, is that only a single query can be made of the database. We
would like to investigate how to support multiple related queries—
e.g., network load or circuit latency—while maintaining PrivEx’s
privacy and utility features.
9. CONCLUSION

We have presented PrivEx, a decentralized system for privately
collecting client statistics in anonymity networks. We have detailed
two variants of PrivEx, one based on secret sharing and the other on
distributed decryption. Both schemes are efﬁcient and resilient to
coercion attacks and malicious actors. We introduce noise, as de-
ﬁned in the differential privacy setting, into our aggregation process
to prevent information leakage that would otherwise occur when
the statistics are published.

We have used Tor as a case study and show how it can incorpo-
rate PrivEx; other anonymity networks can similarly deploy PrivEx.
In this case study we collect statistics about client destination vis-
its at the DC nodes. We show that this can be done in an efﬁcient
manner with low computational and communication overhead for
conditions typical in the Tor network.

With PrivEx, our aim is to convince administrators and users
of anonymity networks that client data collection is possible while
maintaining anonymity and privacy. The beneﬁts are that valuable
information about usage trends will help guide performance and
maintenance efforts. From the research perspective the beneﬁts
will be more accurate usage statistics, client models, and clearer in-
dicators of future directions that anonymous communications and
censorship resistance research should take.
Acknowledgements We would like to thank NSERC, ORF, and
The Tor Project for funding this research and our CrySP lab col-
leagues for their invaluable feedback.
10. REFERENCES
[1] M. Alsabah, K. Bauer, T. Elahi, and I. Goldberg. The Path
Less Travelled: Overcoming Tor’s Bottlenecks with Trafﬁc
Splitting. In Proceedings of the 13th Privacy Enhancing
Technologies Symposium (PETS ), pages 143–163. Springer,
July 2013.

[2] Anonymizer Inc. Anonymizer.

https://www.anonymizer.com/index.html,
2013. Retrieved May 2014.

[3] G. Barthe, G. Danezis, B. Grégoire, C. Kunz, and

S. Zanella-Béguelin. Veriﬁed computational differential
privacy with applications to smart metering. In 26th IEEE
Computer Security Foundations Symposium (CSF), pages
287–301, 2013.

[4] A. Beimel, K. Nissim, and E. Omri. Distributed private data
analysis: Simultaneously solving how and what. In Advances
in Cryptology–CRYPTO 2008, pages 451–468. Springer,
2008.

[5] J. Benaloh. Dense probabilistic encryption. In Proceedings of

the Workshop on Selected Areas in Cryptography, pages
120–128, 1994.

[6] M. Burkhart, M. Strasser, D. Many, and X. Dimitropoulos.

SEPIA: Privacy-preserving aggregation of multi-domain
network events and statistics. In 19th USENIX Security
Symposium, August 2010.

[7] C. Diaz, L. Sassaman, and E. Dewitte. Comparison between

two practical mix designs. In ESORICS 2004, pages
141–159. Springer, 2004.

[8] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The

second-generation onion router. In Proceedings of the 13th
USENIX Security Symposium, August 2004.

[9] C. Dwork. Differential privacy. In Automata, languages and

programming, pages 1–12. Springer, 2006.

[10] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and

M. Naor. Our data, ourselves: Privacy via distributed noise
generation. In Advances in Cryptology-EUROCRYPT 2006,
pages 486–503. Springer, 2006.

[11] C. Dwork, G. N. Rothblum, and S. Vadhan. Boosting and

differential privacy. In 51st IEEE Symposium on Foundations
of Computer Science (FOCS), pages 51–60. IEEE, 2010.

[12] T. Elahi, G. Danezis, and I. Goldberg. PrivEx: Private

Collection of Trafﬁc Statistics for Anonymous
Communication Networks. Technical Report 2014-08,
CACR, 2014. http://cacr.uwaterloo.ca/
techreports/2014/cacr2014-08.pdf.

[13] V. Goyal, I. Mironov, O. Pandey, and A. Sahai.

Accuracy-privacy tradeoffs for two-party differentially
private protocols. In Advances in Cryptology–CRYPTO
2013, pages 298–315. Springer, 2013.

[14] M. Hardt and A. Roth. Beating randomized response on

incoherent matrices. In 44th Symposium on Theory of
Computing (STOC), pages 1255–1268. ACM, 2012.

[15] M. Jawurek and F. Kerschbaum. Fault-tolerant

privacy-preserving statistics. In 12th Privacy Enhancing
Technologies Symposium (PETS), pages 221–238. Springer,
2012.

[16] JonDo Inc. JonDonym.

http://anonymous-proxy-servers.net/, 2013.
Retrieved May 2014.

[17] jrandom (Pseudonym). Invisible internet project (i2p) project

overview. https://geti2p.net/_static/pdf/
i2p_philosophy.pdf, August 2003. Retrieved May
2014.

[18] S. P. Kasiviswanathan, K. Nissim, S. Raskhodnikova, and

A. Smith. Analyzing graphs with node differential privacy. In
Theory of Cryptography, pages 457–476. Springer, 2013.

[19] S. Köpsell and U. Hillig. How to Achieve Blocking

Resistance for Existing Systems Enabling Anonymous Web
Surﬁng. In Workshop on Privacy in the Electronic Society
(WPES), Washington, DC, USA, October 2004.

[20] K. Kursawe, G. Danezis, and M. Kohlweiss. Privacy-friendly

aggregation for the smart-grid. In 11th Privacy Enhancing
Technologies Symposium (PETS), pages 175–191. Springer,
2011.

[21] K. Loesing. Measuring the Tor Network. https:

//research.torproject.org/techreports/
directory-requests-2009-06-25.pdf, 2009.
Retrieved August 2014.

[22] D. McCoy, K. Bauer, D. Grunwald, T. Kohno, and D. Sicker.
Shining light in dark places: Understanding the Tor network.
In 8th Privacy Enhancing Technologies Symposium (PETS),
pages 63–76. Springer, 2008.

[23] A. McGregor, I. Mironov, T. Pitassi, O. Reingold, K. Talwar,

and S. Vadhan. The limits of two-party differential privacy.
In 51st IEEE Symposium on Foundations of Computer
Science (FOCS), pages 81–90. IEEE, 2010.

[24] I. Mironov. On signiﬁcance of the least signiﬁcant bits for
differential privacy. In 2012 ACM Conference on Computer

1078and Communications Security (CCS), pages 650–661. ACM,
2012.

[25] I. Mironov, O. Pandey, O. Reingold, and S. Vadhan.
Computational differential privacy. In Advances in
Cryptology-CRYPTO 2009, pages 126–142. Springer, 2009.
[26] S. J. Murdoch and G. Danezis. Low-cost trafﬁc analysis of

Tor. In 2005 IEEE Symposium on Security and Privacy.
IEEE, May 2005.

[27] L. Øverlier and P. Syverson. Locating hidden servers. In

2006 IEEE Symposium on Security and Privacy. IEEE, May
2006.

[28] J. M. Pollard. Monte carlo methods for index computation
(mod p). Mathematics of computation, 32(143):918–924,
1978.

[29] K. Poulsen. Edward Snowden’s Email Provider Shuts Down

Amid Secret Court Battle. http:
//www.wired.com/2013/08/lavabit-snowden/,
2013. Retrieved May 2014.

[30] D. Shanks. Class number, a theory of factorization, and

genera. In Proc. Symp. Pure Math, volume 20, pages
415–440, 1971.

[31] E. Shi, T.-H. H. Chan, E. G. Rieffel, R. Chow, and D. Song.

Privacy-preserving aggregation of time-series data. In
Network and Distributed System Security Symposium
(NDSS), 2011.

[32] R. Singel. Encrypted E-Mail Company Hushmail Spills to

Feds. http://www.wired.com/threatlevel/
2007/11/encrypted-e-mai/, 2007. Retrieved May
2014.

[33] C. Soghoian. Enforced Community Standards for Research
on Users of the Tor Anonymity Network. In 2nd Workshop
on Ethics in Computer Security Research (WECSR), pages
146–153, 2011.

[34] The Tor Project. Tor Mertics Portal: Network, Advertised

bandwidth distribution. https:
//metrics.torproject.org/network.html,
2014. Retrieved May 2014.

[35] The Tor Project. Tor Mertics Portal: Users. https:

//metrics.torproject.org/users.html, 2014.
Retrieved May 2014.

[36] P. Winter. Towards a Tor Censorship Analysis Tool.

https://blog.torproject.org/category/
tags/measurement, 2013. Retrieved August 2014.

1079