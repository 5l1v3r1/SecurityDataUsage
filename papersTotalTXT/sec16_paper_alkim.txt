Post-quantum Key Exchange—A New Hope
Erdem Alkim, Ege University; Léo Ducas, Centrum voor Wiskunde en Informatica;  

Thomas Pöppelmann, Infineon Technologies AG; Peter Schwabe, Radboud University

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/alkim

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Post-quantum key exchange – a new hope∗

Department of Mathemathics, Ege University, Turkey

Erdem Alkim

Centrum voor Wiskunde en Informatica, Amsterdam, The Netherlands

Léo Ducas

Thomas Pöppelmann

Inﬁneon Technologies AG, Munich, Germany

Digital Security Group, Radboud University, The Netherlands

Peter Schwabe

Abstract
At IEEE Security & Privacy 2015, Bos, Costello,
Naehrig, and Stebila proposed an instantiation of Peik-
ert’s ring-learning-with-errors–based (Ring-LWE) key-
exchange protocol (PQCrypto 2014), together with an
implementation integrated into OpenSSL, with the af-
ﬁrmed goal of providing post-quantum security for TLS.
In this work we revisit their instantiation and stand-alone
implementation. Speciﬁcally, we propose new param-
eters and a better suited error distribution, analyze the
scheme’s hardness against attacks by quantum comput-
ers in a conservative way, introduce a new and more efﬁ-
cient error-reconciliation mechanism, and propose a de-
fense against backdoors and all-for-the-price-of-one at-
tacks. By these measures and for the same lattice dimen-
sion, we more than double the security parameter, halve
the communication overhead, and speed up computation
by more than a factor of 8 in a portable C implementation
and by more than a factor of 27 in an optimized imple-
mentation targeting current Intel CPUs. These speedups
are achieved with comprehensive protection against tim-
ing attacks.

1

Introduction

The last decade in cryptography has seen the birth of
numerous constructions of cryptosystems based on lat-
tice problems, achieving functionalities that were previ-
ously unreachable (e.g., fully homomorphic cryptogra-

∗This work was initiated while Thomas Pöppelmann was a Ph.D.
student at Ruhr-University Bochum with support from the European
Union H2020 SAFEcrypto project (grant no. 644729). This work has
furthermore been supported by TÜBITAK under 2214-A Doctoral Re-
search Program Grant, by the European Commission through the ICT
program under contract ICT-645622 (PQCRYPTO), and by the Nether-
lands Organisation for Scientiﬁc Research (NWO) through Veni 2013
project 13114 and through a Free Competition Grant. Permanent ID
of this document: 0462d84a3d34b12b75e8f5e4ca032869. Date:
2016-06-28.

phy [38]). But even for the simplest tasks in asymmetric
cryptography, namely public-key encryption, signatures,
and key exchange, lattice-based cryptography offers an
important feature: resistance to all known quantum algo-
rithms. In those times of quantum nervousness [73, 74],
the time has come for the community to deliver and op-
timize concrete schemes, and to get involved in the stan-
dardization of a lattice-based cipher-suite via an open
process.

For encryption and signatures, several competitive
schemes have been proposed; examples are NTRU en-
cryption [50, 83], Ring-LWE encryption [67] as well as
the signature schemes BLISS [31], PASS [48] or the pro-
posal by Bai and Galbraith presented in [8]. To complete
the lattice-based cipher-suite, Bos et al. [20] recently
proposed a concrete instantiation of the key-exchange
scheme of Peikert’s improved version of the original pro-
tocol of Ding, Xie and Lin [52, 77]. Bos et al. proved its
practicality by integrating their implementation as addi-
tional cipher-suite into the transport layer security (TLS)
protocol in OpenSSL. In the following we will refer to
this proposal as BCNS.

Unfortunately,

the performance of BCNS seemed
rather disappointing. We identify two main sources for
this inefﬁciency. First the analysis of the failure probabil-
ity was far from tight, resulting in a very large modulus
q ≈ 232. As a side effect, the security is also signiﬁcantly
lower than what one could achieve with Ring-LWE for
a ring of rank n = 1024. Second the Gaussian sampler,
used to generate the secret parameters, is fairly inefﬁcient
and hard to protect against timing attacks. This second
source of inefﬁciency stems from the fundamental mis-
conception that high-quality Gaussian noise is crucial for
encryption based on LWE1, which has also made various
other implementations [29,79] slower and more complex
than they would have to be.

1This is very different for lattice-based signatures or trapdoors,
where distributions need to be meticulously crafted to prevent any leak
of information on a secret basis.

USENIX Association  

25th USENIX Security Symposium  327

1.1 Contributions
In this work, we propose solutions to the performance
and security issues of the aforementioned BCNS pro-
posal [20]. Our improvements are possible through a
combination of multiple contributions:

• Our ﬁrst contribution is an improved analysis of
the failure probability of the protocol. To push
the scheme even further, inspired by analog error-
correcting codes, we make use of the lattice D4
to allow error reconciliation beyond the original
bounds of [77]. This drastically decreases the mod-
ulus to q = 12289 < 214, which improves both efﬁ-
ciency and security.

• Our second contribution is a more detailed secu-
rity analysis against quantum attacks. We pro-
vide a lower bound on all known (or even pre-
supposed) quantum algorithms solving the shortest-
vector problem (SVP), and deduce the potential per-
formance of a quantum BKZ algorithm. Accord-
ing to this analysis, our improved proposal provides
128 bits of post-quantum security with a comfort-
able margin.

• We furthermore propose to replace the almost-
perfect discrete Gaussian distribution by some-
thing relatively close, but much easier to sample,
and prove that this can only affect the security
marginally.

• We replace the ﬁxed parameter a of the original
scheme by a freshly chosen random one in each key
exchange. This incurs an acceptable overhead but
prevents backdoors embedded in the choice of this
parameter and all-for-the-price-of-one attacks.

• We specify an encoding of polynomials in the
number-theoretic transform (NTT) domain which
allows us to eliminate some of the NTT transfor-
mations inside the protocol computation.

• To demonstrate the applicability and performance
of our design we provide a portable reference im-
plementation written in C and a highly optimized
vectorized implementation that targets recent Intel
CPUs and is compatible with recent AMD CPUs.
We describe an efﬁcient approach to lazy reduction
inside the NTT, which is based on a combination
of Montgomery reductions and short Barrett reduc-
tions.

Availability of software. We place all software de-
scribed in this paper
into the public domain and
make it available online at https://cryptojedi.

2

org/crypto/#newhope and https://github.com/
tpoeppelmann/newhope.

Full version of the paper. The full version of this pa-
per contains various appendices in addition to the ma-
terial presented in this proceedings version. The full
version is available online at https://eprint.iacr.
org/2015/1092/ and at https://cryptojedi.org/
papers/#newhope.

Acknowledgments. We are thankful to Mike Hamburg
and to Paul Crowley for pointing out mistakes in a pre-
vious version of this paper, and we are thankful to Isis
Lovecruft for thoroughly proofreading the paper and for
suggesting the name JARJAR for the low-security variant
of our proposal.

2 Lattice-based key exchange

Let Z be the ring of rational integers. We deﬁne for an
x ∈ R the rounding function (cid:29)x(cid:28) = (cid:29)x + 1
2(cid:27) ∈Z . Let Zq,
for an integer q ≥ 1, denote the quotient ring Z/qZ. We
deﬁne R = Z[X]/(X n + 1) as the ring of integer polyno-
mials modulo X n +1. By Rq = Zq[X]/(X n +1) we mean
the ring of integer polynomials modulo X n + 1 where
each coefﬁcient is reduced modulo q. In case χ is a prob-
ability distribution over R, then x $← χ means the sam-
pling of x ∈ R according to χ. When we write a $← Rq
this means that all coefﬁcients of a are chosen uniformly
at random from Zq. For a probabilistic algorithm A we
denote by y $← A that the output of A is assigned to y
and that A is running with randomly chosen coins. We
recall the discrete Gaussian distribution DZ,σ which is
parametrized by the Gaussian parameter σ ∈ R and de-
ﬁned by assigning a weight proportional to exp(−x2
2σ 2 ) to
all integers x.

2.1 The scheme of Peikert
In this section we brieﬂy revisit the passively secure key-
encapsulation mechanism (KEM) that was proposed by
Peikert [77] and instantiated in [20] (BCNS). Peikert’s
KEM scheme is deﬁned by the algorithms (Setup, Gen,
Encaps, Decaps) and after a successful protocol run both
parties share an ephemeral secret key that can be used to
protect further communication (see Protocol 1).

The KEM scheme by Peikert closely resembles a pre-
viously introduced Ring-LWE encryption scheme [66]
but due to a new error-reconciliation mechanism, one
Rq component of the ciphertext can be replaced by a
more compact element in R2. This efﬁciency gain is
possible due to the observation that it is not necessary
to transmit an explicitly chosen key to establish a secure

328  25th USENIX Security Symposium 

USENIX Association

ephemeral session key. In Peikert’s scheme, the recon-
ciliation just allows both parties to derive the session key
from an approximately agreed pseudorandom ring ele-
ment. For Alice, this ring element is us = ass(cid:31) + e(cid:31)s and
for Bob it is v = bs(cid:31) + e(cid:31)(cid:31) = ass(cid:31) + es(cid:31) + e(cid:31)(cid:31). For a full
explanation of the reconciliation we refer to the original
paper [77] but brieﬂy recall the cross-rounding function
(cid:30)·(cid:28)2 deﬁned as (cid:30)v(cid:28)2 := (cid:27) 4
q · v(cid:26) mod 2 and the random-
ized function dbl(v) := 2v− ¯e for some random ¯e where
2, ¯e = 1 with probability 1
¯e = 0 with probability 1
4, and
4. Let I0 = {0,1, . . . ,(cid:27) q
¯e = −1 with probability 1
2(cid:26)−1},
2(cid:22), . . . ,−1}, and E = [− q
4 , q
I1 = {−(cid:27) q
4 ) then the reconcil-
iation function rec(w,b) is deﬁned as
rec(w,b) =(cid:31)0,

if w ∈ Ib + E ( mod q)

1, otherwise.

If these functions are applied to polynomials this means
they are applied to each of the coefﬁcients separately.

Parameters: q,n, χ
KEM.Setup() :
a $← Rq
Alice (server)
KEM.Gen(a) :
s,e $← χ
b←as + e

KEM.Decaps(s, (u,v(cid:31))) :
µ←rec(2us,v(cid:31))

Bob (client)
KEM.Encaps(a,b) :

s(cid:31),e(cid:31),e(cid:31)(cid:31)

$← χ
b
−→ u←as(cid:31) + e(cid:31)
v←bs(cid:31) + e(cid:31)(cid:31)
¯v $← dbl(v)
u,v(cid:31)
←−− v(cid:31) = (cid:30)¯v(cid:28)2
µ←(cid:27)¯v(cid:26)2

Protocol 1: Peikert’s KEM mechanism.

2.2 The BCNS proposal
In a work by Bos, Costello, Naehrig, and Stebila [20]
(BCNS), Peikert’s KEM [77] was phrased as a key-
exchange protocol (see again Protocol 1), instantiated for
a concrete parameter set, and integrated into OpenSSL
(see Section 8 for a performance comparison). Selection
of parameters was necessary as Peikert’s original work
does not contain concrete parameters and the security as
well as error estimation are based on asymptotics. The
authors of [20] chose a dimension n = 1024, a modu-
lus q = 232 − 1, χ = DZ,σ and the Gaussian parameter
σ = 8/√2π ≈ 3.192. It is claimed that these parameters
provide a classical security level of at least 128 bits con-
sidering the distinguishing attack [62] with distinguish-
ing advantage less than 2−128 and 281.9 bits of security

against an optimistic instantiation of a quantum adver-
sary. The probability of a wrong key being established is
less than 2−217
= 2−131072. The message b sent by Alice
is a ring element and thus requires at least log2(q)n = 32
kbits while Bob’s response (u,r) is a ring element Rq and
an element from R2 and thus requires at least 33 kbits. As
the polynomial a ∈ Rq is shared between all parties this
ring element has to be stored or generated on-the-ﬂy. For
timings of their implementation we refer to Table 2. We
would also like to note that besides its aim for securing
classical TLS, the BCNS protocol has already been pro-
posed as a building block for Tor [84] on top of existing
elliptic-curve infrastructure [41].

2.3 Our proposal: NEWHOPE
In this section we detail our proposal and modiﬁcations
of Peikert’s protocol2. For the same reasons as described
in [20] we opt for an unauthenticated key-exchange pro-
tocol; the protection of stored transcripts against future
decryption using quantum computers is much more ur-
gent than post-quantum authentication. Authenticity will
most likely be achievable in the foreseeable future us-
ing proven pre-quantum signatures and attacks on the
signature will not compromise previous communication.
Additionally, by not designing or instantiating a lattice-
based authenticated key-exchange protocol (see [33,85])
we reduce the complexity of the key-exchange protocol
and simplify the choice of parameters. We actually see it
as an advantage to decouple key exchange and authen-
tication as it allows a protocol designer to choose the
optimal algorithm for both tasks (e.g., an ideal-lattice-
based key exchange and a hash-based signature like [16]
for authentication). Moreover, this way the design, se-
curity level, and parameters of the key-exchange scheme
are not constrained by requirements introduced by the
authentication part.
Parameter choices. A high-level description of our pro-
posal is given in Protocol 2 and as in [20, 77] all poly-
nomials except for r ∈ R4 are deﬁned in the ring Rq =
Zq[X]/(X n + 1) with n = 1024 and q = 12289. We de-
cided to keep the dimension n = 1024 as in [20] to be
able to achieve appropriate long-term security. As poly-
nomial arithmetic is fast and also scales better (doubling
n roughly doubles the time required for a polynomial
multiplication), our choice of n appears to be acceptable
from a performance point of view. We chose the modulus
q = 12289 as it is the smallest prime for which it holds
that q ≡ 1 mod 2n so that the number-theoretic trans-
form (NTT) can be realized efﬁciently and that we can
transfer polynomials in NTT encoding (see Section 7).

2For the TLS use-case and for compatibility with BNCS [20] the
key exchange is initiated by the server. However, in different scenarios
the roles of the server and client can be exchanged.

USENIX Association  

25th USENIX Security Symposium  329

3

As the security level grows with the noise-to-modulus
ratio, it makes sense to choose the modulus as small as
possible, improving compactness and efﬁciency together
with security. The choice is also appealing as the prime is
already used by some implementations of Ring-LWE en-
cryption [29, 63, 81] and BLISS signatures [31, 78]; thus
sharing of some code (or hardware modules) between our
proposal and an implementation of BLISS would be pos-
sible.
Noise distribution and reconciliation. Notably, we also
change the distribution of the LWE secret and error and
replace discrete Gaussians by the centered binomial dis-
tribution ψk of parameter k = 16 (see Section 4). The
reason is that it turned out to be challenging to imple-
ment a discrete Gaussian sampler efﬁciently and pro-
tected against timing attacks (see [20] and Section 5).
On the other hand, sampling from the centered binomial
distribution is easy and does not require high-precision
computations or large tables as one may sample from ψk
by computing ∑k
i=0 bi − b(cid:30)i, where the bi,b(cid:30)i ∈ {0,1} are
uniform independent bits. The distribution ψk is cen-
tered (its mean is 0), has variance k/2 and for k = 16
this gives a standard deviation of ς =(cid:31)16/2. Con-

trary to [20, 77] we hash the output of the reconciliation
mechanism, which makes a distinguishing attack irrele-
vant and allows us to argue security for the modiﬁed error
distribution.

Moreover, we generalize Peikert’s reconciliation
mechanism using an analog error-correction approach
(see Section 5). The design rationale is that we only want
to transmit a 256-bit key but have n = 1024 coefﬁcients
to encode data into. Thus we encode one key bit into
four coefﬁcients; by doing so we achieve increased error
resilience which in turn allows us to use larger noise for
better security.
Short-term public parameters. NEWHOPE does not
rely on a globally chosen public parameter a as the ef-
ﬁciency increase in doing so is not worth the measures
that have to be taken to allow trusted generation of this
value and the defense against backdoors [13]. Moreover,
this approach avoids the rather uncomfortable situation
that all connections rely on a single instance of a lattice
problem (see Section 3) in the ﬂavor of the “Logjam”
DLP attack [1].
No key caching. For ephemeral Difﬁe-Hellman key-
exchange in TLS it is common for servers to cache a key
pair for a short time to increase performance. For ex-
ample, according to [24], Microsoft’s SChannel library
caches ephemeral keys for 2 hours. We remark that for
the lattice-based key exchange described in [77], for the
key exchange described in [20], and also for the key ex-
change described in this paper, such short-term caching
would be disastrous for security. Indeed, it is crucial that

both parties use fresh secrets for each instantiation (thus
the performance of the noise sampling is crucial). As
short-term key caching typically happens on higher lay-
ers of TLS libraries than the key-exchange implemen-
tation itself, we stress that particular care needs to be
taken to eliminate such caching when switching from
ephemeral (elliptic-curve) Difﬁe-Hellman key exchange
to post-quantum lattice-based key exchange. This issue
is discussed in more detail in [32].

One could enable key caching with a transformation
from the CPA-secure key exchange to a CCA-secure key
exchange as outlined by Peikert in [77, Section 5]. Note
that such a transform would furthermore require changes
to the noise distribution to obtain a failure probability
that is negligible in the cryptographic sense.

3 Preventing backdoors and all-for-the-

price-of-one attacks

One serious concern about the original design [20] is the
presence of the polynomial a as a ﬁxed system parameter.
As described in Protocol 2, our proposal includes pseu-
dorandom generation of this parameter for every key ex-
change. In the following we discuss the reasons for this
decision.
Backdoor. In the worst scenario, the ﬁxed parameter a
could be backdoored. For example, inspired by NTRU
trapdoors [50, 83], a dishonest authority may choose
mildly small f,g such that f = g = 1 mod p for some
prime p ≥ 4 · 16 + 1 and set a = gf−1 mod q. Then,
given (a,b = as + e), the attacker can compute bf =
afs +fe = gs +fe mod q, and, because g,s,f,e are small
enough, compute gs +fe in Z. From this he can compute
t = s + e mod p and, because the coefﬁcients of s and
e are smaller than 16, their sums are in [−2· 16,2· 16]:
knowing them modulo p ≥ 4· 16 + 1 is knowing them in
Z. It now only remains to compute (b− t)· (a− 1)−1 =
(as− s)· (a− 1)−1 = s mod q to recover the secret s.
One countermeasure against such backdoors is the
“nothing-up-my-sleeve” process, which would, for ex-
ample, choose a as the output of a hash function on a
common universal string like the digits of π. Yet, even
this process may be partially abused [13], and when not
strictly required it seems preferable to avoid it.
All-for-the-price-of-one attacks. Even if this common
parameter has been honestly generated, it is still rather
uncomfortable to have the security of all connections
rely on a single instance of a lattice problem. The sce-
nario is an entity that discovers an unforeseen cryptan-
alytic algorithm, making the required lattice reduction
still very costly, but say, not impossible in a year of
computation, given its outstanding computational power.
By ﬁnding once a good enough basis of the lattice Λ =

330  25th USENIX Security Symposium 

USENIX Association

4

Parameters: q = 12289 < 214, n = 1024
Error distribution: ψ16

Alice (server)
seed $← {0,1}256
a←Parse(SHAKE-128(seed))
s,e $← ψn
b←as + e

16

v(cid:28)←us
ν←Rec(v(cid:28),r)
µ←SHA3-256(ν)

(u,r)
←−−

(b,seed)
−−−−→ a←Parse(SHAKE-128(seed))

Bob (client)

s(cid:28),e(cid:28),e(cid:28)(cid:28)

$← ψn

16

u←as(cid:28) + e(cid:28)
v←bs(cid:28) + e(cid:28)(cid:28)
r $← HelpRec(v)
ν←Rec(v,r)
µ←SHA3-256(ν)

Protocol 2: Our Scheme. For the deﬁnitions of HelpRec and Rec see Section 5. For the deﬁnition of encodings and
the deﬁnition of Parse see Section 7.

{(a,1)x + (q,0)y|x,y ∈ R}, this entity could then com-
promise all communications, using for example Babai’s
decoding algorithm [7].

This idea of massive precomputation that is only de-
pendent on a ﬁxed parameter a and then afterwards can
be used to break all key exchanges is similar in ﬂa-
vor to the 512-bit “Logjam” DLP attack [1]. This at-
tack was only possible in the required time limit because
most TLS implementations use ﬁxed primes for Difﬁe-
Hellman. One of the recommended mitigations by the
authors of [1] is to avoid ﬁxed primes.
Against all authority. Fortunately, all those pitfalls can
be avoided by having the communicating parties gen-
erate a fresh a at each instance of the protocol (as we
propose).
If in practice it turns out to be too expen-
sive to generate a for every connection, it is also possi-
ble to cache a on the server side3 for, say a few hours
without signiﬁcantly weakening the protection against
all-for-the-price-of-one attacks. Additionally, the perfor-
mance impact of generating a is reduced by sampling a
uniformly directly in NTT format (recalling that the NTT
is a one-to-one map), and by transferring only a short
256-bit seed for a (see Section 7).

A subtle question is to choose an appropriate prim-
itive to generate a “random-looking” polynomial a out
of a short seed. For a security reduction,
it seems
to the authors that there is no way around the (non-
programmable) random oracle model (ROM). It is ar-
gued in [34] that such a requirement is in practice an
overkill, and that any pseudorandom generator (PRG)
should also work. And while it is an interesting question
how such a reasonable pseudo-random generator would
interact with our lattice assumption, the cryptographic

3But recall that the secrets s,e,s(cid:28),s(cid:28),e(cid:28)(cid:28) have to be sampled fresh for

every connection.

5

notion of a PRG is not helpful to argue security. Indeed,
it is an easy exercise4 to build (under the NTRU assump-
tion) a “backdoored” PRG that is, formally, a legitimate
PRG, but that makes our scheme insecure.

Instead, we prefer to base ourselves on a standard
cryptographic hash-function, which is the typical choice
of an “instantiation” of the ROM. As a suitable op-
tion we see Keccak [19], which has recently been stan-
dardized as SHA3 in FIPS-202 [72], and which offers
extendable-output functions (XOF) named SHAKE. This
avoids costly external iteration of a regular hash function
and directly ﬁts our needs.

We use SHAKE-128 for the generation of a, which
offers 128-bits of (post-quantum) security against colli-
sions and preimage attacks. With only a small perfor-
mance penalty we could have also chosen SHAKE-256,
but we do not see any reason for such a choice, in partic-
ular because neither collisions nor preimages lead to an
attack against the proposed scheme.

4 Choice of the error distribution

On non-Gaussian errors. In works like [20, 29, 81], a
signiﬁcant algorithmic effort is devoted to sample from a
discrete Gaussian distribution to a rather high precision.
In the following we argue that such effort is not neces-
sary and motivate our choice of a centered binomial ψk
as error distribution.
Indeed, we recall

the original worst-case to
average-case reductions for LWE [80] and Ring-

that

4Consider a secure PRG p, and parse its output p(seed) as two
small polynomial (f,g): an NTRU secret-key. Deﬁne p(cid:28)(seed) = gf−1
mod q: under the decisional NTRU assumption, p(cid:28) is still a secure PRG.
Yet revealing the seed does reveal (f,g) and provides a backdoor as de-
tailed above.

USENIX Association  

25th USENIX Security Symposium  331

LWE [67] state hardness for continuous Gaussian dis-
tributions (and therefore also trivially apply to rounded
Gaussian, which differ from discrete Gaussians). This
also extends to discrete Gaussians [21] but such proofs
are not necessarily intended for direct implementations.
We recall that the use of discrete Gaussians (or other dis-
tributions with very high-precision sampling) is only cru-
cial for signatures [65] and lattice trapdoors [39], to pro-
vide zero-knowledgeness.

The following Theorem states that choosing ψk as er-
ror distribution in Protocol 2 does not signiﬁcantly de-
crease security compared to a rounded Gaussian distri-

bution with the same standard deviation σ =(cid:31)16/2.
Theorem 4.1 Let ξ be the rounded Gaussian distribu-
tion of parameter σ = √8, that is, the distribution of
(cid:30)√8 · x(cid:28) where x follows the standard normal distribu-
tion. Let P be the idealized version of Protocol 2, where
the distribution ψ16 is replaced by ξ . If an (unbounded)
algorithm, given as input the transcript of an instance
of Protocol 2 succeeds in recovering the pre-hash key ν
with probability p, then it would also succeed against P
with probability at least

q ≥ p9/8/26.

Proof See Appendix B in the full version of this paper.

As explained in Section 6, our choice of parameters
leaves a comfortable margin to the targeted 128 bits
of post-quantum security, which accommodates for the
slight loss in security indicated by Theorem 4.1. Even
more important from a practical point of view is that no
known attack makes use of the difference in error distri-
bution; what matters for attacks are entropy and standard
deviation.
Simple implementation. We remark that sampling from
the centered binomial distribution ψ16 is rather trivial
in hardware and software, given the availability of a
uniform binary source. Additionally, the implementa-
tion of this sampling algorithm is much easier to pro-
tect against timing attacks as no large tables or data-
dependent branches are required (cf. to the issues caused
by the table-based approach used in [20]).

5

Improved error-recovery mechanism

In most of the literature, Ring-LWE encryption allows to
encrypt one bit per coordinate of the ciphertext. It is also
well known how to encrypt multiple bits per coordinate
by using a larger modulus-to-error ratio (and therefore
decreasing the security for a ﬁxed dimension n). How-
ever, in the context of exchanging a symmetric key (of,
say, 256 bits), we end up having a message space larger

(0, 1)

(1, 1)

( 1

2

,

1

2 )

(0, 0)

(1, 0)

Figure 1: The lattice ˜D2 with Voronoi cells

than necessary and thus want to encrypt one bit in multi-
ple coordinates.

In [79] Pöppelmann and Güneysu introduced a tech-
nique to encode one bit into two coordinates, and veriﬁed
experimentally that it led to a better error tolerance. This
allows to either increase the error and therefore improve
the security of the resulting scheme or to decrease the
probability of decryption failures. In this section we pro-
pose a generalization of this technique in dimension 4.
We start with an intuitive description of the approach in
2 dimensions and then explain what changes in 4 dimen-
sions. Appendices C and D in the full version of this
paper give a thorough mathematical description together
with a rigorous analysis.

Let us ﬁrst assume that both client and server have the
same vector x ∈ [0,1)2 ⊂ R2 and want to map this vector
to a single bit. Mapping polynomial coefﬁcients from
{0, . . . ,q − 1} to [0,1) is easily accomplished through a
division by q.
Now consider the lattice ˜D2 with basis {(0,1), ( 1
2 , 1
2 )}.
This lattice is a scaled version of the root lattice D2,
speciﬁcally, ˜D2 = 1
2 · D2. Part of ˜D2 is depicted in Fig-
ure 1; lattice points are shown together with their Voronoi
cells and the possible range of the vector x is marked
with dashed lines. Mapping x to one bit is done by
ﬁnding the closest-vector v ∈ ˜D2.
2 ) (i.e.,
x is in the grey Voronoi cell), then the output bit is 1;
if v ∈ {(0,0), (0,1), (1,0), (1,1)} (i.e., x is in a white
Voronoi cell) then the output bit is 0.
This map may seem like a fairly complex way to map
from a vector to a bit. However, recall that client and
server only have a noisy version of x, i.e., the client has
a vector xc and the server has a vector xs. Those two
vectors are close, but they are not the same and can be on
different sides of a Voronoi cell border.

If v = ( 1

2 , 1

Error reconciliation. The approach described above
now allows for an efﬁcient solution to solve this
agreement-from-noisy-data problem. The idea is that
one of the two participants (in our case the client) sends
as a reconciliation vector the difference of his vector xc

6

332  25th USENIX Security Symposium 

USENIX Association

( 1

2

,

1

2 )

Figure 2: Splitting of the Voronoi cell of ( 1
2 ) into 2rd =
16 sub-cells, some with their corresponding difference
vector to the center

2 , 1

and the center of its Voronoi cell (i.e., the point in the
lattice). The server adds this difference vector to xs and
thus moves away from the border towards the center of
the correct Voronoi cell. Note that an eavesdropper does
not learn anything from the reconciliation information:
the client tells the difference to a lattice point, but not
whether this is a lattice point producing a zero bit or a
one bit.

This approach would require sending a full additional
vector; we can reduce the amount of reconciliation in-
formation through r-bit discretization. The idea is to
split each Voronoi cell into 2dr sub-cells and only send
in which of those sub-cells the vector xc is. Both partici-
pants then add the difference of the center of the sub-cell
and the lattice point. This is illustrated for r = 2 and
d = 2 in Figure 2.

q , . . . , q−1

Blurring the edges. Figure 1 may suggest that the prob-
ability of x being in a white Voronoi cell is the same as
for x being in the grey Voronoi cell. This would be the
case if x actually followed a continuous uniform distri-
bution. However, the coefﬁcients of x are discrete values
in {0, 1
q } and with the protocol described so far,
the bits of ν would have a small bias. The solution is to
add, with probability 1
2q ) to x before
running the error reconciliation. This has close to no ef-
fect for most values of x, but, with probability 1
2 moves x
to another Voronoi cell if it is very close to one side of a
border. Appendix E in the full version of this paper gives
a graphical intuition for this trick in two dimensions and
with q = 9. The proof that it indeed removes all biases in
the key is given in Lemma C.2. in the full version of this
paper.

2, the vector ( 1

2q , 1

2 , 1

2 , 1

2 , 1

Z4 and gt =(cid:31) 1

2(cid:30). The lattice ˜D4 is a rotated and

scaled version of the root lattice D4. The Voronoi cells
of this lattice are no longer 2-dimensional “diamonds”,
but 4-dimensional objects called icositetrachoron or 24-
cells [61]. Determining in which cell a target point lies
in is done using the closest vector algorithm CVP ˜D4, and
a simpliﬁed version of it, which we call Decode, gives
the result modulo Z4.

As in the 2-dimensional illustration in Figure 2, we are
using 2-bit discretization; we are thus sending r · d = 8
bits of reconciliation information per key bit.
Putting all of this together, we obtain the HelpRec
function to compute the r-bit reconciliation information
as

(x + bg)(cid:28) mod 2r,
HelpRec(x;b) =CVP ˜D4(cid:29)2r
where b ∈ {0,1} is a uniformly chosen random bit. The
qx− 1
corresponding function Rec(x,r) =Decode( 1
2r Br)
computes one key bit from a vector x with 4 coefﬁcients
in Zq and a reconciliation vector r ∈ {0,1,2,3}4. The
algorithms CVP ˜D4 and Decode are listed as Algorithm 1
and Algorithm 2, respectively.

q

Algorithm 1 CVP ˜D4(x ∈ R4)
Ensure: An integer vector z such that Bz is a closest

vector to x: x− Bz ∈ V

1: v0←(cid:25)x(cid:24)
2: v1←(cid:25)x− g(cid:24)
3: k←((cid:23)x− v0(cid:23)1 < 1) ? 0 : 1
4: (v0,v1,v2,v3)t←vk
5: return (v0,v1,v2,k)t + v3 · (−1,−1,−1,2)t

Algorithm 2 Decode(x ∈ R4/Z4)
Ensure: A bit k such that kg is a closest vector to x+Z4:

x− kg ∈ V + Z4

1: v = x−(cid:25)x(cid:24)
2: return 0 if (cid:23)v(cid:23)1 ≤ 1 and 1 otherwise

Finally it remains to remark that even with this rec-
onciliation mechanism client and server do not always
agree on the same key. Lemma D in the full version
of this paper. provides a detailed analysis of the fail-
ure probability of the key agreement and shows that it is
smaller than 2−60.

From 2 to 4 dimensions. When moving from the 2-
dimensional case considered above to the 4-dimensional
case used in our protocol, not very much needs to change.
The lattice ˜D2 becomes the lattice ˜D4 with basis B =
(u0,u1,u2,g), where ui are the canonical basis vectors of

6 Post-quantum security analysis

In [20] the authors chose Ring-LWE for a ring of rank
n = 1024, while most previous instantiations of the Ring-
LWE encryption scheme, like the ones in [29,42,63,79],

USENIX Association  

25th USENIX Security Symposium  333

7

chose substantially smaller rank n = 256 or n = 512. It
is argued that it is unclear if dimension 512 can offer
post-quantum security. Yet, the concrete post-quantum
security of LWE-based schemes has not been thoroughly
studied, as far as we know. In this section we propose
such a (very pessimistic) concrete analysis. In particu-
lar, our analysis reminds us that the security depends as
much on q and its ratio with the error standard deviation
ς as it does on the dimension n. That means that our ef-
fort of optimizing the error recovery and its analysis not
only improves efﬁciency but also offers superior security.
Security level over-shoot? With all our improvements,
it would be possible to build a scheme with n = 512
(and k = 24, q = 12289) and to obtain security some-
what similar to the one of [20, 42], and therefore fur-
ther improve efﬁciency. We call this variant JARJAR and
details are provided in Appendix A of the full version
of this paper. Nevertheless, as history showed us with
RSA-512 [28], the standardization and deployment of a
scheme awakens further cryptanalytic effort. In particu-
lar, NEWHOPE could withstand a dimension-halving at-
tack in the line of [36, Sec 8.8.1] based on the Gentry-
Szydlo algorithm [40,60] or the subﬁeld approach of [2].
Note that so far, such attacks are only known for princi-
pal ideal lattices or NTRU lattices, and there are serious
obstructions to extend them to Ring-LWE, but such pre-
caution seems reasonable until lattice cryptanalysis sta-
bilizes.

We provide the security and performance analysis of
JARJAR in Appendix A of the full version of this paper
mostly for comparison with other lower-security propos-
als. We strongly recommend NEWHOPE for any imme-
diate applications, and advise against using JARJAR un-
til concrete cryptanalysis of lattice-based cryptography is
better understood.

6.1 Methodology: the core SVP hardness
We analyze the hardness of Ring-LWE as an LWE prob-
lem, since, so far, the best known attacks do not make use
of the ring structure. There are many algorithms to con-
sider in general (see the survey [3]), yet many of those
are irrelevant for our parameter set. In particular, because
there are only m = n samples available one may rule out
BKW types of attacks [53] and linearization attacks [6].
This essentially leaves us with two BKZ [26,82] attacks,
usually referred to as primal and dual attacks that we will
brieﬂy recall below.

The algorithm BKZ proceeds by reducing a lattice ba-
sis using an SVP oracle in a smaller dimension b. It is
known [47] that the number of calls to that oracle re-
mains polynomial, yet concretely evaluating the number
of calls is rather painful, and this is subject to new heuris-
tic ideas [25, 26]. We choose to ignore this polynomial

factor, and rather evaluate only the core SVP hardness,
that is the cost of one call to an SVP oracle in dimension
b, which is clearly a pessimistic estimation (from the de-
fender’s point of view).

6.2 Enumeration versus quantum sieve

Typical implementations [23, 26, 35] use an enumeration
algorithm as this SVP oracle, yet this algorithm runs in
super-exponential time. On the other hand, the sieve al-
gorithms are known to run in exponential time, but are so
far slower in practice for accessible dimensions b ≈ 130.
We choose the latter to predict the core hardness and will
argue that for the targeted dimension, enumerations are
expected to be greatly slower than sieving.

Quantum sieve. A lot of recent work has pushed the ef-
ﬁciency of the original lattice sieve algorithms [69, 75],
improving the heuristic complexity from (4/3)b+o(b) ≈
20.415b down to (cid:31)3/2b+o(b)
≈ 20.292b (see [10, 55]).
The hidden sub-exponential factor is known to be much
greater than one in practice, so again, estimating the
cost ignoring this factor leaves us with a signiﬁcant pes-
simistic margin.

Most of those algorithms have been shown [54, 56] to
beneﬁt from Grover’s quantum search algorithm, bring-
ing the complexity down to 20.265b. It is unclear if fur-
ther improvements are to be expected, yet, because all
those algorithms require classically building lists of size
≈ 20.2075b, it is very plausible that the best
quantum SVP algorithm would run in time greater than
20.2075b.

(cid:31)4/3b+o(b)

Irrelevance of enumeration for our analysis. In [26],
predictions of the cost of solving SVP classically us-
ing the most sophisticated heuristic enumeration algo-
rithms are given. For example, solving SVP in dimension
100 requires visiting about 239 nodes, and 2134 nodes
in dimension 250. Because this enumeration is a back-
tracking algorithm, it does beneﬁt from the recent quasi-
quadratic speedup [70], decreasing the quantum cost to
about at least 220 to 267 operations as the dimension in-
creases from 100 to 250.

On the other hand, our best-known attack bound
20.265b gives a cost of 266 in dimension 250, and the best
plausible attack bound 20.2075b ≈ 239. Because enumera-
tion is super-exponential (both in theory and practice), its
cost will be worse than our bounds in dimension larger
than 250 and we may safely ignore this kind of algo-
rithm.5

5The numbers are taken from the latest full version of [26] available

at http://www.di.ens.fr/~ychen/research/Full_BKZ.pdf.

334  25th USENIX Security Symposium 

USENIX Association

8

6.3 Primal attack
The primal attack consists of constructing a unique-SVP
instance from the LWE problem and solving it using
BKZ. We examine how large the block dimension b is
required to be for BKZ to ﬁnd the unique solution. Given
the matrix LWE instance (A,b = As + e) one builds the
lattice Λ = {x ∈ Zm+n+1 : (A|−Im|−b)x = 0 mod q} of
dimension d = m + n + 1, volume qm, and with a unique-
SVP solution v = (s,e,1) of norm λ ≈ ς√n + m. Note

that the number of used samples m may be chosen be-
tween 0 and 2n in our case and we numerically optimize
this choice.

Success condition. We model the behavior of BKZ us-
ing the geometric series assumption (which is known
to be optimistic from the attacker’s point of view), that
ﬁnds a basis whose Gram-Schmidt norms are given
i (cid:24) = δ d−2i−1 · Vol(Λ)1/d where δ = ((πb)1/b ·
by (cid:24)b(cid:30)
b/2πe)1/2(b−1) [3, 25]. The unique short vector v will
be detected if the projection of v onto the vector space
spanned by the last b Gram-Schmidt vectors is shorter
Its projected norm is expected to be ς√b,
than b(cid:30)
that is the attack is successful if and only if

d−b.

ς√b ≤ δ 2b−d−1 · qm/d.

(1)

6.4 Dual attack
The dual attack consists of ﬁnding a short vector in the
dual lattice w∈ Λ(cid:21) ={(x,y)∈ Zm×Zn : Atx = y mod q}.
Assume we have found a vector (x,y) of length (cid:27) and
compute z = vt ·b = vtAs +vte = wts +vte mod q which
is distributed as a Gaussian of standard deviation (cid:27)ς if
(A,b) is indeed an LWE sample (otherwise it is uniform
mod q). Those two distributions have maximal vari-
ation distance bounded by6 ε = 4exp(−2π2τ2) where
τ = (cid:27)ς /q, that is, given such a vector of length (cid:27) one
has an advantage ε against decision-LWE.

The length (cid:27) of a vector given by the BKZ algorithm is
given by (cid:27) = (cid:24)b0(cid:24). Knowing that Λ(cid:21) has dimension d =
m + n and volume qn we get (cid:27) = δ d−1qn/d. Therefore,
obtaining an ε-distinguisher requires running BKZ with
block dimension b where

− 2π2τ2 ≥ ln(ε/4).

(2)

Note that small advantages ε are not relevant since the
agreed key is hashed: an attacker needs an advantage of
at least 1/2 to signiﬁcantly decrease the search space of
the agreed key. He must therefore amplify his success

6A preliminary version of this paper contained a bogus formula for
ε leading to under-estimating the cost of the dual attack. Correcting
this formula leads to better security claim, and almost similar cost for
the primal and dual attacks.

86
86

78
78

Known

Best

m

b

Known
Attack
Classical Quantum Plausible
BCNS proposal [20]: q = 232 − 1, n = 1024, ς = 3.192
Primal 1062 296
Dual
1055 296
NTRUENCRYPT [49]: q = 212, n = 743, ς ≈(cid:31)2/3
Primal
159
Dual
159
JARJAR: q = 12289, n = 512, ς = √12
119
Primal
Dual
118
NEWHOPE: q = 12289, n = 1024, ς = √8
Primal 1100 967
Dual
1099 962

623
602

256
255

131
131

282
281

603
600

449
448

613
635

176
175

61
61

125
124

93
92

200
199

Table 1: Core hardness of NEWHOPE and JARJAR and se-
lected other proposals from the literature. The value b denotes
the block dimension of BKZ, and m the number of used sam-
ples. Cost is given in log2 and is the smallest cost for all pos-
sible choices of m and b. Note that our estimation is very op-
timistic about the abilities of the attacker so that our result for
the parameter set from [20] does not indicate that it can be bro-
ken with ≈ 280 bit operations, given today’s state-of-the-art in
cryptanalysis.

probability by building about 1/ε2 many such short vec-
tors. Because the sieve algorithms provide 20.2075b vec-
tors, the attack must be repeated at least R times where

R = max(1,1/(20.2075bε2)).

This makes the conservative assumption that all the vec-
tors provided by the Sieve algorithm are as short as the
shortest one.

6.5 Security claims
According to our analysis, we claim that our proposed
parameters offer at least (and quite likely with a large
margin) a post-quantum security of 128 bits. The cost
of the primal attack and dual attacks (estimated by our
script scripts/PQsecurity.py) are given in Table 1.
For comparison we also give a lower bound on the secu-
rity of [20] and do notice a signiﬁcantly improved se-
curity in our proposal. Yet, because of the numerous
pessimistic assumption made in our analysis, we do not
claim any quantum attacks reaching those bounds.

Most other RLWE proposals achieve considerably
lower security than NEWHOPE; for example, the highest-
security parameter set used for RLWE encryption in [42]
is very similar to the parameters of JARJAR. The situ-
ation is different for NTRUENCRYPT, which has been
instantiated with parameters that achieve about 128 bits
of security according to our analysis7.

7For comparison we view the NTRU key-recovery as an homoge-

USENIX Association  

25th USENIX Security Symposium  335

9

Speciﬁcally, we refer to NTRUENCRYPT with n =
743 as suggested in [49]. A possible advantage of
NTRUENCRYPT compared to NEWHOPE is somewhat
smaller message sizes, however, this advantage becomes
very small when scaling parameters to achieve a sim-
ilar security margin as NEWHOPE. The large down-
side of using NTRUENCRYPT for ephemeral key ex-
change is the cost for key generation. The implemen-
tation of NTRUENCRYPT with n = 743 in eBACS [17]
takes about an order of magnitude longer for key gener-
ation alone than NEWHOPE takes in total. Also, unlike
our NEWHOPE software, this NTRUENCRYPT software
is not protected against timing attacks; adding such pro-
tection would presumably incur a signiﬁcant overhead.

7

Implementation

In this section we provide details on the encodings of
messages and describe our portable reference implemen-
tation written in C, as well as an optimized implementa-
tion targeting architectures with AVX vector instructions.

7.1 Encodings and generation of a
The key-exchange protocol described in Protocol 1 and
also our protocol as described in Protocol 2 exchange
messages that contain mathematical objects (in particu-
lar, polynomials in Rq). Implementations of these proto-
cols need to exchange messages in terms of byte arrays.
As we will describe in the following, the choice of en-
codings of polynomials to byte arrays has a serious im-
pact on performance. We use an encoding of messages
that is particularly well-suited for implementations that
make use of quasi-linear NTT-based polynomial multi-
plication.
Deﬁnition of NTT and NTT−1. The NTT is a tool
commonly used in implementations of ideal lattice-based
cryptography [29, 42, 63, 79]. For some background
on the NTT and the description of fast software im-
plementations we refer to [46, 68].
In general, fast
quasi-logarithmic algorithms exist for the computation
of the NTT and a polynomial multiplication can be per-
formed by computing c = NTT−1(NTT(a) ◦ NTT(b))
for a,b,c ∈ R. An NTT targeting ideal lattices deﬁned
in Rq = Zq[X]/(X n + 1) can be implemented very efﬁ-
ciently if n is a power of two and q is a prime for which
it holds that q ≡ 1 mod 2n. This way a primitive n-th
root of unity ω and its square root γ exist. By multiply-
ing coefﬁcient-wise by powers of γ = √ω mod q before
neous Ring-LWE instance. We do not take into account the combinato-
rial vulnerabilities [51] induced by the fact that secrets are ternary. We
note that NTRU is a potentially a weaker problem than Ring-LWE: it
is in principle subject to a subﬁeld-lattice attack [2], but the parameters
proposed for NTRUENCRYPT are immune.

the NTT computation and after the reverse transforma-
tion by powers of γ−1, no zero padding is required and
an n-point NTT can be used to transform a polynomial
with n coefﬁcients.

For a polynomial g = ∑1023

i=0 giX i ∈ Rq we deﬁne

NTT(g) = ˆg =

ˆgi =

1023

∑

j=0

1023

∑

i=0

ˆgiX i, with

γ jg jωi j,

where we ﬁx the n-th primitive root of unity to ω = 49
and thus γ = √ω = 7. Note that in our implementation
we use an in-place NTT algorithm which requires bit-
reversal operations. As an optimization, our implemen-
tations skips these bit-reversals for the forward transfor-
mation as all inputs are only random noise. This opti-
mization is transparent to the protocol and for simplicity
omitted in the description here.

The function NTT−1 is the inverse of the function
NTT. The computation of NTT−1 is essentially the
same as the computation of NTT, except that it uses ω−1
mod q = 1254, multiplies by powers of γ−1 mod q =
8778 after the summation, and also multiplies each coef-
ﬁcient by the scalar n−1 mod q = 12277 so that

NTT−1(ˆg) =g =

1023

∑

i=0

giX i, with

gi = n−1γ−i

1023

∑

j=0

ˆg jω−i j.

The inputs to NTT−1 are not just random noise, so in-
side NTT−1 our software has to perform the initial bit
reversal, making NTT−1 slightly more costly than NTT.
Deﬁnition of Parse. The public parameter a is generated
from a 256-bit seed through the extendable-output func-
tion SHAKE-128 [72, Sec. 6.2]. The output of SHAKE-
128 is considered as an array of 16-bit, unsigned, little-
endian integers. Each of those integers is used as a coef-
ﬁcient of a if it is smaller than 5q and rejected otherwise.
The ﬁrst such 16-bit integer is used as the coefﬁcient of
X 0, the next one as coefﬁcient of X 1 and so on. Earlier
versions of this paper described a slightly different way
of rejection sampling for coefﬁcients of a. The more ef-
ﬁcient approach adopted in this ﬁnal version was sug-
gested independently by Gueron and Schlieker in [45]
and by Yawning Angel in [5]. However, note that a re-
duction modulo q of the coefﬁcients of a as described
in [45] and [5] is not necessary; both our implementa-
tions can handle coefﬁcients of a in {0, . . . ,5q − 1}.
Due to a small probability of rejections, the amount of
output required from SHAKE-128 depends on the seed –

336  25th USENIX Security Symposium 

USENIX Association

10

what is required is n = 1024 coefﬁcients that are smaller
than 5q. The minimal amount of output is thus 2 KB; the
average amount is ≈ 2184.5 bytes. The resulting poly-
nomial a (denoted as ˆa) is considered to be in NTT do-
main. This is possible because the NTT transforms uni-
form noise to uniform noise.

Using a variable amount of output from SHAKE-128
leaks information about a through timing information.
This is not a problem for most applications, since a is
public. As pointed out by Burdges in [22], such a tim-
ing leak of public information can be a problem when
deploying NEWHOPE in anonymity networks like Tor.
Appendix F in the full version of this paper describes
an alternative approach for Parse, which is slightly more
complex and slightly slower, but does not leak any timing
information about a.

The message format of (b,seed) and (u,r). With the
deﬁnition of the NTT, we can now deﬁne the format
of the exchanged messages. In both (b,seed) and (u,r)
the polynomial is transmitted in the NTT domain (as in
works like [79,81]). Polynomials are encoded as an array
of 1792 bytes, in a compressed little-endian format. The
encoding of seed is straight-forward as an array of 32
bytes, which is simply concatenated with the encoding
of b. Also the encoding of r is fairly straight-forward:
it packs four 2-bit coefﬁcients into one byte for a to-
tal of 256 bytes, which are again simply concatenated
with the encoding of u. We denote these encodings to
byte arrays as encodeA and encodeB and their inverses
as decodeA and decodeB. For a description of our key-
exchange protocol including encodings and with explicit
NTT and NTT−1 transformations, see Protocol 3.

7.2 Portable C implementation
This paper is accompanied by a C reference implemen-
tation described in this section and an optimized imple-
mentation for Intel and AMD CPUs described in the next
section. The main emphasis in the C reference imple-
mentation is on simplicity and portability.
It does not
use any ﬂoating-point arithmetic and outside the Kec-
cak (SHA3-256 and SHAKE-128) implementation only
needs 16-bit and 32-bit integer arithmetic. In particular,
the error-recovery mechanism described in Section 5 is
implemented with ﬁxed-point (i.e., integer-) arithmetic.
Furthermore, the C reference implementation does not
make use of the division operator (/) and the modulo op-
erator (%). The focus on simplicity and portability does
not mean that the implementation is not optimized at all.
On the contrary, we use it to illustrate various optimiza-
tion techniques that are helpful to speed up the key ex-
change and are also of independent interest for imple-
menters of other ideal-lattice-based schemes.

NTT optimizations. All polynomial coefﬁcients are
represented as unsigned 16-bit integers. Our in-place
NTT implementation transforms from bit-reversed to
natural order using Gentleman-Sande butterﬂy oper-
ations [27, 37]. One would usually expect that each
NTT is preceded by a bit-reversal, but all inputs to
NTT are noise polynomials that we can simply consider
as being already bit-reversed; as explained earlier, the
NTT−1 operation still involves a bit-reversal. The core
of the NTT and NTT−1 operation consists of 10 layers
of transformations, each consisting of 512 butterﬂy
operations of the form described in Listing 2.

Montgomery arithmetic and lazy reductions. The per-
formance of operations on polynomials is largely deter-
mined by the performance of NTT and NTT−1. The
main computational bottleneck of those operations are
5120 butterﬂy operations, each consisting of one addi-
tion, one subtraction and one multiplication by a precom-
puted constant. Those operations are in Zq; recall that q
is a 14-bit prime. To speed up the modular-arithmetic
operations, we store all precomputed constants in Mont-
gomery representation [71] with R = 218, i.e., instead
of storing ωi, we store 218ωi (mod q). After a multi-
plication of a coefﬁcient g by some constant 218ωi, we
can then reduce the result r to gωi (mod q) with the fast
Montgomery reduction approach. In fact, we do not al-
ways fully reduce modulo q, it is sufﬁcient if the result of
the reduction has at most 14 bits. The fast Montgomery
reduction routine given in Listing 1a computes such a re-
duction to a 14-bit integer for any unsigned 32-bit integer
in {0, . . . ,2 32 − q(R− 1)− 1}. Note that the speciﬁc im-
plementation does not work for any 32-bit integer; for
example, for the input 232 − q(R− 1) =1073491969 the
addition a=a+u causes an overﬂow and the function re-
turns 0 instead of the correct result 4095. In the following
we establish that this is not a problem for our software.
Aside from reductions after multiplication, we also
need modular reductions after addition. For this task
we use the “short Barrett reduction” [9] detailed in List-
ing 1b. Again, this routine does not fully reduce modulo
q, but reduces any 16-bit unsigned integer to an integer
of at most 14 bits which is congruent modulo q.

In the context of the NTT and NTT−1, we make sure
that inputs have coefﬁcients of at most 14 bits. This al-
lows us to avoid Barrett reductions after addition on ev-
ery second level, because coefﬁcients grow by at most
one bit per level and the short Barrett reduction can
handle 16-bit inputs. Let us turn our focus to the in-
put of the Montgomery reduction (see Listing 2). Be-
fore subtracting a[j+d] from t we need to add a mul-
tiple of q to avoid unsigned underﬂow. Coefﬁcients
never grow larger than 15 bits and 3· q = 36867 > 215,
so adding 3 · q is sufﬁcient. An upper bound on the

USENIX Association  

25th USENIX Security Symposium  337

11

Parameters: q = 12289 < 214, n = 1024
Error distribution: ψn
16
Alice (server)
seed $← {0, . . . ,255} 32
ˆa←Parse(SHAKE-128(seed))
s,e $← ψn
ˆs←NTT(s)
ˆb←ˆa◦ ˆs + NTT(e)

16

ma=encodeA(seed,ˆb)
−−−−−−−−−−−−→

1824 Bytes

mb=encodeB(ˆu,r)
←−−−−−−−−−−

2048 Bytes

(ˆu,r)←decodeB(mb)
v(cid:28)←NTT−1(ˆu◦ ˆs)
ν←Rec(v(cid:28),r)
µ←SHA3-256(ν)

Bob (client)

s(cid:28),e(cid:28),e(cid:28)(cid:28)

$← ψn

16

(ˆb,seed)←decodeA(ma)
ˆa←Parse(SHAKE-128(seed))
ˆt←NTT(s(cid:28))
ˆu←ˆa◦ ˆt + NTT(e(cid:28))
v←NTT−1(ˆb◦ ˆt) +e (cid:28)(cid:28)
r $← HelpRec(v)
ν←Rec(v,r)
µ←SHA3-256(ν)

Protocol 3: Our proposed protocol including NTT and NTT−1 computations and sizes of exchanged messages; ◦
denotes pointwise multiplication; elements in NTT domain are denoted with a hat (ˆ)

expression ((uint32_t)t + 3*12289 - a[j+d]) is
obtained if t is 215 − 1 and a[j+d] is zero; we
thus obtain 215 + 3 · q = 69634. All precomputed
constants are in {0, . . . ,q − 1},
so the expression
(W * ((uint32_t)t + 3*12289 - a[j+d]), the in-
put to the Montgomery reduction, is at most 69634· (q−
1) = 855662592 and thus safely below the maximum in-
put that the Montgomery reduction can handle.

Listing 2 The Gentleman-Sande butterﬂy inside odd lev-
els of our NTT computation. All a[j] and W are of type
uint16_t.

W = omega[jTwiddle++];
t = a[j];
a[j] = bred(t + a[j+d]);
a[j+d] = mred(W * ((uint32_t)t + 3*12289 - a[j+d]));

Listing 1 Reduction routines used in the reference im-
plementation.
(a) Montgomery reduction (R = 218).
uint16_t mred(uint32_t a) {

uint32_t u;
u = (a * 12287);
u &= ((1 << 18) - 1);
a += u * 12289;
return a >> 18;

}
(b) Short Barrett reduction.
uint16_t bred(uint16_t a) {

uint32_t u;
u = ((uint32_t) a * 5) >> 16;
a -= u * 12289;
return a;

}

cak permutation and slightly modiﬁed code taken from
the “TweetFIPS202” implementation [18] for everything
else.

The sampling of centered binomial noise polynomi-
als is based on a fast PRG with a random seed from
/dev/urandom followed by a quick summation of 16-
bit chunks of the PRG output. Note that the choice of
the PRG is a purely local choice that every user can
pick independently based on the target hardware archi-
tecture and based on routines that are available anyway
(for example, for symmetric encryption following the
key exchange). Our C reference implementation uses
ChaCha20 [12], which is fast, trivially protected against
timing attacks, and is already in use by many TLS clients
and servers [57, 58].

Fast random sampling. As a ﬁrst step before perform-
ing any operations on polynomials, both Alice and Bob
need to expand the seed to the polynomial a using
SHAKE-128. The implementation we use is based on
the “simple” implementation by Van Keer for the Kec-

7.3 Optimized AVX2 implementation
Intel processors since the “Sandy Bridge” generation
support Advanced Vector Extensions (AVX) that oper-
ate on vectors of 8 single-precision or 4 double-precision

338  25th USENIX Security Symposium 

USENIX Association

12

ﬂoating-point values in parallel. With the introduction
of the “Haswell” generation of CPUs, this support was
extended also to 256-bit vectors of integers of various
sizes (AVX2). It is not surprising that the enormous com-
putational power of these vector instructions has been
used before to implement very high-speed crypto (see,
for example, [14, 16, 43]) and also our optimized refer-
ence implementation targeting Intel Haswell processors
uses those instructions to speed up multiple components
of the key exchange.
NTT optimizations. The AVX instruction set has been
used before to speed up the computation of lattice-based
cryptography, and in particular the number-theoretic
transform. Most notably, Güneysu, Oder, Pöppelmann
and Schwabe achieve a performance of only 4480 cycles
for a dimension-512 NTT on Intel Sandy Bridge [46].
For arithmetic modulo a 23-bit prime, they represent co-
efﬁcients as double-precision integers.

We experimented with multiple different approaches
to speed up the NTT in AVX. For example, we vector-
ized the Montgomery arithmetic approach of our C ref-
erence implementation and also adapted it to a 32-bit-
signed-integer approach.
In the end it turned out that
ﬂoating-point arithmetic beats all of those more sophisti-
cated approaches, so we are now using an approach that
is very similar to the approach in [46]. One computation
of a dimension-1024 NTT takes 8448 cycles, unlike the
numbers in [46] this does include multiplication by the
powers of γ and unlike the numbers in [46], this excludes
a bit-reversal.
Fast sampling. Intel Haswell processors support the
AES-NI instruction set and for the local choice of noise
sampling it is obvious to use those. More speciﬁcally,
we use the public-domain implementation of AES-256 in
counter mode written by Dolbeau, which is included in
the SUPERCOP benchmarking framework [17]. Trans-
formation from uniform noise to the centered binomial
is optimized in AVX2 vector instructions operating on
vectors of bytes and 16-bit integers.

For the computation of SHAKE-128 we use the same
code as in the C reference implementation. One might
expect that architecture-speciﬁc optimizations (for exam-
ple, using AVX instructions) are able to offer signiﬁcant
speedups, but the benchmarks of the eBACS project [17]
indicate that on Intel Haswell, the fastest implementation
is the “simple” implementation by Van Keer that our C
reference implementation is based on. The reasons that
vector instructions are not very helpful for speeding up
SHAKE (or, more generally, Keccak) are the inherently
sequential nature and the 5 × 5 dimension of the state
matrix that makes internal vectorization hard.
Error recovery. The 32-bit integer arithmetic used by
the C reference implementation for HelpRec and Rec

is trivially 8-way parallelized with AVX2 instructions.
With this vectorization, the cost for HelpRec is only 3404
cycles, the cost for Rec is only 2804 cycles.

8 Benchmarks and comparison

In the following we present benchmark results of our
software. All benchmark results reported in Table 2 were
obtained on an Intel Core i7-4770K (Haswell) running
at 3491.953 MHz with Turbo Boost and Hyperthreading
disabled. We compiled our C reference implementation
with gcc-4.9.2 and ﬂags -O3 -fomit-frame-pointer
-march=corei7-avx -msse2avx. We compiled our
optimized AVX implementation with clang-3.5 and ﬂags
-O3 -fomit-frame-pointer -march=native.

As described in Section 7, the sampling of a is not
running in constant time; we report the median run-
ning time and (in parentheses) the average running time
for this generation, the server-side key-pair generation
and client-side shared-key computation; both over 1000
runs. For all other routines we report the median of
1000 runs. We built the software from [20] on the
same machine as ours and—like the authors of [20]—
used openssl speed for benchmarking their software
and converted the reported results to approximate cycle
counts as given in Table 2.

Comparison with BCNS and RSA/ECDH. As previ-
ously mentioned, the BCNS implementation [20] also
uses the dimension n = 1024 but the larger modulus
q = 232 − 1 and the Gaussian error distribution with
Gaussian parameter σ = 8/√2π = 3.192. When the au-
thors of BCNS integrated their implementation into SSL
it only incurred a slowdown by a factor of 1.27 compared
to ECDH when using ECDSA signatures and a factor of
1.08 when using RSA signatures with respect to the num-
ber of connections that could be handled by the server.
As a reference, the reported cycle counts in [20] for a
nistp256 ECDH on the client side are 2 160 000 cycles
(0.8 ms @2.77 GHz) and on the server side 3 221 288
cycles (1.4 ms @2.33 GHz). These numbers are obvi-
ously not state of the art for ECDH software. Even on
the nistp256 curve, which is known to be a far-from-
optimal choice, it is possible to achieve cycle counts of
less than 300000 cycles for a variable-basepoint scalar
multiplication on an Intel Haswell [44]. Also OpenSSL
optionally includes fast software for nistp256 ECDH
by Käsper and Langley and we assume that the authors
of [20] omitted enabling it. Compared to BCNS, our
C implementation is more than 8 times faster and our
AVX implementation even achieves a speedup factor of
more than 27. At this performance it is in the same ball-
park as state-of-the-art ECDH software, even when TLS
switches to faster 128-bit secure ECDH key exchange

USENIX Association  

25th USENIX Security Symposium  339

13

Table 2: Intel Haswell cycle counts of our proposal as compared to the BCNS proposal from [20].

Generation of a

NTT
NTT−1
Sampling of a noise polynomial
HelpRec
Rec
Key generation (server)

Key gen + shared key (client)

BCNS [20] Ours (C ref) Ours (AVX2)
37470a
(36863)a
8448
9464b
5900c
3404
2804
88920
(89079)
110986
(111169)
19422

43440a
(43607)a
55360
59864b
32684c
14608
10092
258246
(258965)
384994
(385146)
86280

≈ 2477958
≈ 3995977
≈ 481937

Shared key (server)
a Includes reading a seed from /dev/urandom
b Includes one bit reversal
c Excludes reading a seed from /dev/urandom, which is shared across multiple calls to the noise generation

based on Curve25519 [11], as recently speciﬁed in RFC
7748 [59].

In comparison to the BCNS proposal we see a large
performance advantage from switching to the binomial
error distribution. The BCNS software uses a large pre-
computed table to sample from a discrete Gaussian dis-
tribution with a high precision. This approach takes
1042700 cycles to samples one polynomial in constant
time. Our C implementation requires only 32684 cy-
cles to sample from the binomial distribution. Another
factor is that we use the NTT in combination with a
smaller modulus. Polynomial multiplication in [20] is
using Nussbaumer’s symbolic approach based on re-
cursive negacyclic convolutions [76]. The implemen-
tation in [20] only achieves a performance of 342800
cycles for a constant-time multiplication. Additionally,
the authors of [20] did not perform pre-transformation
of constants (e.g., a) or transmission of coefﬁcients in
FFT/Nussbaumer representation.

Follow-Up Work. We would like to refer the reader to
follow-up work in which improvements to NEWHOPE
and its implementation were proposed based on a
preprint version of this work [4].
In [45] Gueron and
Schlieker introduce faster pseudorandom bytes gener-
ation by changing the underlying functions, a method
to decrease the rejection rate during sampling (see Sec-
tion 7.1), and a vectorization of the sampling step. Longa
and Naehrig [64] optimize the NTT and present new
modular reduction techniques and are able to achieve a
speedup of factor-1.90 for the C implementation and a
factor-1.25 for the AVX implementation compared to the
preprint [4] (note that this version has updated numbers).

An alternative NTRU-based proposal and implementa-
tion of a lattice-based public-key encryption scheme,
which could also be used for key exchange, is given by
Bernstein, Chuengsatiansup, Lange, and van Vredendaal
in [15], but we leave a detailed comparison to future
work. An efﬁcient authenticated lattice-based key ex-
change scheme has recently been proposed by del Pino,
Lyubashevsky, and Pointcheval in [30].

References
[1] ADRIAN, D., BHARGAVAN, K., DURUMERIC, Z., GAUDRY,
P., GREEN, M., HALDERMAN,
J. A., HENINGER, N.,
SPRINGALL, D., THOMÉ, E., VALENTA, L., VANDERSLOOT,
B., WUSTROW, E., BÉGUELIN, S. Z., AND ZIMMERMANN, P.
Imperfect forward secrecy: How Difﬁe-Hellman fails in practice.
In CCS ’15 Proceedings of the 22nd ACM SIGSAC Conference on
Computer and Communications Security (2015), ACM, pp. 5–17.
https://weakdh.org/. 4, 5

[2] ALBRECHT, M., BAI, S., AND DUCAS, L. A subﬁeld lattice
attack on overstretched NTRU assumptions.
IACR Cryptology
ePrint Archive report 2016/127, 2016. http://eprint.iacr.
org/2016/127. 8, 10

[3] ALBRECHT, M. R., PLAYER, R., AND SCOTT, S. On the con-
crete hardness of learning with errors. IACR Cryptology ePrint
Archive report 2015/046, 2015. http://eprint.iacr.org/
2015/046/. 8, 9

[4] ALKIM, E., DUCAS, L., PÖPPELMANN, T., AND SCHWABE,
P. Post-quantum key exchange - a new hope.
IACR Cryptol-
ogy ePrint Archive report 2015/1092, 2015. https://eprint.
iacr.org/2015/1092/20160329:201913. 14

[5] ANGEL, Y.

Post-quantum secure hybrid handshake based
Posting to the tor-dev mailing list, 2016.

on NewHope.
https://lists.torproject.org/pipermail/tor-dev/
2016-May/010896.html. 10

[6] ARORA, S., AND GE, R. New algorithms for learning in
presence of errors. In Automata, Languages and Programming

14

340  25th USENIX Security Symposium 

USENIX Association

(2011), L. Aceto, M. Henzingeri, and J. Sgall, Eds., vol. 6755 of
LNCS, Springer, pp. 403–415. https://www.cs.duke.edu/
~rongge/LPSN.pdf. 8

[7] BABAI, L.

On Lovász’ lattice reduction and the nearest
Combinatorica 6, 1 (1986), 1–13.

lattice point problem.
http://www.csie.nuk.edu.tw/~cychen/Lattices/
On%20lovasz%20lattice%20reduction%20and%20the%
20nearest%20lattice%20point%20problem.pdf. 5

[8] BAI, S., AND GALBRAITH, S. D. An improved compression
technique for signatures based on learning with errors. In Topics
in Cryptology – CT-RSA 2014 (2014), J. Benaloh, Ed., vol. 8366
of LNCS, Springer, pp. 28–47. https://eprint.iacr.org/
2013/838/. 1

[9] BARRETT, P. Implementing the Rivest Shamir and Adleman pub-
lic key encryption algorithm on a standard digital signal proces-
sor.
In Advances in Cryptology – CRYPTO ’86 (1987), A. M.
Odlyzko, Ed., vol. 263 of Lecture Notes in Computer Science,
Springer-Verlag Berlin Heidelberg, pp. 311–323. 11

[10] BECKER, A., DUCAS, L., GAMA, N., AND LAARHOVEN, T.
New directions in nearest neighbor searching with applications to
lattice sieving. In SODA ’16 Proceedings of the twenty-seventh
annual ACM-SIAM symposium on Discrete Algorithms (2016 (to
appear)), SIAM. 8

[11] BERNSTEIN, D. J. Curve25519: new Difﬁe-Hellman speed
In Public Key Cryptography – PKC 2006 (2006),
records.
M. Yung, Y. Dodis, A. Kiayias, and T. Malkin, Eds., vol. 3958
of LNCS, Springer, pp. 207–228. http://cr.yp.to/papers.
html#curve25519. 14

[12] BERNSTEIN, D. J. ChaCha, a variant of Salsa20. In Workshop
Record of SASC 2008: The State of the Art of Stream Ciphers
(2008). http://cr.yp.to/papers.html#chacha. 12

[13] BERNSTEIN, D. J., CHOU, T., CHUENGSATIANSUP, C., HÜLS-
ING, A., LANGE, T., NIEDERHAGEN, R., AND VAN VREDEN-
DAAL, C. How to manipulate curve standards: a white paper for
the black hat. IACR Cryptology ePrint Archive report 2014/571,
2014. http://eprint.iacr.org/2014/571/. 4

[14] BERNSTEIN, D. J., CHUENGSATIANSUP, C., LANGE, T., AND
SCHWABE, P. Kummer strikes back: new DH speed records. In
Advances in Cryptology – EUROCRYPT 2015 (2014), T. Iwata
and P. Sarkar, Eds., vol. 8873 of LNCS, Springer, pp. 317–337.
full version: http://cryptojedi.org/papers/#kummer. 13
[15] BERNSTEIN, D. J., CHUENGSATIANSUP, C., LANGE, T., AND
VAN VREDENDAAL, C. NTRU Prime. IACR Cryptology ePrint
Archive report 2016/461, 2016. https://eprint.iacr.org/
2016/461. 14

[16] BERNSTEIN, D. J., HOPWOOD, D., HÜLSING, A., LANGE, T.,
NIEDERHAGEN, R., PAPACHRISTODOULOU, L., SCHNEIDER,
M., SCHWABE, P., AND WILCOX-O’HEARN, Z. SPHINCS:
practical stateless hash-based signatures. In Advances in Cryp-
tology – EUROCRYPT 2015 (2015), E. Oswald and M. Fis-
chlin, Eds., vol. 9056 of LNCS, Springer, pp. 368–397. https:
//cryptojedi.org/papers/#sphincs. 3, 13

[17] BERNSTEIN, D. J., AND LANGE, T. eBACS: ECRYPT bench-
marking of cryptographic systems. http://bench.cr.yp.to
(accessed 2015-10-07). 10, 13

[18] BERNSTEIN, D. J., SCHWABE, P., AND ASSCHE, G. V.
Tweetable FIPS 202, 2015. http://keccak).noekeon.org/
tweetfips202.html (accessed 2016-03-21). 12

[19] BERTONI, G., DAEMEN, J., PEETERS, M., AND ASSCHE,
G. V. Keccak. In Advances in Cryptology – EUROCRYPT 2013
(2013), T. Johansson and P. Q. Nguyen, Eds., vol. 7881 of LNCS,
Springer, pp. 313–314. 5

[20] BOS, J. W., COSTELLO, C., NAEHRIG, M., AND STEBILA, D.
Post-quantum key exchange for the TLS protocol from the ring
learning with errors problem. In 2015 IEEE Symposium on Secu-
rity and Privacy (2015), pp. 553–570. http://eprint.iacr.
org/2014/599. 1, 2, 3, 4, 5, 6, 7, 8, 9, 13, 14

[21] BRAKERSKI, Z., LANGLOIS, A., PEIKERT, C., REGEV, O.,
AND STEHLÉ, D. Classical hardness of learning with errors. In
Proceedings of the forty-ﬁfth annual ACM symposium on Theory
of computing (2013), ACM, pp. 575–584. http://arxiv.org/
pdf/1306.0281. 6

[22] BURDGES,

J.

Post-quantum secure hybrid handshake
based on NewHope.
Posting to the tor-dev mailing
list, 2016. https://lists.torproject.org/pipermail/
tor-dev/2016-May/010886.html. 11

[23] CADÉ, D., PUJOL, X., AND STEHLÉ, D.

fplll 4.0.4, 2013.
https://github.com/dstehle/fplll (accessed 2015-10-
13). 8

[24] CHECKOWAY, S., FREDRIKSON, M., NIEDERHAGEN, R., EV-
ERSPAUGH, A., GREEN, M., LANGE, T., RISTENPART, T.,
BERNSTEIN, D. J., MASKIEWICZ, J., AND SHACHAM, H. On
the practical exploitability of Dual EC in TLS implementations.
In Proceedings of the 23rd USENIX security symposium (2014).
https://projectbullrun.org/dual-ec/index.html. 4

[25] CHEN, Y.

Lattice reduction and concrete security of fully
homomorphic encryption.
l’Université Paris
Diderot, 2013. Available at http://www.di.ens.fr/~ychen/
research/these.pdf. 8, 9

PhD thesis,

[26] CHEN, Y., AND NGUYEN, P. Q. BKZ 2.0: Better lattice
security estimates.
In Advances in Cryptology – ASIACRYPT
2011, D. H. Lee and X. Wang, Eds., vol. 7073 of LNCS.
Springer, 2011, pp. 1–20. http://www.iacr.org/archive/
asiacrypt2011/70730001/70730001.pdf. 8

[27] CHU, E., AND GEORGE, A. Inside the FFT Black Box Serial and
Parallel Fast Fourier Transform Algorithms. CRC Press, Boca
Raton, FL, USA, 2000. 11

[28] COWIE, J., DODSON, B., ELKENBRACHT-HUIZING, R. M.,
LENSTRA, A. K., MONTGOMERY, P. L., AND ZAYER, J. A
world wide number ﬁeld sieve factoring record: on to 512 bits.
In Advances in Cryptology – ASIACRYPT’96 (1996), K. Kim and
T. Matsumoto, Eds., vol. 1163 of LNCS, Springer, pp. 382–394.
http://oai.cwi.nl/oai/asset/1940/1940A.pdf. 8

[29] DE CLERCQ, R., ROY, S. S., VERCAUTEREN, F., AND VER-
BAUWHEDE, I. Efﬁcient software implementation of ring-LWE
encryption. In Design, Automation & Test in Europe Conference
& Exhibition, DATE 2015 (2015), EDA Consortium, pp. 339–
344. http://eprint.iacr.org/2014/725. 1, 4, 5, 7, 10

[30] DEL PINO, R., LYUBASHEVSKY, V., AND POINTCHEVAL, D.
The whole is less than the sum of its parts: Constructing more ef-
ﬁcient lattice-based AKEs. IACR Cryptology ePrint Archive re-
port 2016/435, 2016. https://eprint.iacr.org/2016/435.
14

[31] DUCAS, L., DURMUS, A., LEPOINT, T., AND LYUBASHEVSKY,
V. Lattice signatures and bimodal Gaussians.
In Advances
in Cryptology – CRYPTO 2013 (2013), R. Canetti and J. A.
Garay, Eds., vol. 8042 of LNCS, Springer, pp. 40–56. https:
//eprint.iacr.org/2013/383/. 1, 4

[32] FLUHRER, S. Cryptanalysis of ring-LWE based key exchange
IACR Cryptology ePrint Archive report

with key share reuse.
2016/085, 2016. http://eprint.iacr.org/2016/085. 4

[33] FUJIOKA, A., SUZUKI, K., XAGAWA, K., AND YONEYAMA,
K. Practical and post-quantum authenticated key exchange from
one-way secure key encapsulation mechanism. In Symposium on
Information, Computer and Communications Security, ASIA CCS
2013 (2013), K. Chen, Q. Xie, W. Qiu, N. Li, and W. Tzeng, Eds.,
ACM, pp. 83–94. 3

USENIX Association  

25th USENIX Security Symposium  341

15

[34] GALBRAITH, S. D. Space-efﬁcient variants of cryptosystems
https://www.math.

based on learning with errors, 2013.
auckland.ac.nz/~sgal018/compact-LWE.pdf. 5

[35] GAMA, N., NGUYEN, P. Q., AND REGEV, O. Lattice enu-
meration using extreme pruning.
In Advances in Cryptology –
EUROCRYPT 2010 (2010), H. Gilbert, Ed., vol. 6110 of LNCS,
Springer, pp. 257–278.
http://www.iacr.org/archive/
eurocrypt2010/66320257/66320257.pdf. 8

[36] GARG, S., GENTRY, C., AND HALEVI, S. Candidate mul-
tilinear maps from ideal lattices.
In Advances in Cryptology
– EUROCRYPT 2013 (2013), vol. 7881, Springer, pp. 1–17.
https://eprint.iacr.org/2012/610. 8

[37] GENTLEMAN, W. M., AND SANDE, G. Fast Fourier transforms:
for fun and proﬁt.
In Fall Joint Computer Conference (1966),
vol. 29 of AFIPS Proceedings, pp. 563–578. http://cis.rit.
edu/class/simg716/FFT_Fun_Profit.pdf. 11

[38] GENTRY, C.

In STOC ’09 Proceedings of

Fully homomorphic encryption using ideal
lattices.
the forty-ﬁrst an-
nual ACM symposium on Theory of computing (2009),
ACM, pp. 169–178. https://www.cs.cmu.edu/~odonnell/
hits09/gentry-homomorphic-encryption.pdf. 1

[39] GENTRY, C., PEIKERT, C., AND VAIKUNTANATHAN, V. Trap-
doors for hard lattices and new cryptographic constructions. In
STOC ’08 Proceedings of the fortieth annual ACM symposium
on Theory of computing (2008), ACM, pp. 197–206. https:
//eprint.iacr.org/2007/432/. 6

[40] GENTRY, C., AND SZYDLO, M. Cryptanalysis of the re-
vised NTRU signature scheme.
In Advances in Cryptology –
EUROCRYPT 2002 (2002), XXX, Ed., vol. XXX of LNCS,
Springer, pp. 299–320. https://www.iacr.org/archive/
eurocrypt2002/23320295/nsssign_short3.pdf. 8

[41] GHOSH, S., AND KATE, A. Post-quantum secure onion routing
(future anonymity in today’s budget). IACR Cryptology ePrint
Archive report 2015/008, 2015. http://eprint.iacr.org/
2015/008. 3

[42] GÖTTERT, N., FELLER, T., SCHNEIDER, M., BUCHMANN,
J. A., AND HUSS, S. A. On the design of hardware building
blocks for modern lattice-based encryption schemes. In Crypto-
graphic Hardware and Embedded Systems - CHES 2012 (2012),
E. Prouff and P. Schaumont, Eds., vol. 7428 of LNCS, Springer,
pp. 512–529. http://www.iacr.org/archive/ches2012/
74280511/74280511.pdf. 7, 8, 9, 10

[43] GUERON, S. Parallelized hashing via j-lanes and j-pointers tree
modes, with applications to SHA-256. IACR Cryptology ePrint
Archive report 2014/170, 2014. https://eprint.iacr.org/
2014/170. 13

[44] GUERON, S., AND KRASNOV, V. Fast prime ﬁeld elliptic-curve
cryptography with 256-bit primes. Journal of Cryptographic En-
gineering 5, 2 (2014), 141–151. https://eprint.iacr.org/
2013/816/. 13

[45] GUERON, S., AND SCHLIEKER, F. Speeding up r-lwe post-
quantum key exchange. IACR Cryptology ePrint Archive report
2016/467, 2016. https://eprint.iacr.org/2016/467. 10,
14

Software speed records for lattice-based signatures.

[46] GÜNEYSU, T., ODER, T., PÖPPELMANN, T., AND SCHWABE,
P.
In
Post-Quantum Cryptography (2013), P. Gaborit, Ed., vol. 7932
of LNCS, Springer, pp. 67–82.
http://cryptojedi.org/
papers/#lattisigns. 10, 13

[47] HANROT, G., PUJOL, X., AND STEHLÉÉ, D. Terminating BKZ.
IACR Cryptology ePrint Archive report 2011/198, 2011. http:
//eprint.iacr.org/2011/198/. 8

[48] HOFFSTEIN, J., PIPHER, J., SCHANCK, J. M., SILVERMAN,
J. H., AND WHYTE, W. Practical signatures from the partial
Fourier recovery problem.
In Applied Cryptography and Net-
work Security (2014), I. Boureanu, P. Owesarski, and S. Vaude-
nay, Eds., vol. 8479 of LNCS, Springer, pp. 476–493. https:
//eprint.iacr.org/2013/757/. 1

[49] HOFFSTEIN, J., PIPHER, J., SCHANCK, J. M., SILVERMAN,
J. H., WHYTE, W., AND ZHANG, Z. Choosing parameters
for NTRUEncrypt.
IACR Cryptology ePrint Archive report
2015/708, 2015. http://eprint.iacr.org/2015/708. 9, 10
[50] HOFFSTEIN, J., PIPHER, J., AND SILVERMAN, J. H. NTRU:
a ring-based public key cryptosystem.
In Algorithmic num-
ber theory (1998), J. P. Buhler, Ed., vol. 1423 of LNCS,
Springer, pp. 267–288. https://www.securityinnovation.
com/uploads/Crypto/ANTS97.ps.gz. 1, 4

[51] HOWGRAVE-GRAHAM, N. A hybrid lattice-reduction and
meet-in-the-middle attack against NTRU.
In Advances in
Cryptology-CRYPTO 2007. Springer, 2007, pp. 150–169.
http://www.iacr.org/archive/crypto2007/46220150/
46220150.pdf. 10

[52] JINTAI DING, XIANG XIE, X. L. A simple provably secure
key exchange scheme based on the learning with errors prob-
lem.
IACR Cryptology ePrint Archive report 2012/688, 2012.
http://eprint.iacr.org/2012/688. 1

[53] KIRCHNER, P., AND FOUQUE, P.-A. An improved BKW al-
gorithm for LWE with applications to cryptography and lattices.
In Advances in Cryptology – CRYPTO 2015 (2015), R. Gennaro
and M. Robshaw, Eds., vol. 9215 of LNCS, Springer, pp. 43–62.
https://eprint.iacr.org/2015/552/. 8

[54] LAARHOVEN, T. Search problems in cryptography. PhD the-
sis, Eindhoven University of Technology, 2015. http://www.
thijs.com/docs/phd-final.pdf. 8

[55] LAARHOVEN, T. Sieving for shortest vectors in lattices using
angular locality-sensitive hashing.
In Advances in Cryptology
– CRYPTO 2015 (2015), R. Gennaro and M. Robshaw, Eds.,
vol. 9216 of LNCS, Springer, pp. 3–22. https://eprint.
iacr.org/2014/744/. 8

[56] LAARHOVEN, T., MOSCA, M., AND VAN DE POL,

J.
Finding shortest lattice vectors faster using quantum search.
Designs, Codes and Cryptography 77, 2 (2015), 375–400.
https://eprint.iacr.org/2014/907/. 8

[57] LANGLEY, A.

TLS symmetric crypto. Blog post on im-
perialviolet.org, 2014. https://www.imperialviolet.org/
2014/02/27/tlssymmetriccrypto.html (accessed 2015-10-
07). 12

[58] LANGLEY, A., AND CHANG, W.-T. ChaCha20 and Poly1305
based cipher suites for TLS: Internet draft. https://tools.
ietf.org/html/draft-agl-tls-chacha20poly1305-04
(accessed 2015-02-01). 12

[59] LANGLEY, A., HAMBURG, M., AND TURNER, S. RFC 7748:
Elliptic curves for security, 2016. https://www.rfc-editor.
org/rfc/rfc7748.txt. 14

[60] LENSTRA, H. W., AND SILVERBERG, A. Revisiting the gentry-
szydlo algorithm. In Advances in Cryptology – CRYPTO 2014,
J. A. Garay and R. Gennaro, Eds., vol. 8616 of LNCS. Springer,
2014, pp. 280–296. https://eprint.iacr.org/2014/430.
8

[61] LEYS,

J., GHYS, E., AND ALVAREZ, A.

Dimensions,
2010. http://www.dimensions-math.org/ (accessed 2015-
10-19). 7

[62] LINDNER, R., AND PEIKERT, C. Better key sizes (and at-
tacks) for LWE-based encryption. In Topics in Cryptology - CT-
RSA 2011 (2011), A. Kiayias, Ed., vol. 6558 of LNCS, Springer,
pp. 319–339. https://eprint.iacr.org/2010/613/. 3

16

342  25th USENIX Security Symposium 

USENIX Association

[63] LIU, Z., SEO, H., ROY, S. S., GROSSSCHÄDL, J., KIM, H.,
AND VERBAUWHEDE, I. Efﬁcient Ring-LWE encryption on 8-
bit AVR processors.
In Cryptographic Hardware and Embed-
ded Systems - CHES 2015 (2015), T. Güneysu and H. Hand-
schuh, Eds., vol. 9293 of LNCS, Springer, pp. 663–682. https:
//eprint.iacr.org/2015/410/. 4, 7, 10

[64] LONGA, P., AND NAEHRIG, M. Speeding up the number theo-
retic transform for faster ideal lattice-based cryptography. IACR
Cryptology ePrint Archive report 2016/504, 2016. https://
eprint.iacr.org/2016/504. 14

[65] LYUBASHEVSKY, V.

Lattice signatures without

trapdoors.
In Advances in Cryptology – EUROCRYPT 2012 (2012),
D. Pointcheval and T. Johansson, Eds., vol. 7237 of LNCS,
Springer, pp. 738–755. https://eprint.iacr.org/2011/
537/. 6

[66] LYUBASHEVSKY, V., PEIKERT, C., AND REGEV, O. On
ideal lattices and learning with errors over rings.
In Advances
in Cryptology – EUROCRYPT 2010 (2010), H. Gilbert, Ed.,
vol. 6110 of LNCS, Springer, pp. 1–23. http://www.di.ens.
fr/~lyubash/papers/ringLWE.pdf. 2

[67] LYUBASHEVSKY, V., PEIKERT, C., AND REGEV, O. On ideal
lattices and learning with errors over rings. Journal of the ACM
(JACM) 60, 6 (2013), 43:1–43:35. http://www.cims.nyu.
edu/~regev/papers/ideal-lwe.pdf. 1, 6

[68] MELCHOR, C. A., BARRIER, J., FOUSSE, L., AND KILLI-
JIAN, M. XPIRe: Private information retrieval for everyone.
IACR Cryptology ePrint Archive report 2014/1025, 2014. http:
//eprint.iacr.org/2014/1025. 10

[69] MICCIANCIO, D., AND VOULGARIS, P. Faster exponential
time algorithms for the shortest vector problem.
In SODA ’10
Proceedings of the twenty-ﬁrst annual ACM-SIAM symposium
on Discrete Algorithms (2010), SIAM, pp. 1468–1480. http:
//dl.acm.org/citation.cfm?id=1873720. 8

[70] MONTANARO, A. Quantum walk speedup of backtracking al-
arXiv preprint arXiv:1509.02374, 2015. http://

gorithms.
arxiv.org/pdf/1509.02374v2. 8

[71] MONTGOMERY, P. L.

Mathematics of Computation 44,

trial division.
(1985),
mcom/1985-44-170/S0025-5718-1985-0777282-X/
S0025-5718-1985-0777282-X.pdf. 11

Modular multiplication without
170
http://www.ams.org/journals/

519–521.

[78] PÖPPELMANN, T., DUCAS, L., AND GÜNEYSU, T. Enhanced
lattice-based signatures on reconﬁgurable hardware. In Crypto-
graphic Hardware and Embedded Systems – CHES 2014 (2014),
L. Batina and M. Robshaw, Eds., vol. 8731 of LNCS, Springer,
pp. 353–370. https://eprint.iacr.org/2014/254/. 4

[79] PÖPPELMANN, T., AND GÜNEYSU, T.

Towards practi-
cal lattice-based public-key encryption on reconﬁgurable hard-
ware.
In Selected Areas in Cryptography – SAC 2013 (2013),
T. Lange, K. Lauter, and P. Lisonˇek, Eds., vol. 8282 of LNCS,
Springer, pp. 68–85. https://www.ei.rub.de/media/sh/
veroeffentlichungen/2013/08/14/lwe_encrypt.pdf. 1,
6, 7, 10, 11

[80] REGEV, O. On lattices, learning with errors, random linear codes,
and cryptography. Journal of the ACM 56, 6 (2009), 34. http:
//www.cims.nyu.edu/~regev/papers/qcrypto.pdf. 5

[81] ROY, S. S., VERCAUTEREN, F., MENTENS, N., CHEN, D. D.,
AND VERBAUWHEDE, I. Compact Ring-LWE cryptoproces-
sor. In Cryptographic Hardware and Embedded Systems – CHES
2014 (2014), L. Batina and M. Robshaw, Eds., vol. 8731 of
LNCS, Springer, pp. 371–391. https://eprint.iacr.org/
2013/866/. 4, 5, 11

[82] SCHNORR, C.-P., AND EUCHNER, M.

sum problems.

Lattice basis re-
improved practical algorithms and solving sub-
Mathematical programming 66, 1-
http://www.csie.nuk.edu.tw/

duction:
set
3 (1994),
~cychen/Lattices/Lattice%20Basis%20Reduction_
%20Improved%20Practical%20Algorithms%20and%
20Solving%20Subset%20Sum%20Problems.pdf. 8

181–199.

[83] STEHLÉ, D., AND STEINFELD, R. Making NTRU as secure as
worst-case problems over ideal lattices. In Advances in Cryptol-
ogy – EUROCRYPT 2011 (2011), K. G. Paterson, Ed., vol. 6632
of LNCS, Springer, pp. 27–47.
http://www.iacr.org/
archive/eurocrypt2011/66320027/66320027.pdf. 1, 4

[84] Tor project: Anonymity online. https://www.torproject.

org/. 3

[85] ZHANG, J., ZHANG, Z., DING, J., SNOOK, M., AND DAGDE-
LEN, Ö. Authenticated key exchange from ideal lattices. In Ad-
vances in Cryptology – EUROCRYPT 2015 (2015), E. Oswald
and M. Fischlin, Eds., vol. 9057 of LNCS, Springer, pp. 719–751.
https://eprint.iacr.org/2014/589/. 3

[72] NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY.
FIPS PUB 202 – SHA-3 standard: Permutation-based hash and
extendable-output functions, 2015. http://nvlpubs.nist.
gov/nistpubs/FIPS/NIST.FIPS.202.pdf. 5, 10

[73] NATIONAL INSTITUTE OF STANDARDS AND TECHNOL-
Workshop on cybersecurity in a post-quantum
2015.
http://www.nist.gov/itl/csd/ct/

OGY.
world,
post-quantum-crypto-workshop-2015.cfm. 1

[74] NATIONAL SECURITY AGENCY.

NSA suite B cryp-
https://www.nsa.gov/ia/programs/suiteb_

tography.
cryptography/, Updated on August 19, 2015. 1

[75] NGUYEN, P. Q., AND VIDICK, T. Sieve algorithms for the short-
est vector problem are practical. Journal of Mathematical Cryp-
tology 2, 2 (2008), 181–207. ftp://ftp.di.ens.fr/pub/
users/pnguyen/JoMC08.pdf. 8

[76] NUSSBAUMER, H. J. Fast polynomial transform algorithms for
digital convolution. IEEE Transactions on Acoustics, Speech and
Signal Processing 28, 2 (1980), 205–215. 14

[77] PEIKERT, C. Lattice cryptography for the Internet.

In Post-
Quantum Cryptography (2014), M. Mosca, Ed., vol. 8772 of
LNCS, Springer, pp. 197–219. http://web.eecs.umich.edu/
~cpeikert/pubs/suite.pdf. 1, 2, 3, 4

USENIX Association  

25th USENIX Security Symposium  343

17

