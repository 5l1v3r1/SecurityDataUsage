Synthesis of Fault Attacks on Cryptographic

Implementations

Gilles Barthe

IMDEA Software Institute
gilles.barthe@imdea.org

François Dupressoir
IMDEA Software Institute

francois.dupressoir@imdea.org

Pierre-Alain Fouque
Université de Rennes 1 &

Institut Universitaire de France

pierre-alain.fouque@ens.fr

Benjamin Grégoire

Jean-Christophe Zapalowicz

benjamin.gregoire@inria.fr

jean-christophe.zapalowicz@inria.fr

Inria

Inria

ABSTRACT
Fault attacks are attacks in which an adversary with physical
access to a cryptographic device, say a smartcard, tampers
with the execution of an algorithm to retrieve secret mate-
rial. Since the seminal Bellcore attack on modular exponen-
tiation, there has been extensive work to discover new fault
attacks against cryptographic schemes and develop counter-
measures against such attacks. Originally focused on high-
level algorithmic descriptions, these eﬀorts increasingly fo-
cus on concrete implementations. While lowering the ab-
straction level leads to new fault attacks, it also makes their
discovery signiﬁcantly more challenging.
In order to face
this trend, it is therefore desirable to develop principled,
tool-supported approaches that allow a systematic analy-
sis of the security of cryptographic implementations against
fault attacks.

We propose,

implement, and evaluate a new approach
for ﬁnding fault attacks against cryptographic implementa-
tions. Our approach is based on identifying implementation-
independent mathematical properties, or fault conditions.
We choose fault conditions so that it is possible to recover
secret data purely by computing on suﬃciently many data
points that satisfy them. Fault conditions capture the essence
of a large number of attacks from the literature, including
lattice-based attacks on RSA. Moreover, they provide a ba-
sis for discovering automatically new attacks: using fault
conditions, we specify the problem of ﬁnding faulted imple-
mentations as a program synthesis problem. Using a special-
ized form of program synthesis, we discover multiple faulted
attacks on RSA and ECDSA. Several of the attacks found
by our tool are new, and of independent interest.

 
Permission to make digital or hard copies of all or part of this work for personal 
or  classroom  use  is  granted  without  fee  provided  that  copies  are  not  made  or 
distributed  for  profit  or  commercial  advantage  and  that  copies  bear this  notice 
and the full citation on the first page. Copyrights for components of this work 
owned by others than the author(s) must be honored. Abstracting with credit is 
permitted. To copy otherwise, or republish, to post on servers or to redistribute to 
lists, requires prior specific permission and/or a fee. Request permissions from 
permissions@acm.org. 
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA. 
Copyright is held by the owner/author(s). Publication rights licensed to ACM. 
ACM 978-1-4503-2957-6/14/11…$15.00. 
http://dx.doi.org/10.1145/2660267.2660304

Categories and Subject Descriptors
E.3 [Data encryption]: Public key cryptosystems; F.3.1
[Logics and Meanings of Programs]: Specifying and
Verifying and Reasoning about Programs

Keywords
Fault attacks; program veriﬁcation; program synthesis; au-
tomated proofs

1.

INTRODUCTION

Embedded devices often play a central role in security ar-
chitectures for large-scale software infrastructures. For in-
stance, they are used pervasively for authentication, identity
management, or digital signatures. As a consequence, em-
bedded devices are also a prime target for attackers. There
are primarily two means to retrieve secret material from
embedded devices. The ﬁrst one is to carry non-invasive
monitoring of the device and to obtain information from
side-channels, such as timing and power consumption, elec-
tromagnetic radiations, or even noise. The second one is to
perform active attacks, injecting faults that interfere with
the normal execution of the devices, and to recover the se-
cret information through the device’s normal interface, or
through side-channels. The eﬀects of these faults vary: they
may modify the control ﬂow of the program by skipping a
conditional test [2] or induce behaviours similar to buﬀer
overﬂows [20]. In the context of cryptographic attacks, they
often allow the adversary to directly recover secret keys.
There are various ways to inject faults in devices using, for
example, power spikes, glitches on the clock signal, temper-
ature variations, or electromagnetic radiations [2, 26, 4].

The existence of eﬃcient fault attacks against crypto-
graphic schemes was ﬁrst demonstrated in [13] by Boneh,
DeMillo and Lipton. They consider an algorithm, shown in
Figure 3, for computing RSA signatures using the Chinese
Remainder Theorem (CRT) and its standard recombination
formula:

S = (Sq · p

−1 mod q) · p + (Sp · q

−1 mod p) · q mod N

where Sp and Sq are modular exponentiations of the reduc-
tions modulo p and q of the integer M that encodes the
message m. The algorithm is popular in practice, because it
achieves a signiﬁcant speedup (approximately 4 times faster)
over the direct computation of S = M d mod N . The fault

1016second attack, due to Lenstra [25], only requires knowledge

attack Boneh et al. exhibit allows them to retrieve the fac-
torization of N , i.e. p and q, with a simple gcd computation.
This attack requires knowledge of a valid signature S and

a faulted signature (cid:98)S for the same padded message M . A
of a single faulted signature (cid:98)S for a known padded message
from the identity gcd(S −(cid:98)S, N ) = q;
N from the identity gcd(M −(cid:98)Se, N ) = q.

• in the ﬁrst case, one can recover the factorization of N
• in the second case, one can recover the factorization of

M . Injecting fault during the computation modulo p,

Both attacks, often known as the Bellcore attacks, are re-
stricted to deterministic encodings. However, Boneh et al.
describe another attack that applies to probabilistic encod-
ings; unfortunately, this third attack is not as eﬃcient as the
others. In fact, it is only very recently that Fouque, Guiller-
min, Leresteux, Tibouchi and Zapalowicz [19] propose the
ﬁrst eﬃcient fault attacks against RSA-CRT signatures with
probabilistic encodings; their attacks are applicable against
PKCS#1 v2.0 (PSS) signatures. In addition to the RSA-
CRT signature considered in [13], Fouque et al. consider
another variant of RSA-CRT (Figure 4) based on Garner’s
recombination formula:

S = Sq + q · (q

−1 · (Sp − Sq) mod p)

However, the main diﬀerence between [13] and [19] lies
in their level of description of RSA-CRT: whereas Boneh et
al. [13] consider a high-level algorithmic description in which
modular exponentiation is treated abstractly, Fouque et al.
consider reasonably detailed implementations, going down
to algorithmic descriptions of modular multiplication. They
consider four diﬀerent implementations of modular expo-
nentiation, among which the Square-and-Multiply algorithm
and Montgomery’s modular exponentiation algorithm [32].
Figure 1 shows the Coarsely Integrated Operand Scanning
(CIOS) algorithm for modular multiplication, used in Mont-
gomery’s modular exponentiation algorithm (shown in Fig-
ure 2). Fouque et al. show that, by injecting faults in the im-
plementations of Montgomery modular multiplication, one

can obtain faulted signatures (cid:98)S that are close multiples of

p or q, and then use lattice-based techniques to recover the
factorization of N with about 50 faulty signatures. This
example provides strong evidence that analyzing implemen-
tations rather than algorithmic descriptions can lead to the
discovery of interesting attacks. However, it also highlights
a number of diﬃculties with this approach:

1. the number of faulted implementations grows at least
exponentially in the length of the original program, in par-
ticular if multiple faults are considered;

2. some fault attacks require to tamper with some (but
not all) loop iterations, or to add or remove some loop itera-
tions; hence, the number of faulted implementations cannot
be bounded solely based on the length of the program;

3. analyzing the eﬀects of faults becomes very involved

and error-prone, in particular for programs with loops;

4. there exist multiple implementations of basic arith-
metic operations, requiring to repeat the analysis for each;
5. there might exist numerous countermeasures against a
fault attack, requiring to repeat the analysis for each of the
protected implementations.
This current trend towards analyzing security against fault
attacks of implementations rather than high-level algorithmic

descriptions is not speciﬁc to RSA signatures. In fact, it is
also witnessed in elliptic curve cryptography. Biehl, Meyer
and M¨uller [12] were among the ﬁrst to consider fault at-
tacks against elliptic curve cryptosystems; more speciﬁcally,
they consider an elliptic curve variant of ElGamal encryp-
tion. Their attacks exploit some of the ideas from Boneh
et al. and are cast in the setting of a high-level algorithmic
description of scalar multiplication between a ﬁeld element
and a point in the curve. These attacks were generalized to
a more concrete setting by Ciet and Joye [16]. Later, Nac-
cache, Nguyen, Tunstall and Whelan [36] exhibit fault at-
tacks on implementations of DSA and its elliptic curve vari-
ant ECDSA, whose description is given in Figure 6. Their
attack introduces a fault during the generation of the nonce
k and is cast in an algorithmic setting. In contrast, more
recent works [41, 3, 9, 31] study fault attacks against im-
plementations of ECDSA, based on detailed accounts of in-
teger multiplication, scalar multiplication, and point dou-
bling. For example, the attack on integer multiplication [3]
by Barenghi et al. works by injecting faults during the inte-
ger multiplication of a known random value and the secret
key. Then, by considering the textbook multiplication im-
plementation, they show that it is possible to recover the se-
cret key. Finally, the attack of [31] shows that it is possible to
inject a fault during the conversion from projective to aﬃne
coordinates. These two attacks show that it is beneﬁcial
to consider all steps of an implementation-level description
when looking for fault attacks. Our goal in this paper is to
search for fault attacks by considering full implementation-
level descriptions of cryptographic algorithms.

a ← 0
y0 ← y mod b
for j = 0 to k − 1 do

1: function CIOS(x, y)
2:
3:
4:
5:
6:

a0 ← a mod b
uj ← (a0 + xj · y0) · q(cid:48) mod b

a ←(cid:106) a + xj · y + uj · q

(cid:107)

b

7:
8:
9:
10:
11:
12: end function

end for
if a ≥ q then a ← a − q
end if
return a

Figure 1: The Montgomery multiplication algo-
rithm. The xi’s and yi’s are the digits of x and y
in base b; q(cid:48) = −q−1 mod b is precomputed. The re-
turned value is (xy · b−k mod q). Since b = 2r, the
division is a bit shift.

Our contributions
The thesis of this work is that it is beneﬁcial to develop
and implement rigorous methodologies for discovering fault
attacks on cryptographic implementations. To support our
thesis, we propose and validate experimentally a principled,
tool-supported approach for discovering fault attacks on cryp-
tographic implementations. Our approach relies on two broad
contributions:

1. identifying fault conditions, a novel concept that cap-
tures the essence of fault attacks in a logical, implementation
independent setting;

1017if ei = 0 then

1: function ExpLadder(x, e, q, c)
¯x ← CIOS(x, R2 mod q)
2:
A ← R mod q
3:
for i = t down to 0 do
4:
5:
¯x ← CIOS(A, ¯x)
6:
A ← CIOS(A, A)
7:
else if ei = 1 then
8:
A ← CIOS(A, ¯x)
9:
¯x ← CIOS(¯x, ¯x)
10:
11:
end for
12:
A ← CIOS(A, c)
13:
14:
return A
15: end function

end if

Figure 2: Montgomery’s Ladder for computing mod-
ular exponentiations: ExpLadder(x, e, q, c) = xe · c mod
q.
e0, . . . , et are the bits of the exponent e (from
the least to the most signiﬁcant), b is the base in
which computations are carried out (gcd(b, q) = 1)
and R = bk.

1: function SignRSA–CRT(m)
2:
3:
4:
5:
6:
7: end function

M ← µ(m) ∈ ZN
p ← ExpLadder(M mod p, dp, p, q−1 mod p)
S(cid:48)
q ← ExpLadder(M mod q, dq, q, p−1 mod q)
S(cid:48)
S ← S(cid:48)
return S

p · q mod N

q · p + S(cid:48)

(cid:46) message encoding

Figure 3: RSA–CRT signature generation. p and q
are large primes and N = pq is the modulus. The
public key is denoted by (N, e) and the associated
private key by (p, q, d). The reductions dp, dq modulo
p − 1, q − 1 of the private exponent, as well as the
p−1 mod q and q−1 mod p CRT coeﬃcients, are pre-
computed.

2. applying a form of program synthesis on concrete cryp-
tographic implementations to automatically discover faulted
implementations that realize fault conditions and lead to at-
tacks.
A third, more practical contribution is an evaluation of our
approach on implementations of RSA and ECDSA signa-
tures. During the process, we discover several faulted im-
plementations, some of which lead to new attacks of inde-
pendent interest. We elaborate on these points below.

Fault conditions. The ﬁrst contribution (Section 3) is of
methodological nature, and rests on the introduction of fault
conditions. Informally, fault conditions are implementation-
independent mathematical properties, speciﬁc to a crypto-
graphic system, which capture suﬃcient conditions under
which an attacker can launch a successful attack. Consider,
for instance, the case of RSA signatures with public RSA
modulus N = pq of length n. Any adversary with knowl-
edge of a value ˆS that is multiple of p but not multiple of q
can obtain p by performing a simple GCD computation, and
then q by division. This is captured by the fault condition

ˆS : ˆS = 0 mod p ∧ ˆS (cid:54)= 0 mod q

(cid:46) message encoding

M ← µ(m) ∈ ZN
Sp ← ExpLadder(M mod p, dp, p, 1)
Sq ← ExpLadder(M mod q, dq, q, 1)
t ← Sp − Sq
if t < 0 then t ← t + p
end if

1: function SignRSA–Garner(m)
2:
3:
4:
5:
6:
7:
8:
9:
10: end function

S ← Sq +(cid:0)(t · π) mod p(cid:1) · q

return S

Figure 4: RSA–Garner signature generation. The
Garner coeﬃcient π = q−1 mod p is precomputed.

R0 ← ∞
for i = t down to 0 do

1: function ECScalMul(k,P )
2:
3:
4:
5:
6:
end for
7:
return R0
8:
9: end function

R0 ← [2] · R0
if ki = 1 then R0 ← R0 + P
end if

Figure 5: Scalar Multiplication of an elliptic curve
point by a ﬁeld element. [2]· denotes point doubling,
and + denotes point addition.

Figure 7 summarizes some relevant instances of fault condi-
tions for RSA signatures; in Section 3, we also consider fault
conditions for ECDSA signatures. For each of the fault con-
ditions we consider, we exhibit an attack for retrieving the
secret key. Broadly speaking, the attacks fall into two cat-
egories. The ﬁrst one encompasses attacks that perform an
elementary computation from a value satisfying the fault
condition. The second one covers attacks that require many
values that satisfy the fault condition, and involve more com-
plex computations, typically based on lattice reductions. For
the latter, we implement the attacks in a computer algebra
system, and we experimentally validate their eﬀectiveness
for diﬀerent choices of parameters.

Fault Models and Policies. The literature oﬀers a wide
range of fault models, that aﬀect both data ﬂow (for example
the null fault model in which integer variables can be set to

1: function SignECDSA(m)
2:

(cid:46) message encoding

h ← H(m)
k $← [0, q − 1]
(u, v) ← [k] · P
r ← u mod q; if r = 0 then goto step 3;
s ← k−1(h + rx) mod q; if s = 0 then goto step 3;
return (r, s)

3:
4:
5:
6:
7:
8: end function

Figure 6: ECDSA signature based on an elliptic
curve E over a prime ﬁeld Fp. P is a base point
of order q and H is a cryptographic hash function of
output length equal to the size of q. The private key
is an element x ∈ Fq and the public key is denoted
by (p, q, H, P, Q) with Q = [x]P .

1018Informal description
S is a multiple of p
S is an almost full linear combination of p and q
S is an almost full aﬃne transform of p or q

Fault condition
Validity
Attack technique
S = 0 mod p ∧ S (cid:54)= 0 mod q
GCD computation
Prop. 1
∃α, β. S = α p + β q ∧ α, β < 2
Orthogonal lattices Prop. 2
∃α, β. S = α p + β ∧ α < q, β < 2n/2−ε Orthogonal lattices Prop. 3

2 −ε

n

Figure 7: Fault conditions for RSA signatures. The value of ε depends on the size n of the modulus and is a
multiple of the words size.

a null value) and control ﬂow (for example, the instruction
skip fault model, where an instruction can be skipped). We
consider various fault policies, that subsume a wide range of
such fault model and provide ﬁne-grained speciﬁcations of
the faults that can be performed on implementations. They
model faults using replacement clauses of the form (x, e)
where x is a variable and e is an expression, or (c, c(cid:48)), where
c and c(cid:48) are commands. These clauses respectively state that
it is possible to replace x by e, and c by c(cid:48) in the execution
of the program.

Automated synthesis of faulted implementations. Iden-
tifying fault conditions that allow eﬃcient attacks to exist
is a manual process that requires cryptographic expertise,
and some good understanding of the mathematical tools
available for cryptanalysis. The signiﬁcant pay-oﬀ of fault
conditions is that the process of ﬁnding complying faulted
implementations can be automated. Our second contribu-
tion (Section 4) is a fully automated method for discover-
ing faulted implementations that verify the fault condition.
Our method can be seen as an instance of program synthe-
sis, an area that is currently undergoing rapid and signiﬁ-
cant progress (see Section 6). Broadly construed, the goal of
program synthesis is to ﬁnd, given a speciﬁcation φ (for in-
stance, φ might capture the input/output behavior of a pro-
gram), a set of programs that satisfy φ. Because synthesis
is computationally expensive, there exist many specialized
forms of program synthesis that restrict the search space
using non-functional requirements or by providing a partial
description of the desired programs. We also specialize our
synthesis algorithm to keep it computationally reasonable.
Speciﬁcally, our algorithm takes as input a fault condition
φ, an implementation c, and searches for all faulted imple-
mentations of c that satisfy φ. The search is constrained by
two additional inputs. The ﬁrst additional input is a fault
policy; the second, optional input is an upper bound on the
number of faults we allow.

Our algorithm exploits many of the standard techniques
used in other approaches to program synthesis, including
weakest preconditions and invariant generation, and inter-
faces with SMT solvers for checking the validity of ﬁrst-order
formulae. In addition, our algorithm relies on an automated
prover to simplify the intermediate conditions generated by
weakest precondition computations; the prover is specialized
to formulae that combine arithmetic inequalities and size
constraints; such formulae include many fault conditions, in-
cluding all those we explore in this paper (see Figure 7). On
the other hand, our algorithm noticeably departs from recent
works on program synthesis by its simplicity: indeed, phys-
ical limits on the number and nature of faults suﬃciently
constrain the search space for faulted implementations, al-
lowing us to dispense from using more elaborate techniques
that are required to manage very large search spaces (see
Section 6). Experimental results, which we report below,

demonstrate that our synthesis algorithm performs well on
standard examples.

Application: old and new attacks on RSA and ECDSA
signatures. The third contribution of our work is a prac-
tical evaluation of our approach on RSA and ECDSA sig-
natures. We carry out the evaluation using the computer
algebra system SAGE, and the EasyCrypt tool1. Concretely,
we use the former for estimating the eﬀectiveness of lattice-
based attacks for diﬀerent fault conditions, and the latter
(or more precisely an implementation of our synthesis al-
gorithm built on top of EasyCrypt) for synthesizing faulted
implementations of RSA and ECDSA signatures. During
the process, we rediscover many known attacks; moreover,
we also discover many new attacks, several of which are ef-
ﬁcient attacks of independent interest. We summarize our
main ﬁndings below:

1. For RSA-CRT signatures based on Garner’s recombi-
nation, we recover the basic and most eﬃcient attack of [19]
which injects a null fault in the last call to CIOS during the
computation of modular exponentiation. We also discover
a new eﬃcient attack, based on forcing additional iterations
in the last call to CIOS. This attack yields almost full aﬃne
transforms of p or q, a small number of which is suﬃcient to
recover the factorization of the RSA modulus using orthog-
onal lattices or Simultaneous Diophantian Approximations
as in [21, 27].

2. For RSA-CRT signatures based on the usual CRT re-
combination, we discover a new fault attack; to our best
knowledge, this is the ﬁrst eﬃcient fault attack that works
with randomized padding. The attack is based on forcing ad-
ditional iterations in the last call to CIOS and yields almost
full linear combinations of p and q. From a small number of
such faulty signatures, the factorization of the RSA modulus
can easily be recovered using orthogonal lattices.

3. For ECDSA signatures, we discover several new and
eﬃcient fault attacks for implementations based on the im-
plementation of scalar multiplication given in Figure 5. A
ﬁrst attack is based on skipping the last iterations in the
computation of scalar multiplication. A second attack is
based on forcing the evaluation of a conditional inside the
loop executed for the computation. The largest group of at-
tacks (containing more than 100 faulted programs) is based
on faulting the implementation of the point addition opera-
tion. Each faulted signature allows us to recover the least or
most signiﬁcant bits of the nonce; we then ﬁnish the attack
using classic techniques, and obtain the secret key from a
small number of faulty signatures. We also recover an exist-
ing attack [36] that lets the faulted algorithm produce valid
signatures that may nevertheless be exploited in a similar
fashion.

1https://www.easycrypt.info

10192. BACKGROUND ON LATTICES

Lattice reduction is a powerful tool that is extensively
used in the cryptanalysis of public-key cryptosystems.
In
this section, we provide a brief introduction to some key
deﬁnitions and algorithms that are used in the paper. More
background is given in the long version of this paper [7].

A lattice L is a subgroup of Zn, i.e.

a non-empty set
of vectors closed under addition and inverse. Every lattice
L has a basis, i.e. a ﬁnite set of linearly independent vec-
tors that generate all elements in L. Conversely, every set
(b1, . . . , b(cid:96)) of linearly independent vectors over Zn gener-
ate a lattice L = (cid:104)b1, . . . , b(cid:96)(cid:105) consisting of all integer linear
combinations of the bi’s.

A central problem with lattices is to compute nearly re-
duced bases, i.e. bases that consist of reasonably short and
almost orthogonal vectors. There exist many eﬃcient algo-
rithms for performing lattice reductions, including the cel-
ebrated Lenstra-Lenstra-Lovasz (LLL) algorithm [30] and
Block Korkin-Zolotarev (BKZ) variants [42]. Lattice reduc-
tion is an essential tool in cryptanalysis, and we use it exten-
sively in our attacks. In theory, LLL outputs in polynomial-
time a reduced basis and each vector of the base is related
to the shortest ones by an approximation factor which is ex-
ponential in the dimension. BKZ algorithms allow diﬀerent
tradeoﬀ between the quality of the approximation and the
time complexity. In practice, LLL implementations are very
fast and when the dimension is much less than 200 [45], it
is expected that LLL produces shorter vectors than other
algorithms since its approximation factor is α ≈ 1.01, as
shown experimentally in [22]. In larger dimensions, the ap-
proximation factor increases (unless we greatly increase the
time complexity) and the success probability of our attacks
is reduced. To any lattice L in Zn is associated its orthogo-
nal lattice L⊥, deﬁned as the set of all vectors in Zn that are
orthogonal to all vectors of L. It is possible to reduce the
computation of the orthogonal lattice to lattice reduction in
polynomial time [38]. Orthogonal lattices were introduced
in cryptanalysis by Nguyen and Stern in [37], and have since
found many applications [38].

3. FAULT CONDITIONS

The primary goal of fault attacks is to induce outputs
which satisfy an implementation-independent, mathematical
property that guarantees that the secret key or some other
conﬁdential data can be eﬃciently recovered. Our approach
critically relies on providing a precise formalization of these
mathematical conditions, using fault conditions. Informally,
a fault condition is a statement of the form

v1, . . . , vn : φ ; s1, . . . , sk

where φ is a logical formula that depend on v1, . . . , vn, and
such that an attacker with access to suﬃciently many dis-
tinct tuples of values (v1, . . . , vn) satisfying φ is able to re-
cover secrets s1, . . . , sk (typically parameters of the cryp-
tosystem) with high probability. More formally, φ is a ﬁrst-
order formula over some ﬁrst-order theory T , for instance
modular arithmetic, and all variables that appear free in φ
but not on the left of the colon can only denote parameters
of the cryptosystem.

In this section, we introduce several fault conditions for
RSA and ECDSA schemes, and show how, given suﬃciently
many satisfying values, one can eﬃciently retrieve either the

factorization of the modulus (for the RSA case) or the secret
key (for the ECDSA case). Many of these conditions appear
implicitly in some variant form in the literature.

Convention. All the conditions we consider are of the form
v1, . . . , vn : φ ; p, q for RSA and v1, . . . , vn : φ ; x for
ECDSA. Since the secret values s1, . . . , sk are determined by
the case study, from now on we simply write v1, . . . , vn : φ.
3.1 Fault conditions for RSA signatures

Throughout this section, we assume that N is an RSA
modulus of size n, product of two large primes p and q.
Proofs are detailed in the long version of this paper [7].

Finding multiples of p or q. Our ﬁrst fault condition con-
siders faulted signatures that are a multiple of p or q. This
fault condition enables attacks on RSA by simple gcd com-
putations.

Proposition 1. Given a single value S satisfying the con-

dition:

S : S ≡ 0 mod p ∧ S (cid:54)≡ 0 mod q,

one can eﬃciently factor the RSA modulus N . Obviously
the same result holds by switching p and q.

Proof. One can retrieve the factorization of N by per-

forming a simple gcd computation between S and N .

This fault condition is implicit for instance in [19].

Finding “almost full” linear combinations of p and q.
Our second fault condition considers faulted signatures that
are linear combinations of p and q with almost full coeﬃ-
cients. A variant of this fault condition is implicit in [14].

Proposition 2. Assume that N is a balanced RSA mod-
ulus, i.e. N = p · q such that p, q < 2n/2. Given a suﬃcient
number of values that satisfy the fault condition:
S : ∃x, y. S = x · p + y · q ∧ x, y < 2n/2−ε

with ε > 0, one can eﬃciently factor the RSA modulus N .
The value of ε depends on n and impacts the eﬃciency and
success probability of the algorithm to recover the factoriza-
tion.

Relating this fault condition with [14]. In [14], the au-
thors force random faults on the modulus during CRT re-
combination and obtain a fault condition of the following
form.

−1 mod q)+β·q(q

−1 mod p)∧α, β < 2n/2.

(cid:98)S : ∃α, β.(cid:98)S = α·p(p

If our condition is similar to theirs, the algorithmic prob-
lem ours captures is more general. Indeed, in the analysis,
the crucial parameter is the ratio between the size of p, q
and the size of α, β in the relation S = α · p + β · q. The
larger this ratio is, the easier the attack is since the target
√
vector, called u above is larger. In our case, the size of this
vector is close to 2ε/
(cid:96) while [14] consider a much larger

one (their ratio is(cid:112)N/(cid:96)).

1020p, q
xi, yi

(cid:96)

512 (bits)
480
472
26
33

464
22

496
74

968
37

1024 (bits)
984
976
44
53

992
67

Figure 8: Minimal number of signatures (cid:96) to be
faulted depending on the bitsize of xi, yi. Almost
full linear combinations of p and q.

p, q
xi, yi

(cid:96)

512 (bits)
480
472
28
35

464
23

496
77

968
39

1024 (bits)
984
976
46
56

992
71

Figure 9: Minimal number of signatures (cid:96) to be
faulted depending on the bitsize of yi. Almost full
aﬃne transforms of p or q.

Finding “almost full” afﬁne transforms of p or q. Our
third fault condition considers faulted signatures that are
almost full aﬃne transforms of p or q. This condition is
implicit in [19].

Proposition 3. Assume that N is a balanced RSA mod-
ulus, i.e. p, q such that p, q < 2n/2. Given a suﬃcient num-
ber of values that satisfy the fault condition:

S : ∃x, y. S = x · p + y ∧ x < q,|y| < 2n/2−ε,

one can eﬃciently factor the RSA modulus N . The value ε
depends on n and impacts the eﬃciency and success proba-
bility of the algorithm to recover the factorization.

Implementation and evaluation of key recovery
We now describe how the attacks outlined above can be
performed in practice. Moreover, we estimate the number
of signatures required for recovering the factorization.

Implementation. We use the SAGE computer algebra sys-
tem [45] to implement the attacks. The attacks take as
input a suﬃcient number of signatures S1,··· , S(cid:96) satisfying
the fault condition given in Proposition 2 or Proposition 3.
The implementation heuristically recovers the factorization
of the RSA modulus N as follows.

• Compute an LLL-reduced basis {b1,··· , b(cid:96)−1} of the
lattice (S1,··· , S(cid:96))⊥. This is done by applying LLL
to the lattice in Z1+(cid:96) generated by the rows of the

following matrix: κS1

1

0

. . .

0

1

...
κS(cid:96)



where κ is a suitably large constant, and removing the
ﬁrst component of each resulting vector [37].

• Compute an LLL-reduced basis {x(cid:48), y(cid:48)} of the orthog-
onal lattice {b1,··· , b(cid:96)−2}⊥. Again, this is done by
applying LLL to the lattice in Z(cid:96)−2+(cid:96) generated by

the rows of κ(cid:48)b1,1

...

κ(cid:48)b1,(cid:96)

··· κ(cid:48)b(cid:96)−2,1

...

··· κ(cid:48)b(cid:96)−2,1

1

0

. . .

0

1



and keeping the last (cid:96) components of each resulting
vector.

• For all the linear combinations z of x(cid:48) and y(cid:48) that sat-
isfy the size constraints, compute the test gcd(z1S2 −
z2S1, N ) or gcd(y1 − S1, N ), depending on the fault
condition considered, which allows to recover the prime
factors p and q.

Evaluation. We use our SAGE implementation to evaluate
the number of signatures required for the attacks to succeed.
The results are given in Figures 8 and 9. We see for instance
that 35 values are required to retrieve the factorization of
N when p and q are 1024-bit and the size of the xis and yis
have size 960, i.e. 64 bits shorter than the full size.
3.2 Fault conditions for ECDSA signatures

For ECDSA signatures, we consider fault conditions of a
diﬀerent nature, that rely on partial knowledge of the nonce
k used in the computation. We ﬁrst consider a novel fault
condition focusing only on faulting the scalar multiplication.
Then, we discuss an already-exploited fault condition where
k can be faulted during both the scalar multiplication and
the computation of its inverse, as considered in [36]. In both
cases, knowing some bits of the nonce k is suﬃcient to mount
a classic lattice-based attack. In the following, we assume
that the message to be signed is known and its hash value is
h and we denote abs the abscissa of an elliptic curve point,
lsb(cid:96) k the (cid:96) least signiﬁcant bits of k and (cid:29) for the right-shift
operator.

Faulting r. Our fault condition considers faulted signatures
such that r is computed using only some of the bits of k:

Proposition 4. Given suﬃciently many values satisfy-

ing one of the fault conditions:
r, s : ∃k. r = abs([k (cid:29) (cid:96)] · P ) ∧ s = k

−1(h + rx) mod q

r, s : ∃k. r = abs(±[2(cid:96)] · [k (cid:29) (cid:96)] · P ) ∧ s = k

one can eﬃciently retrieve the secret key x.

(1)
−1(h + rx) mod q
(2)

The proof of this proposition can be done in two parts,
summed up by two facts. We do the proof for condition (1),
but a similar proof applies for condition (2). In particular,
Fact 2 tells us that it is suﬃcient to be able to recover (cid:96)
bits of k to recover the secret key x, and the proof of Fact 1
generalizes to condition (2), since it revolves around compu-
tations on curve points ±[2(cid:96)] · [k (cid:29) (cid:96)] · P .

Fact 1. Given a single pair (r, s) that satisﬁes the fault

condition:

r, s : ∃k. r = abs([k (cid:29) (cid:96)] · P ) ∧ s = k

−1(h + rx) mod q,
one can eﬃciently retrieve the (cid:96) least signiﬁcant bits of k.

Now, given suﬃciently many faulty signatures, the secret

x can be recovered using a technique based on lattices.

Fact 2. Given a suﬃcient number of ECDSA signatures
whose nonces k are partially known, one can eﬃciently re-
trieve the secret key x.

1021Note to conclude that a similar result holds for the most
signiﬁcant bits. For example, condition 1 in this case could
be written as follows.

r, s : r = abs([k mod 2n−(cid:96)]P ) ∧ s = k

−1(h + rx) mod q.

In this case, we retrieve the most signiﬁcant bits of the
nonces and adapt the lattice to this case without diﬃculty.

Using short randomness: faulting r and s.. We also con-
sider the following fault condition, implicitly used in the
original attack on ECDSA by Nguyen et al. [36], where both
the scalar multiplication and ﬁeld inversion are faulted to
simulated short values for k (that is, values whose most sig-
niﬁcant or least signiﬁcant bits are zero).

Proposition 5

([36]). Given a suﬃcient number of pairs

(r, s) that satisfy the fault condition:
r, s : ∃k. r = abs([lsb(k)] · P ) ∧ s = lsb(k)
one can eﬃciently recover the secret key x.

−1(h + rx) mod q,

Although we do not prove it, the validity of this fault

condition is justiﬁed by its use in existing attacks.

q
(cid:96)
d

160 (bits)
4
8
23

61 ( (cid:39)70%)

16
11

256 (bits)
8
38

16
17

32
9

384 (bits)
8
61

16
26

Figure 10: Minimal number of signatures d to
be faulted depending on (cid:96) using curves brain-
poolP160r1, brainpoolP256r1 and brainpoolP384r1.
The percentage given in one case represents the suc-
cess rate of the attack and could be increased by
increasing the value of d.

Implementation and evaluation.. We also implement our
key recovery attacks on ECDSA in Sage to evaluate their
performance. Some experimental values of ((cid:96), d) are given
in Figure 10.
3.3 Discussion

All the fault conditions considered above are intended to
predicate over the output of faulted signatures. However,
fault conditions may also relate outputs of faulted and valid
signatures, or inputs and outputs of signatures. Examples
of such fault conditions are given by the original Bellcore
attack and by Lenstra’s variant:

: S1 − S2 ≡ 0 mod p ∧ S1 − S2 (cid:54)≡ 0 mod q
S1, S2
M, S : S − M e ≡ 0 mod p ∧ S − M e (cid:54)≡ 0 mod q

Both conditions can be further reﬁned. For instance, the
fault condition for the Bellcore attack can be reﬁned to ex-
press that one of the Si, say for instance S1, is a valid sig-
nature of a message m, and S2 is a faulty signature of m. In
fact, one can deﬁne a partial order on fault conditions2 and
prove that the above fault conditions are less than the fault
condition given in Proposition 1.
2 (v1, . . . , vn : φ) ≤ (w1, . . . , wm : ψ) if there exists
an eﬃcient and public n-ary function f that returns m-
tuples of values and such that for every v1, . . . , vn such
that φ(v1, . . . , vn) holds and for every w1, . . . , wm such that
f (v1, . . . , vn) = (w1, . . . , wm), we also have ψ(w1, . . . , wm).

C ::= skip
| C; C
| V ← E
| V $← DE
|
| while E do C
| V ← P(E, . . . ,E)
| return E

if E then C else C conditional
while loop
procedure call
return expression

sequencing
deterministic assignment
random assignment

where V denotes the set of variables, E denotes the set of
expressions, DE denotes the set of distribution expressions
and P denotes the set of procedures.

Figure 11: Syntax of programs

4. SYNTHESIS OF FAULTED IMPLEMEN-

TATIONS

In this section, we present an automated tool that synthe-
sizes faulted implementations that verify a fault condition.
Our tool is built on top of EasyCrypt [8], a tool-assisted
framework for verifying the security of cryptographic con-
structions.
4.1 Programming and assertion language

We consider programs that are written in a core imper-
ative language with deterministic and probabilistic assign-
ments, conditionals, loops, procedure calls, and sequential
composition; the syntax of programs is given in Figure 11.
The programming language essentially subsumes the lan-
guage proposed in [11] and in particular is suﬃciently ex-
pressive to capture cryptographic implementations.

Expressions used in programs, for instance on the right-
hand side of assignments or as guards in conditional state-
ments and loops are built inductively from user-deﬁned con-
stants, operators, and variables. In this paper, we speciﬁ-
cally focus on expressions that are built from operations for
modular arithmetic, and ﬁnite ﬁeld and elliptic curve op-
erations. We use a simple type system for expressions and
programs, and we only consider well-typed programs.

Assertions are ﬁrst-order formulae over the theories inher-
ited from the expression language. Reasoning about asser-
tions is delegated to the EasyCrypt proof engine, which can
either use lemmas from libraries or invoke SMT solvers to
prove the validity of an assertion.
4.2 Fault models and fault policies

Fault models. Fault models are high-level speciﬁcations of
the type of faults that can be injected on embedded devices;
they generally target speciﬁc architectures, and are designed
to reﬂect the eﬀects and capacities of speciﬁc perturbation
techniques.

For the purpose of this paper, it is suﬃcient to know that
there exist two broad classes of fault models. The ﬁrst class
captures faults that modify the dataﬂow, for instance by set-
ting a particular register to a default value (the null fault
model) or to a constant but unknown value (the constant
fault model), or by setting part of the register to a constant
value (the zero high-order bits fault model and its variants).
In practice, it is often important to consider models that
combine several kinds of faults; for instance, one can con-
sider a fault model which allows null faults on small registers,

1022and constant faults on larger registers. Such faults are con-
sidered for example in [20], where the authors also justify
their practical feasibility. The second class captures faults
that modify the control ﬂow, for instance by skipping an
instruction (the instruction skip model), by forcing a condi-
tional instruction to enter into a speciﬁc branch (the branch
fault model), or by forcing the execution of a loop to be in-
terrupted before the guard is set to false, or continued after
it is set to false (the loop fault model). These models are
classic and are considered in [39], for instance. Both mod-
els overlap, in the sense that one can sometimes achieve the
same eﬀect by a dataﬂow fault attack, or by a control ﬂow
fault attack.

Fault policies. Instead of hardcoding the diﬀerent fault
models, our tool allows users to specify ﬁne-grained fault
policies that delineate very precisely the space of faulted
implementations by describing which faults can be injected
in the program. Fault policies are program speciﬁc, and are
given by two sets of replacement clauses.

The ﬁrst set consists of variable replacement clauses of the
form (x, e) where x is a program variable and e is an expres-
sion; such a clause says that one can replace the variable
x by the expression e in the course of program execution.
These declarations can be used to model data faults; for in-
stance, the null fault on x is captured by the clause (x, 0),
whereas the zero high order bits fault on x that sets r bits
to zero is captured by the clause (x, msbr(x)).
The second set consists of command replacement clauses
of the form (c, c(cid:48)), where c and c(cid:48) are commands; such a
clause says that one can replace the command c by the com-
mand c(cid:48) in the course of program execution. These declara-
tions can be used to model control ﬂow faults; for instance,
instruction skip faults on an assignment c is captured by
the clause (c, skip), whereas branch faults are captured by
the clause (if b then c1 else c2, ci) where i = 1 if the goal
is to force execution to go into the true branch, and i = 2,
otherwise. By convention, we require that all instruction re-
placements do not increase the set of modiﬁed variables, i.e.
the set of modiﬁed variables of a command c(cid:48) is a subset of
the set of modiﬁed variables of the command c it replaces.
This is the case for all control ﬂow attacks described above,
and is essential for the completeness of our tool.

Although it is useful in practice, fault policies do not cur-
rently include a mechanism to impose any locality constraint
on the clauses, i.e.
replacements may occur anywhere in
the program. This can easily be circumvented by writing
programs in pseudo-SSA form, for instance by adding sub-
scripts for the diﬀerent occurences of the same variable in
the program.

Finally, fault policies may also include some upper bounds
on the number of times a clause can be used to fault an
implementation. This is useful to constrain the space of
faulted implementations and to match physical constraints.

Discussion. There is a direct relation between fault models
and fault policies, in the sense that every fault model deter-
mines a unique fault policy for each program. However,
many fault attacks require multiple faults and can only be
captured by hybrid fault models, that combine several sim-
pler ones. An example of hybrid fault model is one that
considers null faults on variables that denote small registers
(for instance, variables that store values smaller than 28),

and constant faults on variables representing larger regis-
ters.

It would be interesting to develop a high-level language
for describing hybrid fault models, and a compiler for gen-
erating automatically fault policies from high-level speciﬁca-
tions. However, building the compiler requires a signiﬁcant
amount of infrastructure, including the ability to automat-
ically infer program invariants:
for the example discussed
above, the compiler would need to infer that the value held
by a variable x is always smaller than 28 in order to gener-
ate the clause (x, 0). We leave the design of this high-level
language and the implementation of the compiler for future
work, and require for now that fault policies (albeit in some
edulcorated form) are given as input to the tool.
4.3 Algorithm

Our tool takes as input a (non-faulted) implementation
written in the programming language of EasyCrypt, a fault
condition, a fault policy, and optionally a precondition ψ.
It outputs a set of faulted implementations that satisfy the
fault condition and are valid faults of the original implemen-
tation with respect to the fault model considered. The core
of the tool is an algorithm that interleaves the computation
of weakest preconditions, logical simpliﬁcations, and genera-
tion of faults. For simplicity, we describe a non-deterministic
and ineﬃcient version of the algorithm, whereas the imple-
mentation uses a more eﬃcient implementation, and some
caching and early pruning techniques for the smart explo-
ration of the search space. We initially explain how the
algorithm works on straightline programs, i.e. programs
without loops, conditionals, and procedure calls. Then, we
explain how to extend the algorithm to procedure calls and
loops. First, we deﬁne the notion of faulted instruction.

Faulted commands. The fault policy determines for each
command c of the program a set of faulted instances, consist-
ing of commands c(cid:48) that can be obtained from c according
to the fault policy. All commands are faulted instances of
themselves, and moreover the command c(cid:48) is a faulted in-
stance of c if there exists an instruction replacement clause
(c, c(cid:48)). Moreover, there are some speciﬁc rules for each con-
struct of the language.
• x ← e[e1, . . . , en/y1, . . . , yn] is a faulted instance of
x ← e, provided for i = 1 . . . n, the replacements of yi
by ei are allowed by the fault policy.
• the commands while b do c(cid:48), and if b then c(cid:48); while b do c,
and while b(cid:48) do c; if b then c(cid:48) are all faulted instances of
while b do c, where c(cid:48) is a faulted instance of c, and b(cid:48)
is a guard that forces exactly one less iteration of the
loop body.

The last clause captures faults on the ﬁrst and last iteration
of a loop, and can be extended to model faults on the ﬁrst
and last k iterations of a loop, for k ≥ 1.

Straightline programs. The algorithm is given as input

a fault policy, and manipulates triples of the form (c, φ,(cid:98)c).

a new triple (c(cid:48), φ(cid:48),(cid:98)c(cid:48)) as follows;

Initially, the algorithm is given the triple (c, φ, skip) consist-
ing of the program being analyzed against fault attacks, the
fault condition, and the empty statement. At each iteration,
the algorithm consumes the last command of c and outputs
1. c is decomposed into a sequence c(cid:48); i, where i is the last
command of the program (necessarily an assignment or

10232. the algorithm checks whether i aﬀects φ, i.e.

a random sampling). If c is empty, then the algorithm
checks if φ is a consequence of the precondition, and

returns(cid:98)c if this is the case and nothing otherwise;
algorithm breaks to the next iteration with (c(cid:48), φ,(cid:98)c(cid:48)),
where (cid:98)c(cid:48) = i;(cid:98)c;

if any
of the variables modiﬁed by i occur in φ. If not, the

3. if some variable modiﬁed by i occurs in φ, then the
algorithm chooses non-deterministically a faulted in-
stance i(cid:48) of i;
4. the algorithm computes the weakest precondition of
i(cid:48) on φ. For instance, the rules for computing weak-
est preconditions of deterministic and random assign-
ments are:

WP(x ← e, φ) = φ{x ← e}
WP(x $← d, φ) = ∀v ∈ dom(d), φ{x ← v},

where dom(d) is the set of values that have a non-
zero probability in d. Note that the weakest precon-
dition computation takes an assertion and returns an
assertion. This is achieved by viewing probabilistic as-
signments as non-deterministic assignments over the
domain of the distribution from which the assignment
is sampled;

5. the algorithm applies logical simpliﬁcations to the as-
sertion φ output by the weakest precondition compu-
tation. The output is a new assertion φ(cid:48) that has fewer
free variables than φ;

6. the algorithm proceeds to the next iteration with state

(c, φ(cid:48),(cid:98)c(cid:48)), where (cid:98)c(cid:48) = i(cid:48);(cid:98)c.

Breaking to the next iteration in step 2 and performing log-
ical simpliﬁcations in Step 5 may in fact signiﬁcantly prune
the search space, without ruling out any potential attacks:
computing the weakest precondition on a command i whose
left-hand-side does not appear in the fault condition never
changes that fault condition, whichever fault may be se-
lected. Indeed, our algorithm is sound and relatively com-
plete for straightline code, in the sense that, given an oracle
that can decide logical implications, the algorithm would re-
turn all faulted versions c(cid:48) of c such that the Hoare triple
{ψ}c(cid:48){φ} is valid. In practice, logical implications are veri-
ﬁed using SMT solvers, and hence the implementation might
actually fail to ﬁnd a valid fault attack.

Procedure calls. Our tool deals with programs that make
non-recursive procedure calls by entering into the code of the
procedure when reaching a call. This is intuitively equiva-
lent to inlining all procedure calls and applying the non-
procedural analysis to the inlined code. Although it is cer-
tainly possible to develop more sophisticated approaches, in-
cluding ones that deal with recursive procedure calls, based
on state-of-the-art techniques, our elementary approach has
the advantage of simplicity and is suﬃcient for most imple-
mentations of cryptographic algorithms.

Loops. Dealing with loops is the main source of complex-
ity for our tool, as computing weakest preconditions re-
quires knowing some useful loop invariants, i.e. assertions
that hold throughout all iterations of the loop body. We
provide two elementary mechanisms for dealing with loops:
an invariant generator, and an algorithm for turning (user-
provided) invariants for non-faulted loops into invariants for
their faulted instances. There is admittedly signiﬁcant scope

for improving these mechanisms, in particular by building
upon recent developments in invariant generation; we leave
this avenue for future work.

Pruning. We use two main pruning techniques for improv-
ing the eﬃciency of the search algorithm. First, since SMT
solvers are a clear performance bottleneck, we cache all SMT
queries and their result. Second, we maintain a table of all

intermediate statements (c, φ,(cid:98)c), and abort execution when-

ever the algorithm computes a triple which coincides in the
ﬁrst and second component with an element of the table.

5. APPLICATIONS

Using our tool, we are able to discover many attacks on
implementations of RSA-CRT and ECDSA signatures. Sev-
eral of these attacks are new, and of independent interest.
In this section, we review in some detail the most relevant
attacks we ﬁnd.
5.1 RSA-CRT signatures

We consider a CRT-based implementation of RSA that
uses the Montgomery ladder (Figure 2) for modular expo-
nentiation and the CIOS algorithm (Figure 1) for modu-
lar multiplication. We consider implementations using both
Garner’s recombination algorithm (Figure 4) and the stan-
dard CRT recombination with optimizations (Figure 3). Most
of the attacks we ﬁnd involve faults injected during the last
call to CIOS in the ladder (line 13, Figure 2), which takes
the result of the exponentiation back into its classical rep-
resentation. We assume that the parameter x in CIOS is
stored in a shift-register, used to extract its individual dig-
its in base b.

Finding multiples of p or q. Using the fault condition from
Proposition 1, and allowing null faults on small variables
(that contain integers mod b) we recover the most basic
and eﬃcient attack of [19], which sets q(cid:48) to 0 during the
ﬁnal call to CIOS( ¯Sq, 1).
In addition, the tool also ﬁnds
several variants of the fault, indicating which (combinations
of) variables can be set to 0 to fulﬁll the fault condition.
For example, setting both uj and xj to 0 throughout the
computation still yields a null result.

This attack and its variants only work when the ﬁnal call
to CIOS occurs with 1 as second argument. This is not
always the case when CRT recombination is used, since the
call to CIOS can be used to optimize a multiplication away as
illustrated in Figure 3. In this case, by adding control ﬂow
faults to the fault policy, our tool also ﬁnds that faulting q(cid:48)
to 0 and doubling the number of loop iterations during this
ﬁnal call forces its result to zero. Indeed, in this case, after
the normal number of iterations, the shift-register initially
containing x contains zero and any further loop iteration
simply shifts a to the right, eventually forcing it to zero as
well. A much simpler, albeit much less elegant, control ﬂow
fault involves simply faulting the initial loop condition so no
computation is performed.

Finding “almost full” linear transforms of p or q. It
may not always be possible to skip the loop entirely, or to
ensure that the loop is run at least twice as many times as
expected. However, it may be easier to inject faults on loop
counters that consistently add a small (possibly unknown)

1024number of iterations. Our tool automatically ﬁnds that such
faults, when q(cid:48) is set to zero during the additional loop iter-
ations are in fact suﬃcient to guarantee the fault condition
from Proposition 3 using both Garner and CRT recombi-
nation. For each additional iteration, the size of the expo-
nentiation’s result is reduced by the size of a base b digit,
quickly leading to a result that can be exploited by the clas-
sic lattice-based attacks described in Section 3.1.
Alternatively, instead of faulting the control ﬂow and a
variable, our tool also ﬁnds that simply setting q(cid:48) and xj to
zero during the last iterations of the loop leads to a similarly
faulted signature, that fulﬁlls the desired fault condition.

Finding “almost full” linear combinations of p and q.
When given the fault condition from Proposition 2, our tool
ﬁnds that running the previous size-reducing attacks on both
half-exponentiations yields a suitable faulted signature when
using the classic CRT recombination rather than Garner’s.
The relative eﬃciency of the lattice-based attack from Sec-
tion 3.1 compared to the one from Section 3.1 may justify
the additional faults.

5.2 ECDSA signatures

We also run our tool on the ECDSA signature algorithm.
We consider an implementation where scalar multiplication
is computed using MSB-ﬁrst Double-and-Add (Figure 5).
The main challenge here is that the fault conditions we con-
sider are very precise, in the sense that they give a full func-
tional description of the result depending on some (faulted)
inputs. We therefore need not only to be able to ﬁnd the
faults, but also to be able to prove the functional correctness
of the non-faulted algorithms.

Faults on the randomness. We ﬁrst consider the fault con-
dition from Proposition 5, that we generalized from [36].
The tool ﬁnds that performing a zero-higher-order bit fault
on k after it is sampled is suﬃcient to guarantee the fault
condition (as we then have k = k (cid:29) (cid:96)). However, we do not
automatically ﬁnd more complex attacks (that use proposi-
tion 5) on the algorithms computing scalar multiplications
and ﬁeld element inversions. We believe that our tool would
in fact ﬁnd such attacks given precise enough implementa-
tions for these operations, and precise enough loop invariants
for their non-faulted versions.

Faults on scalar multiplication.. Fault condition (1) from
Proposition 4 allows our algorithm to quickly focus the fault
search on the computation of the scalar multiplication in
ECDSA. The tool discovers that exiting the loop early when
computing [k] · P , and letting all other computations oc-
cur normally, yields signatures (r, s) that fulﬁll fault condi-
tion 4(1).

The second fault condition (2) from Proposition 4 leads
to a slightly more ﬂexible overall attack, since it does not
require the number of faulted iterations to be known. Given
this fault condition and an abstract algorithmic description
of the ECDSA algorithm, our tool ﬁnds that forcing the
branch condition at line 5 (Figure 5) to false for a number of
iterations towards the end of the loop yields an exploitable
result. Generalizing, faulting line 6 or its implementation
such that it computes R0 ← ±R0 instead of R0 ← R0 + P
would yield the same result.

Faults on point addition. This observation leads us to con-
sider more concrete reﬁnements of the point addition algo-
rithm. In particular, we consider a register-level algorithm
for Jacobian-Jacobian point addition, as presented by Mur-
dica [35, Algorithm 36]. This algorithm, shown in the long
version of this paper, is only correct when applied to distinct
curve points that are not at inﬁnity or inverse of each other.
Given the implementation where the partial point addi-
tion algorithm is wrapped in tests ensuring it is applied cor-
rectly (that is, Q, R (cid:54)= ∞ and Q (cid:54)= ±R), our tool quickly
ﬁnds that faulting the conditional checks is suﬃcient to
force the fault condition: by faulting the test that checks
whether the second argument is inﬁnite, we can easily force
the wrapped addition algorithm to return its ﬁrst argument,
forcing the fault condition.

However, since the base point P is of order q, and R0 is
always a scalar multiple of P , such checks can be optimized
away when the addition algorithm is used for scalar multipli-
cation. With an additional condition that none of the scalar
multiples of P are on the vertical axis our tool ﬁnds null
faults, and some faults in combined models involving null
faults and instruction skips, that lead to the faulted com-
putation of R0 + P returning −R0. Performing this fault
during the last iterations of the Double-and-Add loop then
yields a faulted ECDSA signature that fulﬁlls fault condi-
tion 4(2) and can be used in the lattice-based attack. Our
tool yields a list of more than 100 ways to fault point ad-
dition such that the faulted ECDSA signature fulﬁlls fault
condition 4(2).

6. RELATED WORK

Formal methods for cryptography. This work is more
closely related to a recent series of articles that apply for-
mal methods to fault attacks. However, our emphasis is on
ﬁnding fault attacks against implementations, whereas other
works focus on proving absence of fault attacks against algo-
rithmic descriptions or implementations. Two independent
eﬀorts by Christoﬁ, Chetali, Goubin and Vigilant [15] and
by Rauzy and Guilley [40] prove the absence of fault attacks
against RSA-CRT with Vigilant countermeasure. In a sim-
ilar spirit, Moro et al. [33] propose an approach based on
redundancy to protect implementations against instruction
skip attacks. More recently, Barthe, Dupressoir, Fouque,
Gr´egoire, Tibouchi and Zapalowicz [6] formally verify the
security RSA-PSS against non-random faults using Easy-
Crypt [8].

Another recent series of papers use type systems and SMT
solvers for verifying whether cryptographic implementations
are correctly masked [34, 10, 18]; in particular, Eldib and
Wang [17] have developed a method for synthesizing mask-
ing countermeasures.

Synthesis. Program synthesis is an active area of research
that is undergoing rapid and signiﬁcant progress, thanks
to novel and practically achievable approaches, and to ad-
vances in SMT solvers. In contrast to the early works that
pursue deductive program synthesis, where the program is
extracted from the proof of a theorem, typically a ∀∃ state-
ment, most of the current work focuses on inductive program
synthesis, and uses SMT solvers. Many works on induc-
tive synthesis, notably early ones, have focused on loop-free

1025programs [43, 23, 24]. Other recent works allow synthez-
ing programs with loops; for instance, Srivastava, Gulwani
and Foster [44] introduce proof-theoretic synthesis, a variant
of synthesis that combines inference of loop invariants and
synthesis of loop-free programs. However, this approach is
limited to programs whose loop invariants fall into a lim-
ited class of assertions. Syntax-guided program synthesis [1]
is a recently proposed framework that subsumes many of
the previous approaches to synthesis. One ambition of this
project is to develop a framework for testing and compar-
ing diﬀerent implementations, and in particular to provide a
common input format inspired from SMT-LIB for synthesis
tools. In the future, it would be interesting to suggest auto-
mated discovery of fault attacks as a challenge for syntax-
guided synthesis competitions.

Our approach shares many similarities with program re-
pair, an instance of program synthesis that aims at automat-
ically eliminating deﬁciencies in code. Informally, a program
repair algorithm takes as input a program p and a property
φ that must be satisﬁed by the output of p, and computes
by small successive modiﬁcations of p a program p(cid:48) that sat-
isﬁes φ. There exist many approaches to program repair;
some of them are based on genetic algorithms [29], others
are based on code contracts [46]. We refer the reader to a
recent overview [28] for more information. The connection
with program repair is very direct; indeed, one can even view
faulted implementations as a form of program repair for the
attacker. However, the techniques used in program repair
are not immediately applicable to ﬁnding fault attacks on
cryptographic implementations.

7. CONCLUDING REMARKS

We have presented a new approach to discover automat-
ically fault attacks on cryptographic implementations. The
technical core of our approach is a new and practical form
of program synthesis. Pleasingly, the tool that implements
our approach is able to discover new and interesting attacks.
An exciting perspective for further work is to apply our tool
to an extensive class of implementations. There are also in-
teresting directions for improving and extending our tool.
The ﬁrst one is to integrate state-of-the-art invariant gen-
eration and synthesis techniques in the tool. Another one
is to implement a synthesis algorithm based on relational
veriﬁcation in order to deal with relational fault conditions,
i.e. fault conditions that relate faulted and valid signatures.
Although cast in a diﬀerent context, the work reported in [5]
provides an excellent starting point. Yet another one would
be to use synthesis for discovering countermeasures against
fault attacks as done in [18] for side-channel attacks.

Whereas the focus of this paper is on implementations of
public key cryptography, our method would also apply to
the symmetric setting. Finding good fault conditions, as
well as the considerable size of the implementations would
make such an application challenging, but should allow fairly
easily to ﬁnd attacks on the last few rounds of computation.

Acknowledgments. The work of Barthe and Dupressoir
has been partially supported by ONR grant N00014-12-1-
0914, Madrid regional project S2009TIC-1465 PROMETI-
DOS, and Spanish projects TIN2009-14599 DESAFIOS 10
and TIN2012-39391-C04-01 Strongsoft.

8. REFERENCES
[1] R. Alur, R. Bod´ık, G. Juniwal, M. M. K. Martin,

M. Raghothaman, S. A. Seshia, R. Singh,
A. Solar-Lezama, E. Torlak, and A. Udupa.
Syntax-guided synthesis. In FMCAD, pages 1–17.
IEEE, 2013.

[2] R. J. Anderson and M. G. Kuhn. Low cost attacks on

tamper resistant devices. In Security Protocols
Workshop, pages 125–136, 1997.

[3] A. Barenghi, G. Bertoni, A. Palomba, and R. Susella.
A novel fault attack against ECDSA. In HOST, pages
161–166, 2011.

[4] A. Barenghi, G. M. Bertoni, L. Breveglieri, and
G. Pelosi. A fault induction technique based on
voltage underfeeding with application to attacks
against AES and RSA. Journal of Systems and
Software, 86(7):1864–1878, 2013.

[5] G. Barthe, J. M. Crespo, S. Gulwani, C. Kunz, and

M. Marron. From relational veriﬁcation to SIMD loop
synthesis. In PPOPP, pages 123–134. ACM, 2013.

[6] G. Barthe, F. Dupressoir, P.-A. Fouque, B. Gr´egoire,
M. Tibouchi, and J.-C. Zapalowicz. Making RSA-PSS
provably secure against non-random faults.
Cryptology ePrint Archive, Report 2014/252, 2014.
http://eprint.iacr.org/2014/252.

[7] G. Barthe, F. Dupressoir, P.-A. Fouque, B. Gregoire,

and J.-C. Zapalowicz. Synthesis of fault attacks on
cryptographic implementations. Cryptology ePrint
Archive, Report 2014/436, 2014.
http://eprint.iacr.org/2014/436.

[8] G. Barthe, B. Gr´egoire, S. Heraud, and S. Z. B´eguelin.

Computer-aided security proofs for the working
cryptographer. In P. Rogaway, editor, CRYPTO 2011,
volume 6841 of LNCS, pages 71–90. Springer, Aug.
2011.

[9] A. Bauer, E. Jaulmes, E. Prouﬀ, and J. Wild.

Horizontal collision correlation attack on elliptic
curves. In Selected Areas in Cryptology. Springer, 2013.

[10] A. G. Bayrak, F. Regazzoni, D. Novo, and P. Ienne.

Sleuth: automated veriﬁcation of software power
analysis countermeasures. In Cryptographic Hardware
and Embedded Systems-CHES 2013, pages 293–310.
Springer, 2013.

[11] M. Bellare and P. Rogaway. The security of triple

encryption and a framework for code-based
game-playing proofs. In S. Vaudenay, editor,
EUROCRYPT 2006, volume 4004 of LNCS, pages
409–426. Springer, May / June 2006.

[12] I. Biehl, B. Meyer, and V. M¨uller. Diﬀerential fault

attacks on elliptic curve cryptosystems. In M. Bellare,
editor, CRYPTO 2000, volume 1880 of LNCS, pages
131–146. Springer, Aug. 2000.

[13] D. Boneh, R. A. DeMillo, and R. J. Lipton. On the
importance of checking cryptographic protocols for
faults (extended abstract). In W. Fumy, editor,
EUROCRYPT’97, volume 1233 of LNCS, pages 37–51.
Springer, May 1997.

[14] E. Brier, D. Naccache, P. Q. Nguyen, and

M. Tibouchi. Modulus fault attacks against RSA-CRT
signatures. In B. Preneel and T. Takagi, editors,
CHES 2011, volume 6917 of LNCS, pages 192–206.
Springer, Sept. / Oct. 2011.

1026[15] M. Christoﬁ, B. Chetali, L. Goubin, and D. Vigilant.

Formal veriﬁcation of a CRT-RSA implementation
against fault attacks. J. Cryptographic Engineering,
3(3):157–167, 2013.

[16] M. Ciet and M. Joye. Elliptic curve cryptosystems in

the presence of permanent and transient faults.
Designs, Codes and Cryptography, 36(1):33–43, 2005.

[17] H. Eldib and C. Wang. Synthesis of masking

countermeasures against side channel attacks. In
Computer Aided Veriﬁcation (CAV’14). Springer,
2014. To appear.

[18] H. Eldib, C. Wang, and P. Schaumont. SMT-based

veriﬁcation of software countermeasures against
side-channel attacks. In Tools and Algorithms for the
Construction and Analysis of Systems, pages 62–77.
Springer, 2014.

[19] P.-A. Fouque, N. Guillermin, D. Leresteux,

M. Tibouchi, and J.-C. Zapalowicz. Attacking
RSA-CRT signatures with faults on montgomery
multiplication. In E. Prouﬀ and P. Schaumont,
editors, CHES 2012, volume 7428 of LNCS, pages
447–462. Springer, Sept. 2012.

[20] P.-A. Fouque, D. Leresteux, and F. Valette. Using

faults for buﬀer overﬂow eﬀects. In SAC, pages
1638–1639, 2012.

[21] P.-A. Fouque, G. Martinet, and G. Poupard.

Attacking unbalanced RSA-CRT using SPA. In C. D.
Walter, ¸Cetin Kaya. Ko¸c, and C. Paar, editors,
CHES 2003, volume 2779 of LNCS, pages 254–268.
Springer, Sept. 2003.

[22] N. Gama and P. Q. Nguyen. Predicting lattice

reduction. In N. P. Smart, editor,
EUROCRYPT 2008, volume 4965 of LNCS, pages
31–51. Springer, Apr. 2008.

[23] S. Gulwani, S. Jha, A. Tiwari, and R. Venkatesan.

Synthesis of loop-free programs. In PLDI, 2011.

[24] S. Jha, S. Gulwani, S. Seshia, and A. Tiwari.

Oracle-guided component-based program synthesis. In
ICSE, 2010.

[25] M. Joye, A. K. Lenstra, and J.-J. Quisquater. Chinese

remaindering based cryptosystems in the presence of
faults. Journal of Cryptology, 12(4):241–245, 1999.
[26] M. Joye and M. Tunstall, editors. Fault Analysis in

Cryptography. Information Security and Cryptography.
Springer, 2012.

[27] J. C. Lagarias. The computational complexity of

simultaneous diophantine approximation problems. In
23rd FOCS, pages 32–39. IEEE Computer Society
Press, Nov. 1982.

[28] C. Le Goues, S. Forrest, and W. Weimer. Current
challenges in automatic software repair. Software
Quality Jornal, 21:421–443, 2013.

[29] C. Le Goues, T. Nguyen, S. Forrest, and W. Weimer.

Genprog: A generic method for automatic software
repair. IEEE Transactions on Software Engineering,
38:54–72, 2012.

[30] A. Lenstra, H. Lenstra, and L. Lov´asz. Factoring

polynomials with rational coeﬃcients. Math. Ann.,
261:515–534, 1982.

[31] D. Maimut, C. Murdica, D. Naccache, and

M. Tibouchi. Fault attacks on projective-to-aﬃne
coordinates conversion. In COSADE, pages 46–61,
2013.

[32] P. L. Montgomery. Modular multiplication without

trial division. Mathematics of Computation,
44:519–521, 1985.

[33] N. Moro, K. Heydemann, E. Encrenaz, and

B. Robisson. Formal veriﬁcation of a software
countermeasure against instruction skip attacks.
Journal of Cryptographic Engineering, pages 1–12,
2014.

[34] A. Moss, E. Oswald, D. Page, and M. Tunstall.

Compiler assisted masking. In CHES, pages 58–75.
Springer, 2012.

[35] C. Murdica. Physical Security of Elliptic Curve

Cryptography. PhD thesis, T´el´ecom ParisTech, 2014.

[36] D. Naccache, P. Q. Nguyen, M. Tunstall, and

C. Whelan. Experimenting with faults, lattices and
the DSA. In S. Vaudenay, editor, PKC 2005, volume
3386 of LNCS, pages 16–28. Springer, Jan. 2005.

[37] P. Q. Nguyen and J. Stern. Merkle-Hellman revisited:

A cryptoanalysis of the Qu-Vanstone cryptosystem
based on group factorizations. In B. S. Kaliski Jr.,
editor, CRYPTO’97, volume 1294 of LNCS, pages
198–212. Springer, Aug. 1997.

[38] P. Q. Nguyen and J. Stern. Lattice reduction in

cryptology: An update. In ANTS, pages 85–112, 2000.

[39] D. Page and F. Vercauteren. Fault and side-channel

attacks on pairing based cryptography. Cryptology
ePrint Archive, Report 2004/283, 2004.
http://eprint.iacr.org/2004/283.

[40] P. Rauzy and S. Guilley. A formal proof of

countermeasures against fault injection attacks on
CRT-RSA. Journal of Cryptographic Engineering,
pages 1–13, 2013.

[41] J.-M. Schmidt and M. Medwed. A fault attack on

ecdsa. In Fault Diagnosis and Tolerance in
Cryptography (FDTC), 2009 Workshop on, pages
93–99, Sept 2009.

[42] C.-P. Schnorr and M. Euchner. Lattice basis reduction:
Improved practical algorithms and solving subset sum
problems. Math. Program., 66:181–199, 1994.

[43] A. Solar-Lezama, R. M. Rabbah, R. Bod´ık, and

K. Ebcioglu. Programming by sketching for
bit-streaming programs. In PLDI, 2005.

[44] S. Srivastava, S. Gulwani, and J. S. Foster. From

program veriﬁcation to program synthesis. In POPL,
2010.

[45] W. Stein et al. Sage Mathematics Software (Version

4.8). The Sage Development Team, 2012.
http://www.sagemath.org.

[46] Y. Wei, Y. Pei, C. A. Furia, L. S. Silva, S. Buchholz,

B. Meyer, and A. Zeller. Automated ﬁxing of programs
with contracts. In ISSTA, pages 61–72. ACM, 2010.

1027