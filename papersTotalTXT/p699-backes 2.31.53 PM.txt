Computational Soundness

without Protocol Restrictions

Michael Backes1, Ankit Malik2 and Dominique Unruh3

1 Saarland University, Germany and MPI-SWS

2 Dept. of Math., IIT Delhi

3 University of Tartu, Estonia

ABSTRACT
The abstraction of cryptographic operations by term al-
gebras, called Dolev-Yao models, is essential in almost all
tool-supported methods for verifying security protocols. Re-
cently signiﬁcant progress was made in establishing compu-
tational soundness results: these results prove that Dolev-
Yao style models can be sound with respect to actual crypto-
graphic realizations and security deﬁnitions. However, these
results came at the cost of imposing various constraints on
the set of permitted security protocols: e.g., dishonestly gen-
erated keys must not be used, key cycles need to be avoided,
and many more. In a nutshell, the cryptographic security
deﬁnitions did not adequately capture these cases, but were
considered carved in stone;
in contrast, the symbolic ab-
stractions were bent to reﬂect cryptographic features and
idiosyncrasies, thereby requiring adaptations of existing ver-
iﬁcation tools.

In this paper, we pursue the opposite direction: we con-
sider a symbolic abstraction for public-key encryption and
identify two cryptographic deﬁnitions called PROG-KDM
(programmable key-dependent message) security and MKE
(malicious-key extractable) security that we jointly prove to
be suﬃcient for obtaining computational soundness with-
out imposing assumptions on the protocols using this ab-
straction. In particular, dishonestly generated keys obtained
from the adversary can be sent, received, and used. The deﬁ-
nitions can be met by existing cryptographic schemes in the
random oracle model. This yields the ﬁrst computational
soundness result for trace-properties that holds for arbitrary
protocols using this abstraction (in particular permitting to
send and receive dishonestly generated keys), and that is ac-
cessible to all existing tools for reasoning about Dolev-Yao
models without further adaptations.

Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network
Protocols—Protocol Veriﬁcation

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

General Terms
Security, theory, veriﬁcation

Keywords
Computational soundness, sending keys, key dependent mes-
sages

1.

INTRODUCTION

Proofs of security protocols are known to be error-prone
and, owing to the distributed-system aspects of multiple
interleaved protocol runs, awkward for humans to make.
Hence work towards the automation of such proofs started
soon after the ﬁrst protocols were developed. From the start,
the actual cryptographic operations in such proofs were ide-
alized into so-called Dolev-Yao models, following [23, 24, 30],
e.g., see [25, 34, 1, 28, 33, 13]. This idealization simpliﬁes
proof construction by freeing proofs from cryptographic de-
tails such as computational restrictions, probabilistic behav-
ior, and error probabilities. The success of these Dolev-Yao
models for the tool-supported security analysis stems from
their conceptual simplicity: they only consist of a small set
of explicitly permitted rules that can be combined in an arbi-
trary manner, without any further constraints on the usage
and combination of these rules. Recently signiﬁcant progress
was made in establishing so-called computational soundness
results: these results prove that Dolev-Yao style models can
be sound with respect to actual cryptographic realizations
and security deﬁnitions, e.g., see [2, 26, 10, 8, 27, 31, 22, 19,
11, 21].

However, prior computational soundness results came at
the price of imposing various constraints on the set of per-
mitted protocols. In addition to minor extensions of sym-
bolic models, such as reﬂecting length information or ran-
domization, core limitations were to assume that the sur-
rounding protocol does not cause any key cycles, or – more
importantly – that all keys that are used within the pro-
tocol have been generated using the correct key generation
algorithm. The latter assumption is particularly problem-
atic since keys exchanged over the network might have been
generated by the adversary, and assuming that the adversary
is forced to honestly generate keys can hardly be justiﬁed in
practice.

In a nutshell, these constraints arose because the respec-
tive cryptographic security deﬁnitions did not adequately
capture these cases, but were considered carved in stone; in
contrast, the symbolic abstractions were bent to reﬂect cryp-
tographic features and idiosyncrasies. As a result, existing

699tools needed to be adapted to incorporate extensions in the
symbolic abstractions, and the explicitly imposed protocol
constraints rendered large classes of protocols out-of-scope of
prior soundness results. Moreover, if one intended to analyze
a protocol that is comprised by such prior results, one addi-
tionally had to formally check that the protocol meets the
respective protocol constraints for computational soundness,
which is not necessarily doable in an automated manner.

Our Contribution. In this paper, we are ﬁrst to pursue
the opposite direction: we consider an unconstrained sym-
bolic abstraction for public-key encryption and we strive for
avoiding assumptions on the protocols using this abstrac-
tion. We in particular permit sending and receiving of po-
tentially dishonestly generated secret keys. Being based on
the CoSP framework, our result is limited to trace prop-
erties. We do not, however, see a principal reason why it
should not be possible to extend it to equivalence proper-
ties.

To this end, we ﬁrst identify which standard and which
more sophisticated properties a cryptographic scheme for
public-key encryption needs to fulﬁll in order to serve as
a computationally sound implementation of an unrestricted
Dolev-Yao model, i.e., eliminating constraints on the set of
permitted cryptographic protocols. This process culminates
in the novel deﬁnitions of an PROG-KDM (programmable
key-dependent message) secure and an MKE (malicious-key
extractable) secure encryption scheme. Our main result will
then show that public-key encryption schemes that satisfy
PROG-KDM and MKE security constitute computationally
sound implementations of unrestricted Dolev-Yao models for
public-key encryption. The deﬁnitions can be met by exist-
ing public-key encryption schemes. (A number of additional
conditions are needed, e.g., that a public key can be ex-
tracted from a ciphertext. But these can be easily enforced
by suitable tagging. See Appendix A for the full list.)

Our computational soundness result in particular encom-
passes protocols that allow honest users to send, receive
and use dishonestly generated keys that they received from
the adversary, without imposing further assumptions on the
symbolic abstraction. This solves a thus far open problem
in the cryptographic soundness literature.1

In a nutshell, we obtain the ﬁrst computational sound-
ness result that avoids to impose constraints on the proto-
cols using this abstraction (in particular, it permits to send,
receive, and use dishonestly generated keys), and that is ac-
cessible to all existing tools for reasoning about Dolev-Yao
models without further adaptations.

Related work. Backes, Pﬁtzmann, and Scedrov [9] give
a computational soundness result allowing key-dependent
messages and sending of secret keys. But they impose the
protocol condition that no key that is revealed to the ad-
versary is every used for encrypting. Ad˜ao, Bana, Herzog,
and Scedrov [3] give a computational soundness result al-
lowing key-dependent messages, but only for passive adver-
saries. No adaptive revealing of secret keys is supported.
1In an interesting recent work, Comon-Lundh et al. [20]
also achieved a computational soundness result for dishon-
est keys. Their work is orthogonal to our work in that they
proposed an extension of the symbolic model while keeping
the standard security assumptions IND-CPA and IND-CTXT
for the encryption scheme. As explained before, we avoid
symbolic extensions at the cost of novel cryptographic deﬁ-
nitions.

Mazar´e and Warinschi [29] give a computational soundness
that allows for adaptive revealing of secret keys (in the case
of symmetric encryption). But they disallow key-dependent
messages, encrypting of keys, key-dependent messages, en-
cryptions of ciphertexts, or forwarding of ciphertexts. They
show that under these conditions, IND-CCA2 security is suf-
ﬁcient. Bana and Comon-Lundh [12] have a computational
soundness result not imposing any restrictions on the proto-
col. Their symbolic modeling, however, is weakened so that
no secrecy (even symbolically) is guaranteed when key de-
pendent messages or adaptive revealing of secret keys occur.

Outline of the Paper. First, we introduce our symbolic
abstraction of unconstrained public-key encryption within
the CoSP framework in Section 2. We give the notion of
computation soundness in Section 3 and review how prior
computational soundness proofs were conducted in CoSP in
Section 4 for the sake of illustration. We identify where the
aforementioned restrictions arise in these proofs and explain
how to overcome these limitations in Section 5. The cor-
responding formal result is established in Section 6. Full
proofs are deferred to the full version [7]

2. THE SYMBOLIC MODEL

We ﬁrst describe our symbolic modeling here. The model
is fairly standard and follows that of [4], except that we
added some additional operations on secret keys.

Let C := {enc/3,

Constructors and nonces.
ek /1, dk /1, sig/3, vk /1, sk /1, pair /2, string0 /1, string1 /1,
and
empty /0, garbageSig /2, garbage /1, garbageEnc/2}
N := NP ∪ NE. Here NP and NE are countably inﬁnite
sets representing protocol and adversary nonces, respec-
tively. (f /n means f has arity n.) Intuitively, encryption,
decryption, veriﬁcation, and signing keys are represented
as ek (r), dk (r), vk (r), sk (r) with a nonce r (the randomness
used when generating the keys). enc(ek (r′), m, r) encrypts
m using the encryption key ek (r′) and randomness r.
sig(sk (r′), m, r) is a signature of m using the signing
key sk (r′) and randomness r. The constructors string0 ,
string1 , and empty are used to model arbitrary strings
used as payload in a protocol (e.g., a bitstring 010 would
be encoded as string0 (string1 (string0 (empty )))). garbage,
garbageEnc, and garbageSig are constructors necessary to
express certain invalid terms the adversary may send, these
constructors are not used by the protocol.

Message type.2 We deﬁne T as the set of all terms T

2In the CoSP framework, the message type represents the
set of all well-formed terms. Having such a restriction (and
excluding, e.g., enc(dk (N ), . . . ) or similar) makes life easier.
However, when applying the computational soundness result
to a calculus that does not support message types, one needs
to remove the restriction that only terms in the message type
are considered. [4] give a theorem that guarantees that this
can be done without losing computational soundness.

700matching the following grammar:

T ::= enc(ek (N ), T, N ) | ek (N ) | dk (N ) |
sig(sk (N ), T, N ) | vk (N ) | sk (N ) |
pair (T, T ) | S | N |
garbage(N ) | garbageEnc(T, N ) |
garbageSig (T, N )

S ::= empty | string 0(S) | string 1(S)

where the nonterminal N stands for nonces.

Destructors. D := {dec/2, isenc/1, isek /1, isdk /1, ekof /1,
ekofdk /1, verify/2, issig/1, isvk /1, issk /1, vkof /2, vkofsk /1,
fst /1, snd /1, unstring 0/1, unstring 1/1, equals/2}.
The
destructors isek , isdk , isvk , issk , isenc, and issig realize
predicates to test whether a term is an encryption key,
decryption key, veriﬁcation key, signing key, ciphertext,
or signature, respectively.
ekof extracts the encryption
key from a ciphertext, vkof extracts the veriﬁcation key
from a signature.
dec(dk (r), c) decrypts the ciphertext
c. verify(vk (r), s) veriﬁes the signature s with respect to
the veriﬁcation key vk (r) and returns the signed message
if successful.
ekofdk and vkofsk compute the encryp-
tion/veriﬁcation key corresponding to a decryption/signing
key. The destructors fst and snd are used to destruct pairs,
and the destructors unstring0 and unstring1 allow to parse
payload-strings.
(Destructors ispair and isstring are not
necessary, they can be emulated using fst, unstring i, and
equals(·, empty).)

The destructors are deﬁned by the rules in Figure 1; an

application matching none of these rules evaluates to ⊥:

Deduction relation. ⊢ is the smallest relation satisfy-
ing the rules in Figure 2. This deduction relation spec-
iﬁes which terms the adversary can deduce given already
known messages S. We use the shorthand evalf for the ap-
plication of a constructor or destructor. evalf (t1, . . . , tn) =
f (t1, . . . , tn) if f (t1, . . . , tn) 6= ⊥ and f (t1, . . . , tn) ∈ T and
evalf (t1, . . . , tn) = ⊥ otherwise.

Protocols. We use the protocol model from the CoSP
framework [4]. There, a protocol is modeled as a (possibly
inﬁnite) tree of nodes. Each node corresponds to a particular
protocol action such as receiving a term from the adversary,
sending a previously computed term to the adversary, ap-
plying a constructor or destructor to previously computed
terms (and branching depending on whether the applica-
tion is successful), or picking a nonce. We do not describe
the protocol model in detail here, but it suﬃces to know
that a protocol can freely apply constructors and destruc-
tors (computation nodes), branch depending on destructor
success, and communicate with the adversary. Despite the
simplicity of the model, it is expressive enough to embed
powerful calculi such as the applied π-calculus (shown in
[4]) or RCF, a core calculus for F# (shown in [6]).

Protocol execution. Given a particular protocol Π (mod-
eled as a tree), the set of possible protocol traces is deﬁned
by traversing the tree: in case of an input node the adver-
sary nondeterministically picks a term t with S ⊢ t where
S are the terms sent so far through output nodes; at com-
putation nodes, a new term is computed by applying a con-
structor or destructor to terms computed/received at earlier
nodes; then the left or right successor is taken depending on
whether the destructor succeeded. The sequence of nodes

dec(dk (t1), enc(ek (t1), m, t2)) = m

isenc(enc(ek (t1), t2, t3)) = enc(ek (t1), t2, t3)
isenc(garbageEnc(t1, t2)) = garbageEnc(t1, t2)

isek (ek (t)) = ek (t)
isdk (dk (t)) = dk (t)
ekof (enc(ek (t1 ), m, t2 )) = ek (t1)
ekof (garbageEnc(t1 , t2 )) = t1

ekofdk (dk (t1)) = ek (t1)

verify(vk (t1), sig(sk (t1), t2, t3)) = t2

issig(sig(sk (t1), t2, t3)) = sig(sk (t1), t2, t3)
issig(garbageSig (t1, t2)) = garbageSig (t1, t2)

isvk (vk (t1)) = vk (t1)

issk (sk (t)) = sk (t)

vkof (sig(sk (t1), t2, t3)) = vk (t1)
vkof (garbageSig (t1, t2)) = t1

vkofsk (sk (t1)) = vk (t1)

fst (pair (x, y)) = x
snd (pair (x, y)) = y
unstring 0(string 0(s)) = s
unstring 1(string 1(s)) = s
equals(t1, t1) = t1

Figure 1: Rules deﬁning the destructors. A destruc-
tor application matching none of these rules evalu-
ates to ⊥.

we traverse in this fashion is called a symbolic node trace
of the protocol. By specifying sets of node traces, we can
specify trace properties for a given protocol. We refer to [4]
for details on the protocol model and its semantics.

3. DEFINITIONS OF COMPUTATIONAL

SOUNDNESS

We now sketch how computational soundness is deﬁned.
For details, we refer to [4].
In order to say whether we
have computational soundness or not, we ﬁrst need to
specify a computational implementation A. Following [4],
this is done by specifying a partial deterministic function
AF : ({0, 1}∗)n → {0, 1}∗ for each constructor or destruc-
tor F/n.3 Also AN is an distribution of bitstrings modeling
the distribution of nonces. Given a computational imple-
mentation, we can execute a protocol in the computational
model. This execution is fully analogous to the symbolic
execution, except that in computation nodes, instead of ap-
plying constructors/destructors F to terms, we apply AF
to bitstrings, and in input/output nodes, we receive/send
bitstring from/to a polynomial-time adversary.

Definition 1

(Comput. soundn. – simplified [4]).

We say a computational implementation A is a computa-
tionally sound implementation of a symbolic model for a

3Probabilistic algorithms such as encryption are modeled
by an explicit additional argument that takes a nonce as
randomness.

701m ∈ S
S ⊢ m

N ∈ NE
S ⊢ N

S ⊢ t

t ∈ T

F ∈ C ∪ D
S ⊢ evalF (t)

evalF (t) 6= ⊥

Figure 2: Deduction rules for the symbolic model

A

τ

Sim

β

Π

Figure 3: A typical CoSP simulator

class P of protocols if the following holds with overwhelming
probability for any polynomial-time adversary A and any
protocol Π ∈ P : The node trace in the computational
protocol execution is a valid node trace in the symbolic
protocol execution.

4. COMPUTATIONAL

SOUNDNESS

PROOFS IN COSP

Before we proceed and present the computational assump-
tions, we ﬁrst give an overview on how prior computational
soundness proofs were conducted. Since we based our result
on the proof in the CoSP framework, we review the proof
as it was performed there [4]. The problems we will face are
not speciﬁc to their proof though.

Remember that in the CoSP framework, a protocol is
modeled as a tree whose nodes correspond to the steps of
the protocol execution; security properties are expressed as
sets of node traces. Computational soundness means that
for any polynomial-time adversary A the trace in the com-
putational execution is, except with negligible probability,
also a possible node trace in the symbolic execution. The
approach for showing this is to construct a so-called simu-
lator Sim. The simulator is a machine that interacts with a
symbolic execution of the protocol Π on the one hand, and
with the adversary A on the other hand; we call this a hy-
brid execution. (See Figure 3.) The simulator has to satisfy
the following two properties:

• Indistinguishability: The node trace in the hybrid ex-
ecution is computationally indistinguishable from that
in the computational execution with adversary A.

• Dolev-Yaoness: The simulator Sim never (except for
negligible probability) sends terms t to the protocol
with S 0 t where S is the list of terms Sim received
from the protocol so far.

The existence of such a simulator (for any A) then guar-
antees computational soundness: Dolev-Yaoness guarantees
that only node traces occur in the hybrid execution that are
possible in the symbolic execution, and indistinguishability
guarantees that only node traces occur in the computational
execution that can occur in the hybrid one.

How to construct a simulator? In [4], the simulator
Sim is constructed as follows: Whenever it gets a term
from the protocol, it constructs a corresponding bitstring
and sends it to the adversary, and when receiving a bit-
string from the adversary it parses it and sends the re-
sulting term to the protocol. Constructing bitstrings is

done using a function β, parsing bitstrings to terms us-
ing a function τ .
(See Figure 3.) The simulator picks
all random values and keys himself: For each protocol
nonce N , he initially picks a bitstring rN . He then trans-
lates, e.g., β(N ) := rN and β(ek (N )) := Aek (rN ) and
β(enc(ek (N ), t, M )) := Aenc(Aek (rN ), β(t), rM ). Translat-
ing back also is natural: Given m = rN , we let τ (m) := N ,
and if c is a ciphertext that can be decrypted as m using
Adk (rN ), we set τ (c) := enc(ek (N ), τ (m), M ). However, in
the last case, a subtlety occurs: what nonce M should we
use as symbolic randomness in τ (c)? Here we distinguish
two cases:

If c was earlier produced by the simulator: Then c was
the result of computing β(t) for some t = enc(ek (N ), t′, M )
and some nonce M . We then simply set τ (c) := t and have
consistently mapped c back to the term it came from.

If c was not produced by the simulator:

In this case
it is an adversary generated encryption, and M should
be an adversary nonce to represent that fact. We could
just use a fresh nonce M ∈ NE, but that would intro-
duce the need of additional bookkeeping:
If we compute
t := τ (c), and later β(t) is invoked, we need to make sure
that β(t) = c in order for the Sim to work consistently (for-
mally, this is needed in the proof of the indistinguishability
of Sim). And we need to make sure that when computing
τ (c) again, we use the same M . This bookkeeping can be
avoided using the following trick: We identify the adversary
nonces with symbols N m annotated with bitstrings m. Then
τ (c) := enc(ek (N ), τ (m), N c), i.e., we set M := N c. This
ensures that diﬀerent c get diﬀerent randomness nonces N c,
the same c is always assigned the same N c, and β(t) is easy
to deﬁne: β(enc(ek (N ), m, N c)) := c because we know that
enc(ek (N ), m, N c) can only have been produced by τ (c). To
illustrate, here are excerpts of the deﬁnitions of β and τ (the
ﬁrst matching rule counts):

• τ (c) := enc(ek (M ), t, N ) if c has earlier been output

by β(enc(ek (M ), t, N )) for some M ∈ N, N ∈ NP

• τ (c) := enc(ek (M ), τ (m), N c) if c is of type ciphertext
and τ (Aekof (c)) = ek (M ) for some M ∈ NP and m :=
Adec(Adk (rM ), c) 6= ⊥

• β(enc(ek (N ), t, M ))

:= Aenc(Aek (rN ), β(t), rM )

if

M ∈ NP

• β(enc(ek (M ), t, N m)) := m if M ∈ NP

Bitstrings m that cannot be suitably parsed are mapped into
terms garbage (N m) and similar that can then be mapped
back by β using the annotation m.

Showing indistinguishability. Showing indistinguisha-
bility essentially boils down to showing that the functions
β and τ consistently translate terms back and forth. More
precisely, we show that β(τ (m)) = m and τ (β(t)) = t. Fur-
thermore, we need to show that in any protocol step where
a constructor or destructor F is applied to terms t1, . . . , tn,
we have that β(F (t1, . . . , tn)) = AF (β(t1), . . . , β(tn)). This
makes sure that the computational execution (where AF is
applied) stays in sync with the hybrid execution (where F is
applied and the result is translated using β). The proofs of

702these facts are lengthy (involving case distinctions over all
constructors and destructors) but do not provide much addi-
tional insight; they are very important though because they
are responsible for most of the implementation conditions
that are needed for the computational soundness result.

Showing Dolev-Yaoness. The proof of Dolev-Yaoness is
where most of the actual cryptographic assumptions come
in.
In this sketch, we will slightly deviate from the orig-
inal proof in [4] for easier comparison with the proof in
the present paper. The diﬀerences are, however, inessential.
Starting from the simulator Sim, we introduce a sequence
of simulators Sim 2, Sim 4, Sim 7. (We use a numbering with
gaps here to be compatible with our full proof [7].)

In Sim 2, we change the function β as follows: When in-
voked as β(enc(ek (N ), t, M )) with M ∈ NP , instead of com-
puting Aenc(Aek (rN ), β(t), rM ), β invokes an encryption or-
acle ON
enc to produce the ciphertext c. Similarly, β(ek (N ))
returns the public key provided by the oracle ON
enc. The hy-
brid executions of Sim and Sim 2 are then indistinguishable.
(Here we use that the protocol conditions guarantee that no
randomness is used in two places.) Also, the function τ is
changed to invoke ON
enc whenever it needs to decrypt a ci-
phertext while parsing. Notice that if c was returned by β(t)
with t := enc(. . . ), then τ (c) just recalls the term t without
having to decrypt. Hence ON
enc is never asked to decrypt a
ciphertext it produced.

In Sim 4, we replace the encryption oracle ON

enc by a fake
encryption oracle ON
fake that encrypts zero-plaintexts instead
of the true plaintexts. Since ON
enc is never asked to decrypt a
ciphertext it produced, IND-CCA2 security guarantees that
the hybrid executions of Sim 2 and Sim 4 are indistinguish-
able. Since the plaintexts given to ON
fake are never used, we
can further change β(enc(N, t, M )) to never even compute
the plaintext β(t).

Finally, in Sim 7, we additionally change β to use a sign-
ing oracle in order to produce signatures. As in the case of
Sim 2, the hybrid executions of Sim 4 and Sim 7 are indistin-
guishable.

Since the hybrid executions of Sim and Sim 7 are indis-
tinguishable, in order to show Dolev-Yaoness of Sim, it is
suﬃcient to show Dolev-Yaoness of Sim 7.

The ﬁrst step to showing this is to show that whenever
Sim 7 invokes β(t), then S ⊢ t holds (where S are the terms
received from the protocol). This follows from the fact that
β is invoked on terms t0 sent by the protocol (which are then
by deﬁnition in S), and recursively descends only into sub-
terms that can be deduced from t0. In particular, in Sim 4 we
made sure that β(t) is not invoked by β(enc(ek (N ), t, M ));
t would not be deducible from enc(ek (N ), t, M ).

Next we prove that whenever S 0 t, then t contains a vis-
ible subterm tbad with S 0 tbad such that tbad is a protocol
nonce, or a ciphertext enc(. . . , N ) where N is a protocol
nonces, or a signature, or a few other similar cases. (Visibil-
ity is a purely syntactic condition and essentially means that
tbad is not protected by an honestly generated encryption.)
Now we can conclude Dolev-Yaoness of Sim 7: If it does
not hold, Sim 7 sends a term t = τ (m) where m was sent by
the adversary A. Then t has a visible subterm tbad . Visi-
bility implies that the recursive computation of τ (m) had a
subinvocation τ (mbad ) = tbad . For each possible case of tbad
we derive a contradiction. For example, if tbad is a proto-
col nonce, then β(tbad ) was never invoked (since S 0 tbad )

and thus mbad = rN was guessed by the simulator without
ever accessing rN which can happen only with negligible
probability. Other cases are excluded, e.g., by the unforge-
ability of the signature scheme and by the unpredictability
of encryptions. Thus, Sim 7 is Dolev-Yao, hence Sim is in-
distinguishable and Dolev-Yao. Computational soundness
follows.

5. RESTRICTIONS IN THE PROOF AND

HOW TO SOLVE THEM

The proof of computational soundness from [4] only works

if protocols obey the following restrictions:

• The protocol never sends a decryption key (not even

within a ciphertext).

• The protocol never decrypts using a decryption key it

received from the net.

• The protocol avoids key cycles (i.e., encryptions of de-
cryption keys using their corresponding encryptions
keys). This latter condition is actually already ensured
by never sending decryption keys, but we mention it
explicitly for completeness.

(Similar restrictions occur for signing keys in [4], however,
those restrictions are not due to principal issues, removing
them just adds some cases to the proof.)

We will now explain where these restrictions come from

and how we avoid them in our proof.

5.1 Sending secret keys

The ﬁrst restriction that we encounter in the above proof
is that we are not allowed to send secret keys. For example,
the following simple protocol is not covered by the above
proof:

Alice picks a encryption/decryption key pair (ek , dk ) and
publishes ek . Then Alice sends enc(ek , N ) for some fresh
nonce N . And ﬁnally Alice sends dk .

When applying the above proof to this protocol, the faking
simulator (more precisely, the function τ in that simulator)
will translate enc(ek , N ) into an encryption c of 0 (as op-
posed to an encryption of rN ). But then, when dk is sent
later by the symbolic protocol, the simulator would have to
send the corresponding computational decryption key. But
that would allow the adversary to decrypt c, and the adver-
sary would notice that c is a fake ciphertext.

The following solution springs to mind: We modify the
faking simulator such that he will only produce fake cipher-
texts when encrypting with respect to a key pair whose se-
cret key will never be revealed. Indeed, if we could do so,
it might solve our problem. However, in slightly more com-
plex protocols than our toy example, the simulator may not
know in advance whether a given secret key will be revealed
(this may depend on the adversary’s actions which in turn
may depend on the messages produced by the simulator). Of
course, we might let the simulator guess which keys will be
revealed. That, however, will only work when the number
of keys is logarithmic in the security parameter. Otherwise
the probability of guessing correctly will be negligible.4

(Notice also that the problem is also not solved if the sim-
ulator does not produce fake ciphertexts if in doubt: Then

4This is closely related to selective opening security (SOA)
[14]. However, although selective SOA addresses a similar
problem, it is not clear how SOA could be used to prove
computational soundness.

703our argument that the bitstring mbad is unguessable would
become invalid.)

To get rid of the restriction, we take a diﬀerent approach.
Instead of forcing the simulator to decide right away whether
a given ciphertext should be a fake ciphertext or not, we let
him decide this later. More precisely, we make sure that the
simulator can produce a ciphertext c without knowing the
plaintext, and later may “reprogram” the ciphertext c such
that it becomes an encryption of a message m of his choice.
(But not after revealing the secret key, of course.)

At the ﬁrst glance, this seems impossible. Since the ci-
phertext c may already have been sent to the adversary, c
cannot be changed.
It might be possible to have an en-
cryption scheme where for each encryption key, there can be
many decryption keys; then the simulator could produce a
special decryption key that decrypts c to whatever he wishes.
But simple counting arguments show that then the decryp-
tion key would need to be as long as the plaintexts of all
ciphertexts c produced so far together. This would lead to
a highly impractical scheme, and be impossible if we do not
impose an a-priori bound on the number of ciphertexts. (See
[32].)

However, we can get around this impossibility if we work
in the random oracle model. (In the following, we use the
word random oracle for any oracle chosen uniformly out of
a family of functions; thus also the ideal cipher model or the
generic group model fall under this term. The “standard”
random oracle [15] which is a uniformly randomly chosen
function from the set of all functions we call “random hash
oracle” for disambiguation.)

In the random oracle model, we can see the random oracle
as a function that is initially undeﬁned, and upon access,
the function table is populated as needed (lazy sampling).
This enables the following proof technique: When a certain
random oracle location has not been queried yet, we may
set it to a particular value of our choosing (this is called
“programming the random oracle”). In our case this can be
used to program a ciphertext c: As long as we make sure
that the adversary has not yet queried the random oracle at
the locations needed for decrypting c (e.g., because to ﬁnd
these locations he needs to know the secret key), we can
still change the value of the oracle at these locations. This
in turn may allow us to change the value that c decrypts to.
Summarizing, we look for an encryption scheme with the
following property: There is a strategy for producing (fake)
keys and ciphertexts, and for reprogramming the random
oracle (we will call this strategy the “ciphertext simulator”),
such that the following two things are indistinguishable:
(a) (Normally) encrypting a value m, sending the resulting
ciphertext c, and then sending the decryption key. (b) Pro-
ducing a fake ciphertext c. Choosing m. And sending the
decryption key.

Such a scheme could then be used in our computational
soundness proof: Sim 2 would encrypt messages m normally.
Sim 4 would produce fake ciphertexts c instead, and only
when revealing the decryption key, reprogram the cipher-
texts c to contain the right messages m. Then, we would
consider an additional simulator Sim 5 that does not even
compute m until it is needed. This will then allow us to
argue that the bitstring mbad corresponding to a “bad” sub-
term tbad cannot be guessed because the information needed
for guessing this bitstring was never computed/accessed.

A security deﬁnition for encryption schemes with the re-

quired properties has been presented in [35] (called PROG-
KDM), together with a natural construction satisfying the
deﬁnition. In the following, we present and explain their def-
inition and how it allows us to get computational soundness
for protocols sending secret keys.

In particular,

Formally deﬁning PROG-KDM security turns out to be
more complex than one might expect. We cannot just state
that the ciphertext simulator is indistinguishable from an
honest encryption oracle. The ciphertext simulator has a
completely diﬀerent interface from the honest encryption
oracle.
it expects the plaintext when be-
ing asked for the secret key, while the encryption oracle
would expect these upon encryption. To cope with this
problem, we deﬁne two “wrappers”, the real and the fake
challenger. The real challenger essentially gives us access to
the encryption algorithm while the fake challenger, although
it expects the plaintexts during encryption (to be indistin-
guishable from the real challenger), uses the plaintexts only
when the decryption key is to be produced. These two chal-
lengers should then be indistinguishable. (The challengers
additionally make sure that the adversary does not perform
any forbidden queries such as submitting a ciphertext for
decryption that was produced by the challenger.)

We ﬁrst deﬁne the real challenger. The real challenger
needs to allows us to query the encryption and decryp-
tion keys, to perform encryptions and decryptions, and to
give us access to the underlying random oracle. However,
if we only have these queries, situations like the follow-
ing would lead to problems: The adversary wishes to get
Enc(ek 1, Enc(ek 2, m)). We do not wish the adversary to
have to request Enc(ek 2, m) ﬁrst and then resubmit it for the
second encryption, because this would reveal Enc(ek 2, m),
and we might later wish to argue that Enc(ek 2, m) stays se-
cret. To be able to model such setting, we need to allow the
adversary to evaluate sequences of queries without reveal-
ing their outcome. For this, we introduce queries such as
R := encch(N, R1). This means: Take the value from regis-
ter R1, encrypt it with the key with index N ∈ {0, 1}∗, and
store the result in register R. Also, we need a query to apply
arbitrary functions to registers: R := evalch(C, R1, . . . , Rn)
applies the circuit C to registers R1, . . . , Rn. (This in par-
ticular allows us to load a ﬁxed value into a register by using
a circuit with zero inputs (n = 0). Finally, we have a query
revealch(R1) that outputs the content of a register.

Formally, the deﬁnition of the real challenger is the fol-

lowing:

Definition 2

(Real challenger). Fix an oracle O
and an encryption scheme (K, E, D) relative to that or-
acle. The real challenger RC is an interactive machine
deﬁned as follows. RC has access to the oracle O. RC
maintains a family (ek N , dk N )N∈{0,1}∗ of key pairs (ini-
tialized as (ek N , dk N ) ← K(1η) upon ﬁrst use), a family
(reg N )N∈{0,1}∗ of registers (initially all reg N = ⊥), and a
family of sets cipher N (initially empty). RC responds to the
following queries (when no answer is speciﬁed, the empty
word is returned):

• R := getekch(N ): RC sets reg R := ek N .
• R := getdkch(N ): RC sets reg R := dk N .
• R := evalch(C, R1, . . . , Rn) where C is a Boolean cir-
cuit:5 Compute m := C(reg R1 , . . . , reg Rn ) and set
reg R := m.

5Note that from the description of a circuit, it is possible to

704• R := encch(N, R1): Compute c ← EO(ek N , reg R1 ),

append c to cipher N , and set reg R := c.

• oraclech(x): Return O(x).
• decch(N, c): If c ∈ cipher N , return forbidden where
forbidden is a special symbol (diﬀerent from any bit-
string and from a failed decryption ⊥). Otherwise, in-
voke m ← DO(dk N , c) and return m.

• revealch(R1): Return reg R1 .

Here N and c range over bitstrings, R ranges over bitstrings
with reg R = ⊥ and the Ri range over bitstrings R with
reg Ri

6= ⊥.

Notice that the fact that we can do “hidden evaluations”
of complex expressions, also covers KDM security (security
under key-dependent messages): We can make a register
contain the computation of, e.g., Enc(ek , dk ) where dk is
the decryption key corresponding to ek .

We now proceed to deﬁne the fake challenger. The fake
challenger responds to the same queries, but computes the
plaintexts as late as possible. In order to do this, upon a
query such as R := encch(N, R1), the fake challenger just
stores the symbolic expression “encch(N, R1)” in register R
(instead of an actual ciphertext). Only when the content
of a register is to be revealed, the bitstrings are recursively
computed (using the function FCRetrieve below) by query-
ing the ciphertext simulator. Thus, before deﬁning the fake
challenger, we ﬁrst have to deﬁne formally what a ciphertext
simulator is:

A

deccs(c),

enccs(R, m),

Definition 3

(Ciphertext simulator).

ci-
phertext simulator CS for an oracle O is an inter-
active machine that responds to the following queries:
fakeenccs(R, l),
getekcs(),
getdkcs(), and programcs(R, m). Any query is answered
with a bitstring (except deccs(c) which may also return
⊥). A ciphertext simulator runs in polynomial-time in
the total
length of the queries. A ciphertext simulator is
furthermore given access to an oracle O. The ciphertext
simulator is also allowed to program O (that is, it may
perform assignments of the form O(x) := y). Furthermore,
the ciphertext simulator has access to the list of all queries
made to O so far.6

The interesting queries here are fakeenccs(R, l) and
programcs(R, m). A fakeenccs(R, l)-query is expected to
return a fake ciphertext for an unspeciﬁed plaintext of
length l (associated with a handle R). And a subsequent
programcs(R, m)-query with |m| = l is supposed to pro-
gram the random oracle such that decrypting c will return
m. The ciphertext simulator expects to get all necessary
programcs(R, m)-queries directly after a getdkcs()-query re-
vealing the key. (Formally, we do not impose this rule, but
the PROG-KDM does not guarantee anything if the cipher-
text simulator is not queried in the same way as does the
fake challenger below.) We stress that we allow to ﬁrst ask
for the key and then to program. This is needed to handle
key dependencies, e.g., if we wish to program the plaintext to
be the decryption key. The deﬁnition of the fake challenger
will make sure that although we reveal the decryption key

determine the length of its output. This will be important
in the deﬁnition of FCLen below.
6Our scheme will not make use of the list of the queries to
O, but for other schemes this additional power might be
helpful.

before programming, we do not use its value for anything
but the programming until the programming is done.

Note that we do not ﬁx any concrete behavior of the ci-
phertext simulator since our deﬁnition will just require the
existence of some ciphertext simulator.

We can now deﬁne the real challenger together with its

recursive retrieval function FCRetrieve:

Definition 4

(Fake challenger). Fix an oracle O,
a length-regular encryption scheme (K, E, D) relative to that
oracle, and a ciphertext simulator CS for O. The fake chal-
lenger FC for CS is an interactive machine deﬁned as fol-
lows. FC maintains the following state:

• A family

• A family of instances (CSN )N∈{0,1}∗ of CS (initial-
ized upon ﬁrst use). Each ciphertext simulator is given
(read-write) oracle access to O.
of

(initially
all reg R = ⊥).
Registers reg N are either un-
deﬁned (reg N = ⊥), or bitstrings, or queries
(written
or
“evalch(C, R1, . . . , Rn)” etc.).

(reg R)R∈{0,1}∗

“getekch(N )”

“getdkch(N )”

registers

or

• A family (cipher N )N∈{0,1}∗ of sets of bitstrings. (Ini-

tially all empty.)

FC answers to the same queries as the real challenger, but
implements them diﬀerently:

• R := getekch(N ) or R := getdkch(N ) or R :=
evalch(C, R1, . . . , Rn) or R := encch(N, R1): Set
reg R := “getekch(N )” or reg R := “getdkch(N )”
or reg R := “evalch(C, R1, . . . , Rn)” or reg R :=
“encch(N, R1)”, respectively.

• decch(N, c): If c ∈ cipher N , return forbidden. Other-
wise, query deccs(c) from CSN and return its response.

• oraclech(x): Return O(x).
• revealch(R1): Compute m ← FCRetrieve(R1).
(FCRetrieve is deﬁned below in Deﬁnition 5.) Return
m.

Definition 5

(Retrieve function of FC). The re-
trieve function FCRetrieve has access to the registers reg R
and the ciphertext simulators CSN of FC.
It additionally
stores a family (plainN )N∈{0,1}∗ of lists between invocations
(all plainN are initially empty lists). FCRetrieve takes an
argument R (with reg R 6= ⊥) and is recursively deﬁned as
follows:

• If reg R is a bitstring, return reg R.
• If reg R = “getekch(N )”: Query CSN with getekcs().

Store the answer in reg R. Return reg R.

• If reg R = “evalch(C, R1, . . . , Rn)”: Compute mi
FCRetrieve(Ri) for i = 1, . . . , n. Compute m′
C(m1, . . . , mn). Set reg R := m′. Return m′.

:=
:=

• If reg R = “encch(N, R1)” and there was no getdkcs()-
query to CSN yet: Compute l := FCLen(R1). (FCLen
is deﬁned in Deﬁnition 7 below.) Query CSN with
fakeenccs(R, l). Denote the answer with c.
Set
reg R := c. Append (R 7→ R1) to the list plainN . Ap-
pend c to cipher N . Return c.

• If reg R = “encch(N, R1)” and there was a getdkcs()-
query to CSN : Compute m := FCRetrieve(R1).
Query CSN with enccs(R, m). Denote the answer with
c. Set reg R := c. Append (R 7→ R1) to plainN . Ap-
pend c to cipher N . Return c.

• If reg R = “getdkch(N )”: Query CSN with getdkcs().
Store the answer in reg R.
this was the ﬁrst
getdkcs(N )-query for that value of N , do the following

If

705for each (R′ 7→ R′
in the list):

1) ∈ plain N (in the order they occur

– Invoke m := FCRetrieve(R′
– Send the query programcs(R′, m) to CSN .

1).

Finally, return reg R.

The retrieve function uses the auxiliary function FCLen
that computes what length a bitstring associated with a
register should have. This function only makes sense if we
require the encryption scheme to be length regular, i.e., the
length of the output of the encryption scheme depends only
on the lengths of its inputs.

Definition 6

(Length regular encryption scheme).

An encryption scheme (K, E, D) is length-regular if there
are functions ℓek , ℓdk , ℓc such that for all η ∈  and all
m ∈ {0, 1}∗ and for (ek , dk ) ← K(1η) and c ← E(ek , m)
we have |ek | = ℓek (η) and |dk | = ℓdk (η) and |c| = ℓc(η, |m|)
with probability 1.

Definition 7

(Length function of FC). The

length function FCLen has (read-only) access to the registers
reg R of FC. FCLen takes an argument R (with reg R 6= ⊥)
and is recursively deﬁned as follows:

• If reg R is a bitstring, return |reg R|.
• If reg R = “evalch(C, R1, . . . , Rn)”: Return the length
of the output of the circuit C. (Note that the length
of the output of a Boolean circuit is independent of its
arguments.)

• If reg R = “getekch(N )” or reg R = “getdkcs(N )”: Let
ℓek and ℓdk be as in Deﬁnition 6. Return ℓek (η) or
ℓdk (η), respectively.

• If reg R = “encch(N, R1)”: Let ℓc be as in Deﬁnition 6.

Return ℓc(η, FCLen(R1)).

We are now ﬁnally ready to deﬁne PROG-KDM security:

Definition 8

(PROG-KDM security). A

length-
regular encryption scheme (K, E, D) (relative to an oracle
O) is PROG-KDM secure iﬀ there exists a ciphertext simu-
lator CS such that for all polynomial-time oracle machines
A,7 Pr[ARC(1η) = 1] − Pr[AFC(1η) = 1] is negligible in η.
Here RC is the real challenger for (K, E, D) and O and FC
is the fake challenger for CS and O. Notice that A does not
directly query O.

which does not use the real challenger any more, but di-
rectly accesses the ciphertext simulator (in the same way
as the fake challenger would). Sim 5 is then indistinguish-
able from Sim 2, but, since the fake challenger performed all
computations on when needed, Sim 2 now also performs all
computations only when actually needed. This has the eﬀect
that in the end, we can show that the bitstring mbad rep-
resents a contradiction because it guesses values that were
never accessed.

[35] shows that PROG-KDM security can be achieved us-
ing a standard construction, namely hybrid encryption us-
ing any CCA2-secure key encapsulation mechanism, a block
cipher (modeled as an ideal cipher) in CBC-mode, and
encrypt-then-MAC with an arbitrary one-time MAC.

We have now removed the restriction that a protocol may
not send its decryption keys. (And in one go, we also enabled
key-cycles because PROG-KDM covers that case, too.) It
remains to remove the restriction that we cannot use de-
cryption keys received from the adversary,

The need for PROG-KDM security. The question that
arises in this context is whether we actually need such a
strong notion as PROG-KDM in this context. Obviously,
IND-CCA2 security alone is not suﬃcient, there are schemes
that are IND-CCA2 secure and break down in the presence
of key-cycles.8 But what about, e.g., KDM-CCA2 [18] that
covers key dependent messages and active attacks?

To illustrate the necessity of a notion stronger than KDM-
CCA2, consider the following example: Assume a protocol
in which we want to share a secret s with n parties in such a
way that n/2 parties are needed to recover the secret s. We
do this by distributing n decryption keys to the n parties,
and by producing a number of nested encryptions such that
n/2 − 1 of the decryption keys are not suﬃcient to recover
s. More precisely, we use the following protocol:9

• The dealer D chooses a nonce s and n key pairs

(ek i, dk i).

• D chooses additional key pairs (ek i,j , dk i,j) for i =

0, . . . , n/2 and j = 0, . . . , n.

• D

ei,j

computes

←
Enc(ek j , (Enc(ek i−1,0, dk i,j ), . . . , Enc(ek i−1,j−1, dk i,j)))
for all i = 1, . . . , n/2, j = 1, . . . , n, and publishes
all ei,j, dk 0,j .
(dk i,j can then be computed if dk j
is known and at least i keys from dk 1, . . . , dk j are
known.)

If we assume that the computational implementation of
ek , dk , enc, dec is a PROG-KDM secure encryption scheme,
we can make the proof sketched in Section 4 go through even
if the protocol may reveal its decryption keys: The simulator
Sim 2 uses the real challenger to produce the output of β. He
does this by computing all of β(t) inside the real challenger
(using queries such as R := evalch(C, . . . )). Then Sim 4 uses
the fake challenger instead. By PROG-KDM security, Sim 2
and Sim 4 are indistinguishable. But Sim 4 still provides all
values needed in the computation early (because the real
challenger needs them early). But we can then deﬁne Sim 5

7Here we consider A polynomial-time if it runs a polynomial
number of steps in η, and the number of steps performed
by RC or FC is also polynomially-bounded. This additional
requirement is necessary since for an encryption scheme with
multiplicative overhead (say, length-doubling), a sequence of
queries Ri := encch(N, Ri−1) of polynomial length will lead
to the computation of an exponential-length ciphertext.

• D computes ej ← Enc(ek n/2,j , s) for j = 1, . . . , n, and

publishes all ej.
(s can then be computed if dk n/2,j is known for some j.
Thus, s can be computed if n/2 of the dk j are known.)
• The adversary may choose n/2 − 1 indices j ∈
{1, . . . , n}, and D sends dk j for each of the selected j.

• The adversary wins if he guesses the secret nonce s.

It is easy to see that given n/2 keys dk j , one can recover
s. But in a reasonable symbolic model (e.g., the one from

8Take,
e.g., an IND-CCA2 secure encryption scheme
(KeyGen, Enc, Dec) and modify it such that Enc(ek , dk ) :=
dk if ek and dk are a valid key pair, and let Dec(dk , dk ) :=
dk . It is easy to see that the modiﬁed scheme is still IND-
CCA2 secure, but the key cycle Enc(ek , dk ) reveals the de-
cryption key.
9A simpler protocol would be
:=
Enc(dk i1 , . . . Enc(dk in/2 , s) . . . ) for each set I = {i1, . . . , in/2
of size n/2. But that protocol would need to send an expo-
nential number of ciphertexts I.

to publish eI

706Section 2), the adversary cannot win.10 So a computational
soundness result without restrictions on sending and en-
crypting decryption keys would imply that the protocol is
secure in the computational setting. Hence any security no-
tion that allows us to derive the computational soundness
result must also be suﬃcient to show that the protocol is
secure in a computational setting. (Notice that situations
similar to the one in this protocol could occur, e.g., if we
enforce some complex authorization policy by a suitable set
of nested encryptions.)

But it seems that IND-CCA2 or KDM-CCA2 security
does not allow us to prove the security of this protocol. In a
proof using one of these notions, one typically ﬁrst deﬁnes a
game G1 which models an execution of the protocol. Then
one deﬁnes a modiﬁed game G2 in which some of the ci-
phertexts are replaced by encryptions of 0. Then one uses
IND-CCA2 or KDM-CCA2 to show that G1 and G2 are
indistinguishable. Finally, one uses that in game G2, the
secret s is never accessed, because we have replaced all oc-
currences of s by 0.
If we would know in advance which
keys dk j the adversary requests, this proof would indeed go
through. However, the selection of the dk j by the adver-
sary can be done adaptively, even depending on the values
of the ei,j . (E.g., the adversary could produce a hash of all
protocol messages and use the bits in the hash value to de-
cide which keys to reveal.) Hence, when encrypting, we do
not know yet which ciphertexts will be opened. Since there
are an exponential number of possibilities, we cannot guess.
There seems to be no other way of choosing which cipher-
texts should be 0-encryptions. Because of this, IND-CCA2
and KDM-CCA2 seem unapplicable for this protocol.11

Also notions such as IND-SO-CPA and SIM-SO-CPA
which are designed for situations with selective opening of
ciphertexts (cf. [17]) do not seem to match this protocol.
Possibly extensions of these notions might cover this case,
but it is not clear what these extensions should look like (in
particular if we extend the protocol such that some of the
ei,j may depend on other ei,j , e.g., by including the latter
in some of the plaintexts of the former).

So, it seems that the only known security notion for en-
cryption schemes that can show the security of the above
protocol is PROG-KDM. Thus it is not surprising that we
need to use PROG-KDM security in our proof.

5.2 Receiving decryption keys

The second restriction we face in the proof sketched in
Section 4 is that a protocol is not allowed to receive decryp-
tion keys. This is due to the way the simulator Sim parses
a bitstring into a term (using the function τ ): When receiv-
ing a ciphertext c for which the decryption key d is known,
Sim computes τ (c) := enc(ek (N e), τ (m), N c) where m is
the plaintext of c and e the corresponding encryption key.
If d is not known (because c was produced by the adver-
sary with respect to a key that the protocol did not pick),
10Proof sketch: Fix a set I ⊆ {dk 1, . . . , dk n}. Let S :=
{ej , ei,j, dk 0,j } ∪ I. By induction over i, we have that S ⊢
dk i,j implies |I ∩ {dk 1, . . . , dk j}| ≥ i. If S ⊢ s there is a j
with S ⊢ dk n/2,j , and hence |I| ≥ |I ∩{dk 1, . . . , dk j}| ≥ n/2.
So S ⊢ s only if |I| ≥ n/2, i.e., the adversary can only
recover s by requesting at least n/2 keys.
11Of course, this is no proof that these notions are indeed
insuﬃcient. But it shows that at least natural proof ap-
proaches fail. We expect that an impossibility result relative
to some oracle can be proven but we have not done so.

Sim computes τ (c) := garbageEnc(ek (N e), N c). Notice that
in the latter case we are cheating: even though c may be
a valid ciphertext (just with respect to an encryption key
whose decryption key we do not know), we declare it to be
an invalid ciphertext. But the fact that we will never use
the decryption key saves us: we will never be caught in a
lie. The situation is diﬀerent if we receive decryption keys
from the adversary. Then the adversary might ﬁrst send
c which we parse to garbageEnc(ek (N e), N c). Then later
he sends us the corresponding decryption key d which we
parse to dk (N e). But then in the computational execution,
decrypting c using d works, while in the hybrid execution,
decrypting garbageEnc(ek (N e), N c) necessarily fails.

So if we allow the protocol to receive decryption keys,
we need to change the simulator so that it parses τ (c) :=
enc(ek (N e), t, N c) when receiving a valid ciphertext c, even
if the he cannot decrypt c. But then, how should the simu-
lator compute the term t? And for that matter, how should
the simulator know that c is valid? (It might be invalid, and
then should be parsed as garbageEnc(ek (N e), N c).)

A solution for this problem has been proposed in the ﬁrst
revision of [5] (not contained in later versions!) but has not
been applied there. The idea is to allow the simulator to
partially parse terms (lazy simulator). That is, we allow
the simulator to output terms that contain variables, and
to only after the hybrid execution we ask the simulator to
decide what terms these variables stand for.

In our case, we change the simulator such that when pars-
ing a ciphertext c (corresponding to a key not picked by the
simulator), the simulator just outputs τ (c) := xc.
(Here
we assume an inﬁnite set of variables x indexed by cipher-
texts.) And in the end, when the hybrid execution ﬁnished,
the simulator outputs a “ﬁnal substitution” ϕ that maps xc
to either enc(N e, τ (m), N c) if by the end of the execution
the simulator has learned the corresponding decryption key
and can compute the plaintext m, or to garbageEnc(N e, N c)
if the decryption key was not received or decryption fails.

Unfortunately, to make this go through, the simulator gets
an additional tasks. In the original hybrid execution, terms
sent to the protocol do not contain variables, and whenever
we reach a computation node in the protocol, we can ap-
ply the constructor or destructor to the arguments of that
node and compute the resulting new term. This is not pos-
sible any more. For example, what would be the output a
dec-node with plaintext argument xc? Thus, the hybrid ex-
ecution will in this case just maintain a “destructor term”, in
which the destructors are not evaluated. (E.g., a node might
then store the term dec(dk (N e), xc).) That leaves the fol-
lowing problem: A computation node branches to its yes- or
no-successor depending on whether constructor/destructor
application succeeds or fails. But in the hybrid execution,
the constructor/destructor application is not evaluated, we
do not know whether it succeeds or fails. This leads to an
additional requirement for the simulator: After each compu-
tation node in the hybrid execution, the simulator is asked
a “question”. This question consists of the destructor term
that is computed at the current node, and the simulator
has to answer yes or no, indicating whether the application
should be considered to have succeeded or failed. (And then
the yes- or no-successor of the current node is taken accord-
ingly.)

In our case, to answer these questions, the simulator will
just reduce the term as much as possible (by evaluating de-

707structors), replace variables xc by enc- or garbageEnc-terms
wherever we already know the necessary keys, and make the
“right” choices when destructors are applied to xc. If all de-
structors succeed, the simulator answers yes. A large part of
the full proof is dedicated to showing that this can be done
in a consistent fashion.

In [5], it is shown that if a lazy simulator with the fol-
lowing four properties (sketched below) exists, then we have
computational soundness:

• Indistinguishability: The hybrid and the computa-
tional execution are indistinguishable (in terms of the
nodes passed through in execution).

• DY-ness: Let ϕ be the ﬁnal substitution (output by
the simulator at the end of the execution). Then in
any step of the execution it holds that Sϕ ⊢ tϕ where
t is the term sent by the simulator to the protocol, and
S is the set of the terms received by the protocol (note
that although S, t may be destructor terms, Sϕ and tϕ
do not contain variables any more and thus reduce to
regular terms without destructors).

• Consistency: For any question Q that was asked from
the simulator, we have that the simulator answered yes
iﬀ evaluating Qϕ (which contains destructors but no
variables) does not return ⊥.

• Abort-freeness: The simulator does not abort.
In the proof we construct such a simulator and show all the
properties above. (Indistinguishability is relatively similar
to the case without lazy parsing, but needs some additional
care because the invariants need to be formulated with re-
spect to unevaluated destructor terms. DY-ness follows the
same lines but becomes considerably more complicated.)

In the proof of DY-ness, it does, however, turn out that
lazy sampling does not fully solve the problem of receiving
decryption keys. In fact, PROG-KDM security alone is not
suﬃcient to guarantee computational soundness in this case
(and neither is IND-CCA2). We illustrate the problem by
an example protocol:

Alice picks a key ek (N ), a nonce M and sends a cipher-
text c := enc(ek (N ), M, R) over the network (i.e., to the
adversary). Then Alice expects a ciphertext c∗. Then Alice
sends dk (N ). Then Alice expects a secret key sk ∗. Finally,
Alice tests whether dec(sk ∗, c∗) = (M, M ).

It is easy to see that in the symbolic model, this test will
always fail. But in the computational setting, it is possible
to construct encryption schemes with respect to which the
adversary can produce c∗, sk ∗ such that this test succeeds:
Start with a secure encryption scheme (KeyGen′, Enc′, Dec′).
Then let KeyGen := KeyGen′, and Enc := Enc′, but mod-
ify Dec′ as follows: Given a secret key of the form sk =
(special, m), and a ciphertext c = (special), Dec(sk , c)
outputs m. On other inputs, Dec behaves like Dec′. Now the
adversary can break the above protocol by sending sk ∗ :=
(special, (M, M )). Notice that if (KeyGen′, Enc′, Dec′) was
PROG-KDM (or IND-CCA2), then (KeyGen, Enc, Dec) is
still PROG-KDM (or IND-CCA2): Both deﬁnitions say
nothing about the behavior of the encryption scheme for
dishonestly generated keys.

Of course, the above encryption scheme can easily be ex-
cluded by adding simple conditions on encryption schemes:
Encryption keys should uniquely determine decryption keys
and vice versa, any valid decryption key should successfully
decrypt any ciphertext that was honestly generated using

the corresponding encryption key, ciphertexts should deter-
mine their encryption key.

But even then a more complex construction works: Let
C be some class of circuits such that for each C ∈ C,
there exists at most one x, y such that C(x, y) = 1. Let
KeyGen := KeyGen′. Modify Enc′ as follows: Upon input
ek = (special, ek ′, C), Enc(ek , m) runs Enc′(ek ′, m). For
other inputs, Enc behaves like Enc′. And Dec′
is modi-
ﬁed as follows: Upon input dk = (special, dk ′, C, x, y) and
c = (special, ek ′, C) with C(x, y) = 1, Dec(dk , c) returns x.
Upon dk = (special, dk ′, C, x, y) with C(x, y) = 1 and dif-
ferent c, Dec(dk , c) returns Dec′(dk ′, c). And upon all other
inputs, Dec′ behaves like Dec. Again, this construction does
not loose PROG-KDM or IND-CCA2 security.

The adversary can break our toy protocol by choosing
C as the class of circuits Cc deﬁned by Cc((M, M ), sk ) =
1 if Dec(sk , c) = M and Cc(x, y) = 0 in all other
cases.
the adversary chooses
(ek ′, dk ′) ← KeyGen′, c∗ := (special , ek ′, Cc) and after re-
ceiving a decryption key dk from Alice, he chooses dk ∗ :=
(special , dk ′, Cc, (M, M ), dk ).

Then after getting c,

Notice that this example can be generalized to many dif-
ferent protocols where some m is uniquely determined by
the messages sent by Alice, and the adversary learns m only
after producing c but before sending the corresponding de-
cryption key: Simply choose a diﬀerent class C of circuits
such that C(m, x) = 1 is a proof that m is the message
encoded by Alice.

Clearly, the above example shows that PROG-KDM alone
does not imply computational soundness. To understand
what condition we need,
let us ﬁrst understand where
the mismatch between the symbolic and the computational
model is.
In the symbolic model, the adversary can only
produce an encryption of some message if he knows the un-
derlying plaintext.
In the computational model, however,
even if we require unique decryption keys, it is suﬃcient
that the underlying plaintext is ﬁxed, it is not necessary
that the adversary actually knows it.

Thus, to get computational soundness, we need to ensure
that the adversary actually knows the plaintext of any mes-
sage he produces. A common way for modeling knowledge is
to require that we can extract the plaintext from the adver-
sary. Since we work in the random oracle model anyway (as
PROG-KDM only makes sense there), we use the following
random-oracle based deﬁnition:12

call

an

Definition 9. We

scheme
encryption
for any
(KeyGen, Enc, Dec) malicious-key extractable if
polynomial-time (A1, A2),
there exists a polynomial-time
algorithm MKE (the malicious-key-extractorsuch that the
following probability is negligible:

Pr(cid:2)DecO(d, c) 6= ⊥ ∧ DecO(d, c) /∈ M : (z, c) ← AO

M ← MKE O(1η, c, queries), d ← AO

1 (1η),
2 (1η, z)(cid:3)

Here O is a random oracle. And queries is the list of all
random oracle queries performed by A1. And M is a list of
messages (of polynomial length).

This deﬁnition guarantees that when the adversary pro-

12This is closely related to the notion of plaintext-awareness
[16], except that plaintext-awareness applies only to the case
of honestly generated keys.

708duces a decryption key d that decrypts c to some message
m, then he must already have known m while producing c.
Notice that malicious-key extractability is easy to achieve:
Given a PROG-KDM secure encryption scheme, we mod-
ify it so that instead of encrypting m, we always encrypt
(m, H(m)) where H is a random hash oracle (and decryp-
tion checks the correctness of that hash value). The re-
sulting scheme does not loose PROG-KDM security and is
malicious-key extractable.

In Deﬁnition 9, we only require that the extractor can
output a list of plaintexts, one of which should be the cor-
rect one. We could strengthen the requirement and require
the extractor to output only a single plaintext. This deﬁni-
tion would considerably simplify our proof (essentially, we
could get rid of lazy sampling since we can decrypt all ad-
versary generated ciphertexts). However, that stronger def-
inition would, for example, not be satisﬁed by the scheme
that simply encrypts (m, H(m)). Since we strive for mini-
mal assumptions, we opt for the weaker deﬁnition and the
more complex proof instead.

How is malicious-key extractability used in the proof of
computational soundness? We extend the simulator to call
the extractor on all ciphertexts he sees (Sim 3). In the origi-
nal proof, a simulator that is not DY implied that a term t
with Sϕ 0 tϕ is produced by τ in some step i. This means
that tϕ has a “bad” subterm tbad . This, however, does not
immediately lead to a contradiction, because tbad could be
a subterm not of t, but of ϕ(xc) for some variable xc in
t. Since ϕ(xc) is produced at some later point, we cannot
arrive at a contradiction (because the bitstring mbad which
is supposed to be unguessable in step i, might already have
been sent in step j). But if the simulator runs the malicious-
key extractor in step i, we can conclude that the bitstring
mbad corresponding to the subterm tbad of ϕ(xc) has already
been seen during step i. This then leads to a contradiction
as before.

6. THE MAIN RESULT

We are now ready to state the main result of this paper.
First, we state the conditions a symbolic protocol should
satisfy.

Definition 10. A CoSP protocol is randomness-safe if it

satisﬁes the following conditions:

1. The argument of every ek -, dk -, vk -, and sk -
computation node and the third argument of every E-
and sig-computation node is an N -computation node
with N ∈ NP . (Here and in the following, we call the
nodes referenced by a protocol node its arguments.) We
call these N -computation nodes randomness nodes.
Any two randomness nodes on the same path are an-
notated with diﬀerent nonces.

2. Every computation node that is the argument of an
ek -computation node or of a dk -computation node on
some path p occurs only as argument to ek - and dk -
computation nodes on that path p.

3. Every computation node that is the argument of a vk -
computation node or of an sk -computation node on
some path p occurs only as argument to vk - and sk -
computation nodes on that path p.

4. Every computation node that is the third argument of
an E-computation node or of a sig-computation node

on some path p occurs exactly once as an argument in
that path p.

5. There are no computation nodes with the constructors

garbage , garbageEnc, garbageSig , or N ∈ NE.

In contrast to [4], we do not put any restrictions on the
use of keys any more. The requirements above translate to
simple syntactic restrictions on the protocols that require
us to use each randomness nonce only once. For example,
in the applied π-calculus, this would mean that whenever
we create a term enc(e, p, r), we require that r is under a
restriction νr and used only here.

In addition to randomness-safe protocols, we put a num-
ber of conditions on the computational implementation. The
cryptographically relevant conditions are PROG-KDM se-
curity and malicious-key extractability of the encryption
scheme, and strong existential unforgeability of the signature
scheme. In addition, we have a large number of additional
conditions of syntactic nature, e.g., that the pair-constructor
works as expected, that from a ciphertext one can eﬃciently
compute the corresponding encryption key, or that an en-
cryption key uniquely determines its decryption key. These
requirements are either natural or can be easily achieved by
suitable tagging (e.g., by tagging ciphertexts with their en-
cryption keys). The full list of implementation conditions is
given in Appendix A.

Theorem 1. The implementation A (satisfying the im-
plementation conditions from Appendix A) is a computa-
tionally sound implementation of the symbolic model from
Section 2 for the class of randomness-safe protocols. (Note
that our deﬁnition of computational soundness covers trace
properties, not equivalence properties.)

The full proof of this theorem is given in [7]. From this
result, we get, e.g., immediately computational soundness
in the applied π-calculus (see [4]) without the restrictions
on keys imposed there.

Acknowledgments. Dominique Unruh was supported by
the Cluster of Excellence “Multimodal Computing and Inter-
action”, by the European Social Fund’s Doctoral Studies and
Internationalisation Programme DoRa, by the European Re-
gional Development Fund through the Estonian Center of
Excellence in Computer Science, EXCS, by the European
Social Fund through the Estonian Doctoral School in In-
formation and Communication Technology. Michael Backes
was supported by CISPA (Center for IT-Security, Privacy
and Accountability), and by an ERC starting grant. Part
of the work was done while Ankit Malik was at MPI-SWS,
and while Dominique Unruh was at the Cluster of Excellence
“Multimodal Computing and Interaction”.

APPENDIX

A.

IMPLEMENTATION CONDITIONS

1. A is an implementation of M in the sense of [4] (in par-
ticular, all functions Af (f ∈ C ∪ D) are polynomial-
time computable).

2. There are disjoint and eﬃciently recognizable sets of
bitstrings representing the types nonces, ciphertexts,
encryption keys, decryption keys, signatures, veriﬁca-
tion keys, signing keys, pairs, and payload-strings. The

709set of all bitstrings of type nonce we denote Noncesk.13
(Here and in the following, k denotes the security pa-
rameter.)

3. The functions Aenc, Aek , Adk , Asig , Avk , Ask , and Apair
are length-regular. We call an n-ary function f length
regular if |mi| = |m′
i| for i = 1, . . . , n implies |f (m)| =
|f (m′)|. All m ∈ Noncesk have the same length.

4. AN for N ∈ N returns a uniformly random r ∈

Noncesk.

5. Every image of Aenc is of type ciphertext, every image
of Aek and Aekof is of type encryption key, every image
of Adk is of type decryption key, every image of Asig is
of type signature, every image of Avk and Avkof
is of
type veriﬁcation key, every image of Aempty , Astring 0 ,
and Astring 1 is of type payload-string.

{0, 1}∗

we

∈

all m1, m2

have
Afst (Apair (m1, m2)) = m1 and Asnd (Apair (m1, m2)) =
m2. Every m of type pair is in the range of Apair . If
m is not of type pair, Afst (m) = Asnd (m) = ⊥.
payload-string

type

all m of
that Aunstringi (Astringi (m))

we
have
= m and
Aunstringi (Astringj (m)) = ⊥ for i, j ∈ {0, 1}, i 6= j.
For m = empty or m not of type payload-string,
Aunstring0 (m) = Aunstring1 (m) = ⊥. Every m of type
payload-string is of the form m = Astring 0 (m′) or
m = Astring 1 (m′) or m = empty for some m′ of type
payload-string. For all m of type payload-string, we
have |Astring 0 (m)|, |Astring 1 (m)| > |m|.

6. For

7. For

8. Aekof (Aenc(p, x, y)) = p for all p of type encryption
key, x ∈ {0, 1}∗, y ∈ Noncesk. Aekof (e) 6= ⊥ for any e
of type ciphertext and Aekof (e) = ⊥ for any e that is
not of type ciphertext.

9. Avkof (Asig (Ask (x), y, z)) = Avk (x) for all y ∈ {0, 1}∗,
x, z ∈ Noncesk. Avkof (e) 6= ⊥ for any e of type sig-
nature and Avkof (e) = ⊥ for any e that is not of type
signature.

10. Aenc(p, m, y) = ⊥ if p is not of type encryption key.
11. Adec(Adk (r), m) = ⊥ if r ∈ Noncesk and Aekof (m) 6=
(This implies that the encryption key is

Aek (r).
uniquely determined by the decryption key.)

12. Adec(d, c) = ⊥ if Aekof (c) 6= Aekofdk (d) or Aekofdk (d) =

⊥.

13. Adec(d, Aenc(Aekofdk (e), m, r)) = m if r ∈ Noncesk and

d := Aekofdk (e) 6= ⊥.

14. Aekofdk (d) = ⊥ if d is not of type decryption key.
15. Aekofdk (Adk (r)) = Aek (r) for all r ∈ Noncesk.
16. Avkofsk (s) = ⊥ if s is not of type signing key.
17. Avkofsk (Ask (r)) = Avk (r) for all r ∈ Noncesk.
18. Adec(Adk (r), Aenc(Aek (r), m, r′)) = m for all r, r′ ∈

Noncesk.

19. Averify (Avk (r), Asig (Ask (r), m, r′)) = m for all r, r′ ∈

Noncesk.

20. For all p, s ∈ {0, 1}∗ we have that Averify (p, s) 6= ⊥

implies Avkof (s) = p.

21. Aisek (x) = x for any x of type encryption key.

Aisek (x) = ⊥ for any x not of type encryption key.

22. Aisvk (x) = x for any x of type veriﬁcation key.

Aisvk (x) = ⊥ for any x not of type veriﬁcation key.

23. Aisenc(x) = x for any x of type ciphertext. Aisenc(x) =

⊥ for any x not of type ciphertext.

13This would typically be the set of all k-bit strings with a
tag denoting nonces.

24. Aissig (x) = x for any x of type signature. Aissig (x) = ⊥

for any x not of type signature.

25. We deﬁne an encryption scheme (KeyGen, Enc, Dec) as
follows: KeyGen picks a random r ← Noncesk and re-
turns (Aek (r), Adk (r)). Enc(p, m) picks a random r ←
Noncesk and returns Aenc(p, m, r). Dec(k, c) returns
Adec(k, c). We require that then (KeyGen, Enc, Dec) is
PROG-KDM secure.

26. Additionally, we require that (KeyGen, Enc, Dec) is

malicious-key extractable.

27. We deﬁne a signature scheme (SKeyGen, Sig, Verify) as
follows: SKeyGen picks a random r ← Noncesk and
returns (Avk (r), Ask (r)).
Sig(p, m) picks a random
r ← Noncesk and returns Asig (p, m, r). Verify(p, s, m)
returns 1 iﬀ Averify (p, s) = m. We require that then
(SKeyGen, Sig, Verify) is strongly existentially unforge-
able.

28. For all e of type encryption key and all m, m′ ∈ {0, 1}∗,
the probability that Aenc(e, m, r) = Aenc(e, m′, r′) for
uniformly chosen r, r′ ∈ Noncesk is negligible.

29. For all rs ∈ Noncesk and all m ∈ {0, 1}∗, the probabil-
ity that Asig (Ask (rs), m, r) = Asig (Ask (rs), m, r′) for
uniformly chosen r, r′ ∈ Noncesk is negligible.

30. Aekofdk is injective. (I.e., the encryption key uniquely

determines the decryption key.)

31. Avkofsk is injective. (I.e., the veriﬁcation key uniquely

determines the signing key.)

B. REFERENCES
[1] M. Abadi and A. D. Gordon. A calculus for

cryptographic protocols: The spi calculus. In Proc. 4th
ACM Conference on Computer and Communications
Security, pages 36–47, 1997.

[2] M. Abadi and P. Rogaway. Reconciling two views of

cryptography: The computational soundness of formal
encryption. In Proc. 1st IFIP International
Conference on Theoretical Computer Science, volume
1872 of LNCS, pages 3–22. Springer, 2000.

[3] P. Ad˜ao, G. Bana, J. Herzog, and A. Scedrov.

Soundness and completeness of formal encryption:
The cases of key cycles and partial information
leakage. Journal of Computer Security, 17(5):737–797,
2009.

[4] M. Backes, D. Hofheinz, and D. Unruh. CoSP: A

general framework for computational soundness
proofs. In ACM CCS 2009, pages 66–78, November
2009.

[5] M. Backes, D. Hofheinz, and D. Unruh. CoSP: A

general framework for computational soundness
proofs. IACR Cryptology ePrint Archive 2009/080,
2009. Version from 2009-02-18.

[6] M. Backes, M. Maﬀei, and D. Unruh. Computationally
sound veriﬁcation of source code. In ACM CCS 2010,
pages 387–398. ACM Press, October 2010. Preprint on
IACR ePrint 2010/416.

[7] M. Backes, A. Malik, and D. Unruh. Computational

Soundness without Protocol Restrictions. IACR ePrint
archive, 2012. Full version of this paper.

[8] M. Backes and B. Pﬁtzmann. Symmetric encryption in

a simulatable Dolev-Yao style cryptographic library.
In Proc. 17th IEEE Computer Security Foundations
Workshop (CSFW), pages 204–218, 2004.

710[9] M. Backes, B. Pﬁtzmann, and A. Scedrov.

Key-dependent message security under active attacks -
brsim/uc-soundness of dolev-yao-style encryption with
key cycles. Journal of Computer Security,
16(5):497–530, 2008.

[10] M. Backes, B. Pﬁtzmann, and M. Waidner. A
composable cryptographic library with nested
operations (extended abstract). In Proc. 10th ACM
Conference on Computer and Communications
Security, pages 220–230, 2003. Full version in IACR
Cryptology ePrint Archive 2003/015, Jan. 2003,
http://eprint.iacr.org/2003/015.

[11] M. Backes and D. Unruh. Computational soundness of
symbolic zero-knowledge proofs. Journal of Computer
Security, 18(6):1077–1155, 2010. Preprint on IACR
ePrint 2008/152.

[12] G. Bana and H. Comon-Lundh. Towards

unconditional soundness: Computationally complete
symbolic attacker. In P. Degano and J. Guttman,
editors, Principles of Security and Trust, volume 7215
of Lecture Notes in Computer Science, pages 189–208.
Springer Berlin / Heidelberg, 2012.

[13] D. Basin, S. M¨odersheim, and L. Vigan`o. OFMC: A

symbolic model checker for security protocols.
International Journal of Information Security, 2004.

[14] M. Bellare, D. Hofheinz, and S. Yilek. Possibility and
impossibility results for encryption and commitment
secure under selective opening. In EUROCRYPT
2009, pages 1–35, 2009.

[15] M. Bellare and P. Rogaway. Random oracles are

practical: A paradigm for designing eﬃcient protocols.
In ACM Conference on Computer and
Communications Security, pages 62–73, 1993.

[16] M. Bellare and P. Rogaway. Optimal asymmetric

encryption. In Advances in Cryptology: EUROCRYPT
’94, volume 950 of LNCS, pages 92–111. Springer,
1994.

[17] F. B¨ohl, D. Hofheinz, and D. Kraschewski. On

deﬁnitions of selective opening security. In M. Fischlin,
J. Buchmann, and M. Manulis, editors, PKC 2012,
volume 7293 of LNCS, pages 522–539. Springer, 2012.
[18] J. Camenisch, N. Chandran, and V. Shoup. A public
key encryption scheme secure against key dependent
chosen plaintext and adaptive chosen ciphertext
attacks. In A. Joux, editor, Eurocrypt 2009, volume
5479 of LNCS, pages 351–368. Springer, 2009.

[19] R. Canetti and J. Herzog. Universally composable

symbolic analysis of mutual authentication and key
exchange protocols. In Proc. 3rd Theory of
Cryptography Conference (TCC), volume 3876 of
LNCS, pages 380–403. Springer, 2006.

[20] H. Comon-Lundh, V. Cortier, and G. Scerri. Security

proof with dishonest keys. In POST, pages 149–168,
2012.

[21] V. Cortier, S. Kremer, and B. Warinschi. A survey of

symbolic methods in computational analysis of
cryptographic systems. J. Autom. Reasoning,
46(3-4):225–259, 2011.

[22] V. Cortier and B. Warinschi. Computationally sound,
automated proofs for security protocols. In Proc. 14th
European Symposium on Programming (ESOP), pages
157–171, 2005.

[23] D. Dolev and A. C. Yao. On the security of public key
protocols. IEEE Transactions on Information Theory,
29(2):198–208, 1983.

[24] S. Even and O. Goldreich. On the security of

multi-party ping-pong protocols. In Proc. 24th IEEE
Symposium on Foundations of Computer Science
(FOCS), pages 34–39, 1983.

[25] R. Kemmerer, C. Meadows, and J. Millen. Three

systems for cryptographic protocol analysis. Journal
of Cryptology, 7(2):79–130, 1994.

[26] P. Laud. Semantics and program analysis of

computationally secure information ﬂow. In Proc. 10th
European Symposium on Programming (ESOP), pages
77–91, 2001.

[27] P. Laud. Symmetric encryption in automatic analyses
for conﬁdentiality against active adversaries. In Proc.
25th IEEE Symposium on Security & Privacy, pages
71–85, 2004.

[28] G. Lowe. Breaking and ﬁxing the Needham-Schroeder

public-key protocol using FDR. In Proc. 2nd
International Conference on Tools and Algorithms for
the Construction and Analysis of Systems (TACAS),
volume 1055 of LNCS, pages 147–166. Springer, 1996.

[29] L. Mazar´e and B. Warinschi. Separating trace

mapping and reactive simulatability soundness: The
case of adaptive corruption. In P. Degano and
L. Vigan`o, editors, ARSPA-WITS 2009, volume 5511
of LNCS, pages 193–210. Springer, 2009.

[30] M. Merritt. Cryptographic Protocols. PhD thesis,

Georgia Institute of Technology, 1983.

[31] D. Micciancio and B. Warinschi. Soundness of formal

encryption in the presence of active adversaries. In
Proc. 1st Theory of Cryptography Conference (TCC),
volume 2951 of LNCS, pages 133–151. Springer, 2004.

[32] J. B. Nielsen. Separating random oracle proofs from

complexity theoretic proofs: The non-committing
encryption case. In M. Yung, editor, Advances in
Cryptology, Proceedings of CRYPTO ’02, volume 2442
of Lecture Notes in Computer Science, pages 111–126.
Springer-Verlag, 2002.

[33] L. Paulson. The inductive approach to verifying
cryptographic protocols. Journal of Cryptology,
6(1):85–128, 1998.

[34] S. Schneider. Security properties and CSP. In Proc.
17th IEEE Symposium on Security & Privacy, pages
174–187, 1996.

[35] D. Unruh. Programmable encryption and

key-dependent messages. IACR ePrint archive
2012/423, 2012.

711