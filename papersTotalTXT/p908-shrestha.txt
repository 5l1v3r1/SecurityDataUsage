The Sounds of the Phones: Dangers of Zero-Effort

Second Factor Login based on Ambient Audio

Babins Shrestha

University of Alabama at Birmingham

babins@uab.edu
Prakash Shrestha

University of Alabama at Birmingham

prakashs@uab.edu

Abstract
Reducing user burden underlying traditional two-factor authentica-
tion constitutes an important research effort. An interesting repre-
sentative approach, Sound-Proof, leverages ambient sounds to de-
tect the proximity between the second factor device (phone) and
the login terminal (browser). Sound-Proof was shown to be secure
against remote attackers and highly usable, and is now under early
deployment phases.

In this paper, we identify a weakness of the Sound-Proof sys-
tem, namely, the remote attacker does not have to predict the am-
bient sounds near the phone as assumed in the Sound-Proof paper,
but rather can deliberately make—or wait for—the phone to pro-
duce predictable or previously known sounds (e.g., ringer, notiﬁca-
tion or alarm sounds). Exploiting this weakness, we build Sound-
Danger, a full attack system that can successfully compromise the
security of Sound-Proof. The attack involves buzzing the victim
user’s phone, or waiting for the phone to buzz, and feeding the cor-
responding sounds at the browser to login on behalf of the user.
The attack works precisely under Sound-Proof’s threat model.

Our contributions are three-fold. First, we design and develop
the Sound-Danger attack system that exploits a wide range of a
smartphone’s functionality to break Sound-Proof, such as by ac-
tively making a phone or VoIP call, sending an SMS and creating
an app-based notiﬁcation, or by passively waiting for the phone to
trigger an alarm. Second, we re-implement Sound-Proof’s audio
correlation algorithm and evaluate it against Sound-Danger under
a large variety of attack settings. Our results show that many of our
attacks succeed with a 100% chance such that the Sound-Proof cor-
relation algorithm will accept the attacked audio samples as valid.
Third, we collect general population statistics via an online sur-
vey to determine the phone usage habits relevant to our attacks.
We then use these statistics to show how our different correlation-
based attacks can be carefully executed to, for instance, compro-
mise about 57% user accounts in just the ﬁrst attempt and about
83% user accounts in less than a day. Finally, we provide some
mitigation strategies and future directions that may help overcome
some of our attacks and strengthen Sound-Proof.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24-28, 2016, Vienna, Austria
c(cid:13) 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978328

Maliheh Shirvanian

University of Alabama at Birmingham

maliheh@uab.edu

Nitesh Saxena

University of Alabama at Birmingham

saxena@cis.uab.edu

1.

INTRODUCTION

Two-factor authentication (2FA), combining the use of a pass-
word (“something you know”) and a token (“something you have”),
is gaining momentum for web authentication. A traditional 2FA
scheme requires the user (Alice) to enter her password and copy a
random one-time PIN (OTP) from the token over to the authenti-
cation terminal. This improves security because the attacker now
needs to not only guess the user’s password but also the current
OTP value to hack into the user’s account. The use of a general-
purpose smartphone as a token [3, 12, 14], as opposed to a dedi-
cated device [21, 27], helps improve usability and deployability of
2FA, and is currently a commonly used approach on the Internet.

However, the need to look-up and interact with the phone, and
copy the OTP value during a 2FA authentication session lowers the
system’s usability, which may prevent users from adopting this ap-
proach for authentication [17]. In this light, researchers and prac-
titioners have recognized the need for reducing, and ideally elim-
inating, the user burden underlying traditional 2FA, giving rise to
an important research direction. The goal of such zero-effort 2FA
schemes is to allow the user to login using the 2FA approach by
ideally only typing in her password.

An interesting representative zero-effort 2FA approach, Sound-
Proof [17], leverages ambient sounds to detect the proximity be-
tween the phone and the login terminal (browser). Speciﬁcally,
during the login session, the browser and the phone each record a
short audio clip, and the login is deemed successful only if the two
recorded audio samples are highly correlated with each other (and
the correct password is supplied). Except of entering the password,
Sound-Proof does not require any user action (e.g., transferring PIN
codes or even looking-up the phone) – mere proximity of the phone
with the terminal is sufﬁcient to login. It may also work even if the
phone is inside a purse or pocket. Unlike other zero-effort 2FA
approaches [11, 23], which rely upon proximity channels, such as
Bluetooth or Wi-Fi, to automatically transfer the PIN codes, a com-
pelling deployability feature of Sound-Proof is that it does not re-
quire browser plugins or any changes to the current browsers.

The main security goal of Sound-Proof is to defeat a remote at-
tacker, who has learned the user’s password (e.g., by hacking into
a password database server of the web service in question), and
is attempting to login to the user’s account, and possibly multiple
user accounts. As argued in [17], given the prominence of remote
attacks on the web today, this is a very legitimate goal. In order
to login to the user’s account, the remote attacker against Sound-
Proof would have to predict the ambient sounds in the environment
of the phone and possibly be in a very similar environment as the
user, which may be a difﬁcult endeavor in practice, as shown in the

908security analysis reported in [17]. In other words, if the attacker
can not predict the user’s environment and is in a different environ-
ment than the user, the audio samples at the browser’s end and the
phone’s end would not correlate, thereby preventing the attacker
from logging in [17]. Indeed, in the comprehensive security evalu-
ation reported in [17], Sound-Proof was shown to be highly secure
against such remote attackers. In addition, in the usability evalu-
ation reported in [17], Sound-Proof was shown to be highly user-
friendly, when contrasted with a traditional 2FA scheme involv-
ing OTPs [14]. Given these very promising security and usability
properties, Sound-Proof is apparently now under early deployment
phases in the form of a start-up (see: http://sound-proof.ch/).

In this paper, we set out to closely inspect the security of Sound-
Proof, motivated by its very appealing usability and practicality
features. Unfortunately, we identify a weakness of the Sound-Proof
system. Namely, the remote attacker against Sound-Proof does not
have to predict the ambient sounds near the phone, but rather can
make the phone create predictable or previously known sounds,
or wait for the phone to produce such sounds (e.g., ringer, noti-
ﬁcation or alarm sounds). Given the close physical proximity of
the source of these sounds (the phone’s speaker) and the receiver
of these sounds (the phone’s microphone), the phone’s recordings
would be dominated by these sounds rather than the ambient noises
present in the environment.

Exploiting this weakness, we introduce and build Sound-Danger,
a full attack system that can successfully compromise the security
of Sound-Proof. The attack involves remotely buzzing the victim
user’s phone, or waiting for the phone to buzz on its own, and
feeding the corresponding sounds at the browser to login on be-
half of the user. The attack works precisely under the limits of
Sound-Proof’s threat model, only uses the information available
in hacked password databases (e.g., passwords, phone numbers or
other account information [1, 2, 4, 6–9]), is fully remote and can
be launched against multiple user accounts. We note that phone
numbers, in particular, are readily available in password databases
as they are commonly used to facilitate account recovery in case of
forgotten username/password and are essential for 2FA-supported
web services which often need to send OTPs to users’ phones via
SMS (Sound-Proof also supports fallback to traditional 2FA [17]).
Our Contributions: We believe that our work makes the following
scientiﬁc contributions:

1. A Novel Attack against a Notable Zero-Effort 2FA Scheme: We
introduce, design and develop the Sound-Danger attack system
that exploits a wide variety of a smartphone’s functionality to
break Sound-Proof, a prominent zero-effort 2FA scheme. Our re-
mote attack involves either making the phone to generate known
sounds, such as, by actively making a phone or VoIP call, sending
an SMS and triggering an app-based notiﬁcation, or by passively
waiting for the phone to sound an alarm at a predictable moment.
Our attack exploits the “sounds of the phones”, which is funda-
mentally different from, and more devastating than, the attacks
studied in [17] which exploit the “sounds of the ambience”.

2. Correlation Analysis of the Attack System: We re-implement the
Sound-Proof’s audio correlation algorithm and evaluate it against
Sound-Danger under a large variety of attack settings. Our re-
sults show that many of our attacks (e.g., WhatsApp1 or Face-
book calling, Viber2 notiﬁcations and phone alarm) succeed with
a 100% chance such that Sound-Proof’ correlation detection en-
gine accepts the attacked audio samples as valid, i.e., the attacker

1http://www.whatsapp.com/
2http://www.viber.com/

(browser) and the phone are deemed to be in proximity (even
though they are remote).

3. Real-World Attack Strategies based on Population Statistics: As
a representative example of how to deploy our attacks in prac-
tice, we collect general population statistics via an online survey
to determine the phone usage habits and patterns relevant to our
attacks. We then use these common statistics from our popula-
tion sample to show how our different correlation-based attacks
against Sound-Proof can be carefully executed to compromise,
for example, about 57% user accounts in the ﬁrst attempt and
about 83% user accounts in less than a day. Our attack strategy
is extensible to other population samples beyond the one we stud-
ied, and may actually be used to eventually compromise almost
all user accounts.

Potential Defenses and Broader Implications: While our work
mainly serves to raise an alarm against the pitfalls and challenges
of designing zero-effort two-factor authentication mechanisms, we
also provide some strategies for Sound-Proof designers that may
help mitigate some of our attacks and could strengthen the security
of Sound-Proof, hopefully without undermining its usability. Fur-
ther work will be needed in this direction though. We believe that
our work is timely, since the Sound-Proof system seems to be near-
ing deployment at this point. Addressing the vulnerability reported
in our paper, prior to fully launching Sound-Proof in the wild, will
help protect future Sound-Proof users.

Our attack is not just limited to the speciﬁc audio correlation al-
gorithm implemented by Sound-Proof. Since we essentially create
the very similar sounds at the attacker’s (browser’s) end as the vic-
tim’s (phone’s) end, it seems that any audio correlation engine may
be defeated. Another algorithm for audio correlation was proposed
in [16], which also seems vulnerable to our attacks. On the other
hand, if the detection approach employs stricter parameters, such as
very high correlation thresholds and narrower synchronization lags
between audio samples, to lower the impact of the attack, it would
considerably lower the usability of the system, since even in the be-
nign settings, many matching samples will be rejected, preventing
the legitimate user from logging in.

Also, at the conceptual level, our attack is not just limited to
the domain of two-factor authentication. There exists other zero-
interaction proximity detection and device pairing schemes based
on ambient audio, which also seem vulnerable to our attack. For
example, one security scheme is geared for preventing relay at-
tacks in the context of “local” terminal authentication (e.g., mo-
bile payments) [16]. And, another scheme is aimed for pairing of
devices based on common ambient audio signals [22]. Here, if
the attacker knows the victim’s phone number or app account user-
names, it could also succeed in defeating such schemes. However,
in the threat model of such schemes, such personalized information
about the victim’s phone may not be available to the attacker, un-
like Sound-Proof where this information is readily available from
the same databases which leak the victim’s passwords.

Overall, the main broader lesson learned from our study is that,
while reducing the user effort and removing the user from the au-
thentication loop is a compelling proposition, it requires utmost
care in the design of such schemes.

2. BACKGROUND

Sound-Proof [17] is claimed to be a usable and deployable zero-
effort 2FA mechanism, which does not require interaction between
a user and the 2FA application on the device during the authenti-
cation process. In Sound-Proof, the second authentication factor is
the proximity of the user’s phone and the client terminal (browser),

909which is veriﬁed by the application on the phone by comparing the
ambient noise recorded by the phone and the browser.
2.1 Threat Model

The primary goal of Sound-Proof is to defeat a remote attacker,
who may be attempting to login into a victim user’s account from a
remote machine, which is in full control of the attacker. Sound-
Proof’s threat model assumes that this remote attacker has the
knowledge of the victim user’s username and password. This infor-
mation can be learned, for example, via leaked password databases
of the web service that may be using Sound-Proof or other web ser-
vices for the purpose of authenticating its users. The attacker’s goal
is to authenticate to the web service on behalf of the user and pos-
sibly compromise multiple user accounts. Sound-Proof assumes
that the attacker has not compromised the user’s phone and/or the
user’s terminal. If the attacker gains control of one of the victim’s
devices, the security of any 2FA scheme reduces to the security
of password-only authentication. Also, Sound-Proof does not con-
sider targeted attacks such as those involving co-located malicious
entities that are in close physical proximity of the victim.

This threat model may be weaker than that considered by tradi-
tional 2FA schemes involving OTPs. However, as argued in [17],
given the prominence of remote attacks, this is still a very legit-
imate model.
If more and more web services and users adopt
Sound-Proof given its unique zero-effort feature, and remote at-
tackers could still be thwarted, this will be a major improvement to
the state of web authentication in practice.

As such, our proposed Sound-Danger system follows a threat
model very similar to that of Sound-Proof. We consider that
the attacker gets other user information from the leaked password
database besides user credentials. That is, we assume that the pass-
word databases store phone numbers for password-only or 2FA im-
plementations in order to send account recovery information or ver-
iﬁcation codes [1, 7], IP address information from which the users
log in [1, 2, 9], or even users’ physical address information [9]. The
Sound-Danger attacker uses the phone numbers to perform active
attacks while it utilizes IP addresses or physical address informa-
tion to locate the users and their timezones. By identifying the
timezone of the users, the attacker can estimate when a particular
noise may occur at the users’ side, such as morning alarms. Since
many users often use the same usernames across multiple web ap-
plications, the attacker can utilize the username information to per-
form attacks based on notiﬁcations triggered by apps that use the
same username. For example, if a user has the same username in
the leaked database server and Skype, the attacker can send a no-
tiﬁcation (e.g., a friend’s request) to user’s Skype account. Like in
Sound-Proof’s threat model, the Sound-Danger system does not at-
tempt targeted attacks. Rather, it assumes that the attacker can col-
lect general population statistics through online user surveys in or-
der to devise speciﬁc attack strategies against a population of users
for compromising multiple user accounts.
2.2 Implementing Sound-Proof Framework

As a prerequisite to evaluating the Sound-Danger attack system,
we ﬁrst re-implemented Sound-Proof, as described in [17]. We
implemented phone-side, server-side and browser-side applications
as described below:
• Phone Application: We created an Android app that stays idle in
the background and is automatically activated when a push mes-
sage arrives. Google Cloud Messaging (GCM) is used to send
a push message from the browser to the Android phone. When
GCM push message arrives from the browser for recording, the
Android app automatically gets activated and starts recording the

ambient noise. The app stops recording as soon as another GCM
push message arrives.
• Web Server and Browser Application: The server component is
implemented using PHP while the browser component is imple-
mented in HTML and JavaScript. Browser application has a
simple button to control the recordings on the browser and on
the phone. When the button is pressed to “start recording”, the
browser application sends GCM push message to the Android
phone. If the button is pressed to stop recording, a “stop record-
ing” GCM push message is sent to the Android phone. In the
meantime, the browser application also starts recording ambi-
ent noise. Thus, the browser application has two main func-
tions:
(1) sending start/stop recording commands, i.e., GCM
push messages, to the Android phone, and (2) recording ambi-
ent noise. In order to record ambient noise through the browser,
we use HTML5 WebRTC API [15]. In particular, we use nav-
igator.getUserMedia() API to access the local microphone from
within the browser.

Time Synchronization: As the two devices (phone and terminal
running browser application) may have two different local time
clocks, our implementation, like Sound-Proof, requires the record-
ings from these devices to be synchronized. For this reason, both
the phone and the browser applications run a simple time synchro-
nization protocol with the web-server. Similar to Sound-Proof,
the protocol is implemented over HTTP that allows each device
to compute the time difference between the local time and the
server time. Each device runs the time synchronization protocol
while it is recording the ambient audio. Both devices compute
their round-trip time delay (θ = t2 − t0) and then clock differ-
ence (δ = t2 − t1 − θ/2) with the web-server. Here, t0, t1, and t2
are the timestamps of the device’s request transmission, the server’s
request reception/response transmission, and the device’s response
reception, respectively. During our ofﬂine analysis of audio sam-
ples, the recordings from each of the devices are adjusted taking
into account the clock difference (δ) with the web-server.
2.3 Implementing and Testing Sound-Proof’s

Correlation Engine

Correlation Analysis: Correlation analysis between an audio pair
is implemented in a similar fashion as Sound-Proof. That is, we
used one-third octave band ﬁltering and cross-correlation to get a
similarity score of an audio pair, as described below:
• One-third Octave Bands: We divide the audio samples into dif-
ferent bands based on frequency. Each band covers a speciﬁc
range of frequencies. A frequency is said to be an octave in
width when the upper band frequency is twice the lower band
frequency. A one-third octave band is deﬁned as a frequency
band whose upper band-edge frequency is equal to the lower
band frequency multiplied by the cube root of two [20]. The
audio spectrum from 20Hz to 20kHz can be divided into 32 one-
third octave bands with the center frequency of 19th one-third
octave band set to 1000Hz. The center frequency of the lowest
band is 16Hz covering from 14.1Hz to 17.8Hz, while the center
frequency of the highest band is 20kHz covering from 17.78kHz
to 22.39kHz [25].
Since we are targeting Sound-Proof, we divide the audio into the
bands ranging from 50Hz to 4kHz. Sound-Proof utilizes only
these set of bands, as these bands provided the best Equal Er-
ror Rate (EER) in the analysis reported in [17]. Hence, we only
use the sixth band with the center frequency 50Hz to the twenty
sixth band with the center frequency 4kHz, i.e. we consider only

910twenty bands out of the thirty two available bands. We use twen-
tieth order Butterworth bandpass ﬁlter [19] in MATLAB to split
the audio samples into these bands.

• Cross Correlation: We use the same system that was imple-
mented in [16] to correlate ambient noise. Sound-Proof also
closely follows this system for calculating cross-correlation. We
use standard cross-correlation function to measure the similar-
ity between the time-based signals Xi and Xj. To calculate the
similarity, we ﬁrst normalize the signals according to their en-
ergy. Then, we calculate the correlation between each signal at
different lags and use maximum correlation value. The corre-
lation between two time-based signals Xi and Xj is measured
as:

Corr(i, j) = max(CrossCorr(Xi, Xj))

(1)

Sound-Proof also considers the lag to get the cross-correlation.
This plays a major role to prevent attacks on the system when an
attacker submits a similar audio sample as that in victim’s envi-
ronment, which may be separated by a certain lag. Sound-Proof
has bound the lag l between 0 and lmax, where it sets lmax to
150ms. Hence, in our attack analysis, we also check the max-
imum cross-correlation of audio pairs with the time lag bound
to 150ms. This lag value yielded a low EER in Sound-Proof’s
analysis reported in [17].

Data Collection and Experiments: We collected audio samples
using the framework described in Section 2.2 at different loca-
tions such as lab/ofﬁce, home, cafe, and library. We used Google
Chrome on MacBook Air and Samsung Galaxy S V to record the
audio samples using our implementation of Sound-Proof. We col-
lected total of 525 audio pair samples and mix-matched them to get
the correlation between each audio pair. The data collection exper-
iment was approved by our University’s IRB. The audio recordings
were around 8 seconds long which were trimmed to 3 seconds after
time synchronization for the correlation analysis (similar to [17]).
Similar to Sound-Proof, our implementation uses one-third oc-
tave band ﬁltering and cross-correlation to calculate the similarity
score between an audio pair, as described above. We use octave
band ﬁltering to split 3 second long audio recordings from both
devices into 20 one-third octave bands. Maximum correlation is
computed with the time-lag bound to 150ms between these audio
pairs in their respective bands. The average correlation value ob-
tained from these bands is the correlation between the audio pair.

The audio pairs which are co-recorded (recorded at the same lo-
cation and at almost the same time) are labeled as True Positive
(TP) and the rest are labeled as True Negatives (TN). Once the cor-
relation values for each of the co-recorded audio pairs as well as
non co-recorded audio pairs are calculated, we compute the FPR
(False Positive Rate) and FNR (False Negative Rate) as a function
of the correlation threshold. FPR for a given threshold deﬁnes the
fraction of audio pairs (out of all audio pairs) which are not co-
recorded but are classiﬁed as valid (TP) at that threshold, while
FNR for a given threshold deﬁnes the fraction of co-recorded audio
pairs (out of all audio pairs) that are classiﬁed as invalid (TN) at that
threshold. Using FPR and FNR at different threshold values, we
calculate EER (Equal Error Rate) and determine the optimal value
of correlation threshold (Tc) at which FNR and FPR are equal.

From the data collected in our experiments, we obtained the op-
timal threshold Tc of 0.1524 yielding an EER of 0.1607. The cor-
relation threshold set in our experiment is in line with the corre-
lation threshold of Sound-Proof (0.13) [17]. Moreover, our other
parameter settings are exactly the same as in Sound-Proof’s im-
plementation [17], i.e., using the audio samples each of length 3

seconds, ﬁltering the audio samples into 20 different one-third oc-
tave bands, and cross-correlating the audio samples with time lag
bound to 150ms. Since our correlation threshold is higher than that
used in Sound-Proof’s implementation, it means that attacking our
implementation will be harder than attacking Sound-Proof’s im-
plementation reported in [17]. In other words, the Sound-Danger
attack against our implementation (threshold 0.1524) would imply
an attack against Sound-Proof’s implementation (threshold 0.13)
[17]. Nevertheless, we analyze the performance of Sound-Danger
for different (higher) correlation threshold values in the attack anal-
ysis in Section 4, and show that the attacks still work well even at
such higher thresholds.

3. ATTACKS

As the threat model of our Sound-Danger attack system sug-
gests, we assume that the attacker is already in possession of the
victim’s username and password but is not co-located with the vic-
tim (i.e. victim’s phone). The attacker’s goal is to satisfy the second
factor requirement, which is to fool the system into accepting the
co-location of the attacker’s terminal and the victim’s phone.

We consider two types of attacks against Sound-Proof, both of
which exploit the sounds generated by the phone itself. The ﬁrst
type of Sound-Danger attack is the active attack, where the attacker
performs an activity by which a sound (a phone ringing tone or an
app-based notiﬁcation) would dominate the ambient audio around
the victim’s device. Since the attacker is aware of the audio pro-
duced at the phone’s end, it can generate the same sound at its
own surroundings (or feed the same sound programmatically to the
browser) and succeed in proving the co-location with the phone.
The second type of Sound-Danger attack is the passive attack, in
which the attacker waits for the phone to create a previously known
sound, speciﬁcally a morning alarm, at an opportune moment and
then tries to generate the same noise at its local terminal. The steps
taken by the attacker to target Sound-Proof are shown in Figure 1.
3.1 Active Attacks

In the Sound-Danger active attack scenarios, we assume that the
attacker has already compromised the web service that uses Sound-
Proof. Since account databases on such servers typically store other
forms of user’s data (e.g., phone number for the password recovery
purposes), hacking into the server reveals other information that
can be a used in the active attacks. Such data if not stored on the
main server is assumed to be obtained with data aggregation attack
through other services that user has an account with (which proba-
bly does not use 2FA).

Based on the type of information that the attacker possesses, we

deﬁne (and later implement and evaluate) the following attacks:
Ringtone Attack: In this attack, the attacker predicts the ringtone
(or vibration sound) that the victim has set for the received phone
calls. The attacker calls the victim using the knowledge it has ob-
tained from compromised account database. At the same time, the
attacker attempts to login by entering the previously leaked vic-
tim’s credentials to the login page via its own login terminal. To
mimic the victim’s ambient noise (now the sound of the ringtone),
attacker plays the same ringtone audio at its location next to the
login terminal.
Information known to the attacker: Victim’s username and pass-
word, victim’s phone number and victim’s ringtone.
Task of the attacker: Ring the victim’s phone and create same sound
around the local login terminal.
App Notiﬁcation Attack: In this attack, the attacker predicts the
voice/messaging application running on the victim’s phone and

911Figure 1: Sound-Danger Attack Flowchart: The attacker (human or bot) enforces the ambient audio to be highly similar at both (attacker’s and victim’s)
ends by making calls or sending notiﬁcations to the victim’s phone, or waiting for an alarm to go off at the victim’s phone, and by simultaneously feeding the
same sounds at its own end. The attacker would succeed in logging into the webservice, while the user may remain unaware of the attack or even when the
attack is detected, the account may already have been compromised.

tries to activate the notiﬁcation tone or ring tone of the application
by communicating to the victim through the application. Since the
user typically registers to many of the web services using phone
number or user id, the attacker can contact the user on these ap-
plications either by their phone number (obtained by hacking the
primary account database) or user id (possibly similar to the one
registered with the primary service.

Examples of such applications are Google Voice, FaceTime,
Skype, Facebook, WhatsApp and Viber. Calling or texting the user
on these applications generates a default ringtone or notiﬁcation
tone that is known to the attacker and is usually not changed by the
users. Hence, the attacker starts a login attempt to the primary ser-
vice using the known credentials, and then contacts the user on any
of the mentioned applications. At the same time, it plays the same
ringtone or notiﬁcation tone locally near the login terminal. The
attacker would succeed since it regenerates the same ambient noise
as the victim’s phone locally (around the attacker’s login terminal).
Information known to the attacker: Victim’s username and pass-
word, victim’s phone number, victim’s installed application on the
phone, victim’s id with the application (same as phone number or
primary username) and application ringtone.
Task of the attacker: Ring the victim’s messaging application and
create the same sound around the local login terminal.
Feasibility of Attacks: In all of our attacks above, the attacker
would have to predict some information necessary to execute the
attacks (e.g., the type of ringtone used by the victim). However,
given predictable patterns and phone usage habits across users, this
is not much of a problem for the attacker. In Section 5, we sup-
port these assumptions and claims made here, based on the data
gathered from the participants in an online survey.
3.2 Passive Attacks

In the passive attack, the attacker predicts, or knows users’ ac-
tivity and launches the attack based on the knowledge it has from
the users’ proﬁle gathered from the leaked database. Unlike the
active attack, the attacker does not attempt to generate a sound at

the user’s side but only regenerates the same ambient sound that is
supposed to be available at the user’s side. Unlike the active attack,
the passive attack does not alert the user by creating a sound, and
hence can be repeatedly attempted without triggering suspicion.

Although there are different scenarios where an attacker can cre-
ate a similar ambient noise to that at victim’s side such as simi-
lar media attack (both attacker and victim are watching same me-
dia/TV channel, as also brieﬂy considered in [17]), same event
(both attacker and victim are attending a popular event), or similar
vehicles sound (attacker knows when victim commutes and uses
similar in-vehicle sound), we chose to exploit the ambient noise
that is created by victim’s phone itself such as alarms or morning re-
ports. We believe that this attack has a higher chance of succeeding
compared to other ambience-based passive attacks since the sound
of the alarm of the phone will dominate the ambient sounds.
Alarm Attack: In this attack, the attacker knows the speciﬁc app
which generates an audio at particular time of day such as the morn-
ing alarm. Attacker attempts to log in at a speciﬁc moment when
such alarm is supposed to go off using the victim’s credential. At
the same moment, the attacker plays the alarm tone at its local lo-
gin terminal to mimic the ambient noise around the victim’s phone.
In this attack apart from the victim’s username and password, the
victim’s alarm time, alarm tone is also known to the attacker.
Information known to the attacker: Victim’s username and pass-
word, victim’s alarm ringtone and victim’s timezone.
Task of the attacker: Create the same alarm sound around its local
login terminal.
Feasibility of the Attack: Similar to the active attacks, the attacker
would have to predict some information necessary to execute the
attacks (e.g., the type of ringtone used by the victim and victim’s
timezone). However, given predictable patterns and phone usage
habits across users, this is not challenging, as we demonstrate in
Section 5 based on the results of an online survey.
3.3 Active vs. Passive Attacks

We introduced passive and active attacks, each of which has their

912(a) Phone Call

(b) WhatsApp Call

(c) SMS Notiﬁcation

(d) Facebook Notiﬁcation

Figure 2: Change in correlations when an attacker makes call or sends notiﬁcation via different apps at different point of time. In Figures a and b, the ringtone
at the victim’s side starts playing at the 5th second while in Figures c and d the notiﬁcation audio goes off at 4th second as depicted by highest correlation.
There is no audio at the victim’s side from the ringtone when the attacker plays the respective audio at 0th second. The correlation values are higher when the
ringer is ringing compared to that when there is no ringer i.e. before 2 sec in call.

own merits. With the passive alarm attack, it is very likely that the
victim user would not notice the ongoing malicious login attempt.
Therefore, the attacker might be able to repeat the attack repeatedly
until it is successful. In case of active attacks, the sounds generated
by the attacker on the user’s phone (e.g., a phone ringing tone)
could notify the user and seek her attention. However, only a few
seconds of audio is enough for the Sound-Proof system to verify
the co-presence of the phone and the terminal. Therefore, by the
time the user attends to the phone (e.g., to pick up the call) and
even when the user notices the malicious login attempt, the attack
would have already succeeded and the user’s account might have
already been compromised.

Although Sound-Proof logs the login attempts on the device (as
suggested in [17]), the users may leave their phones unattended, in
purses or bags, might not be concerned about security or be dili-
gent enough to the extent that they review the logs carefully and
frequently. Extensive research literature in user-centered security
shows that users may not pay attention to security notiﬁcations or
heed security warnings and messages (e.g., [13, 24]). Moreover,
relying upon the users to detect such attacks will break the “zero-
effort” property of Sound-Proof. Furthermore, even if the logs were
read and understood by the users, the attack may have already suc-
ceeded by the time suspicious activity is noticed.
4. ATTACK CORRELATION ANALYSIS

In this section, we show the correlation analysis of different at-
tacks using Sound-Danger introduced in Section 3. In other words,
we test the rate at which the attack samples (corresponding to at-
tacker’s browser and victim’s phone) will be accepted as valid lo-
gin attempts by our implementation of the Sound-Proof app. In our
analysis, we used Samsung Galaxy S5 from Verizon as the victim’s
smartphone along with Google Chrome browser in MacBook Air
(mid 2012) as attacker’s terminal to perform the attack. The at-
tacker makes calls or sends notiﬁcation from LG G3 from Verizon
or a computer to create an audio it desires at the victim’s side.

To perform the attacks described in Section 3, the attacker fol-
lows the steps as illustrated in Figure 1. The attacker who per-
forms such attacks tries to generate or predict a similar audio at
the victim’s side while it logs into the victim’s account with the
victim’s credentials. The attacker has full control over the com-

puter/browser that it is using. However, the attacker does not have
any direct control over the victim’s smartphone/app.
4.1 Ringtone and App Notiﬁcation Attacks

To test our ringtone and app notiﬁcation based active attacks, as
described in Section 3, we use phone ringtone (call/SMS) as well as
various other ringtones from some of the popular apps in Google
Play Store, such as Facebook, WhatsApp Messenger, Viber, and
Skype. We use default ringer of the app/phone call. Although some
of the victims may have customized the ringtone for phone call or
any other app, some of these apps do not allow users to customize
the ringtone for calls or notiﬁcations. The primary difference be-
tween call and notiﬁcation attack is that the ringtone audio is played
longer for the call than it is for the notiﬁcation.

Since the attacker does not have any direct control over the vic-
tim’s phone, the attacker faces challenges due to two types of de-
lays: (1) Sound-Proof recording delay, and (2) call/notiﬁcation de-
lay. Due to Sound-Proof recording delay, the attacker cannot per-
fectly guess at what time instance Sound-Proof starts recording au-
dio from the victim’s phone for the purpose of login. And, due to
the call/notiﬁcation delay, when the attacker makes call or sends
notiﬁcation to the victim’s phone, the attacker also cannot make a
perfect estimate to when the ringer sound will be played at the vic-
tim’s side. To estimate these two delays, the attacker can run an
experiment by making calls or sending notiﬁcations to itself and
monitor the delays. Based on this, the attacker tries to synchro-
nize the ringer being played at both sides as much as possible. We
run and analyze the attacks assuming that the attacker knows when
Sound-Proof starts recording at its end. This is a valid assumption
since the attacker fully controls its terminal. Because of the delays
mentioned above, during the actual attack, Sound-Proof may start
recording either before or after the ringer goes off at the victim’s
side. We set forth to analyze how the correlation values change
when the victim’s ringer goes off at different points of time.
Attack Analysis: Sound-Proof compares 3-second long audio
samples, as discussed in Section 2.3. Let us say the victim receives
call/notiﬁcation by an attacker at the nth second. The attacker starts
the authentication at the tth second. This is when Sound-Proof
starts recording at both sides. If Sound-Proof starts recording at t
such that t < n − 3, Sound-Proof will not record any audio com-

913ponent due to the ringer, and hence, there will be low correlation
between the audio pair. When t = n, the correlation will be the
highest as the attacker has fully synchronized the audio at its side
with that at the victim’s side. This pattern exhibited by the cor-
relation values can be visualized in Figure 2. Here, the ringer for
call goes off at the 5th second (Figures 2a and 2b) while the sound
of the notiﬁcation goes off at the 4th second (Figures 2c and 2d).
Hence, the correlation is very low prior to the ﬁrst 2 seconds. Now,
when t > n, the correlation should drop as the two audio samples
are not synchronized. However, the correlation after the ringer has
started ringing (t > n) is higher than that when there was no au-
dio at all (t < (n − 3)). Therefore, we know that the correlation
increases and is reasonably high as long as there is some matching
audio even if the two audio samples are not at perfect match or syn-
chronized. The increase in the correlation values after t > (n − 3)
proves this pattern as depicted in Figures 2a and 2b.

Figure 3: Analyzing Facebook notiﬁcation audio sample (∼687ms long).
The ﬁrst audio sample (top) represents the audio played by the attacker. The
second audio sample (middle) and the third audio sample (bottom) represent
the audio recorded at victim’s side when the notiﬁcation audio rings after or
before the attacker’s side, respectively.

To further analyze this property, we choose Facebook notiﬁca-
tion attack instead of call attack for simplicity. We use Audacity3
to analyze why the correlation in Figure 2d increases at t = 3.4
second and drops only after t = 4.6 second while the exact match
occurs at 4th second as illustrated in Figure 3. The ﬁrst audio signal
in Figure 3 represents the audio signal that the attacker plays at its
terminal which is 3 second long. The audio due to Facebook no-
tiﬁcation has audible signal of length 687ms which starts at 1.26th
second. The second audio signal represents the audio recorded by
the app at victim’s terminal for t = 4.6 second where the notiﬁ-
cation ringtone goes off at 1.60th second. The third audio signal
represents the audio recorded by the app at victim’s terminal for
t = 3.4 second where the notiﬁcation ringtone goes off at 0.90th
second in the 3 second long audio. From these three audio samples,
we can see that whenever there is an overlap between the audible
sounds, the correlation rises despite the time lag bound to 150ms.
This is because when there is some audio, the correlation values
from some of the 1/3-octave bands out of 20 bands increase, in-
creasing the overall average correlation value.
Real Attacks and Success Rates: After analyzing the attack
methodologies mentioned above, we set forth to perform the real
attacks. To perform such attacks, the attacker needs to: (1) make a
call/send a message via different apps to a victim’s smartphone, (2)
log in from a browser on a terminal which it fully controls, and (3)
play the ringtone or a notiﬁcation sound that the victim device may
generate due to attacker’s call/message. At the attacker’s end, we
used an LG G3 phone and a MacBook Air and, at the victim’s end,
we used a Samsung Galaxy S5 phone. The attacker ﬁrst observed
how long it takes for another device to ring in each different app
3http://www.audacityteam.org/

Table 1: Success rate of different types of attacks with respect to different
correlation thresholds. Highlighted cells represent attack with success rate
at least 90%.

Attack Type
Phone Call
Viber
WhatsApp
Facebook
Skype
Facetime
Vibration

l
l
a
C
e
v
i
t
c
A

o
i
t
a
c
ﬁ

n SMS
Skype
WhatsApp
Viber

i
t
o
N

Tc= 0.1524
81.82%
100.00%
100.00%
100.00%
41.67%
92.86%
85.42%
64.71%
85.71%
66.67%
100.00%

Tc = 0.2
Tc = 0.18
63.64%
72.73%
100.00%
90.00%
100.00% 100.00%
100.00%
72.73%
16.67%
25.00%
42.86%
57.14%
72.92%
81.25%
17.65%
35.29%
52.38%
19.05%
25.00%
33.33%
92.86%
85.71%

e
v
i
s
s
a
P

Alarm

100.00%

90.00%

80.00%

when it makes a call to the corresponding apps. Then, the attacker
made calls to the victim’s device from those apps. The attacker
tried to synchronize the ringtone played when it logs in from the
Google Chrome browser on MacBook Air.

We tested different attacks (active calls and notiﬁcations) against
our implementation of the Sound-Proof system, and collected the
audio samples stored in the victim’s smartphone and the audio up-
loaded to the server from the attacker’s browser. The success rates
for our attacks with the correlation threshold Tc = 0.1524 for dif-
ferent types of attacks are shown in Table 1. We can see that many
of our attacks were highly successful, including WhatsApp, Face-
book and Viber calling, Viber notiﬁcation and alarm. We also used
vibration based attack where the noise is produced by a vibration
of the phone instead of the phone playing a ringtone during a call.
We placed the phone in different location such as on desk, inside
a pocket, inside a bag, and in hand to see if the audio detected
by the phone for such placements of the phone affects the attack
success rate. Table 1 also shows the attack success rate when the
threshold was increased to Tc = 0.18 and Tc = 0.2. When the
correlation threshold is increased, the attack success rate decreases
slightly as expected (although many attacks are still highly success-
ful). We note that increasing the threshold would make the attacks
little harder but at the expense of usability since even legitimate
user may be prevented from logging in more frequently. Further
experiments revealed that the attack success rate did not change
even when the victim device was placed in front of a television
with high volume. This conﬁrmed our hypothesis that the sounds
of the phone will dominate the sounds of the ambient surroundings.
4.2 Passive Alarm Attack

As described in Section 3.2, the attacker could execute the alarm
attack at a speciﬁc time of the day (assuming the attacker knows
when the alarm will go off at the victim’s phone). Here, the at-
tacker may know the timezone of the victim (through leaked pass-
word databases). Since the attacker has control over the browser
and the device it is using at its end, the attacker can change its own
timezone to be synchronized with that of the victims. To simu-
late this setting, we played LG G5’s default alarm in front of the
browser while the phone was set to create the alarm at a ﬁxed time
instance. Since both phones played the same alarm simultaneously
at different ends, we achieved high correlation for the alarm attack
reﬂecting to 100.00% success rate with Tc = 0.1524. The success
rate decreased when we increase the correlation threshold, but we
could still achieve 80% success rate. The result for this attack for
different threshold is summarized in Table 1 (last row).

9145. LEARNING POPULATION STATISTICS
To support the claims and assumptions made in Section 3, we
conducted a survey by recruiting Amazon Mechanical Turk work-
ers. The study was approved by our University’s IRB. The partici-
pation in the study was strictly voluntary and participants could opt
out of the study at any time. The survey took only about 10 minutes
for each participant, for which they were compensated $0.7. In this
section, we discuss the design and results from this survey.
5.1 Study Design

To better inform the design and execution of our attacks in the
real-world, we asked the participants to answer several questions
about their smartphone usage, including their habits of using the
smartphones, the smartphone applications they use, and the ring-
tone and the notiﬁcation sound they set or prefer to use. Below we
summarize the set of questions we posed during the survey:
Demographic Information: We asked the participants about their
gender, age, education, industry or ﬁeld they belong to, country of
residence, and their general computer knowledge.
Applications: We asked the participants about the applications in-
stalled and used on the phone, particularly those that generate a
ringtone or a notiﬁcation sound (e.g., Google Voice, FaceTime,
Skype, Viber, Tango, ooVoo, LINE, WhatsApp, Telegram Mes-
senger, Facebook, Phone, Text Message, Alarm Clock, and Cal-
endar). Such applications are the primary target of the attacker in
our Sound-Danger system.
Notiﬁcations and Sounds: We queried about the type of ringtone
(e.g., default, vibrate, silent), and notiﬁcation tones that the partici-
pants set for their applications in different situations and time of the
day (e.g., while at work or asleep). If a particular popular ringtone
is set often, the attacker can possibly attack many participants with
our ringtone attack.
5.2 Study Results
General and Technical Background: We recruited 113 Amazon
Mechanical Turk workers. Almost equal number of male (50.82%)
and female (49.18%) users participated in the study. Although we
did not set any geographical restriction, majority of the participants
were from U.S.A (73%) and India (21%). The participants were
falling in the age group 18 to 65, precisely 18-24 (12.30%), 25-
34 (54.92%), 35-44 (22.95%), 45-54 (8.20%), and 55-64 (1.64%).
The participants had high school (6.56%), college degree (25.41%),
Associate degree (7.38%), Bachelor’s degree (40%), Master’s de-
gree (1.72%), and Doctorate degree (2.46%). The participants were
from different industrial background including: education, techni-
cal services, marketing, information technology, health care, and
ﬁnancial services. The demographic information shows that the
survey covers a representative sample of real-world users.

The participants seem to have a reasonable general computer
background as they ranked their general computer skill mostly as
good (40%) and excellent (45%). We asked the users about their
choice of username and password. The result shows that many
users reuse the same username and/or password over multiple ser-
vices. We will discuss in Section 7 that reusing the username may
help an attacker who has compromised the web-service and knows
the username of the victim to more successfully perform the ringing
attack on an application (e.g., Skype) with the same username.
Habits of Using Smartphone and Apps: All of our participants
said they have a smartphone. 80% of the participants said they
carry their phone all the time and they have their phone connected
to Internet always or most of the time. Most of the participants had
voice, text and data services activated in their plan. Apple iPhone

Table 2: Popularity of instant messaging applications and the default ring-
tones for each app among participants.

Popularity Default Ringtone

Application
Facebook
Skype
Google Voice
FaceTime
WhatsApp
Viber

87%
55%
41%
41%
36%
22%

67%
63%
66%
83%
66%
68%

Table 3: Popular ringtone setting for Samsung and iPhone.

Phone Brand

Apple

Samsung

Location
At home
At work
Asleep
At home
At work
Asleep

Ringing Setting

Silent Vibrate Default Custom
5%
20%
25%
13%
20%
27%

43%
64%
41%
13%
50%
20%

45%
16%
30%
40%
13%
37%

30%
11%
18%
37%
20%
20%

with over 39% and Samsung with 27% were the two most popu-
lar phone brands (other popular brands were: LG, Motorola, and
HTC). The information obtained from this part of the survey shows
that launching the introduced attack would be feasible, since many
of the participants have a smartphone with voice/data/text plans that
can be used by the attacker in an active attack.

All the participants in the survey said they frequently use phone
calling and text messaging applications. The most popular instant
messaging applications installed on participants’ phones were:
Facebook, Skype, Google Voice, FaceTime, WhatsApp and Viber.
Application with higher popularity (such as Skype) especially those
for which people use default ringing tone are the most attractive tar-
get applications for Sound-Danger. Table 2 summarizes the frac-
tion of participants who use a given app and the default ringtone
popularity among the participants who use the app.

We asked the participants about the kind of sounds they use for
each application on their smartphone. The more predictable the
ringtone is, the more successful the active ringtone attack would be
in Sound-Danger. For the phone calls and text messaging, vibra-
tion and default ringtone are the most popular settings, silent and
custom ringtone being less popular. It seems people tend to set the
vibration at work, and set the default ringtone while at home. While
still some participants tend to set custom ringtone for their phone
calls and text messaging, custom ringtone is not that popular for
instant messaging applications. More than half of the participants
set the default ringtone for the instant messaging applications. Vi-
bration is the second most popular setting for the instant messaging
applications. The participants said that during a day they keep their
phone on ringing mode or on vibrate mode about half the time,
while they set it on silent mode only once in a while. These mea-
sures show that the Sound-Danger active attacks that target users by
calling them on some popular instant messaging applications have a
higher chance to succeed. Apart from the instant messaging appli-
cation, launching a passive attack by playing the default alarm tone
seems quite feasible. About half of the participants set the default
alarm tone that the attacker can play locally at certain time of the
day to mimic the sounds of the victim’s phone. Table 3 summarizes
the popular ringing setting of the two most popular phone brands,
namely iPhone and Samsung among the participants, in three com-
mon situations: at home, at work and while asleep.

6. REAL-WORLD ATTACK STRATEGIES
The survey results in Section 5 help us devise real-world attack
strategies and estimate the corresponding attack success rates. The

915Table 4: Sound-Danger Attack Strategy (Tc = 0.1524): The percentage of compromised users at the beginning of each attack round i is denoted as
CNi. Effective attack success rate (Ef fi) of the attack at each round i depends upon the particular type of device victim is using (device), the particular
state of the device the attack is targeting (state), the iterative success rate for a number of login attempts (k) the attack will be repeated for (Itt), and the
percentage of currently uncompromised users the attack is targeted towards (U Ni), as shown in Equation 3. In our calculations, k = 3 all throughout. The
last column (CNi = 1 − U Ni) shows the percentage of compromised users (CN) after each attack round. Before the start of the attack, i.e., at round 0,
CN0 = 0% (U N0 = 100%). When the attack applies to all devices (e.g., vibrational attacks), the device probability (device) is 100%, and when it applies
to speciﬁc device types, iPhone and Samsung, the device probabilities are 39% and 27%, respectively. The highlighted cell represents the percentage of user
accounts successfully compromised in eight rounds, which may ﬁnish in less than a day.

Attack Round (i)

Attack Description

1
2
3
4
5
6
7
8

Vibration at work
iPhone call at work
Samsung call at work
Vibrate at night
iPhone call at night
Samsung call at night
iPhone alarm
Samsung alarm

Probabilities

x

state

device
100.00% 57.00% 85.40%
39.00% 16.00% 81.80%
27.00% 13.00% 81.80%
100.00% 30.00% 85.40%
39.00% 30.00% 81.80%
27.00% 37.00% 81.80%
39.00% 50.00% 100.00%
27.00% 50.00% 100.00%

Itt(k = 3)

Ef fi(k = 3)

Compromised User Accounts

(CNi = 1 − U Ni)

99.69%
99.40%
99.40%
99.69%
99.40%
99.40%
100.00%
100.00%

56.82%
2.68%
1.41%
11.69%
3.19%
2.40%
3.19%
1.88%

56.82%
59.50%
60.19%
72.60%
75.79%
78.19%
81.38%
83.27%

strategies to maximize the impact of the attack based on the target
user population under question.

effective success rate of the attack, for an adversary who does not
know (but can guess) the user’s behavior and their habits of using
the phone, can be calculated by multiplying the usage probabilities
we obtained from the survey by the success rates reported in our
correlation analysis of the attacks (Section 4).
Preliminaries: Let us call the success rate of the correlation-
based attack, as we presented in Table 1, as x (e.g., success rate
of a ringing attack for an attacker who knows the victim’s ring-
tone). Then, such attack would succeed with the probability p =
device×state×x, where device denotes the probability of owning
a speciﬁc type of device (e.g., Apple’s iPhone) and state denotes
the probability of the phone being in a particular state (e.g., default
ringtone at home). Note that the attacker can make multiple login
attempts at a given point of time to increase the chances of success.
In this case, for k iterations of login, the “Iterative success rate”
(termed Itt(k)), for a particular attack (with success rate x) can be
calculated as:

Itt(k) = 1 − (1 − x)k

(2)

The attacker repeats the above attack, with different attack vari-
ations, in multiple rounds. During each attack round i, the attacker
performs the attack with k iterations targeting the remaining un-
compromised users from round i − 1 (i.e., U Ni−1). Initially, no
users have been compromised (i.e., U N0 = 100%). Thus, the “Ef-
fective attack success rate” Ef fi(k), in round i with k iterations,
which represents the fraction of users the attacker has compromised
in round i, is given by:

Ef fi(k) = device × state × Itt(k) × U Ni−1

(3)

Note that device, state and Itt(k) do not depend on the at-
tack round per se, but rather they depend on the type of attack per-
formed, i.e., these values remain the same even when the order in
which the attack rounds are executed is changed. In contrast, Ef f
and U N depend upon the attack round.
A Concrete Sample Strategy: The attacker can devise a strategy
to compromise the maximum number of victims by choosing any
subset of the attack variations discussed in Section 3 and launch-
ing them in a particular order. In the rest of this section, we show
a sample attack strategy based on our online survey results (Sec-
tion 5) and a subset of our attacks (Table 1) in a speciﬁc order to
compromise about 83% of user accounts in a total period of less
than a day. Our attack strategy is summarized in Table 4. This is
only a sample strategy for demonstrating the overall effectiveness
of our attack. In practice, a real-world attacker can devise other

As in our Sound-Danger attack model, we start with the assump-
tion that the attacker has already obtained username, password,
phone number and timezone of each of the target users by compro-
mising a server and is trying to login to the victim user’s account
by: (1) entering the ﬁrst authentication factor (username and the
password), and (2) attacking the Sound-Proof application to prove
the possession of the second factor (the phone). We also assume
that the server throttles login attempt after three login trials to pre-
vent a login brute force attack (a common practice employed by
many web services). Therefore, we limit the attacker’s login at-
tempts to three, setting k = 3 in our attack strategy throughout.
We test our attack strategy against our implementation of Sound-
Proof with the threshold Tc = 0.1524.

We start with U N0 equal to 100.00% of the user accounts (no
account has yet been compromised). Since many of the users in
our survey indicated that they keep their phones in vibration mode
at work and this attack works irrespective of the device type, we
attack such users in the ﬁrst round. We know that 57.00% of
the users have their device in vibration mode at work (Table 3),
and the attack success rate x for the vibration attack is 85.42%
(Table 1). This yields the iterative attack success rate (Itt) in
this round to be 99.69%. Hence, the effective attack success
rate (Ef f1) for this attack is device × state × Itt × U N0 =
100.00% × 57.00% × 99.69% × 100.00% = 56.82%. This means
that we can compromise 56.82% of the users with the vibration
attack by just making three phone calls during work hours. The
calculations and success rates for this round of the attack are sum-
marized in Table 4, row 1. Compromising about 57% accounts in
just one round, for example, right after the password database was
leaked, would be a signiﬁcant threat. The attacker may stop here,
or continue to the next round to compromise more user accounts.

To attack the rest of the uncompromised users, U N1 = 43.18%,
after the ﬁrst round, we choose the next popular device and state
combination based on Table 3. Through our survey, we observed
that 39.00% of the users have iPhone. From Table 3, we know
that 16.00% of the users keep their device under default ringtone
at work. Therefore, in our strategy, the second attack round would
involve the default ringtone call for the “iPhone at work” users,
since we can have the maximum impact with this approach. From
Table 1, the attack success rate for default ringtone x is 81.80%,
which amounts to Itt equal to 99.40%. The effective attack suc-
cess rate (Ef f2) for this round of the attack is device × state ×

916Itt × U N1 = 39.00% × 50.00% × 16.00% × 43.18% = 2.68%.
Hence, after the second round of the attack, we have successfully
compromised 59.50% of the user population (56.82% in the ﬁrst
round plus 2.68% in the second round). This attack round is sum-
marized in Table 4, row 2. The attacker may continue for the
next few rounds in a similar fashion, as shown in Table 4.
In
case of alarm attack (round 7 and 8), the attacker needs to guess
when the alarm normally goes off at the victim’s end. Our user
survey reports that all of the users use alarm; however only 50%
of them use default alarm ringtone. Now, for a morning alarm,
we assume that users set their alarms at 5am, 6am, 7am, and
8am. For three attempts, the probability that the attacker plays
the alarm simultaneously with the victim’s alarm is 75% (3 out of
4). Hence, Ef f7 is calculated as device × state × x × U N6 =
39.00%×50.00%×100.00%×21.81%×75% = 3.19%. Similarly,
we calculate Ef f8 using the same alarm guessing probability. As
we can see, after the eighth round, our Sound-Danger system will
have compromised a total of over 83% of the user accounts.

Since we started the attack “at work”, and end it in the morning
time (with the alarm attack), it is fair to say that all the rounds
of the attacks will have ﬁnished over a period of less than a day.
A persistent attacker may continue further the next day, perhaps
trying other attacks at different points of time, and may gradually
compromise almost all user accounts in few days.

Finally, we re-calculated the success rate for the above attack
strategy against our implementation of Sound-Proof with threshold
values higher than Tc = 0.1524. We found that even when we in-
crease Tc, our attack strategy is still successful, by compromising
82.60% of the users with Tc = 0.18, and 81.52% with Tc = 0.2.
Hence, our attack strategy remains robust to increased thresholdiza-
tion, highlighting the overall vulnerability of Sound-Proof.

7. POTENTIAL MITIGATION

A natural defense against our attacks would be to disable the 2FA
system in the scenario when a call or a notiﬁcation is received (and
the corresponding sounds are played by the phone), or when an
alarm is triggered. Alternatively, the calls, notiﬁcations or alarms
could be disabled when the 2FA login takes place. This approach
is in line with the conﬁgurable feature of the iOS system to mute
the device when an app is recording, or block recording when the
device is playing sounds. However, such mitigation will prevent
the user from receiving calls/notiﬁcations or setting alarms while
logging into Sound-Proof enabled accounts, and could possibly de-
grade the usability of the phone system.

Another possible defense is to reduce the probability of guessing
the phone sounds. This defense relies on the user to prevent the at-
tack by picking ringtones that are difﬁcult for the attacker to predict
and possibly changing them frequently in order to stop the attacker
from attempting an exhaustive search. The analysis of the user sur-
vey in Section 5 shows that many users set the default ringtone for
the instant messaging applications (e.g., Skype or Facebook) that
makes it easier for an active attacker to predict the sound.

Similar to the custom ringtone, combination of sounds and/or
vibration is a possible defense mechanism. During our attack anal-
ysis, we noticed that the correlation reduces to below the thresh-
old value when the notiﬁcation sound is mixed with vibration and
the attacker plays only the notiﬁcation ringtone at its side. Simply
combining the ringtone and the vibration at the attacker’s side to
mimic the audio at the victim’s side does not work for the attacker
as we noticed that the vibration started at different point when the
ringtone starts playing at the victim’s phone. Hence, for a success-
ful attack, the combination should be precisely synced with the one

at the victim’s side (with the occurrence of vibration at the exact
position in the audio), which seems unlikely.

Our user survey shows that many users reuse their username over
multiple accounts. The security issues rising from reusing the pass-
word have been demonstrated previously (reuse of the password
helps the attacker, who compromises one service, to compromise
other accounts with the same password). In light of our attacks, the
reuse of the username raises a similar issue as that of the password
reuse. For example, an attacker who has compromised the web-
service and knows the username of the victim might successfully
perform the ringing attack on an application (e.g., Skype) with the
same username. Picking a different username for each account pre-
vents the attacker who has already compromised the server from
trying to launch our active attacks.

Any of the above defenses possibly introduce certain usability is-
sues. For example, users might prefer default notiﬁcation tone over
custom ringtone. Or reusing the username requires the user to re-
member multiple usernames associated with each account. Further
study is required to understand how these possible usability issues
may impact the user experience of the phone system while strength-
ening the security of Sound-Proof in the face of Sound-Danger.

8. DISCUSSION AND FUTURE WORK
Sound-Proof Demo Analysis: Karapanos et al. [17] have deployed
Sound-Proof demo app and released apps for Android4 and Apple5.
We set forth to analyze how the demo app (version 1.6 on Android)
performs against our attacks compared to our implementation of
Sound-Proof. We observed that the demo app uses higher value of
correlation threshold (Tc = 0.2) than the one reported in the paper
[17] (Tc = 0.13). As we only had access to the app binary (and not
source code), we could not directly ﬁgure out the values for other
parameters deployed in the demo app.

Our evaluation showed that FNR of the demo app (benign set-
ting) when the phone was kept beside the computer was quite high,
at 27.91%. When the phone was kept inside a bag/purse, FNR in-
creased to 50%. Compared to the results reported in [17], the higher
FNR might have been due to the use of higher value of correlation
threshold (and possibly other tighter parameters) than that reported
in the paper.

We then attacked the demo app with one active attack and one
passive attack. In the active attack trials, we made calls to the vic-
tim using WhatsApp.
In the passive attack trials, we tested the
demo app against alarm audio using two different devices (victim
uses Samsung Galaxy S5 while attacker uses LG G3). FPR for the
active attacks was found to be 38.46% while that for the passive
attacks was 64.71%. The attack success rate on the demo app is
less than that on our implementation of Sound-Proof. This may
again be due to the fact that the demo app uses higher value of
Tc (and possibly other stricter parameters). As shown in Table 1,
the success rate for different attacks against our implementation of
Sound-Proof decreased when T c was increased. Moreover, we no-
ticed that the average correlation provided by the demo app was
relatively high (e.g., the average correlation for the alarm clock is
0.29 with 0.16 as minimum correlation). Hence, if the demo app
had used the Tc reported in the paper [17] (Tc = 0.13), the alarm
attacks would have been 100.00% successful.

Furthermore, we analyzed for which parameters in our imple-
mentation of Sound-Proof will produce similar results to that by
Sound-Proof demo app. To this end, we recorded audio from two
devices simultaneously using both apps. We collected 30 audio
4https://play.google.com/store/apps/details?id=ch.soundproof
5https://itunes.apple.com/us/app/sound-proof/id1069858990

917instances and logged the correlation score from the demo app.
We calculated the correlation results for different length of audio
recorded (3s, 4s, 5s, and 6s) and for different threshold values
(0.1524, 0.18 and 0.2). We found that when we compared 6 sec-
ond long audio with Tc = 0.2, the scores from our app and the
demo app had the maximum correlation (we used the alternative
computation formula for Pearson’s r [18] to calculate the correla-
tion level). This suggests that the demo app is using 6-second long
audio snippets rather than 3-second.

Overall, this analysis suggests that the Sound-Proof demo app
uses much stricter parameters, which resulted in very high FNRs.
Notably, even with this parametrization resulting in very low us-
ability (high FNR), the Sound-Danger attack can still be successful
against the demo app, further validating its feasibility as a viable
real-work attack against Sound-Proof.
Attacking Sound-Proof Smartwatch Implementation: Sound-
Proof is currently implemented with a smartphone as the second
factor device. However, if Sound-Proof is implemented using other
devices, such as smartwatches, as brieﬂy discussed in [17], our
Sound-Danger attacks will still work. When an attacker makes a
call to the victim’s phone, the victim’s smartwatch would record the
ambient audio containing the call’s sound generated by the phone.
This audio sample recorded by the smartwatch is similar to the au-
dio samples recorded by the smartphone, hence these two audio
(from phone or from watch) should yield similar correlation val-
ues as that between the audio samples of phone and terminal. If
the smartwatch itself features a speaker and rings when a call or
a notiﬁcation is received, a similar attack will still apply. Android
Wear 1.4 provides support for the devices with embedded speak-
ers, such as Huawei watches and ASUS ZenWatch 2 available in
Google Store. Moreover, our preliminary study on smartwatches
shows that the current smartwatches do not feature high quality mi-
crophones as in phones and the correlation using the audio recorded
by a smartwatch has higher error rates compared to that using the
audio recorded by a phone. In the future, if smartwatches features
better microphones along with speaker hardware and become stan-
dalone devices (no companion device, like a phone, needed), these
smartwatches would still be vulnerable to our attacks.
Attacking Other Security Applications: As we will review in
Section 9, there are different systems which use audio as one
of the modalities to detect the co-presence of two devices. Co-
presence detection of two devices has generally been proposed in
the context of mobile payment applications to prevent relay attacks
[16, 22, 26]. Further, another security scheme is aimed for pairing
of devices based on common ambient audio signals [22]. How-
ever, the threat model for co-presence detection and device pairing
systems differs from that for 2FA systems. These systems do not
consider that the user information is leaked and that the attacker
may already know the phone numbers and other speciﬁcs associ-
ated with the corresponding users. Further, our attacks become dif-
ﬁcult against such co-presence detection systems as the attacker has
to interact with the point-of-sale (POS) payment terminal in a retail
store rather than the web browser under its full control.

If we extend the threat model of the above systems such that
the attacker knows the phone number/user id of the user, then our
attacks are applicable. A motivated attacker against co-presence
detection systems [16, 26] can go near a POS terminal and gener-
ate a ringtone audio at its side (let’s say in a jewelry store) while
a colluding attacker makes call/sends notiﬁcation to the victim’s
phone at the same time (let’s say in a restaurant). This will break
the co-presence detection system as audio at both ends can be dom-
inated by the ringer’s audio. In a similar vein, the security of device
pairing systems based on ambient audio [22] can be compromised.

Here, the attacker can perform an active attack to produce certain
sounds which will then be used by the pairing system as a seed
to generate a common secret between two devices. If the ringtone
dominates the ambient noise then the seed used by victim’s devices
can match with the seed at the attacker’s side.

9. RELATED WORK
Two-Factor Authentication: Most common and traditional form
of 2FA employs hardware tokens such as RSA SecurID [21] and
Yubico [27]. These hardware tokens are specialized devices used
solely for the purpose of authentication. Such schemes require
users to carry and interact with the token. These schemes may be
expensive to deploy because the service provider must provide one
such token per customer.

Many software tokens 2FA schemes are also available, includ-
ing Google 2-Step Veriﬁcation [14], Duo Push [12], and Celestix’s
HOTPin [3]. These schemes are both scalable and ﬂexible as single
personal device can be used with multiple services in such schemes.
These schemes are also cost effective, since deploying software to-
kens are logistically much simpler. These schemes prompt the user
with a push message on his phone with current login attempt infor-
mation and the user interacts with his phone to authorize the login.
PhoneAuth [11] is a software token 2FA scheme that leverages
Bluetooth communication between the browser and the phone, to
eliminate user-phone interaction. The Bluetooth channel enables
the server (through the browser) and the phone to run a challenge-
response protocol which provides second authentication factor.
This scheme requires browser to have Bluetooth communication
capability which is currently not available on many browsers. Au-
thy [10] is another approach that allows seamless 2FA using Blue-
tooth communication between the computer and the phone. How-
ever, Authy requires extra software to be installed on the computer.
Traditionally, these 2FA schemes increase resistance to online
dictionary attacks. The work of [23] presented several 2FA that
are enhanced to strengthen security against both online and ofﬂine
attacks. The main idea underlying all their 2FA protocols is for the
server to store a randomized hash of the password, h = H(p, s),
and for the device to store the corresponding random secret s. The
authentication protocol checks whether the user types the correct
password p and also that it can access the device that stores s.

SlickLogin [5] (recently acquired by Google) minimizes the user
phone interaction. It employs near-ultrasounds to transfer the veri-
ﬁcation code. The notion is to generate unique near-ultrasounds for
each login attempt and use the very non-audible audio to authorize
the attempt. To verify user’s identity, a website plays a uniquely
generated, nearly-silent sound through the computer’s speakers. An
app running on the user’s phone picks up the sound, analyzes it, and
sends the signal back to the site’s server. The server veriﬁes the user
with the possession of the phone as a second factor.
Co-Presence Detection: Similar to 2FA systems, co-presence de-
tection systems use different medium to verify the co-presence of
two devices. The common application of such co-presence detec-
tion system is to prevent relay attacks. Although relay attacks are
usually targeted attacks, we discuss them here as some of the sys-
tems using ambient audio can be thwarted with our attacks.

Schurmann et al. [22] use ambient sound to establish a secure
communication channel among devices based on similar audio pat-
terns. They exploit ambient sound as the seed to generate a com-
mon secret for the secure information exchange and authentication.
Halevi et al. [16] use ambient audio to detect the co-presence of
two devices in payment scenario. In an NFC transaction, they cor-
relate the audio collected from two devices (NFC phone and NFC

918reader) and validate if both devices are together. They mention that
if the attacker manipulates physical environment, it may succeed
in launching relay attack, however, the tampering with audio looks
like a daunting task and such activity can be easily detected.

Truong et al. [26] use various Radio Frequency (RF) sensors
such as Wi-Fi, Bluetooth and GPS besides audio to detect the co-
presence of two devices. In their work, they report that when the
system uses only audio to detect the co-presence between two de-
vices, F-measure is 0.933 with 4.09% FPR in benign setting. How-
ever, in an adversarial setting, the FPR rises to 100.00% where
the attacker manipulates the audio signal only. In their adversar-
ial setting, the attacker captures the ambient information (audio)
near device 1 and reproduces that information (audio) near device
2 without suppressing the ambient information sensed by device 2.
10. CONCLUSION

Zero-effort two-factor authentication is a compelling notion that
may push two-factor authentication towards wide-scale adoption
on the web. The idea of using ambient sounds to verify the user’s
possession of (or proximity to) the authentication token (phone) is
intriguing, which aims to remove the human user from the loop of
authentication (except of password entry). In this paper, we demon-
strated that the ambient audio approach to zero-effort two-factor
authentication is highly susceptible to a remote attack that makes
the phone record its own predictable sounds in the form of a ringer,
app-based notiﬁcations and alarms. Since these sounds are pre-
dictable, the attacker can generate the same (very similar or highly
correlated) sounds at the browser’s end under its full control and
succeed in logging into the user’s account. Further, by proactively
collecting statistics about a given population (not a speciﬁc user),
the attacker can devise a strategy that can allow the attacker to com-
promise a large fraction of users’ accounts in a short span of time.
Since the attack exploits the sounds of the phones, one obvious
defense would be to deliberately mute the phone at the time the lo-
gin takes place. However, this may reduce user experience since
important calls or notiﬁcations may be missed or delayed. Fur-
ther work is necessary to assess this and other potential mitigation
strategies we presented in the paper. Overall, our work serves to
call the security of a prominent, deployment-ready zero-effort two-
factor authentication scheme into question, highlight the tension
between the security and usability of two-factor authentication and
raise a demand for utmost care when attempting to design authen-
tication approaches transparent to the human user.
Acknowledgments & Disclosure
We would like to thank CCS 2016 anonymous reviewers, and Ab-
hishek Anand, Tzipora Halevi and Hugo Krawczyk for their useful
feedback on a previous version of the paper. This work has been
funded in part by NSF CNS-1526524 and CNS-1547350 grants.

We notiﬁed the authors of the Sound-Proof system [17] about the
reported vulnerability. The authors acknowledged the vulnerability
and indicated that they had applied several patches, in line with the
potential mitigations suggested in Section 7. While these ﬁxes may
serve to defeat the vulnerability, the usability of the system may
be reduced (as discussed in Section 7), which we believe is the
fundamental challenge in the design of zero-effort authentication
systems demanding continued future research.

References
[1] Anonymous
site

leaks database
#opisrael.

from israeli musical
act mag-
http://thehackernews.com/2012/12/

azine
anonymous-leaks-database-from-israeli.html.

[2] Bulgarian

torrent

tracker

forum hacked

and

accused

of

collecting
bulgarian-torrent-tracker-forum-hacked.html.

user

ip.

http://thehackernews.com/2012/11/

[3] Celestix hotpin two factor authentication. http://www.celestixworks.

com/HOTPin.asp.

hacked & agents

in-
http://thehackernews.com/2011/12/

of
leaked.

law enforcement

[4] Coalition
formation
coalition-of-law-enforcement-hacked.html.
the

[5] Google

slicklogin,

word
google-acquires-slicklogin-the-sound-based-password-alternative/.

pass-
http://techcrunch.com/2014/02/16/

sound-based

acquires
alternative.

[6] Hacker

leaks 250gb of nasa data,

hijack

to
nasa-data-leaked-nasa-drone-hacked/.

drone.

nasa

another group claims
https://www.hackread.com/

[7] Snapchat

hacked:

4.6 million

user

names,

phone

tial
http://www.abc15.com/news/local-news/water-cooler/
snapchat-hacked-46-million-user-names-partial-phone-numbers-leaked.

numbers

ABC15

leaked

-

par-
Arizona.

[8] Sony europe hacked by lebanese hacker...

again - naked
https://nakedsecurity.sophos.com/2011/06/04/

security.
sony-europe-hacked-by-lebanese-hacker-again/.

[9] What’s

in

the

released

ashley madison

hack-
ers
http://qz.com/482875/
whats-in-the-ashley-madison-database-that-hackers-released-online/.
Authy.

authentication

Two-factor

database

quartz.

online

Inc.

that

-

-

[10] Authy

https://www.authy.com/.

[11] A. Czeskis, M. Dietz, T. Kohno, D. Wallach, and D. Balfanz. Strength-
ening user authentication through opportunistic cryptographic identity
assertions. In ACM conference on Computer and communications se-
curity, 2012.

[12] Duo Security Inc. Easy, mobile two-factor authentication. https://duo.

com/solutions/features/user-experience/easy-authentication.

[13] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner. Android
permissions demystiﬁed. In ACM conference on Computer and com-
munications security, 2011.

[14] Google Inc. Google 2-step veriﬁcation. https://www.google.com/

landing/2step/.

[15] Google Inc. WebRTC. https://webrtc.org/.
[16] T. Halevi, D. Ma, N. Saxena, and T. Xiang. Secure proximity detection
for nfc devices based on ambient sensor data. In European Symposium
on Research in Computer Security. 2012.

[17] N. Karapanos, C. Marforio, C. Soriente, and S. Capkun. Sound-proof:
usable two-factor authentication based on ambient sound. In USENIX
Security Symposium, 2015.

[18] D. Lane. Computing Pearson’s r, 2003.

9zcGzDDu@4/Computing-Pearsons-r.

http://cnx.org/contents/

[19] MathWorks. Butterworth ﬁlter design. http://www.mathworks.com/

help/signal/ref/butter.html.

[20] U. of Illinois at Urbana-Champaign. Center frequencies and high/low
frequency limits for octave bands, 1/2- and 1/3-octave bands, 2011.
https://courses.physics.illinois.edu/phys193/labs/octave_bands.pdf.

[21] RSA. Securid | rsa security token based authentication.

https://
www.rsa.com/en-us/products-services/identity-access-management/
securid.

[22] D. Schurmann and S. Sigg. Secure communication based on ambient

audio. IEEE Transactions on Mobile Computing, 12(2), 2013.

[23] M. Shirvanian, S. Jarecki, N. Saxena, and N. Nathan. Two-factor au-
thentication resilient to server compromise using mix-bandwidth de-
vices. In Network and Distributed System Security Symposium, 2014.
[24] J. Sunshine, S. Egelman, H. Almuhimedi, N. Atri, and L. F. Cra-
nor. Crying wolf: An empirical study of ssl warning effectiveness.
In USENIX Security Symposium, 2009.

[25] The Engineering ToolBox. Octave bands - frequency limits. http:

//www.engineeringtoolbox.com/octave-bands-frequency-limits-d_
1602.html.

[26] H. T. T. Truong, X. Gao, B. Shrestha, N. Saxena, N. Asokan, and
P. Nurmi. Comparing and fusing different sensor modalities for re-
lay attack resistance in zero-interaction authentication. In Pervasive
Computing and Communications, 2014.

[27] Yubico AB. Trust the net with yubikey strong two-factor authentica-

tion. https://www.yubico.com/.

919