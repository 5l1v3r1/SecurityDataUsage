Trends and Lessons from Three Years Fighting 

Malicious Extensions

Nav Jagpal, Eric Dingle, Jean-Philippe Gravel, Panayiotis Mavrommatis,  

Niels Provos, Moheeb Abu Rajab, and Kurt Thomas, Google

https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/jagpal

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXTrends and Lessons from Three Years Fighting Malicious Extensions

Nav Jagpal Eric Dingle

Jean-Philippe Gravel

Panayiotis Mavrommatis

Niels Provos Moheeb Abu Rajab Kurt Thomas

Google

{nav, ericdingle, jpgravel, panayiotis, niels, moheeb, kurtthomas}@google.com

Abstract

In this work we expose wide-spread efforts by crimi-
nals to abuse the Chrome Web Store as a platform for
distributing malicious extensions. A central compo-
nent of our study is the design and implementation of
WebEval, the ﬁrst system that broadly identiﬁes mali-
cious extensions with a concrete, measurable detection
rate of 96.5%. Over the last three years we detected
9,523 malicious extensions: nearly 10% of every ex-
tension submitted to the store. Despite a short window
of operation—we removed 50% of malware within 25
minutes of creation— a handful of under 100 extensions
escaped immediate detection and infected over 50 mil-
lion Chrome users. Our results highlight that the exten-
sion abuse ecosystem is drastically different from ma-
licious binaries: miscreants proﬁt from web trafﬁc and
user tracking rather than email spam or banking theft.

1

Introduction

Browsers have evolved over recent years to mediate a
wealth of user interactions with sensitive data. Part of
this rich engagement includes extensions: add-ons that
allow clients to customize their browsing experience by
altering the core functionality of Chrome, Firefox, and
Internet Explorer. Canonical examples include search
toolbars, password managers, and ad blockers that once
installed intercept webpage content through well-deﬁned
APIs to modify every page a user visits.

Criminals have responded in kind by developing ma-
licious extensions that interpose on a victim’s brows-
ing sessions to steal information, forge authenticated re-
quests, or otherwise tamper with page content for ﬁnan-
cial gain. Poignant malware strains include Facebook
account hijackers, ad injectors, and password stealers
that exist purely as man-in-the-browser attacks [21, 25,
37, 41]. While many of these threats have binary-based
equivalents—for instance the Torpig banking trojan that

injected rogue phishing forms into banking webpages or
the ZeroAccess bot that tampered with page advertise-
ments [27, 34]—extensions bridge the semantic gap be-
tween binaries and browsers, trivializing broad access to
complex web interactions.

In this paper we expose wide-spread efforts by crim-
inals to abuse the Chrome Web Store as a platform for
distributing malicious extensions. Our evaluation cov-
ers roughly 100,000 unique extensions submitted to the
Chrome Web Store over a three year span from January
2012–2015. Of these, we deem nearly one in ten to
be malicious. This threat is part of a larger movement
among malware authors to pollute ofﬁcial marketplaces
provided by Chrome, Firefox, iOS, and Android with
malware [7, 10, 42].

A central component of our study is the design and
implementation of WebEval, the ﬁrst system that broadly
identiﬁes malicious extensions with a concrete, measur-
able detection rate of 96.5%. We arrive at a verdict
by classifying an extension’s behaviors, code base, and
developer reputation.
In the process, we incorporate
existing techniques that detect speciﬁc malware strains
and suspicious extension behaviors and evaluate each of
their effectiveness in comparison to our own [21,37,41].
WebEval also faces a unique challenge: live deployment
protecting the Chrome Web Store where attackers have
a strong incentive to adapt to our infrastructure. We ex-
plore the impact that evasive threats have on our overall
accuracy throughout our deployment and the necessity of
human experts to correct for model drift.

In total, we removed 9,523 malicious extensions from
the Chrome Web Store. The most prominent threats in-
cluded social network session hijackers that generated
synthetic likes, friend requests, and fans; ad injectors
that rewrote DOM content to laden pages with addi-
tional advertisements; and information stealers that in-
jected rogue tracking pixels and covertly siphoned search
keywords. Despite a short window of operation—we re-

USENIX Association  

24th USENIX Security Symposium  579

1

ported 50% of malware within 25 minutes of creation—
a handful of under 100 malicious extensions distributed
via binary payloads were able to infect nearly 50 million
users before removal. We distill these observations into
a number of key challenges facing app marketplaces that
extend beyond just the Chrome Web Store.

In summary, we frame our contributions as follows:
• We present a comprehensive view of how malicious
extensions in the Chrome Web Store have evolved
and monetized victims over the last three years.

• We detail the design and implementation of our
security framework that combines dynamic analy-
sis, static analysis, and reputation tracking to detect
96.5% of all known malicious extensions.

• We highlight the importance of human experts in
operating any large-scale, live deployment of a se-
curity scanner to address evasive malware strains.
• We explore the virulent impact of malicious exten-
sions that garner over 50 million installs; the single
largest threat infecting 10.7 million Chrome users.

2 Background

We provide a brief background on how users ob-
tain extensions and the control extensions have over the
Chrome browser that simplify malware development.

2.1 Chrome Web Store
The Chrome Web Store is the central repository of all
Chrome extensions. While initially the store was an op-
tional ecosystem, rampant abuse outside of the store lead
to Chrome locking down all Windows machines in May
2014 [13]. With this policy decision, Chrome now au-
tomatically blocks all extensions not present in the store
from installation.

The Chrome Web Store relies on built in protections
against malware that subject every extension to an abuse
review. This approach is not unique to Chrome: Fire-
fox, iOS, and Android all rely on application reviews to
protect their user base from malware [1, 14, 17]. Mali-
cious extensions detected during preliminary review are
never exposed to the public.
In the event the Chrome
Web Store retroactively detects a malicious extension,
the store can take down the offending code and signal for
all Chrome clients to expunge the extension [16]. This
defense layer provides a homogeneous enforcement pol-
icy for all Chrome users compared to the heterogeneous
security environments of their desktop systems that may
have no recourse against malicious extensions.1

2.2 Chrome Extension Architecture

Developers author extensions much like websites us-
ing a combination of JavaScript, CSS, and HTML. Un-
like websites, extensions are exempt from same ori-
gin protections and are afforded a range of Chrome
and document-level controls that allow customizing how
users interact with the Internet.
Permissions: Extensions may interact with privileged
Chrome resources such as tabs, cookies, and network
trafﬁc through a Chrome-speciﬁc API. Chrome me-
diates these sensitive capabilities through a coarsely
deﬁned permission model where a permission con-
sists of a resource (e.g.,
cookies) and a scope
(e.g., https://mail.google.com) [4]. When a developer au-
thors an extension, she lists all desired permissions in a
static manifest. As discussed by Carlini et al., this design
favors “benign but buggy” extensions where the author
adheres to a principle of least privilege [9]. The model
provides no protection against malicious extensions be-
yond explicitly signaling broad capabilities (e.g., inter-
cepting all network trafﬁc).
Background Page & Content Scripts: Chrome loads
an extension’s core logic into a long running process
called a background page. This privileged process ob-
tains access to all of the Chrome API resources speci-
ﬁed in the extension’s permission manifest. To prevent
permission re-delegation attacks, Chrome isolates back-
ground pages from all other extensions and web sites.
Chrome eases this isolation by allowing extensions to
register content scripts that run directly in the context of a
web page as though part of the same origin (and thus with
access to all of the origin’s DOM content, DOM meth-
ods, and session cookies). Background pages communi-
cate with content scripts through a thin message passing
layer provided by Chrome. As with the Chrome API,
extensions must specify content scripts and the targeted
domains in an extension’s manifest.

3 System Overview

We develop our system called WebEval to protect the
Chrome Web Store from malicious extensions. The chal-
lenge is messy and fraught with evasive malware strains
that adapt to our detection techniques. We rely on a blend
of automated systems and human experts who work in
conjunction to identify threats and correct for failures
surfaced by user reports of abuse. Before diving into de-
tailed system operations, we highlight the design princi-
ples that guided our development and offer a birds eye
view of the entire architecture’s operation.

1Chrome extensions are not supported on Android or other mobile
platforms. As such, we limit our discussion of malicious extensions to

desktop environments.

580  24th USENIX Security Symposium 

USENIX Association

2

3.1 Design Goals
At its heart, WebEval is designed to return a verdict for
whether an extension is malicious.
If the extension is
pending publication, the Chrome Web Store should block
the extension from release. Previously published exten-
sions must be taken down and uninstalled from all af-
fected Chrome instances. Arriving at a malware verdict
is constrained by multiple requirements:

1. Minimize malware installs. Our foremost goal with
WebEval is to minimize the number of users ex-
posed to malicious extensions. However, near-zero
false positives are imperative as Chrome expunges
an extension’s entire user base if we return a mal-
ware verdict incorrectly. We design our system such
that human experts vet every verdict prior to action-
ing.

2. Simplify human veriﬁcation. Whenever possible,
our system should be fully automated to minimize
the time required from human experts to conﬁrm an
extension is malicious.

3. Time-constrained. Our system embargoes exten-
sions from public release until we reach a verdict.
Its critical that we return a decision within one hour.
Relatedly, our system must scale to the throughput
of newly submitted items to the Chrome Web Store
and weekly re-evaluated extensions that we estimate
at roughly 19,000 reviews/day.

4. Comprehensible, historical reports. Any automated
reports produced by our system must be com-
prehensible to human analysts, including machine
learning verdicts. Similarly, all reports should con-
tain some annotation to allow a historical perspec-
tive on the evolution of malicious extensions.

5. Tolerant to feature drift. Finally, our system must
keep pace with the evasive nature of malware and
adaptations in monetization strategies. This in-
cludes allowing experts to easily deploy new rules
to capture emerging threats that are then automati-
cally incorporated into long-running detection mod-
ules.

3.2 System Flow
WebEval is a living system that has evolved over the last
three years in response to threats facing the Chrome Web
Store. We describe our current pipeline for classifying an
extension as malicious in Figure 1. The system consists
of four stages: () a scheduler that submits extensions
for evaluation; () our extension execution framework
that captures behavioral signals; () an annotation phase

that incorporates content similarity, domain reputation,
and anti-virus signatures; and ﬁnally () scoring where
manually curated rules, an automated classiﬁer, and hu-
man experts reach a verdict for whether an extension is
malicious.
Scheduler: We feed every extension uploaded to the
Chrome Web Store, either new or updated, into our sys-
tem and analyze it within one hour of submission.
In
total, we analyzed 99,818 Chrome extensions submitted
over the course of January 2012–January 2015. This set
includes extensions that were blocked prior to public re-
lease.2 Furthermore, we have access to each revision of
the extension’s code base: over 472,978 unique variants
(measured by SHA1 sums). Each revision triggers a re-
scan in addition to a weekly re-scan aimed at extensions
that fetch dynamic, remote resources that can become
malicious.
Evaluation: We subject every extension to an evalu-
ation phase that extracts behavioral signals for classi-
ﬁcation. This includes a reputation scan of the pub-
lisher, static analysis of the extension’s code base, and
dynamic analysis that emulates common tasks performed
in Chrome: querying search engines, visiting social me-
dia, and browsing popular news sites. We store all raw
features for posterity, totaling over 45 TB. Our philoso-
phy is to retain everything (even packet contents) in or-
der to enable ofﬂine analysis in the event an extension
becomes defunct due to dead or broken remotely fetched
resources. This storage simultaneously enables tracking
trends in malware behavior over time and retroactively
applying new malware signatures. We present the full
details of our evaluation framework in Section 4.
Annotation: We practice a defense in depth strategy that
incorporates domain blacklists, anti-virus engines, and
content similarity that contextualizes an extension’s be-
haviors against the larger ecosystem of malicious devel-
opers and extensions. We include these signals as anno-
tations to an extension’s evaluation in the event our own
behavioral suites fail to surface any malicious logic. We
present the annotation process in greater detail at the end
of Section 4.
Scoring: The ﬁnal step of WebEval returns a verdict
for whether to expunge a malicious extension. We use
a combination of manually curated rules and a logistic
regression classiﬁer re-trained daily over all previously
detected malicious extensions to generate a score. A hu-
man expert then conﬁrms our automated verdict before
passing our decision on to the Chrome Web Store to take
action. We present our technique for training, regulariza-

2We note that any extensions blocked prior to release are absent
from the previous work by Kapravelos et al. [21] that studied malicious
extensions found in the Chrome Web Store.

USENIX Association  

24th USENIX Security Symposium  581

3

Figure 1: Our pipeline for detecting malicious extensions. WebEval’s architecture consists of a scheduler, extension execution
framework, an annotator that incorporates third-party security intelligence, and ﬁnally scoring where we return a malware verdict.

tion, and manual decision rules in Section 5. We discuss
our approach for obtaining labeled data and evaluating
our system’s accuracy later in Section 6.

4 Evaluating Extensions

WebEval’s core automation systems generate a report
that surfaces signals about an extension’s code base, the
impact it has a user’s browsing experience, and who de-
veloped the extension. With a few exceptions, none of
these signals in isolation indicate outright malice: we
leave it up to our classiﬁer and human experts to deter-
mine which combinations of features clearly distinguish
malware.

4.1 Static Analysis
Apart from remotely fetched resources, all of an exten-
sion’s HTML, CSS, JavaScript, and manifest are self-
contained and available to the Chrome Web Store upon
submission. We scan through these components to iden-
tify potential threats.
Permissions & Content Scripts: We enumerate all an
extension’s permissions, content scripts, and contexts.
Permissions in particular offer some indication of an ex-
tension’s capabilities such as intercepting and modify-
ing trafﬁc (proxy, webRequest), triggering on a page load
(tabs), introspecting on all cookies (cookies), and unin-
stalling or disabling other extensions (management). As
part of this process we also identify broad contexts (e.g.,
<all urls>, https://*) that allow an extension to interact
with every page.
Code Obfuscation: We scan for the presence of three
types of code obfuscation: miniﬁcation, encoding, and
packing. We build on the detection strategy of Kaplan
et al. that identiﬁes common character substrings found
in obfuscated vs. unobfuscated code [20]. Instead of de-
tecting individual characters, we develop a set of regular
expressions that identiﬁes boilerplate initialization tied

to the most prominent packers (e.g., jsmini.com, jscom-
press.com, and /packer/). We employ a similar approach
for detecting long encoded character strings. Finally, we
detect miniﬁcation by measuring the distance between a
prettiﬁed version of an extension’s JavaScript against the
original supplied by the developer.
Files and Directory Structure: We extract the ﬁle
names and directory structure of an extension as well
as text shingles of the contents of every ﬁle. We rely
on these features for detecting near-duplicate extensions
(discussed in Section 4.4) as well as identifying com-
monly imported libraries and malicious ﬁles.

4.2 Dynamic Analysis

We collect the majority of our malware signals by black-
box testing each extension with a barrage of behavioral
suites that simulate common browsing experiences as
well as custom tailored detection modules that trigger
malicious logic. While more exhaustive approaches such
as symbolic JavaScript execution exist [32], in practice
we obtain sufﬁcient enough behavioral coverage to reach
accurate malware verdicts as discussed in Section 6.
Sandbox Environment: Our testing environment con-
sists of a Windows virtual machine outﬁtted with two
logging components: (1) a system monitor that captures
low-level environment changes such as Windows set-
tings, Chrome settings, and ﬁle creation; and (2) an in-
browser activity logger that interposes on and logs all
DOM events and Chrome API calls. This activity logger
is natively built into Chrome explicitly for monitoring
the behavior of extensions [28]. We note that Chrome
isolates extensions from this logging infrastructure. Ex-
tensions cannot tamper with our results unless they com-
promise Chrome itself.

We supplement our monitoring infrastructure by rout-
ing all network trafﬁc through a network logging proxy.
This proxy also serves as a replay cache. For each test

582  24th USENIX Security Symposium 

USENIX Association

4

suite we develop, we ﬁrst record the network events pro-
duced by Chrome absent any extension installed. During
dynamic evaluation we replay any network events from
the cache that match. If a cache miss occurs, we route
requests out of our sandbox to the Internet. This proxy
allows us to minimize page dynamism, guarantee that
test suites are consistent across executions absent new
dynamic behavior, and reduce overall network round trip
time. Similarly, we can easily ﬂag network requests pro-
duced by our test actions (e.g., a click or fetching ad con-
tent) versus those produced by an extension.

The output of our dynamic analysis is a list of all net-
work requests, DOM operations, and Chrome API calls
made by an extension. Each of these include the page the
event occurred on as well as the remote target of XHR
requests and injected scripts. We supply all of these as
raw features to our classiﬁer as well as to human experts
who can generate manual rules that capture sequences of
events tied to known malware strains.
Behavioral Suites: The event driven nature of exten-
sions requires that we replay realistic browsing scenar-
ios to trigger malware. Our system allows human ex-
perts to record complex interactions (e.g., clicks, text
entry, etc) with webpages that we then replay against
every extension to detect malicious behaviors. These
simulations, called behavioral suites, cover querying
google.com with multiple searches; logging into face-
book.com via a test account and viewing the account’s
news feed; shopping on amazon.com and walmart.com;
and lastly browsing popular media sites including ny-
times.com and youtube.com. As new threats arise, ana-
lysts can easily deploy new behavioral suites to trigger a
malicious extension’s logic.
Generic Suites: Our replay suites are by no means ex-
haustive; we rely on a generic set of test suites to simulate
a wider variety of browser events. These tests are dupli-
cates of the techniques previously discussed by Kaprav-
elos et al. for Hulk [21] and include simulating network
requests to popular news, video, shopping, and banking
sites to trigger an extension’s webRequest handler as well
as using HoneyPages that create dummy elements on the
ﬂy to satisfy JavaScript requests from extensions.
Malicious Logic Suites: We supplement our browsing
actions by explicitly testing an extension’s logic against
known threats: uninstalling other extensions (e.g., anti-
virus, Facebook malware remover); preventing unin-
stallation by terminating or redirecting tabs opening
chrome://extensions; and stripping or modifying Content
Security Policy headers. We explicitly ﬂag each of these
activities in addition to the log signals produced through-
out the extension’s evaluation.

4.3 Developer Analysis
The closed-garden nature of the Chrome Web Store en-
ables tracking ﬁne-grained reputation about developers
and the extensions they author. We monitor where devel-
opers log in from, the email domain they use to register,
the age of the developer account, and the total number of
extensions authored thus far. These signals help us de-
tect fake developer accounts that miscreants register via
commonly abused email providers and proxies, staples
of abusive account creation [39]. We note that newly
registered developers must pay a nominal one-time fee
of $5 that increases the overhead of churning out fake
accounts [15].

In the event a malicious extension escapes initial de-
tection, we also incorporate signals generated from users
interacting with the Chrome Web Store. These includes
the number of installs an extension receives, the number
of users who have rated the extension, and the average
rating. Our intuition is that highly used extensions that
never receive any feedback are suspicious as are exten-
sions that receive many low ratings.

4.4 Annotation
In the event the signals we collect during evaluation are
insufﬁcient, we rely on a defense in depth strategy that
incorporates intelligence from the broader security com-
munity. In particular, we scan all of the ﬁles included in
an extension with multiple anti-virus engines similar to
VirusTotal.3 If any single anti-virus vendor reports a ﬁle
as malicious we ﬂag the ﬁle in our report. We extend a
similar strategy to all of the outgoing network requests
produced by an extension where we scan the domains
contacted against Google Safe Browsing and a collection
of domain blacklists.

We also evaluate an extension in the context of all
previously scanned extensions. We take the text shin-
gles of an extension’s code base computed during static
analysis and identify near-duplicate extensions that share
80% of the same code. This approach allows us to detect
extension developers that routinely re-upload previously
detected malicious extensions. We extend this cluster-
ing logic to group extensions based on common embed-
ded strings such as Google Analytics UIDs, Facebook
App IDs, and Amazon Afﬁliate IDs. Finally, for exten-
sions that evade initial detection and are released to the
Chrome Web Store, we cluster the extensions based on
the referrer of all incoming install requests to identify
common websites involved in social engineering. We
surface these clusters to human experts along with the
ratio of known malware in each cluster.

3Due to licensing agreements, we are unable to disclose which anti-

virus software we scan with.

USENIX Association  

24th USENIX Security Symposium  583

5

5 Scoring Extensions

We reach a concrete verdict of an extension’s malice
by ﬂagging any extension caught by our automated clas-
siﬁer or manually constructed heuristics. A human ex-
pert then veriﬁes our decision and removes the offending
extension from the Chrome Web Store if appropriate.

5.1 Automated Detection
Our automated detection uses a proprietary implemen-
tation of an online gradient descent logistic regression
with L1 regularization to reduce the size of our feature
space [6]. We believe similar accuracy can be achieved in
a distributed fashion with the open source machine learn-
ing libraries provided by Spark [33]. We train a model
daily over all previously scanned extensions with labeled
training data originating from human experts (discussed
shortly in Section 6).

Our feature set for classiﬁcation consist of a collection
of over 20 million signals. For each extension we con-
struct a sparse string feature vector that contains every
requested permission, the contexts the extension oper-
ates on, whether obfuscation was present, and a string
representation of all of the extension’s ﬁle names and
directory structure. From dynamic analysis we include
a feature for every DOM operation, Chrome API call,
XHR request, remotely contacted domain, and a bit for
whether the extension uninstalled a security related ex-
tension, prevented uninstallation, or modiﬁed CSP head-
ers. From the developer analysis we include the email
domain, last login geolocation, and a discretized bucket
of the developer account’s age.

We exclude annotation signals from learning; they are
only used by human experts for manually curating rules
and analyzing clusters of badness. We also exclude text
shingles both to limit our feature space and retain mean-
ingful signals. Our philosophy is that any input to the
classiﬁer should have a direct translation to an activity
that analysts can recognize rather than loosely contextu-
alized text blobs.

As part of the learning stage, we assign each feature a
weight which we optimize using a gradient descent on a
logistic regression model. In particular, we use L1 reg-
ularization to reduce our feature set to roughly 1,000 of
the most impactful features. These features become de-
cision rules, which we use to classify new extensions.
Because human reviewers cannot look at every single ex-
tensions in the Web Store, we have variable conﬁdence
in the malware or benign labels assigned to training in-
stances. To compensate for this, we multiply the gradi-
ent descent learning rate with a correction factor that is
proportional to an approximate conﬁdence level. Every
known malware items gets a correction factor of 1.0 due

to prior vetting by a human expert. On the other hand,
the learning rate for benign items is scaled down by the
following factor:

min( P
Pt

f =

,1.0) +min( A
At

2

,1.0)

We represent the popularity of an extension P as the num-
ber of existing installs and the age of an extension A as
the number of days since the extension was published.
Pt and At represent thresholds above which we omit any
penalty. This correction factor captures the risk that a
new extensions with no user base is malicious and yet
to be identiﬁed, while seasoned extensions with tens of
thousands of users are likely benign.

For the sake of tuning the learning pipeline, we use
5-folds cross validation to conﬁrm we do not overﬁt the
model. The ﬁnal model we use in production is trained
on 100% of the data available. For the purposes of our
study, we evaluate our model based on its accuracy the
next day rather than relying on a holdout golden dataset.
5.2 Manual Rules
We supplement our automated detection with manually
curated rules generated by human experts that address
many of the most prominent threats facing the Chrome
Web Store (discussed later in Section 7). While these
rules are fall backs in the event our automated classi-
ﬁer fails, they are immensely helpful in contextualizing
the monetization strategy of malicious extensions that we
track over time. We note that all extensions surfaced by
these rules are still subject to expert veriﬁcation.
Facebook Hijacking: Initial reports of malicious exten-
sions hijacking a victim’s Facebook account to post sta-
tus updates, send chat messages, befriend users, or “like”
content without consent ﬁrst emerged in 2012 and have
persisted ever since [29]. We detect these extensions by
scanning network logs produced during dynamic eval-
uation for outgoing network POSTs to resources (e.g.,
ajax/follow/follow proﬁle.php) that may indicate unau-
thorized account behavior.
Ad Injection: Ad injection extensions insert or replace
web advertisements. We identify this behavior by com-
paring the origin of inserted DOM elements and injected
scripts against a list of known advertisers derived from
third party ad block software, previous reports on ad in-
jection afﬁliate programs [37, 41], and domains surfaced
during manual review. We also scan for DOM operations
that replace existing advertisements on any of the pages
visited during our behavioral suites where we know ad
positions a priori.

584  24th USENIX Security Symposium 

USENIX Association

6

Search Leakage: Search leakage broadly refers to any
extension that funnels search queries to third parties, typ-
ically for modifying search results, injecting advertise-
ments, or tracking user interests. We detect search leak-
age by scanning outgoing network requests to determine
whether they contain the same keywords our behavioral
suite supplies to google.com. This module may poten-
tially miss term leakage in the event of encrypted or ob-
fuscated network parameters.
User Tracking: We rely on a heuristic to detect user
tracking that involves scanning all DOM operations for
the insertion of 0×0, 1×1, or hidden image during dy-
namic analysis. We consider any such operation a likely
indicator of inserting a tracking pixel.

6 Evaluation

We evaluate WebEval under a live deployment and
track daily accuracy as vetted by human experts. As part
of our analysis we offer insights into the most important
features for classiﬁcation and the role of human experts
in correcting for evasive strains.
6.1 Dataset
Our evaluation dataset consists of 99,818 extensions
scored by WebEval between January 2012–2015. Hu-
man experts provided our ground truth labels. Due to the
possibility of delayed detection we continue to update
labels one month after the cut off for our dataset. In to-
tal, experts identiﬁed 9,523 malicious extensions (9.4%
of all extensions created during the same window). For
the purposes of our evaluation, we deﬁne WebEval’s ver-
dict as a false positive if WebEval returned a malware
label that was either rejected as incorrect by human ex-
perts or later refuted by the extension’s developer and
overturned upon secondary review. Similarly, we deﬁne
a false negative as any extensions surfaced by human ex-
perts or external reports despite our system returning a
benign verdict. We likely underestimate false negatives
as some threats are bound to escape both automated and
external review.
6.2 Overall Accuracy
We measure the precision and recall of WebEval as a
function of all scored extensions over the last three years.
In total, our machine learning pipeline and manually cu-
rated rule sets surfaced 93.3% of all known malicious
extensions to human experts (recall). Of the extension’s
that WebEval ﬂagged as potentially malicious, human
experts agreed 73.7% of the time (precision). If we re-
strict our calculation to the last year, WebEval had a
recall of 96.5% and a precision of 81%. We ﬁnd that
accuracy is a living process that we detail in Figure 2.

100%

e
r
u
s
a
e
M

80%

60%

40%

G

G

G

G

G G

G

G

G G

G G

G

G

G

07/12

01/13

07/13

G

G

G

G G

G

G

G

G

G

G

G

G

G

G

G

01/14

07/14

01/15

G precision

recall

Figure 2: Monthly precision and recall of all scoring systems
in aggregate from 2012–2015.

100%

e
r
u
s
a
e
M

75%

50%

25%

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

GG

01/14

04/14

GGG

GG
G
G

G

GGGGG
G

G

GGG

G

G

G

G

G

G

G

GG

G

G

G

07/14

10/14

01/15

G precision

recall

Figure 3: Weekly precision and recall of logistic regression
classiﬁer from 2014–2015.

We experience drops in recall when new threats emerge
which we subsequently recover from via updated rules
and daily retraining of our classiﬁer with new samples.
We consistently value recall over precision: we would
rather burden human experts with more reviews rather
than expose users to malicious extensions. Nevertheless,
our precision is reasonable enough as to not force human
experts to review every extension in our dataset.

6.3 Automated Classiﬁer Accuracy
Ideally WebEval can run in a purely automated fashion
without curated rules or expert veriﬁcation. We evaluate
this possibility by calculating the precision and recall of
our logistic model, shown in Figure 3. Over the last year
our classiﬁer surfaced 77% of known threats. Human ex-
perts agreed with our model’s verdict 86% of the time.
Overall performance has steadily increased over time
with the addition of new features, an increasing train-
ing corpus, and increasingly frequent model retraining.
Accuracy of the classiﬁer during the ﬁnal two weeks of
our evaluation boasted 98% precision and 91% recall—
on par with human experts. However, new threats al-
ways require human intervention as indicated by consis-
tent drops in recall throughout time: while the model can
quickly recover with daily retraining, we maintain that

USENIX Association  

24th USENIX Security Symposium  585

7

Requested Permission
tabs
webRequest
webRequestBlocking
notiﬁcations
contextMenus
storage
webNavigation
cookies
unlimitedStorage
idle

Precision Recall
84%
39%
27%
27%
26%
25%
19%
14%
13%
10%

12%
23%
22%
14%
15%
9%
21%
10%
14%
27%

DOM Operation
eval
Window.navigator
XMLHttpRequest.onreadystatechange
XMLHttpRequest.open
Document.createElement
Window.setTimeout
Node.appendChild
HTMLElement.onload
HTMLScriptElement.src
Window.location

Precision Recall
76%
59%
56%
53%
47%
46%
45%
30%
25%
12%

10%
19%
31%
21%
20%
18%
20%
25%
51%
23%

Table 1: Top 10 permissions requested in extension manifest.

Table 3: Top 10 DOM operations performed during dynamic
execution.

Chrome API
12%
runtime.onInstalled
29%
tabs.onUpdated
21%
runtime.connect
25%
extension.getURL
47%
tabs.executeScript
31%
tabs.query
46%
runtime.onConnect
43%
tabs.get
browserAction.setBadgeText
28%
browserAction.setBadgeBackgroundCol... 39%

Precision Recall
79%
61%
50%
34%
31%
27%
25%
24%
23%
21%

Table 2: Top 10 Chrome API calls performed during dynamic
execution.

experts must always be part of our pipeline to minimize
both false positives and false negatives. This is an imme-
diate consequence of a centralized market for extensions
where there are limited external sources of labeled train-
ing data. In contrast, email and telephony spam systems
can rely on honeypots and informed users to readily gen-
erate representative daily training data. While our human
throughput currently scales to the size of the Chrome
Web Store, larger ecosystems face a signiﬁcant challenge
for sustainable accuracy.
6.4 Relevance of Individual Signals
WebEval is an amalgam of behavioral signals where no
single feature captures the majority of malicious exten-
sions. We examine assumptions we had of certain be-
haviors, whether they are unique to malware, and which
signals are the most important to classiﬁcation.
Requested Permissions: We list the most popular per-
missions used by malware and benign extensions in Ta-
ble 1. These permissions include allowing an extension
to trigger when Chrome creates a new tab (84% of all
malware) or when Chrome generates a network request
(39%). While these behaviors appear fundamental to
malware they are equally prevalent in benign applica-

Behavioral Signal
XHR Request
Code Obfucsation
Script Injected
HTTP 400 Error
Modiﬁes CSP Headers
Uninstalls Extension
Prevents Uninstallation

Precision Recall
52%
25%
19%
9%
2%
0.5%
0.1%

30%
21%
50%
41%
86%
96%
100%

Table 4: Precision and recall of individual behavioral signa-
tures.

tions. This observation captures a signiﬁcant limitation
of the current Chrome permission model as applied to-
wards security judgments: coarse permissions required
by all extensions provide no indication that an exten-
sion is malicious. Similarly, 93% of all malicious ex-
tensions request to interact with every URL as do 57%
of all other extensions. These broad contexts make it dif-
ﬁcult to determine the pages an extension interacts with,
further complicating dynamic analysis.
Chrome API Calls & DOM Operations: We ﬁnd the
strongest features for detecting malware originate from a
mixture of Chrome API calls and DOM operations. We
provide a list of the most common operations in Table 2
and Table 3. The majority of malware (and benign exten-
sions) rely on injecting scripts, generating XHR requests,
and adding new DOM elements that target newly created
tabs. What distinguishes the two are the aggregate set
of events triggered as well as the domains of remote re-
sources loaded into a page (e.g., injected scripts or con-
tent). Our model effectively learns which resources are
commonly fetched by malware in addition to common
strategies for tampering with pages.
Malicious Logic: Recent work by Kapravelos et al. pro-
posed a number of behavioral ﬂags they deemed “suspi-
cious” for extensions. We evaluate the effectiveness of

586  24th USENIX Security Symposium 

USENIX Association

8

100%

e
r
a
w
a
m

l

 
f

 

o
n
o

i
t
c
a
r
F

75%

50%

25%

0%

0.1

10.0

Delay (hours)

1,000.0

Figure 4: CDF of the delay before catching a malicious exten-
sion after it is ﬁrst submitted to the Chrome Web Store. We
catch malicious extensions within a median of 25 minutes.

l

l

s
e
p
m
a
s
 
e
r
a
w
a
m
 
y
h
t
n
o
M

l

800
600
400
200
0

G

G

G

G

G

G

GG

G

G

G

G

G

G

G

G G

G

GG G

G

G

G

G

G

G

G

G

G

GG

G

G

01/12 07/12 01/13 07/13 01/14 07/14 01/15

G blocked

taken down

Figure 5: Actions taken against malicious extensions in the
Chrome Web Store over time. Our systems are becoming in-
creasingly proactive at blocking malware rather than reactive.

these signals in Table 4. We ﬁnd that behaviors such as
modifying CSP headers, uninstalling extensions, or pre-
venting uninstallation are exclusive to malware, though
rare. Contrastingly, Hulk’s decision to surface exten-
sions that produce network request errors or inject scripts
would overly burden human experts due to low precision.
These signals still have value, but they must be combined
with the other features collected by our system in order
to generate a precise verdict.

6.5 Detection Latency
A critical metric of WebEval’s performance is our vul-
nerability window: the time between when a developer
submits a malicious extension to the Chrome Web Store
until its detection. This metric represents a worst case
scenario where we assume an extension is malicious
from its onset rather than after an update or a remote
resource begins including malicious functions. Over
the last year it took a median of 25 minutes before we
ﬂagged an extension as malicious—within the one hour
window an extension is embargoed from public access.

However, this delay has a long tail as shown in Figure 4.
We catch 70% of malicious extensions within 5 days and
90% within 3 months. During this period, users are ex-
posed to malicious content, the impact of which we eval-
uate in Section 7. Over time, our verdicts have become
increasingly proactive rather than reactive as shown in
Figure 5. Blocked extensions never reach the public,
while extensions taken down by the Chrome Web Store
leave users vulnerable for a short period. As we discuss
shortly, proactive blocking has a substantial impact on
reducing the number of known victims exposed to mal-
ware.
6.6 Manual Review Effort
WebEval relies heavily on human experts to validate the
verdicts of automated classiﬁcation and manual rules to
guarantee high precision. In the last year, we surfaced
10,120 suspicious extensions for review, entailing a to-
tal of 464 hours of analysis—an average of 2.75 minutes
per extension. This process is simpliﬁed by access to all
of WebEval’s dynamic and static analysis and concrete
training features as previously discussed in Section 4 and
Section 5. We recognize that manual review by experts
represents a scarce resource that is challenging to scale.
Consequently, we continuously look for ways to improve
automated verdicts to achieve a precision on par with hu-
man experts.

7 Trends in Malicious Extensions

Consistently high recall over the last three years al-
lows us to provide a retrospective on how malicious ex-
tensions have evolved over time. This includes the mon-
etization vectors used, the breadth of users impacted, and
the developers responsible.
7.1 Abuse Vectors
Despite hundreds of new monthly malicious extensions,
we ﬁnd the strategies for abusing Chrome users have re-
mained largely constant. Figure 6 shows a breakdown of
abuse strategies of extensions per month where a manu-
ally curated label is available;4 we categorize extensions
ﬂagged by automated systems that provide no context
on abuse vectors as “other”. Noticeably absent from the
top threats are banking trojans, password theft, and email
spam. While these are all within the realm of a malicious
extension’s capabilities—and have cropped up from time
to time—such threats are dwarfed by Facebook hijack-
ing, ad injection, and information theft.

4Labels are not guaranteed to be unique; an extension can simul-
taneously hijack Facebook credentials, inject ads, and insert tracking
pixels.

USENIX Association  

24th USENIX Security Symposium  587

9

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G
G

G

G

G
G

G

G

G

G

G

G

G

G

G
G

500

400

300

200

100

l

s
e
p
m
a
s
 
e
r
a
w
a
m
 
y
h

l

l

t

n
o
M

G

G

G

G
G G

G

G

0
01/12 07/12 01/13 07/13 01/14 07/14 01/15

GG

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

ad injection
facebook

G

leak
other

tracking

Figure 6: Malware varietals detected each month from 2012–
2015.

i

s
n
o
s
n
e
t
x
e
 
f
o
 
t
n
e
c
r
e
P

100%

75%

50%

25%

0%

10

1,000

Installs

100,000

10,000,000

active user base

web store installs

Figure 7: CDF of installs broken down by those originating
from the Chrome Web Store and an extension’s active pings
that capture both store-based and sideloaded installs.

Facebook Hijacking: Our ﬁndings show that Facebook
malware remains a persistent threat with over 4,809 vari-
ants in the last three years. These malicious extensions
purport to offer enhancements such as removing the
Facebook Timeline, adding a “dislike” button, or chang-
ing the theme of the Facebook interface. The hook has
evolved over time. The latest rendition tricks users into
installing an extension masquerading as a video codec
required to view a video posted by a friend. Once in-
stalled, the extension hijacks the victim’s credentials to
post status updates that propagate the malware. How
the extensions monetize Facebook accounts is not en-
tirely clear, but appears to involve inﬂating likes, fans,
and friend counts much like previously studied fake en-
gagement contagions on Twitter [36, 38].
Ad Injection: Ad injection is the second most prevalent
threat in the Chrome Web Store comprising 3,496 exten-
sions. These extensions rely on content scripts that run
on every page that allow the extension to scan DOMs for

common banners to replace with rogue advertisements
or simply insert new ads into pages. We note that ad in-
jection is not expressly prohibited by the Chrome Web
Store: the extensions ﬂagged also performed some other
malicious behavior or violated one of the store’s policies
as determined by a human expert.
Other Variants: In recent months we have witnessed a
larger variety of abuse vectors. In depth investigations
of a sample of these extensions reveal malware tamper-
ing with bitcoin wallets, injecting into banking sessions
for Brazilian institutions, and modifying Amazon afﬁli-
ate URLs. While we lack manual rules for these speciﬁc
abuse vectors, we are nevertheless able to catch them via
our classiﬁer.

Installs

7.2
Malicious extensions obtain installs in one of two fash-
ions: (1) via binaries that modify Chrome’s user pro-
ﬁle to sideload extensions,5 or (2) via social engineering
where miscreants direct users to the Chrome Web Store
or prompt users with an install dialogue on a third-party
site. We measure both approaches using two metrics. We
deﬁne an extension’s active user base as the total number
of Chrome clients who ping the Chrome Web Store with
update requests (sent by all extensions, including side-
loaded extensions). This value changes each day as users
install or uninstall extensions, so we select the all-time
maximum. We deﬁne an extension’s web store installs as
the total number of install dialogues Chrome clients initi-
ate with the Chrome Web Store. We note that a third op-
tion exists for miscreants to obtain installs: paying an ex-
isting, legitimate extension developer to hand over their
app. In practice, we found only 6 malicious extensions
(0.06%) that involved an ownership transfer.
Evidence of Side Loading: We provide a breakdown of
both install metrics in Figure 7. We ﬁnd that 51% of ma-
licious extensions never received any active user base or
Web Store installs due to early detection. Evidence of
sideloading is relatively rare: only 290 extensions had
a larger active user base than Web Store installs. How-
ever, these extensions were immensely popular with over
43.5 million combined active users. In contrast, all mali-
cious extensions combined received 29.6 million installs
via the Chrome Web Store. As such, it would appear that
binary distribution of malicious extensions contributed
substantially to user infections. This allows malware au-
thors to rely on the same distribution models of the past
(e.g., drive-by downloads [30], exploit packs [18], pay-
per-install [8]) while tapping into the extension API as a
means for simplifying exploitation.

5The extension still must be in the Chrome Web Store due to the

lockdown policy discussed previously in Section 2

588  24th USENIX Security Symposium 

USENIX Association

10

6M

s

l
l

a

t
s
n

4M

I
 

e
r
o

t
s
b
e
W

2M

0M

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G

G
G

G

G

G

G

G

G

150

100

t

 

s
r
o
h
u
a
e
r
a
w
a
m
w
e
n

 

l

l

t

 
y
h
n
o
M

50

0

2004

2006

2008

2010

2012

2014

01/12 07/12 01/13 07/13 01/14 07/14 01/15

G

ad injection
facebook

G

leak
other

tracking

Figure 8: Malware installations via the Chrome Web Store for
the past three years broken down by abuse vector. This ex-
cludes binaries sideloading extensions.

Country
United States
Brazil
Mexico
Colombia
Turkey
Argentina
India
Russia
Peru
Vietnam

Infected Users
2,375,363
1,982,570
1,942,288
1,634,933
1,569,949
1,525,364
1,475,228
1,244,932
955,695
806,625

Popularity
8%
7%
6%
5%
5%
5%
5%
4%
3%
3%

Table 5: Top 10 regions impacted by malicious extensions
downloaded via the Chrome Web Store.

Equally problematic, installs follow a long tail distri-
bution. We ﬁnd that 64 extensions (1% of all malware)
attained an aggregate 46.6 million active users, 83% of
all installations. The top two most popular threats were
ad injectors and search hijackers that each garnered over
10 million active users. Miscreants distributed each ex-
tension solely via binaries ﬂagged as malware by Google
Safe Browsing. Our results emphasize that seemingly
small false negative detection rates can have substantial
negative impact on Chrome users. This drastically differs
from email and telephony spam where an incorrectly la-
beled message typically impacts only a single user—not
millions.
Popular Social Engineering Campaigns: Focusing ex-
clusively on installs mediated by the Chrome Web Store,
we investigate which abuse vectors achieved the most
new installs per month and the country of origin of in-
stalls. Figure 8 tracks the rise and fall of various mon-
etization strategies over time. Despite a short window

Figure 9: Registration time of malware authors. Most authors
rely on accounts created in the last three years.

before catching malicious extensions we still ﬁnd that so-
cial engineering campaigns enticed millions of new users
each month to install Facebook malware, ad injection
software, and information stealers. The downward trend
in recent months is the result of proactive blocking rather
than retroactive takedowns that expose users to malware
for a short window. We ﬁnd no single country is dis-
proportionately represented as the source of installs, as
shown in Table 5. Our results highlight the global scale
and negative impact that malicious extensions have on
users and the need for greater research attention to the
problem.

7.3 Malicious Developers

We identify 2,339 malicious extension developers
throughout the course of our study. While 50% of de-
velopers authored their malicious extension within 3 to
4 months of registering, there is a long tail of potentially
compromised accounts used to interact with the Chrome
Web Store as shown in Figure 9. We ﬁnd miscreants ac-
cess 31% of developer accounts from IPs within Turkey
followed in popularity by range of other countries de-
tailed in Table 6. Many of the countries with the highest
infection counts were also prominent locations for mali-
cious developers indicating threats were likely localized.
Re-use of malicious developer accounts was fairly lim-
ited: 50% of accounts authored fewer than 2 malicious
extensions while 90% authored fewer than 10.

8 Discussion

With multiple years spent ﬁghting malicious exten-
sions, we reﬂect on some of the lessons we have learned,
limitations of our approach, and potential technical and
policy improvements that can help prevent malicious ex-
tensions in the future.

USENIX Association  

24th USENIX Security Symposium  589

11

Country
Turkey
United States
Dominican Republic
Brazil
Vietnam
Russia
Germany
Peru
India
Israel

Developers
552
164
126
106
83
60
43
43
43
39

Popularity
31%
9%
7%
6%
4%
3%
2%
2%
2%
2%

Table 6: Top 10 login geolocations of malicious developers.

8.1 Lessons Learned
When we ﬁrst set out to identify malicious extensions
our expectation was to ﬁnd banking trojans and pass-
word stealers that duplicated the strategies pioneered by
Zeus and SpyEye.
In practice, the abusive extension
ecosystem is drastically different from malicious bina-
ries. Monetization hinges on direct or indirect relation-
ships with syndicated search partners and ad injection af-
ﬁliate programs, some of which earn millions of dollars
from infected users [37]. Miscreants derive wealth from
trafﬁc and user targeting rather than the computing re-
sources or privileged access mediated via the browser. It
may simply be that the authors of malicious binaries have
little incentive (or external pressure) to change, leaving
extensions to a distinct set of actors. This uncertainty is
a strong motivation for exploring the extension ecosys-
tem further.

A second lesson is the importance of equipping an
abuse prevention team with the tools necessary to rapidly
respond to new, unforeseen threats. As we have shown,
even momentary lapses in protection have drastic con-
sequences on Chrome users. This is especially true in
the case of social engineering campaigns like those used
to distribute malicious Facebook extensions that spread
exponentially. We argue that evaluating a detection sys-
tem purely on precision and recall is not effective when
the ultimate goal is to protect users from malware in-
stallations.
Instead, we must weigh false negatives by
their consequences—the number of victims exposed to
malware. In this light, our system has continuously im-
proved over the last three years.

In the long term we believe the Chrome Web Store
must extricate itself from the current ﬁre-ﬁghting ap-
proach to malicious extensions and outright disrupt the
malicious actors involved. This reﬂects a nascent strat-
egy within the research community to pursue criminal
relationships such as those underpinning spammed phar-
maceuticals [26]. However, to arrive at this point we
must ﬁrst lay a foundation for how to study the extension

ecosystem. As the research community develops the nec-
essary understanding this abuse space—and in particular
the ad and search relationships involved—there must be
a system to both protect users as well as generate longi-
tudinal data on abuse strategies and their support infras-
tructure. WebEval satisﬁes both of these requirements.

8.2 Role of Policy
Research primarily considers technical solutions to
abuse, but we argue that policy decisions prove equally
effective at protecting users. When Chrome ﬁrst released
extensions there was no requirement of developers up-
loading their code to the Chrome Web Store. This en-
abled malicious developers to side-load extensions via
binaries and left Chrome users with little room for dis-
covering the installation or recourse. The subsequent
Chrome lockdown forced all malicious extensions to at
least be surfaced to the Chrome Web Store and cre-
ated a homogeneous enforcement policy for all Chrome
users. While binaries can still side-load extensions in the
Chrome Web Store, WebEval now incorporates signals
to detect organic versus silent installs.

It is worth noting the Chrome lockdown policy has
some limitations. Anecdotally, we have observed bina-
ries distributing payloads that overwrite the local content
of legitimate extensions previously installed by a user.
Because only the legitimate extension is in the store,
WebEval cannot offer any protection. Chrome has since
responded to this threat by introducing extension content
veriﬁcation, but this is just a single stage in an increasing
arms race.

8.3 Limitations
Dynamic analysis and security crawlers consistently run
the risk of overlooking malicious behaviors due to cloak-
ing [2, 23, 31]. Extension analysis is equally vulnerable.
Potential threats include malware delaying execution un-
til after WebEval’s evaluation; supplying benign versions
of remotely fetched JavaScript until after evaluation; or
malware developers ﬁngerprinting our evaluation envi-
ronment and IP addresses. A separate issue is code cov-
erage: our behavioral suites are not guaranteed to trig-
ger all of an extension’s logic during evaluation. Worse,
we face an intractably broad threat surface that we must
test as the majority of malware requests access to every
page a user visits. While symbolic execution systems
exist for Javascript [32], they rely on fuzzing that is not
guaranteed to trigger malicious behavior due to the im-
plicit event-driven nature of extensions where activation
requires a speciﬁc sequence of listeners to ﬁre. Solutions
to these challenges remain elusive; we currently rely on
human experts and abuse reports to surface false nega-
tives so we can adapt our detection framework.

590  24th USENIX Security Symposium 

USENIX Association

12

Improving Detection

8.4
Fundamentally improving WebEval (and by proxy other
security scanners) requires we break from evaluating
extensions in a sandboxed environment vulnerable to
cloaking and instead move to in situ monitoring of
Chrome users. This strategy, previously considered by
researchers to improve drive-by download detection [35],
applies equally to malicious extensions. However, such
a move creates a new challenge of balancing early infec-
tions of clients, user privacy, and anonymous but feature-
rich reporting of an extension’s behaviors with enough
details to detect malice.

Furthermore, while we can retrain our a model of ma-
licious extensions to incorporate client logs, the process
would be immensely aided by the cooperation of website
developers who label DOM resources as sensitive. We
should take these labels as hints, not facts, to account for
overzealous developers who label every DOM element as
sensitive in an effort to dissuade extension modiﬁcations,
even when desired by users. We believe this combined
approach strikes the best balance between Chrome’s cur-
rent philosophy of allowing users to alter their browsing
experience in any way with the necessity of early detec-
tion of malicious modiﬁcations.

9 Related Work

Security Sandboxes & Malware Detection: WebEval
borrows heavily from a history of malware analysis
sandboxes that capture system calls and network traf-
ﬁc. Examples include Anubis [5], CWSandbox [40],
and GQ [24] among a breadth other architectures [12].
However, malicious extensions pose a unique set of chal-
lenges that limit the effectiveness of these sandboxes
without modiﬁcation. Unlike standalone applications,
Chrome extensions run in the context of a webpage mak-
ing it harder for traditional system-wide malware moni-
toring techniques to isolate malware activity from that of
the browser. Our system manages to achieve this isola-
tion by comparing extension activity to baseline activity
captured while the extension was not running as well as
by tapping natively into Chrome’s JavaScript and API
modules.

The closest system to our own is Hulk which cap-
tures in-browser activity logs [21]. Unlike Hulk, our
system goes beyond identifying suspicious behaviors to
return a concrete verdict of malice. This is imperative
as the signals proposed by Hulk are insufﬁcient at de-
tecting most malicious extensions as we showed in Sec-
tion 6. Research has also explored competing strate-
gies such as information ﬂow tracking in JavaScript with
tainted inputs [11] or tracking common API calls made
by Browser Helper Objects installed by adware [22].

These techniques inﬂuence our design but only capture
a subset of the malicious extensions we identify.
Buggy & Malicious Extensions: Most research into
browser extensions has focused on their security and
permission model in light of the possible vulnerabili-
ties [3, 4, 9, 19]. Only recently has research shifted to-
wards the threat of outright malicious extensions. This
includes re-imagining application-based attacks as man-
in-the-browser threats [25]; examining the role of exten-
sions in the ad injection ecosystem [37, 41]; and charac-
terizing malicious extensions found in the Chrome Web
Store [21]. Our observations agree with many of these
former studies. We expand upon these works by offer-
ing a complete perspective of how malicious extension
monetization techniques have evolved over the last three
years and the techniques malware developers use to dis-
tribute extensions.

10 Conclusion

In this work we exposed wide-spread efforts by crim-
inals to abuse the Chrome Web Store as a platform for
distributing malicious extensions. As part of our study,
we presented the design and implementation of a frame-
work that automatically classiﬁes an extension’s behav-
iors, code base, and author reputation to surface mal-
ware. Due to our live deployment, this system cannot
run in a fully automated fashion: we required regular in-
puts from human experts to correct for false negatives
surfaced via Chrome user reports and manual investiga-
tions. Our unique combination of automated and human
systems yielded a framework that identiﬁed 96.5% of all
known malware submitted to the Chrome Web Store be-
tween January 2012–2015.

In total, we detected 9,523 malicious extensions that
hijacked social networking sessions to generate synthetic
likes, friend requests, and fans; ad injectors and afﬁli-
ate fraudsters that rewrote DOM content to laden pages
with additional advertisements; and information steal-
ers that injected rogue tracking pixels and covertly si-
phoned search keywords. Despite a short window of
operation—we disabled 50% of malware within 25 min-
utes of creation—a handful of under 100 malicious ex-
tensions were able to infect over 50 million users before
removal. Our results highlight key challenges of protect-
ing app marketplaces that are broadly applicable beyond
the Chrome Web Store.

References
[1] Apple. App Review. https://developer.apple.com/

app-store/review/, 2015.

[2] Davide Balzarotti, Marco Cova, Christoph Karlberger, Engin
Kirda, Christopher Kruegel, and Giovanni Vigna. Efﬁcient de-

USENIX Association  

24th USENIX Security Symposium  591

13

tection of split personalities in malware. In Proceedings of the
Network and Distributed System Security Conference, 2010.

[3] Sruthi Bandhakavi, Samuel T King, Parthasarathy Madhusudan,
and Marianne Winslett. Vex: Vetting browser extensions for se-
curity vulnerabilities.
In Proceedings of the USENIX Security
Symposium, 2010.

[4] Adam Barth, Adrienne Porter Felt, Prateek Saxena, and Aaron
Boodman. Protecting browsers from extension vulnerabilities.
In Proceedings of the Network and Distributed System Security
Conference, 2010.

[5] Ulrich Bayer, Paolo Milani Comparetti, Clemens Hlauschek,
Christopher Kruegel, and Engin Kirda. Scalable, behavior-based
malware clustering.
In Proceedings of the Network and Dis-
tributed System Security Conference, 2009.

[6] Jeremy Bem, Georges R Harik, Joshua L Levenberg, Noam
Shazeer, and Simon Tong. Large scale machine learning systems
and methods, 2007. US Patent 7,222,127.

[7] Christina Bonnington. First instance of ios app store malware
detected, removed. http://www.wired.com/2012/07/
first-ios-malware-found/, 2012.

[8] Juan Caballero, Chris Grier, Christian Kreibich, and Vern Paxson.
Measuring pay-per-install: The commoditization of malware dis-
tribution.
In Proceedings of the USENIX Security Symposium,
2011.

[9] Nicholas Carlini, Adrienne Porter Felt, and David Wagner. An
evaluation of the google chrome extension security architecture.
In Proceedings of the USENIX Security Symposium, 2012.

[10] Lucian Constantin. Malicious browser extensions pose a
http://www.

serious threat and defenses are lacking.
pcworld.com/article/2049540/malicious-
browser-extensions-pose-a-serious-threat-
and-defenses-are-lacking.html, 2014.

[11] Mohan Dhawan and Vinod Ganapathy. Analyzing information
ﬂow in javascript-based browser extensions. In Proceedings of
the Annual Computer Security Applications Conference, 2009.

[12] Manuel Egele, Theodoor Scholte, Engin Kirda, and Christopher
Kruegel. A survey on automated dynamic malware-analysis tech-
niques and tools. ACM Computing Surveys, 2012.

Protecting Chrome users

[13] Erik Kay.
extensions.
2014/05/protecting-chrome-users-from-
malicious.html, 2014.

from malicious
http://chrome.blogspot.com/

[14] Firefox. Review Process. https://addons.mozilla.
org/en-US/developers/docs/policies/reviews,
2015.

[15] Google. Developer registration fee. https://support.

google.com/chrome_webstore/answer/187591?
hl=en, 2015.

[16] Google.

Google Chrome Web Store Developer Agree-
ment. https://developer.chrome.com/webstore/
terms, 2015.

[17] Google.

Google Play Developer Program Policies.

https://play.google.com/about/developer-
content-policy.html, 2015.

[18] Chris Grier, Lucas Ballard, Juan Caballero, Neha Chachra, Chris-
tian J Dietrich, Kirill Levchenko, Panayiotis Mavrommatis, Da-
mon McCoy, Antonio Nappa, Andreas Pitsillidis, et al. Manu-
facturing compromise: the emergence of exploit-as-a-service. In
Proceedings of the Conference on Computer and Communica-
tions Security, 2012.

[19] Arjun Guha, Matthew Fredrikson, Benjamin Livshits, and Nikhil
Swamy. Veriﬁed security for browser extensions. In Proceedings
of the IEEE Symposium on Security and Privacy, 2011.

[20] Scott Kaplan, Benjamin Livshits, Benjamin Zorn, Christian
Siefert, and Charlie Curtsinger. ” nofus: Automatically detect-
ing”+ string. fromcharcode (32)+” obfuscated”. tolowercase ()+”
javascript code. In Technical Report, Microsoft, 2011.

[21] Alexandros Kapravelos, Chris Grier, Neha Chachra, Chris
Kruegel, Giovanni Vigna, and Vern Paxson. Hulk: Eliciting ma-
licious behavior in browser extensions.
In Proceedings of the
USENIX Security Symposium, 2014.

[22] Engin Kirda, Christopher Kruegel, Greg Banks, Giovanni Vigna,
and Richard Kemmerer. Behavior-based spyware detection. In
Proceedings of the USENIX Security Symposium, 2006.

[23] Clemens Kolbitsch, Benjamin Livshits, Benjamin Zorn, and
Christian Seifert. Rozzle: De-cloaking internet malware. In Pro-
ceedings of the IEEE Symposium on Security and Privacy, 2012.
[24] Christian Kreibich, Nicholas Weaver, Chris Kanich, Weidong
Cui, and Vern Paxson. Gq: Practical containment for measuring
modern malware systems. In Proceedings of the ACM SIGCOM
Internet Measurement Conference, 2011.

[25] Lei Liu, Xinwen Zhang, Guanhua Yan, and Songqing Chen.
In
Chrome extensions: Threat analysis and countermeasures.
Proceedings of the Network and Distributed System Security
Conference, 2012.

[26] Damon McCoy, Hitesh Dharmdasani, Christian Kreibich, Geof-
frey M. Voelker, and Stefan Savage. Priceless: The role of pay-
ments in abuse-advertised goods. In Proceedings of the Confer-
ence on Computer and Communications Security, 2012.

[27] Paul Pearce, Vacha Dave, Chris Grier, Kirill Levchenko, Saikat
Guha, Damon McCoy, Vern Paxson, Stefan Savage, and Geof-
frey M. Voelker. Characterizing large-scale click fraud in zeroac-
cess. In Proceedings of the Conference on Computer and Com-
munications Security, 2014.

[28] Adrienne Porter Felt. See what your apps & extensions have been
up to. http://blog.chromium.org/2014/06/see-
what-your-apps-extensions-have-been.html,
2015.

[29] Emil Protalinski. Malicious Chrome extensions hijack Face-
http://www.zdnet.com/article/

book accounts.
malicious-chrome-extensions-hijack-
facebook-accounts/, 2012.

[30] Niels Provos, Panayiotis Mavrommatis, Moheeb Abu Rajab, and
Fabian Monrose. All your iFRAMEs point to us. In Proceedings
of the USENIX Security Symposium, 2008.

[31] M Rajab, Lucas Ballard, Nav Jagpal, Panayiotis Mavrommatis,
Daisuke Nojiri, Niels Provos, and Ludwig Schmidt. Trends in
circumventing web-malware detection. In Google Technical Re-
port, 2011.

[32] Prateek Saxena, Devdatta Akhawe, Steve Hanna, Feng Mao,
Stephen McCamant, and Dawn Song. A symbolic execution
framework for JavaScript.
In Proceedings of the IEEE Sympo-
sium on Security and Privacy, 2010.

[33] Spark. Machine learning library (mllib) programming guide.

http://spark.apache.org/docs/1.4.0/mllib-
guide.html, 2015.

[34] Brett Stone-Gross, Marco Cova, Lorenzo Cavallaro, Bob Gilbert,
Martin Szydlowski, Richard Kemmerer, Christopher Kruegel,
and Giovanni Vigna. Your botnet is my botnet: Analysis of a
botnet takeover. In Proceedings of the Conference on Computer
and Communications Security, 2009.

[35] Gianluca Stringhini, Christopher Kruegel, and Giovanni Vigna.
Shady paths: Leveraging surﬁng crowds to detect malicious web
pages. In Proceedings of the Conference on Computer and Com-
munications Security, 2013.

592  24th USENIX Security Symposium 

USENIX Association

14

[36] Gianluca Stringhini, Gang Wang, Manuel Egele, Christopher
Kruegel, Giovanni Vigna, Haitao Zheng, and Ben Y Zhao. Fol-
low the green: Growth and dynamics in twitter follower markets.
In Proceedings of the ACM SIGCOM Internet Measurement Con-
ference, 2013.

[37] Kurt Thomas, Elie Bursztein, Chris Grier, Grant Ho, Nav Jagpal,
Alexandros Kapravelos, Damon McCoy, Antonio Nappa, Vern
Paxson, Paul Pearce, Niels Provos, and Moheeb Abu Rajab. Ad
injection at scale: Assessing deceptive advertisement modiﬁca-
tions.
In Proceedings of the IEEE Symposium on Security and
Privacy, 2015.

[38] Kurt Thomas, Frank Li, Chris Grier, and Vern Paxson. Con-
sequences of connectivity: Characterizing account hijacking on
twitter. In Proceedings of the Conference on Computer and Com-
munications Security, 2014.

[39] Kurt Thomas, Damon McCoy, Chris Grier, Alek Kolcz, and Vern
Paxson. Trafﬁcking fraudulent accounts: The role of the under-
ground market in twitter spam and abuse. In Proceedings of the
USENIX Security Symposium, 2013.

[40] Carsten Willems, Thorsten Holz, and Felix Freiling. Toward au-
tomated dynamic malware analysis using cwsandbox.
In Pro-
ceedings of the IEEE Symposium on Security and Privacy, 2007.
[41] Xinyu Xing, Wei Meng, Udi Weinsberg, Anmol Sheth, Byoungy-
oung Lee, Wenke Lee, and Roberto Perdisci. Unraveling the rela-
tionship between ad-injecting browser extensions and malvertis-
ing. In Proceedings of the International Conference on the World
Wide Web, 2015.

[42] Yajin Zhou, Zhi Wang, Wu Zhou, and Xuxian Jiang. Hey, you,
get off of my market: Detecting malicious apps in ofﬁcial and
alternative android markets. In Proceedings of the Network and
Distributed System Security Conference, 2012.

USENIX Association  

24th USENIX Security Symposium  593

15

