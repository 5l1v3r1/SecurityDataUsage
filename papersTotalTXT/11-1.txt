PIRMAP: Efﬁcient Private Information Retrieval

for MapReduce

Travis Mayberry, Erik-Oliver Blass, and Agnes Hui Chan

College of Computer and Information Science
Northeastern University, Boston MA-02115, USA
ftravism,blass,ahchang@ccs.neu.edu

Abstract. Private Information Retrieval (PIR) allows a user to retrieve bits from
a database while hiding the user’s access pattern. However, the practicality of PIR
in a real-world cloud computing setting has recently been questioned. In such a
setting, PIR’s enormous computation and communication overhead is expected
to outweigh the cost saving advantages of cloud computing. In this paper, we
ﬁrst examine existing PIR protocols, analyzing their efﬁciency and practicality in
realistic cloud settings. We identify shortcomings and, subsequently, present an
efﬁcient protocol (PIRMAP) that is particularly suited to MapReduce, a widely
used cloud computing paradigm. PIRMAP focuses especially on the retrieval
of large ﬁles from the cloud, where it achieves good communication complex-
ity with query times signiﬁcantly faster than previous schemes. To achieve this,
PIRMAP enhance related work to allow for optimal parallel computation during
the “Map” phase of MapReduce, and homomorphic aggregation in the “Reduce”
phase. To improve computational cost, we also employ a new, faster “somewhat
homomorphic” encryption, making our scheme practical for databases of use-
ful size while still keeping communication costs low. PIRMAP has been imple-
mented and tested in Amazon’s public cloud with database sizes of up to 1 TByte.
Our evaluation shows that non-trivial PIR such as PIRMAP can be more than one
order of magnitude cheaper and faster than trivial PIR in the real-world.

1

Introduction

Cloud computing has recently been identiﬁed as an important business technology [10],
as it offers greater ﬂexibility and reduced costs to companies outsourcing data and com-
putation. The cost advantage of cloud computing comes from the fact that cloud users
do not need to maintain their own, expensive data center, but instead can pay a cloud
provider for hosting. However, despite the hype, hesitations remain among potential
cloud users. Lack of security and privacy guarantees has been identiﬁed as a major
adoption obstacle for both large enterprise [20] and governmental organizations [15].

Privacy issues stem from the fact that, when a user hands over his information to the
cloud, control of that data is relinquished to the cloud. Public clouds are threatened by
hackers due to the much larger target they present. Insiders such as data center admin-
istrative staff can easily access private data that has been outsourced. Additionally, as
cloud providers place data centers abroad in countries with unclear privacy laws, local
authorities become an additional threat to outsourced data. Such attacks are realistic

and have already been reported [11, 22]. This shows that users need to take precautions
to ensure the privacy and integrity of their cloud data.

While encryption of data at rest helps to protect data conﬁdentiality, it is often not
sufﬁcient: the subsequent data access patterns can leak information about patients. For
example, if the outsourced data in question contains encrypted patient records, the cloud
provider might learn that a patient has been diagnosed with cancer when it sees that the
patient’s records have been retrieved by an oncologist. In general, it is hard to assess
which information may be leaked, what inferences an adversary may make, and what
risks the leakage may incur.

Private Information Retrieval (PIR) offers a solution to the information leakage
problem by hiding access patterns [6, 13], independent of an encryption mechanism.
In PIR, a database stored at a server holds n strings each of size l bits, and a user can
query for one l bit string without leaking which string to the database. A trivial way
to accomplish this is to simply transmit the entire database to the user. However, this
is communication inefﬁcient, and research focuses on achieving lower communication
bounds. In contrast, computational cost of every PIR scheme is necessarily O(n (cid:1) l), as
the server must “touch” every piece of the database if the server is to remain oblivious
of the requested piece.

In existing work, the server’s computation is comprised of expensive cryptographic
operations over the entire database. Because of the signiﬁcant overhead this imposes,
it has recently been questioned whether PIR will ever become practical in a real-world
cloud computing setting, cf. Sion and Carbunar [19]. Typically, cloud providers such as
Amazon charge their customers for both data transfer and CPU hours [2]. Due to the
necessary condition that PIR protocols compute over the entire database for each query,
it has been argued that trivial PIR (retrieving the whole (l (cid:1) n) bit database) is not only
faster, but also cheaper for the cloud customer compared to a PIR query that involves
lengthy computation [5, 17, 19].

Another open question is how to perform PIR in a real-world cloud computing en-
vironment. In contrast to a single machine server storing the data, one of the biggest
challenges in cloud computing is a design that scales easily to the large distributed
systems which are characteristic in cloud settings. In order to alleviate this difﬁculty,
major cloud providers (e.g., Amazon, Google, IBM, Microsoft) offer an interface to the
prominent MapReduce [8] API for distributed computing to their users. MapReduce
comprises not only parallelization (“Map”) of work, but an aggregation (“Reduce”) of
individual results to keep computational burden on the user side low.

This paper considers the single-server, computationally-private information retrieval
setting. This is appropriate, because, although a cloud provider may allow access to
many servers, they must all be considered a single “trust entity”: they are under the
control of the same organization. Trust-wise, the cloud as a single, large server with
many distributed CPUs. In the single-server setting, it is known that unconditionally
secure PIR cannot be more efﬁcient than transferring the entire database [7], so we are
concerned instead with a computationally secure protocol (cPIR). Further use of the
term PIR will be in reference to computationally-secure PIR, unless otherwise noted.

We present PIRMAP, an efﬁcient single-server cPIR protocol suited for MapReduce
clouds. PIRMAP especially targets retrieval of relatively large ﬁles, a more speciﬁc

setting than considered by previous work. In a scenario with n ﬁles each of size l bits
and l ≫ n, PIRMAP achieves communication complexity linear in l with low constants.
PIRMAP is designed for and leverages MapReduce parallelization and aggregation.
We have implemented PIRMAP in Hadoop MapReduce, and its performance will be
presented in Section 5.

Our contributions are:
1.) An analysis of existing work with respect to its practicality in a MapReduce

cloud setting.
2.) PIRMAP, an efﬁcient, practical PIR scheme for MapReduce with optimal com-
munication complexity O(l) when retrieving an l bit ﬁle for l ≫ n. Additionally,
PIRMAP has computational complexity as good or better than prominent related work
due to use of a more efﬁcient homomorphic encryption. PIRMAP runs on top of stan-
dard MapReduce, not requiring changes to the underlying cloud infrastructure.

3.) An implementation of PIRMAP that is usable in real-world MapReduce clouds
today, e.g., Amazon. We evaluate PIRMAP, ﬁrst, in our own (tiny) local cloud and, sec-
ond, with Amazon’s cloud. We verify its practicality by scaling up to 1 TByte of data in
Amazon’s cloud setting. Compared to the previously largest single database PIR exper-
iment with up to 28 GByte of data [17], this demonstrates the efﬁciency and practicality
of PIRMAP in the real-world. PIRMAP is more than one order of magnitude cheaper
and faster than trivial PIR, and – in our particular scenario – we can signiﬁcantly out-
perform related work. PIRMAP’s source code is available for download [18].

2 Problem Statement

PIR: A PIR protocol is a series of interactions between a user and a server storing n
ﬁles that results in the user retrieving one ﬁle while the server does not learn which ﬁle.
More formally, the server cannot guess with probability greater than 1=n which ﬁle was
queried. Note that this probability does not increase over multiple queries. This effec-
tively hides the user’s access pattern as each query is computationally indistinguishable
from the others. The only information leaked is the number of ﬁles queried.

A CP IRn

l protocol (Query; Transfer; Recover) is a computationally-secure pri-
vate information retrieval protocol over a database of n elements, each of bit length l.
The Query function generates the query and sends it to the server. Transfer is run on
the server and involves transforming the received query into the results of the query
and sending it back to the client. Finally, Recover is run by the client to transform the
response from the server into the correct plaintext query result.

MapReduce: With the trend towards more computers and more cores rather than
faster individual processors, it is important that any practical PIR implementation be
deployable in a way that can take full advantage of parallel and cluster computing en-
vironments. Perhaps the most widely adopted architecture for scaling parallel compu-
tation in public clouds today is Google’s MapReduce [8]. Its design allows for a set of
computations, or “job”, to be deployed across many nodes in a cloud cloud. Its biggest
advantage is that it scales transparently to the programmer. That is, once an implemen-
tation is written using MapReduce, it can run on any number of nodes in the data center,
from one up to hundreds or thousands, without changes in the code. This is managed

by splitting computation into two phases, each of which can be run in parallel on many
computing nodes.

The ﬁrst phase is called the “Map” phase. MapReduce will automatically split the
input to the computation equally among available nodes in the cloud data center, and
each node will then run a function called map on their respective pieces (called Input-
Splits). It is important to note that the splitting actually occurs when the data is uploaded
into the cloud (in our case when the patient record/ﬁles are uploaded) and not when the
job is run. This means that each “mapper” node will have local access to its InputSplit
as soon as computation has started and you avoid a lengthy copying and distributing pe-
riod. The map function runs a user deﬁned computation on each InputSplit and outputs
a number of key-value pairs that go into the next phase.

The second phase, “Reduce”, takes as input all of the key-value pairs emitted by the
mappers and sends them “reducer” nodes in the data center. Speciﬁcally, each reducer
node receives a single key, along with the sequence of values output by the mappers
which share that key. The reducers then take each set and combine it in some way,
outputting a single value for each key.

Despite being widely used, MapReduce is a very speciﬁc computational model and
not all algorithms can be easily adapted to it. A practical PIR such as PIRMAP has to
take its speciﬁcs into account – as we will see below.

3 Related Work Analysis

Despite the large amount of theoretical research, there has not been much investigation
into practical PIR. Recently, Trostle and Parrish [21] experimented with the state of the
art and found that it took at least 8 minutes to retrieve a ﬁle of size only 3 MB, out of
a data set of 3 GB on commodity hardware. Additionally, existing schemes have sig-
niﬁcant communication overhead for ﬁles of that size and larger. For example, Lipmaa
[14], enjoying the most efﬁcient asymptotic communication complexity today, requires
30 MB of communication in the above scenario.

In examining related work, we make two nonstandard observations which apply
to our MapReduce cloud setting. First, since computation for PIR must necessarily be
O(n (cid:1) l), computation will most likely be the bottleneck in any protocol. The time to
communicate queries and responses will be relatively small in our setting, compared to
the time it takes to calculate over the entire database. Therefore, it may be useful to trade
some extra communication for smaller computational burden. The second observation
relates to MapReduce itself. Since each mapper may run on a different node in the cloud,
communication and synchronization within the cloud are very expensive. To take full
advantage of the cloud, there should be few, if any, inter-dependencies between stages
of computation.

Overview One of the ﬁrst cPIR schemes to achieve sublinear communication is that of
Kushilevitz and Ostrovsky [13], using an additively homomorphic cipher E as follows:
1. The server arranges an n elements database as a
2. Query(x) – The user generates a vector v of length

p
n (cid:2) p
p
n matrix
n where vx = E(1), and

vi = E(0);8i ̸= x

3. Transfer(v) – Vector v is sent to the server. The server multiplies v with the

database matrix and returns the result as vector v

p
n encrypted elements, one of which is the
element the user is interested in. The user chooses this element and decrypts it,
discarding the rest.

′ now consists of

4. Recover(v

) – v

′

′

rows in the matrix besides the row requested. The communication costs is O(l (cid:1) p

The scheme is sound, because the user sends a vector v which “zeroes out” all the
n)
which is still quite high for large values of n. Kushilevitz and Ostrovsky [13] also
show that this protocol can be repeated recursively to achieve communication less than
O(nc) for any c > 0, but at the cost of worse constants and computational complexity.
This “square-root solution” computes only once over the database, but has impractically
large communication costs.
Lipmaa [14] reduces communication complexity to O(l (cid:1) log n + k (cid:1) log2 n), where
k is a security parameter. This is accomplished by generalizing the Kushilevitz and
Ostrovsky [13] scheme into a family of protocols, parameterized by a dimension (cid:11).
The Kushilevitz and Ostrovsky [13] scheme can be seen as two-dimensional, because
the database elements are arranged in a
n matrix. If (cid:11) = log(n), the database
is viewed as a log(n) dimensional 2 (cid:2) 2 (cid:2) : : : (cid:2) 2 matrix. In this manner, the user
may send a sequence of log(n) vectors, each only length 2 which “zero out” half of the
remaining database elements at each step. It is conceptually similar to specifying a path
in a binary tree, and when the leaf node is reached the only element that will remain
non-zero is the one corresponding to that node.

p
n (cid:2) p

1

log n
i=1

The down side of this scheme is that it requires computing over the entire database
twice (
2i = 2). While not a signiﬁcant problem asymptotically, as mentioned
before, cPIR schemes are usually bottlenecked by their computational cost. Increasing
this cost by 100% dramatically effects the efﬁciency of the scheme, especially given
the cloud setting where twice the computation corresponds to twice the monetary cost.
Another problem is that the computational complexity of Lipmaa [14] is O(n (cid:1) l (cid:1) k2),
because it requires modular exponentiations on ciphertexts of size k. This is a signiﬁcant
overhead that we can avoid by using a more efﬁcient homomorphism.

Although Lipmaa [14] requires only one round of communication with the user, it
is iterative in that it requires log(n) rounds of computation on the server, each round
depending on the output of the previous round and operating on a smaller set of data.
As we will see, a large part of the cost for MapReduce is in initializing the parallel
computation, so restarting MapReduce log(n) times adds a signiﬁcant overhead.

∑

More recently, Aguilar-Melamine and Gaborit [1] have proposed a scheme using
lattice-based homomorphic encryption (similar to Hoffstein et al. [12]) which has much
better computational complexity, both asymptotically and in practice. Their scheme
also takes advantage of the fact that modern GPUs can solve large parallel problems
very quickly. Aguilar-Melamine and Gaborit [1] are able to achieve fast query response
times, but at the cost of a large communication cost. Additionally, their protocol is
tuned speciﬁcally to the requirements of GPUs and would not scale well in a real-world
distributed cloud environment like MapReduce.

Using a different encryption scheme based on the Trapdoor Group Assumption,
Trostle and Parrish [21] propose a more traditional PIR scheme based on Kushilevitz

Table 1: Communication and computational complexities of related work.

Communication
n (cid:1) l)
Kushilevitz and Ostrovsky [13]
O(
O(l (cid:1) log(n)2)
Aguilar-Melamine and Gaborit [1] O(l + n (cid:1) k) O(l (cid:1) n (cid:1) log(k) (cid:1) log(log(k)))
O(l + n (cid:1) k) O(l (cid:1) n (cid:1) log(k) (cid:1) log(log(k)))

Computation
O(l (cid:1) n (cid:1) k2)
O(l (cid:1) n (cid:1) k2)

p

Lipmaa [14]

PIRMAP

and Ostrovsky [13]. They also achieve much faster query response, but again, with large
communication costs.

Comparison of existing work To understand how existing work compares and is suited
to the application targeted in this paper, we start by examining asymptotic computation
and communication complexities in Table 1. We can see that Lipmaa [14] has very
good communication complexity with relatively bad computational complexity, while
Aguilar-Melamine and Gaborit [1] have the opposite. While our protocol PIRMAP has
the same asymptotic complexities than Aguilar-Melamine and Gaborit [1], this does not
adequately describe the costs involved with PIR: we are primarily addressing a concrete,
practical setting where constants become very important.

Consequently, in Table 2, we present analytically calculated communication costs
for speciﬁc database and ﬁle sizes. Aguilar-Melamine and Gaborit [1] state that their
requests are of size 25kb (cid:1) n and the responses are 6 (cid:1) l. For databases with l > n (cid:1)
k, Lipmaa [14] requires transmitting log2(n) elements of size k in the request and
receiving a response of size log(n) (cid:1) l. We chose to use k = 2048, as suggested by
Lipmaa [14].

In Table 2, we can see that even though Lipmaa [14] has good asymptotic commu-
nication, there is room for improvement in a concrete setting, especially for databases
composed of large ﬁles. Aguilar-Melamine and Gaborit [1], similarly to PIRMAP, is
designed speciﬁcally for these types of databases but it also has relatively high commu-
nication costs due to large constants.

Our approach In conclusion, we would like to achieve, in real world settings, the small
communication cost of Lipmaa [14] with the fast query response times of Aguilar-
Melamine and Gaborit [1] and Trostle and Parrish [21]. Lipmaa notes that, when (cid:11) = 1,
the PIR scheme is particularly efﬁcient for databases where l > n (cid:1) k. We choose this
case as a base for our new protocol PIRMAP, because it requires only one iteration
of the database during Transfer and has communication complexity of O(l + n (cid:1) k).
When l > n (cid:1) k, this is optimal, since the server response must always be of size l. In
short, PIRMAP can be thought of as a combination of this protocol with the fast en-
cryption scheme used by Trostle and Parrish [21]. This new “somewhat” homomorphic
encryption scheme requires only modular multiplications rather than exponentiations,
signiﬁcantly improving the asymptotic and real world computational requirements.

Table 2: Real communication costs of related work in MB for different database sizes.

1 MB Files

5 MB Files

10 MB Files

Lipmaa

1 GB 10 GB 100 GB 1 GB 10 GB 100 GB 1 GB 10 GB 100 GB
10
Aguilar-Gaborit 29
3

17
2350
38

13
240
6

71
499
18

100
83
22

133
295
26

PIRMAP

38
35
11

55
77
12

66
62
22

4 PIRMAP

PIRMAP modiﬁes the PIR protocol by Lipmaa [14], speciﬁcally addressing the short-
comings perceived in regards to retrieval of large ﬁles in a parallelization-aggregation
computation framework such as MapReduce. We start by giving an overview of PIRMAP
which can be used with any additively homomorphic encryption scheme.

Upload. In the following, we assume that the cloud user has already uploaded its

ﬁles into the cloud using the interface provided by the cloud provider.

Query. Our data set holds n ﬁles, each of l bits length. Additional parameter k spec-
iﬁes the block size of a cipher. For ease of presentation, we consider the case where all
ﬁles are the same length, but PIRMAP can easily be extended to accommodate variable
length ﬁles using padding. PIRMAP is summarized as follows:
1. Query – If the user wishes to retrieve ﬁle 1 (cid:20) x (cid:20) n out of the n ﬁles, he creates
a vector v = (v1; : : : ; vn), where vx = E(1) and vi = E(0)8i ̸= x. Here, E is
any IND-CPA additively homomorphic encryption scheme. The user sends v to the
cloud.
2. Multiply – The cloud arranges ﬁles into a table T similar to Table 3. The cloud
g and multiplies each block by vi,

k blocks fBi;1; : : : ; Bi; l

divides each ﬁle i into l
i.e., B

i;j = vi (cid:1) Bi;j. Here, “(cid:1)” denotes scalar multiplication.
′

3. Sum – The cloud adds column-wise to create one result vector r = (r1; : : : ; r l

).
Each element ri of that vector is of size k, so the total bit length of r is l bits. Vector
r is an encryption of ﬁle x. Vector r is returned to the user who decrypts it.

k

k

Table 3: Cloud splits ﬁles into pieces

(cid:1)(cid:1)(cid:1)

l
k

1

2

f ile1 B1;1 B1;2 (cid:1)(cid:1)(cid:1) B1; l
f ile2 B2;1 B2;2 (cid:1)(cid:1)(cid:1) B2; l
(cid:1)(cid:1)(cid:1)
f ilen Bn;1 Bn;2 (cid:1)(cid:1)(cid:1) Bn; l

(cid:1)(cid:1)(cid:1)

k

k

k

The cloud performs the matrix-vector multiplication r = v (cid:1) T . In practice, the
cloud does not need to create a table, but just needs to perform the block wise scalar
multiplications and additions.

The computation consists of multiplying each of the n (cid:1) l

k blocks by a value in the
request vector and then performing (n (cid:0) 1) (cid:1) l
k additions to obtain the ﬁnal sum. The
computational complexity of this scheme is O(n (cid:1) l (cid:1) M (k) + (n (cid:0) 1) (cid:1) l (cid:1) A(k), where
M (k) is the cost of performing one scalar multiplication in the additively homomorphic
encryption system, and A(k) is the cost of one addition. The communication complexity
can be broken down into two parts: user to cloud and cloud to user. The user sends
a vector of size n containing ciphertexts of size k, so the bandwidth complexity user-
cloud is O(n(cid:1)k). The cloud sends back a vector of l
k entries, each of size O(k), resulting
in complexity O(l). This results in the overall communication complexity of O(n(cid:1)k+l).
PIRMAP achieves better overhead than related work [4, 14] in practice, due to the
speciﬁc values of n and l in our setting. Existing work in PIR is efﬁcient only for
data sets with large values for n and small values for l. PIRMAP would do poorly in
that setting, because the complexity would be dominated by n. However, PIRMAP’s
cloud-to-user communication is optimal at O(l), because the cloud must send back a
message at least the size of the ﬁle the user queries for. For values of l larger than
n (cid:1) k, PIRMAP allows for complexity of O(l) with small constants. We argue that in
n (cid:2) p
p
practice this is often true. For example, if a user has a 1 TB data set of 10 MB ﬁles,
l
n
matrix would result in a download cost of 1024 (cid:1) 10 MB (cid:25) 10 GB. Even if n > l,
n
the actual communication costs are low for practical choices of the parameters, see
Section 5. Many cloud providers such as Amazon do not charge the user for uploads,
but only for downloads. This is an additional beneﬁt of our scheme, because the query
result (communication the user is charged for) is always very close to optimal, even
when the overall communication is not.

(cid:25) 800. In contrast, under the same conditions, arranging the ﬁles in a

Our assumption of l > n is realistic and useful for many real-world applications.
For example, medical records may contain one or more images (x-ray, MRI, etc) which
would make them several megabytes at the very least.

Optimization: Although the cloud performs most of the computation in this scheme,
the user is still required to generate a vector of ciphertexts of length n and then decrypt
the resulting response. As encryption is relatively expensive for additive IND-CPA ci-
phers, this might require a non-trivial amount of computation that might hurt, e.g., users
with low-powered devices such as smartphones. A way to alleviate this problem is to
have a moderately powerful trusted server to pre-generate vectors of ciphertexts and up-
load them to the cloud for the users to use. This trusted server would generate m “dis-
posable” vectors of size n such that Vi;j = E(1) where j = HMAC(i) and Vi;j = E(0)
otherwise. This allows the user to use one of these disposable vectors at query time
and permute it so that the single E(1) is at the index of the ﬁle it wishes to retrieve. If
the key used in the HMAC is shared between the user and trusted server, the user can
efﬁciently locate E(1). The user then generates a description of a permutation which
moves the E(1) value to the correct position and randomly shufﬂes all other locations.
A description of this permutation is of size n (cid:1) log(n) which is smaller than the size of
the vector for k > 30. This also effectively front loads the upload cost of the query and
makes response time even faster.

Although the particular encryption scheme we use (see Section 4.2 below) can per-
form encryptions very quickly and does not require the use of this optimization, we
point it out as a general improvement regardless of the cipher used.

4.1 PIRMAP Speciﬁcation

In our protocol, the cloud performs two operations: multiplication of each block by the
corresponding value in the “PIR vector” v, and column-wise addition to construct the
encrypted ﬁle chosen by the user. These two stages translate exactly to map and reduce
implementations respectively. The ﬁles will be distributed evenly over all participating
nodes where the map function will split each ﬁle into blocks and multiply the blocks
by the correct encrypted value. The output of these mappers is a set of key-value pairs
where the key is the index of the block, and the value is the product of the block and
encrypted PIR value. These values are all passed on to the reducers, which take a set of
values for each key (block position or column) and add them together to get the ﬁnal
value for each block.

Being interested in f ilex, the user executes the above Query to compute v which is
sent to the MapReduce cloud. There, each mapper node evaluates Multiply on its locally
stored ﬁle and generates key-values pairs for the reducer. The reducer simply computes
the Sum step by adding all values with the same key and sending them back to the user.
The user receives l

k values of size k from the reducers and decrypts to get f ilex.

User

function GenQuery(n; x)

v := fg
for i = 1 to n do
if i = x then
vi := E(1)
vi := E(0)

else

end if
end for

end function

Cloud

function Map(f ile; v)

for i = 1 to n do

c := Bi (cid:1) vi
Emit(i; c)

end for

end function
function Reduce(key; v)

total := 0
for i = 1 to n do

total := total + vi

end for
Emit(key; total)

end function

4.2 Encryption Scheme

Since the map phase of our protocol involves multiplying every piece of the data set by
an encrypted PIR value, it is important that we choose an efﬁcient cryptosystem. Tra-
ditional additively homormorphic cryptosystems, such as Paillier’s, use some form of
multiplication as their homomorphism. That is, for elements a and b, E(a) (cid:1) E(b) =
E(a + b). Since our map phase consists of multiplying ciphertexts by unencrypted
scalars, we would have to do exponentiation of a ciphertext. PIRMAP, and all PIR
schemes, must compute on the whole data set, so this step would be computationally
intensive.

Similar to our recent ﬁndings [3], we mitigate this problem by using a somewhat ho-
momorphic encryption scheme introduced by Trostle and Parrish [21] that relies on the

trapdoor group assumption. Fully homomorphic encryption schemes support an unlim-
ited number of computations without increasing the size of the ciphertexts. In contrast,
this scheme results in ciphertexts which grow in size by O(log2 n) bits for n additions.
In return for this size increase, we can have an encryption scheme where the additive
homomorphism is integer addition. This scheme encrypts n bits with security parameter
k > n as follows:

KeyGen(1k): Generate a prime m of k bits and a random b < m; b and m are secret.
Encrypt E(x) = b (cid:1) (r (cid:1) 2n + x) mod m, for a random r
Decrypt D(c) = b

(cid:0)1 (cid:1) c mod m mod 2n

This encryption has the desired homomorphic property E(a) + E(b) = E(a + b):
This scheme is somewhat homomorphic, because it cannot support an unlimited number
of additions. When two ciphertexts c1 and c2 are added, you can express the sum as

b (cid:1) (r1 (cid:1) 2n + x1) + b (cid:1) (r2 (cid:1) 2n + x2) = b (cid:1) ([r1 + r2] (cid:1) 2n + x1 + x2):

As m remains secret, note that the cloud performs addition as integer addition, not
modulo m. If the inside term (r1 + r2) (cid:1) 2n + x1 + x2 exceeds m and “wraps around”,
then it will not be decrypted correctly, because application of the modulus will cause a
loss of information. The modulus m must be chosen large enough to support the number
of additions expected to occur. To support t additions, m should be increased by log2 t
bits. Additionally, each scalar multiplication can be thought of as up to 2n additions,
meaning that the size of m must be doubled for each supported scalar product. For
our PIR scheme, m must be chosen to be O(2k + log2(n)) to support the required
homomorphic operations.

In return for the reasonable increase in ciphertext size caused by the larger modulus
(about 300% in our evaluations in Section 5), we are able to do very efﬁcient computa-
tions over the encrypted data. Additionally, encryption is equivalent to only two multi-
plications, an addition and a modular reduction, while decryption is one multiplication
and a reduction. This compares very favorably with other homomorphic encryption
schemes, such as Paillier, requiring a modular exponentiation.

With our encryption scheme deﬁned, we can now express more precise computa-
tional complexities for the protocol. Our previous complexity was parameterized over
M (k) and A(k), the complexity of scalar multiplication and addition, respectively.
For our encryption, addition is simply regular integer addition. Since each cipher text
is at most 2k + log2(n) bits long, addition is O(2k + log2(n)). We can do scalar
multiplication as integer multiplication as well. Integer multiplication can be done
for m bits in O(m log(m) log(log(m))) [9], so M (k) = O(2k + log2(n) log(2k +
log2(n)) log(log(2k + log2(n)))). The complexity is then dominated by the multipli-
cation cost and results in:

O(n (cid:1) l
k

(cid:1) (k + log(n)) log(k + log(n)) log(log(k + log(n))))
= O((n (cid:1) l + n (cid:1) log(n)) log(k + log(n)) log(log(k + log(n))))

(2)
If l > n, then l > log(n), and we can simplify to O(n (cid:1) l (cid:1) log(k + log(n)) (cid:1)
log(log(k + log(n)))). Additionally, k has to be much larger than log(n), otherwise the

(1)

server has the resources to ﬁnd key (m; k) by brute force. This allows us to simplify to
O(n (cid:1) l (cid:1) log(k) (cid:1) log(log(k))).

4.3 Privacy Analysis

PIRMAP inherits privacy properties of the work it is based on, i.e., Lipmaa [14] and
the PIR variant by Trostle and Parrish [21]. In the following, we sketch our privacy
rationale.

PIRMAP is privacy-preserving, iff an adversary (the cloud) cannot guess, after each
query, with probability greater than 1=n, which ﬁle was retrieved by the user after an
invocation of the protocol. There are two pieces of information that the adversary has
access to: the set of uploaded ﬁles and the vector v of PIR values. The uploaded ﬁles are
independent of any encryption used in the PIR protocol and can be efﬁciently simulated
by the adversary. Therefore, privacy depends only on v.

Vector v contains many encryptions of “0” and one encryption of “1”. The problem
of determining which ﬁle was selected is then equivalent to distinguishing between
encryptions of “0” and encryptions of “1” in the underlying encryption. However, the
scheme we use is provably secure against distinguishing under the Trapdoor Group
Assumption [21]. Consequently, PIRMAP preserves user privacy.

5 Evaluation

We have evaluated the performance of our scheme in three contexts: a local “cloud” (a
single server with multiple CPUs), a commodity laptop, and Amazon’s EC2 cloud using
Elastic MapReduce [2]. We have implemented PIRMAP in Java for standard Hadoop
MapReduce version 1.0.3 and the source code is available for download [18].

5.1 Setup

Local We used a local server to prototype and debug our application and to do de-
tailed timing analysis requiring many runs of MapReduce. This server, running Arch
Linux 2011.08.19, has a dual 2.4 GHz quad-core Xeon E-5620 processor and 48 GB of
memory. Based on specs and benchmark results, this local server is closest to an “EC2
Quadruple Extra Large” instance, which has dual 2.9 GHz quad-core Xeon X-5570
processors and 24 GB of memory.

We have measured the time needed for PIR queries, i.e., the time to upload PIR
vector v plus the time to process the query and download the result. Using Amazon’s
standard cost model, we have calculated the price of each PIR query as the amount
of money required to run the query on one of the above EC2 instances (for the same
amount of time it took to run locally) plus the bandwidth cost of downloading the re-
sults [2]. Since uploading data to Amazon is free, this does not add any additional cost.
To put our measurements into perspective, we have also evaluated time and cost of two
other, hypothetical, PIR protocols. We have implemented a Baseline, which does not
perform any cryptographic operations and merely “touches” each piece of data through
the MapReduce API. This measure shows the theoretical lower bound of computation

Fig. 1: Time per query, local server

Fig. 2: Cost per query, local server

Fig. 3: Time per query, Amazon

Fig. 4: Cost per query, Amazon

and time required for any PIR scheme that uses MapReduce, independent of the en-
cryption and exact PIR method used.

To highlight the advantage of computational PIR, we have also included the time
and cost required for the “trivial” PIR scheme. The trivial scheme is one where the user
downloads the entire data set and simply discards the ﬁles he is not interested in. This
is very bandwidth intensive, but computationally lightweight. Sion and Carbunar [19]
conjecture this trivial PIR to be the most cost effective in the real-world. We have calcu-
lated the cost based on the amount that Amazon charges to download the corresponding
amount of data and the time based on a 11.28 Mbps connection, an average as reported
by Nasuni [16]. Note that we generally do not count the cost for long-term storage of
data at Amazon. Although potentially signiﬁcant for large amounts of data, the user has
to pay for this regardless of whether he wants queries to be privacy-preserving or not.
PIRMAP does not increase the amount of storage in Amazon.

Laptop We also ran our implementation on a 2012 MacBook Pro with a 2.3 Ghz i7,
8 GB of RAM and an NVIDIA GeForce 650M. The purpose of this test was to com-
pare query time with related work, and the results are shown in Table 4. The Aguilar
scheme takes advantage of GPU resources, so we chose a machine with comparable
graphics and GPU resources (unlike the above server, which had no discrete graph-
ics). This represents the performance you would get on a commodity machine and also

 100 200 500 1000 2000 5000 10000 10 20 30 40 50 60 70 80 90 100Time (s)Total amount of data (GByte)Trivial PIRPIRMAP 1MBPIRMAP 3MBBaseline 1MBBaseline 3MB 0.01 0.02 0.05 0.1 0.2 0.5 1 2 5 10 10 20 30 40 50 60 70 80 90 100Cost ($)Total amount of data (GByte)Trivial PIRPIRMAP 1MBPIRMAP 3MBBaseline 1MBBaseline 3MB 100 200 500 1000 2000 5000 10000 20000 50000 100000 50 100 150 200 1000Time (s)Total amount of data (GByte)Trivial PIRPIRMAP 1MBBaseline 1MB 2 5 10 15 20 50 100 50 100 150 200 1000Cost ($)Total amount of data (GByte)Trivial PIRPIRMAP 1MBBaseline 1MBshows that query generation is not very taxing. To compare with Lipmaa [14], we used
openssl speed rsa to time determine how many RSA private key operations can
be computed per second. Each scalar multiplication in that scheme is equivalent to one
modular exponentiation, or one RSA private key operation as required by Lipmaa [14].
This estimation is quite generous for Lipmaa [14], because it does not include disk ac-
cess or homomorphic additions (modular multiplication), but we believe it is close due
to the time being largely dominated by exponentiations.

Table 4: Query time in minutes, including generation, evaluation, and decryption, for
databases of varying sizes, composed of 5 MB ﬁles.

Lipmaa
Aguilar-Gaborit
PIRMAP

5 GB 10 GB 15 GB 20 GB 25 GB 30 GB
1852 3704 5508 7312 9116 10920

4
1

7
2

11
3

14
3

17
4

20
4

Amazon Besides the local experiments, to demonstrate the scalability of PIRMAP,
we have also evaluated it on Amazon’s Elastic MapReduce cloud. Amazon imposes a
maximum limit of 20 instances per MapReduce job by default. In keeping with this
restriction, we used 20 “Cluster Compute Eight Extra Large” instances which each
having dual eight-core Xeon E5-2670 processors and 64 GB of RAM.

5.2 Results
Time and total cost: Figures 1 to 4 show our evaluation results. Figures 1 and 2 show
the local server evaluation, while ﬁgures 3 and 4 show evaluation with Amazon. In each
ﬁgure, the x-axis shows the total amount of data stored at the cloud, i.e., number of ﬁles
n times ﬁle size l. The y-axis shows either the time elapsed (for the whole query from
the time the user submits the query until MapReduce returns the result back) or the cost
implied with the query. In all four graphs, we scale the y-axis logarithmically, and in
ﬁgures 3 and 4 we also scale the x-axis logarithmically. Each data point represents the
average of at least 3 runs. Relative standard deviation was low at (cid:25) 5%.

To verify the impact of varying ﬁle sizes l, for our local evaluation, we show results
with ﬁle sizes of 1 MB and 3 MB, attaining approximately equal runtime in both cases.
This is to be expected because, in each data point, we have ﬁxed the size of the database
so varying retrieval sizes merely reshapes the matrix without changing the number of
elements in it. The execution is dominated by the scalar multiplications that occur dur-
ing the map phase, and the same number of those is required no matter the dimension
of the matrix.

Our evaluation shows that PIRMAP outperforms trivial PIR in both time and cost
by one order of magnitude. We also compare performance to a baseline PIR protocol
implemented in MapReduce where the mappers simply read and ignore any rows that
are no requested and return the single row that was. Any MapReduce-based PIR proto-
col will require at least this amount of computation. Compared to this theoretical, yet

unrealistic optimum, PIRMAP introduces only 20% of overhead in the case of Amazon.
Locally, we experience slightly larger overhead of 100%. This is because executing on
Amazon has a much higher ”administrative” cost due to the higher number of nodes
and more distributed setting. These results indicate not only PIRMAP’s efﬁciency over
Trivial PIR and Baseline, but also its real-world practicality: in a small database com-
prising 10,000 ﬁles of size 1 MB each (10 GByte), a user can retrieve a single record in
(cid:25) 3 min for only (cid:25) $0:03. In a huge data set with 1; 000; 000 ﬁles, a single ﬁle can be
retrieved in (cid:25) 13 min for (cid:25) $14. In scenarios where it is necessary to retrieve data in a
fully privacy-preserving manner, we conjecture that this to be acceptable.

Although a comparison with related research is not straightforward (as PIRMAP tar-
gets a very special scenario), we put our results into perspective with those of Aguilar
and Lipmaa. We show that, while Lipmaa’s scheme has very good communication com-
plexity in all cases, it is completely impractical due to the enormous amount of com-
putation needed to respond to queries. We also show that our scheme is comparable
with that of Aguilar, in terms of computation, and beats it in communication cost by a
signiﬁcant margin.

Query Generation and Decryption: Due to the efﬁciency of the encryption in
PIRMAP, PIR query generation is very fast. One ciphertext (element of v) is generated
for each ﬁle in the cloud, so the generation time is directly proportional to the number
of ﬁles. We omit in-depth analysis, but in our trials on our commodity laptop running
on a single core it takes about 2.5 seconds per 100,000 ﬁles in the cloud. Decryption is
slightly more expensive than encryption, but we still managed, on the same machine, to
decrypt approximately 3 MB per second. We conclude this overhead to be feasible for
the real-world.

Bandwith: PIRMAP introduces bandwith overhead, 1.) to upload v, and 2.) to
download the encrypted version of the ﬁle. For security, we set k = 2048 bit, so each
of the n elements of vector v has size 2048 bit. For a data set with 10,000 ﬁles (10
GByte), this requires the user to upload (cid:25) 2:5 MByte. As this can become signiﬁcant
with larger number of ﬁles, we suggest to then use the optimization in Section 4, espe-
cially for constrained devices.

6 Conclusion

Retrieval of previously outsourced data in a privacy-preserving manner is an important
requirement in the face of an untrusted cloud provider. PIRMAP is the ﬁrst practical
PIR mechanism suited to real-world cloud computing. In the case where a cloud user
wishes to privately retrieve large ﬁles from an untrusted cloud, PIRMAP is communica-
tion efﬁcient. Designed for prominent MapReduce clouds, it leverages their parallelism
and aggregation phases for maximum performance. Our analysis shows that PIRMAP
is an order of magnitude more efﬁcient than trivial PIR and introduces acceptable over-
head over non-privacy-preserving data retrieval. Additionally, we have shown that our
scheme can scale to cloud stores of up to 1 TB on Amazon’s Elastic MapReduce.

Acknowledgments: This work was partially supported by NSF grant 1218197.

Bibliography

[1] C. Aguilar-Melamine and P. Gaborit. A Lattice-Based Computationally-Efﬁcient Private
Information Retrieval Protocol, 2007. http://eprint.iacr.org/2007/446.pdf.
[2] Amazon.
http://aws.amazon.com/
[3] E.-O. Blass, R. Di Pietro, R. Molva, and M. ¨Onen. PRISM – Privacy-Preserving Search in
MapReduce. In Proceedings of Privacy Enhancing Technologies Symposium, pages 180–
200, Vigo, Spain, 2012. ISBN 978-3-642-31679-1.

elasticmapreduce/.

Elastic MapReduce,

[4] C. Cachin, S. Micali, and M. Stadler. Computationally private information retrieval with
In Advances in Cryptology, EUROCRYPT, pages 402–

2010.

polylogarithmic communication.
414, Prague, Czech Republic, 1999.

[5] Y. Chen and R. Sion. On securing untrusted clouds with cryptography. In Workshop on

Privacy in the Electronic Society, pages 109–114, Chicago, USA, 2010.

[6] B. Chor, O. Goldreich, and E. Kushilevitz. Private Information Retrieval. In Proceedings

of Symposium on Foundations of Computer Science, 1995.

[7] B. Chor, O. Goldreich, E. Kushilevitz, and M. Sudan. Private Information Retrieval. In

Proceedings of Symposium on Foundations of Computer Science, pages 41–50, 1995.

[8] J. Dean and S. Ghemawat. MapReduce: Simpliﬁed Data Processing on Large Clusters. In
Proceedings of Symposium on Operating System Design and Implementation, pages 137–
150, San Francisco, USA, 2004.

[9] M. F¨urer. Faster integer multiplication. In Proceedings of Symposium on Theory of Com-

puting, 1997.

[10] Gartner. Gartner Identiﬁes the Top 10 Strategic Technologies for 2011, 2010. http:

//www.gartner.com/it/page.jsp?id=1454221.

[11] Google. A new approach to China, 2010. http://googleblog.blogspot.com/

2010/01/new-approach-to-china.html.

[12] J. Hoffstein, J. Pipher, and J. Silverman. NTRU: A ring-based public key cryptosystem.
In Joe Buhler, editor, Algorithmic Number Theory, Lecture Notes in Computer Science.
Springer Berlin, Heidelberg, 1998.

[13] E. Kushilevitz and R. Ostrovsky.

Replication is not needed: single database,
computationally-private information retrieval. In Proceedings of Symposium on Founda-
tions of Computer Science, pages 364–373, 1997.

[14] H. Lipmaa. An Oblivious Transfer Protocol with Log-Squared Communication. In Confer-

ence on Information Security, pages 314–328, Taipei, Taiwan, 2005.

[15] D. McClure. GSA’s role in supporting development and deployment of cloud computing

technology, 2010. http://www.gsa.gov/portal/content/159101.

[16] Nasuni.

State of Cloud Storage Providers Industry Benchmark Report, 2011.

http://cache.nasuni.com/Resources/Nasuni_Cloud_Storage_
Benchmark_Report.pdf.

[17] F.G. Olumoﬁn and I. Goldberg. Revisiting the Computational Practicality of Private Infor-

mation Retrieval. In Proceedings of Financial Cryptography, 2011.
[18] PIRMAP. Source Code, 2012. http:/pasmac.ccs.neu.edu.
[19] R. Sion and B. Carbunar. On the Computational Practicality of Private Information Re-
In Proceedings of Network and Distributed Systems Security Symposium, pages

trieval.
1–10, San Diego, USA, 2007.

[20] Symantec. State of Cloud Survey, 2011. http://www.symantec.com.
[21] J. Trostle and A. Parrish. Efﬁcient computationally private information retrieval from
anonymity or trapdoor groups. In Proceedings of Conference on Information Security, pages
114–128, Boca Raton, USA, 2010.

[22] Z. Whittaker. Microsoft admits Patriot Act can access EU-based cloud data, 2011. http:

//www.zdnet.com/.

