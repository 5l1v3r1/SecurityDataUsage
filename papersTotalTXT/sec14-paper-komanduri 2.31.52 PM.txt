Telepathwords: Preventing Weak Passwords  

by Reading Users’ Minds

Saranga Komanduri, Richard Shay, and Lorrie Faith Cranor, Carnegie Mellon University; 

Cormac Herley and Stuart Schechter, Microsoft Research

https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/komanduri

This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXTelepathwords: preventing weak passwords by reading users’ minds

Saranga Komanduri, Richard Shay, Lorrie Faith Cranor

Carnegie Mellon University

Cormac Herley, Stuart Schechter

Microsoft Research

Abstract
To discourage the creation of predictable passwords, vul-
nerable to guessing attacks, we present Telepathwords.
As a user creates a password, Telepathwords makes real-
time predictions for the next character that user will type.
While the concept is simple, making accurate predictions
requires efﬁcient algorithms to model users’ behavior
and to employ already-typed characters to predict subse-
quent ones. We ﬁrst made the Telepathwords technology
available to the public in late 2013 and have since served
hundreds of thousands of user sessions.

We ran a human-subjects experiment to compare pass-
word policies that use Telepathwords to those that rely
on composition rules, comparing participants’ passwords
using two different password-evaluation algorithms. We
found that participants create far fewer weak passwords
using the Telepathwords-based policies than policies
based only on character composition. Participants using
Telepathwords were also more likely to report that the
password feedback was helpful.

Introduction

1
Users are often advised or required to choose passwords
that comply with certain policies. Passwords must be at
least eight characters long. They must contain charac-
ters from at least three out of four character categories
(uppercase characters, lowercase characters, digits, and
symbols). The password should not be based on a dictio-
nary word.

While rules for composing passwords often feel arbi-
trary and capricious, they respond to a problem of gen-
uine concern: left to their own devices, a signiﬁcant frac-
tion of users will choose common passwords that attack-
ers may guess quickly. Composition rules were created
decades ago under the assumption that minimum-length
and character-set requirements would result in passwords
that were harder for attackers to guess. It is only in the

past few years that researchers have begun to test this hy-
pothesis (and found the evidence to support it far weaker
than assumed).

Indeed, password-composition rules feel arbitrary and
capricious because, quite simply, they often are. Users
can hardly be blamed if they question the credibility of
rules that reward those who choose the common pass-
word P@ssw0rd over those who enter a long randomly
generated string restricted to lowercase letters (e.g., to
facilitate typing on a touch-screen keyboard) or of pass-
word meters that offer irreconcilably different quality es-
timates for the same string [4]. If we are to prevent users
from selecting weak passwords, we must ﬁrst improve
the technology used to identify weak choices, but also
overcome any skepticism caused the failure to clearly ex-
plain the need for the restrictions being imposed.

Our proposal, Telepathwords, is different from previ-
ous weak-password prevention schemes in that, as users
enter their proposed password, it shows its best predic-
tions for the next character they will type in real time (see
Figure 1). Telepathwords makes these predictions us-
ing knowledge of common behaviors users exhibit when
choosing passwords, common strings they frequently use
to construct passwords, and a general model of the user’s
language. Telepathwords presents users who enter weak
passwords with immediate and compelling evidence that
their intended password may be easier to guess than they
had previously assumed: a display of the characters they
are about to type.

We describe the design,

implementation, human-
subjects testing, public deployment, and user response
to the Telepathwords system. The results of our se-
curity testing are particularly compelling.
In a 2,560-
person Mechanical Turk study, passwords created us-
ing Telepathwords signiﬁcantly outperformed (using
both entropy and guessing number metrics) those cre-
ated under length and character composition policies,
while remaining as memorable as passwords chosen
with the least stringent requirement (an eight-character

USENIX Association  

23rd USENIX Security Symposium  591

592  23rd USENIX Security Symposium 

USENIX Association

Figure1:TheTelepathwordssystem,shownhereasdeployedinapubliclyavailablepassword-weaknesschecker,attemptstoguessthenextcharacterofausers’passwordbeforeheorshetypesit.minimum-lengthrequirement).Theymatchedorslightlybeatpasswordscreatedunderapolicythatcheckedagainstalargecracking-dictionary,whileatthesametimehavingmoreusersstatethattheyfoundthevisualfeedbackuseful.Theimprovementsinguessingresis-tanceweremostpronouncedforthemostvulnerablepartofthedistribution.Thatis,theweakestpasswordscre-atedusingTelepathwordsrequireordersofmagnitudemoreguessesthantheweakestpasswordscreatedunderpoliciesbasedoncompositionandlength.ThissuggeststhatTelepathwordscanoffermeaningfulimprovementindefendingagainstonlineguessingattacks;animprove-mentthatwehopecanrebuildusers’conﬁdencethattheconstraintsbeingimposedonthemareindeednecessary.2DesignandImplementationWebeginourdiscussionoftheTelepathwordssystembydescribingtheintendeduserexperience,thendiscusstheoverallarchitectureandpredictionalgorithmsrequiredtoimplementthatexperience.Wealsodescribethefeed-backmechanismsweincludedtoobserveusageofthesystem,aswellasthelimitationsinherenttoourimple-mentation.2.1UserExperienceTelepathwordsenhancesthetextﬁeldintowhichuserstypenewpasswordswithtwoadditionalelements:apre-dictiondisplayandafeedbackbar.Figure1illustratesboth,withthepredictiondisplayjusttotherightofthetypedpassword(P@)andthefeedbackbarimmedi-atelyaboveit.2.1.1PredictiondisplayThepredictiondisplayshowsthethreecharacters(orfewer)thatTelepathwordspredictstheuserismostlikelytotypenext.Asusersaremostlikelytobefamiliarwithpredictionfromautocomplete,wherethepredictionsrep-resentadesirablemechanismtosavelabor,weneededtoemphasizethatthecharacterstelepathwordspredictareundesirable,asthesechoicesareleastlikelytomakethepasswordharderforattackerstoguess.Wethusdisplaypredictedcharactersinblockuppercasewithintheprohi-bitionsymbol,or‘universalnosymbol’:aredcirclewithaslashthroughit.Weanticipatedthesymbolwouldbefamiliartousersbecauseitisstandardized(ISO3864-1,thoughwedidnotstrivetoachievefullcomplianceinouruse),widelyusedinroadsigns,andpervasiveinpopularculturesuchast-shirtsandmovies.Totherightofthecharacterwepresentashortexpla-nationofwhythatcharacterwaspredicted.Ifwepre-dictedthecharacterbecausewedetectedtheusertypingarepeatingsequenceofcharacters,wedisplay‘repeat-ing’followedbythecharactersequencebeingrepeated.Ifitisthenextcharacterofacommonstring,wepresentthewords‘asin’followedbythatstring,withthenextcharacterboldfacedandunderlined.Forexample,inFig-ure1,theinputof“P@$$”yieldspredictions:“Wasinpassword,”“Iasinpassion,”and“Pasinpassport.”2.1.2FeedbackbarInthefeedbackbarabovethepassword-entryﬁeld,weshoweitheracheckmarkorcrossoutsymbolaligneddi-rectlyaboveeachofthecharactersalreadytyped.AcheckmarkmeansthecharacterwasnotpredictedbyTelepathwords,whereasacrossoutindicatesitwasoneofthecharactersguessed.Wealsodisplayacrossoutiftheusertypesacommonsubstituteforoneofthepre-dictedcharacters,suchasan@toavoidusingana.Totherightofthesesymbolsweprovideguidanceastohowmanymorehard-to-guesscharactersarerecommended,orwouldberequiredifTelepathwordsweredeployedwithaparticularminimumhard-to-guesscharacterre-quirement.Forexample,Figure1showsonecheckandthreecrossoutsabovetheuserinput“P@$$”sinceeachofthelastthreecharacterswaspredictedbasedonthecharactersthatcamebeforeit.22.1.3 Special cases

In many applications, password-creation ﬁelds are con-
ﬁgured to hide the keys typed, replacing them with a
generic symbol (usually a solid circle or an asterisk).
When the password ﬁeld is conﬁgured to hide the char-
acters that have been typed, we also replace those char-
acters with a solid circle in our prediction string. The
predicted characters are still shown.

When users type a common substitute for a predicted
character, such as a $ when an s is predicted, we display
the following message customized for the replacement:

Replacing a predictable letter with a key that looks
similar?

Attackers also know to substitute
it does little to improve your password.

for s, so

We faced a particularly delicate conundrum in how to
handle predictions that completed profanities. An exam-
ination of the Rockyou leaked dataset reveals that pro-
fanities are not uncommon choices. Unlike applications
of prediction in search queries, we could not simply re-
move these predictions, as this would lead users to be-
lieve falsely that profane passwords were less weak than
they actually are. On the other hand, we could not dis-
play profanities to users who might have no intent of typ-
ing them, and who might be minors. We decided that
providing good security advice mandated that we predict
the next character, but we replace the rest of the profane
string with a string of solid circles in the explanation
of the prediction. We also display a pop-up message if
users complete a profanity, alerting them to the fact that
profanities are common in passwords and thus quite pre-
dictable. In crafting this message, we decided to embrace
the inevitability that some users might ﬁnd humor in our
attempts to hide profanity.

Do you email your mother with that keyboard?

Many people include profanity in their pass-
words. Attackers know this.
If you also use
profanity, you’ll just make your password easier for
attackers to guess.

2.2 Architecture
Telepathwords employs a client-server architecture, us-
ing JavaScript to present a front-end user interface us-
ing predictions asynchronously queried from a prediction
server. The constraints of client-side prediction would
not have allowed our prediction engine to use a 1.5GB
language corpus (see Section 2.3.1), which we hope to
grow in order to increase prediction quality and recog-
nize additional languages.

ResultSet
string
Prediction[]

Prediction
char
Score
Reason[]

passwordPrefix
predictions

charPredicted
likelihoodScore
reasonsForPrediction

parent
queryStr
penalty
nodeForEachSuffixLength

Figure 2: When the client queries the server with a pass-
word preﬁx, the Telepathwords prediction engine gener-
ates a result set containing a series of predictions, each
of which may have been predicted based on a number of
reasons (e.g., a dictionary match or a keyboard pattern).

WindowOfTrieNodes
WindowOfTrieNodes
string
Score
{uint→TrieNode}
Other weak-password-prevention systems, such as
common password meters, eschew server-side predic-
tions. One justiﬁcation is security. However, the current
architecture of the web necessitates that whatever pass-
word the user eventually chooses will inevitably be sent
to the website’s servers in a plaintext-decryptable format.
To prevent the size of a prediction from revealing the pre-
ﬁx sent to the server, we use a custom format to compress
and then pad responses to a common length. We route all
client-server communications over HTTPS.

TrieNode
Score
{char→TrieNode} children

likelihoodScore

A second reason to eschew server-side predictions is
performance. However, network latencies are relatively
small in comparison to users’ expectations of response
time, and can be made smaller by moving servers closer
to users and pre-fetching likely queries, as demonstrated
by the speed of auto-complete in web search. For exam-
ple, though our deployment used servers in a single ge-
ographic location to serve users worldwide, the median
latency between key-up and the rendering of a prediction
at the client was a ﬁfth of a second (see Section 3).

One additional security risk we decided to take was to
maintain a cache of previously queried preﬁxes on the
server, whereas we would otherwise be able to delete all
evidence of a past request after serving a prediction. This
greatly increases the likelihood that when the nth char-
acter of a password arrives, the server will already have
done the work to process the ﬁrst n− 1 characters.

2.3 Prediction algorithms
When performing a prediction, we create a result set data
structure and populate it with a set of predictions, as il-
lustrated in Figure 2. Each prediction object represents a
possible next character of the password and a score that
indicates its estimated likelihood. There may be more
than one reason to predict a character, and so each pre-
diction object contains a set of reason objects. We pop-
ulate the result set by spawning a set of predictors, algo-
rithms which identify reasons for predicting a character

USENIX Association  

23rd USENIX Security Symposium  593

3

TrieNode
Score
{char→TrieNode} children

likelihoodScore

(a) Node data structure

…

p

a

s

r

r

o

g

…

…

…

p

a

s

r

r

o

g

…

…

(b) A section of the trie

(c) Descent to node par.

Figure 3: The trie data structure maps strings to likeli-
hood scores. Nodes (circles) with higher scores appear
to the left of lower-scoring siblings. Subﬁgure (c) illus-
trates a walk to the node storing the likelihood score for
string par.

will be typed next, add that reason to the prediction ob-
ject for that character, and increase the predictions score
as necessary.

When all the predictors have run, we rank the pre-
dictions and reasons. Before sending predictions to the
client, we discard predictions and reasons that are not
ranked high enough to be displayed to the user. We cache
the result set so that we can use it again for future queries
for this string, or extensions of this string.

Telepathwords currently contains predictors for com-
re-

mon character sequences, keyboard movements,
peated strings, and interleaved strings.

2.3.1 Common character sequences
This predictor detects known preﬁxes of common char-
acter sequences from language models and databases of
common passwords, and predicts the remaining sufﬁx.
The expected likelihood of the prediction increases with
the length and frequency with which the preﬁx was ob-
served when the model was built.

To search quickly through a large preﬁx of known
strings and their frequencies, we use the space-efﬁcient
completion trie of Hsu and Ottaviano [10], as illustrated
in Figure 3. The trie used by Telepathwords contains
a 1.5GB English-language model derived from browser
search queries and a set of passwords that occurred ﬁve
times or more in the RockYou dataset. We removed all
capitalization and spaces from the language model be-
fore building the trie.

Completion tries are already used for auto-completion
and word-breaking applications, and these applications
require algorithms that adapt to common misspellings
and typos. For example, existing systems will walk a

WindowOfTrieNodes
WindowOfTrieNodes
Score
TrieNode[]

parent
penalty
nodeForEachSuffix

a

b

c

b

c

c

a

b

b

a

parent

parent

Figure 4: Telepathwords uses a sliding window to walk
the trie for each sufﬁx of the queried string. If the query
string is a single character (e.g., a), the sliding window
will contain only one node (left). A two-character string
(ab) will a sliding window that walks the trie to two dif-
ferent nodes (center). The query string abc yields a win-
dow that covers the sufﬁxes c, bc, and the full sufﬁx abc
(right). Adding one character to the query causes the
pointer to each node to descend to the child node for that
added character, and creates a new node in the window
by stepping from the root node to the added character.
Telepathwords may add a penalty to the window when
the path down the trie is different from the actual string
queried, such as if a window is created to represent a
transposition.

completion trie reversing the two characters at the sufﬁx,
applying a penalty to account for the fact that transposi-
tions occur with much lower frequency than correctly se-
quenced characters. If the transposed preﬁx occurs with
sufﬁcient frequency to overcome the penalty, the system
may continue to track that transposition and make pre-
dictions based on it.

Since Telepathwords uses tries to look for common
strings that may begin anywhere in the query (e.g.,
passw in the query notapassword), we maintain a win-
dow of completion-trie nodes for each possible starting
position, as illustrated in Figure 4. We track the trie
node for each possible sufﬁx of the query. In addition,
we maintain two special windows: one that walks the
trie only when letters are typed and one that does so
only when digits are typed. These special windows help
to detect words broken up by non-alphabetic characters
(e.g., pa1234ssword) or numbers broken up by non-
digits (e.g., 12x34y678z9).

In contrast to other applications of tries, users choose
passwords with the deliberate goal of creating a string
that is hard to predict, leaving many more anomalies to
detect and work around than if divergences from known
strings occurred only by accident. We thus maintained a
large list of windows for each queried password preﬁx so
as to preserve nodes that might not immediately appear

594  23rd USENIX Security Symposium 

USENIX Association

4

USENIX Association  

23rd USENIX Security Symposium  595

Figure5:Thecommoncharactersequencepredictorwalkstheancestrychaintoseeifacompletionthatwasbrokenbyanunpredictedcharactermightstillprovidethebestguessforwhathappensnext.Forpa**w,thethirdancestor(pa)predictedthewintheﬁfthposition,andsincetherearenootherlikelypredictions,predic-tionsusingthisancestorreachthetop.valuablebutmightprovepredictiveasmorecharactersarrive.Wealsobuiltatablemappingcommoncharactersub-stitutions,suchas3fore,fors,and0foro,thatareof-tenprovidedinpassword-creationguidance(inourview,misguidedly).Ifwedetectacharacterthatisoftensubsti-tuteforanother,wecreateawindowusingthecharacterwebelievewassubstitutedforandassignthatwindowanappropriatepenalty.Todetectwhenuserstypedistractorcharactersinplaceofpredictedcharacters,thencarryonwiththepre-dictedstring,wewalkuptheancestrypathofthecurrentpreﬁxtolookforpredictionsthatmayhavebeenaban-donedduetosuchbehavior.Forexample,iftheuserhastypedthepreﬁxpa**w,thealgorithmwillwalkupfrompa**wtotheancestorpreﬁxpa,determinethatthepre-dictionofpasswordforthispreﬁxwouldhavecorrectlypredictedthewintheﬁfthposition,andmaythusrevivethatpredictiontopredictaointhenextposition.SeeFigure5.Similarly,weusethestandarderror-correctiontechniqueofdetectingwhenauserhasskippedakeyandtypedthesecondcharacterpredictedinplaceofthenextcharacterpredicted.Theanalysisofeachpasswordpreﬁxoflengthnbe-ginswiththeanalysisofitsimmediatepreﬁxoflengthn−1.Thus,thecostofanalysisgrowsatleastlinearlywiththelengthofthepassword.Wemaintainamain-memorycacheofrecentlyanalyzedquerystringssothatresultscanbere-usedwhenthesufﬁxesofapreviously-queriedstringarequeried.Evenunderheavyload,thecacheissmallincompar-isontothe1.5GBlanguagecorpus.Inourdeployment,thelanguagecorpusisstoredinmainmemory.Duringdevelopment,wefoundperformancetobesufﬁcientlyfastusingasolidstatedrive(SSD)tostorethecorpusandonlymappingpagesintomainmemoryondemand.Inourdeployment,weprefetchedthefullcorpusintoDRAMasourserversdidnothaveSSDs.Figure6:Thepassword3edc4,composedofverticalcolumnsonaQWERTYkeyboard(3edc,4rfv,etc.),triggersthekeyboard-movementpredictoryieldingrasthetopguessforthenextcharacter.Thesecondpre-dictionguessesthatthe4isusedinplaceofforinforever,andthethirdpredictionguessesthatecuadorisinterleavedintoeveryothercharacterofthepassword.Figure7:Thestartofarepeatingstringtriggerstherep-etitionpredictor.2.3.2KeyboardmovementsWedevelopedthispredictortodetectpasswordscom-posedofasequenceofcharacterstypedbymovingone’sﬁngeroverasequenceofadjacentkeys.Webuiltakeyboardmodelthatmapscharacterstoxandycoordinatesthatrepresentthecolumnandrowofthekeyusedtotypeeachcharacteronakeyboard.Werepresentann-characterpasswordpreﬁxasasequenceofnkeypositions,thengenerateaseriesofn−1move-mentsfromtheﬁrsttothelastcharacter.Wethenworkbackwardfromtheendofthepreﬁxtocountthenum-berofconsecutivemovesthataretoadjacentkeysand,ofthose,thenumberofconsecutivemovesinthesamedirection.Wecountmovementsthatwrapfromoneendofthekeyboard(e.g.,fromtoptobottom)asadjacent.WehavecurrentlymappedonlyQWERTYkeyboards,buttheimplementationisgeneralizedtosupportanymappingofcharacterstocoordinates.2.3.3RepeatedstringsThispredictorlooksforinstancesofrepeatedstringsinpasswordpreﬁxes.Foreachpossiblesufﬁxoflengthn,itlooksforrepeatedsequencesofthesufﬁx.Thelongertherepeatedsequence,thestrongertheprediction.Iftherep-etitionsareadjacenttoeachother(xyabcabcabc),thenthepredictorguessesthenextcharacterintherepeatedsequence(ortheﬁrstiftheendhasbeenreached).Ifthesufﬁxanditscopyarenotadjacent,thentheearlycopyandtheinterveningstringareassumedtobeinthepro-cessofrepeating.Forexample,inabcdefabcthesufﬁxabcisrepeatedtwiceandthepredictorguessesthatdefwillcomenext.52.3.4 Interleaved strings
This predictor looks for passwords composed of two
predictable strings interleaved with each other, such as
p*a*s*s*w*o*r*d or ppaasswwoorrdd. It splits pass-
words to separate the odd- and even-indexed characters
and runs the other predictors (with interleaving-detection
turned off) on the substrings. If, for example, the next
character is at an even-index, it uses the even-index sub-
string to make the prediction, and also examines the pre-
dictability of the odd-index substring in evaluating the
likelihood that the query actually represents two inter-
leaved strings.

2.4 Telemetry
Our public deployment of Telepathwords maintains a
limited log of user behaviors, including page loading, re-
sizing, key-up events, and prediction rendering events.
Unless users explicitly opt-in to ‘donate’ their keystrokes
to science, we record the timing of keyup events, the
number of keys added or deleted, and the position of the
change, but not the actual keys typed. We also record
whether characters currently in the password ﬁeld were
among those predicted, recording data similar to that
which is displayed in the feedback bar.

While we store logs online, the server is unable to read
their contents. At the start of a user session the client-
side JavaScript requests a one-time session-encryption
key from the server. The server generates the key, en-
crypts it with a public key, and then writes the encrypted
session key to the ﬁrst entry of the log for the session.
It then sends the key to the client and maintains no fur-
ther record of it. The private key is not stored on any
publicly facing server. The client XORs the log data
stream with a bit stream generated by using AES in
counter mode with the Stanford Javascript Crypto Li-
brary (SJCL) [27]. We opted for this approach, inspired
by Kelsey and Schneier [23], because of its simplicity
and as concerns over conﬁdentiality far outweighed that
of integrity. As logs are never read online, and no action
is taken with them but to store them, we do not know of
a scenario in which an adversary could learn the contents
of the logs by modifying them.

2.5 System Limitations
The current deployment of Telepathwords has some lim-
itations that are inherent to research prototypes. The lan-
guage corpus is US-centric and somewhat dated, and so
unlikely to pick up on words or phrases uncommon in the
United States or that have entered the common lexicon
since 2012. An ideal set of corpora would be interna-
tional and receive constant updates from the latest search
queries, news, and other topical sources.

Telepathwords cannot currently detect reversed char-
acter sequences (gfedcba in place of abcdefg) unless
that reversal is itself already common enough to be in
the language corpus (as it is for drowssap, for exam-
ple). One way to implement reversal detection would be
to reverse the more common strings in our language cor-
pus, assess a penalty for the reversal, and insert them into
our completion trie.

The privacy promises made by the current deployment
of Telepathwords prohibit analysis of passwords for any
purpose other than the issuing of predictions, and so the
language corpus, scoring rules, and known set of com-
mon password-creation behaviors do not grow over time.
Thus, if users ﬂock to common behaviors in response
to Telepathwords (as they do in response to password-
composition rules) we may not be able to detect these
behaviors in the current deployment.

3 Deployment

to test

that offer

Our ﬁrst deployment of the Telepathwords technol-
ogy is a password-testing website, similar in pur-
pose to existing websites
the
‘strength’ of passwords [9, 16, 20], which is hosted at
https://telepathwords.research.microsoft.com. We took
great pains to avoid positioning the service as measur-
ing any form of ‘strength’ or ‘security’, as no system can
be certain that any user-chosen password is truly strong
or secure. There is no guarantee that a password that ap-
pears strong would not be predictable by an attacker with
better knowledge of how certain users construct pass-
words.

As with any publicly facing Internet service, we de-
ployed Telepathwords with some trepidation not know-
ing what usage levels to expect and not knowing what
factors we may have failed to anticipate when perform-
ing load-testing experiments.
In our pre-deployment
throughput tests, Telepathwords processed 454,486 pass-
words in a database of breached Yahoo! Voices pass-
words in under 7 hours using 3 cores of a 3Ghz Xeon E5
1607 (roughly ﬁve passwords per core-second.)

We opened up our system to the public on December 5,
2013 and saw our highest usage rates shortly afterward,
as the technical press published articles about the release.

3.1 Data collected
We downloaded our encrypted logs to a researcher’s
workstation for decryption and analysis. We graph the
arrival rate of users to our service in Figure 8, which il-
lustrates the burst of trafﬁc during initial release dissi-
pating over time. We are also able to observe the de-
lay experienced by users between the time they typed a
key and received a prediction for what the following key

596  23rd USENIX Security Symposium 

USENIX Association

6

60000

50000

40000

30000

20000

10000

0

s
r
e
s
u
 
f
o
 
r
e
b
m
u
N

3
1
0
2
/
5
/
2
1

3
1
0
2
/
6
/
2
1

3
1
0
2
/
7
/
2
1

3
1
0
2
/
8
/
2
1

3
1
0
2
/
9
/
2
1

3
1
0
2
/
0
1
/
2
1

3
1
0
2
/
1
1
/
2
1

3
1
0
2
/
2
1
/
2
1

3
1
0
2
/
3
1
/
2
1

3
1
0
2
/
4
1
/
2
1

3
1
0
2
/
5
1
/
2
1

3
1
0
2
/
6
1
/
2
1

3
1
0
2
/
7
1
/
2
1

3
1
0
2
/
8
1
/
2
1

3
1
0
2
/
9
1
/
2
1

3
1
0
2
/
0
2
/
2
1

3
1
0
2
/
1
2
/
2
1

3
1
0
2
/
2
2
/
2
1

3
1
0
2
/
3
2
/
2
1

3
1
0
2
/
4
2
/
2
1

Date

Figure 8: Sessions served per day by the Telepathwords
service shortly after release. (A Session is counted when
the Telepathwords page loads and the server receives a
request for a session ID and encryption key used for log-
ging.)

160000

140000

120000

100000

80000

60000

40000

20000

s
e
k
o
r
t
s
y
e
k
 
f
o
 
r
e
b
m
u
N

0

0

100

200

300

500

400
Milliseconds

600

700

800

900

1000

Figure 9: The distribution of the delay between the
“keyup” and “render” events for all keystrokes during the
recording period. The median occurs at 208ms.

would be, graphed in Figure 9. The median delay was
200ms. A peak in the graph around 20ms is likely due to
fast rendering of predictions cached within the browser.
We are also able to use the logs to track how much
activity users perform during each user session. In Fig-
ure 10, we examine the distribution of number of keys
pressed per user session, seeing that some users appeared
to use the site to test multiple passwords.

4 Experimental Methodology

In addition to the deployment, we conducted a compar-
ative evaluation of Telepathwords and a number of ex-
isting password-composition policies via a two-part on-
line study using Amazon’s Mechanical Turk crowdsourc-
ing service. To facilitate comparisons with prior work,
much of our methdology mirrors that of a recent line
of research from Carnegie Mellon University, includ-
ing that of Kelley [12], Komanduri [13], Mazurek [15],
Shay [24, 25], Ur [28], and others.

4500

4000

3500

3000

2500

2000

1500

1000

500

0

s
r
e
s
u
 
f
o
 
r
e
b
m
u
N

147

0
1

3
1

6
1

9
1

2
2

5
2

8
2

1
3

4
3

7
3

0
4

3
4

6
4

9
4

2
5

5
5

8
5

1
6

4
6

7
6

0
7

3
7

6
7

9
7

2
8

5
8

8
8

1
9

4
9

7
9

0
0
1

Keystrokes

Figure 10: The number of keystrokes received per user
session provides insight into user engagement with the
site. The median is 15 and the mean is 21 keys pressed
per session.

Our experiment was approved by Carnegie Mellon
University’s institutional review board prior to the start
of our study.

4.1 Recruiting and Data Collection
We recruited participants from Amazon’s Mechanical
Turk by listing a Human Intelligence Task (HIT) in
which we offered 55 cents to “Take a 5-minute survey
with 70-cent bonus opportunity!” We required partici-
pants be 18 years of age and located in the United States.
We asked participants to imagine that their email ac-
count had been compromised and that they needed to cre-
ate a new password to replace it. We used a round-robin
algorithm to assign participants one of six password-
composition policies. As users typed their proposed
password, we provided real-time feedback indicating the
conditions that needed to be met for participants to sat-
isfy their assigned policy. Whereas prior CMU studies
checked compliance with password policies after partic-
ipants had submitted them, in this study we enabled the
submit button only after a participant had satisﬁed the
policy (and correctly retyped the password).

After participants submitted the password, we pre-
sented a survey with up to 24 questions to ask about their
experience creating the password, more general ques-
tions about their password habits, and their demograph-
ics. Following the survey we asked participants to recall
their passwords, giving them ﬁve attempts to do so. We
displayed their password to them if they could not recall
it within those ﬁve attempts. This concluded part one of
our study.

Two days later, we invited participants to return for
part two of our study, sending them an email via an in-
terface provided by Mechancial Turk. We offered 70
cents to return for this HIT, in which we asked partici-
pants to recall their passwords. Again, we allowed par-

USENIX Association  

23rd USENIX Security Symposium  597

7

ticipants ﬁve attempts to provide the correct password.
We displayed participants’ passwords if they were unable
to succeed within ﬁve attempts, though we did not tell
them this a priori. We wanted participants to complete
the study whether or not they recalled their password, so
we provided them with a last-resort mechanism for re-
covering their passwords: a link, which would send an
email, which contained a link, which led to a webpage,
which displayed the correct password. We took this in-
tentionally circuitous approach, rather than simply show-
ing participants their passwords on request, to discourage
them from using the recovery mechanism without ﬁrst
trying to recall their passwords. Outside the extra effort
for password recovery, we did not further penalize par-
ticipants for failing to recall their passwords; if we had,
and future participants learned about it, they might have
been more likely to store their passwords.

Finally, we asked participants to take an 18-question
survey asking about their password-recall process and
whether they had stored their passwords.

Except as noted, we focus our analysis on those par-
ticipants who ﬁnished the ﬁrst part of our study. Our
analysis of dropout rates examines all participants who
begin the study, and our analysis of part two examines
only those participants who ﬁnished part two. We ex-
clude participants from part two if they did not complete
it within three days of the invitation.

4.2 Treatments
The only features of our study that varied between par-
ticipants were the assigned password-composition pol-
icy, whether the password ﬁeld hid the characters typed
into it, and a few survey questions about policies speciﬁc
to certain treatments. Of the six password policies we
assigned to participants, two use a Telepathwords-based
policy and four use policies based on composition-rules
and (in one case) dictionary checks.

(cid:127) telepath,

telepath-v These two conditions em-
ployed a Telepathwords-based policy that required
users to provide a password with at least six charac-
ters that were not predicted by the system. The sys-
tem does not predict the ﬁrst character, and so the
ﬁrst character of each password always counted to-
ward the requirement. The two conditions differed
only in that passwords would be shown by default
as they were being typed in telepath-v and were hid-
den by default in telepath.

(cid:127) basic8 This condition required passwords of at least

eight characters in length.

Figure 11: The 3class8-d treatment on the experimental
website.

Figure 12: The telepath treatment on the experimental
website.

acter classes: uppercase letters, lowercase letters,
digits, and symbols. This policy mirrors the default
password policy for Microsoft Windows Active Di-
rectory.

(cid:127) 3class12 This condition required passwords of at
least 12 characters in length from three of four char-
acter classes.

(cid:127) 3class8-d This condition required passwords to in-
clude at least eight characters, from three of four
character classes, and required that the string of all
letters within the password not match any of the
roughly 3M words in the free Openwall cracking
dictionary [5].

We displayed the requirements that had not yet been
met directly above the password-entry ﬁeld, as shown in
Figure 11. If the password had not yet met the length
requirement, we displayed that requirement. If a pass-
word met the length requirement, we displayed remain-
ing composition requirements, if any.
If the password
met the length and composition requirements but failed a
dictionary check (for 3class8-d), we displayed the match
and indicated that the password must not contain the
matched word.

(cid:127) 3class8 This condition also required passwords of at
least eight characters in length, adding the require-
ment that the password include three of four char-

We displayed a checkbox that allowed participants to
show or hide the characters being typed. With the excep-
tion of telepath-v, the password was hidden by default.

598  23rd USENIX Security Symposium 

USENIX Association

8

Participation

arrived at part one
ﬁnished part one 431/476 (91%) 440/475 (93%) 425/472 (90%) 402/469 (86%) 420/476 (88%) 442/476 (93%)
returned & ﬁnished part two in <3 days 270/431 (63%) 296/440 (67%) 277/425 (65%) 260/402 (65%) 267/420 (64%) 257/442 (58%)

475

472

469

476

476

476

basic8

3class8

3class12

3class8-d

telepath

telepath-v

Password Selection & Handling among part-two participants

did not store 172/270 (64%) 197/296 (67%) 168/277 (61%) 155/260 (60%) 168/267 (63%) 141/257 (55%)
did not re-use 221/270 (82%) 228/296 (77%) 226/277 (82%) 214/260 (82%) 229/267 (86%) 203/257 (79%)
did not store or re-use 135/270 (50%) 149/296 (50%) 140/277 (51%) 118/260 (45%) 138/267 (52%) 112/257 (44%)

Password Recall in 5 tries without reminder

during part one 423/431 (98%) 434/440 (99%) 414/425 (97%) 391/402 (97%) 407/420 (97%) 429/442 (97%)
all part-two participants 176/270 (65%) 213/296 (72%) 186/277 (67%) 193/260 (74%) 183/267 (69%) 178/257 (69%)
part two did not store 105/172 (61%) 131/197 (66%) 104/168 (62%) 103/155 (66%) 103/168 (61%)
86/141 (61%)
part two did not re-use 144/221 (65%) 163/228 (71%) 151/226 (67%) 155/214 (72%) 159/229 (69%) 143/203 (70%)
69/112 (62%)

83/135 (61%)

97/149 (65%)

86/140 (61%)

73/118 (62%)

84/138 (61%)

part two did not store or re-use

Table 1: We tally the set of participants who began part one of our study, ﬁnished it, and who returned for part two.
We measure recall rates for part one (shortly after password selection) and part two. We break down part-two recall
rates to factor out participants who reported re-using passwords they already knew or storing their passwords.

5 Experimental Results and Analysis

The application of multiple statistical tests increases the
chance of producing a Type I error, ﬁnding a signiﬁcant
difference where none exists. To compensate for this, we
use a standard two-step process. First, we only perform
pairwise tests if an omnibus test is signiﬁcant. We use
the Kruskal-Wallis omnibus test (KW) for quantitative
data and the χ2 test for categorical data. Second, we cor-
rect all pairwise tests using the Holm-Bonferroni method
(HC). We use the Mann-Whitney U for quantitative pair-
wise comparisons and Fisher’s Exact Test and the χ2 test
for categorical pairwise comparisons.

We performed our experiment in February 2014. We
recruited 2,844 workers to accept our HIT for part one
of our study. Of these, 2,560 ﬁnished, received payment,
and received invitations to return two days later. A total
of 1,627 participants (64%) returned for the second HIT
within three days of when we sent their invitation. Par-
ticipants’ demographics reﬂected a typical population of
workers on Mechanical Turk, with a median reported age
of 27, nearly 60% reporting as male, and 44% reporting
having at least a bachelor’s degree.

We show the progress of participants through our
study in Table 1. We removed from our analysis ﬁve par-
ticipants who created more than one password by using
the back button or reloading the password-creation page.
The condition with the highest dropout rate was
3class8-d, while the lowest dropout rate was telepath-v.
Table 2 shows the dropout rates for each condition. It
also gives the test’s p-value for the null hypothesis (that
the difference between dropout rates was unaffected by
condition) for each pair of conditions. For example, at
p = 0.01 (resp. p = 0.007) the difference in dropout rates
between 3class8-d and 3class8 (resp. telepath-v) is sig-

Fisher’s Exact Test p

(Holm-Bonferroni corrected)

h
t
a
p
e
l
e

2
1
s
s
a
l
c
3

8
c
i
s
a
b

8
s
s
a
l
c
3

v
-
h
t
a
p
e
l
e
t

Treatment Part one dropout t
3class8-d 67/469 14% 1.000 .458 .318 .010 .007
telepath
56/476 12%
1.000 1.000 .318 .255
3class12
47/472 10%
1.000 1.000 1.000
basic8
1.000 1.000
9%
45/476
3class8
7%
35/475
1.000
telepath-v 34/476
7%

Omnibus χ2

5 =19.373, p=0.002

Table 2: The fraction of participants who dropped out
during part one, with corrected pairwise comparisons of
all treatment groups.

niﬁcant. For all of the other condition pairs the hypoth-
esis that condition had no effect on dropout rate is not
ruled out. Note that the table has a triangular structure
since we list the result of each pairwise test only once,
and this same format is used for our other categorical
tests (i.e. Tables 3, 4, 5, 6 and 7).

The median time spent to create a password was 32
seconds for participants in basic8, 43 for 3class8, 53 for
both 3class12 and 3class8-d, 85 for telepath-v, and 96
for telepath. We anticipated participants using Telepath-
words might spend more time, as these treatments in-
cluded three lines of instructions not present in other
treatments (see Figure 12) and their novelty may have
led to more exploration.

USENIX Association  

23rd USENIX Security Symposium  599

9

Fisher’s Exact Test p

(Holm-Bonferroni corrected)

v
-
h
t
a
p
e
l
e

d
-
8
s
s
a
l
c
3

2
1
s
s
a
l
c
3

8
s
s
a
l
c
3

8
c
i
s
a
b

Treatment Creation difﬁcult t
telepath
telepath-v 158/442 36%
3class8-d 123/402 31%
3class12
87/425 20%
3class8
73/440 17%
basic8
51/431 12%
Omnibus χ2

163/420 39% .374 .078 <.001 <.001 <.001
.374 <.001 <.001 <.001
.006 <.001 <.001
.005
.209

5 =135.199, p<.001

.374

Table 3: The fraction of participants in each treatment
who agreed that it was difﬁcult to create a password dur-
ing the experiment.

Fisher’s Exact Test p

(Holm-Bonferroni corrected)

d
-
8
s
s
a
l
c

v
-
h
t
a
p
e
l
e
t

2
1
s
s
a
l
c
3

8
s
s
a
l
c
3

8
c
i
s
a
b

Treatment Creation annoying 3
telepath
3class8-d 165/402 41%
telepath-v 175/442 40%
3class12
136/425 32%
3class8
129/440 29%
basic8
92/431 21%
Omnibus χ2

175/420 42% 1.000 1.000 .034 .002 <.001
1.000 .052 .004 <.001
.117 .013 <.001
1.000 .005
.052

5 =61.805, p<.001

Table 4: The fraction of participants in each treatment
who agreed that it was annoying to create the password
during the experiment.

Figure 13: “Creating my password was difﬁcult” and
“Creating my password was annoying.”

5.1 Recall
We provide recall rates for part one of the study for ref-
erence only, as just minutes had passed since participants
had chosen their passwords. In the second section of Ta-
ble 1, we see that 61.5% of participants indicated that
they had not stored their password and that we had not
detected them pasting or auto-ﬁlling a password into the
recall ﬁeld. Differences between treatment groups were
not statistically signiﬁcant (χ2

5 =9.231, p=0.1).

We looked at the number of part two recall attempts
by the subset of participants who did not store their pass-
words, did not use the reminder feature, and did not
re-use a previous password. Of these 502 participants,
79.3% entered the password on the ﬁrst attempt, and
14.5% entered it on the second attempt. While the om-
nibus test shows a signiﬁcant difference between condi-
tions for taking more than one attempt (χ2
5 =13.943, p
=0.016), the pairwise tests showed no signiﬁcant differ-
ences. Among the 398 of these participants who en-
tered their password correctly on the ﬁrst attempt, the
median password-entry time was 14.8 seconds; this did
not vary signiﬁcantly by condition (KW χ2
5 =4.705, p
=0.453). Looking at the 1159 participants who did not
use the reminder, 80.9% entered the password correctly
on the ﬁrst try. This differed by condition (χ2
5 =12.604, p
=0.027), but no pairwise test was signiﬁcant.

5.2 Participant Sentiment
In addition to recording participant behavior, we asked
participants about their experience. We asked all partic-
ipants whether they felt that creating their password was
difﬁcult or annoying, with results in Figure 13. We show
the pairwise comparisons across conditions for difﬁculty
in Table 3 and annoyance in Table 4.

The three policies that tested participants’ passwords
against lists of common passwords (the Telepathwords
conditions and 3class8-d) had a greater proportion of par-
ticipants who were annoyed than those using the purely
composition-based policies. The differences with the
simplest policies were signiﬁcant, as shown in Table 4.

Figure 14: “When compared to the password I use for
my primary email account, the password I created for
this study was:”.

We also asked participants whether they believed their
study-created password to be more, less, or just as secure
as their primary email password. The results are in Fig-
ure 14. Belief that the study passwords were more secure

600  23rd USENIX Security Symposium 

USENIX Association

10

Fisher’s Exact Test p

(Holm-Bonferroni corrected)

Fisher’s Exact Test p

(Holm-Bonferroni corrected)

h
t
a
p
e
l
e

v
-
h
t
a
p
e
l
e
t

d
-
8
s
s
a
l
c
3

8
s
s
a
l
c
3

8
c
i
s
a
b

Treatment More Secure t
180/425 42% 1.000 .329 .134 <.001 <.001
3class12
telepath
.552 .309 <.001 <.001
172/420 41%
telepath-v 161/442 36%
1.000 .013 <.001
3class8-d 139/402 35%
.075 <.001
3class8
116/440 26%
.027
basic8
78/431 18%

Omnibus χ2

5 =83.62, p<.001

v
-
h
t
a
p
e
l
e

2
1
s
s
a
l
c
3

d
-
8
s
s
a
l
c
3

8
s
s
a
l
c
3

8
c
i
s
a
b

Treatment
telepath
telepath-v 331/442 75%
3class12
253/425 60%
3class8-d 224/402 56%
3class8
241/440 55%
basic8
146/431 34%

Gave Insight t
315/420 75% 1.000 <.001 <.001 <.001 <.001
<.001 <.001 <.001 <.001
.678 <.001
1.000 <.001
<.001

.873

Omnibus χ2

5 =208.104, p<.001

Table 5: The fraction of participants who selected “More
secure” in response to “When compared to the password
I use for my primary email account, the password I cre-
ated for this study was:”.

Table 6: Agreement with “The visual feedback I received
gave me insight into the quality of my password.”

Fisher’s Exact Test p

(Holm-Bonferroni corrected)

v
-
h
t
a
p
e
l
e

2
1
s
s
a
l
c
3

d
-
8
s
s
a
l
c
3

8
s
s
a
l
c
3

8
c
i
s
a
b

Treatment Feedback Helped t
telepath
telepath-v 241/442 55%
3class12
231/425 54%
3class8-d 180/402 45%
3class8
183/440 42%
basic8
77/431 18%
Omnibus χ2

231/420 55% 1.000 1.000 .029 .001 <.001
1.000 .029 .001 <.001
.033 .001 <.001
1.000 <.001
<.001

5 =178.62, p<.001

Table 7: Agreement with “The visual feedback that was
displayed helped me to create a stronger password that I
would have otherwise.”

5.3 Security Results
In Table 8 we present statistics summarizing the com-
position of passwords created under each policy, and se-
curity scores calculated by three metrics. We focus our
analysis on the passwords identiﬁed to be weakest as an
attacker is most likely to try these ﬁrst. Dictionary at-
tacks to obtain beachheads into organizations succeed
when the ﬁrst account is breached. Thus, improving the
security of the weakest password in an organization by
a small amount is far more likely to prevent an attacker
from obtaining a beachhead than a large improvement to
the average password would. This is particularly true for
an online attack where a limited number of guesses per
account can be tried.

We did not encounter any repeat passwords in our
sample, so we cannot use frequency as a metric. Rather,
the ﬁrst metric we apply is an entropy calculation gener-
ated by the open-source zxcvbn password meter [30]. Its
advantages are that it is publicly available, open-source,
and already relied on by large-scale systems, including
DropBox.
Its primary disadvantage is that it was de-

Figure 15: “The visual feedback I received gave me
insight into the quality of my password” and “The vi-
sual feedback that was displayed helped me to create a
stronger password that I would have otherwise.”

ranged from 18.1% for basic8 to 42.4% for 3class12, and
signiﬁcant differences are in Table 5.

We displayed visual feedback in all conditions to help
participants comply with their assigned policy. We asked
participants if they believed the feedback gave them in-
sight into their passwords and if it helped them to create
better passwords. We show their responses in Figure 15
paired with signiﬁcance tests in Tables 6 and 7.

The Telepathwords treatments, along with 3class12,
had the greatest proportion of participants who believed
the feedback helped them create a stronger password.
A signiﬁcantly larger portion of participants in the two
Telepathwords conditions agreed that the feedback pro-
vided more insight than the other treatments—including
the dictionary-based feedback in 3class8-d. This is tem-
pered of course by the higher number who found pass-
word creation difﬁcult or annoying with the tool. We see
this as a hopeful sign that Telepathwords can help im-
prove the credibility of technology designed to prevent
users from choosing weak passwords.

USENIX Association  

23rd USENIX Security Symposium  601

11

signed to meet the constraints required for deployment
as a client-side password meter; it needed to be small
enough to download quickly and efﬁcient enough to run
in JavaScript. As such, it cannot perform the same level
of computational analysis or apply the same body of
knowledge as a tool designed for guessing.

The second metric we apply is a guess-number calcu-
lator developed by Saranga Komanduri, which ﬁrst ap-
peared in Kelley et al. [12, 25]. We call this metric
Weir+ because it builds on the guessing approach of Weir
et al. [29].
Its advantages are that it is designed with
the explicit goal of measuring the number of guesses re-
quired to crack a password, can be trained to target spe-
ciﬁc password policies, and represents the state of the
art in measuring strength against a guessing attack. The
disadvantages of Weir+ include that it is available only
by contacting the author, written in multiple program-
ming languages, and has not been made easy to conﬁg-
ure. Further, its results may vary based on the size and
quality of the training data.
In order to create a large
training set of passwords that comply with the Telepath-
words policies, we used the 133,109 passwords in the
Yahoo! Voices breach data set that received a score of
6 hard-to-guess characters or more from Telepathwords,
which represents 29% of the 453,488 passwords revealed
by that breach.

Our ﬁnal metric is the score provided by the current
version of Telepathwords itself—the number of hard-to-
guess characters. We ﬁnd this informative for comparing
treatments other than those that employ Telepathwords.
The scores for participants in telepath and telepath-v
are provided exclusively for completeness, as partici-
pants who were able to generate a password that met the
Telepathwords policy will score well by default (though
we note that two participants received a 5 due to a change
to predictions from the version deployed during the ex-
periment and the version used to calculate scores).

Regardless of metric, the telepath and telepath-v pass-
words do substantially better than all other conditions,
with the possible exception of 3class8-d. We present the
scores for each metric in Table 8.

For the zxcvbn entropy measure, we show in Fig-
ure 16 that telepath and telepath-v passwords outperform
those from all other conditions for the weakest password
in each condition and the weakest 2.5%, 5%, and 10%
of passwords. Thus, Telepathwords did the best job of
preventing weak passwords. Only when we consider the
median entropy do 3class12 and 3class8-d become com-
petitive. The improvement with respect to 3class8 and
basic8 is enormous.

Figure 17 illustrates the Weir+ measurements. Again
the two Telepathwords conditions show enormous im-
provement over basic8 and 3class8. They show con-
siderable improvement over 3class12 on minimum en-

10.0%

d
e
r
e
v
o
c
 
t
n
e
c
r
e
P

1.0%

0.1%

0

basic8
3class8
3class12
3class8−d
telepath
telepath−v

5

10

zxcvbn entropy scores

15

20

Figure 16: We sort the passwords in each condition
by zxcvbn-entropy scores, from lowest to highest, and
present the fraction of passwords with scores at or be-
low a given value. Only passwords with entropy scores
of 20 or less are shown in order to highlight the weakest
passwords in each condition.

10.0%

d
e
k
c
a
r
c
 
t

n
e
c
r
e
P

1.0%

0.1%

100

103

106

Weir+ guess numbers

109

basic8
3class8
3class12
3class8−d
telepath
telepath−v

Figure 17: We sort the passwords in each condition by
their Weir+ guess number, from lowest to highest, and
present the fraction of passwords that with guess counts
at or below a given number of guesses.

tropy, and on entropy of the weakest 2.5%, 5%, and 10%.
The 3class8-d condition is roughly comparable to the
two Telepathwords conditions, except when we consider
minimum entropy, where it does considerably worse.

To substantiate further the impact of using Telepath-
words and dictionary-based approaches, we present in
Table 9 the weakest 2.5% of passwords according to
each metric. For example,
the weakest 2.5% under
3class8 contain such obvious and easily-guessed choices
as Password1 and P@5sword, which compare unfavor-
ably with those in either of the Telepathwords conditions
of 3class8-d.

602  23rd USENIX Security Symposium 

USENIX Association

12

3class12
3class8-d
3class8
basic8
telepath
telepath-v

N Upper
1.7
1.5
1.6
1.0
1.0
1.1

425
402
438
429
420
441

Lower
8.0
6.6
6.6
7.9
7.0
7.0

Digit
3.2
2.6
2.5
2.4
2.5
2.7

Mean characters per class

zxcvbn Entropy

Telepathwords score

Weir+ score
Symbol Min 2.5% 5% 10% Med Min 2.5% 5% 10% Med Min 2.5% 5% 10%
6.4 22.4 27.8 31.5
16.0 26.6 29.4 33.6
0.0 14.4 17.4 24.9
1.0 13.0 17.7 22.4
21.0 26.1 29.3 33.0
19.9 27.4 29.9 33.2

6.8 14.8 17.0 20.4 33.4
11.0 15.6 17.8 22.1 32.7
3.0 11.7 14.1 16.1 29.1
0.0 9.5 12.6 15.4 27.9
9.7 17.9 19.7 22.4 32.0
13.0 18.4 20.4 22.4 32.8

0.9
0.8
0.6
0.4
0.6
0.5

2
1
1
1
5
6

3
3
2
2
6
6

3
3
2
2
6
6

4
3
3
3
6
6

7
6
6
6
7
7

Table 8: Security metrics of passwords created by participants. We show minimum and median zxcvbn and Telepath-
words scores, along with percentiles selected to indicate the vulnerability of each condition to early guessing. We
report Weir+ scores as the log2 of their guess numbers for comparison with entropy scores. We do not show median
Weir+ scores as only basic8 reached 50% cracked in our analysis.

zxcvbn

basic8

password
12345678
P@55w0rd

PASSWORD1234

passwordme

sunshine

Youknow123

brittany
drowssap

Washington1

3class8

3class12

Password8

Password1
P@5sword

Thispassword1
Password@123

3class8-d
1qaz2wsx!
123456789jI
EL1Z@B3TH Qwerty12345@ Zaq12wsx
@bs0lute
A11iance
Beer4y0u
Hawk3y3s
G0dZ1Ll4
My2password MonKeY12345! @SunSh1n3
Shelby1234
Cut13p13

Passwordneeds1
!PaSsWoRd123
StephenASmith1
1NewP@ssword
Chief$123456

Samantha1
Whatever1
Whoi1234

Mypassword1

Asdfghjkl123

telepath

telepath-v

thisisapassword guessmypassw0rd
2014welcome

jim1965
$hrod3
1024scott

mothertrucker

burkeds
pi$$a123
12noraa

c@reful951

Mary3476
altoids123
almay123
the1step!

snoopy1969!

kylemonkey1986
Scr3wdr1v3r123

sion12
lmi2014

1987camaros

Weir+

password
12345678
sunshine
brittany

qwertyuiop
drowssap
trinity1
sugarbaby
deeznuts
monkey69

Password1
Password8
Rainbow3
Robert07
Cougars1
Andrew24
Marcus12
Liverpool15
Bahamut1
Abby1234

1024scott
jim1965
cesar5000
mi1213

Pokemon91
Redtruck1
Nackson1
ZaqXsw12
H1r12345

Asdfghjkl123
Password@123
bulldog*1234
Jp1234567890
Johnny#12345
mothertrucker
Strawberry246 Monkeydude1 thisisapassword
Guadalajara1
imalittleteapot
123Cheetos!!
Abc123456789! Godalmighty1
Qwerty12345@

Plascencia1
Caedus12

awdxsz
chieri

coffeecup123

Yaniku13

Password1

EL1Z@B3TH

Telepathwords
frenchfry
qwertyuiop
password
p09op09o
P@55w0rd

BearBear1
B4sk3r*v1ll3

P@5sword
Robert07
Samantha1

MountainDew1
P00lsidebars
Elephants.19
Password@123
cRAYON123456
PASSWORD1234 Whatever1 MonKeY12345!
Abc123456789!
!PaSsWoRd123 Monkeydude1
Asdfghjkl123
ZaqXsw12
Qwerty12345@ Galvestontx1

Ilove!myself
Zaq12wsx
Cut13p13

Qwaszx12
Monkeys21
Scoobydoo2

Redtruck1
A11iance

R0ckstar!

iamabeliever
feeﬁfofum
motuwethfr

snorelax
broseph
cats59

peacaboo1
almay123
altoids123

jacran1
sion12

Table 9: The weakest 2.5% of passwords as scored by each metric (weakest at top). For the Telepathwords metric,
the weakest passwords in the telepathwords conditions are not shown because there are too many passwords at the
minimum score threshold to present here.

5.4 Limitations
All artiﬁcial experiments have limitations and ours was
no exception. We make note of two such limitations.

Our study used a role-playing scenario to encourage
users to create passwords. Participants playing roles may

choose weaker passwords than they would for an ac-
count they value. They might also choose stronger pass-
words than they would for an account they didn’t value.
Schechter et al. [22] have shown that participants in se-
curity studies behave differently when the laboratory en-

USENIX Association  

23rd USENIX Security Symposium  603

13

vironment frees them from risk, and Fahl et al. [7] have
shown a speciﬁc effect for choice of passwords. While
limiting the interpretations of absolute scores, so long
as these effects impact conditions equally, the method-
ology still facilitates cross-condition comparisons—the
primary focus of the experiment. In fact, if our goal is
to study the ability of technology to help unmotivated
users choose better passwords, having participants who
are less motivated than they would be in real-world con-
ditions may be beneﬁcial.

We measured recall over a short period of two to ﬁve
days in a context where participants entered their pass-
word a few minutes after choosing it.
In contexts in
which users do not re-enter their passwords immediately
after creating them, or in which they do not return for
more than ﬁve days, they may be more likely to forget
them. In contexts where users use their passwords more
frequently after creating them, they may be less likely to
forget them within two to ﬁve days. Had we selected dif-
ferent return periods we might have been more likely to
see differences in recall rates.

6 Related Work

While some security practitioners simply hope that pass-
words, and their associated weaknesses, can be wished
away, Bonneau et al. [3] have argued that passwords are
not going away anytime soon. Password-composition
rules date back at least to 1979, when Morris and Thomp-
son reported on the predictability of the passwords used
by users on their Unix systems; they proposed that pass-
words longer than four characters, or purely alphabetic
passwords longer than ﬁve characters, will be “very safe
indeed” [19]. Bonneau analyzed nearly 70 million pass-
words in 2012, 33 years later, to measure the impact of
a six-character minimum requirement compared with no
requirement [2]. He found that it made almost no differ-
ence in security. In a study of the distribution of pass-
word policies, Florˆencio and Herley found that usability
imperatives appeared to play at least as large a role as
security among the 75 websites examined [8].

Early studies of proactive password-quality veriﬁca-
tion mechanisms includes the work of Spafford [26], who
suggests an efﬁcient method for storing a dictionary for
checking. Bishop et al., in 1995, suggested checking
passwords for dictionary entries, user information, and
other common patterns at password creation [1]. They
also provided some statistics on these patterns in pass-
words. Weir et al. also examined password-composition
rules by looking at samples of passwords [29]. These
works did not look at passwords created under varying
rules, however.

Microsoft Windows

password-
composition rules at least as far back as 2000, with

enforced

has

the default requiring at least 8 characters from three
of four character classes: uppercase, lowercase, digits,
and others [17, 18]. One problem with the Windows
implementation is that when Windows rejects a user’s
proposed password, it does not provide a list of the rules
being enforced or identify speciﬁcally which rules the
password is violating.

Many websites offer password meters that provide
feedback on the strength of passwords as users type
them. Based on a survey of the top 100 websites in 2012,
most password meters use simple password-composition
rules such as length and number of non-lowercase char-
acters to determine when a password is good enough to
reach the next level on the meter [28]. Egelman et al. [6]
examined whether the presence of a password meter
made any appreciable difference in password strength.
They found that the meter made a difference when users
were changing their password for an existing impor-
tant account; but the meter had little effect when users
were registering a new password for a low-importance
account. Ur et al. also studied the effect of password-
strength meters on password-creation. They found that
when users became frustrated and lost conﬁdence in the
meter, more weak passwords appeared [28]. Very re-
cently, de Carn´e de Carnavalet and Mannan [4] examined
several password meters in use at popular websites and
found gross inconsistencies, with the same password reg-
istering very different strength across different meters.
Collectively, these ﬁndings are in line with our concern
that password policies and meters may harm credibility
and lead users to put less effort into choosing a good
password.

One exception to the reliance on composition rules in
password meters is zxcvbn, an open-source meter devel-
oped and used by DropBox, which uses a small language
corpus to calculate entropy estimates in real time [30].
Designed to run entirely in the users’ browser, it is writ-
ten in JavaScript and compresses down to 320KB. While
zxcvbn provides a much-needed improvement in the
credibility of its strength estimates when compared to ap-
proaches relying solely on composition rules, this cred-
ibility is unlikely to be observed by users.
In fact, its
perceived credibility may suffer if users, who have been
told that adding characters increases password strength,
see scores decrease when certain characters are added.
For example, when typing iatemylunch, the strength
estimate decreases from the second-best score (3) to the
worst score (1) when the ﬁnal character is added. Even if
users ﬁnd zxcvbn’s strength estimates credible, they are
unlikely to understand the underlying entropy-estimation
mechanism and thus be unsure how to improve their
scores. The advice zxcvbn offers, such as using inside
jokes and unusual use of uppercase, could potentially

604  23rd USENIX Security Symposium 

USENIX Association

14

lead users to cluster around common strategies, yielding
a set of new common passwords for attackers to guess.

words were slightly weaker than the genuine passwords,
they were similar in many other respects.

Schechter et al. [21] offered another alternative to
password-composition rules, suggesting a system that
prevents users from choosing passwords popular among
a large set of users. Another approach that seeks to limit
dangerously common passwords was proposed by Mal-
one and Maher [14]. These approaches, however, are
most appropriate for systems with tens of millions of
users, in which uniqueness is a strong indicator that a
password is hard to guess. Relatively weak passwords
may be unique among hundreds or thousands of user ac-
counts.

The human-subjects experiment we perform in this
work seeks to replicate the methodology used in prior
password studies. Many of our choices in recruiting,
question design, and the timing of the invitation to part
two of the study reﬂect a desire to facilitate comparison
with prior work. This includes the work of Komanduri et
al. [13] and Kelley et al. [12], who used similar study
designs to perform comparative analyses of password-
composition rules. These prior studies found that in-
creasing length requirements in passwords generally led
to more usable passwords that were also less likely to be
identiﬁed as weak by their guessing algorithm [13, 12].
Most recently, Shay et al. studied password-composition
policies requiring longer passwords, ﬁnding the best per-
formance came from mixing a 12-character minimum
with a requirement of three character sets [25]. One key
difference between our work and most prior studies is
that all of our treatments provided feedback to users as
they typed their passwords. With the exception of Ur
et al.’s examination of meters providing optional guid-
ance [28], all of these prior studies from Carnegie Mellon
required participants to submit passwords before testing
for, or providing feedback on, compliance with a policy.
A valuable use case for Telepathwords-based policies,
which do not place any character-set requirements on
passwords, is the affordance of creating all-lowercase
passwords for easy entry on a touch screen.
Jakobs-
son and Akavipat proposed a scheme for mobile devices
that uses easily-typed passwords with auto-completion
for easier password entry [11].

Fahl et al. [7] pointed out limitations in studies that
use role-playing to generate passwords, as we do in this
study. They ﬁnd signiﬁcant differences between pass-
words generated in these scenarios and real passwords.
Komanduri et al. found that users created stronger pass-
words when asked to role-play, compared to when asked
simply to create a password for a study [13]. Mazurek et
al. used a methodology similar to ours and compared
their results to genuine user passwords in a univer-
sity [15]. They found that while the experimental pass-

7 Conclusion

Telepathwords provides users with signiﬁcantly more in-
sight into the quality of their passwords than all other
approaches, and results in passwords stronger than ap-
proaches that do not use dictionaries. For example, the
metrics suggest that to crack 1% of Telepathwords pass-
words, an attacker needs to make more than a factor of a
thousand more guesses per password than for passwords
created under the default password policy employed by
Microsoft Windows Active Directory. While a higher
number of users found password creation difﬁcult or an-
noying using the tool, the security improvements did not
come at any measurable impact to memorability.

References
[1] BISHOP, M., AND V KLEIN, D.

Improving system security
via proactive password checking. Computers & Security 14, 3
(1995), 233–249.

[2] BONNEAU, J. The science of guessing: analyzing an anonymized
In 2012 IEEE Symposium on

corpus of 70 million passwords.
Security and Privacy (May 2012).

[3] BONNEAU, J., HERLEY, C., VAN OORSCHOT, P. C., AND STA-
JANO, F. The Quest to Replace Passwords: A Framework for
Comparative Evaluation of Web Authentication Schemes.
In
2012 IEEE Symposium on Security and Privacy (May 2012).

[4] DE CARNAVALET, X. D. C., AND MANNAN, M. From very
weak to very strong: Analyzing password-strength meters.
In
Network and Distributed System Security Symposium (NDSS14)
(2013).

[5] DESIGNER, S. Openwall project free wordlist.

http://

download.openwall.net/pub/wordlists/all.gz.

[6] EGELMAN, S., SOTIRAKOPOULOS, A., MUSLUKHOV,

I.,
BEZNOSOV, K., AND HERLEY, C. Does my password go up
to eleven?: the impact of password meters on password selection.
In Proceedings of the SIGCHI Conference on Human Factors in
Computing Systems (2013), ACM, pp. 2379–2388.

[7] FAHL, S., HARBACH, M., ACAR, Y., AND SMITH, M. On the
ecological validity of a password study.
In Proceedings of the
Ninth Symposium on Usable Privacy and Security (2013), ACM,
p. 13.

[8] FLOR ˆENCIO, D., AND HERLEY, C. Where Do Security Policies

Come From? Proc. SOUPS (2010).

[9] How

secure

is

my

password.

howsecureismypassword.net/.

https://

[10] HSU, B., AND OTTAVIANO, G. Space-efﬁcient data structures
In 22nd International World Wide Web

for top-k completion.
Conferences (May 13–17 2013).

[11] JAKOBSSON, M., AND AKAVIPAT, R. Rethinking passwords to

adapt to constrained keyboards.

[12] KELLEY, P. G., KOMANDURI, S., MAZUREK, M. L., SHAY,
R., VIDAS, T., BAUER, L., CHRISTIN, N., CRANOR, L. F.,
AND L ´OPEZ, J. Guess again (and again and again): Measuring
password strength by simulating password-cracking algorithms.
IEEE Symposium on Security and Privacy 0 (2012), 523–537.

USENIX Association  

23rd USENIX Security Symposium  605

15

[30] WHEELER, D. zxcvbn: realistic password strength estimation.
Dropbox Tech Blog. https://tech.dropbox.com/2012/04/
zxcvbn-realistic-password-strength-estimation/,
Apr. 2004.

[13] KOMANDURI, S., SHAY, R., KELLEY, P. G., MAZUREK, M. L.,
BAUER, L., CHRISTIN, N., CRANOR, L. F., AND EGELMAN,
S. Of passwords and people: measuring the effect of password-
composition policies. In Proceedings of the SIGCHI Conference
on Human Factors in Computing Systems (New York, NY, USA,
2011), CHI ’11, ACM, pp. 2595–2604.

[14] MALONE, D., AND MAHER, K. Investigating the distribution of

password choices. In Proc. WWW (2012).

[15] MAZUREK, M. L., KOMANDURI, S., VIDAS, T., BAUER, L.,
CHRISTIN, N., CRANOR, L. F., KELLEY, P. G., SHAY, R., AND
UR, B. Measuring password guessability for an entire university.
In Proceedings of the 2013 ACM SIGSAC conference on Com-
puter & communications security (2013), ACM, pp. 173–186.

[16] MICROSOFT CORPORATION.

Check your passwordis it
https://www.microsoft.com/en-gb/security/

strong?
pc-security/password-checker.aspx.

[17] MICROSOFT CORPORATION. TechNet Conﬁguring Password
Policies. Microsoft TechNet. http://msdn.microsoft.com/
en-us/library/cc236715.aspx.

[18] MICROSOFT CORPORATION. Windows NT 4.0 Domain
Microsoft TechNet.

Controller Conﬁguration Checklist.
http://technet.microsoft.com/en-us/library/
cc722923.aspx.

[19] MORRIS, R., AND THOMPSON, K. Password security: A case
history. Communications of the ACM 22, 11 (1979), 594—597.

[20] The password meter. http://www.passwordmeter.com/.
[21] SCHECHTER, S., HERLEY, C., AND MITZENMACHER, M. Pop-
ularity is everything: A new approach to protecting passwords
from statistical-guessing attacks. In The 5th USENIX Workshop
on Hot Topics in Security (HotSec) (Aug. 10 2010).

[22] SCHECHTER, S. E., DHAMIJA, R., OZMENT, A., AND FIS-
CHER, I. The emperors new security indicators: An evaluation
of website authentication and the effect of role playing on usabil-
ity studies. In In Proceedings of the 2007 IEEE Symposium on
Security and Privacy (May 2007).

[23] SCHNEIER, B., AND KELSEY, J. Secure audit logs to support
computer forensics. ACM Transactions on Information and Sys-
tem Security 2 (1999), 159–176.

[24] SHAY, R., KELLEY, P. G., KOMANDURI, S., MAZUREK, M. L.,
UR, B., VIDAS, T., BAUER, L., CHRISTIN, N., AND CRANOR,
L. F. Correct horse battery staple: exploring the usability of
system-assigned passphrases. In Proceedings of the Eighth Sym-
posium on Usable Privacy and Security (New York, NY, USA,
2012), SOUPS ’12, ACM, pp. 7:1–7:20.

[25] SHAY, R., KOMANDURI, S., DURITY, A. L., HUH, P. S.,
MAZUREK, M. L., SEGRETI, S. M., UR, B., BAUER, L.,
CHRISTIN, N., AND CRANOR, L. F. Can long passwords be
secure and usable? In CHI (2014).

[26] SPAFFORD, E. H. OPUS: Preventing weak password choices.

Computers & Security 11, 3 (1992), 273–278.

[27] STARK, E., HAMBURG, M., AND BONEH, D. Symmetric Cryp-
In Annual Computer Security Applica-

tography in Javascript.
tions Conference (2009), pp. 373–381.

[28] UR, B., KELLEY, P. G., KOMANDURI, S., LEE, J., MAASS,
M., MAZUREK, M. L., PASSARO, T., SHAY, R., VIDAS, T.,
BAUER, L., CHRISTIN, N., AND CRANOR, L. F. How does your
password measure up? the effect of strength meters on password
creation. In Proceedings of the 21st USENIX Security Symposium
(Aug. 8–10 2012).

[29] WEIR, M., AGGARWAL, S., COLLINS, M., AND STERN, H.
Testing metrics for password creation policies by attacking large
sets of revealed passwords. In Proceedings of the 17th ACM con-
ference on Computer and communications security (New York,
NY, USA, 2010), CCS ’10, ACM, pp. 162–175.

606  23rd USENIX Security Symposium 

USENIX Association

16

