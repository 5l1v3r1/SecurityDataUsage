Detection of Malicious PDF Files Based on Hierarchical Document Structure

Nedim ˇSrndi´c and Pavel Laskov
Department of Cognitive Systems

University of T¨ubingen

T¨ubingen, Germany

{nedim.srndic, pavel.laskov}@uni-tuebingen.de

Abstract

Malicious PDF ﬁles remain a real threat, in practice, to
masses of computer users, even after several high-proﬁle
security incidents. In spite of a series of a security patches
issued by Adobe and other vendors, many users still have
vulnerable client software installed on their computers. The
expressiveness of the PDF format, furthermore, enables at-
tackers to evade detection with little effort. Apart from tra-
ditional antivirus products, which are always a step behind
attackers, few methods are known that can be deployed for
protection of end-user systems. In this paper, we propose a
highly performant static method for detection of malicious
PDF documents which, instead of analyzing JavaScript or
any other content, makes use of essential differences in the
structural properties of malicious and benign PDF ﬁles. We
demonstrate its effectiveness on a data corpus containing
about 660,000 real-world malicious and benign PDF ﬁles,
both in laboratory conditions and during a 10-week opera-
tional deployment with weekly retraining. Additionally, we
present the ﬁrst comparative evaluation of several learning
setups with regard to resistance against adversarial evasion
and show that our method is reasonably resistant to sophis-
ticated attack scenarios.

1

Introduction

Despite the recent improvements in security of the PDF
rendering software, PDF documents remain a popular at-
tack vector “for the masses”. Several large-scale attacks
have been recently reported using known PDF vulnerabil-
ities [35, 15, 29]. These attacks demonstrate a surprising
effectiveness of rather outdated attack vectors in the com-
munity of ordinary computer users. Additionally, several
novel vulnerabilities in the Adobe Reader application have
been discovered recently [13].

The existing defense mechanisms against PDF-based at-
tacks suitable for wide-scale deployment are still inadequate

for the expressive power, and hence the evasive capability
of PDF malware. Even though the majority of modern an-
tivirus products support detection of PDF-speciﬁc attacks,
the detection techniques are still based on signatures and
rigid heuristics. Hence they cannot quickly adapt to novel
attack vectors even if the latter constitute only minor modi-
ﬁcations of existing exploits.

Recent research on the detection of malicious PDF doc-
uments has been surprisingly sparse. Some early, format-
agnostic approaches for detection of malicious ﬁle content
used machine learning methods combined with byte-level
n-gram analysis [21, 32]. These methods are also appli-
cable to detection of PDF-based attacks. However, since
they were developed even before the pandemic spread of
PDF malware in 2009, they could not be evaluated on large
corpora of modern malicious PDF documents. The ma-
jority of recent detection methods are based on dynamic
analysis. Among the most popular systems of this kind
are WEPAWET1 using the sandbox JSAND [9], MALOF-
FICE [11] adapted from CWSANDBOX [38], and SHELLOS
[34].
In general, dynamic analysis introduces signiﬁcant
overhead and latency, since it inherently depends on the
execution of malicious code. This has motivated methods
based on static analysis [19] as well as the combination of
static and dynamic analysis [37]. Both of these methods
are focused on detection of malicious JavaScript content in
PDF documents, which relates them to a large body of work
on detection of drive-by-downloads; e.g., [27, 31, 10, 6].

In contrast to prior work, the method we present in this
article is intended for static detection of malicious PDF doc-
uments without a special consideration for JavaScript con-
tent. Although the vast majority of PDF-based exploits do
rely on JavaScript, there exist two major technical chal-
lenges that make JavaScript-based detection especially dif-
ﬁcult. The ﬁrst challenge is to locate JavaScript content in
a PDF ﬁle. JavaScript may be hidden deep within the logi-
cal structure of a PDF document, even beyond the locations

1http://wepawet.iseclab.org/

designated in the PDF Standard [25]. Any textual content
in a PDF document can be interpreted as JavaScript using
the eval() function or its equivalents. Hence, nothing
prevents an attacker from distributing chunks of JavaScript
code anywhere in the text and assembling them together at
runtime. The second challenge lies in the high-degree ex-
pressiveness in the JavaScript language, which provides at-
tackers with a powerful platform for code obfuscation. Al-
though some methods have been recently proposed for de-
tecting of obfuscated JavaScript [17], their practical utility
remains unclear.

As an alternative to JavaScript-based detection, we pro-
pose analyzing the structural properties of PDF documents
to discriminate between malicious and benign ﬁles. Instead
of looking for the speciﬁc malicious content, our method
evaluates documents on the basis of side-effects from mali-
cious content within their structure. This approach is based
on the intuition that, due to the complexity of the PDF for-
mat, the logical structure of PDF ﬁles conveys a signiﬁcant
amount of the documents’ semantics. Hence, we postulate
that a comprehensive analysis of structural properties would
reveal a salient structural difference between malicious and
benign PDF documents. In our main contribution, we pro-
pose a novel representation for the structure of PDF docu-
ments, denoted as structural paths, which can be used as
features for automatic processing by various data analysis
methods.

Extraction of structural paths can be efﬁciently carried
out using existing PDF parsers. Parsing the structure of
a document is an order of magnitude less complex than
the interpretation and rendering of its content. Even if the
parser itself may be vulnerable, its attack surface is much
narrower than that of an underlying rendering application.
As the vast majority of PDF-related vulnerabilities are re-
lated to JavaScript, the probability of an attack against the
parser is negligible since parsing is naturally decoupled
from JavaScript interpretation. The proposed methodology
for feature extraction can be deployed with any parser. This
reduces the opportunity for evasion techniques exploiting
the ambiguities in ﬁle processing [16]. Due to its efﬁciency,
the proposed method can be used as a light-weight built-
in detector within the respective PDF renderer, thus com-
pletely avoiding the parser’s ambiguity.

The effectiveness of the proposed method is demon-
strated on the largest-ever data corpus hitherto used in eval-
uation of document malware detectors. We have collected
over 570,000 malicious and benign PDF documents from
the popular malware portal VIRUSTOTAL and augmented
this dataset with a realistic sample of 90,000 benign PDF
documents indexed by Google. Our laboratory experiments
show that the proposed method attains the detection rate
of 99.88% at the false positive rate of 0.0001% on the mali-
cious VIRUSTOTAL and benign Google data, more than any

commercial antivirus operating at VIRUSTOTAL. The same
accuracy at the false positive rate of 0.0003% was observed
with benign VIRUSTOTAL data which is obviously skewed
towards being suspicious. In a 10-week operational deploy-
ment with weekly retraining on 440,000 malicious and be-
nign PDF ﬁles, the proposed method consistently outper-
formed the best antivirus engine deployed at VIRUSTOTAL2
in 7 weeks, scoring even in 1 week and losing in the re-
maining 2 weeks, due to bursts of novel data. These results
demonstrate an excellent detection power of the proposed
structural path features, at least for the current PDF mal-
ware observed in the real world.

Can the situation change if attackers attempt to evade
our method? Despite the fact that it is content-agnostic, the
proposed method is not trivial to evade. The main difﬁculty
for the attacker lies, again, in the complexity of the PDF
format. Even if the attacker knows which features are re-
sponsible for successful detection, he cannot easily remove
them, as this may break the attack functionality. Further,
addition of benign content, which is always an option for
the attacker, may not always lead to a successful evasion.
We have experimentally evaluated several potential feature
addition attacks and observed that some classiﬁcation algo-
rithms deployed in our system are remarkably robust against
this kind of attacks (less that 0.025% success rate).

In summary, the paper offers the following contributions:

1. A novel set of features is deﬁned which enable one
to effectively capture the structural difference between
benign and malicious PDF ﬁles.

2. Using the proposed structural features, a classiﬁer
of PDF documents is presented whose detection ac-
curacy, estimated on about 220,000 PDF documents
under laboratory conditions, surpasses the accuracy
of 43 antivirus engines deployed at VIRUSTOTAL at
the time.

3. A 10-week operational deployment of the classiﬁer
with weekly retraining on 440,000 malicious and be-
nign PDF ﬁles demonstrated the practical applicability
of the proposed method under real-world conditions.

4. The new classiﬁer does not rely on the analysis of
JavaScript code and hence is not affected from poten-
tial novel techniques for hiding JavaScript in PDF doc-
uments.

5. The throughput of the classiﬁer is evaluated and shown
to be comparable to state-of-the-art static detection
techniques.

6. The robustness of the proposed method against a num-

ber of evasion techniques is experimentally veriﬁed.

2It should be noted that only command-line versions of antivirus en-

gines are deployed at VIRUSTOTAL.

Presentation of our methods begins with the review of re-
lated work in Section 2, which provides the motivation for
the new kind of features and detection techniques investi-
gated in the paper. The details of the PDF format necessary
for understanding of technical aspects of our method are
summarized in Section 3. The system architecture and the
deployed algorithms are presented in Section 4. Our data
corpora, the results of experiments aimed at evaluation of
the detection accuracy, and the throughput of our system
are reported in Section 5. Potential evasion techniques are
analyzed and experimentally veriﬁed in Section 6. We end
up with the discussion of our ﬁndings in Section 7 and con-
clusions in Section 8.

2 Related Work

Previous work on the detection of document malware
shares many common ideas with the methods for detecting
drive-by-downloads. This is not surprising, since the ex-
ploitation techniques underlying both kinds of malware are
the same. Existing methods can be classiﬁed, with some
degree of overlap, into dynamic analysis methods, in which
documents are opened in a specially instrumented environ-
ment, and static methods, in which detection is carried out
without malware execution.

Several key ideas have fueled the development of
dynamic analysis methods.
Early work followed the
emulation-based approach in which a suspicious payload
was executed using abstract payload execution [36] or soft-
ware emulation [1, 26]. However, software emulation does
not have full coverage of the instruction set and hence can
be detected and evaded. To overcome this problem and im-
prove scalability, the recently proposed system SHELLOS
uses hardware virtualization instead of emulation for con-
trolled execution of shellcode [34].
Implemented as an
operating system kernel, SHELLOS is able to effectively
detect shellcode in any buffer allocated by an application.
However, this effectiveness has its price. While SHELLOS
performs with outstanding bandwidth in detecting network-
level attacks, its application to document malware suffers
from high latency (on the order of seconds). Such latency
is due to the fact that detection is carried out at the level of
memory buffers which must be allocated by an application
before they can be analyzed.

Another group of dynamic analysis methods has fo-
cused on detection of malicious behavior during execution
of JavaScript. JSAND uses 10 carefully designed heuristic
features to train models of benign JavaScript and detect at-
tacks as large deviations from these models [9]. A similar
approach has been successfully applied for detection of Ac-
tionScript 3 malware [24]. CUJO is built on top of a special-
ized JavaScript sandbox and automatically learns models of
sequences of events affecting the state of the JavaScript in-

terpreter [31]. JavaScript-speciﬁc dynamic analysis meth-
ods improve on the performance of the methods focused on
shellcode detection, bringing it in the range of hundreds of
milliseconds per ﬁle, while maintaining high detection ac-
curacy and an extremely low false positive rate.

Early static methods based on n-gram analysis [21, 32]
have never been evaluated on modern PDF malware. Since
they do not address some essential properties of the PDF
format, such as encoding, compression and encryption, they
can be easily evaded by modern PDF malware using tech-
niques similar to those used against conventional signature-
based antivirus systems. PJSCAN was the ﬁrst method that
demonstrated feasibility of anomaly-based static detection
of PDF malware focused on JavaScript content [19]. For
the sake of efﬁciency, the JavaScript extractor of PJSCAN
only searches for locations where the presence of JavaScript
is prescribed by the PDF Standard. Unfortunately, this ex-
traction strategy can be defeated by placing JavaScript code
into an arbitrary location accessible via the PDF JavaScript
API and fetching it with an eval()-like function call. An-
other recently proposed system, MALWARE SLAYER [23],
is based on the pattern recognition methods applied to tex-
tual keywords extracted from PDF documents using the
PDFID tool. It exhibits excellent detection and false alarm
rates on real PDF data but is limited to the extraction func-
tionality of PDFID and can handle neither multiple revision
numbers nor objects hidden in object streams. PDFRATE
is a recent learning-based, static PDF classiﬁer operating
on simple PDF metadata and byte-level ﬁle structure evalu-
ated on a large dataset of PDF ﬁles with excellent classiﬁca-
tion performance [33]. However, it does not extract object
streams, a feature that could be used to hide features from
the detector.

Another two contributions must be mentioned that com-
bine static and dynamic analysis techniques. MDSCAN
[37] employs static analysis of the PDF ﬁle in order to
extract all chunks of JavaScript code that can serve as an
entry point to the JavaScript execution. To this end, a
special-purpose parser was developed for MDSCAN, which
attempts to extract additional information from a ﬁle includ-
ing objects omitted from a cross-reference table as well as
potentially malformed objects. The extracted scripts are ex-
ecuted in a JavaScript engine which emulates the engine of
Acrobat Reader. During the controlled execution, all mem-
ory buffers are checked using a tool for shellcode detection
based on binary emulation (NEMU). In ZOZZLE [10], the
roles of the static and the dynamic components are reversed.
The dynamic part of ZOZZLE extracts parts of JavaScript
from the JavaScript engine of Internet Explorer before their
execution, which naturally unfolds JavaScript obfuscation.
The static part of ZOZZLE uses Bayesian classiﬁcation built
on top of the syntactic analysis of detected JavaScript code.
The comparison of related work shows a clear trade-

off exhibited in the up-to-date static and dynamic systems
for document malware detection. While dynamic systems
demonstrate excellent detection accuracy and low false pos-
itive rates, these advantage come at the cost of latency, per-
formance overhead and the need for specially instrumented
environments. The new method proposed in the paper at-
tempts to bridge this gap from the static side, by boosting
the detection performance while retaining the simplicity of
design and computational efﬁciency typical for static meth-
ods. To achieve this goal, we develop the methodology for
a comprehensive static analysis of PDF documents using an
off-the-shelf PDF parser (POPPLER). Furthermore, we pay
a special attention to potential evasion strategies and exper-
imentally evaluate the robustness of the proposed method to
selected attack strategies.

Before presenting the design and the evaluation of our
system, we review the main features of the PDF format and
document structure which are relevant for understanding the
technical aspects of our method.

3 The PDF Document Structure

Portable Document Format (PDF) is an open standard
published as ISO 32000-1:2008 [25] and referred to as the
PDF Reference hereinafter.

The syntax of PDF comprises the four main elements:

• Objects. These are the basic building blocks in PDF.

• File structure. It speciﬁes how objects are laid out and

modiﬁed in a PDF ﬁle.

• Document structure. It determines how objects are
logically organized to represent the contents of a PDF
ﬁle (text, graphics, etc.).

• Content streams. They provide a means for efﬁcient

storage of various parts of the document content.

There are 9 basic object types in PDF. Simple object
types are Boolean, Numeric, String and Null. PDF strings
have bounded length and are enclosed in parentheses ’(’ and
’)’. The type Name is used as an identiﬁer in the descrip-
tion of the PDF document structure. Names are introduced
using the character ‘/’ and can contain arbitrary characters
except null (0x00). The aforementioned 5 object types will
be referred to as primitive types in this paper. An Array
is a one-dimensional ordered collection of PDF objects en-
closed in square brackets, ‘[’ and ‘]’. Arrays may contain
PDF objects of different type, including nested arrays. A
Dictionary is an unordered set of key-value pairs enclosed
between the symbols ‘<<’ and ‘>>’. The keys must be
name objects and must be unique within a dictionary. The
values may be of any PDF object type, including nested dic-
tionaries. A Stream object is a PDF dictionary followed by

a sequence of bytes. The bytes represent information that
may be compressed or encrypted, and the associated dictio-
nary contains information on whether and how to decode
the bytes. These bytes usually contain content to be ren-
dered, but may also contain a set of other objects3. Finally,
an Indirect object is any of the previously deﬁned objects
supplied with a unique object identiﬁer and enclosed in the
keywords obj and endobj. Due to their unique identi-
ﬁers, indirect objects can be referenced from other objects
via indirect references.

The syntax of PDF objects is illustrated in a simpliﬁed
exemplary PDF ﬁle shown in the left-hand side of Fig-
ure 1.
It contains four indirect objects denoted by their
two-part object identiﬁers, e.g., 1 0 for the ﬁrst object, and
the obj and endobj keywords. These objects are dictio-
naries, as they are surrounded with the symbols ‘<<’ and
‘>>’. The ﬁrst one is the Catalog dictionary, denoted by
its Type entry which contains a PDF name with the value
Catalog. The Catalog has 2 additional dictionary entries:
Pages and OpenAction. OpenAction is an example of a
nested dictionary.
It has two entries: S, a PDF name in-
dicating that this is a JavaScript action dictionary, and JS, a
PDF string containing the actual JavaScript script to be ex-
ecuted: alert(’Hello!’);. Pages is an indirect refer-
ence to the object with the object identiﬁer 3 0: the Pages
dictionary that immediately follows the Catalog. It has an
integer, Count, indicating that there are 2 pages in the docu-
ment, and an array Kids identiﬁable by the square brackets,
with two references to Page objects. The same object types
are used to build the remaining Page objects. Notice that
each of the Page objects contains a backward reference to
the Pages object in their Parent entry. Altogether, there are
three references pointing to the same indirect object, 3 0,
the Pages object.

The relations between various basic objects constitute
the logical, tree-like document structure of a PDF ﬁle, il-
lustrated in the middle part of Figure 1. The nodes in the
document structure are objects themselves, and the edges
correspond to the names under which child objects reside
in a parent object. For arrays, the parent-child relationship
is nameless and corresponds to an integer index of individ-
ual elements. Notice that the document structure is, strictly
speaking, not a tree but rather a directed, potentially cyclic
graph, as indirect references may point to other objects any-
where in the document structure. The root node in the doc-
ument structure is a special PDF dictionary with the manda-
tory Type entry containing the name Catalog. Any object of
a primitive type constitutes a leaf in the document structure.
The following list shows exemplary structural paths from

real-world benign PDF ﬁles:

3This feature has been originally intended for storing collections of
small objects in a compressed form. However, it has become a popular
tool for obfuscation of the document structure by attackers.

Figure 1. Various representations of the PDF structure: physical layout (left), logical structure (mid-
dle) and a set of structural paths (right)

/Metadata
/Type
/Pages/Kids
/OpenAction/Contents
/StructTreeRoot/RoleMap
/Pages/Kids/Contents/Length
/OpenAction/D/Resources/ProcSet
/OpenAction/D
/Pages/Count
/PageLayout

...

It was learned in experiments presented in Section 5.3.5 that
these are the structural paths whose presence in a ﬁle is most
indicative that the ﬁle is benign, or, alternatively, whose ab-
sence indicates that a ﬁle is malicious. For example, ma-
licious ﬁles are not likely to contain metadata in order to
minimize ﬁle size, they do not jump to a page in the docu-
ment when it is opened and are not well-formed so they are
missing paths such as /Type and /Pages/Count.

The following is a list of structural paths from real-world

malicious PDF ﬁles, learned in the same experiment:

/AcroForm/XFA
/Names/JavaScript
/Names/EmbeddedFiles
/Names/JavaScript/Names
/Pages/Kids/Type
/StructTreeRoot

/OpenAction/Type
/OpenAction/S
/OpenAction/JS
/OpenAction

...

We see that malicious ﬁles tend to execute JavaScript stored
within multiple different locations upon opening the doc-
ument, and make use of Adobe XML Forms Architecture
(XFA) forms as malicious code can also be launched from
there.

In the following section, we present the general method-
ology and the technical instruments needed for the analysis
of the document structure leading to a reliable discrimina-
tion between malicious and benign PDF documents.

4 System Design

The proposed method for structure-based detection of
malicious PDF documents comprises the following two
steps, schematically shown in Figure 2:

1. Extraction of structural features. As the basic pre-
processing step, the content of a PDF document is
parsed and converted into the special form, bag-of-
paths, which characterizes the document structure in
a well-deﬁned way.

2. Learning and classiﬁcation. The detection process is
driven by examples of malicious and benign PDF doc-

leads to different leaf objects. Empirical evidence indicates
that the counts of speciﬁc paths in a document constitute a
good measure of structural similarity between different doc-
uments. This motivates the choice of the set of structural
paths as the intrinsic features of our system.

Due to the widespread use of indirect references in PDF
documents, multiple structural paths may lead to the same
object. Indirect references may even form circular depen-
dencies, in which case the set of structural paths becomes
inﬁnite.
In some semantic constructs of PDF, e.g., page
trees, multiple paths are required in order to facilitate con-
tent rendering. Precise treatment of indirect references is
only possible with directed graphs. Since the comparison
of graphs is computationally difﬁcult, we adhere to the tree-
like view of the document structure and introduce additional
heuristics in the following section which produce a ﬁnite set
of structural paths while maintaining a reasonable semantic
approximation of the existing relations.

Thus, the main operation to be performed in our feature
extraction step is counting of the structural paths in a docu-
ment. Additional transformations, to be referred to as “em-
beddings”, can be applied to the path counts. The binary
embedding detects the presence of non-zero counts, the fre-
quency embedding divides the counts over the total number
of paths in a document, and the count embedding refers to
the path count itself. All three embeddings were experimen-
tally evaluated and the binary one was chosen over the other
two for its slightly better detection performance.

4.2 Extraction of PDF Document Structure

Extraction of the structural features deﬁned in Sec-

tion 4.1 must meet the following requirements:

R1: All paths must be extracted with their exact counts.

R2: The algorithm must be repeatable and robust, i.e., it
must produce the same set of paths for PDF ﬁles with
the same logical structure.

R3: The choice among multiple paths to a given object
should be semantically the most meaningful one with
respect to the PDF Reference [25].

As a ﬁrst step in the extraction process, the document is
parsed using the PDF parser POPPLER5. The key advan-
tages of POPPLER are its robust treatment of various encod-
ings used in PDF and the reliable extraction of objects from
compressed streams.
In principle, any other robust PDF
parser would be suitable for extraction of structural paths,
and our choice of POPPLER was only motivated by its free
availability and ease of installation. The parser maintains

5http://poppler.freedesktop.org/, v.0.14.3.

Figure 2. System architecture

uments. During the learning step, a model is created
from the data with known labels (“training data”). The
model encodes the differences between the malicious
and benign data. During the classiﬁcation step, the
model is applied to new data (“test data”), to classify it
as malicious or benign.

The technical realization of these two fundamental tasks is
presented below.

4.1 Feature Deﬁnition

A common approach to the design of data-driven secu-
rity instruments is to manually deﬁne a set of “intrinsic fea-
tures” which are subsequently used for learning and clas-
siﬁcation.
It was successfully applied for network intru-
sion detection [20, 22], botnet detection [12], detection of
drive-by-downloads [9, 10, 6], and other related problems.
The challenge in deﬁning features for detection of malicious
PDF documents lies in the complex structure of the PDF
format. We therefore depart from the knowledge-driven
strategy mentioned above and consider a richer set of poten-
tial features that capture PDFs’ complexity. These features
will be later automatically reduced to a smaller subset based
on the available data.

The ultimate goal of the structural analysis of PDF doc-
uments is to recover all parent-child relations between its
objects. The tree-like structure of PDF documents can be
represented by a set of paths from the root to leaves, as
shown in the rightmost part of Figure 1. Formally, we de-
ﬁne a structural path to be a concatenation of the names
encountered along the edges leading to a speciﬁc leaf. For
notational convenience, we will use the forward slash sym-
bol ’/’ as a delimiter between the names on a structural
path4. The same structural path may occur multiple times
in a document if the same path crosses some arrays and

4Technically, null is the only character that is not allowed in a PDF

name and hence, the only suitable delimiter in a structural path.

an internal representation of the document and provides ac-
cess to all ﬁelds of individual objects. Conceptually, path
extraction amounts to a recursive enumeration of leafs in
the document structure, starting from the Catalog object re-
turned by the parser. The extracted paths are inserted into a
suitable data structure, e.g., a hash table or a map, to accu-
mulate the counts of structural paths.

Several reﬁnements must be introduced to this general
algorithm to ensure that it terminates and that the above re-
quirements are met.

The requirement R1 is naturally satisﬁed by the recur-
sive nature of our feature extraction. Since our recursion
terminates only if a leaf node is encountered, the algorithm
is guaranteed to never underestimate the count of a partic-
ular path. To prevent an overestimation of the path count
due to multiple paths as well as an inﬁnite recursion due to
circular references, the requirement R3 must be enforced.

The enforcement of requirements R2 and R3 is tightly
coupled and ultimately relies on the intelligent treatment
of indirect references. Obviously, one cannot always de-
reference them, as this may result in an inﬁnite recursion.
One cannot also avoid their de-referencing, as the algorithm
would hardly ever move beyond the root node. Hence, a
consistent strategy for selective de-referencing must be im-
plemented.

In our extraction algorithm, we approach these issues by
maintaining a breadth-ﬁrst search (BFS) order in the enu-
meration of leaf objects. This strategy assumes that the
shortest path to a given leaf is semantically the most mean-
ingful. For example, this observation intuitively holds for
various cases when circular relations arise from explicit up-
ward references by means of the Parent entry in a dictio-
nary, as demonstrated by our example in Figure 1. Although
we do not have further evidence to support this observation,
in our experience the BFS traversal always produced mean-
ingful paths.

Two further technical details are essential for the imple-
mentation of the BFS traversal. It is important to keep track
of all objects visited at least once during the traversal and
backtrack whenever an object is visited more than once. It
is also necessary to sort all entries in a dictionary in some
ﬁxed order before descending to the node’s children. Since
no speciﬁc ordering of dictionary ﬁelds is required by the
PDF Reference, such ordering must be artiﬁcially enforced
in order to satisfy the requirement R2.

4.3 Learning and Classiﬁcation

Once the counts or other embeddings over the set of
structural paths are extracted, almost any learning algorithm
can be applied to create a model from the given training
data and use this model to classify unknown examples. For
an overview of suitable algorithms, the reader may refer to

any standard textbook on machine learning, e.g., [4, 14],
or use any entry-level machine learning toolbox, such as
SHOGUN6 or WEKA7. It is beyond the scope of this pa-
per to provide a comprehensive experimental evidence as to
which machine learning method is most suitable for detec-
tion of malicious PDF documents using the structural paths.
We have chosen two speciﬁc algorithms, decision trees and
Support Vector Machines, for subjective reasons presented
in the following section along with a high-level description
of the respective method.

Although both of the chosen methods are, in principle,
suitable for high-dimensional data, we have decided to ar-
tiﬁcially reduce its dimensionality for computational rea-
sons by selecting only those sequential paths that occur in
at least 1,000 ﬁles in our corpus (see Section 5.1 for a de-
tailed description of the data used in our experimental eval-
uation). This reduces the number of features, i.e., structural
paths, in our laboratory experiments from over 9 million
to 6,087. We did not use class information for the selection
of “discriminative features” as it was done, e.g., in ZOZZLE
[10]. Such manual pre-selection of features introduces an
artiﬁcial bias to a speciﬁc dataset and provides an attacker
with an easy opportunity to evade the classiﬁer by adding
features from the opposite class to his malicious examples.

4.3.1 Decision Trees

The decision tree is a popular classiﬁcation technique in
which predictions are made in a sequence of single-attribute
tests. Each test either assigns a certain class to an example
or invokes further tests. Decision trees have arisen from
the ﬁeld of operational decision making and are especially
attractive for security applications, as they provide a clear
justiﬁcation for speciﬁc decisions – a feature appreciated
by security administrators. An example of a decision tree
classifying whether a person may be involved in a trafﬁc
accident is shown in Figure 3.

Figure 3. Example of a decision tree

6http://www.shogun-toolbox.org/
7http://www.cs.waikato.ac.nz/ml/weka/

The goal of automatic decision tree inference is to build
a decision tree from labeled training data. Several classi-
cal algorithms exist for decision tree inference, e.g., CART
[5], RIPPER [7], C4.5 [28]. We have chosen a modern de-
cision tree inference implementation C5.0 which provides
a number of useful features for practical applications, such
as automatic cross-validation and class weighting8. It can
also transform decision trees into rule sets which facilitate
the visual inspection of large decision trees.

4.3.2 Support Vector Machines

The Support Vector Machine (SVM) is another popular ma-
chine learning algorithm [8]. Its main geometric idea, illus-
trated in Figure 4, is to ﬁt a hyperplane to data in such a way
that examples of both classes are separated with the largest
possible margin M. In the case of a linear decision func-
tion, it is represented by the hyperplane’s weight vector w
and the threshold ρ which are directly used to assign labels
y to unknown examples x:

y(x) = w⊤x − ρ

Nonlinear decision functions are also possible by applying
a nonlinear transformation to input data which maps it into
a feature space with special properties, the so-called Repro-
ducing Kernel Hilbert Space (RKHS). The elegance of SVM
consists in the fact that such transformation can be done im-
plicitly, by choosing an appropriate nonlinear kernel func-
tion k(x1, x2) which compares two examples x1 and x2.
The solution α to the dual SVM learning problem, equiv-
alent to the primal solution w, can be used for a nonlinear
decision function expressed as a comparison of an unknown
example x with selected examples xi in the training data,
the so-called “support vectors” (marked with the black cir-
cles in Figure 4):

y(x) = X

αiyik(x, xi) − ρ

∈∈SV

w

M

Figure 4. Linear and nonlinear SVM

Efﬁcient implementations of SVM learning are available
in various machine learning packages, including WEKA

8http://www.rulequest.com/see5-info.html, v.2.07.

and SHOGUN. In our experiments, we used a well-known
stand-alone SVM implementation LibSVM9.

5 Experimental Evaluation

The goal of the experiments presented in this section is to
measure the effectiveness and throughput of our proposed
method and its operational applicability under real-world
conditions. In addition, we compare the classiﬁcation per-
formance of our method to other existing methods for de-
tecting malicious PDF ﬁles: PJSCAN and the established
antivirus tools. Our evaluation is based on an extensive
dataset comprising around 660,000 real-world PDF docu-
ments.

5.1 Experimental Dataset

Dataset quality is essential for the inference of mean-
ingful models as well as for a compelling evaluation of
any data-driven approach. For our evaluation, we have ob-
tained a total of 658,763 benign and malicious PDF ﬁles
(around 595 GB). Our dataset was collected from Google
and VIRUSTOTAL10, an online service that checks ﬁles up-
loaded by ordinary users for viruses using the majority of
available antivirus programs. The collected data comprises
the following 6 datasets:

D1: VIRUSTOTAL malicious, containing 38,207 (1.4 GB)
malicious PDF ﬁles obtained from VIRUSTOTAL dur-
ing the course of 18 days, between the 5th and 22nd
of March 2012, which were labeled by at least 5 an-
tiviruses as malicious,

D2: VIRUSTOTAL malicious new, containing 11,409
(527 MB) malicious PDF ﬁles obtained from VIRUS-
TOTAL 2 months later, during the course of 33 days,
between the 23rd of May and 24th of June 2012, which
were labeled by at least 5 antiviruses as malicious,

D3: VIRUSTOTAL benign, containing 79,200 (75 GB) be-
nign PDF ﬁles obtained from VIRUSTOTAL during
the course of 18 days, between the 5th and 22nd of
March 2012, which were labeled by all antiviruses as
benign,

D4: Google benign, containing 90,384 (73 GB) benign
PDF ﬁles obtained from 1,000 Google searches for
PDF ﬁles, without search keywords, during the course
of 2,000 days, between the 5th of February 2007 and
the 25th of July 2012

9http://www.csie.ntu.edu.tw/˜cjlin/libsvm/, v.3.12.
10https://www.virustotal.com/.

D5: Operational malicious, containing 32,526 (2.7 GB)
malicious PDF ﬁles obtained from VIRUSTOTAL dur-
ing the course of 14 weeks, between the 16th of July
and 21st of October 2012, which were labeled by at
least 5 antiviruses as malicious,

D6: Operational benign, containing 407,037 (443 GB)
benign PDF ﬁles obtained from VIRUSTOTAL dur-
ing the course of 14 weeks, between the 16th of July
and 21st of October 2012, which were labeled by all
antiviruses as benign.

The VIRUSTOTAL data comprises PDF ﬁles used by
people from all over the world, which brings us as close
to real-world private PDF data as possible. In fact, the be-
nign VIRUSTOTAL data is even biased towards being ma-
licious, as users usually upload ﬁles they ﬁnd suspicious.
The dataset obtained by Google searches removes the bias
towards maliciousness in benign data and attempts to cap-
ture the features of an average benign PDF ﬁle found on the
Internet.

Note that we consider a VIRUSTOTAL ﬁle to be mali-
cious only if it was labeled as such by at least 5 antiviruses.
Files labeled malicious by 1 to 4 AVs are discarded al-
together from the experiments because there is little con-
ﬁdence in their correct labeling, as veriﬁed empirically.
Given the lack of reliable ground truth for all PDF ﬁles, we
assumed the zero false positive rate for the antivirus prod-
ucts and could not perform their fair comparison with the
proposed method with respect to the false positive rate.

5.2 Experimental Protocol

Two types of experiments were devised to evaluate the
detection performance of the presented method: laboratory
and operational experiments.

The three laboratory experiments operate on static
data, captured in a speciﬁc point in time, where training
and classiﬁcation data are intermixed using 5-fold cross-
validation11:

• The Standard experiment is designed to evaluate the
overall effectiveness of our method on known mali-
cious and average benign data. To this end, we use the
VIRUSTOTAL malicious dataset (D1) and the Google
benign dataset (D4).

115-fold cross-validation works as follows: we randomly split our data
into 5 disjoint subsets, each containing one ﬁfth of malicious and one ﬁfth
of benign ﬁles. Learning and classiﬁcation are repeated ﬁve times, each
time selecting a different combination of four subsets for learning and the
remaining one for classiﬁcation. This experimental protocol enables us
to classify every ﬁle exactly once while ensuring that no ﬁle processed in
the classiﬁcation phase was used in the learning phase for the respective
model.

• The Suspicious experiment is designed to evaluate the
effectiveness of our method on PDF ﬁles that ordinary
users do not trust. For this experiment, we use VIRUS-
TOTAL malicious data (D1) and VIRUSTOTAL benign
data (D3). The classiﬁcation task in this experiment is
harder than in the Standard experiment since its be-
nign data is biased towards malicious.

• The WithJS experiment is designed to enable the com-
parison of our method to PJSCAN. For this experi-
ment, a subset of the datasets used for the Standard
experiment (D1 and D4) was used comprising only
those ﬁles that contain directly embedded JavaScript
which PJSCAN can extract; i.e., 30,157 malicious and
906 benign ﬁles.

In contrast, in the two operational experiments, classiﬁ-
cation is performed on ﬁles which did not exist at all at the
time of training, i.e., ﬁles obtained at a later time:

• The Novel experiment evaluates our method on novel
malicious threats when trained on an outdated training
set. For this experiment, we apply the models learned
in the Standard experiment to new VIRUSTOTAL ma-
licious data (D2), which is two months newer. Novel
benign data was not evaluated as its observed change
in this timespan was not signiﬁcant.

• The 10Weeks experiment is designed to evaluate the
classiﬁcation performance of our method in a real-
world, day-to-day practical operational setup and com-
pare it to the results of the best VIRUSTOTAL antivirus
in the same time period. This experiment is performed
on the data from the Operational benign (D6) and ma-
licious (D5) datasets, containing ﬁles gathered during
the course of 14 weeks. The experiment is run once ev-
ery week, for 10 weeks starting from week 5. In every
run, feature selection is performed on ﬁles gathered in
the past 4 weeks. A new model is learned from scratch
based on these features and data; this model is used
to classify the ﬁles obtained during the current week.
Thus the data obtained during weeks 1 to 4 is used to
learn a model which classiﬁes data gathered in week 5,
weeks 2 to 5 are used for week 6, etc.

Note that, in practice, there are no fundamental difﬁcul-
ties for periodic re-training of classiﬁcation models as new
labeled data becomes available. The models deployed at
end-user systems can be updated in a similar way to signa-
ture updates in conventional antivirus systems. As will be
shown in Section 5.4, SVMs are efﬁcient enough to allow
periodic re-training of models from scratch. Our decision
tree learning algorithm implementation, however, lacked
the required computational performance and was not evalu-
ated in this experiment.

5.3 Experimental Results

Both the decision tree learning algorithm and the SVM
were evaluated in our laboratory experiments. For the SVM,
we selected the radial basis function (RBF) kernel with γ =
0.0025 and a cost parameter C = 12, based on an empirical
pre-evaluation.

5.3.1 The Standard experiment

Table 1 shows detection results for both classiﬁcation al-
gorithms in the Standard experiment. The top part shows
the confusion matrices (the number of positive and negative
ﬁles with true and false classiﬁcations) obtained by aggre-
gating the results of all ﬁve cross-validation runs. The bot-
tom part shows other performance indicators: the true and
false positive rates and the overall detection accuracy.

True Positives
False Positives
True Negatives
False Negatives

True Positive Rate
False Positive Rate
Detection Accuracy

Decision tree

SVM

38,102
51
90,783
105

.99725
.00056
.99879

38,163
10
90,824
44

.99885
.00011
.99958

Table 1. Aggregated results of the Standard
experiment

The Standard experiment evaluates the overall perfor-
mance of our method under laboratory conditions. As Ta-
ble 1 shows, although the SVM slightly outperforms the de-
cision tree learning algorithm, both algorithms show excel-
lent classiﬁcation performance. Very high detection accu-
racy (over 99.8%) was achieved, while false positives rate
remained in the low promille range (less than 0.06%).

This experiment raises the question of how our method
compares to modern, fully up-to-date commercial antivirus
products. We were able to acquire detection results for 43
AV engines available at VIRUSTOTAL at the time of data
collection. It is important to note that, because VIRUSTO-
TAL runs the AVs using their command-line interface, the
detection capabilities of the AVs were limited to static ﬁle
processing.

Figure 5 shows the comparison of true positive rates of
the VIRUSTOTAL AVs and of our method using both de-
cision trees and SVM. With the mentioned limitations in
place, both of our algorithms outperform the commercial
antivirus engines in this respect, and as many as 30 antivirus
engines miss at least 15% of the threats.

Total
Our Method (SVM)
Our Mehtod (DT)
GData
Avast
DrWeb
BitDefender
F-Secure
Kaspersky
Microsoft
NOD32
Sophos
AntiVir
Ikarus
eTrust-Vet
Emsisoft
VIPRE
ClamAV
F-Prot
McAfee-GW-Edition
Fortinet
K7AntiVirus
McAfee
nProtect
Commtouch
Comodo
AVG
TrendMicro
TrendMicro-HouseCall
VirusBuster
Norman
Symantec
AhnLab-V3
CAT-QuickHeal
PCTools
Antiy-AVL
Jiangmin
Rising
eSafe
Panda
VBA32
ViRobot
TheHacker
ByteHero
SUPERAntiSpyware
Prevx

0

5000

10000

15000
25000
Number of detected files

20000

30000

35000

40000

Figure 5. Comparison of our method to com-
mercial antiviruses

5.3.2 The Suspicious experiment

Results for the Suspicious experiment are shown in Table 2.
The classiﬁcation performance of both algorithms indeed
decreases when applied to this harder, suspicious data in
comparison to the Standard experiment, however, the per-
formance degradation is very small.

True Positives
False Positives
True Negatives
False Negatives

True Positive Rate
False Positive Rate
Detection Accuracy

Decision tree

SVM

38,118
68
79,132
89

.99767
.00086
.99866

38,163
27
79,173
44

.99885
.00034
.99939

Table 2. Aggregated results of the Suspicious
experiment

Decision tree

SVM PJScan

Decision tree

SVM

True Positives
False Positives
True Negatives
False Negatives

True Positive Rate
False Positive Rate
Detection Accuracy

30,130
14
892
27

.9991
.0154
.9986

30,149
12
894
8

.9997
.0132
.9993

21,695
1
905
8,462

.7194
.0011
.7275

Table 3. Aggregated results of the WithJS ex-
periment

5.3.3 The WithJS experiment

Table 3 shows detailed experimental results for both of
our algorithms and PJSCAN. Since PJSCAN performs
anomaly detection; i.e., it learns using only examples of one
class (malicious), the experimental protocol for PJSCAN is
slightly different. Five-fold cross-validation is employed on
the same data subsets as with our method, except that the
benign training ﬁles are left unused for PJSCAN.

Overall, our method performs somewhat worse than
in the Standard experiment, due to the strong class im-
balance in the dataset. However, it signiﬁcantly outper-
forms PJSCAN, a method specialized for detecting mali-
cious JavaScript, even on a dataset carefully chosen for it.
PJSCAN’s high false negative rate in this experiment can be
attributed to its failure to deal with intricate obfuscations.
The reported effectiveness of PJSCAN is comparable to the
results presented earlier with VIRUSTOTAL data [19].

The experimental results presented above represent a sig-
niﬁcant improvement in comparison to previous results on
detection of PDF malware reported in the literature, sum-
marized in Table 4 on the following page. It can be clearly
seen that the detection performance of the proposed method
(referred to as STRPATH) is signiﬁcantly better than in pre-
viously reported results. Its closest competitor, MALWARE
SLAYER [23], attains similar true positive rate but at the
cost of more than 200-fold increase of the false positive
rate. Both of the dynamic analysis methods, MDSCAN [37]
and SHELLOS [34], generate no false positives12 but de-
tect only 80-90% of malware; it should be also noted that
these results have been measured on an order of magnitude
smaller datasets.

12Strangely, no data on false positive rate is reported for SHELLOS al-
though benign data was collected. We presume it to be zero, as there is
no reason to believe that a false detection of injected shellcode would have
been reported on some realistic benign data.

True Positives
False Negatives

10,681
728

10,870
539

True Positive Rate

.9361

.9527

Table 5. Aggregated results of the Novel ex-
periment

5.3.4 The Novel experiment

Table 5 shows the results for the Novel experiment13.

The Novel experiment shows that, even when our learn-
ing algorithms are trained on a 2 to 3 month-old dataset,
they still achieve respectable 93% (decision tree) or 95%
(SVM) true positive rates.

5.3.5 The 10Weeks experiment

Figure 6 shows the comparison of our method to the best
VIRUSTOTAL antivirus14 in the 10Weeks experiment in
terms of true positive rate (TPR). The best AV achieves
an overall TPR of 92.81%, signiﬁcantly better than 87.14%
achieved by our method. However, our method consistently
outperforms the best AV in 7 out of 10 weeks, and there
is a draw in week 8. The performance degradation of our
method in weeks 14 and, most notably, 12 has motivated
a further investigation which uncovered a curious trend in
VIRUSTOTAL submissions.

Our Method
Best Antivirus
Total Positives

6000
5000
4000
3000
2000
1000
0

t

 

n
u
o
C
e
v
i
t
i
s
o
P

5

6

7

8

10

9
Week

11

12

13

14

R
P
T

1.0
0.8
0.6
0.4
0.2
0.0

Figure 6. Comparison of the true positive rate
of our method to the best antivirus for the
10Weeks experiment

The top half of Figure 6 shows the number of PDF sub-
missions to VIRUSTOTAL detected by at least 5 AVs, i.e.,

13Note that some information, such as the true negative count, is missing
for this experiment because it was only applied to malicious data, since
changes in benign performance were negligible.

14The name of the best AV is not disclosed, as there are several AVs
within a 5% margin of the TPR achieved in this experiment, and their rank-
ings may change from week to week.

STRPATH MDSCAN

PJSCAN

SHELLOS MALWARE SLAYER

Number of malicious samples
Number of benign samples

True positive rate
False positive rate

38,207
90,384

.9988
.0001

197
2,000

.8934
0

30,157
906

.7194
.0011

405
179

.8024
N/A

11,157
9,989

0.9955
0.0251

Table 4. Comparison of the proposed method with previous results

the number of positives per week. In the ﬁrst week of Octo-
ber 2012, week 12, VIRUSTOTAL saw the positive submis-
sion count increase by approx. 150%, from around 2,000 to
around 5,000. This elevated level of submissions has per-
sisted to the end of the experiment. A closer inspection of
the submissions in this week has revealed that there are two
groups of ﬁles, one with 1,842 and the other with 2,595,
which differ byte-wise from each other, but have identi-
cal PDF structure, i.e., every ﬁle in a group corresponds
to the same bag-of-paths. Furthermore, there is a high sim-
ilarity between the structure of the ﬁles in the two groups.
The bag-of-paths of the smaller group consists of 99 struc-
tural paths, all of which are present in the other group as
well. The two only differ by the presence of additional 11
structural paths in the bigger group. Files with the same
bag-of-paths were also submitted later, but not before this
week. This ﬁnding strongly suggests that the submissions
of week 12 and later stem in great part from a single source
and are generated using fuzzing techniques.

The cause for the false negative rate of 37% in week 12
is that all the 1,842 ﬁles in the smaller group were wrongly
labeled as benign by our method. The prediction is the same
for all ﬁles because they all translate into equal bags-of-
paths, i.e., the same data point. A wrong classiﬁcation of
one data point in this case led to a false negative rate of
more than 1/3 because the test data was heavily skewed by
one source producing very similar, fuzzed PDFs. In about
20 cases, these fuzzed PDFs were also missed by all the
AVs.

The data point corresponding to the bag-of-paths of the
smaller group of ﬁles is located on the wrong side of the
SVM decision boundary, although very close to it. The
addition of further 11 structural paths positioned the data
point corresponding to the bag-of-paths of the larger group
signiﬁcantly over the decision boundary into the positive
class. The reason for this lies in the fact that 8 out of 11
added structural paths are strong indicators of malicious-
ness in the learned SVM model15. In the weeks following
week 12, these examples showed up in the learning stage

15A linear SVM was trained for the purpose of this feature interpretation
which exhibits the same misclassiﬁcation problem for the smaller group of
ﬁles. The evaluation was performed analogue to the evasion strategy for
linear SVMs presented in Section 6 by calculating and sorting weights for
all features.

and were correctly classiﬁed.

The performance drop in week 14 comes from a very
high number of submitted ﬁles (over 900) which our parser
could not open. This anomaly was not further investigated
as these are either malformed PDFs which are not danger-
ous to the PDF renderer application but are still scanned by
ignorant AVs or parser bugs, in which case it sufﬁces to up-
date or ﬁx the parser or even employ a completely different
one, as the method is parser-agnostic.

The overall false positive rate of our method in this ex-
periment is 0.0655%, as in laboratory tests. The AVs do not
have false positives by deﬁnition of our experiments, as the
“undecided” ﬁles (the ones between 1 and 4 detections) are
ﬁltered.

5.4 Throughput

High throughput is an important consideration when
dealing with large volumes of PDF data, as is the case with
VIRUSTOTAL, big companies or governments. Our system
was designed to handle such loads and utilize the parallel
processing capabilities of modern computer systems. We
have measured the time it takes to perform feature extrac-
tion, learning and classiﬁcation for datasets D1, D2, D3 and
D4 with both decision trees and SVMs. The measurements
were made on a quad-core CPU with 8 GBs of RAM and
a 7,200 RPM SATA hard disk with the memory caches pre-
viously cleared.

Feature extraction is the most time-consuming operation,
as it requires to load all the PDF ﬁles from the hard drive.
It was performed using 7 parallel processes. In total, 121
minutes and 55 seconds were spent on feature extraction
for the 150 GB of data in the above mentioned datasets, of
which 5 minutes and 13 seconds were spent on malicious
ﬁles and 116 minutes and 42 seconds on benign ﬁles. This
yields a throughput of 168 Mbit/s.

Numbers for learning and classiﬁcation differ for deci-

sion trees and SVMs. They are presented in Table 6.

Since each of the 5 cross-validation runs trains on 80%
of the training data, we divided the total sum of execution
times for all runs by four to obtain an estimate of how long a
single training would take for the entire dataset. The classi-
ﬁcation time is a simple sum of 5 individual classiﬁcations,

Learning

Classiﬁcation

Decision tree
SVM

6m 31s
1m 23s

52s
54s

Table 6. Time required for learning and clas-
siﬁcation for the Standard experiment

as each deals with 20% of the testing data. Note that exe-
cuting the cross-validation runs in parallel increases perfor-
mance linearly with the number of processes. Even though
decision trees are signiﬁcantly slower than the SVM, the
overall running time is dominated by feature extraction.

The total time required for feature extraction, learning
and classiﬁcation using SVMs in the Standard experiment
with the datasets D1 and D4 of 74.4 GB was 1 hour and 2
seconds, which yielded a total throughput of around 169
Mbit/s and a mean processing time of 28 ms per ﬁle. The
high performance numbers are achieved by static detection
and parallel execution. In contrast, dynamic methods such
as MDSCAN (slightly less than 3,000 ms per malicious
ﬁle, 1,500 ms per benign ﬁle on average) and SHELLOS (on
average 5.46 seconds per ﬁle for analysis, plus additional 2
(benign) to 20 (malicious, non-ROP) seconds for buffer ex-
traction) require orders of magnitude more time. The only
other fully static method, PJSCAN, takes 23 ms per ﬁle, be-
cause it only extracts a well-deﬁned, limited subset of the
entire PDF ﬁle.

6 Evasion

An important aspect of every proposed security measure
is how difﬁcult it is to evade. Given the increasing interest to
the application of learning methods for security problems,
some previous work has addressed the methodology for se-
curity analysis of learning algorithms [3, 18, 2]. Following
such methodology, in the following section, we present and
experimentally evaluate a novel type of attacks against our
method which is motivated by the speciﬁc constraints im-
posed by the structural features on the attacker.

The ﬂexibility of the PDF format and the lax enforce-
ment of its rules by the Acrobat Reader gives the attacker
ample opportunity to inﬂuence both the content and the
structure of the ﬁle. The only fundamental constraint on
the attacker is the need to deliver the malicious content and
trigger its execution by means of an appropriate attack vec-
tor. In our evasion model, we assume that the attacker has
crafted a malicious PDF ﬁle that is correctly classiﬁed as
malicious. The attacker’s goal now is to modify the ﬁle
such that it is classiﬁed as benign. We assume that the at-
tacker can not decrease the detection footprint by removing
parts of malicious content and is thus limited to only adding

content that the classiﬁcation model considers benign. Al-
though we cannot verify that this limitation is insurmount-
able for an attacker, intuitively it is much easier to add ar-
bitrary benign content to a PDF document than to change
its syntactic structure of an existing document such that it
is still “correctly” rendered by the viewer and triggers the
exploit.

In our analysis, we assume that the attacker has com-
plete knowledge of the detection mechanism and its classi-
ﬁcation model. Although the latter assumption may seem
too restrictive, nothing prevents the attacker from collect-
ing a surrogate dataset, similar to the one used for training,
train a classiﬁer of his own and thus obtain a good guess
of the classiﬁcation model. Alternatively, if our method
were to be deployed on end-user systems, the ﬁles contain-
ing the learning models would be distributed to end-users,
as with antivirus deﬁnitions. This would make them com-
pletely available to the attackers by means of reverse engi-
neering. In the remaining part of this section, we analyze
the potential impact of feature addition attacks on different
classiﬁcation algorithms deployed in our system.

In order to evade a decision tree classiﬁer, the attacker
has to modify his malicious ﬁle in such a way that will
change the decision path and result in a false negative.
To accomplish this, the attacker inspects the decision tree
and ﬁnds the exact decision which, lead to a terminal node
with the correct classiﬁcation as malicious. Then the at-
tacker must backtrack along this path and ﬁnd the ﬁrst non-
terminal node that leads directly to a terminal node with
the benign class if the test is positive. The test is positive
if a certain feature exists in the ﬁle (as is the case with bi-
nary embedding) or if a feature has a count larger than a
certain threshold (count embedding). In such case, it is usu-
ally straightforward for the attacker to “add” this feature
into the feature vector by adding appropriate content to the
PDF ﬁle. This forces the decision tree classiﬁer into mak-
ing the wrong decision. If the feature in question can not be
added to this ﬁle easily (some parts of the PDF structure are
strictly enforced) the attacker can continue the search for a
better choice of feature. If there are no positive decisions
on the path that lead directly to a benign terminal node but
to a subtree instead, the attacker can still modify his ﬁle,
insert such a feature, get a new decision path and repeat
the search procedure. This algorithm can be easily auto-
mated. We were able to empirically verify its effectiveness
by adding a previously nonexistent feature to a real-world
malicious PDF sample, which forced our decision tree to
misclassify it. Using random forests instead of single deci-
sion trees would make it computationally more challenging
to evade detection, but they are still exposed to the same
underlying problem.

A different attack strategy can be devised for the lin-
ear SVM. Recall that its decision function is computed as

y(x) = w⊤x − ρ. Parameters w and ρ are given by the
model while the attacker controls the input vector x. The
attacker’s goal is to change the prediction from positive
to negative. For the count embedding, this can be easily
achieved by picking the dimension j with the most negative
weight wj in the model and inserting ¯xj content chunks cor-
responding to the feature j such that y(x) becomes negative.
Simple algebra reveals that ¯xj = (y(x) − ρ)/wj. We have
successfully veriﬁed this evasion attack in practice. If the
most negative feature cannot be inserted or can only be in-
serted once, the attacker can ﬁnd the feature with the second
most negative weight, and so on. For the binary embedding,
the attacker must insert multiple features, but this is only a
minor practical constraint.

Evading an SVM with an RBF kernel presents a funda-
mentally harder problem than in the linear case. The reason
lies in the fact that the radial basis function is nonlinear,
which makes the task of modifying an input vector to yield
a negative result a nonconvex optimization problem. The
example that we successfully used for the evasion of lin-
ear SVM did not work for RBF. As a more potent strategy,
we decided to attempt evasion using a mimicry attack, by
masquerading malicious ﬁles to look benign. In our case,
this can be accomplished by copying all features of some
benign ﬁle into a malicious one. To verify the efﬁcacy of
this strategy in practice, we randomly sampled 5,000 mali-
cious and 5,000 benign training ﬁles, trained an RBF SVM
and then classiﬁed another randomly selected 5,000 ma-
licious and 5,000 benign test ﬁles. The benign ﬁle that
was classiﬁed with the greatest distance from the separat-
ing hyperplane; i.e., the one classiﬁed most conﬁdently as
benign, was chosen as a camouﬂage in order to maximize
the chance of a successful attack. We copied all the fea-
tures of this ﬁle to all the 5,000 malicious feature vec-
tors in the test set. As a result, the number of false nega-
tives increased from 28 to 30; i.e., the strongest conceivable
mimicry attack added only 2 misclassiﬁcations in 5,000 ex-
amples (0.025%)! For the linear SVM in the same setting,
the mimicry attack was able to decrease detection accuracy
to about 50%. This experiment practically demonstrates the
strong resistance of RBF SVMs to mimicry attacks.

7 Discussion

The experimental evaluation and the analysis of potential
evasion techniques presented above unequivocally demon-
strate that the structure of PDF documents bears a strong
discriminative power for detecting malicious documents.
This ﬁnding is quite surprising given the fact that the struc-
tural difference is only a side-effect of the presence of ma-
licious content. Although, in principle, it can be expected
that attackers may ﬁnd a way to camouﬂage malicious con-
tent within a benign structure, our experiments with several

evasion strategies suggest that this task may be harder than
one thinks. The most aggressive evasion strategy we could
conceive was successful for only 0.025% of malicious ex-
amples tested against an off-the-shelf nonlinear SVM clas-
siﬁer with the RBF kernel using the binary embedding. Cur-
rently, we do not have a rigorous mathematical explanation
for such a surprising robustness. Our intuition suggests that
the main difﬁculty on attacker’s part lies in the fact that the
input features under his control, i.e., the structural elements
of a PDF document, are only loosely related to the true fea-
tures used by a classiﬁer. The space of true features is “hid-
den behind” a complex nonlinear transformation which is
mathematically hard to invert. This observation is corrob-
orated by the fact that the same attack staged against the
linear classiﬁer with binary embedding had a 50% success
rate; hence, the robustness of the RBF classiﬁer must be
rooted in its nonlinear transformation.

The comparison of interpretations of learned models
with the success of evasion attacks leads us to the hypoth-
esis that explainability and robustness against evasion are
antagonistic qualities of learning methods. Indeed, the most
naturally explained method, the decision tree, was the most
trivial one to evade. In fact, the evasion of decision trees
is so trivial that we would not recommend their use for
any security-related applications. The linear SVM, whose
model is relatively well interpretable (see, e.g., [30, 31] for
exemplary interpretations of linear SVM in security appli-
cations), is attackable with a moderate effort. On the other
hand, SVM with the RBF kernel, which exhibited the best
robustness, is almost impossible to interpret. Further re-
search effort is needed to better understand such trade-offs
for speciﬁc learning methods and for development of prac-
tical compromises.

8 Conclusions

We have proposed a novel method for the detection of
malicious PDF ﬁles based on the difference between the un-
derlying structural properties of benign and malicious PDF
ﬁles. By relying on structure instead of the actual content, it
renders it unnecessary to deal with the very expressive PDF
obfuscation techniques, interpretation of JavaScript and dy-
namic execution – hard problems with which related meth-
ods continue to struggle – and reaps the beneﬁts of remain-
ing a static method: very high throughput and robustness.

Experimental evaluation has demonstrated excellent be-
havior of our method in both laboratory and operational
experiments on a very large dataset of around 660,000 be-
nign and malicious PDF ﬁles. It compares favorably to re-
cent related work from the literature (PJSCAN, MDSCAN,
SHELLOS and MALWARE SLAYER). The proposed method
has proved to be very effective against novel attacks, main-
taining the high detection accuracy even on real PDF mal-

ware ﬁrst seen more than two months after the classiﬁca-
tion model was created. A 10-week operational deployment
in real-world conditions with weekly retraining has demon-
strated an excellent performance of the proposed method,
while also showing its difﬁculty to handle sudden changes
in attack patterns in a timely manner. Techniques for im-
proving its performance on strongly nonstationary data will
be investigated in future work.

Computational efﬁciency of the proposed methods is
on par with the fastest previously known static detection
method (PJSCAN) and attains the throughput of 169 Mbit/s.
Such performance is an order of magnitude higher than that
of hybrid static/dynamic methods and almost two orders of
magnitude higher than established dynamic detection meth-
ods. Thanks to the high efﬁciency of the proposed method,
a 150 GB dataset collected from VIRUSTOTAL and Google
search could be processed in two hours.

In our analysis of potential evasion strategies, we have
speciﬁcally focused on the feature addition attack scenario,
in which an attacker is limited in his ability to remove mali-
cious content but is free to add benign content to avoid de-
tection. Our analysis and experimental evaluation showed
than some classiﬁers that were deployed in our framework,
such as decision trees and linear SVM, can be easily de-
feated by feature addition, whereas others, such as SVM
with the RBF kernel, are almost immune to sophisticated
attack scenarios.

The ﬁndings presented in this paper reveal several im-
portant open issues. The surprising fact that the structure of
PDF documents delivers strong indicators for the presence
of malicious content calls for a deeper investigation of the
syntax of the PDF format to understand the correlation of
its speciﬁc features with semantics of known attacks. Such
investigation should also address further potential evasion
strategies against structure-based detection methods. While
our experiments showed that some non-linear classiﬁcation
algorithms can be robust against feature addition attacks,
detailed consideration of the PDF semantics is essential for
understanding of content modiﬁcation or feature removal
attacks.

References

[1] P. Akritidis, E. Markatos, M. Polychronakis, and K. Anag-
nostakis. STRIDE: Polymorphic sled detection through in-
struction sequence analysis. In 20th International Confer-
ence on Information Security, pages 375–392, 2005.

[2] M. Barreno, B. Nelson, A. Joseph, and J. Tygar. The secu-
rity of machine learning. Machine Learning, 81(2):121–148,
2010.

[3] M. Barreno, B. Nelson, R. Sears, A. Joseph, and J. Tygar.
Can machine learning be secure? In ACM Symposium on
Information, Computer and Communication Security, pages
16–25, 2006.

[4] C. M. Bishop. Pattern Recognition and Machine Learning.

Springer, 2007.

[5] L. Breiman, J. Friedman, J. Olshen, and C. Stone. Classiﬁ-

cation and Regression Trees. Wadsworth, 1984.

[6] D. Canali, M. Cova, G. Vigna, and C. Kruegel. Prophiler:
a fast ﬁlter for the large-scale detection of malicious web
pages.
In International Conference on World Wide Web
(WWW), pages 197–206, 2011.

[7] W. Cohen. Fast effective rule induction.

In International
Conference on Machine Learning (ICML), pages 115–123,
1995.

[8] C. Cortes and V. Vapnik. Support vector networks. Machine

Learning, 20:273–297, 1995.

[9] M. Cova, C. Kruegel, and G. Vigna. Detection and analysis
of drive-by-download attacks and malicious JavaScript code.
In International Conference on World Wide Web (WWW),
pages 281–290, 2010.

[10] C. Curtsinger, B. Livshits, B. Zorn, and C. Seifert. ZOZ-
ZLE: Fast and precise in-browser JavaScript malware detec-
tion. In USENIX Security Symposium, pages 33–48, 2011.

[11] M. Engelberth, C. Willems, and H. T. MalOfﬁce – analysis
of various application data ﬁles. In Virus Bulletin Interna-
tional Conference, 2009.

[12] G. Gu, P. Porras, V. Yegneswaran, M. Fong, and W. Lee.
BotHunter: Detecting malware infection through IDS-
driven dialog correlation. In USENIX Security Symposium,
pages 167–182, 2007.

[13] Google warns of using adobe reader - particularly on
http://www.h-online.com/open/news/item/Google-

linux.
warns-of-using-Adobe-Reader-particularly-on-Linux-
1668153.html.

[14] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of
Statistical Learning: data mining, inference and prediction.
Springer series in statistics. Springer, New York, N.Y., 2009.
2nd edition.

[15] Vorsicht

bei

angeblicher

telekom-onlinerechnung.

http://heise.de/-1545909.

[16] S. Jana and V. Shmatikov. Abusing ﬁle processing in mal-
In IEEE Symposium on

ware detectors for fun and proﬁt.
Security and Privacy, pages 80–94, 2012.

[17] S. Kaplan, B. Livshits, B. Zorn, C. Siefert, and C. Cursinger.
“nofus: Automatically detecting” + string.fromcharcode(32)
+ “obfuscated ”.tolowercase() + “javascript code”. Technical
report, Microsoft Research, 2011.

[18] P. Laskov and M. Kloft. A framework for quantitative secu-
rity analysis of machine learning. In Proceedings of the 2nd
ACM Workshop on AISec, pages 1–4, Nov. 2009.

[19] P. Laskov and N. ˇSrndi´c. Static detection of malicious
JavaScript-bearing PDF documents.
In Annual Computer
Security Applications Conference (ACSAC), pages 373–382,
2011.

[20] W. Lee, S. Stolfo, and K. Mok. A data mining framework
for building intrusion detection models. In IEEE Symposium
on Security and Privacy, pages 120–132, 1999.

[21] W.-J. Li, S. Stolfo, A. Stavrou, E. Androulaki, and
A. Keromytis. A study of malcode-bearing documents. In
Detection of Intrusions and Malware & Vulnerability As-
sessment (DIMVA), pages 231–250, 2007.

[22] M. Mahoney and P. Chan. Learning rules for anomaly detec-
tion of hostile network trafﬁc. In International Conference
on Data Mining (ICDM), 2003.

[23] D. Maiorca, G. Giacinto, and I. Corona. A pattern recogni-
tion system for malicious pdf ﬁles detection. pages 510–524,
2012.

[24] T. V. Overveldt, C. Kruegel, and G. Vigna. FlashDetect:
ActionScript 3 malware detection. In Recent Adances in In-
trusion Detection (RAID), pages 274–293, 2012.

[25] PDF Reference.

http://www.adobe.com/devnet/pdf/pdf reference.html,
2008.

[26] M. Polychronakis, K. Anagnostakis, and E. Markatos. Com-
prehensive shellcode detection using runtime heuristics. In
Annual Computer Security Applications Conference (AC-
SAC), pages 287–296, 2010.

[27] N. Provos, P. Mavrommatis, M. Abu Rajab, and F. Monrose.
All your iFRAMEs point to us. In USENIX Security Sympo-
sium, pages 1–16, 2008.

[28] J. Quinlan. C4.5: Programs for Machine Learning. Morgan

Kaufmann, 1992.

[29] Blackhole

crimeware

kit

spike.
sophos fakeav conﬁcker/.

threat
http://www.theregister.co.uk/2012/01/26/

drives

web

[30] K. Rieck, T. Holz, K. Willems, P. D¨ussel, and P. Laskov.
Learning and classiﬁcation of malware behavior.
In De-
tection of Intrusions and Malware & Vulnerability Assess-
ment (DIMVA), 5th International Conference, pages 108–
125, July 2008.

[31] K. Rieck, T. Kr¨uger, and A. Dewald. Cujo: Efﬁcient de-
tection and prevention of drive-by-download attacks. In An-
nual Computer Security Applications Conference (ACSAC),
pages 31–39, 2010.

[32] Z. Shaﬁq, S. Khayam, and M. Farooq. Embedded malware
detection using markov n-grams. In Detection of Intrusions
and Malware & Vulnerability Assessment (DIMVA), pages
88–107, 2008.

[33] C. Smutz and A. Stavrou. Malicious PDF detection using
metadata and structural features. In Annual Computer Secu-
rity Applications Conference (ACSAC), 2012. To appear.

[34] K. Z. Snow, S. Krishnan, F. Monrose, and N. Provos. Shel-
lOS: Enabling fast detection and forensic analysis of code
injection attacks. In USENIX Security Symposium, 2011.

[35] PDF malware writers

keep

targeting

vulnerability.

http://www.symantec.com/connect/blogs/pdf-malware-
writers-keep-targeting-vulnerability.

[36] T. Toth and C. Kruegel. Accurate buffer overﬂow detection
via abstract payload execution. In Recent Adances in Intru-
sion Detection (RAID), pages 274–291, 2002.

[37] Z. Tzermias, G. Sykiotakis, M. Polychronakis,

and
E. Markatos. Combining static and dynamic analysis for the
detection of malicious documents. In European Workshop
on System Security (EuroSec), 2011.

[38] C. Willems, T. Holz, and F. Freiling. CWSandbox: Towards
automated dynamic binary analysis. IEEE Security and Pri-
vacy, 5(2):32–39, 2007.

