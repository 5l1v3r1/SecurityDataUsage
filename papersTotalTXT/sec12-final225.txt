Enemy of the State:

A State-Aware Black-Box Web Vulnerability Scanner

Adam Doup´e, Ludovico Cavedon, Christopher Kruegel, and Giovanni Vigna

University of California, Santa Barbara

{adoupe, cavedon, chris, vigna}@cs.ucsb.edu

Abstract

Black-box web vulnerability scanners are a popular
choice for ﬁnding security vulnerabilities in web appli-
cations in an automated fashion. These tools operate in
a point-and-shoot manner, testing any web application—
regardless of the server-side language—for common se-
curity vulnerabilities. Unfortunately, black-box tools
suffer from a number of limitations, particularly when
interacting with complex applications that have multi-
ple actions that can change the application’s state.
If
a vulnerability analysis tool does not take into account
changes in the web application’s state, it might overlook
vulnerabilities or completely miss entire portions of the
web application.

We propose a novel way of inferring the web applica-
tion’s internal state machine from the outside—that is, by
navigating through the web application, observing dif-
ferences in output, and incrementally producing a model
representing the web application’s state.

We utilize the inferred state machine to drive a black-
box web application vulnerability scanner. Our scanner
traverses a web application’s state machine to ﬁnd and
fuzz user-input vectors and discover security ﬂaws. We
implemented our technique in a prototype crawler and
linked it to the fuzzing component from an open-source
web vulnerability scanner.

We show that our state-aware black-box web vulnera-
bility scanner is able to not only exercise more code of
the web application, but also discover vulnerabilities that
other vulnerability scanners miss.

1 Introduction

Web applications are the most popular way of delivering
services via the Internet. A modern web application is
composed of a back-end, server-side part (often written
in Java or in interpreted languages such as PHP, Ruby,
or Python) running on the provider’s server, and a client

part running in the user’s web browser (implemented in
JavaScript and using HTML/CSS for presentation). The
two parts often communicate via HTTP over the Internet
using Asynchronous JavaScript and XML (AJAX) [20].

The complexity of modern web applications, along
with the many different technologies used in various ab-
straction layers, are the root cause of vulnerabilities in
web applications. In fact, the number of reported web
application vulnerabilities is growing sharply [18, 41].

The occurrence of vulnerabilities could be reduced
by better education of web developers, or by the use
of security-aware web application development frame-
works [10, 38], which enforce separation between struc-
ture and content of input and output data. In both cases,
more effort and investment in training is required, and,
therefore, cost and time-to-market constraints will keep
pushing for the current fast-but-insecure development
model.

A complementary approach for ﬁghting security vul-
nerabilities is to discover and patch bugs before mali-
cious attackers ﬁnd and exploit them. One way is to use
a white-box approach, employing static analysis of the
source code [4, 15, 17, 24, 28]. There are several draw-
backs to a white-box approach. First, the potential ap-
plications that can be analyzed is reduced to only those
applications that use the target programming language.
In addition, there is the problem of substantial false pos-
itives. Finally, the source code of the application itself
may be unavailable.

The other approach to discovering security vulnera-
bilities in web applications is by observing the applica-
tion’s output in response to a speciﬁc input. This method
of analysis is called black-box testing, as the applica-
tion is seen as a sealed machine with unobservable in-
ternals. Black-box approaches are able to perform large-
scale analysis across a wide range of applications. While
black-box approaches usually have fewer false positives
than white-box approaches, black-box approaches suffer

view.php

index.php

index.php

S_0

login.php

S_1

view.php

login.php

index.php

Figure 2: State machine of a simple web application.

Figure 1: Navigation graph of a simple web application.

2 Motivation

from a discoverability problem: They need to reach a
page to ﬁnd vulnerabilities on that page.

Classical black-box web vulnerability scanners crawl
a web application to enumerate all reachable pages and
then fuzz the input data (URL parameters, form values,
cookies) to trigger vulnerabilities. However, this ap-
proach ignores a key aspect of modern web applications:
Any request can change the state of the web application.

In the most general case, the state of the web applica-
tion is any data (database, ﬁlesystem, time) that the web
application uses to determine its output. Consider a fo-
rum that authenticates users, an e-commerce application
where users add items to a cart, or a blog where visitors
and administrators can leave comments. In all of these
modern applications, the way a user interacts with the
application determines the application’s state.

Because a black-box web vulnerability scanner will
never detect a vulnerability on a page that it does not
see, scanners that ignore a web application’s state will
only explore and test a (likely small) fraction of the web
application.

In this paper, we propose to improve the effectiveness
of black-box web vulnerability scanners by increasing
their capability to understand the web application’s inter-
nal state. Our tool constructs a partial model of the web
application’s state machine in a fully-automated fashion.
It then uses this model to fuzz the application in a state-
aware manner, traversing more of the web application
and thus discovering more vulnerabilities.

The main contributions of this paper are the following:

• A black-box technique to automatically learn a

model of a web application’s state.

• A novel vulnerability analysis technique that lever-
ages the web application’s state model to drive
fuzzing.

• An evaluation of our technique, showing that both
code coverage and effectiveness of vulnerability
analysis are improved.

Crawling modern web applications means dealing with
the web application’s changing state. Previous work in
detecting workﬂow violations [5, 11, 17, 30] focused on
navigation, where a malicious user can access a page that
is intended only for administrators. This unauthorized
access is a violation of the developer’s intended work-
ﬂow of the application.

We wish to distinguish a navigation-based view of the
web application, which is simply derived from crawling
the web application, from the web application’s internal
state machine. To illustrate this important difference, we
will use a small example.

Consider a simple web application that has only three
pages, index.php, login.php, and view.php. The
view.php page is only accessible after the login.php
page is accessed. There is no logout functionality. A
client accessing this web application might make a series
of requests like the following:
hindex.php, login.php, index.php, view.php,
index.php, view.phpi

Analyzing this series of requests from a navigation
perspective creates a navigation graph, shown in Fig-
ure 1. This graph shows which page is accessible from
every other page, based on the navigation trace. How-
ever, the navigation graph does not represent the infor-
mation that view.php is only accessible after accessing
login.php, or that index.php has changed after re-
questing login.php (it includes the link to view.php).
What we are interested in is not how to navigate the
web application, but how the requests we make inﬂuence
the web application’s internal state machine. The sim-
ple web application described previously has the internal
state machine shown in Figure 2. The web application
starts with the internal state S 0. Arrows from a state
show how a request affects the web application’s inter-
nal state machine. In this example, in the initial state,
index.php does not change the state of the application,
however, login.php causes the state to transition from
S 0 to S 1. In the new state S 1, both index.php and
view.php do not change the state of the web applica-
tion.

The state machine in Figure 2 contains important in-
formation about the web application. First, it shows that
login.php permanently changes the web application’s

state, and there is no way to recover from this change.
Second, it shows that the index.php page is seen in two
different states.

Now the question becomes: “How does knowledge of
the web application’s state machine (or lack thereof) af-
fect a black-box web vulnerability scanner?” The scan-
ner’s goal is to ﬁnd vulnerabilities in the application, and
to do so it must fuzz as many execution paths of the
server-side code as possible1. Consider the simple appli-
cation described in Figure 2. In order to fuzz as many
code paths as possible, a black-box web vulnerability
scanner must fuzz the index.php page in both states S 0
and S 1, since the code execution of index.php can fol-
low different code paths depending on the current state
(more precisely, in state S 1, index.php includes a link
to view.php, which is not present in S 0).

A black-box web vulnerability scanner can also use
the web application’s state machine to handle requests
that change state.
For example, when fuzzing the
login.php page of the sample application, a fuzzer will
try to make several requests to the page, fuzzing different
parameters. However, if the ﬁrst request to login.php
changes the state of the application, all further requests to
login.php will no longer execute along the same code
path as the ﬁrst one. Thus, a scanner must have knowl-
edge of the web application’s state machine to test if the
state was changed, and if it was, what requests to make
to return the application to the previous state before con-
tinuing the fuzzing process.

We have shown how a web application’s state machine
can be leveraged to improve a black-box web vulnerabil-
ity scanner. Our goal is to infer, in a black-box manner,
as much of the web application’s state machine as possi-
ble. Using only the sequence of requests, along with the
responses to those requests, we build a model of as much
of the web application’s state machine as possible.
In
the following section, we describe, at a high level, how
we infer the web application’s state machine. Then, in
Section 4, we provide the details of our technique.

3 State-Aware Crawling

In this section, we describe our state-aware crawling ap-
proach. In Section 3.1, we describe web applications and
deﬁne terms that we will use in the rest of the paper.
Then, in Section 3.2, we describe the various facets of
the state-aware crawling algorithm at a high level.

1Hereinafter, we assume that the scanner relies on fuzzer-based
techniques. However, any other automated vulnerability analysis tech-
nique would beneﬁt from our state-aware approach.

3.1 Web Applications

Before we can describe our approach to inferring a web
application’s state, we must ﬁrst deﬁne the elements that
come into play in our web application model.

A web application consists of a server component,
which accepts HTTP requests. This server component
can be written in any language, and could use many
different means of storage (database, ﬁlesystem, mem-
cache). After processing a request, the server sends back
a response. This response encapsulates some content,
typically HTML. The HTML content contains links and
forms which describe how to make further requests.

Now that we have described a web application at a
high level, we need to deﬁne speciﬁc terms related to
web applications that we use in the rest of this paper.

• Request—The HTTP request made to the web ap-
plication. Includes anything (typically in the form
of HTTP headers) that is sent by the user to the web
application: the HTTP Method, URL, Parameters
(GET and POST), Cookies, and User-Agent.

• Response—The response sent by the server to the
Includes the HTTP Response Code and the

user.
content (typically HTML).

• Page—The HTML page that is contained in the re-

sponse from a web application.

• Link—Element of an HTML page that tells the
browser how to create a subsequent request. This
can be either an anchor or a form. An anchor al-
ways generates a GET request, but a form can gener-
ate either a POST or GET request, depending on the
parameters of the form.

• State—Anything that inﬂuences the web applica-

tion’s server-side code execution.

3.1.1 Web Application Model

We use a symbolic Mealy machine [7] to model the web
application as a black-box. A Mealy machine is an au-
tomaton where the input to the automaton, along with
the current state, determines the output (i.e., the page
produced by the response) and the next state. A Mealy
machine operates on a ﬁnite alphabet of input and out-
put symbols, while a symbolic Mealy machine uses an
inﬁnite alphabet of input and output symbols.

This model of a web application works well because
the input to a web application, along with the current
state of the web application, determines the output and
the next state. Consider a simple e-commerce web appli-
cation with the state machine show in Figure 3. In this
state graph, all requests except for the ones leaving a state

S_0

POST /login.php
GET /logout.php

no_items

POST /add_item.php
GET /delete_item.php

item_in_cart

GET /logout.php

POST /login.php

POST /purchase.php

S_1

purchased_item

GET /logout.php
POST /login.php

S_2

Figure 3: The state machine of a simple e-commerce application.

bring the application back to the same state. Therefore,
this state graph does not show all the request that can be
made to the application, only the subset of requests that
change the state.

For instance, in the initial state S 0, there is only
one request that will change the state of the applica-
tion, namely POST /login.php. This change logs
the user into the web application.
From the state
no items, there are two requests that can change the
state, GET /logout.php to return the user to state S 0
and POST /add item.php to add an item to the user’s
shopping cart.

Note that

the graph shown in Figure 3 is not a
strongly connected graph—that is, every state cannot
be reached by every other state.
In this example, pur-
chasing an item is a permanent action, it irrecoverably
changes the state (there is no link from purchased item
to item in cart). Another interesting aspect is that
one request, GET /logout.php, leads to three differ-
ent states. This is because once the web application’s
state has changed, logging out, and then back in, does
not change the state of the cart.

3.2 Inferring the State Machine

Inferring a web application’s state machine requires the
ability to detect when the state of the web application has
changed. Therefore, we start with a description of the
state-change detection algorithm, then explain the other
components that are required to infer the state machine.

The key insight of our state-change algorithm is the
following: We detect that the state of the web application
has changed when we make an identical request and get
a different response. This is the only externally visible
effect of a state-change: Providing the same input causes
a different output.

Using this insight, our state-change detection algo-
rithm works, at a high level, as follows: (1) Crawl the
web application sequentially, making requests based on
a link in the previous response. (2) Assume that the state
stays the same, because there is no evidence to the con-
trary. (3) If we make a request identical to a previous
request and get a different response, then we assume that
some request since the last identical request changed the
state of the web application.

The intuition here is that a Mealy machine will, when
given the same input in the same state, produce the same
output. Therefore, if we send the same request and get a
different output, the state must have changed. By detect-
ing the web application’s state changes only using inputs
and outputs, we are agnostic with respect to both what
constitutes the state information and where the state in-
formation is located. In this way, we are more generic
than approaches that only consider the database to hold
the state of the application, when in fact, the local ﬁle
system or even memory could hold part of the web ap-
plication’s state.

The state-change detection algorithm allows us to infer
when the web application’s state has changed, yet four
other techniques are necessary to infer a state machine:
the clustering of similar pages, the identiﬁcation of state-
changing requests, the collapsing of similar states, and
navigating.

Clustering similar pages. We want to group together
pages that are similar, for two reasons: To handle inﬁnite
sections of web applications that are generated from the
same code (e.g., the pages of a calendar) and to detect
when a response has changed.

Before we can cluster pages, we model them using the
links (anchors and forms) present on the page. The in-
tuition here is that the links describe how the user can
interact with the web application. Therefore, changes to
what a user can do (new or missing links) indicate when
the state of the web application has changed. Also, in-
ﬁnite sections of a web application will share the same
link structure and will cluster together.

With our page model, we cluster pages together based
on their link structure. Pages that are in different clusters
are considered different. The details of this approach are
described in Section 4.1.

Determining the state-changing request. The state-
change detection algorithm only says that the state has
changed, however we need to determine which request
actually changed the state. When we detect a state
change, we have a temporal list of requests with identical
requests at the start and end. One of the requests in this
list changed the state. We use a heuristic to determine
which request changed the state. This heuristic favors
newer requests over older requests, POST requests over
GET requests, and requests that have previously changed

the state over those that have never changed the state.
The details are described in Section 4.2.
Collapsing similar states. The state-change detection
algorithm detects only when the state has changed, how-
ever, we need to understand if we returned to a previ-
ous state. This is necessary because if we detect a state
change, we want to know if this is a state we have pre-
viously seen or a brand new state. We reduce this prob-
lem to a graph coloring problem, where the nodes are
the states and an edge between two nodes means that the
states cannot be the same. We add edges to this graph
by using the requests and responses, along with rules to
determine when two states cannot be the same. After the
graph is colored, states that are the same color are col-
lapsed into the same state. Details of this state-merging
technique are provided in Section 4.3.
Navigating. We have two strategies for crawling the web
application.

First, we always try to pick a link in the last response.
The rational behind choosing a link in the last response
is that we emulate a user browsing the web application.
In this way, we are able to handle multi-step processes,
such as previewing a comment before it is committed.

Second, for each state, we make requests that are the
least likely to change the state of the web application.
The intuition here is that we want to ﬁrst see as much of a
state as possible, without accidentally changing the state,
in case the state change is permanent. Full details of how
we crawl the web application are provided in Section 4.4

Page

/html/body/div/span/a

/html/body/div/form

/user

/post

profile.php

edit.php

(id, page)

(all, sorted)

(text, email, id)

(0)

(0, 1)

(5)

(NULL)

(5)

Figure 4: Representation of a page’s link vectors stored
in a preﬁx tree. There are ﬁve links present on this tree,
as evidenced by the number of leaf nodes.

our state-change detection algorithm, we are not inter-
ested in changes to the content, but rather to changes in
the navigation structure. We focus on navigation changes
because the links on a page deﬁne how a user can inter-
act with the application, thus, when the links change, the
web application’s state has changed.

Therefore, we model a page by composing all the an-
chors and forms. First, every anchor and form is trans-
formed into a vector constructed as follows:

hdompath, action, params, valuesi

4 Technical Details

where:

Inferring a web application’s state machine requires con-
cretely deﬁning aspects such as page clustering or navi-
gation. However, we wish to stress that this is one imple-
mentation of the state machine inference algorithm and
it may not be optimal.

4.1 Clustering Similar Pages

Our reason for grouping similar pages together is
twofold: Prevent inﬁnite scanning of the website by
grouping the “inﬁnite” areas together and detect when
the state has changed by comparing page responses in an
efﬁcient manner.

• dompath is the DOM (Document Object Model)

path of the HTML link (anchor or form);

• action is a list where each element is from the href
(for anchors) or action (for forms) attribute split
by ‘/’;

• params is the (potentially empty) set of parameter

names of the form or anchor;

• values is the set of values assigned to the parameters

listed in params.

For instance, an anchor tag with the href attribute of
/user/profile.php?id=0&page might have the fol-
lowing link vector:

4.1.1 Page Model

h/html/body/div/span/a, /user, proﬁle.php, (id, page), (0)i

The output of a web application is usually an HTML
document (it can actually be any arbitrary content, but
we only consider HTML content and HTTP redirects).
An HTML page is composed of navigational informa-
tion (anchors and forms) and user-readable content. For

All link vectors of a page are then stored in a preﬁx
tree. This preﬁx tree is the model of the page. A preﬁx
tree for a simple page with ﬁve links is shown in Fig-
ure 4. The link vector previously described is highlighted
in bold in Figure 4.

APT

(/html/body/div/span/a, /html/body/div/form)

REDIRECT

(/html/body/table/div/a)

(/user, /post)

/messages

(/comments)

(profile.php, edit.php)

show.php

(all.php)

((id, page), (all, sorted), (text, email, id))

(id)

(sorted)

((0), (0, 1), (5), (NULL), (5))

((5), (5, 3), (1), (YES), (10))

(1)

(NULL)

(ASC)

(DSC)

(RAND)

Figure 5: Abstract Page Tree. Every page’s link vector is stored in this preﬁx tree. There are seven pages in this tree.
The page link vector from Figure 4 is highlighted in bold.

HTTP redirects are handled as a special case, where
the only element is a special redirect element having the
target URL as the value of the location attribute.

4.1.2 Page Clustering

To cluster pages, we use a simple but efﬁcient algorithm.
As described in the previous section, the model of a page
is a preﬁx tree representing all the links contained in the
page.

These preﬁx trees are translated into vectors, where
every element of this vector is the set of all nodes of a
given level of the preﬁx tree, starting from the root. At
this point, all pages are represented by a page link vector.
For example, Figure 4 has the following page link vector:

h(/html/body/div/span/a, /html/body/div/form),
(/user, /post),
(proﬁle.php, edit.php),
((id, page), (all, sorted), (text, email, id)),
((0), (0, 1), (5), (NU LL), (5))i

The page link vectors for all pages are then stored in
another preﬁx tree, called the Abstract Page Tree (APT).
In this way, pages are mapped to a leaf of the tree. Pages
which are mapped to the same leaf have identical page
link vectors and are considered to be the same page. Fig-
ure 5 shows an APT with seven pages. The page from
Figure 4 is bold in Figure 5.

However, we want to cluster together pages whose
page link vectors do not match exactly, but are similar
(e.g., shopping cart pages with a different number of el-
ements in the cart). A measure of the similarity between
two pages is how many elements from the beginning of
their link vectors are the same between the two pages.
From the APT perspective, the higher the number of an-
cestors two pages (leaves) share, the closer they are.

Therefore, we create clusters of similar pages by se-
lecting a node in the APT and merging into one cluster,
called an Abstract Page, all the leaves in the correspond-
ing subtree. The criteria for deciding whether to cluster
a subtree of depth n from the root is the following:

• The number of leaves is greater than the median
number of leaves of all its siblings (including itself);
in this way, we cluster only subtrees which have a
larger-than-usual number of leaves.

• There are at least f (n) leaves in the subtree, where
f (n) is inversely related to n. The intuition is that
the fewer ancestors a subtree has in common (the
higher on the preﬁx tree it is), the more pages it must
have to cluster them together. We have found that
the function f (n) = 8(1 + 1
n+1 ) works well by ex-
perimental analysis on a large corpus of web pages.

• The pages share the same dompath and the ﬁrst ele-
ment of the action list of the page link vector; in this
way, all the pages that are clustered together share
the same link structure with potentially different pa-
rameters and values.

4.2 Determine the State-Changing Request

When a state change is detected, we must determine
which request actually changed the web application’s
state. Recall that we detect a state change when we make
a request that is identical to a previous request, yet has
different output. At this point, we have a list of all the
requests made between the latest request R and the re-
quest R′ closest in time to R such that R is identical to R′.
We use a heuristic to determine which request in this list
changed the web application’s state, choosing the request
i between R′ and R which maximizes the function:

score(ni,transition , ni,seen , distancei)

where:

• ni,transition is the number of times the request caused

a state transition;

• ni,seen is the number of times the request has been

made;

• distancei is how many requests have been made be-

tween request R and request i.

The function score is deﬁned as:

score(ni,transition , ni,seen , distancei) =
1 − (1 − ni,transition+1
ni,seen+1

)2 + BOOSTi
distancei+1

BOOSTi is .2 for POST requests and .1 for GET requests.

We construct the score function to capture two prop-

erties of web applications:

1. A POST request is more likely to change the state
than a GET request. This is suggested by the HTTP
speciﬁcation, and score captures this intuition with
BOOSTi.

2. Resistant to errors. Because we cannot prove that
the selected request changed the state, we need to be
resistant to errors. That is why score contains the ra-
tio of ni,transition to ni,seen. In this way, if we acciden-
tally choose the wrong state-changing request once,
but then, later, make that request many times with-
out changing the state, we are less likely to choose
it as a state-changing request.

4.3 Collapsing Similar States

Running the state detection algorithm on a series of re-
quests and responses will tell us when the state has
changed. At this point, we consider each state unique.
This initial state assignment, though, is not optimal, be-
cause even if we encounter a state that we have seen in
the past, we are marking it as new. For example, in the
case of a sequence of login and logout actions, we are
actually ﬂipping between two states, instead of entering
a new state at every login/logout. Therefore, we need
to minimize the number of different states and collapse
states that are actually the same.

The problem of state allocation can be seen as a graph-
coloring problem on a non-planar graph [27]. Let each
state be a node in the graph G. Let two nodes a and b be
connected by an edge (meaning that the states cannot be
the same) if either of the following conditions holds:

1. If a request R was made when the web application
was in states a and b and results in pages in different
clusters. The intuition is that two states cannot be

the same if we make an identical request in each
state yet receive a different response.

2. The two states a and b have no pages in common.
The idea is to err on the conservative side, thus we
require that two states share a page before collaps-
ing the states into one.

After adding the edges to the graph by following the
previous rules, G is colored. States assigned the same
color are considered the same state.

To color the nodes of G, we employ a custom greedy
algorithm. Every node has a unique identiﬁer, which is
the incremental number of the state as we see it in the
request-response list. The nodes are ordered by identi-
ﬁer, and we assign the color to each node in a sequential
way, using the highest color available (i.e., not used by
its neighbors), or a new color if none is available.

This way of coloring the nodes works very well for
state allocation because it takes into account the temporal
locality of states: In particular, we attempt to assign the
highest available color because it is more likely for a state
to be the same as a recently seen state rather than one
seen at the beginning of crawling.

There is one ﬁnal rule that we need to add after the
graph is colored. This rules captures an observation
about transitioning between states: If a request, R, tran-
sitions the web application from state a1 to state b, yet,
later when the web application is in state a2, R transitions
the web application to state c, then a1 and a2 cannot be
the same state. Therefore, we add an edge from a1 to a2
and redo the graph coloring.

We continue enforcing this rule until no additional
edges are added. The algorithm is guaranteed to con-
verge because only new edges are added at every step,
and no edges are ever removed.

At the end of the iteration, the graph coloring output
will determine the ﬁnal state allocation—all nodes with
the same color represent the same state (even if seen at
different stages during the web application crawling pro-
cess).

4.4 Navigating

Typical black-box web vulnerability scanners make con-
current HTTP requests to a web application to increase
performance. However, as we have shown, an HTTP
request can inﬂuence the web application’s state, and,
in this case, all other requests would occur in the new
state. Also, some actions require a multi-step, sequential
process, such as adding items to a shopping cart before
purchasing them. Finally, a user of the web application
does not browse a web application in this parallel fash-
ion, thus, developers assume that the users will browse
sequentially.

def f u z z _ s t a t e _ c h a n g i n g ( f u z z _ r e q u e s t ) :

m a k e _ r e q u e s t ( f u z z _ r e q u e s t )
if s t a t e _ h a s _ c h a n g e d () :

if s t a t e _ i s _ r e v e r s i b l e () :

m a k e _ r e q u e s t s _ t o _ r e v e r t _ s t a t e ()
if not b a c k _ i n _ p r e v i o u s _ s t a t e () :

r e s e t _ a n d _ p u t _ i n _ p r e v i o u s _ s t a t e ()

else :

r e s e t _ a n d _ p u t _ i n _ p r e v i o u s _ s t a t e ()

Listing 1:
request.

Psuedocode for

fuzzing state-changing

Our scanner navigates a web application by mimicking
a user browsing the web application sequentially. Brows-
ing sequentially not only allows us to follow the devel-
oper’s intended path through the web application, but it
enables us to detect which requests changed the web ap-
plication’s state.

Thus, a state-aware crawler must navigate the applica-
tion sequentially. No concurrent requests are made, and
only anchors and forms present in the last visited page
are used to determine the next request.
In the case of
a page with no outgoing links we go back to the initial
page.

Whenever the latest page does not contain unvisited
links, the crawler will choose a path from the current
page towards another page already seen that contains
links that have not yet been visited. If there is no path
from the current page to anywhere, we go back to the
initial page. The criteria for choosing this path is based
on the following intuitions:

• We want to explore as much of the current state as
possible before changing the state, therefore we se-
lect links that are less likely to cause a state transi-
tion.

• When going from the current page to a page with an
unvisited link, we will repeat requests. Therefore,
we should choose a path that contains links that we
have visited infrequently. This give us more infor-
mation about the current state.

The exact algorithm we employ is Dijkstra Shortest
Path Algorithm [14] with custom edge length. This edge
length increases with the number of times we have previ-
ously visited that link. Finally, the edge length increases
with how likely the link is to cause a state change.

5 State-Aware Fuzzing

After we crawl the web application, our system has in-
ferred, as much as possible, the web application’s state
machine. We use the state machine information, along
with the list of request–responses made by the crawler, to

drive a state-aware fuzzing of the web application, look-
ing for security vulnerabilities.

To fuzz the application in a state-aware manner, we
need the ability to reset the web application to the initial
state (the state when we started crawling). We do not use
this ability when crawling, only when fuzzing. It is nec-
essary to reset the application when we are fuzzing an
irreversible state-changing request. Using the reset func-
tionality, we are able to recover from these irreversible
state changes.

Adding the ability to reset the web application does
not break the black-box model of the web application.
Resetting requires no knowledge of the web application,
and can be easily performed by running the web applica-
tion in a virtual machine.

Our state-aware fuzzing starts by resetting the web ap-
plication to the initial state. Then we go through the re-
quests that the crawler made, starting with the initial re-
quest. If the request does not change the state, then we
fuzz the request as a typical black-box scanner. However,
if the request is state-changing, we follow the algorithm
shown in Listing 1. The algorithm is simple: We make
the request, and if the state has changed, traverse the in-
ferred state machine to ﬁnd a series of requests to tran-
sition the web application to the previous state. If this
does not exist, or does not work, then we reset the web
application to the initial state, and make all the previ-
ous requests that the crawler made. This ensures that the
web application is in the proper state before continuing
to fuzz.

Our state-aware fuzzing approach can use any fuzzing
component. In our implementation, we used the fuzzing
plugins of an open-source scanner, w3af [37]. The
fuzzing plugins take an HTTP request and generate vari-
ations on that request looking for different vulnerabili-
ties. Our state-aware fuzzing makes those requests while
checking that the state does not unintentionally change.

6 Evaluation

As shown in previous research [16], fairly evaluating
black-box web vulnerability scanners is difﬁcult. The
most important, at least to end users, metric for compar-
ing black-box web vulnerability scanners is true vulner-
abilities discovered. Comparing two scanners that dis-
cover different vulnerabilities is nearly impossible.

There are two other metrics that we use to evaluate

black-box web vulnerability scanners:

• False Positives. The number of spurious vulnera-
bilities that a black-box web vulnerability scanner
reports. This measures the accuracy of the scan-
ner. False positives are a serious problem for the
end user of the scanner—if the false positives are

Application
Gallery
PhpBB v2
PhpBB v3
SCARF
Vanilla Forums
WackoPicko v2
WordPress v2
WordPress v3

Description
Photo hosting.
Discussion forum.
Discussion forum.
Stanford conference and research forum.
Discussion forum.
Intentionally vulnerable web application.
Blogging platform.
Blogging platform.

Version
3.0.2
2.0.4
3.0.10
2007-02-27
2.0.17.10
2.0
2.0
3.2.1

Lines of Code
26,622
16,034
110,186
798
43,880
900
17,995
71,698

Table 1: Applications that we ran the crawlers against to measure vulnerabilities discovered and code coverage.

high, the user must manually inspect each vulner-
ability reported to determine the validity. This re-
quires a security-conscious user to evaluate the re-
ports. Moreover, false positives erode the user’s
trust in the tool and make the user less likely to use
it in the future.

• Code Coverage. The percentage of the web appli-
cation’s code that the black-box web vulnerability
scanner executes while it crawls and fuzzes the ap-
plication. This measures how effective the scanner
is in exercising the functionality of the web applica-
tion. Moreover, code coverage is an excellent met-
ric for another reason: A black-box web vulnera-
bility scanner, by nature, cannot ﬁnd a vulnerability
along a code path that it does not execute. There-
fore, greater code coverage means that a scanner
has the potential to discover more vulnerabilities.
Note that this is orthogonal to fuzzing capability:
A fuzzer—no matter how effective—will never be
able to discover a vulnerability on a code path that
it does not execute.

We use both the metrics previously described in our
evaluation. However, our main focus is on code cover-
age. This is because a scanner with greater code cover-
age will be able to discover more vulnerabilities in the
web application.

However, code coverage is not a perfect metric. Evalu-
ating raw code coverage percentage numbers can be mis-
leading. Ten percent code coverage of an application
could be horrible or excellent depending on how much
functionality the application exposes. Some code may
be intended only for installation, may be only for ad-
ministrators, or is simply dead code and cannot be ex-
ecuted. Therefore, comparing code coverage normalized
to a baseline is more informative, and we use this in our
evaluation.

6.1 Experiments

We evaluated our approach by running our state-aware-
scanner along with three other vulnerability scanners

Scanner Description
wget

GNU command-line
website downloader.

w3af Web Application At-
tack and Audit Frame-
work.

skipﬁsh Open-source,

high-
performance vulnera-
bility scanner.
Our state-aware vul-
nerability scanner.

state-
aware-
scanner

Language
C

Version
1.12

Python

1.0-stable

C

2.03b

Python

1.0

Table 2: Black-box web vulnerability scanners that we
compared.

against eight web applications. These web applications
range in size, complexity, and functionality. In the rest of
this section, we describe the web applications, the black-
box web vulnerability scanners, and the methodology we
used to validate our approach.

6.1.1 Web Applications

Table 1 provides an overview of the web applications
used with a short description, a version number, and lines
of executable PHP code for each application. Because
our approach assumes that the web application’s state
changes only via requests from the user, we made slight
code modiﬁcations to three web applications to reduce
the inﬂuence of external, non-user driven, forces, such as
time. Please refer to Appendix A for a detailed descrip-
tion of each application and what was changed.

6.1.2 Black-Box Web Vulnerability Scanners

This section describes the black-box web vulnerability
scanners that were compared against our approach, along
with the conﬁguration or settings that were used. Ta-
ble 2 contains a short description of each scanner, the
scanner’s programming language, and the version num-
ber. Appendix B shows the exact conﬁguration that was
used for each scanner.

wget is a free and open-source application that is used
to download ﬁles from a web application. While not a
vulnerability scanner, wget is a crawler that will make
all possible GET requests it can ﬁnd. Thus, it provides an
excellent baseline because vulnerability scanners make
POST requests as well as GET requests and should dis-
cover more of the application than wget.

wget is launched with the following options: recur-

sive, download everything, and ignore robots.txt.
w3af is an open-source black-box web vulnerability
scanner which has numerous fuzzing modules. We en-
abled the blindSqli, eval, localFileInclude, osCommand-
ing, remoteFileInclude, sqli, and xss fuzzing plugins.
skipﬁsh is an open-source black-box web vulnerability
scanner whose focus is on high speed and high perfor-
mance. Skipﬁsh epitomizes the “shotgun” approach, and
boasts about making more than 2,000 requests per sec-
ond to a web application on a LAN. Skipﬁsh also at-
tempts to guess, via a dictionary or brute-force, directory
names. We disabled this behavior to be fair to the other
scanners, because we do not want to test the ability to
guess a hidden directory, but how a scanner crawls a web
application.
state-aware-scanner is our state-aware black-box vul-
nerability scanner. We use HtmlUnit [19] to issue the
HTTP requests and render the HTML responses. Af-
ter crawling and building the state-graph, we utilize the
fuzzing plugins from w3af to generate fuzzing requests.
Thus, any improvement in code coverage of our crawler
over w3af is due to our state-aware crawling, since the
fuzzing components are identical.

6.1.3 Methodology

We ran each black-box web vulnerability scanner against
a distinct, yet identical, copy of each web application.
We ran all tests on our local cloud [34].

Gallery, WordPress v2, and WordPress v3 do not re-
quire an account to interact with the website, thus each
scanner is simply told to scan the test application.

For the remaining applications (PhpBB v2, PhpBB v3,
SCARF, Vanilla Forums, and WackoPicko v2), it is difﬁ-
cult to fairly determine how much information to give the
scanners. Our approach only requires a username/pass-
word for the application, and by its nature will discover
the requests that log the user out, and recover from them.
However, other scanners do not have this capability.

Thus, it is reasonable to test all scanners with the same
level of information that we give our scanner. However,
the other scanners lack the ability to provide a username
and password. Therefore, we did the next best thing: For
those applications that require a user account, we log into
the application and save the cookie ﬁle. We then instruct

the scanner to use this cookie ﬁle while scanning the web
application.

While we could do more for the scanners, like prevent-
ing them from issuing the logout request for each appli-
cation, we believe that our approach strikes a fair com-
promise and allows each scanner to decide how to crawl
the site. Preventing the scanners from logging out of the
application also limits the amount of the application they
will see, as they will never see the web application from
a guest’s perspective.

6.2 Results

Table 3 shows the results of each of the black-box web
vulnerability scanners against each web application. The
column “% over Baseline” displays the percentage of
code coverage improvement of the scanner against the
wget baseline, while the column “Vulnerabilities” shows
total number of reported vulnerabilities, true positives,
unique true positives among the scanners, and false pos-
itives.

The prototype implementation of our state-aware-
scanner had the best code coverage for every application.
This veriﬁes the validity of our algorithm: Understand-
ing state is necessary to better exercise a web application.
Figure 6 visually displays the code coverage percent
improvement over wget. The most important thing to
take from these results is the improvement state-aware-
scanner has over w3af. Because we use the fuzzing com-
ponent of w3af, the only difference is in our state-aware
crawling. The results show that this gives state-aware-
scanner an increase in code coverage from as little as half
a percent to 140.71 percent.

Our crawler discovered three unique vulnerabilities,
one each in PhpBB v2, SCARF, and WackoPicko v2.
The SCARF vulnerability is simply a XSS injection on
the comment form. w3af logged itself out before fuzzing
the comment page. skipﬁsh ﬁled the vulnerable page un-
der “Response varies randomly, skipping checks.” How-
ever, the content of this page does not vary randomly, it
varies because skipﬁsh is altering it. This random cate-
gorization also prevents skipﬁsh from detecting the sim-
ple XSS vulnerability on WackoPicko v2’s guestbook.
This result shows that a scanner needs to understand the
web application’s internal state to properly decide why a
page’s content is changing.

Skipﬁsh was able to discover 15 vulnerabilities in
Vanilla Forums. This is impressive, however, 14 stem
from a XSS injection via the referer header on an error
page. Thus, even though these 14 vulnerabilities are on
different pages, it is the same root cause.

Surprisingly, our scanner produced less false positives
than w3af. All of w3af’s false positives were due to
faulty timing detection of SQL injection and OS com-

Scanner

Application

% over Baseline

Vulnerabilities

state-aware-scanner Gallery
Gallery
w3af
Gallery
skipﬁsh
wget
Gallery
PhpBB v2
state-aware-scanner
PhpBB v2
skipﬁsh
PhpBB v2
w3af
wget
PhpBB v2
PhpBB v3
state-aware-scanner
PhpBB v3
skipﬁsh
PhpBB v3
w3af
PhpBB v3
wget
state-aware-scanner
SCARF
SCARF
skipﬁsh
SCARF
w3af
wget
SCARF
state-aware-scanner Vanilla Forums
Vanilla Forums
w3af
Vanilla Forums
wget
skipﬁsh
Vanilla Forums
state-aware-scanner WackoPicko v2
skipﬁsh
WackoPicko v2
WackoPicko v2
w3af
wget
WackoPicko v2
state-aware-scanner WordPress v2
WordPress v2
w3af
wget
WordPress v2
skipﬁsh
WordPress v2
state-aware-scanner WordPress v3
WordPress v3
w3af
skipﬁsh
WordPress v3
WordPress v3
wget

16.20%
15.77%
10.96%
0%
38.34%
5.10%
1.04%
0%
115.45%
60.21%
16.16%
0%
67.03%
55.66%
21.55%
0%
30.89%
1.06%
0%
-2.32%
241.86%
194.77%
101.15%
0%
14.49%
12.49%
0%
-18.34%
9.84%
9.23%
3.89%
0%

Reported
0
3
0

True Unique
0
0
0

0
0
0

False
0
3
0

4
3
5

0
2
0

1
0
0

0
0

17
5
4
5

0
0

1
0
3
1

3
2
1

0
0
0

1
0
0

0
0

15
5
3
5

0
0

0
0
0
0

1
0
0

0
0
0

1
0
0

0
0

2
1
1
1

0
0

0
0
0
0

1
1
4

0
2
0

0
0
0

0
0

2
0
1
0

0
0

1
0
3
1

Table 3: Results of each of the black-box web vulnerability scanners against each application. The table is sorted by
the percent increase in code coverage over the baseline scanner, wget.

manding. We believe that using HtmlUnit prevented
our scanner from detecting these spurious vulnerabili-
ties, even though we use the same fuzzing component
as w3af.

Finally, our approach inferred the state machines of
the evaluated applications. These state machines are very
complex in the large applications. This complexity is
because modern, large, application have many actions
which modify the state. For instance, in WackoPicko v2,
a user can log in, add items to their cart, comment on
pictures, delete items from their cart, log out of the appli-
cation, register as a new user, comment as this new user,
upload a picture, and purchase items. All of these ac-
tions interact to form a complex state machine. The state
machine our scanner inferred captures this complex se-
ries of state changes. The inferred WackoPicko v2 state
machine is presented in Figure 7.

7 Limitations

Although dynamic page generation via JavaScript is sup-
ported by our crawler as allowed by the HtmlUnit frame-
work [19], proper AJAX support is not implemented.
This means that our prototype executes JavaScript when
the page loads, but does not execute AJAX calls when
clicking on links.

Nevertheless, our approach could be extended to han-
dle AJAX requests. In fact, any interaction with the web
application always contains a request and response, how-
ever the content of the response is no longer an HTML
page. Thus, we could extend our notion of a “page” to
typical response content of AJAX calls, such as JSON or
XML. Another way to handle AJAX would be to follow
a Crawljax [33] approach and covert the dynamic AJAX
calls into static pages.

state-aware-scanner
w3af
skipﬁsh

250%

230%

210%

190%
120%

100%

80%

60%

40%

20%

0%

-20%

t
e
g
w

r
e
v
O

t
n
e
m
e
v
o
r
p
m

I

e
g
a
t
n
e
c
r
e
P

G

allery

Php

B

B

v2

Php

B

B

v3

S

C

A

R

F

Vanilla

ackoPicko

v2

Foru

ms

W

W

W

ordPress

ordPress

v2

v3

Figure 6: Visual representation of the percentage increase of code coverage over the baseline scanner, wget. Important
to note is the gain our scanner, state-aware-scanner, has over w3af, because the only difference is our state-aware
crawling. The y-axis range is broken to reduce the distortion of the WackoPicko v2 results.

Another limitation of our approach is that our scanner
cannot be used against a web application being accessed
by other users (i.e., a public web application), because
the other users may inﬂuence the state of the application
(e.g., add a comment on a guestbook) and confuse our
state change detection algorithm.

8 Related Work

Automatic or semi-automatic web application vulnera-
bility scanning has been a hot topic in research for many
years because of its relevance and its complexity.

Huang et al. developed a tool (WAVES) for assess-
ing web application security with which we share many
points [24]. Similarly to us, they have a scanner for ﬁnd-
ing the entry points in the web application by mimicking
the behavior of a web browser. They employ a learn-
ing mechanism to sensibly ﬁll web form ﬁelds and al-
low deep crawling of pages behind forms. Attempts to
discover vulnerabilities are carried out by submitting the
same form multiple times with valid, invalid, and faulty
inputs, and comparing the result pages. Differently from
WAVES, we are using the knowledge gathered by the
ﬁrst-phase scanner to help the fuzzer detect the effect of
a given input. Moreover, our ﬁrst-phase scanner aims not
only at ﬁnding relevant entry-points, but rather at build-
ing a complete state-aware navigational map of the web
application.

A number of tools have been developed to try to au-
tomatically discover vulnerabilities in web applications,
produced as academic prototypes [4,17,22,25,28,29,31],
as open-source projects [8,9,37], or as commercial prod-
ucts [1, 23, 26, 35].

Multiple projects [6,16,42,43] tackled the task of eval-
uating the effectiveness of popular black-box scanners
(in some cases also called point-and-shoot scanners).
The common theme in their results is a relevant discrep-
ancy in vulnerabilities found across scanners, along with
low accuracy. Authors of these evaluations acknowledge
the difﬁculties and challenges of the task [21, 43].
In
particular, we highlighted how more deep crawling and
reverse engineering capabilities of web applications are
needed in black-box scanners, and we also developed the
WackoPicko web application which contains known vul-
nerabilities [16]. Similarly, Bau et al. investigated the
presence of room for research in this area, and found im-
provement is needed, in particular for detecting second-
order XSS and SQL injection attacks [6].

Reverse engineering of web applications has not been
widely explored in the literature,
to our knowledge.
Some approaches [13] perform static analysis on the
code to create UML diagrams of the application.

Static analysis, in fact, is the technique mostly em-
ployed for automatic vulnerability detection, often com-
bined with dynamic analysis.

385

POST /cart/action.php?action=purchase

397

GET /users/logout.php

400

POST /users/login.php

POST /users/register.php

POST /passcheck.php

POST /comments/add_comment.php

325

471

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

GET /users/logout.php

POST /passcheck.php

POST /passcheck.php

POST /users/login.php

POST /users/register.php

523

417

726

POST /users/login.php

POST /users/register.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

424

POST /comments/add_comment.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /users/login.php

POST /users/register.php

543

POST /comments/add_comment.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

549

0

93

GET /users/logout.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /passcheck.php

GET /users/logout.php

POST /users/login.php

POST /users/register.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

147

1536

91

POST /comments/add_comment.php

POST /users/login.php

POST /users/register.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /users/login.php

POST /users/register.php

POST /cart/action.php?action=purchase

780

879

POST /comments/add_comment.php

GET /users/logout.php

794

1615

POST /comments/add_comment.php

POST /users/login.php

POST /users/register.php

813

231

POST /comments/add_comment.php

POST /comments/add_comment.php

POST /comments/add_comment.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

350

261

970

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /cart/action.php?action=delete

GET /users/logout.php

POST /cart/action.php?action=purchase

POST /cart/action.php?action=delete

POST /passcheck.php

290

1641

169

POST /users/login.php

POST /users/register.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /comments/add_comment.php

POST /cart/action.php?action=purchase

POST /comments/add_comment.php

POST /comments/add_comment.php

GET /users/logout.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /comments/add_comment.php

1725

1669

904

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /users/login.php

POST /users/register.php

1055

POST /comments/add_comment.php

874

GET /users/logout.php

200

899

POST /comments/add_comment.php

POST /users/login.php

POST /users/register.php

POST /users/login.php

POST /users/register.php

GET /users/logout.php

GET /users/logout.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

1735

907

1157

1240

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

GET /users/logout.php

POST /cart/action.php?action=delete

857

POST /comments/add_comment.php

1328

1248

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

1756

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

1769

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

1782

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /cart/action.php?action=purchase

GET /users/logout.php

POST /users/login.php

POST /users/register.php

GET /users/logout.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

GET /users/logout.php

884

1256

POST /comments/add_comment.php

GET /cart/action.php?action=add&picid=7
GET /cart/action.php?action=add&picid=8
GET /cart/action.php?action=add&picid=9
GET /cart/action.php?action=add&picid=14
GET /cart/action.php?action=add&picid=15

POST /comments/add_comment.php

POST /users/login.php

POST /users/register.php

1389

889

POST /comments/add_comment.php

894

Figure 7: State machine that state-aware-scanner inferred for WackoPicko v2.

Halfond et al. developed a traditional black-box vul-
nerability scanner, but improved its result by leveraging
a static analysis technique to better identify input vec-
tors [22].

Pixy [28] employed static analysis with taint propa-
gation in order to detect SQL injection, XSS and shell
command injection, while Saner [4] used sound static
analysis to detect failures in sanitization routines. Saner
also takes advantage of a second phase of dynamic anal-
ysis to reduce false positives. Similarly, WebSSARI [25]
also employed static analysis for detecting injection vul-
nerabilities, but, in addition, it proposed a technique for
runtime instrumentation of the web application through
the insertion of proper sanitization routines.

Felmetsger et al. investigated an approach for detect-
ing a different type of vulnerability (some categories of
logic ﬂaws) by combining execution traces and symbolic
model checking [17]. Similar approaches are also used
for generic bug ﬁnding (in fact, vulnerabilities could be
considered a subset of the general bug category). Csall-
ner et al. employ dynamic traces for bug ﬁnding and for
dynamic veriﬁcation of the alerts generated by the static
analysis phase [12]. Artzi et al., on the other hand, use
symbolic execution and model checking for ﬁnding gen-
eral bugs in web applications [3].

On a completely separate track, efforts to improve web
application security push the developers toward writing
secure code in the ﬁrst place. Security experts are ty-

ing to achieve this goal by either educating the devel-
opers [40] or designing frameworks which prohibit the
use of bad programming practices and enforce some se-
curity constraints in the code. Robertson and Vigna de-
veloped a strongly-typed framework which statically en-
forces separation between structure and content of a web
page, preventing XSS and SQL injection [38]. Also
Chong et al. designed their language for developers to
build web applications with strong conﬁdentiality and
integrity guarantees, by means of compile-time and run-
time checks [10].

Alternatively, consequences of vulnerabilities in web
applications can be mitigated by trying to prevent the
attacks before they reach some potentially vulnerable
code, like, for example, in the already mentioned Web-
SSARI [25] work. A different approach for blocking at-
tacks is followed by Scott and Sharp, who developed a
language for specifying a security policy for the web ap-
plication; a gateway will then enforce these policies [39].
Another interesting research track deals with the prob-
lem of how to explore web pages behind forms, also
called the hidden web [36]. McAllister et al. monitor
user interactions with a web application to collect sen-
sible values for HTML form submission and generate
test cases that can be replayed to increase code cover-
age [32]. Although not targeted to security goals, the
work of Raghavan and Garcia-Molina is relevant for our
project for their contribution in classiﬁcation of different
types of dynamic content and for their novel approach
for automatically ﬁlling forms by deducing the domain
of form ﬁelds [36]. Raghavan and Garcia-Molina car-
ried out further research in this direction, by reconstruct-
ing complex and hierarchical query interfaces exposed
by web applications.

Moreover, Amalﬁtano et al. started tackling the prob-
lem of reverse engineering the state machine of client-
side AJAX code, which will help in ﬁnding the web ap-
plication server-side entry points and in better understat-
ing complex and hierarchical query interfaces [2].

Finally, we need to mention the work by Berg et al.
in reversing state machines into a Symbolic Mealy Ma-
chine (SMM) model [7]. Their approach for reversing
machines cannot be directly applied to our case because
of the infeasibility of fully exploring all pages for all the
states, even for a small subset of the possible states. Nev-
ertheless, the model they propose for a SMM ﬁts our
needs.

9 Conclusion

We have described a novel approach to inferring, as
much as possible, a web application’s internal state ma-
chine. We leveraged the state machine to drive the state-
aware fuzzing of web applications. Using this approach,

our crawler is able to crawl—and thus fuzz—more of the
web application than a classical state-agnostic crawler.
We believe our approach to detecting state change by dif-
ferences in output for an identical response is valid and
should be adopted by all black-box tools that wish to un-
derstand the web application’s internal state machine.

Acknowledgements

This work was supported by the Ofﬁce of Naval Research
(ONR) under Grant N000141210165, the National Sci-
ence Foundation (NSF) under grant CNS-1116967, and
by Secure Business Austria.

References

[1] ACUNETIX. Acunetix Web Vulnerbility Scanner. http://www.

acunetix.com/.

[2] AMALFITANO, D., FASOLINO, A., AND TRAMONTANA, P. Re-
verse Engineering Finite State Machines from Rich Internet Ap-
plications. In 2008 15th Working Conference on Reverse Engi-
neering (2008), IEEE, pp. 69–73.

[3] ARTZI, S., KIEZUN, A., DOLBY, J., TIP, F., DIG, D., PARAD-
KAR, A., AND ERNST, M. Finding bugs in web applications
using dynamic test generation and explicit state model checking.
IEEE Transactions on Software Engineering (2010).

[4] BALZAROTTI, D., COVA, M., FELMETSGER, V., JOVANOVIC,
N., KIRDA, E., KRUEGEL, C., AND VIGNA, G. Saner: Com-
posing Static and Dynamic Analysis to Validate Sanitization in
Web Applications.
In 2008 IEEE Symposium on Security and
Privacy (2008), IEEE, pp. 387–401.

[5] BALZAROTTI, D., COVA, M., FELMETSGER, V., AND VIGNA,
G. Multi-module Vulnerability Analysis of Web-based Applica-
tions. In Proceedings of the ACM conference on Computer and
Communications Security (CCS) (2007), pp. 25–35.

[6] BAU, J., BURSZTEIN, E., GUPTA, D., AND MITCHELL, J. State
of the Art: Automated Black-Box Web Application Vulnerability
Testing. In Security and Privacy (SP), 2010 IEEE Symposium on
(2010), IEEE, pp. 332–345.

[7] BERG, T., JONSSON, B., AND RAFFELT, H. Regular Inference
for State Machines using Domains with Equality Tests. In Pro-
ceedings of the Theory and practice of software, 11th interna-
tional conference on Fundamental approaches to software engi-
neering (2008), Springer-Verlag, pp. 317–331.

[8] BYRNE, D. Grendel-Scan.

http://www.grendel-scan.

com/.

[9] CHINOTEC TECHNOLOGIES.

Paros.

http://www.

parosproxy.org/.

[10] CHONG, S., VIKRAM, K., AND MYERS, A. SIF: Enforcing con-
ﬁdentiality and integrity in web applications. In Proceedings of
16th USENIX Security Symposium on USENIX Security Sympo-
sium (2007), USENIX Association, p. 1.

[11] COVA, M., BALZAROTTI, D., FELMETSGER, V., AND VIGNA,
G. Swaddler: An Approach for the Anomaly-based Detection of
State Violations in Web Applications. In Proceedings of the Inter-
national Symposium on Recent Advances in Intrusion Detection
(RAID 2007) (2007), pp. 63–86.

[12] CSALLNER, C., SMARAGDAKIS, Y., AND XIE, T. DSD-
Crasher: A hybrid analysis tool for bug ﬁnding. ACM Trans-
actions on Software Engineering and Methodology (TOSEM) 17,
2 (2008), 1–37.

[13] DI LUCCA, G., FASOLINO, A., PACE, F., TRAMONTANA, P.,
AND DE CARLINI, U. WARE: a tool for the reverse engi-
neering of Web applications.
In Sixth European Conference
on Software Maintenance and Reengineering, 2002. Proceedings
(2002), pp. 241–250.

[14] DIJKSTRA, E. W. A Note on Two Problems in Connexion with

Graphs. Numerische Mathematik 1 (1959), 269–271.

[15] DOUP ´E, A., BOE, B., KRUEGEL, C., AND VIGNA, G. Fear
the EAR: Discovering and Mitigating Execution After Redirect
Vulnerabilities. In Proceedings of the 18th ACM Conference on
Computer and Communications Security (CCS 2011) (Chicago,
IL, October 2011).

[16] DOUP ´E, A., COVA, M., AND VIGNA, G. Why Johnny Can’t
Pentest: An Analysis of Black-box Web Vulnerability Scanners.
In Detection of Intrusions and Malware, and Vulnerability As-
sessment (DIMVA 2010) (2010), Springer, pp. 111–131.

[17] FELMETSGER, V., CAVEDON, L., KRUEGEL, C., AND VIGNA,
G. Toward Automated Detection of Logic Vulnerabilities in Web
Applications. In Proceedings of the USENIX Security Symposium
(Washington, DC, August 2010).

[18] FOSSI, M. Symantec Global Internet Security Threat Report.

Tech. rep., Symantec, April 2009. Volume XIV.

[31] LI, X., YAN, W., AND XUE, Y. SENTINEL: Securing Database
In CODASPY (2012),

from Logic Flaws in Web Applications.
pp. 25–36.

[32] MCALLISTER, S., KIRDA, E., AND KRUEGEL, C. Leverag-
ing User Interactions for In-Depth Testing of Web Applications.
In Recent Advances in Intrusion Detection (2008), Springer,
pp. 191–210.

[33] MESBAH, A., BOZDAG, E., AND VAN DEURSEN, A. Crawling
AJAX by Inferring User Interface State Changes.
In Web En-
gineering, 2008. ICWE ’08. Eighth International Conference on
(july 2008), pp. 122 –134.

[34] NURMI, D., WOLSKI, R., GRZEGORCZYK, C., OBERTELLI,
G., SOMAN, S., YOUSEFF, L., AND ZAGORODNOV, D. The
Eucalyptus Open-Source Cloud-Computing System. In Cluster
Computing and the Grid, 2009. CCGRID ’09. 9th IEEE/ACM In-
ternational Symposium on (may 2009), pp. 124 –131.

[35] PORTSWIGGER. Burp Proxy. http://www.portswigger.

net/burp/.

[36] RAGHAVAN, S., AND GARCIA-MOLINA, H. Crawling the hid-
den web. In Proceedings of the International Conference on Very
Large Data Bases (2001), Citeseer, pp. 129–138.

[37] RIANCHO, A. w3af – Web Application Attack and Audit Frame-

[19] GARGOYLE SOFTWARE INC. HtmlUnit. http://htmlunit.

work. http://w3af.sourceforge.net/.

sourceforge.net/.

[20] GARRETT, J. J. Ajax: A New Approach to Web Appli-
http://www.adaptivepath.com/ideas/essays/

cations.
archives/000385.php, Feb. 2005.

[21] GROSSMAN, J. Challenges of Automated Web Application Scan-

ning. Blackhat Windows 2004, 2004.

[22] HALFOND, W., CHOUDHARY, S., AND ORSO, A. Penetration
testing with improved input vector identiﬁcation.
In Software
Testing Veriﬁcation and Validation, 2009. ICST’09. International
Conference on (2009), IEEE, pp. 346–355.

[38] ROBERTSON, W., AND VIGNA, G.

Static Enforcement of
Web Application Integrity Through Strong Typing. In Proceed-
ings of the USENIX Security Symposium (Montreal, Quebec CA,
September 2009).

[39] SCOTT, D., AND SHARP, R. Abstracting application-level web
security. In Proceedings of the 11th international conference on
World Wide Web (2002), ACM, pp. 396–407.

[40] SPI DYNAMICS. Complete Web Application Security: Phase
1 – Building Web Application Security into Your Development
Process. SPI Dynamics Whitepaper, 2002.

[23] HP. WebInspect. https://download.hpsmartupdate.com/

[41] STEVE, C., AND MARTIN, R. Vulnerability Type Distributions

webinspect/.

in CVE. Mitre report, May (2007).

[42] SUTO, L. Analyzing the Accuracy and Time Costs of Web Ap-

plication Security Scanners, 2010.

[43] VIEIRA, M., ANTUNES, N., AND MADEIRA, H. Using Web
Security Scanners to Detect Vulnerabilities in Web Services. In
Dependable Systems & Networks, 2009. DSN’09. IEEE/IFIP In-
ternational Conference on (2009), IEEE, pp. 566–571.

[24] HUANG, Y.-W., HUANG, S.-K., LIN, T.-P., AND TSAI, C.-H.
Web application security assessment by fault injection and behav-
ior monitoring. In Proceedings of the 12th international confer-
ence on World Wide Web (New York, NY, USA, 2003), WWW
’03, ACM, pp. 148–159.

[25] HUANG, Y.-W., YU, F., HANG, C., TSAI, C.-H., LEE, D.-
T., AND KUO, S.-Y. Securing web application code by static
analysis and runtime protection.
In WWW ’04: Proceedings of
the 13th international conference on World Wide Web (New York,
NY, USA, 2004), ACM, pp. 40–52.

[26] IBM.

AppScan.

http://www-01.ibm.com/software/

awdtools/appscan/.

[27] JENSEN, T. R., AND TOFT, B. Graph Coloring Problems.
Wiley-Interscience Series on Discrete Mathematics and Opti-
mization. Wiley, 1994.

[28] JOVANOVIC, N., KRUEGEL, C., AND KIRDA, E. Static anal-
ysis for detecting taint-style vulnerabilities in web applications.
Journal of Computer Security 18, 5 (2010), 861–907.

[29] KALS, S., KIRDA, E., KRUEGEL, C., AND JOVANOVIC, N.
Secubat: a Web Vulnerability Scanner.
In Proceedings of the
15th international conference on World Wide Web (2006), ACM,
pp. 247–256.

[30] LI, X., AND XUE, Y. BLOCK: A Black-box Approach for De-
tection of State Violation Attacks Towards Web Applications. In
Proceedings of the Annual Computer Security Applications Con-
ference (ACSAC 2011) (Orlando, FL, December 2011).

sion 2 contains minor tweaks from the original paper, but
no additional functionality.
WordPress v2 is an open-source blogging platform. An
administrator can create blog posts, where guests can
leave comments. No changes were made to this appli-
cation.
WordPress v3 is an up-to-date version of the open-
source blogging platform. Just like the previous version,
administrators can create blog posts, while a guest can
comment on blog posts. No changes were made to this
application.

B Scanner Conﬁguration

The following describes the exact settings that were used
to run each of the evaluated scanners.

• wget is run in the following way:

wget -rp -w 0 --waitretry=0 -nd

--delete-after --execute robots=off

• w3af settings:

misc-settings
set maxThreads 0
back
plugins
discovery webSpider
audit blindSqli, eval,

localFileInclude, osCommanding,
remoteFileInclude, sqli, xss

• skipﬁsh is run in the following way:

skipfish -u -LV -W /dev/null -m 10

A Web Applications

This section describes the web applications along with
the functionality against which we ran the black-box web
vulnerability scanner.

Gallery is an open-source photo hosting application.
The administrator can upload photos and organize them
into albums. Guests can then view and comment on
the uploaded photos. Gallery has AJAX functional-
ity but gracefully degrades (is fully functional) without
JavaScript. No modiﬁcations were made to the applica-
tion.

PhpBB v2 is an open-source forum software. It allows
registered users to perform many actions such as cre-
ate new threads, comment on threads, and message other
users. Version 2 is notorious for the amount of security
vulnerabilities it contains [6], and we included it for this
reason. We modiﬁed it to remove the “recently online”
section on pages, because this section is based on time.

PhpBB v3 is the latest version of the popular open-
source forum software.
It is a complete rewrite from
Version 2, but retains much of the same functionality.
Similar to PhpBB v2, we removed the “recently online”
section, because it is time-based.

SCARF, the Stanford Conference And Research Fo-
rum,
is an open-source conference management sys-
tem. The administrator can upload papers, and regis-
tered users can comment on the uploaded papers. We
included this application because it was used by previ-
ous research [5, 11, 30, 31]. No modiﬁcations were made
to this application.

Vanilla Forums is an open-source forum software sim-
ilar in functionality to PhpBB. Registered users can cre-
ate new threads, comment on threads, bookmark in-
teresting threads, and send a message to another user.
Vanilla Forums is unique in our test set in that it uses
the path to pass parameters in a URL, whereas all other
applications pass parameters using the query part of
the URL. For instance, a speciﬁc user’s proﬁle is GET
/profile/scanner1, while a discussion thread is lo-
cated at GET /discussion/1/how-to-scan. Vanilla
Forums also makes extensive use of AJAX, and does not
gracefully degrade without JavaScript. For instance, with
JavaScript disabled, posting a comment returns a JSON
object that contains the success or failure of the com-
ment posting, instead of an HTML response. We modi-
ﬁed Vanilla Forums by setting an XSRF token that it used
to a constant value.

WackoPicko v2 is an open-source intentionally vulnera-
ble web application which was originally created to eval-
uate many black-box web vulnerability scanners [16]. A
registered user can upload pictures, comment on other
user’s pictures, and purchase another user’s picture. Ver-

