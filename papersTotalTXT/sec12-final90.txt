Optimally Robust Private Information Retrieval∗

Casey Devet

Ian Goldberg

University of Waterloo

{cjdevet,iang}@cs.uwaterloo.ca

Nadia Heninger

University of California, San Diego

nadiah@cs.ucsd.edu

Abstract

We give a protocol for multi-server information-theoretic
private information retrieval which achieves the theoret-
ical limit for Byzantine robustness. That is, the protocol
can allow a client to successfully complete queries and
identify server misbehavior in the presence of the max-
imum possible number of malicious servers. We have
implemented our scheme and it is extremely fast in prac-
tice: up to thousands of times faster than previous work.
We achieve these improvements by using decoding al-
gorithms for error-correcting codes that take advantage
of the practical scenario where the client is interested in
multiple blocks of the database.

1

Introduction and related work

Private information retrieval (PIR) is a way for a client
to look up information in an online database without let-
ting the database servers learn the query terms or re-
sponses. A simple if inefﬁcient way to do this is for the
database server to send a copy of the entire database to
the client, and let the client look up the information for
herself. This is called trivial download. The goal of PIR
is to transmit less data while still protecting the privacy
of the query. PIR is a fundamental building block for
many proposed privacy-sensitive applications in the liter-
ature, including patent databases [2], domain name reg-
istration [28], anonymous email [33], and improving the
scalability of anonymous communication networks [26].
The simplest kind of query one can make with PIR
is to consider the database to be composed of a number
of blocks of equal size, and to retrieve a particular block
from the database by its absolute position [10]. Although
this simple type of query does not appear to be very use-
ful in practice, it turns out that it can be used as a black-
box building block to construct more complex and use-

∗An extended version of this paper is available. [13]

ful queries, such as searching for keywords [9] or private
SQL queries [28].

PIR protocols can be grouped into two classes corre-
sponding to the security guarantees they provide. One
class is computational PIR [8], in which the database
servers can learn the client’s query if they can ap-
ply sufﬁcient computational power to break a particular
cryptographic system. The other class of protocols —
those we will consider in this work — is information-
theoretic PIR [10, 11], in which no amount of com-
putation will allow the reconstruction of the client’s
In these protocols, the query is protected by
query.
splitting it among multiple database servers.
(Chor et
al. [10] show that information-theoretic PIR with less
data transfer than the trivial download scheme is im-
possible with only one server.) As is common in many
distributed privacy-enhancing technologies, such as mix
networks [7], Tor [14], or some forms of electronic vot-
ing [6], we must assume that some fraction of the servers
above some threshold are not colluding against the client.
While much of the theoretical work on PIR focuses
strictly on minimizing the amount of data transferred [15,
38], in a practical setting we must take other aspects, par-
ticularly the computational performance, into account. In
2007, Sion and Carbunar [36] opined that, given trends
in computational power and network speeds, it would al-
ways be faster to send the whole database to the client
than to use PIR to process it. However, they only consid-
ered one kind of computational PIR [23] in their analysis.
In fact, recent work by Olumoﬁn and Goldberg [29]
demonstrates that a more recent computational PIR
scheme by Aguilar Melchor and Gaborit [1] is an or-
der of magnitude faster than trivial download, while
information-theoretic (IT) PIR can be two to three or-
ders of magnitude faster. These PIR protocols are well
matched to deployment on mobile clients as they require
low data transfer, low client-side computation, and mod-
erate server-side computation [30]. For example, to re-
trieve one 32 KiB block from a 1 GiB database, an IT-

PIR client would send one block of data to, and receive
one block of data from, each server. The servers each
perform about 1.4 CPU seconds of computation, and the
client performs about 140 ms of computation.

1.1 Byzantine robustness
An important practical consideration with multi-server
PIR is how to deal with servers that do not respond
to a client’s queries, or that respond incorrectly, either
through malice or error. These are respectively termed
the robustness and Byzantine robustness problems.

The main result of this paper is to improve the Byzan-
tine robustness of information-theoretic PIR. In order to
guarantee information-theoretic PIR, one must have mul-
tiple servers in the protocol; Byzantine robustness guar-
antees that the protocol still functions correctly even if
some of the servers fail to respond or give incorrect or
malicious responses. Byzantine robustness makes no
assumptions on the type of errors that can appear—the
model covers spurious or random errors as well as ma-
licious interference—and the bounds are given in terms
of the number of servers which ever give incorrect re-
sponses. The client must still be able to determine the an-
swer to her query, even when some number of the servers
fail to respond, or give incorrect answers; further, in the
latter case, the client would like to learn which servers
misbehaved so that they can be avoided in the future. (In
the single-server case, the owner of the database can pro-
vide a cryptographic signature on each block in order to
ensure integrity, as PIR-Tor [26] does. Without computa-
tional assumptions or some kind of shared secret, it does
not make much sense to consider robustness or Byzan-
tine robustness in a single-server PIR setting.)

Beimel and Stahl [3, 4] were the ﬁrst to consider ro-
bustness and Byzantine robustness for PIR. Consider an
(cid:96)-server information-theoretic PIR setting, where only k
of the servers respond, v of the servers respond incor-
rectly, and the system can withstand up to t colluding
servers without revealing the client’s query (t is called
the privacy level). (This is termed “t-private v-Byzantine
robust k-out-of-(cid:96) PIR”.) Then the protocol of Beimel and
Stahl works when v ≤ t < k/3. Under those conditions,
the protocol will always output to the client a unique
block, which will be the correct one; this is called unique
decoding.

In 2007, Goldberg [19] observed that by allowing for
the possibility of list decoding — that is, that the protocol
may sometimes output a small number of blocks instead
of just one — the privacy level and the number of misbe-
having servers can be substantially increased, up to t < k
kt(cid:99). He also showed that in many scenar-
ios, the probability of more than one block being output
by the protocol is vanishingly small, while in others, one

and v < k−(cid:98)√

can employ standard techniques to convert list decoding
to unique decoding [25] at the cost of slightly increasing
the size of the database. The communication overhead
of Goldberg’s protocol is k + (cid:96); that is, to retrieve one
block of data (say b bits), the protocol transfers a total of
(k + (cid:96))b bits, for the optimal choice of block size b.

1.2 Our contributions

• We change only the client side of Goldberg’s 2007
v < k−(cid:98)√
protocol to improve its Byzantine robustness from
kt(cid:99) to v < k−t − 1, which is the theoret-
ically maximum possible value. Depending on the
deployment scenario, the communication overhead
of our protocol ranges from a factor of k + (cid:96) to a
maximum of v(k + (cid:96)).

• Our protocol is considerably faster than Goldberg’s
protocol for many reasonable parameter choices.
We implemented our protocol on top of Goldberg’s
open-source Percy++ [18] distribution and ﬁnd that
our new protocol can be up to 3–4 orders of magni-
tude (thousands of times) faster than the original in
reconstructing the correct response to a query in the
presence of Byzantine servers.

The robustness and efﬁciency improvements to the
PIR protocol given in this paper mean that recovering
from Byzantine errors even in an extremely adversarial
or noisy setting is not just academically feasible, but is
completely reasonable for user-facing applications.

Goldberg’s protocol uses Shamir secret sharing to hide
the query; since Shamir secret sharing is based off of
polynomial interpolation, the problem of recovering the
response in the case of Byzantine failures corresponds
to noisy polynomial reconstruction, which is exactly the
problem of decoding Reed-Solomon codes. The theo-
retical contribution of this work is to observe that the
practical setting of clients performing multiple queries
allows us to use sophisticated decoding algorithms that
can decode multiple queries simultaneously and achieve
an enormous improvement in both performance and the
level of robustness.

1.3 Organization
The remainder of the paper is organized as follows.
In Section 2 we will introduce the tools that we need
to present our protocol: Shamir secret sharing, Reed-
Solomon codes, and decoding algorithms for multipoly-
nomial extensions of these codes. In Section 3 we review
the PIR protocols that form the foundation for our work.
We present our protocol and algorithms in Section 4, and
give experimental results in Section 5. We conclude the
paper in Section 6.

2 Preliminaries

2.3 Error-correcting codes

2.1 Notation
We will use the following variables throughout the paper:

• (cid:96) denotes the total number of servers
• t is the privacy level: no coalition of t or fewer

servers can learn the client’s query

• k is the number of servers that respond
• v is the number of Byzantine servers that respond
and h is the number of honest servers that respond
(so h + v = k). Byzantine servers may respond with
any maliciously chosen value.

• D is the database
• r is the number of blocks in the database
• s is the number of words in each database block
• w is the number of bits per word

e j

the

denote

by

We
vector
(cid:104)0, . . . ,0,1,0, . . . ,0(cid:105) where the 1 is in the jth place.
x ∈R X means selecting the element x uniformly at
random from the space X.

standard

basis

The scheme works as follows:

2.2 Shamir secret sharing
The classic Shamir secret sharing scheme [34] allows a
dealer to choose a secret value σ, and distribute shares
of that secret to (cid:96) players. If t or fewer of the players
come together, they learn no information about σ, but if
more than t pool their shares, they can easily recover the
secret. (t and (cid:96) are parameters of the scheme, with t < (cid:96).)
let σ be an arbi-
trary element of some ﬁnite ﬁeld F (not necessary uni-
formly distributed). The dealer selects (cid:96) arbitrary distinct
non-zero indices α1, . . . ,α(cid:96) ∈ F, and selects t elements
a1, . . . ,at ∈R F uniformly at random. The dealer con-
structs the polynomial f (x) = σ +a1x +a2x2 +··· +atxt,
and gives to player i the share (αi, f (αi)) ∈ F × F for
1 ≤ i ≤ (cid:96). Note that the secret σ is just f (0). Now any
t + 1 or more players can use Lagrange interpolation to
reconstruct the polynomial f , and evaluate f (0) to yield
σ. However, t or fewer players learn absolutely no infor-
mation about σ.

Complications arise during reconstruction, however,
when some of the shares being brought together to re-
construct f are incorrect. Dealing with this case involves
working with error-correcting codes, and will be dis-
cussed in Section 2.3, next.

Sharing a vector of elements in Fr rather than a single
ﬁeld element is done in the straightforward way: each
coordinate of the vector is secret shared separately, using
r independent random polynomials.

We will use error-correcting codes to handle Byzantine
robustness.
In the case of servers that merely fail to
respond, we could try to use an erasure code — an
error-correcting code which can be decoded when some
symbols are erased by the channel. In order to handle
Byzantine failures, we will use error-correcting codes
that can handle both corrupted and missing symbols. Our
scheme will transform malicious errors into random er-
rors, which will allow us to achieve much higher robust-
ness (with high probability) than was efﬁciently possi-
ble before. In addition, the use of these error-correcting
codes allows us to identify servers that cheat during the
protocol, and not use them in the future.

The error-correcting codes that we will use in our pro-
tocol are based off of Reed-Solomon codes. [32] This is
a natural choice to use with Shamir secret sharing, as
they both use polynomial interpolation.
If a message
of length t + 1 consists of elements {a0,a1, . . . ,at} in
some ﬁeld F then we can deﬁne the degree-t polynomial
f (x) = a0 + a1x +··· + atxt. Fix k distinct ﬁeld elements
α1, . . . ,αk. A Reed-Solomon codeword consists of the
evaluations of f at each point: { f (α1), . . . , f (αk)}.
The Berlekamp-Welch [5] algorithm can efﬁciently
decode a Reed-Solomon codeword with up to v < (k −
t)/2 errors, which is the theoretical maximum for unique
decoding. However, if one is willing to accept the pos-
sibility of decoding to multiple valid codewords, the
Guruswami-Sudan algorithm [22] improves the decod-
kt. This is known as list decoding:

ing radius to v < k−√

the algorithm returns a list of all valid codewords.

2.3.1 Multi-polynomial reconstruction

The above decoding algorithms all consider the case of
noisy interpolation of a single polynomial. More re-
cently, Parvaresh and Vardy [31], and Guruswami and
Rudra [21] designed codes that could be efﬁciently list
decoded, approaching the asymptotic limit of v < k −
t − 1. These codes are based around the idea of extend-
ing the Reed-Solomon code to evaluate multiple polyno-
mials simultaneously, and using clever constructions of
the polynomials in order to efﬁciently decode the code-
words. One of the main contributions of this paper is
to adapt these ideas to a cryptographic setting. We can-
not directly use their constructions, as their polynomials
have a special structure that would make them unsuit-
able for secret sharing. However, using a randomized
construction we can nonetheless efﬁciently decode such
multi-polynomial codes in practice with high probability,
yielding a secret sharing system robust to many errors.

The codes that we will use will reconstruct sev-
eral polynomials simultaneously from noisy evaluation

points. Deﬁne m polynomials

f1(x) = a10 + a11x +··· + a1txt ,

...

fm(x) = am0 + am1x +··· + amtxt .

Then a codeword will consist of the evaluations of each
of these polynomials at points α1, . . . ,αk:

f1(α1), . . . , fm(α1),

...

f1(αk), . . . , fm(αk)

is

case

This general
considered by Cohn and
Heninger [12], who give an algorithm that heuristi-
cally reconstructs every polynomial as long as there are
no more than v < k − tm/(m+1)k1/(m+1) values of i for
which the received value of some fp(αi) is incorrect. In
our application to PIR, each polynomial will correspond
to a column of the database matrix D, and each value αi
will correspond to a PIR server; therefore, we will be
able to tolerate v dishonest servers.

2.3.2 Linear multi-polynomial decoding

The list-decoding algorithms of Guruswami-Sudan,
Parvaresh-Vardy, and Cohn-Heninger all work by con-
structing a polynomial which vanishes to high multiplic-
ity at the codeword. If one simply uses multiplicity one,
one can obtain a “linear” variant of the Cohn-Heninger
algorithm [12] which is extremely fast in practice. It re-
constructs each polynomial uniquely when no more than
v ≤ m
m+1 (k−t − 1) values of i have incorrect received
values of some fp(αi). This algorithm works with high
probability in practice as long as the errors are random-
ized. We will show later how to set up our protocol to
enforce that even malicious servers can only insert ran-
dom errors.

Since this linear variant is not explicitly described in

their work, we provide a brief outline in Algorithm 1.

Polynomial lattice basis reduction. Step 4 in the al-
gorithm uses a “polynomial lattice basis row reduction
algorithm”. This is an algorithm which takes as input
a matrix M of polynomials and applies elementary row
operations over the ring of polynomials to produce a ma-
trix M(cid:48) whose coefﬁcient polynomials have minimal de-
gree. [37] There are several polynomial-time polynomial
lattice basis reduction algorithms. (This is a refreshing
contrast to the case of integer lattices where ﬁnding ex-
act shortest vectors is NP-hard and efﬁcient algorithms

Algorithm 1 Fast multi-polynomial reconstruction
Input: km points (αi,yip) 1 ≤ i ≤ k, 1 ≤ p ≤ m, degree
bound t, and minimum number of correct points h =
k− v.

Output: m polynomials f1, . . . , fm of degree at most t
such that for at least h values of i, fp(αi) = yip for
all 1 ≤ p ≤ m
mials f ∗
each 1 ≤ i ≤ k.

1: Use Lagrange interpolation to construct m polyno-
p (αi) = yip for

p of degree at most k− 1 s.t. f ∗

2: Construct the degree-k polynomial

N(x) =

(x− αi)

k

∏

i=1

3: Construct the (m + 1)× (m + 1) polynomial matrix

xt



M =

xt

...



− f ∗
− f ∗

1 (x)
2 (x)

xt − f ∗
m(x)
N(x)

4: Run a polynomial lattice basis row reduction algo-

rithm on M.

5: Discard the largest-degree row in the reduced matrix.
If any remaining row has degree larger than h, abort.
6: Write the remaining m × (m + 1) matrix as [A|b],
where A is an m× m matrix, and b is an m× 1 col-
umn vector.

7: Solve the linear system of equations

(cid:19)

(cid:18) 1

xt A

 = b

f1
f2
...
fm

8: return ( f1, . . . , fm)

such as LLL [24] can only obtain an exponential approx-
imation.) The algorithm of Giorgi et al. [17] runs in time
O(δ nω+o(1)) where δ is the maximum degree of the in-
put basis, n is the dimension, and ω is the exponent of
matrix multiplication. Our implementation uses the al-
gorithm of Mulders and Storjohann [27] which runs in
time O(n3δ 2) but is much simpler and easier to imple-
ment, and yields excellent running times for the input
sizes we care about.

If step 5 does not abort, then there is guaranteed to be
a unique set of polynomials satisfying the requirements;
that is, we are in the unique decoding case. As we will

see later, if the errors are random, this step aborts only
with very low probability.

Without any imposed structure on the codeword poly-
nomials, the Cohn-Heninger algorithm is heuristic; that
is, they conjecture that it will succeed for sufﬁciently
random input. The linear version that we use here is
also heuristic:
there are adversarial inputs on which it
may fail. However, we observe in experiments (see Sec-
tion 5.3) that the heuristic assumption holds with high
probability for random inputs, which is the situation we
need for our cryptographic purposes here. We conjecture
based on the experimental evidence presented in Sec-
tion 5.3 that the probability of failure depends only on
the size of the underlying ﬁeld F. In particular, the algo-
rithm will work with high probability for random poly-
nomials if the errors are uncorrelated. We will see later
that we can enforce this restriction in our protocol even
in the case of Byzantine servers.

2.3.3 Optimality

Relating this to our PIR application, we will be able to
use this algorithm to correctly decode the results of t-
private PIR queries. If k servers respond to us, of which
v are Byzantine (so h = k− v are honest), then this algo-
rithm will succeed with high probability after we query
m+1 (k−t − 1), or equiva-
for m blocks, satisfying v ≤ m
lently, m ≥ v
h−t−1. That is, for m large enough, we can
handle any number of Byzantine servers v < k−t−1. We
note that this bound on v is optimal—if v = k− t − 1, or
equivalently, h = t + 1, then any subset of t + 1 servers’
responses will form a polynomial of degree at most t.
This means that the number of possible valid blocks will
always be exponential, and no polynomial-time algo-
rithm could hope to address this case.

2.4 Dynamic programming

In practice, each of the algorithms we have described
above has different performance characteristics for dif-
ferent inputs. Thus in our implementation, we achieve
the best performance by assembling all of them together
into a portfolio algorithm. This algorithm optimistically
attempts to decode a given input using Lagrange inter-
polation, and if that fails, uses a dynamic program with
timing measurements to fall back to an optimal sequence
of decoding algorithms. See Section 5.2 for more details.

3 Protocols for PIR

In this section, we will introduce the ideas from previous
PIR protocols that will form the basis for our protocol.

3.1 Database queries as linear algebra
We begin with a general mathematical setting of the PIR
schemes we will be considering.
Our database D is structured as an r × s matrix with
r rows. Each row represents one block of the database,
and consists of s words of w bits each. The database D
resides on a remote server. The client wishes to retrieve
one block (row) of the database from the server.



D =



w11 w12
w21 w22
...
...
wr1 wr2

. . . w1s
. . . w2s
...
. . . wrs

One non-private protocol for the client to retrieve row
β of the database would be to transmit the vector eβ con-
sisting of all zeros except for a single 1 in coordinate β
to the server. The server considers eβ as a row vector and
computes the product eβ · D, which it sends back to the
client.



(cid:2)0

0

. . .

1

. . .

0(cid:3)
=(cid:2)wβ 1 wβ 2

w11 w12
w21 w22
...
...
wr1 wr2

(cid:3)

. . . wβ s



. . . w1s
. . . w2s
...
. . . wrs

We will show how to construct

two information-
theoretic PIR schemes that modify this basic scheme to
retrieve blocks from the database without revealing the
query or result to an adversary.

3.2 A simple PIR scheme due to Chor et al.
We next present a simple PIR scheme due to Chor et
al. [10] We begin with the same setup as above. In this
protocol, the words will be single bits, so w = 1, and D
is an r × s matrix of bits. Since we will be construct-
ing information-theoretic PIR, we will be querying more
than one server. We will require that not all of the servers
are colluding to reveal the client’s query. Each of the
(cid:96) ≥ 2 servers gets a copy of D.

A client wishing to retrieve block β of the database
generates the basis vector eβ as above to select coordi-
nate β . Then in order to hide this query vector from
the servers, the client picks (cid:96) − 1 vectors v1, . . . ,v(cid:96)−1
uniformly at random from GF(2)r (that is, (cid:96) − 1 uni-
formly random r-bit binary strings), and computes v(cid:96) =
eβ ⊕ (v1 ⊕···⊕ v(cid:96)−1). v(cid:96) will be a uniformly random
(though not independent) r-bit string, as (cid:96) ≥ 2.
The client sends vi to server i for each 1≤ i≤ (cid:96). Server
i computes the product ri = vi · D, which is the same as

setting ri to be the XOR of those blocks j in the database
for which the jth bit of vi is 1. Each server i returns ri to
the client.
The client XORs the results to obtain r = r1 ⊕ ···⊕
r(cid:96) = (v1 ⊕···⊕ v(cid:96))·D = eβ ·D, which is the β th block of
the database, as required.
Note that this scheme is ((cid:96)− 1)-private; that is, no
combination of (cid:96)− 1 or fewer servers has enough infor-
√
mation to determine i from the information they receive
√
n yields
from, or send to, the client. Choosing r = s =
n bits to privately retrieve
a total communication of 2(cid:96)
a block of size

√
n bits.

3.3 Goldberg’s PIR scheme

Chor’s scheme, above, is not robust; if even one server
fails to respond, the client cannot reconstruct her answer.
Further, it is not Byzantine robust; if one server gives the
wrong answer, then the client not only will reconstruct
the wrong block, but the client will be unable to deter-
mine which server misbehaved.

Goldberg [19] modiﬁed Chor’s scheme to achieve both
robustness and Byzantine robustness. Rather than work-
ing over GF(2) (binary arithmetic), his scheme works
over a larger ﬁeld F, where each element can represent
w bits (so w = (cid:98)lg|F|(cid:99)). The database D is then an r× s
matrix of elements of F.
In Goldberg’s simplest con-
struction, as with Chor’s scheme, each of (cid:96) ≥ 2 servers
gets a copy of the database.

To transform this into a t-private PIR protocol, the
client uses ((cid:96),t) Shamir secret sharing to share the vector
eβ ∈ Fr into (cid:96) independent shares (α1,v1) , . . . , (α(cid:96),v(cid:96)).
That is, the client creates r random degree-t polynomials
f1, . . . , fr satisfying f j(0) = eβ [ j] and chooses (cid:96) distinct
non-zero elements αi ∈ F. Server i’s share will be the
vector vi = (cid:104) f1(αi), . . . , fr(αi)(cid:105).
Each server then computes the product ri = vi · D =



. . . w1s
. . . w2s
...
. . . wrs

(cid:3)

(cid:11) ∈ Fs.

(cid:10)∑ j f j(αi)w j1, . . . , ∑ j f j(αi)w js

(cid:2) f1(αi)
fr(αi)(cid:3)
=(cid:2)∑ j f j(αi)w j1

w11 w12
w21 w22
...
...
wr1 wr2

. . .

. . . ∑ j f j(αi)w js

By the linearity property of Shamir secret sharing,
since {(αi,vi)}(cid:96)
i=1 is a set of Shamir secret shares of
eβ , {(αi,ri)}(cid:96)
i=1 will be a set of Shamir secret shares of
eβ · D, which is the β th block of the database. Look-
ing at it another way, the vector (cid:104)r1[q],r2[q], . . . ,r(cid:96)[q](cid:105)
is a Reed-Solomon codeword encoding the polynomial

gq = ∑ j f jw jq, and the client wishes to compute gq(0)
for each 1 ≤ q ≤ s.

However, some of the servers may be down or Byzan-
tine, so some of the shares returned by these servers may
be missing or incorrect. Goldberg’s scheme ﬁrst op-
timistically assumes that all of the servers that replied
gave correct responses, and uses Lagrange interpolation
to attempt to reconstruct the database row (his EASYRE-
COVER algorithm). He bases this optimistic assump-
tion on the fact that Byzantine servers are discovered
by his scheme, which disincentivizes servers to act ma-
liciously. If the optimism is not justiﬁed, however, his
scheme then uses the Guruswami-Sudan algorithm [22]
(his HARDRECOVER algorithm) to do error correction
(see Section 2.3).

This scheme is t-private, and the Guruswami-Sudan
kt(cid:99) incorrect server re-

sponses. Choosing r = s =(cid:112)n/w yields a total commu-
algorithm can correct v < k−(cid:98)√

√
nw bits to privately retrieve a block

√
nication of (k + (cid:96))
nw bits.
of size

Goldberg’s scheme also allows for an extension called
τ-independence [16], in which the database itself is se-
cret shared among the (cid:96) servers, so that no coalition of
τ or fewer servers can learn the contents of the database.
We will omit the details for ease of presentation, but our
scheme extends naturally to this scenario as well.

4 Our algorithm

Our algorithm follows the same general idea as Gold-
berg during the client-server interaction and Shamir se-
cret sharing. We change the way that queries are ran-
domized and make improvements to the client-side pro-
cessing to greatly improve robustness and the speed of
processing.

Goldberg’s block reconstruction technique uses the
Guruswami-Sudan algorithm to reconstruct the block a
single word at a time. However, we can achieve bet-
ter error-correction bounds with the algorithm of Sec-
tion 2.3.2 by considering multiple blocks simultaneously.
This takes advantage of the observation that a server is
either Byzantine or not; if it is not, it will give correct
results for every query.

receive from the servers are(cid:10)R∗

If the Reed-Solomon codewords the client expects to
1 ≤ q ≤ s, what it actually receives may differ because
some number of servers may be down, and some further
number may be Byzantine. Of the (cid:96) servers, it may only
receive a response from k of them, and of those, v may
be incorrect.
If the client receives (cid:104)R1[q],R2[q], . . . ,R(cid:96)[q](cid:105) for 1 ≤
q ≤ s, then:

(cid:96) [q](cid:11) for

2[q], . . . ,R∗

1[q],R∗

 f1(α1)

...

f1(α(cid:96))





w11 w12
w21 w22
...
...
wr1 wr2

 =

 R1[1]

...
R(cid:96)[1]

R1[2]
...
R(cid:96)[2]

 =

. . . R1[s]
...
. . . R(cid:96)[s]

. . . w1s
. . . w2s
...
. . . wrs

. . .

fr(α1)

...

fr(α(cid:96))

. . .

 g1(α1)

g1(α(cid:96))

...

g2(α1)

...

g2(α(cid:96))

. . .

. . .



gs(α1)

...

gs(α(cid:96))

Figure 1: Our PIR protocol illustrated. Each row of the leftmost matrix corresponds to a Shamir secret share of the
database row being queried; each column of the rightmost two matrices corresponds to a Reed-Solomon codeword
encoding a word of the queried database row. The client sends the ith row of the leftmost matrix to server i and expects
to receive the ith row of the rightmost matrix in reply.

• For (cid:96)− k values of i, Ri[q] =⊥ for all q (these are

the down servers)

• For at least h = k − v values of i, Ri[q] = R∗

i [q] for

all q (these are the honest servers)

• For the remaining at most v values of i, Ri[q] =
R∗
i [q] + ∆iq for error terms ∆iq (these are the Byzan-
tine servers)

4.1 Randomizing queries
In order to use the algorithm of section 2.3.2, we need to
ensure that the Byzantine servers produce random errors;
that is, that the ∆iq terms are randomly and independently
chosen in the m codewords we supply to that algorithm.
We make no a priori assumptions on the types of errors
that the Byzantine servers may produce, but we will ran-
domize the algorithm to cause any kind of spurious or
malicious error to appear random.

To accomplish this, we make the following modi-
the client chooses a
ﬁcation to Goldberg’s protocol:
uniformly random non-zero element ci ∈R F∗ for each
server and sends the server a “blinded” query ciQi =
(cid:104)ci f1(αi), . . . ,ci fr(αi)(cid:105) instead of just Qi. When the
server i returns a vector R(cid:48)
i, the client unblinds it by di-
viding by ci to yield Ri = c−1
i R(cid:48)
i.

This ensures that if the server’s response R(cid:48)

iq = R(cid:48)
iq = Ri[q]− R∗

i was the
correct response to query ciQi, then Ri will be the correct
response to query Qi. Further, for a Byzantine server,
the error ∆(cid:48)
i [q] it maliciously introduces
will be randomized unpredictably by the client to ∆iq =
c−1
i ∆(cid:48)
Note, however, that different errors within the same
server’s response to a single query are not independently
randomized; if a Byzantine server just adds a constant C
to each word of the correct result ciR∗
i before returning it
to the client, the client will see a result Ri that has had the
constant c−1
i C added to each word of the correct result.
from different
queries, though, are independent, and it is this indepen-
dence we leverage to get the linear multi-polynomial al-

Errors from different servers, or

i[q]− ciR∗

i [q].

gorithm in Section 2.3.2 to work: after m queries, we
will have m responses each with independently random
errors, and we can use the algorithm to decode them si-
multaneously with high probability.

4.2 Reconstructing responses
After unblinding, the client possesses responses Ri from
k servers; for ease of notation, suppose they are servers
1 through k. Each Ri is a vector (cid:104)Ri[1], . . . ,Ri[s](cid:105) where s
is the number of words (elements of F) in one database
block. Each (cid:104)R1[q], . . . ,Rk[q](cid:105) for 1 ≤ q ≤ s is a Reed-
Solomon codeword with errors (the (cid:96)−k non-responding
servers’ entries having been removed) encoding a poly-
nomial gq; see Figure 1. The client’s desired block is
(cid:104)g1(0), . . . ,gs(0)(cid:105).

As with Goldberg’s scheme, the client ﬁrst optimisti-
cally attempts to reconstruct each gq using Lagrange in-
terpolation on the points {(α1,R1[q]), . . . , (αk,Rk[q])} to
see if the resulting polynomial has degree at most t. If
there were no Byzantine servers, this will be successful.
For any g j for which Lagrange interpolation fails, we ap-
ply an escalating sequence of error-correction algorithms
from Section 2.3 to attempt to recover g j. Our imple-
mentation ties these together in a portfolio algorithm; see
Section 5.2. If at any time, the error correction algorithm
identiﬁes a particular server as Byzantine, that server’s
results are discarded for all future computations.

If there is still at least one g j which was not yet able to
be reconstructed, any one such unsuccessfully decoded
codeword (cid:104)R1[q], . . . ,Rk[q](cid:105) is stored for later reconstruc-
tion, along with the current state of the computation. The
client’s requested block will not be available at this time.
The client can then do PIR requests for more blocks of
the database. If it was interested in multiple blocks, it can
just request those. Otherwise, it can re-request blocks it
has not yet successfully decoded. Note that the proper-
ties of PIR ensure that the servers cannot tell whether
a request is for a repeated block or a fresh one. Each
time, the client either receives its desired block (from the
Lagrange interpolation or error correcting portfolio algo-

h−t−1

rithms) or another codeword gets stored for later recon-
struction.

(cid:7) ≤ v such codewords have been

When m =(cid:6)

v

collected, we can apply the algorithm of Section 2.3.2.
Since the stored codewords have independent errors, the
algorithm will succeed with high probability. At that
point, all m stored computations can be concluded, the m
blocks will be returned to the client, and the v < k−t −1
Byzantine servers will be identiﬁed. The client can then
avoid those servers in the future.

Note that the decoding algorithm is randomized, so
there is a small chance of failure even when the client
has collected the results of m queries. In this case, the
client can continue to collect queries and construct new
codewords until the algorithm succeeds.
Algorithm 2 summarizes the process.

Algorithm 2 Robust PIR Protocol
Goal: Client wishes to query row β from database D

1: Client

(cid:96) distinct non-zero elements

stored on (cid:96) servers.
chooses
α1, . . . ,α(cid:96) ∈ F∗.
2: Client chooses r random degree-t polynomials
f1, . . . , fr ∈R F[x] satisfying f j(0) = 1 for j = β and
f j(0) = 0 otherwise.
chooses
(cid:96)
c1, . . . ,c(cid:96) ∈R F∗.

random non-zero elements

3: Client

4: Client sends the vector

Qi = (cid:104)ci f1(αi),ci f2(αi), . . . ,ci fr(αi)(cid:105)

to server i.

i = Qi · D to client.

5: Server i receives vector Qi.
6: Server i sends the product R(cid:48)
7: Client receives R(cid:48)
1, . . . ,R(cid:48)
(cid:96).
8: Client computes Ri = c−1
i R(cid:48)
9: Client considers vectors Sq =(cid:104)R1[q], . . . ,R(cid:96)[q](cid:105) as re-
ceived Reed-Solomon codewords and uses the algo-
rithms from Section 2.3 to recover word q of row β
of D.

i for each i.

(cid:7) ≤ v blocks have been re-

ing until m =(cid:6)

10: If the recovery algorithm fails, postpone decod-

v

h−t−1

quested (requesting blocks multiple times if neces-
sary). Then use the algorithm from Section 2.3.2 to
recover all of the blocks simultaneously.

5

Implementation and experiments

We implemented the algorithm described in this paper
as an extension of Goldberg’s implementation of his
protocol, available as the Percy++ project on Source-

Forge [18]. The software is implemented in C++ using
the NTL library [35].

In this paper we are concerned with the speed of the
client-side block reconstruction operation in the pres-
ence of Byzantine servers. Our work does not change
the server side of Goldberg’s protocol in any way; to see
speeds for the server-side operations, see Olumoﬁn and
Goldberg’s 2011 paper [29].

5.1 Choice of underlying ﬁeld
Goldberg’s 2007 work used a 128-bit prime ﬁeld as the
ﬁeld F. Subsequent releases of Percy++, however, were
able to use different ﬁelds, including prime ﬁelds of dif-
ferent sizes as well as GF(28). This last ﬁeld turns out to
be a very efﬁcient choice, as additions in this ﬁeld can be
implemented as XOR operations and multiplications are
simple lookups in a 64 KB table.

Our implementation of our protocols uses C++ tem-
plates to abstract the ﬁeld F, making it very easy to work
over any desired ﬁeld.

5.2 Portfolio algorithms for decoding
Our implementation assembles the error correction al-
gorithms described in Section 2.3 into a portfolio algo-
rithm [20] to do efﬁcient decoding. We use dynamic
programming to choose an optimal sequence of decod-
ing algorithms to try.
Each of the error correction algorithms we use is char-
acterized by the tuple (k,t,h) with k ≥ h > t: we wish to
ﬁnd a polynomial of degree at most t that passes through
at least h of the k input points.

We have a few different choices of algorithm to solve

this problem directly:
Berlekamp-Welch: If h > k+t

Guruswami-Sudan: If h >

2 , we can use the
Berlekamp-Welch algorithm to ﬁnd the unique
polynomial solution, if it exists. This algorithm is
quite fast, and we use it whenever it is applicable.

√
kt, we can use the
Guruswami-Sudan algorithm to ﬁnd all solutions. It
turns out this algorithm is very inefﬁcient if h2 − kt
is small; for the parameter sizes we care about, we
avoid this algorithm if this value is less than 10.

Brute force: Lagrange interpolate each subset of t + 1
points to form a polynomial of degree t, and see if it
passes through at least h points. This works for any

h > t, but is inefﬁcient if(cid:0) k

(cid:1) is large.

t+1

In addition, we have three strategies to attempt to solve
a particular instance with parameters (k,t,h) by recur-
sively solving smaller instances and combining the re-
sults. Let C(k,t,h) represent the expected time cost to

solve an instance of this size; we will bound this cost as
a function of the costs of solving smaller instances.
Guess g incorrect points: If the client can guess that a
particular point is wrong (that is, that the server
that provided that point is Byzantine), then it can
just throw away the point, and solve the remaining
problem, with parameters (k − 1,t,h). In general,
it might guess g points to be wrong, and solve a
problem of size (k − g,t,h). Since at least h of the
original k points are correct, for any set of h + g
points, there exists a subset of g points that can be
removed from the original k so that there are at least
h correct points in the k− g points remaining. Thus

(cid:1) smaller instances and
by recursively solving(cid:0)h+g
(cid:18)h + g
(cid:19)

combining the results, we are guaranteed to ﬁnd all
solutions to our original problem. Thus we see that

g

·C(k− g,t,h)

C(k,t,h) ≤ min
g

g

Guess g correct points: Conversely,

we get that we need to recursively solve (cid:0)k−h+g
(cid:1)

the client might
guess that a particular subset of g points are all cor-
rect (that is, that the servers that provided them are
honest), and recursively try to ﬁnd a polynomial of
degree at most t−g that passes through at least h−g
of the remaining k−g points.1 Similar to the above,
subproblems with parameters (k−g,t −g,h−g), so
we get
C(k,t,h) ≤ min
g

(cid:18)k− h + g
(cid:19)

·C(k− g,t − g,h− g)

g

g

Guess whether d points are correct or incorrect: The
above strategies may not be helpful if the binomial
coefﬁcients are large. Our ﬁnal strategy is to pick a
ﬁxed set of d points. For all g, and for all choices of
g correct and d − g incorrect points within that set,
we recursively try to ﬁnd polynomials of degree at
most t − g that pass through at least h − g of the
remaining k− d points. As before, we get that

(cid:18)d

(cid:19)

g

C(k,t,h) ≤ min

d ∑

g

·C(k− d,t − g,h− g)

Given these three algorithms to directly solve the prob-
lem, and three strategies to indirectly solve it by combin-
ing solutions to smaller instances, we use dynamic pro-
gramming to build a table of the best strategy to use to

1The remaining points are actually slightly modiﬁed before solv-
ing recursively. If (α∗,y∗) is guessed to be correct, then each other
point (αi,yi) is modiﬁed to (αi, yi−y∗
αi−α∗ ) before recursively solving.
If
then
f (x)· (x−α∗) + y∗ interpolates the corresponding h− 1 original points
and also the guessed point.

f (x) interpolates at least h − 1 points of the latter form,

minimize the expected run time for inputs of each com-
bination of parameters (k,t,h). We measure the runtimes
of the direct algorithms experimentally, and compute the
times for the indirect strategies. We pick the lowest result
of the six, and set C(k,t,h) to that value. We currently do
this in a precomputation step for all k ≤ 25 and give the
PIR client access to this table.

5.3 Multi-polynomial decoding
We also implemented the linear multi-polynomial decod-
ing algorithm described in Section 2.3.2 as an extension
of Percy++ using C++ and the NTL library. For the lat-
tice reduction step, our implementation uses the lattice
reduction algorithm by Mulders and Storjohann [27]. Al-
though its theoretical runtime is not the fastest known,
we chose this algorithm because of its simplicity. Af-
ter the lattice reduction, the implementation then solves
the resulting system of linear equations using Gaussian
elimination.

(cid:16) 1|F|

(cid:17)m(h−t−1)−v+1

As previously mentioned, if the errors are random,
then there is a very low probability that
this algo-
rithm will fail. Based on experimental investigation,
we conjecture the probability of failure is, to ﬁrst order,
. (Recall from Section 2.3.3 that in or-
der for the algorithm to work, m≥ v
h−t−1, or equivalently,
m(h−t − 1)− v ≥ 0.) See the appendix for more details
on these experiments. This probability of failure falls
within the conﬁdence intervals for all of our tests with
|F| ≥ 256. We also ran tests with an extremely small
ﬁeld of |F| = 16, and found that failures in that ﬁeld oc-
curred slightly (but statistically signiﬁcantly) more often
than our conjecture predicts. This leads us to believe that
there is a missing second-order term in our conjecture,
which is negligible for reasonable ﬁeld sizes, but signif-
icant for tiny ﬁelds. We hope to nail down the missing
term in future work.

In the cases where the linear multi-polynomial algo-
rithm does fail, our algorithm will wait until another
block is requested and then try again. This increases m
by one and reduces the probability that the algorithm will
fail by a factor of |F|h−t−1; therefore, since h−t ≥ 2, the
probability it will fail a second time is extremely tiny.

5.4 Measuring improvements to Percy++
In his 2007 paper, Goldberg measures the performance
of his protocols using a Lenovo T60p laptop com-
puter with a 2.16 GHz Intel dual-core CPU running
Ubuntu Linux [19]. For the purposes of comparison,
we have performed our measurements on a machine
of the same model and similar Ubuntu Linux conﬁg-
uration. Goldberg reports that the implementation of

Table 1: Measuring improvements to Percy++’s client-side decoding algorithms. For these measurements we ran 100
trials using the parameters (k,t,h) = (20,10,15).

Implementation

Algorithm

Field

Time

timing reported by Goldberg [19]

Percy++
Percy++
this work
this work

Guruswami-Sudan in MuPAD

Guruswami-Sudan in C++
Guruswami-Sudan in C++

Cohn-Heninger in C++ with m = 2 blocks
Cohn-Heninger in C++ with m = 2 blocks

128-bit prime
128-bit prime

GF(28)

128-bit prime

GF(28)

“several minutes”
9000± 3000 ms
3000± 900 ms
2.2± 0.9 ms
1.3± 0.4 ms

his HARDRECOVER algorithm takes “several minutes”
when using the values (k,t,h) = (20,10,15) [19].

Since the writing of that paper, the Percy++ software
has improved. The ﬁrst improvement was to imple-
ment the parts of the HARDRECOVER subroutine pre-
viously written using MuPAD in native C++. We timed
HARDRECOVER 100 times using only this change, and
found the running time reduced to 9000± 3000 ms.

• the Guruswami-Sudan list decoding algorithm from

the latest release of Percy++

• the single-polynomial dynamic programming algo-

rithm described in Section 5.2; and

• the linear multi-polynomial algorithm described in

Section 5.3

The other

improvement

in the latest version of
Percy++ is to use GF(28) as the underlying ﬁeld, rather
than a 128-bit prime ﬁeld. With this change, we again
measured HARDRECOVER 100 times, and found the run-
ning time further reduced to 3000± 900 ms.

Finally, using the implementation of our algorithm de-
scribed in Section 4 we further improve the running time,
again tested with 100 trials using multi-polynomial de-
coding with just m = 2 blocks. With a 128-bit prime
ﬁeld, our algorithm completes in 2.2± 0.9 ms; with
GF(28), in just 1.3± 0.4 ms.

This is a reduction of over three orders of magnitude in
client-side decoding time versus the latest software, and
of over ﬁve orders of magnitude versus Goldberg’s 2007
reported measurements. This comes at a cost of fetching
just two blocks instead of one — something the client is
likely to have done anyway. The results are summarized
in Table 1.

5.5 New client-side measurements
We next outline the results of measurements taken of the
implementation of our new algorithm described in Sec-
tion 4. These measurements are only on the client-side
decoding operations. For these measurements we used
a server with a 2.40 GHz Intel dual-core CPU running
Ubuntu Linux. For each case, we ran at least 100 trials,
all using only a single core. We used the ﬁeld GF(28)
for all experiments in this section.

To illustrate the improvements that our algorithm pro-
vides, we compare time measurements for four algo-
rithms in Figure 2:

• the potentially exponential-time brute force decod-

ing algorithm

Note that the data is plotted on a log scale so that the
results can be easily compared, even though they span
ﬁve orders of magnitude.

Observe that the Guruswami-Sudan algorithm only
works when the number of Byzantine servers v = k − h
is less than k−(cid:98)√
kt(cid:99), and its running time blows up as v
nears that bound. Past that bound, with more Byzantine
servers, the only prior way for the client to decode the re-
sult was to use the brute-force decoding algorithm. Now,
we can see that our single-polynomial dynamic program-
ming algorithm and our multi-polynomial decoding al-
gorithm both outperform the brute-force algorithm, of-
ten substantially. For example, in Figure 2(c) we see
that for eight Byzantine servers with (k,t) = (20,10),
the Guruswami-Sudan algorithm is ineffective, and the
brute-force algorithm takes about 10 seconds. Mean-
while, our dynamic programming algorithm takes about
1.5 seconds, and our multi-polynomial decoding algo-
rithm takes about 6 milliseconds.

(cid:7) = 8 blocks.

this case, m =(cid:6)

ever, of forcing the client to fetch multiple blocks.

The multi-polynomial algorithm comes at a cost, how-
In
If the client were
going to fetch that many blocks anyway, there is no addi-
tional overhead to the scheme. Otherwise, the client may
have to request some blocks multiple times. In the worst
case, the client only wishes to fetch one block, and there
are v = k − t − 2 Byzantine servers. In this worst case,
h = t + 2, and the client must request its desired block
m = v = k− t − 2 times before it will be able to decode
it. Note that, even when multiple blocks are retrieved
from the servers, our multi-polynomial algorithm is run
only once, in order to distinguish the honest servers from
the misbehaving ones.

v

h−t−1

Figure 2: Timing measurements for the client-side decoding algorithms discussed in this paper for different param-
eters. We ran each algorithm 100 times for each choice of feasible parameters and plot the mean running times in
milliseconds. Note that times are plotted on a log scale.

The three vertical lines on each plot show the unique decoding radius for Reed-Solomon codes, on the left, the the-
oretical bound past which the Guruswami-Sudan algorithm used in Percy++ fails, in the middle, and the theoretical
bound past which efﬁcient decoding with any algorithm is impossible, on the right.

The main results of this paper are to give two client-side decoding algorithms that outperform Guruswami-Sudan in
its feasible region, and allow us to extend the range of efﬁcient client-side decoding to the region of interest between
the two vertical lines on the right. Note that the Guruswami-Sudan algorithm performs much slower in practice than
the Berlekamp-Welch algorithm used by our dynamic programming portfolio algorithm within the unique decoding
radius, and its running time blows up very quickly for parameters approaching its theoretical limit.

The running times of the brute force algorithm within the unique decoding radius have extremely high variance; we
do not plot error bars for those timings as they obscure the entire rest of the plot. We do plot error bars for all other
points, but they are generally too small to see.

 0.01 0.1 1 10 1001,00010,000100,000 0 2 4 6 8 10 12 14 16Time (ms)v (number of Byzantine servers)(a): (k,t) = (20,3) 0.01 0.1 1 10 1001,00010,000100,000 0 2 4 6 8 10 12Time (ms)v (number of Byzantine servers)(b): (k,t) = (20,7) 0.01 0.1 1 10 1001,00010,000100,000 0 1 2 3 4 5 6 7 8 9Time (ms)v (number of Byzantine servers)(c): (k,t) = (20,10) 0.01 0.1 1 10 1001,00010,000100,000 0 1 2 3 4 5Time (ms)v (number of Byzantine servers)(d): (k,t) = (20,14)brute force algorithmlatest version of Percy++ (using Guruswami-Sudan)our single-polynomial dynamic programming algorithm (sec. 5.2)our linear multi-polynomial decoding algorithm (sec. 5.3)unique decoding bound (v = (k-t-1)/2)theoretical limit for Guruswami-Sudan (v = k - √(kt))theoretical limit for polynomial-time decoding (v = k - t - 2)6 Conclusions

We have improved the client side of Goldberg’s 2007
Byzantine-robust information-theoretic private informa-
tion retrieval protocol to use state-of-the-art decoding al-
gorithms to improve the Byzantine robustness of the pro-
tocol to its theoretical limit. We did this using decoding
algorithms that are able to take advantage of decoding
information in multiple blocks of data simultaneously,
observing that in practical scenarios, clients will often be
interested in more than one block at a time.

We implemented our protocol and found that it is very
fast in practice: several thousand times faster than previ-
ous protocols, and usually less than 10 ms for the param-
eter choices in our experiments.

Combined with fast processing on the server side [29]
and scenarios in which the database servers are not in
collusion [28], we can see that information-theoretic pri-
vate information retrieval can be practical even in highly
adversarial settings.

Acknowledgements

We thank Dan Bernstein for pointing out the connections
between multi-polynomial error correction and some
kinds of PIR. We thank Mark Giesbrecht and Arne Stor-
johann for their pointers on implementing polynomial
lattice basis reduction. This material is based upon
work supported by NSERC, Mprime, the National Sci-
ence Foundation under Award No. DMS-1103803, and
the MURI program under AFOSR Grant No. FA9550-
08-1-0352. Finally, we thank the Shared Hierarchical
Academic Research Computing Network (SHARCNET)
and Compute/Calcul Canada for the computing cluster
on which we ran the experiments in Section 5.3 and the
appendix.

References

[1] C. Aguilar Melchor and P. Gaborit. A lattice-
based computationally-efﬁcient private information
In Western European Work-
retrieval protocol.
shop on Research in Cryptology (WEWoRC2007),
Bochum, Germany. Book of Abstracts, pages 50–
54, 2007.

[2] D. Asonov.

Private Information Retrieval: An
In ECDPvA Work-

overview and current trends.
shop, 2001.

rity in Communication Networks (SCN’02), pages
326–341, 2003.

[4] A. Beimel and Y. Stahl. Robust information-
theoretic private information retrieval. Journal of
Cryptology, 20:295–321, 2007.

[5] E. Berlekamp and L. Welch. Error correction of al-
gebraic block codes. US Patent Number 4,633,470,
1986.

[6] R. Carback, D. Chaum, J. Clark, J. Conway, A. Es-
sex, P. S. Herrnson, T. Mayberry, S. Popoveniuc,
R. L. Rivest, E. Shen, A. T. Sherman, and P. L.
Vora. Scantegrity II Municipal Election at Takoma
Park: The First E2E Binding Governmental Elec-
tion with Ballot Privacy. In 19th USENIX Security
Symposium, pages 291–306, 2010.

[7] D. L. Chaum. Untraceable electronic mail, re-
turn addresses, and digital pseudonyms. Commun.
ACM, 24(2):84–90, Feb. 1981.

[8] B. Chor and N. Gilboa. Computationally private
In 29th
information retrieval (extended abstract).
annual ACM Symposium on Theory of Computing
(STOC’97), pages 304–313, 1997.

[9] B. Chor, N. Gilboa, and M. Naor. Private informa-
tion retrieval by keywords. Technical Report TR
CS0917, Department of Computer Science, Tech-
nion, Israel, 1997.

[10] B. Chor, O. Goldreich, E. Kushilevitz, and M. Su-
dan. Private information retrieval. In 36th Annual
IEEE Symposium on Foundations of Computer Sci-
ence (FOCS’95), pages 41 –50, oct 1995.

[11] B. Chor, E. Kushilevitz, O. Goldreich, and M. Su-
dan. Private information retrieval. J. ACM, 45:965–
981, November 1998.

[12] H. Cohn and N. Heninger. Approximate common
divisors via lattices. Cryptology ePrint Archive,
Report 2011/437, 2011. http://eprint.iacr.
org/.

[13] C. Devet, I. Goldberg, and N. Heninger. Optimally
Robust Private Information Retrieval. Cryptology
ePrint Archive, Report 2012/083, 2012.

[14] R. Dingledine, N. Mathewson, and P. Syverson.
In 13th

Tor: the second-generation onion router.
USENIX Security Symposium, 2004.

[3] A. Beimel and Y. Stahl. Robust information-
theoretic private information retrieval. In Proceed-
ings of the 3rd International Conference on Secu-

[15] W. I. Gasarch. A survey on private information re-
trieval (column: Computational complexity). Bul-
letin of the EATCS, 82:72–107, 2004.

[16] Y. Gertner, S. Goldwasser, and T. Malkin. A
Random Server Model for Private Information Re-
trieval. In 2nd International Workshop on Random-
ization and Approximation Techniques in Computer
Science, pages 200–217, 1998.

[17] P. Giorgi, C.-P. Jeannerod, and G. Villard. On the
complexity of polynomial matrix computations. In
2003 International Symposium on Symbolic and Al-
gebraic Computation, pages 135–142, 2003.

[28] F. Olumoﬁn and I. Goldberg. Privacy-preserving
In 10th Inter-
queries over relational databases.
national Privacy Enhancing Technologies Sympo-
sium, pages 75–92, 2010.

[29] F. Olumoﬁn and I. Goldberg. Revisiting the Com-
putational Practicality of Private Information Re-
trieval. In 15th International Conference on Finan-
cial Cryptography and Data Security, pages 158–
172, 2011.

[18] I. Goldberg.

Percy++ project on sourceforge.
Accessed

http://percy.sourceforge.net.
February 2012.

[19] I. Goldberg.

Improving the robustness of private
information retrieval. In 2007 IEEE Symposium on
Security and Privacy, pages 131–148, 2007.

[20] C. Gomes and B. Selman. Algorithm Portfolios.

Artiﬁcial Intelligence, 126(1):43–62, 2001.

[21] V. Guruswami and A. Rudra. Explicit codes achiev-
ing list decoding capacity: Error-correction with
optimal redundancy. IEEE Transactions on Infor-
mation Theory, 54(1):135–150, 2008.

[22] V. Guruswami and M. Sudan. Improved decoding
of Reed-Solomon and algebraic-geometric codes.
39th Annual IEEE Symposium on Foundations of
Computer Science (FOCS’98), pages 28–39, 1998.

[23] E. Kushilevitz and R. Ostrovsky. Replication is not
needed: single database, computationally-private
In 38th Annual Symposium
information retrieval.
on Foundations of Computer Science (FOCS’97),
pages 364–373, 1997.

[24] H. W. Lenstra, A. K. Lenstra, and L. Lov´asz. Fac-
toring polynomials with rational coeﬁcients. Math-
ematische Annalen, 261(4):515–534, 1982.

[25] S. Micali, C. Peikert, M. Sudan, and D. A. Wilson.
Optimal Error Correction Against Computationally
In 2nd Theory of Cryptography
Bounded Noise.
Conference, pages 1–16, February 2005.

[26] P. Mittal, F. Olumoﬁn, C. Troncoso, N. Borisov,
and I. Goldberg.
PIR-Tor: Scalable Anony-
mous Communication Using Private Information
In 20th USENIX Security Symposium,
Retrieval.
pages 475–490, 2011.

[30] F. Olumoﬁn, P. Tysowski, I. Goldberg, and U. Hen-
gartner. Achieving efﬁcient query privacy for lo-
In 10th International Pri-
cation based services.
vacy Enhancing Technologies Symposium, pages
93–110, 2010.

[31] F. Parvaresh and A. Vardy. Correcting errors be-
yond the Guruswami-Sudan radius in polynomial
time. In 46th Annual IEEE Symposium on Founda-
tions of Computer Science (FOCS’05), pages 285–
294, 2005.

[32] I. S. Reed and G. Solomon. Polynomial Codes
Journal of the Soci-
over Certain Finite Fields.
ety for Industrial and Applied Mathematics (SIAM),
8(2):300–304, 1960.

[33] L. Sassaman, B. Cohen, and N. Mathewson. The
Pynchon Gate: a Secure Method of Pseudony-
mous Mail Retrieval. In Proceedings of the 2005
ACM Workshop on Privacy in the Electronic Soci-
ety (WPES ’05), pages 1–9, 2005.

[34] A. Shamir. How to share a secret. Commun. ACM,

22:612–613, November 1979.

[35] V. Shoup. NTL, a library for doing number theory.
http://www.shoup.net/ntl/, 2005. Accessed
February 2012.

[36] R. Sion and B. Carbunar. On the computational
practicality of private information retrieval. In Pro-
ceedings of the Network and Distributed Systems
Security Symposium, 2007.

[37] J. von zur Gathen. Hensel and Newton methods
in valuation rings. Math. Comp., 42(166):637–661,
1984.

[27] T. Mulders and A. Storjohann. On lattice reduc-
tion for polynomial matrices. Journal of Symbolic
Computation, 35(4):377 – 401, 2003.

[38] S. Yekhanin. Towards 3-query locally decodable
codes of subexponential length. J. ACM, 55(1):1–
16, 2008.

(cid:17)m(h−t−1)−v+1

(cid:16) 1|F|

Figure 3: In Section 5.3, we conjectured that the linear multi-polynomial algorithm we present will fail with probability
. We ran several hundred million trials in order to test this conjecture. In plots (a)-(d), we varied a
single parameter, keeping other parameters ﬁxed, and plotted the observed proportion of failures for our linear multi-
polynomial algorithm (black dots, with error bars at the 95% conﬁdence interval) along with the conjectured value
(dotted line). For plot (e) we varied m and used the maximum possible value of v for the given number of polynomials.

 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.11625665537Proportion of FailuresSize of the Field(a) Varying the Field Size 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1101112Proportion of Failuresv (Number of Byzantine Servers)(b) Varying the Number of Byzantine Servers 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1234Proportion of Failuresm (Number of Polynomials)(c) Varying the Number of Polynomials (GF(28)) 1e-08 1e-07 1e-06 1e-05 0.0001 0.001 0.01 0.1345Proportion of Failuresm (Number of Polynomials)(d) Varying the Number of Polynomials (GF(24))Conjectured Failure Rate 0 0.002 0.004 0.006 0.008 0.01 0 5 10 15 20 25 30 35 40Proportion of Failuresm (Number of Polynomials)(e) Varying the Number of Polynomials with Maximum Number of Byzantine ServersAppendix: Failure rate of Algorithm 1

(cid:16) 1|F|

(cid:17)m(h−t−1)−v+1

The linear multi-polynomial algorithm described in Sec-
tion 2.3.2 is probabilistic and may fail with some prob-
ability. We conjecture that the probability of failure is
but do not have a proof. We ran hun-
dreds of millions of tests, varying each of the parameters
in the expression, in order to validate this conjecture ex-
perimentally. Figure 3 contains plots of the results; for
details, see the extended version of this paper [13].
We observe that for large ﬁelds (|F| ≥ 256), our con-
jectured failure rate falls into the 95% conﬁdence interval
of our experimentally observed failure rate for all data
points except 2 of the 39 data points in Figure 3(e). This
is as expected from 95% conﬁdence intervals. However,
for a small ﬁeld (F = GF(24)) our conjecture appears to
consistently underestimate the actual failure rate. This
suggests the presence of an unknown second-order term
in the failure rate; we will be exploring this in future
work.

