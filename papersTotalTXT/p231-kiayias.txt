Traitor Deterring Schemes: Using Bitcoin as Collateral for

Digital Content

Aggelos Kiayias

National and Kapodistrian University of Athens
Dept. of Informatics and Telecommunications

aggelos@di.uoa.gr

Qiang Tang

University of Connecticut

Dept. of Computer Science and Engineering

qtang84@gmail.com

ABSTRACT
We put forth a new cryptographic primitive called a Traitor
Deterring Scheme (TDS). A TDS is a multi-recipient public-
key encryption scheme where an authority issues decryption
keys to a set of users. The distinguishing feature of a TDS is
that secret-keys are issued only after the users provide some
private information as a form of collateral. The traitor de-
terring property ensures that if a malicious coalition of users
(aka “traitors”) produces an unauthorized (aka “pirate”) de-
cryption device, any recipient of the device will be able to re-
cover at least one of the traitors’ collaterals with only black-
box access to the device. On the other hand, honest users’
collaterals are guaranteed to remain hidden. In this fashion
a TDS deincentivizes malicious behavior among users.

We model, construct and analyze TDS’s based on various
cryptographic assumptions and we show how bitcoin can be
used as collateral for real world deployment of TDS’s for the
distribution of digital content. Along the way, we present
cryptographic building blocks that may be of independent
interest, namely fuzzy lockers, and comparison predicate en-
cryption schemes for exponentially large domains. We also
compare TDS with previous primitives speciﬁcally traitor
tracing schemes (TTS) introduced by Chor et al. [9] and
digital signets for self enforcement introduced by Dwork et
al. [12]. A TDS constitutes a strict strengthening of a TTS
and, when modeled in what we call the “known ciphertext
model”, it is a reformulation of digital signets in the public-
key, black-box secure setting. In digital signets the adver-
sary attempts to transmit a pirate copy at a favorable “space
rate”, i.e., without having to send the whole plaintext (and
without revealing the traitor collaterals). It is an open ques-
tion from [12] to construct o(1) space rate schemes under a
falsiﬁable assumption. With our TDS constructions we re-
solve this open question showing feasibility for space rates
O(log λ/λ) and infeasibility for space rates Ω(log2 λ/λ).

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813698.

Categories and Subject Descriptors
K.6 [Management of Computing and Information Sys-
tems]: Security and Protection; E.3 [Data Encryption]:
Public key Cryptosystems

Keywords
Digital Rights Management; Public-key Cryptography; Self-
enforcement; Key Management; Bitcoin

1.

INTRODUCTION

A traitor tracing scheme (TTS) is a multi-user encryp-
tion scheme that when some users (aka traitors) collude to
produce an unauthorized decryption device (aka a pirate de-
cryption box), it is possible to recover at least one of their
identities. TTS’s de-incentivize piracy, in the sense that
colluders may be identiﬁed by the authority once an unau-
thorized device is detected. Since it was introduced in [9],
there have been numerous works, improving diﬀerent aspects
of eﬃciency and security considerations, cf. [2–5, 8, 22, 23].
However, in a TTS, recovering the identity of a traitor can
only happen when the authority becomes aware of the unau-
thorized decryption device. This means that if the traitors
operate stealthily (e.g., distribute a pirate device in some
closed network) there is nothing the authority can do to de-
ter them, and thus in this setting the tracing mechanism
becomes ineﬀective. Furthermore, the penalty that the au-
thority may inﬂict to the traitors can only be applied “after-
the-fact”, i.e., only after the unauthorized decoder has been
recovered and analyzed by the authority.

To address the challenges above, we strengthen the notion
of TTS and put forth a new primitive we call a traitor de-
terring scheme (TDS): a multi-recipient encryption scheme
where each recipient (henceforth also called a user) has some
secret information that is provided as a collateral and hid-
den in a public directory. If the user is honest and keeps her
key to herself, her secret information remains hidden. On
the other hand, if some users collude to produce an unau-
thorized decryption device, any recipient of the device will
be able to recover one of the colluders’ collateral secret in-
formation.

One particularly suitable user-speciﬁc information that
can be used as collateral within a TDS is a bitcoin address
secret key. When registering for service, the subscriber puts
as collateral a small bitcoin amount into a fresh address and
the secret-key of the bitcoin address is embedded as col-
lateral.
In case the bitcoin address is used as input to a
transaction, the public nature of the bitcoin ledger enables

231the service provider to detect it and take appropriate action
(See section 6 for details).

Compared to TTS’s, the main diﬃculty of constructing a
TDS is that one needs to enable a public recovering proce-
dure which returns the user’s secret information that is an
element of an exponentially sized domain — in other words
linear number of bits in the security parameter λ need to be
extracted from the pirate box. Contrary to that, in a TTS,
the authority only needs to recover the identity of a traitor,
which is an element of merely a polynomially sized domain
— in other words just logarithmic number of bits in the se-
curity parameter λ need to be extracted from the pirate box.
As in TTS, the recovering procedure should work given only
black-box access to the pirate decryption box which may
be only partially working. Furthermore, it should operate
without utilizing any private-key information, as in a TTS
with public traceability [8].

A TDS (or a TTS) can also be considered in a stronger ad-
versarial model that we call “the known ciphertext model”.
In this model the adversary aims at communicating a pirated
copy consisting of a sequence of plaintexts that corresponds
to a given set of (polynomially many) ciphertexts (e.g., the
contents in a CD or a public database); without loss of gen-
erality we can assume the pirate copy is in the form of a
pirate box that acts only on the known sequence of cipher-
texts. The adversary aims at producing a pirate box of
smaller size than the sequence of plaintexts; we capture this
in the model by requiring the “space rate” of the attacker
to be o(1). This problem was ﬁrst considered by Dwork,
Lotspiech and Naor [12]. Constructing a TDS or a TTS in
the known ciphertext model under a falsiﬁable assumption
has been an open question since then.

Our contributions. We formalize TDS’s and we give two
diﬀerent construction methods that we instantiate in various
ways; further, we formalize the known-ciphertext model in
the spirit of [12] and we provide both feasibility and infea-
sibility results for TDS in this model. Finally we elaborate
on how to use bitcoin as collateral in conjunction to a TDS.
In more detail:

1. We put forth the formal model for TDS’s. Such schemes
enable the embedding of hidden user-speciﬁc informa-
tion in a public parameter, and have three security
properties: (i) security of plaintexts which is formal-
ized in a standard fashion as in public-key encryption;
(ii) privacy of user information that is hidden in the
public parameters. This property should be upheld
even if all other users conspire against a user as long
as the secret key of the user is not compromised; ﬁ-
nally, (iii) traitor deterring suggests that there is a re-
coverability algorithm that given black-box access to
some working implementation of a decryption device,
it is capable of recovering the private information of at
least one traitor, using only public information.

2. We give two construction methods for TDS’s. The
ﬁrst one is based on ﬁngerprinting codes [9, 20] and
a new primitive we call a fuzzy locker.
In a fuzzy
locker, the message is encrypted using a random code-
word Ci; the decryption operation returns the message
given any C∗ that would result in the i-th user be-
ing accused in the underlying ﬁngerprinting code. In
the TDS construction, the recovering procedure will
ﬁrst retrieve a pirate codeword C∗ from the decryp-
tion device; the traceability of the ﬁngerprinting code

will guarantee that one of the collusion’s codewords
will be accused, thus the corresponding traitor secret
will be unlocked. We then give a concrete construction
of a fuzzy locker for CFN codes [9] using the idea of
fuzzy extractors [11] paired with eﬃcient list decoding
for Reed-Solomon codes [17,30]. Our second construc-
tion method for TDS’s generalizes the constructions
of [4, 5] that are based on comparison predicate en-
cryption (CPE). Contrary to these works however, we
require that the user identity space is exponentially
large, so that a randomly chosen user identity can be
used as a secret key to hide the user secret information
directly. To recover the hidden information given a pi-
rate decryption decoder we utilize a binary search type
of recovering mechanism to navigate through the expo-
nentially sized domain and discover one of the traitor
identities. Given this identity we proceed to unlock
the user hidden data. A CPE scheme can be obtained
via functional encryption (FE) using indistinguisha-
bility Obfuscation (iO) [13]. In order to obtain a con-
struction based on standard assumptions we resort to
bounded collusion FE [14, 15]. We provide a more ef-
ﬁcient construction for this primitive via a combinato-
rial argument and we then use it to instantiate a CPE
with exponential size domain. Our TDS constructions
are summarized in Fig. 1.

3. We revisit the problem of digital signets [12] and we
formulate the “known ciphertext model” for TDS where
the adversary knows the target set of (polynomially
many) ciphertexts before implementing the pirate box.
In an attack in this model, the adversary tries to achieve
a favorable “space rate”, i.e., produce a decryption box
that has size smaller than the total plaintext mate-
rial that is encoded in the known ciphertexts without
leaking any of the traitors’ collaterals. Constructing
a TDS in the known ciphertext model is equivalent to
the problem of constructing digital-signets with self-
enforcement as deﬁned in [12] which is open under fal-
siﬁable assumptions; the construction of [12] assumes
an incompressible function of a speciﬁc type (this is
an unfalsiﬁable assumption) and the recovering strat-
egy has full access to the key. It works for any space
rate o(1). With our TDS constructions we resolve the
open question showing feasibility under falsiﬁable as-
sumptions for space rates O(log λ/λ) while we show
infeasibility for space rates Ω(log2 λ/λ) in the black-
box recoverability setting. In our results, we exploit
bounds on the false positive rate of the membership
testing problem to show how our TDS schemes can be
used while our negative result applies Bloom ﬁlters [1]
to provide an eﬃcient attacker strategy.

4. We describe how one can use bitcoin as a collateral
in a TDS. Recall that collaterals are arbitrary strings
hence a service provider (SP) can embed as collat-
eral the secret-key of a fresh bitcoin address credited
by the user. As part of the user agreement, the ac-
count should remain frozen (i.e., any outgoing trans-
action from this account can be noticed by the service
provider from the public ledger and the subscription
will be cancelled). As long as the user respects the
service agreement the collateral remains safe and the
user may reclaim it when the service contract termi-
nates.

232Assumption Ciphertext size Upper bound on t Recoverability

Construction I
Construction I
Construction II
Construction II

PKE
PKE
LWE

iO

O(t2 log2(n/))

O(log(n/)/λ)

O(t4λ)

O(t3+epoly(λ))

O(1)

n
n
n

Black-box
Black-box
Black-box
Black-box

Figure 1: Comparison of our TDS’s; t is the collusion size, n is total number of users, e = 1/poly(λ),  is the
error term in the ﬁngerprinting code which is negl(λ) and λ is the security parameter. PKE denotes public-key
encryption, LWE denotes the learning with errors problem, and iO denotes indistinguishability obfuscation.

Related primitives. As discussed above, a TTS aims at
providing “a posteriori” deterrence of malicious users while
TDS provides, in addition, a proactive way of deterrence.
Furthermore, traitor tracing is possible only when the au-
thority gains access to the pirate box, while in a TDS, the
mere act of sharing a decryption key (or any, even partially
working, implementation of a decryption algorithm contain-
ing such key) will lead to the leakage of one of the traitors’
secrets. We show that a traitor deterring scheme implies a
publicly traceable traitor tracing scheme [8] (cf. Section 2).
Another closely related notion to a TDS is digital signets
for self-enforcement [12]. In this multi-user encryption sys-
tem, the adversary that controls a set of traitor user keys
and wants to retransmit a certain plaintext that was trans-
mitted, will either send a message as long as the plaintext
itself, or will have to leak some of the traitors’ private data.
The formalization of the problem in [12] assumes that re-
coverability of the collateral information requires direct ac-
cess to the traitor keys (also called white-box access).
In
our terminology, they provide a symmetric-key TDS that
is only secure in the non-black-box sense. The construc-
tion provided by [12] relies on the unfalsiﬁable assumption
that f (x) = gx
(cid:96) is incompressible (incompress-
ible means given x, f , no adversary can come up with an
intermediate value y, such that: (1). |y|/|f (x)| = o(1); (2).
one can recover f (x); (3). x remains hidden).

2|| . . .||gx

1||gx

Kiayias and Tang studied the problem of leakage deter-
ring (LD) public key cryptography [21]. If a key owner leaks
any partially working decryption box, a piece of secret infor-
mation that is embedded in her public key will be revealed
to the recipient. Our notion of TDS is a generalization of
LD from the single user setting to the multi-user setting.
We note that because of collusion attacks in the multi-user
setting the techniques for recoverability from [21] are not
directly applicable for building a TDS (even a scheme with
ciphertext size linear in the number of users is not obvious).
2. DEFINITIONS AND SECURITY MODELS
We provide the formal deﬁnition and security model of

TDS’s and demonstrate their relationship to TTS’s.
Syntax of traitor deterring schemes. Informally, a traitor de-
terring scheme is a multi-user encryption scheme with a de-
terring mechanism such that if some of the receivers collude
to leak an implementation of a (potentially only partially
working) decryption device, any recipient of the device will
be able to recover one of the colluding user’s secret informa-
tion which is hidden in the public parameter of the system.
Formally we have the following:

• Setup(1λ, s1, . . . , sn): This algorithm is composed of
two parts: KeyGen, which, on input the security pa-
rameter it outputs an encryption key pk, and a set of

decryption keys sk1, . . . , skn; and ParGen that on in-
put pk, sk1, . . . , skn and the users’ secrets s1, . . . , sn ∈
{0, 1}λ it outputs public parameter para.

• Enc(pk, m): on input para, pk and a message m, it

outputs a ciphertext c.

• Dec(ski, c): on input para, pk, one of the secret keys

ski and a ciphertext c, it outputs a plaintext m.

• RecB,D(pk, para): on input para, pk with has oracle
access to a device B and a distribution D it outputs a
string in {0, 1}λ or ⊥.

The correctness of the scheme is standard and entails
that Enc(pk,·) can be inverted by Dec(ski,·) for any i =
1, . . . , n. The intended functionality of the algorithm Rec
is that if B is created by a collusion of receivers with se-
cret keys ski1 , . . . , skit and operates correctly for ciphertexts
whose corresponding plaintext follows a distribution D, the
algorithm outputs at least one of the strings si1 , . . . , sit . We
clarify the conditions under which this is supposed to hap-
pen (as well as the other necessary security properties) in
the next paragraph.

Security model. There are three security requirements for
a traitor deterring scheme, security of plaintexts, privacy of
user’s secrets, and traitor deterring.

IND-CPA security. Regarding security of plaintexts we
consider a security property of IND-CPA deﬁned in a stan-
dard fashion: the challenger C runs setup to obtain s1, . . . , sn
and provides the adversary A with para, pk. In response, A
provides two plaintexts m0, m1 to C. Subsequently C com-
putes ψ = Enc(pk, mb) for a random b ∈ {0, 1} and provides
ψ to A. A returns a bit b(cid:48) and C terminates with 1 if b = b(cid:48)
and 0 otherwise. The probability that C returns 1 means
that A is successful and we denote it by SuccindcpaA
(1λ). For
(1λ)] ≤ 1/2 +
security to hold it must be that Pr[SuccindcpaA
negl(λ). The notion of security can be extended in a straight-
forward manner to IND-CCA2.

Privacy. Regarding the privacy of user secret information it
should be the case that each si value remains hidden within
the public parameter even all other users are corrupted. For-
mally, consider the following game:

• The challenger C ﬁrst simulates the KeyGen part of
the Setup algorithm and returns pk to the adversary.
• The adversary A sends an index i as well as private

information {sj}j(cid:54)=i and the pair si,0, si,1 to C.

• The challenger C randomly ﬂips a bit b, and simulates
the ParGen part of Setup on input pk, sk1, . . . , skn,
s1, . . . , si−1, si,b, si+1, . . . , sn. C sends to A the values
para, sk1, . . ., ski−1, ski+1, . . . , skn.

• A returns a single bit b(cid:48) and C returns 1 if b = b(cid:48).

233The event that C returns 1 means A is successful and we
denote it by SuccprivA (1λ). For privacy of secret information
to hold it must be that Pr[SuccprivA (1λ)] ≤ 1/2 + negl(λ) for
any PPT adversary A. Note that letting the challenger send
the public key ﬁrst makes the deﬁnition stronger. It is also
possible to deﬁne weaker variants of the above deﬁnition,
e.g., where A is restricted to a number t of secret-keys or
the pk is returned together with the secret keys.

Traitor-Deterring. Finally we deﬁne the traitor deter-
ring property.
In order to specify the deﬁnition we need
ﬁrst to deﬁne the notion of δ-correctness with respect to a
public-key pk and a plaintext distribution D. A device B
is δ−correct with respect to D and pk if it satisﬁes that
Pr[B(Enc(pk, m)) = m : m ← D] ≥ δ. With the public
parameter, and a non-trivial pirate decryption box B which
is created by the collusion of all users, the recovering algo-
rithm should determine of the colluder’s secret information
si. Formally, consider the following game:

• The challenger C simulates the Setup algorithm and
the adversary A receives pk. A then provides a vector
of secret information s1, . . . , sn as well as an arbitrary
subset T ⊆ {1, . . . , n} to the challenger C and A re-
ceives the secret keys of all users in T , {ski | i ∈ T} as
well as the public parameter para.

• A outputs an implementation B and a distribution D.
• C returns 1 iﬀ RecB,D(pk, para) (cid:54)∈ {si | i ∈ T}.
We deﬁne by SuccdeterA (1λ) the event that C returns 1.
We say a scheme achieves fully collusion resilient, black-box
traitor deterring w.r.t. a class of distributions D (that may
depend on δ) if for any PPT adversary A it holds that
Pr[B is δ-correct w.r.t. D∧D ∈ D∧SuccdeterA (1λ)] = negl(λ).
In the above experiment we assume that Rec has reset-
table black-box access to B. Weaker variants of the above
formulation may be relevant in some settings and can be “t-
collusion resilient” (as opposed to fully-collusion resilient) or
they may extend Rec’s access to B (e.g., in a non-black-box
setting Rec may have access to the traitor keys).
Deﬁnition 2.1 (cid:104)Setup, Enc, Dec, Rec(cid:105) is a (fully-collusion
resistant, black-box) traitor deterring scheme if it satisﬁes,
(i) correctness, (ii) IND-CPA security, (iii) privacy and (iv)
fully-collision resistant, black-box traitor deterring.

TDS and TTS. We conclude the section by a brief argu-
ment that a traitor deterring scheme is a strict generalization
of a traitor tracing scheme (in fact of a TTS with “public-
traceability” [8]). Given a TDS: (cid:104)Setup, Enc, Dec, Rec(cid:105),
the reduction is easy with the following simple observation.
First we set si = i for all i = 1, . . . , n. It follows that the
Setup algorithm requires no other input other than the se-
curity parameter λ. Observe now that the Rec algorithm
will output one of the indices of the colluding users who
jointly produce the decryption box B with only access to
pk, hence it is a TTS with public-traceability.

3. TRAITOR DETERRING FROM FINGER-

PRINTING CODES

In this section, we will present our ﬁrst technique of con-
structing a TDS from ﬁngerprinting codes. We ﬁrst formal-
ize a new encryption scheme we call fuzzy locker (w.r.t a

ﬁngerprinting scheme), from which together with a public
key encryption, we will construct a TDS. We then give a
concrete construction of fuzzy locker for CFN codes [9].

First, let us recall the deﬁnition of ﬁngerprinting codes
[20]. A q-ary ﬁngerprinting code is a pair of algorithms
(Gen, Accuse). Gen is a probabilistic algorithm with input
a security/error parameter  and two numbers n, t denoting
the number of users and the maximum collusion size respec-
tively, and t ∈ [n] = {1, . . . , n}. It outputs n q-ary strings
C = {C1, . . . , Cn} (called codewords), where Ci = ci
1 . . . ci
for i ∈ [n], j ∈ [(cid:96)], ci
j ∈ Q–the alphabet set with size q and
(cid:96)
a tracing key tk. Accuse is a deterministic algorithm with
input a “pirate” codeword C∗, and a user codeword Ci and
the tracing key tk; it outputs a bit in {0, 1}.
Suppose adversary A corrupts up to t users (whose indices
form a set Ucor ⊂ [n]), and outputs a pirate codeword C∗ =
(cid:96) . We deﬁne the accused user set as Uacc = {i ∈
1 . . . c∗
c∗
[n] : Accuse(tk, C∗, Ci) = 1]. A ﬁngerprinting code is called
t−collusion resistant (fully collusion resistant if t = n) if
it satisﬁes: (i) traceability, if the strategy of producing C∗
satisﬁes the “marking assumption”, (for each i ∈ [n], c∗
i =
i for some j ∈ Ucor), then one of the colluders must be
cj
accused, i.e., Pr[Uacc ∩Ucor = ∅] ≤ ; and (ii) soundness, the
probability that an innocent user is accused is bounded by
, i.e., Pr[([n] − Ucor) ∩ Uacc (cid:54)= ∅] ≤ .

3.1 TDS from fuzzy lockers.

Fingerprinting codes are combinatorial designs that en-
able testing whether a codeword is used in generating a pi-
rate codeword. They were demonstrated to be very useful in
building TTS in a line of previous works, e.g., [3, 9, 22]. The
basic idea is that each user will be assigned an “identity”
which is represented by a codeword, and the secret keys for
the user will be selected from a group of keys according to
his codeword. The encryption algorithm will cover all the
user keys. The tracing algorithm will ﬁrst recover a “pirate
codeword” by feeding the pirate decryption device with mal-
formed (but seemingly valid in the view of A) ciphertexts,
and then it will run the tracing algorithm of the ﬁngerprint-
ing code to identify at least one of the colluding users who
participated in producing the pirate codeword.

The main challenge of upgrading the above paradigm to
a TDS is the way of embedding and recovering of the secret
information of the users. To address this, we formalize a new
primitive we call fuzzy locker w.r.t. a (publicly traceable)
ﬁngerprinting code. In a fuzzy locker, a message is encrypted
using a random codeword Ci. The message can be decrypted
(“unlocked”) only if one provides a pirate codeword C∗ such
that Ci will be accused by the accusation algorithm, other-
wise, the message will remain IND-CPA secure. Given such
a primitive, one can construct a TDS as follows: the em-
bedding of the user private information can be simply done
via encryption using the user’s codeword (which is normally
randomly selected according to the Gen algorithm). The pri-
vacy requirement can be easily achieved via the security of
the fuzzy locker. The recover algorithm will ﬁrst retrieve a
“pirate codeword” from the pirate box and then it will try
decrypting all locked data using this pirate codeword. The
traitor deterring property can be guaranteed by the traitor
tracing property of the ﬁngerprinting code, since at least one
of the codewords used in producing the pirate codeword will
be accused and thus the private user data can be retrieved.
We ﬁrst give the formal deﬁnition and security model of

234a fuzzy locker. W.l.o.g., we can think of the Gen algorithm
of the ﬁngerprinting code C to operate in two phases, ﬁrst,
using n, t and the security parameter produces a secret state
st and then uses a C.Sample subroutine that produces the
codewords one-by-one while updating the state st.

Deﬁnition 3.1 A fuzzy locker w.r.t a (publicly traceable)
ﬁngerprinting code C consists of the following two algorithms:
• FL.Enc(Ci, m): Given a codeword Ci ← C.Sample
and a message m, the encryption algorithm outputs
a ciphertext c.

• FL.Dec(C∗, c): Given a ciphertext c and a string C∗,

the algorithm outputs a message m or ⊥.

Correctness: If C.Accuse(tk, Ci, C∗) = 1:

Pr[FL.Dec(C

∗

, c) = m] ≥ 1 − negl(λ).

Security of a fuzzy locker. We deﬁne t-resilient security (fully
resilient if t = n) of a fuzzy locker scheme in the sense of
IND-CPA security, by considering the following game be-
tween a challenger C and an adversary A:

• The challenger produces st using Gen on input , t, n

and sends C1, . . . , Ct ← C.Sample(st) to A.

• A selects two messages m0, m1 and sends them to C.
• The challenger randomly samples a codeword C0 ←
C.Sample(st), randomly ﬂips a coin b, and sends c =
FL.Enc(C0, mb) to the adversary A.

• A outputs her guess b(cid:48).

A fuzzy locker is t-resilient IND-CPA secure if:
| ≤ negl(λ).

FL = | Pr[b
A

Adv

(cid:48)

= b] − 1
2

Construction-I of TDS. Given a fuzzy locker and a public
key encryption (PKE) with the algorithms (KeyGen, Enc, Dec),
we can construct a TDS as follows:

• Setup(1λ, s1, . . . , sn, t): The algorithm ﬁrst runs the
(q-ary) codeword generation algorithm C.Gen which in-
puts the security parameter, and t, n, it returns {Ci}i∈[n],
tk, where Ci = ci
KeyGen of the PKE and returns q(cid:96) key pairs:

(cid:96). The algorithm then runs the

1, . . . , ci

(pk1,1, sk1,1), . . . , (pk1,(cid:96), sk1,(cid:96));
(pk2,1, sk2,1), . . . , (pk2,(cid:96), sk2,(cid:96));

. . .

(pkq,1, skq,1), . . . , (pkq,(cid:96), skq,(cid:96))

Finally, the Setup algorithm takes users’ secrets s1, . . . , sn,
tk, C1, . . . , Cn and all those key pairs as inputs, and
it outputs system parameter para, an encryption key
pk, and a set of decryption keys sk1, . . . , skn. Specif-
ically, pk contains all the public keys above; ski =
} for i ∈ [n]; and para contains tk
{sk1,ci
and (cid:104)ω1, . . . , ωn(cid:105), where ωi = FL.Enc(Ci, si).

, . . . , sk(cid:96),ci

1

(cid:96)

putes m(cid:96) = m−(cid:80)(cid:96)−1

• Enc(pk, m): This algorithm is given pk and a message
m. It ﬁrst randomly samples m1, . . . , m(cid:96)−1, then com-
i=1 mi and cti,j = Enc(pki,j, mj) for
i ∈ [q], j ∈ [(cid:96)]; it outputs the ciphertext ct = {cti,j}.
• Dec(ski, ct): This algorithm takes inputs para, pk, a
secret key ski and a ciphertext ct. It parses the secret
key and the ciphertext, and computes mj = Dec(skj,ci
i=1 mi. The algorithm outputs m.

and further m =(cid:80)(cid:96)

j

, cti,j)

• RecB,D(pk, para): This algorithm inputs para, pk and
has oracle access to a device B and a distribution D. It
ﬁrst runs the following procedure for each index k ∈ [(cid:96)]
to extract a pirate codeword from B:

and computes mk = m −(cid:80)

1. It initializes the pointer value i0 = 1.
2. It samples m ← D, samples messages {mi}i(cid:54)=k
3. It feeds ciphertext {cti,j} to B where ci,j = Enc(pki,j, mj)

i(cid:54)=k mi.

if j (cid:54)= k or i > i0; and ci,k = Enc(pki,k, ri) for
i ≤ i0 where ri is a random message.

denoted by n0.), or it returns ri0 +(cid:80)

4. If in N runs (a value that will be determined in
the analysis), the number of times n1 that B re-
turns m correctly is suﬃciently smaller than that
in the (i0 − 1)−th experiment (the diﬀerence is
j(cid:54)=k mj the
algorithm returns c∗
k = i0; otherwise, it stores n1,
sets i0 = i0 + 1, and repeats from step 2.

The pirate codeword retrieved is C∗. The algorithm
parses para to identify the data (cid:104)ω1, . . . , ωn(cid:105). It then
runs the decryption algorithm of the fuzzy locker on all
of them, i.e, for i ∈ [n], it runs FL.Dec(C∗, ωi) = s∗
i .
The algorithm stops if ∃s∗

i (cid:54)= ⊥ and it returns s∗
i .

Security analysis. Due to lack of space, we present here
only a brief sketch about the security properties, and refer
to the full version for the detailed proofs.

Regarding IND-CPA security, it follows in a straightfor-

ward manner from the security of the underlying PKE scheme.

Regarding privacy of the honest user secrets, follows easily

from the security of the fuzzy locker.

Regarding the black-box traitor deterring property, note
that the Rec algorithm proceeds in two steps, it ﬁrst recov-
ers a pirate codeword C∗ from the box B. If there exists
a colluder codeword Ci, s.t., Accuse(tk, C∗, Ci) = 1, then
in the second step, according to the correctness of the fuzzy
locker, the decryption of FL.Dec(C∗, ωi) will return si. The
security of the ﬁngerprinting code guarantees that if any pi-
rate codeword is produced following the “marking assump-
tion”, it can be used to accuse at least one of the colluders.
The IND-CPA security of the underlying PKE scheme es-
sentially enforces the “marking assumption.” To see this,
suppose the collusion user secret keys are {ski} for i ∈ Ucor,
for each index j, the alphabet c∗
for the pirate codeword
for k (cid:54)∈ Ucor with probabil-
at index i can not be any ck
ity signiﬁcantly larger than the guessing probability δ − α.
i
Otherwise, these keys may be used to decrypt a ciphertext
encrypted under a public key pkk,i.

i

The choice of N, n0 can be easily determined as follows.
There must exist an index i0 such that the probability of
returning a correct plaintext (denoted by p1) is at least [δ −
(δ − α)]/q = α/q smaller than that for i0 − 1 (denoted by
p2). From the Chernoﬀ bound Pr[X < (1− ω)µ] ≤ e−ω2µ/2,
let us use X 1
i = 1 denote the event that decryption query
for i0 − 1 is answered correctly while X 2
i = 0 denote that for
i0 is not answered correctly. Also we use Xi = 1 denote the
above joint event, i.e., Pr[Xi = 1] = Pr[X 1
i = 0] =
p1(1−p2) ≥ p1−p2 ≥ α/q. When we set N = q
α log2 λ, n0 =
α
2q N , where λ is the security parameter, the gap will almost
always appear and thus a pirate codeword will be identiﬁed.

i = 1 ∧ X 2

Theorem 3.2 Given a public key encryption scheme, and
a fully secure fuzzy locker (for a q-ary ﬁngerprinting code),
there exists a TDS satisfying: fully collusion resilient, black-

235box traitor deterring property w.r.t to any message distribu-
tion D that has min-entropy H∞(D) ≥ − log(δ − α), where
δ is the correctness required by the adversarial device, α is
a non-negligible amount that is signiﬁcantly smaller than δ,
and the parameters are set to be N = q
3.2 A Fuzzy locker for CFN codes.

α log2 λ, n0 = α

2q N .

1, . . . , cj

We now propose a construction for a fuzzy locker w.r.t.
CFN codes [9].Consider the CFN ﬁngerprinting scheme where
the collusion size is set to be t; in order generate a codeword
(cid:96) ←
for a user j, the authority randomly samples cj
[q](cid:96). The tracing algorithm accuses the user whose codeword
has the largest number of locations that share the same sym-
bol with the pirate codeword. Observe that this accusation
procedure is identical to ﬁnding the “closest” among all user
codewords to the pirate codeword. To put it in another
way, the user codewords are random strings, but the trac-
ing property of the CFN code guarantees that under the
“marking assumption”, any pirate codeword produced by a
collusion of no more that t random codewords will have a
small L1-distance to one of the colluder codewords.1 To
facilitate the construction of the fuzzy locker we employ a
fuzzy extractor [11] which enables one to retrieve the same
random string from two diﬀerent but correlated strings that
have high entropy (cf. the fuzzy vault scheme [18]).

In more detail, most of the fuzzy extractors follow a correct-
then-extract strategy. When the two strings are close enough,
an error correcting code (ECC) can be used to eliminate
their discrepancies and then a randomness extractor [7] is
applied to extract a uniform output (which will later be used
as a key) from the high entropy codeword (which will be the
source from the point of view of the extractor). However for
the fuzzy locker for CFN codes, the portion of disagreement
(errors) between the codeword used for encryption and the
pirate codeword extracted for decryption is quite large and
beyond the decoding capability of a unique decoding ECC.
We thus give up perfect correctness for the fuzzy locker, and
turn to the use of list decoding [17, 30]. In a list decodable
code, the error correction returns multiple candidates, but
it can decode eﬃciently a number of errors up to portion
almost 1 (as opposed to unique decoding). One last thing
we need to be careful is that the rate of the ECC should
be selected in a way that the entropy loss will not prohibit
randomness extraction.

Combining the above tools, we will use the uniform string
extracted from the fuzzy extractor as a secret key to en-
crypt the user secret data. We further will assume the valid
messages are easily identiﬁable, and that decryption using a
wrong key will almost never yield a valid message. These two
assumptions are easy to achieve by including in the plaintext
a message authentication code or a signature on the message,
for details about this technique, we refer to [11, 24].
Fuzzy locker for CFN codes.: We present below the
fuzzy locker for CFN codes; the choices of the parameters
will be speciﬁed later. Given a randomness extractor Ext
and a secure symmetric key encryption (SE.Enc, SE.Dec):
• FL.Enc(C, m): The algorithm inputs C = c1 . . . c(cid:96)

U←−
F (cid:96)
q , and message m. It ﬁrst samples a random ((cid:96), κ)q
Reed-Solomon code X = x1, . . . , x(cid:96) which can correct
1Actually, from the analysis of CFN one infers that if the
pirate codeword and user codeword agree on more than (cid:96)/t
symbols, the user can be accused.

up to (cid:96) − (cid:96)/t errors, and computes Y = (cid:104)y1, . . . , y(cid:96)(cid:105),
where yi = ci + xi mod q; It then selects a random
bitstring s and computes k = Ext(s, C), 2 and c =
SE.Enc(k, m). The algorithm outputs ct = (Y, s, c).

1, . . . , X(cid:48)

(cid:96) and ciphertext ct, it ﬁrst computes C(cid:48) = c(cid:48)
i = yi − c∗

• FL.Dec(C∗, ct): On input a pirate codeword C∗ =
c∗
1 . . . c(cid:48)
1 . . . c∗
where c(cid:48)
i mod q, and it runs the list de-
coding algorithm on C(cid:48) to get a list of RS codewords
{X(cid:48)
L}. It then computes a list of possible user
codewords {C1, . . . , CL} where Ci = Yi − X(cid:48)
i, where
“-” stands for component-wise modular subtraction.
The algorithm tries the following procedure for ev-
it computes ri = Ext(s, Ci) and
ery user codeword:
If there exists an m (cid:54)= ⊥, the
mi = SE.Dec(ri, c).
algorithm outputs m, otherwise, it outputs ⊥.

(cid:96)

Security analysis. Regarding correctness. First we re-
call the basic idea of the CFN code. It randomly samples
C ← F (cid:96)
q . Suppose t users (w.l.o.g., we assume they have
codewords C1, . . . , Ct) collude to produce a pirate codeword
C∗. Due to the marking assumption, each symbol c∗
i equals
to one of the corresponding symbols in C1, . . . , Ct. It follows
easily that there exists a Ci, such that C∗ and Ci agree on at
least (cid:96)/t locations. We now check the decryption algorithm
on cti = FL.Enc(Ci, mi). C(cid:48) = Y − C∗ = X + (C − C∗)
(cid:96)} agree with x1, . . . , x(cid:96) on at least (cid:96)/t
mod q, thus {c(cid:48)
1, . . . , c(cid:48)
locations. For a Reed-Solomon code RS: Σκ → Σ(cid:96), it can
(cid:96)κ errors. If we have (cid:96)/t ≥ √
decode at most (cid:96) − √
(cid:96)κ, then
RS would return a list of possible candidates which contains
the actual X. Then Y − X would yield the user codeword
Ci; correctness then follows easily.

Regarding security: for any honest user whose codeword
C that is uniformly selected, we can think it is selected after
the pirate code C∗ is produced. Following the probabilistic
 /3, and q ≥ 4t, it holds
analysis from [9], if (cid:96) ≥ 4t log n
that Pr[C∗, C agree on (cid:96)/t locations] ≤ .
It follows that
the decoding algorithm will not return any user codeword.
A bit more formally, we can think of the ciphertext (Y, s, c)
as being generated following the KEM/DEM [10] framework,
where Y, s encrypt the session key k which is used to encrypt
the data in c. Conditioned on Y, s, the min-entropy of C can
be calculated as (cid:96) log q− ((cid:96)− κ) log |Σ| as s is independent of
C, Y is of length (cid:96), and the original random codeword has
entropy κ log |Σ|. Now if we have (cid:96) log q − ((cid:96) − κ) log |Σ| ≥
Θ(λ), the strong extractor can output a suﬃciently long
uniform key k, thus Y, s form a secure KEM. Now the IND-
CPA security of the message follows from the security of the
symmetric key encryption. Due to lack of space, we defer
the detailed proof in the full version.

Setting up the parameters. There are multiple con-
straints about selecting the parameters for the ﬁrst con-
struction of TDS from the CFN code. More speciﬁcally,
for parameters (cid:96), κ, n, t, , λ being the dimension and de-
gree of the RS code, the number of users, the bound of
colluders, the error term in the ﬁngerprinting code and the
security parameter respectively, they have to satisfy: (1).
(cid:96) ≥ max(κt2, 4t log n

 ); (2). (cid:96) log q − ((cid:96) − k) log (cid:96) ≥ Θ(λ).

 , we can choose (cid:96) = q = 4t log n,
and κ = Θ(λ). The resulting traitor deterring scheme will

When κt2 ≤ 4t log n

2we assume here extractors can be applied to large alphabet,
if not, we can simply use the bit string representing C to be
the input to the extractor.

236have ciphertext size O(t2 log2 n
the collusion size is t = O(log n

 ), and the upper bound of
 /λ);

When κt2 ≥ 4t log n

 , we can choose (cid:96) = q = λt2, and
κ = Θ(λ). The resulting traitor deterring scheme will have
ciphertext size O(λt4) for any collusion size t.

To summarize, if we select the parameters in a way that
all the conditions above are satisﬁed, then the correctness
and security of the fuzzy locker for CFN code follows. Then
from the general construction, we can conclude that:

Corollary 3.3 Given PKE, there exists a TDS satisfying:
fully-collusion resilient, black-box traitor deterring w.r.t. to
any message distribution D that has min-entropy H∞(D) ≥
− log(δ − α), where δ is the correctness probability required
by the adversarial device and α is a non-negligible amount
signiﬁcantly smaller than δ. And it is with ciphertext size
O(log n
 /λ.
4. CONSTRUCTION FROM COMPARISON

 /λ; and O(t4λ), if t ≥ 4 log n

 /λ) when t ≤ 4 log n

PREDICATE ENCRYPTION

In this section, we will present our second technique of
constructing TDS’s based on comparison predicate encryp-
tion (CPE) with an exponentially large attribute space. We
ﬁrst give the general construction of TDS, then instantiate
the CPE from (optimized) bounded collusion functional en-
cryption. The resulting TDS exhibits better eﬃciency than
our CFN construction for larger traitor collusions.
4.1 TDS from CPE.

In a CPE, decryption succeeds only when v ≤ x, where
x, v are the attributes for the the ciphertext and the secret
key respectively. Moreover, besides standard security, it also
requires an attribute hiding property that no adversary A
can distinguish c0, c1 which have attributes x0, x1 (assuming
x0 < x1) respectively, as long as A does not have a secret
key skv such that x0 ≤ v < x1 (even if A has secret key skv
that can decrypt both c0, c1). (This corresponds to the fully
attribute hiding of predicate encryption [19]).

It was shown in [4,5] that a weaker version of CPE (called
private linear broadcast encryption in [4], which has only a
polynomially large identity space) implies a TTS. In the con-
struction, each user is assigned an integer index as identity,
and the encryption scheme has the property that Enc(pk, i, m)
is indistinguishable from Enc(pk, i + 1, m) provided A does
not hold ski. Thus the tracer can do a linear scan in the iden-
tity space and feed ciphertexts generated using attributes
from 0 to n + 1 for each test. If he notices a gap between the
responses for some i, and i + 1, then the user i will be ac-
cused. The gap is guaranteed to exist as all users can decrypt
Enc(pk, n + 1, m) and no user can decrypt Enc(pk, 0, m).

To construct a TDS, we observe that if the indices are cho-
sen randomly from an exponentially large space, they could
be used as secret keys to hide the user private information.
Unfortunately, it is not clear how to generalize [4, 5] to an
exponentially large identity space. We tackle this problem
by constructing CPE’s for an exponential large attribute
space from functional encryption; furthermore, we apply a
binary search type of tracing.
In particular, in each step
of search (feeding a sequence of tracing ciphertexts using a
corresponding pivot identity), the recovering algorithm only
consider two states for the pirate box. It is functioning, if
the decryption probability is close to the claimed correctness
of the pirate box; or not functioning, otherwise. Then Rec

decides to move to a smaller pivot or a larger one.Given
a CPE (CPE.Setup,CPE.KeyGen,CPE.Enc,CPE.Dec) and an
authenticated encryption (AE.Enc, AE.Dec), our second con-
struction of TDS (construction-II) is as follows:

• Setup(λ, n, s1, . . . , sn): It ﬁrst runs the CPE.Setup al-
gorithm to output a master key pair (mpk, msk), then
it randomly selects n bitstrings id1, . . . , idn with length
(cid:96), (that is as an integer, each idi ∈ [2(cid:96) − 1]), and runs
the CPE.KeyGen algorithm to generate secret keys for
the users. For user i it assigns the identity idi and then
generates the secret key ski =CPE.KeyGen(msk, idi).
It embeds the secret information of the user si as the
ciphertext ωi = AE.Enc(idi, si). The setup algorithm
outputs public key mpk, secret keys sk1, . . . , skn, and
the public parameter para, where para = (cid:104)ω1, . . . , ωn(cid:105).
It runs CPE.Enc(mpk, 2(cid:96), m) and re-

• Enc(mpk, m):

turns the corresponding output c as ciphertext.

• Dec(ski, c): This algorithm runs CPE.Dec with input

ski and ciphertext c and returns m or ⊥.

• RecB,D(mpk, para): The algorithm maintains a counter
j with initial value (cid:96)− 1 and repeats the following pro-
cedure until j = 0: It ﬁrst samples a sequence of mes-
sages m1, . . . , mN from D; then it generates the query
ciphertexts c1, . . . , cq, where ci =CPE.Enc(mpk, p, mi)
for the position p = 2j and records how many correct
answers does the box B produce; If the number of cor-
rect decryptions is more than n0, the algorithm will set
the pivot for the next test position to be p := p− 2j−1,
otherwise p := p + 2j−1; The algorithm then decreases
the counter j := j − 1 and repeats the procedure. The
values for the parameters N, n0 will be determined in
the analysis. Suppose the above algorithm stops at po-
sition p. The Rec algorithm then runs AE.Dec(p, ωi)
on all ωi and returns the ﬁrst non-⊥ value si.

Remark: We may implement the authenticated encryption
as SE.Enc(k, s||σ) where σ = Sig(s), where Sig is a signature
scheme and the veriﬁcation key is included in para where
SE.Enc is any secure symmetric key encryption scheme.

Analysis. Correctness and privacy follow straightforwardly,
so we focus on the intuition of the black-box traitor-deterring
property. Let us ﬁrst present the following observations. (1).
If all the colluder identities are smaller than the index p used
in the tracing ciphertext, the box will decrypt correctly with
probability close to δ. This holds because of the the attribute
hiding property that CPE.Enc(mpk, p, m) is indistinguish-
able from the regular ciphertext CPE.Enc(mpk, 2(cid:96), m). From
this it can be deduced that failing to decrypt with proba-
bility close to δ suggests that at least one colluder identity
is larger than p, thus the algorithm will not err by moving
to a larger pivot. (2). Similarly, if all colluder identities are
larger than the pivot index p used in the tracing ciphertext,
the box will work with just negligible probability because of
the payload hiding property. It follows that decrypting with
a probability close to δ (non-negligible) implies at least one
colluder identities is smaller than the attribute in the tracing
ciphertext, and hence the tracing algorithm will not err by
moving to a smaller position attribute. (see lemmas in the
appendix.) The above observations imply that every move
is towards a subspace containing some pirate identities.

To be a bit more formal, consider a complete binary tree
which represents the whole identity space. We can think of

237the path walked by the Rec algorithm as moving along such
tree. It starts from the root (represented by index 2(cid:96)−1) and
moves to the root of a complete subtree in each step. We
will show via strong induction that in each move, the subtree
will contain at least one colluding identity.

Theorem 4.1 Construction-II satisﬁes fully collusion re-
silient, black-box traitor deterring property w.r.t.
to any
message distribution D with min-entropy H∞(D) ≥ − log(δ−
α) for some non-negligible α, s.t., δ ≥ 1.5α where δ is
the correctness probability provided by the adversarial device,
and the parameters N = α−2log2 λ, n0 = (δ − α

2 )N .

Proof. Correctness follows directly from the correctness
of the underlying CPE scheme. Privacy is also straightfor-
ward, as the user identity is uniformly sampled, the IND-
CPA security of the underlying encryption scheme guaran-
tees no information about the plaintext is leaked.

Regarding the traitor-deterring property: Suppose a pi-
rate box B is created using secret keys of the users id1, . . . , idt,
and it is with δ−correctness w.r.t a message distribution D,
s.t., H∞(D) ≥ − log δ0, where δ0 = δ − α, for some α. We
ﬁrst present three lemmas that follow easily from the pay-
load hiding and attribute hiding properties of CPE.
Lemma 4.2 If the underlying CFE is payload hiding, and
the tracing ciphertext C is created using a pivot p and mes-
sage m randomly sampled from D, and idi > p for all i =
1, . . . , t, then: | Pr[B(C) = m] − δ0| = negl(λ).
Lemma 4.3 If the underlying CFE is attribute hiding, and
two tracing ciphertexts C1, C2 are created using message m,
and pivots p1, p2 respectively, and for all i = 1, . . . , t, idi (cid:54)∈
[p1, p2), then: | Pr[B(C1) = m]− Pr[B(C2) = m]| = negl(λ).
Lemma 4.4 If the underlying CFE is attribute hiding, the
tracing ciphertext C is created using a message m randomly
sampled from D and a pivot p, and idi ≤ p for i = 1, . . . , t,
then | Pr[B(C) = m] − δ| = negl(λ).

when X = (cid:80) Xi, {Xi} are independent random variables

We then estimate the parameters n0, N for determining
whether B works. Following the Chernoﬀ bounds, Pr[X <
(1 − ω)µ] ≤ e−ω2µ/2, and Pr[X > (1 + ω)µ] ≤ e−ω2µ/3,
over {0, 1}, 0 < ω < 1, and µ = E(X). In this setting, Xi
is the event denoting when Rec feeds the i−th ciphertext
which encrypts a random message m sampled from D, the
box B returns the plaintext correctly. It follows that, if the
traitor indices are all smaller than the pivot, B works with
δ-correctness, Pr[Xi = 1] ≥ δ. After repeating N times, the
probability that at most n0 = (δ − α
2 )N correct answers are
returned by B is bounded by e−α2N/8. On the other hand,
if the traitor indices are all larger than the pivot, B works
with only probability δ − α. The probability that B returns
more than n0 correct answers is bounded by e−α2N/12.

Setting parameters N = α−2log2 λ, n0 = (δ − α

2 )N , less
than n0 correct answers means that there must be a traitor
index larger than the pivot; more than n0 correct answers
means there must be a traitor index smaller than the pivot.
Now we are ready to proceed to prove the theorem. We
can represent all users as leaves in a complete binary tree
indexed by {1, . . . , 2(cid:96)}; given this Rec moves a pivot per-
forming a binary search in this tree by selecting a sequence of
subtrees S0, S1, . . . in the following fashion: at move j ≥ 1,
the pivot pj deﬁnes the subtree Sj−1 as the subtree of the
complete binary tree that is rooted at a node v that has pj

as the index of the rightmost leaf of the left subtree of Sj−1.
Observe that S0 is the whole tree. We will prove by strong
induction that for all j ≥ 0, Sj contains a traitor. The base,
j = 0, is straightforward. Suppose that the statement is
true for S0, S1, . . . , Sj−1. We will prove for Sj.

Case 1. Suppose that Sj is a left subtree of Sj−1. This
means that there is a traitor with index at most pj (oth-
erwise, if all traitors had a bigger index, then by lemma
4.2 the pirate box would be unsuccessful and the recovering
algorithm would move to the right subtree of Sj−1). Now
suppose that none of the traitors belong to Sj and let u
be the largest index of a traitor that has index at most pj.
By the fact that u does not belong to Sj we know that at
least one of the subtrees S1, . . . , Sj−1 is a right subtree of
its containing parent subtree. Let Sk be such a subtree with
the largest k ≤ j − 1. Now note that when the recovering
algorithm used pivot pk (which lies in the center of subtree
Sk−1) it holds that: u ≤ pk. Observe that there is no traitor
with index in the set {pk + 1, . . . , pj}. Based on lemma 4.3
the decision of Rec when testing with pivot pj and pivot pk
should be the same (with overwhelming probability). This
leads to a contradiction as Rec moved to the right (resp.
left) when testing with index pk (resp. pj).

Similarly, we can argue for the case that Sj is a right
subtree of Sj−1. We can conclude that S(cid:96) is a single leaf
node and it also denotes a traitor.
4.2 Instantiations of CPE.

Next we will give concrete constructions of CPE support-
ing an exponentially large attribute space. We ﬁrst note
that, a straightforward instantiation can be obtained from
general functional encryption (FE) which can be constructed
using indistinguishability obfuscation (iO) [13]. The result-
ing TDS will have only a constant size ciphertext however
it will rely on assumptions related to multilinear maps [13].
We now present an instantiation from standard assump-
tions. Note that there exists a bounded collusion FE from
standard assumptions. In a TDS there is only a potentially
small (and in any case polynomially bounded) subset of users
that is colluding to produce a pirate box. We show how to
construct a CPE from bounded collusion FE.
Instantiation-I. General FE secure for a single key query
with succinct ciphertext was constructed in [14]. To am-
plify [14] to a q-query secure FE, one simply runs q indepen-
dent 1-query secure FE schemes in parallel. Each secret key
is generated using a diﬀerent master secret key (this step will
require that the authority maintains and updates a private
state to keep track of which master secret keys have been
used), while each master public key will be used to encrypt
the message resulting in a vector of q ciphertexts encrypting
the same message. Unfortunately using this scheme to in-
stantiate the CPE for a TDS would force q = n. To see this,
even if we choose q = n − 1, there exist a pair of users i, j
such that their secret keys are generated using a same mas-
ter secret key (say the k-th master secret key). When user
i, j are corrupted together, no security can be guaranteed for
the k-th 1-query secure FE instance, and the CPE scheme
cannot be shown secure. Thus the resulting TDS will have
ciphertext size O(n · poly(λ)) which is not preferable espe-
cially given that the collusion t might be much smaller than
n. We then show how to improve the ciphertext complexity.
Instantiation-II. A stateless q bounded FE was constructed
in [15] from a 1-query secure FE using techniques from se-

238ij =i1

cure computation, and their scheme guarantees security un-
der arbitrary collusion with size q, even if more keys are
issued (say n). We can use such a t-bounded FE to instan-
tiate a CPE facing t corrupted users. Unfortunately, the
parameters in [15] were chosen in a way that the ciphertext
size is as big as O(D2t6λτ ), where D is the maximum de-
gree of the polynomial representing the circuits describing
the functions that FE supports, and τ is the ciphertext size
of the underlying 1-query secure FE. For some parameters
d, N , in the construction, there are N 1-query secure FE in-
stances. The encryption algorithm will do a (d+1, N ) secret
sharing on the message and will encrypt each share indepen-
dently under the N 1-query FE instances. Each user will be
assigned a random subset (denoted by Γi, and |Γi| = dD+1)
of keys each of which is generated using the corresponding
master secret key. Note that prior to encrypting each share
is padded with additional randomness to ensure the simu-
lation can succeed.
In total there are N ciphertexts each
encrypting O(t2λ) plaintext elements. (See [15] for details.)
Reference [15] requires that the collusion of size t can not
break enough 1-query secure FE instances to get d+1 shares
and obtain extra information about the message. More
speciﬁcally, it requires |∪i(cid:54)=j(Γi∩Γj)| ≤ d. We observe that if
we can replace this condition to be |∪i1,...,ia (∩ia
Γij )| ≤ d,
for any integer a ≥ 2, through a probabilistic analysis, we
can bring down N to O((Dt)1+eλ) (for e = 1/(a − 1)). Do-
ing this optimization requires us to use an a-query secure FE
as the underlying building block. We can obtain a succinct
a-query secure FE for some polynomially bounded a by ap-
plying the technique of [15] to the succinct 1-query secure
FE of [14].
In this way we obtain a a-query FE that has
ciphertext size O(poly(λ)) which is independent from the
number of users. Then we can apply the extended proba-
bilistic analysis explained above and to obtain a t-query FE
with ciphertext O(t3+epoly(λ)). Note that we are using cir-
cuits for the comparison predicate only and thus the degree
D of the polynomial representing the circuits is at most λ.
Our CPE instantiation. Our ﬁnal CPE instantiation will
be a hybrid of the two instantiations above. When t ≤
1
3+e , we use instantiation-II, the optimized t-FE; when t >
n
1
3+e , we simply use instantiation-I of n-query secure FE.
n
The resulting TDS will be with ciphertext size min[O(t3+e ·
poly(λ)), O(n · poly(λ))]. As the succinct 1-query FE can
be built on fully homomorphic encryption [6] and attribute
based encryption [16], both of which can be based on the
LWE assumption [29] eﬃciently. We summarize the above,
and refer detailed analysis to the appendix.
Corollary 4.5 Under the subexponential LWE assumption,
there exists a TDS satisfying: fully collusion resilient, black-
box traitor deterring w.r.t to any message distribution D with
H∞(D) ≥ − log(δ− α) for some non-negligible α, where δ is
the correctness probability provided by the pirate box and δ ≥
1.5α, and the parameters N = α−2log2 λ, n0 = (δ − α
2 )N .
It has ciphertext length min[O(t3+e · poly(λ)), O(n· poly(λ))],
where n, t are total number of users and corrupted users,
e = 1/poly(λ), and λ the security parameter.
5. TRAITOR DETERRING IN THE KNOWN

CIPHERTEXT MODEL

In the known ciphertext model for TDS, the adversary has
a weaker goal: it aims to produce a pirate box that works
w.r.t. a given sequence of ciphertexts.

Because the sequence of ciphertexts is ﬁxed there is a triv-
ial way to implement the pirate decoder: simply store a
database of all the plaintexts. Thus, in the known cipher-
text model, the adversary should only win when the size of
the decoder is smaller than the trivial attack; formally, we
will associate an attack in this model with a “space rate”
that is equal to the size of the pirate box divided by the
length of the total plaintext contained in the known cipher-
text. An ideally secure scheme should work with respect to
any space rate o(1).

The known ciphertext model is applicable to the setting
of distributing content via CDs, or granting access to an
encrypted database, since in these cases, the attack occurs
after the target ciphertexts become known. (In contrast, the
original traitor deterring model is applicable to all other set-
tings, e.g., online streaming, and movie distribution in Pay-
TV etc.). Traitor deterring in the known ciphertext model
reformulates in the black-box public-key setting the prob-
lem of constructing digital signets as posed in [12]. In [12] a
construction for any space rate o(1) is presented however
it requires the unfalsiﬁable assumption that the function
f (x) = gx
is incompressible (as well as they
assume non-black-box recoverability). They leave as open
question whether a construction exists that is secure under
a falsiﬁable assumption; using our TDS’s we resolve this
open question in this section.
5.1 Deﬁnition: the known ciphertext model.

2|| . . .||gx

1||gx

(cid:96)

We provide the formal deﬁnition of the known ciphertext

model that strengthens our traitor deterring deﬁnition.
(1 − )-correctness. Since the pirate box B may work only
for the ﬁxed set of ciphertext SC = {c1, . . . , cn}, we require
for SC, it almost always works, i.e., Pr[B(i, ci) = mi] ≥ 1−
negl(λ), where mi is the Θ(λ) bit plaintext that is encrypted
in ci (note we also allow B to receive the index of ci).
Privacy: This is the same as in section 2.

Traitor Deterring for Known Ciphertexts. The main diﬀer-
ence with the traitor deterring property is that the adversary
is aware of the ciphertexts before making the device B, and
hence can embed some information into B so that B is able
to check the decryption queries and only works for the given
ciphertexts. Formally,

• The challenger C simulates the Setup algorithm and
the adversary A receives pk. A then sends to C a vec-
tor of secret information s1, . . . , sn, an arbitrary subset
T ⊆ {1, . . . , n} as well as a distribution Pk with sup-
port set that contains k-long vectors of plaintexts for
some k = O(poly(λ)). 3 A receives the secret keys
of all users in T , {ski | i ∈ T} as well as the public
parameter para.

• C samples (m1, . . . , mk) from Pk and sends A, the se-
quence of ciphertexts SC = (cid:104)c1, . . . , ck(cid:105) where ci =
Enc(pk, mi); ﬁnally, A outputs an implementation B.

• C outputs 1 if and only if RecB(pk, para) (cid:54)∈ {si1 , . . . , sit}.

A

We denote the event that C outputs 1 in the above game by
(1λ). We say a scheme achieves black-box traitor
SuccKCdeter
deterring for known ciphertexts with space rate s(k, λ) if for
any PPT adversary A,
3This includes the case of encrypting one single long message
(e.g., a movie ﬁle): it is ﬁrst divided into k blocks and each
block is encrypted individually.

239A

(1λ)]

kλ

Pr[B is (1 − )-correct w.r.t SC∧|B|
≤ s(k, λ)∧SuccKCdeter
is a negligible function on λ, where |B| denotes the size of
the program B. Note that for s(k, λ) = Θ(1) it is trivial to
construct a device B that allows the adversary to win the
above game — simply store all plaintexts m1, . . . , mk in B.
Thus, the question that is raised is whether it is possible to
deter with space rate that is o(1).
5.2 Feasibility and infeasibility for the known

ciphertext model.

At ﬁrst sight, it may seem impossible to have a black-
box recovering algorithm in the known ciphertext setting,
since the Rec algorithm is restricted by the fact that the
adversarial box is only guaranteed to work for a ﬁxed set of
ciphertexts. Indeed, although the size of B can be smaller
than the size of the ciphertexts it is supposed to work for,
there are ways for the adversary to embed some information
and check whether a submitted ciphertext belongs to the
targeted sequence, while reject all other ciphertexts submit-
ted to it. We formalize this intuition and we show a simple
attack following this principle that rules out the possibility
of black-box traitor deterring for known ciphertexts for a
range of space rates. However, we also observe that in order
for the box B to perform a membership test in the tar-
geted ciphertext sequence, the false positive probability of
the testing algorithm increases as the storage used by B gets
smaller. When the false positive probability becomes suﬃ-
ciently high, a random sample of ciphertext will be answered
by the box B with non-negligible probability δ, and thus B
becomes a δ−correct box in the regular model (as deﬁned
section 2); in this way, we can still apply our constructions
of TDS’s against known ciphertext type of attacks. For ease
of presentation, we consider only the 1-correct case, while
all results will also follow for the case of (1 − )-correctness.
The intuition behind the proof of the following theorem
is that when the suitable space bound is imposed on the pi-
rate device, it will have to resort to using the secret-key in a
suﬃciently large plaintext distribution that can be sampled
with a non-negligible probability from the plaintext space.
As a result, the decryption box, is a general purpose decryp-
tion box that is δ-correct for some non-negligible δ and thus
our recoverability algorithms developed for traitor deterring
can be applied in the known ciphertext model as well.

Theorem 5.1 There exists a TDS with superpolynomial in
λ plaintext space that satisﬁes black-box traitor deterring for
known ciphertexts with space rate s(k, λ) = O(log(λ)/λ) =
o(1) for any k = Ω(λ).

Proof. We will show that a TDS satisfying black-box
traitor deterring with any pirate box with λ−c-correctness
is also a TDS with black-box traitor deterring in the known
ciphertext model for any c ∈ N for the stated space rate.

First, we recall a lower bound of the false positive proba-
bility in the approximate membership testing problem (see
deﬁnition A.1 in the appendix) fwhen the space of the tester
is upper bounded. For a universe U with size u, and V ⊂ U
with size v, and v (cid:28) u, using space τ , the false positive η
of any membership tester satisﬁes 2τ ≤ (2η)v. (see Lemma
A.2 in the appendix).Applying logarithm to both sides, we
v −1, thus if τ ≤ c· v · log λ, we have η ≥ λ−c.
can get η ≥ 2− τ
Next, we will use the above result to show that a useful de-
cryption box B with size O(k· log λ) will have non-negligible

correctness w.r.t. uniform distribution over the message
space. Speciﬁcally, we will build an approximate member-
ship tester T (using B) for V = {(m1, c1), . . . , (mk, ck)}, a
subset of the universe U of all plaintext/ciphertext pairs,
with a similar storage as follows. Whenever queried a uni-
formly random pair (m, c), T queries B with c, if B outputs
m, T outputs 1, otherwise T outputs 0. It is easy to see that
if (m, c) ∈ V , T always accepts; if (m, c) (cid:54)∈ V , T accepts
with probability δ, where δ = Pr[B(c) = m ∧ (m, c) (cid:54)∈ V ].
Furthermore, T only needs an extra storage of O(λ) bits
to store the query and compare whether the answer of B
is valid. In the setting that k = Ω(λ), the storage of T is
still O(k · log(λ)). Observe that if δ is negligible, T is a
membership tester which violates the bound in Lemma A.2.
With the above claim, we can see that for a randomly
sampled ciphertext, the box B will answer with some prob-
ability δ and thus we can run the Rec algorithm and retrieve
the corresponding secret information of one of the colluders
assuming that the TDS works for δ w.r.t any distribution
D for which it holds that δ ≥ 2−H∞(D) + α where α is an
arbitrary non-negligible function.

Impossibility results. Next we will show that the above
bound of the size of B is essentially tight, by describing
a generic attack against any traitor deterring scheme for
known ciphertexts. The attacking strategy is simple: using
Bloom ﬁlters [1] the adversary produces a box that contains
a membership tester built in so that it will answer only when
the decryption query belongs to the ciphertext set. This
makes two boxes implemented using diﬀerent keys indistin-
guishable via only oracle access, thus black-box recoverabil-
ity will contradict privacy in this setting. For details of the
proof we refer to the appendix.

Proposition 5.2 There does not exist any, even 1-resilient,
black-box TDS in the known ciphertext model for space rate
s(k, λ) = Ω(log2 λ/λ) for any k.

6. USING BITCOIN AS COLLATERAL

Bitcoin is a decentralized cryptocurrency [25] that uses a
publicly maintained ledger to store transactions and record
transfers between bitcoin accounts. Each bitcoin account
is essentially a hash of a public-key and the owner of the
secret-key has the ability to transfer funds from the account
by posting a transaction in the bitcoin network that con-
tains a signature generated by the account’s secret-key. The
characteristic of bitcoin accounts is that the secret-keys rep-
resent complete ownership of the account.

We consider a TDS deployment for a broadcast service
where a service provider (SP) wants to use a certain amount
of bitcoin as collateral. Upon initiation of the service the
SP generates bitcoin accounts corresponding to each of the
n users setting si = (ai, ki) where ai is the bitcoin address
and ki is the associated secret-key. When a user joins the
system it requests from the user to transfer some amount
of x bitcoin to the ai bitcoin account. The SP shares the
account information (ai, ki) with the user so that it is en-
sured that the x bitcoin is a collateral and the user has the
option to obtain the collateral back whenever she wishes
(and cancel her subscription). The SP then embeds si into
the public directory. At the same time the SP gives to the
user the secret-key ski that corresponds to the account, and
sets a service agreement that the account should be “frozen”
such that no outgoing transaction is allowed until the user

240unsubscribes the service. The user from this point on can
use the service and decrypt ciphertexts associated with the
service. In regular intervals the SP checks the public ledger
to see whether any active account has an outgoing transac-
tion (no matter to who is transferred).
If there is such a
case the subscription of the user should be cancelled (this
would require the revocation of the key ski an issue that we
do not explicitly deal here but can be handled generically
via e.g., a re-key operation where the SP at regular intervals
refreshes the keys of the system keeping the same collaterals
for all the remaining subscribers). Observe that due to the
properties of TDS for as long as the user respects the service
agreement and does not share her secret-key her collateral
bitcoin remain safe. The user can collect her collateral bit-
coin whenever she wants to terminate the service.
7. CONCLUSION AND OPEN PROBLEMS
We formalize and construct the new cryptographic prim-
itive of TDS that achieves proactive deterrence of unautho-
rized device distribution and we show how bitcoin can be
used as a collateral for a TDS deployment.We also revisit
the open problem of digital signets and reformulate as TDS
in the known ciphertext model, and show how we can uti-
lize TDS to solve it under parameter choices that allow a
possibility result.

There are many interesting open problems that remain.
The ﬁrst one is how to construct a TDS with constant size
ciphertext under standard assumptions. This may require a
fuzzy locker for, e.g., Tardos code [31] which currently uses a
secret tracing algorithm. Also, a construction of unbounded
collusion secure CPE is another alternative which will be of
independent interest. Furthermore, combining a TDS with
a revocation system as in [27] to obtain a “Trace Deterring
and Revoke scheme” would be an important advance.

Acknowledgements This work was supported by Euro-
pean Research Council Project CODAMODA.

8. REFERENCES
[1] B. H. Bloom. Space/time trade-oﬀs in hash coding

with allowable errors. Commun. ACM, 13(7):422–426,
July 1970.

[2] D. Boneh and M. K. Franklin. An eﬃcient public key

traitor tracing scheme. In Advances in Cryptology -
CRYPTO ’99, pages 338–353, 1999.

[3] D. Boneh and M. Naor. Traitor tracing with constant

size ciphertext. In ACM CCS 2008, pages 501–510.
[4] D. Boneh, A. Sahai, and B. Waters. Fully collusion
resistant traitor tracing with short ciphertexts and
private keys. In EUROCRYPT 2006, pages 573–592.
[5] D. Boneh and B. Waters. A fully collusion resistant
broadcast, trace, and revoke system. In ACM CCS
2006, pages 211–220, 2006.

[6] Z. Brakerski and V. Vaikuntanathan. Eﬃcient fully
homomorphic encryption from (standard) LWE. In
FOCS 2011, pages 97–106.

[7] L. Carter and M. N. Wegman. Universal classes of

hash functions. J. Comput. Syst. Sci., 18(2):143–154,
1979.

[8] H. Chabanne, D. H. Phan, and D. Pointcheval. Public

traceability in traitor tracing schemes. In
EUROCRYPT 2005, pages 542–558, 2005.

[9] B. Chor, A. Fiat, and M. Naor. Tracing traitors. In

CRYPTO 94, pages 257–270, 1994.

[10] R. Cramer and V. Shoup. Design and analysis of

practical public-key encryption schemes secure against
adaptive chosen ciphertext attack. SIAM J. Comput.,
33(1):167–226, 2004.

[11] Y. Dodis, L. Reyzin, and A. Smith. Fuzzy extractors:

How to generate strong keys from biometrics and
other noisy data. In EUROCRYPT 2004, pages
523–540, 2004.

[12] C. Dwork, J. B. Lotspiech, and M. Naor. Digital

signets: Self-enforcing protection of digital information
(preliminary version). In STOC, pages 489–498, 1996.
[13] S. Garg, C. Gentry, S. Halevi, M. Raykova, A. Sahai,

and B. Waters. Candidate indistinguishability
obfuscation and functional encryption for all circuits.
In FOCS 2013, pages 40–49, 2013.

[14] S. Goldwasser, Y. T. Kalai, R. A. Popa,

V. Vaikuntanathan, and N. Zeldovich. Reusable
garbled circuits and succinct functional encryption. In
STOC’13, pages 555–564.

[15] S. Gorbunov, V. Vaikuntanathan, and H. Wee.

Functional encryption with bounded collusions via
multi-party computation. In CRYPTO 2012, pages
162–179, 2012.

[16] S. Gorbunov, V. Vaikuntanathan, and H. Wee.

Predicate encryption for circuits from lwe. IACR
Cryptology ePrint Archive, 2015.

[17] V. Guruswami and M. Sudan. Improved decoding of

reed-solomon and algebraic-geometry codes. IEEE
Trans on Information Theory, 45(6):1757–1767, 1999.

[18] A. Juels and M. Sudan. A fuzzy vault scheme. Des.

Codes Cryptography, 38(2):237–257, 2006.

[19] J. Katz, A. Sahai, and B. Waters. Predicate

encryption supporting disjunctions, polynomial
equations, and inner products. EUROCRYPT’08,
pages 146–162.

[20] A. Kiayias and S. Pehlivanoglu. Encryption for Digital

Content, volume 52 of Advances in Information
Security. Springer, 2010.

[21] A. Kiayias and Q. Tang. How to keep a secret: leakage

deterring public-key cryptosystems. In ACM CCS
2013, pages 943–954.

[22] A. Kiayias and M. Yung. Traitor tracing with constant

transmission rate. In EUROCRYPT’02, pages
450–465.

[23] K. Kurosawa and Y. Desmedt. Optimum traitor
tracing and asymmetric schemes. In Advances in
Cryptology - EUROCRYPT ’98, pages 145–157, 1998.

[24] S. Micali, C. Peikert, M. Sudan, and D. A. Wilson.

Optimal error correction against computationally
bounded noise. In TCC 2005, pages 1–16, 2005.

[25] S. Nakamoto. Bitcoin: A peer-to-peer electronic cash

system. 2009.

[26] M. Naor. On cryptographic assumptions and

challenges. In CRYPTO 2003, pages 96–109, 2003.
[27] M. Naor and B. Pinkas. Eﬃcient trace and revoke

schemes. FC ’00, pages 1–20.

[28] A. Pagh, R. Pagh, and S. S. Rao. An optimal bloom

ﬁlter replacement. In SODA 2005, pages 823–829.

241[29] O. Regev. On lattices, learning with errors, random

linear codes, and cryptography. J. ACM, 56(6), 2009.

[30] M. Sudan. Decoding of reed solomon codes beyond the
error-correction bound. J. Complexity, 13(1):180–193,
1997.

[31] G. Tardos. Optimal probabilistic ﬁngerprint codes. J.

ACM, 55(2), 2008.

APPENDIX
A. SOME OMITTED PROOFS
Proof of corollary 4.5. We ﬁrst analyze the parameters
of the instantiation of CPE in section 4.2.

For the parallel repetition construction, as every secret
key is generated from a diﬀerent master secret key, and the
ciphertext CT = {CTi}, and CTi = OneFE.Enc(mpki, m)
for the same message m. It is obvious that due to the secu-
rity of the underlying 1-query secure FE, every ciphertext
is simulatable given C(m) by running the corresponding 1-
query secure FE simulator.

Next, we will analyze the optimized q-query secure FE.
Following the analysis of [15], the only diﬀerence of our
scheme is that we use a c-query secure FE as the build-
ing block. We replace the ﬁrst restriction to be | ∪i1,...,ic
Γij )| ≤ d, as each instance now can assure security
(∩ic
given that the for less than d instances, the collusion of t
users have c keys.

ij =i1

Now we can analyze that this condition will improve the
size of N . To be more speciﬁc, suppose Xij denotes the ex-
pected size of the intersection of two random subsets Xi, Xj,
E(Xij|Xi = X) Pr[Xi = X] = E(Xij|Xi = X).

(cid:88)

E(Xij) =

X

To see this, for any X with size dD + 1, the expected value
E(Xij|Xi = X) is the same and the conditional distribution
follows the hypergeometric distribution with dD + 1 good
balls and tD +1 draws, thus E(Xij|Xi = X) = (tD +1)2/N .
For Xijk denoting the expected size of intersection of three

random subsets Xi, Xj, Xk, we have:

(cid:88)
(cid:88)

i

E(Xijk) =

=

=

Pr[Xij = i]E(Xijk|Xij = i)

Pr[Xij = i]i · (dD + 1)/N

i
(dD + 1)

N

E(Xij) =

(tD + 1)3

N 2

.

The expected size Ec of the disjoint of all possible inter-
Γij )| (we denote as γ)

Similarly, we can generalize the second formula to the ex-
pected size of intersection of c random subsets which is
(tD + 1)c/N c−1.
section of c subsets: | ∪i1,...,ic (∩ic
is the summation of all combinations of Xi1,...,ic , i.e.,
Ec = q(q−1) . . . (q−c+1)·(dD+1)c/N c+1 ≤ (2qdD)c/N c−1.
If we let Ec ≤ d
2 , i.e. let N = 4d(Dq)1+e, where e = 1 + 1/c,
then following the Chernoﬀ bound: for any δ > 0, Pr[X >
(1 + δ)E[X]] ≤ e

−δ2
2+δ E[X], thus:

ij =i1

Pr[γ ≥ t] = Pr[γ ≥ (1 + 1)Ec] ≤ e

− Ec

3 = e

−d/6.

While we are focusing on comparison predicate, which can

be easily implemented e.g., for two numbers x, v represented
using bits x1 . . . x(cid:96), v1 . . . v(cid:96), the comparison predicate [x ≤
v] ⇐⇒ [x = v] ∨ [x1 = 0 ∧ v1 = 1] ∨ [(x1 = v1) ∧ (x2 =
0 ∧ v2 = 1)] ∨ . . . ∨ [(x1 . . . x(cid:96)−1 = v1 . . . v(cid:96)−1) ∧ x = v], is
with degree at most (cid:96) = O(λ).
Summarizing the above analysis, if we set d = λ, N =
Γij )| ≥ d] ≤
O(q1+epoly(λ)), we have Pr[| ∪i1,...,ic (∩ic
e−λ/6 = negl(λ). Then following the analysis of [15], all the
ciphertexts can be simulated.
The ciphertext eﬃciency of the optimized scheme is that
O(N · S · τ ) = O(q3+e · poly(λ)), where N, S are the num-
ber of ciphertext and plaintext elements in each ciphertext
respectively, and τ is the size of ciphertext for each plain-
text element of the underlying succinct c−bound FE, for
c = poly(λ), arbitrary polynomially bounded integer.
tion is simply with ciphertext eﬃciency O(n · poly(λ)).

On the other hand, the parallel repetition based construc-

ij =i1

As the succinct 1-query secure FE can be constructed
assuming succinct fully homomorphic encryption and at-
tribute based encryption for circuit, and the following two
can be based on LWE assumption. Then following theorem
4.1, we can conclude as in the corollary.

Deﬁnition A.1 [1,7] For a subset V randomly chosen from
a universe U , the approximate membership testing problem
with a false positive probability η is to produce a data struc-
ture T such that, for a random element x ∈ U , if x ∈ V ,
T (x) always outputs 1, while if x (cid:54)∈ V , T (x) outputs 0 with
probability at least 1−η (i.e., it may output 1 with probability
at most η, a false positive).
Lemma A.2 [28]. For a universe U with size u, and V ⊂
U with size v, and v (cid:28) u, using space τ , the false positive η
in the AMT problem satisﬁes 2τ ≤ (2η)v.

Proof of proposition 5.2. We will show an attack that
uses up to Ω(k·log2 λ) space can defeat the black-box traitor
deterring if the privacy of the user data is also required.
The adversary selects a set k of distinct plaintexts S =
{m1, . . . , mk} and submits this as a distribution Pk. The
adversary furthermore corrupts user i and receives the cor-
responding set of ciphertexts S = {c1, . . . , ck}. A creates a
membership tester T with a false positive probability  for
S, such that T can be constructed using space O(k log 1
 ).
Using Bloom ﬁlters, [1, 28], if A uses space Θ(k log2 λ), then
 will be a negligible function in λ. A produces a pirate box
B with T built in, and when is given input c, B ﬁrst checks
whether c ∈ S (besides the storage, this checking program
has only a constant description). Assuming the test passes,
the algorithm applies the key ski to decrypt the ciphertext.
Assume there is a black-box recovering algorithm recov-
ers user i’s secret information when given oracle access to B,
and another adversary corrupts a diﬀerent user j and build
a similar box B(cid:48) s.t., it is the same as B only when inputs
passes the tester, B(cid:48) uses skj to decrypt the query and re-
spond. It is obvious that the input/output distribution of
B, B(cid:48) is statistically close (with the only diﬀerence because
of the negligibly small false positive), these two boxes can-
not be distinguished by any algorithm via only oracle access
to them. Thus the Rec algorithm will also return the same
output, i.e., secret information of user i when having oracle
access to B(cid:48), hence contradicting the privacy property.

242