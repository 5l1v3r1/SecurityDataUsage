Hey, You Have a Problem: On the Feasibility  
of Large-Scale Web Vulnerability Notification
Ben Stock, Giancarlo Pellegrino, and Christian Rossow, Saarland University;  

Martin Johns, SAP SE; Michael Backes, Saarland University and Max Planck Institute  

for Software Systems (MPI-SWS)

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/stock

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX On the Feasibility of Large-Scale Web Vulnerability Notiﬁcation

Hey, You Have a Problem:

Ben Stock

Giancarlo Pellegrino

Christian Rossow

stock@cs.uni-saarland.de
CISPA, Saarland University
Saarland Informatics Campus

gpellegrino@mmci.uni-saarland.de

crossow@mmci.uni-saarland.de

CISPA, Saarland University
Saarland Informatics Campus

CISPA, Saarland University
Saarland Informatics Campus

Martin Johns
martin.johns@sap.com

SAP SE

Michael Backes
backes@cs.uni-saarland.de

CISPA, Saarland University & MPI-SWS

Saarland Informatics Campus

Abstract

Large-scale discovery of thousands of vulnerable Web
sites has become a frequent event, thanks to recent ad-
vances in security research and the rise in maturity of
Internet-wide scanning tools. The issues related to dis-
closing the vulnerability information to the affected par-
ties, however, have only been treated as a side note in
prior research.

In this paper, we systematically examine the feasibility
and efﬁcacy of large-scale notiﬁcation campaigns. For
this, we comprehensively survey existing communica-
tion channels and evaluate their usability in an automated
notiﬁcation process. Using a data set of over 44,000 vul-
nerable Web sites, we measure success rates, both with
respect to the total number of ﬁxed vulnerabilities and
to reaching responsible parties, with the following high-
level results: Although our campaign had a statistically
signiﬁcant impact compared to a control group, the in-
crease in the ﬁx rate of notiﬁed domains is marginal.

If a notiﬁcation report is read by the owner of the vul-
nerable application, the likelihood of a subsequent res-
olution of the issues is sufﬁciently high: about 40%.
But, out of 35,832 transmitted vulnerability reports, only
2,064 (5.8%) were actually received successfully, result-
ing in an unsatisfactory overall ﬁx rate, leaving 74.5%
of Web applications exploitable after our month-long ex-
periment. Thus, we conclude that currently no reliable
notiﬁcation channels exist, which signiﬁcantly inhibits
the success and impact of large-scale notiﬁcation.

1

Introduction

The large-scale detection of vulnerabilities in Web appli-
cations has become signiﬁcantly more common over the
course of the last years. This can be attributed to two
concurrent developments: The ever-growing adoption of
open-source Web frameworks and the recent advances in
automated vulnerability detection.

Open-source Web application frameworks, such as
Joomla, Drupal, or WordPress, nowadays constitute the
technological basis for a vast number of Web sites. Thus,
a single vulnerability in any of these frameworks makes
tens of thousands of Web applications attackable at once.
Previously disclosed vulnerabilities range from Cross-
Site Scripting attacks [20], to more severe attacks like
SQL injections [10] or object deserialization ﬂaws [19].
Given the rise in maturity and efﬁciency of Internet-
wides scanning tools, such as ZMap [12], such ﬂaws can
effectively be identiﬁed on affected Web sites.

Furthermore, a recent stream of security research has
demonstrated automated approaches that are capable of
discovering Web vulnerabilities on a large scale. Ex-
amples of such research results include the discovery of
high numbers of Client-Side Cross-Site Scripting prob-
lems [22], server-side application logic ﬂaws [9], and in-
stances of vulnerable server-side infrastructure [13].

However, as soon as a researcher has discovered
security-critical vulnerabilities that affect thousands of
Web sites, she has an ethical dilemma: On the one hand,
with the awareness of a vulnerability comes the implicit
responsibility of disclosing it to the affected parties. On
the other hand, large-scale Web vulnerability disclosure
is non-trivial, has not been well-studied, and there are no
guidelines or suggestions on how to proceed.

Thus, in this paper, we explore the following ques-
tions: Is it actually feasible to disseminate vulnerability
information on a large scale? What are suitable com-
munication channels to reach out to the affected parties?
And does such a large-scale notiﬁcation campaign affect
the prevalence of vulnerabilities in the wild?

To answer these questions, we conduct the ﬁrst in-
depth study on the feasibility and efﬁcacy of large-scale
Web vulnerability notiﬁcation campaigns. To this end,
we establish a large body of vulnerable Web sites, suf-
fering from different types of vulnerabilities such as Re-
ﬂected or Client-Side Cross-Site Scripting bugs. We then
review communication channels to notify affected par-

USENIX Association  

25th USENIX Security Symposium  1015

ties at scale, including direct contacts (such as generic
email aliases and WHOIS contacts) and indirect chan-
nels (such as hosting providers or CERTs). We notify the
Web site administrators via these communication chan-
nels and compare how the vulnerabilities in the moni-
tored Web sites evolve over time compared to a control
group of vulnerable Web sites that we do not notify.

Our large-scale experiments reveal important take-
away messages for fellow researchers. First, we show
that while large-scale notiﬁcations can have a statistically
signiﬁcant impact on the ﬁx rate of vulnerable Web ap-
plications, the long-term impact is marginal. Second, we
therefore analyze the efﬁcacy of direct and indirect com-
munication channels, both with respect to reaching the
(initial) recipient of the notiﬁcation as well as the im-
pact of the channel on the vulnerability landscape. Third,
from our results, we derive the core challenges of noti-
ﬁcation campaigns and ﬁnd that failures to reach out to
contact persons cause the most severe degradation of suc-
cess rates. Finally, we cover the lessons we learned dur-
ing our pioneering efforts in order to assist researchers in
future large-scale notiﬁcation campaigns.

To sum up, we make the following contributions:

• We systematically evaluate the suitability of dif-
ferent communication channels for large-scale vul-
nerability disclosure and present a methodology to
measure the feasibility and efﬁcacy of such a dis-
closure process (§3).

• We document the results of a large-scale notiﬁca-
tion campaign, discussing the data set of vulnerable
domains (§4) and the impact our campaign of noti-
fying 35,832 vulnerable domains had (§5).

• Based on the observed (low) impact on the global
landscape, we analyze factors inhibiting the success
of large-scale disclosure campaigns (§6).

• We highlight key insights gathered in our study and
present directions for future work in this space (§7).

2 Problem Statement

the exception. Examples in the recent past include the
identiﬁcation of high numbers of vulnerable SSL imple-
mentations [13], Client-Side XSS vulnerabilities [22],
or execute-after-redirect ﬂaws in Ruby on Rails appli-
cations [9]. With higher numbers of affected parties,
manual effort becomes unfeasible, and hence responsible
disclosure transforms into a distinctly different problem.
Therefore, it is necessary to investigate notiﬁcation pro-
cesses that function with little to no human involvement.
Taking this overarching motivation into consideration,
we reach a set of distinct research questions: For one,
given a large number of vulnerabilities that affect a
similarly large set of disjoint site owners: How can a
scalable responsible vulnerability notiﬁcation process be
conducted? As manual effort is not a realistic option, an
automated vulnerability disclosure process is required.

Furthermore: What are suitable communication chan-
nels to report vulnerabilities? Not all methods to com-
municate vulnerability information can be easily used
in automated processes. Once suitable channels are se-
lected, it is necessary to examine how successful a large-
scale Web vulnerability disclosure process can be. Even
in an automated fashion, a large-scale notiﬁcation cam-
paign results in considerable effort: The notiﬁcation pro-
cess has to be set up, executed, and monitored. More-
over, even automated initial notiﬁcation will in many
cases lead to personal, non-automated communication
with a subset of recipients of the vulnerability reports.
Thus, it is reasonable to examine how signiﬁcant the pos-
itive effect of our campaign was. Based on the results
of such a study, another question arises: Which methods
were most successful in delivering notiﬁcation, and what
might inhibiting factors be?

An increasing number of security researchers (profes-
sional and academic) spend signiﬁcant time and effort
to discover and ﬁx security-critical software bugs, often
wondering about how to proceed with large-scale disclo-
sure processes. With the aforementioned research ques-
tions, we aim to shed light on the under-explored issue
of whether, how and with what chance of success re-
searchers can notify affected parties.

In this section, we outline the research questions we aim
to answer. Secondly, we follow up with information on
the actual vulnerabilities we consider for our work.

2.1 Research Questions
The ad-hoc process of reporting individual Web-related
vulnerabilities to a single vendor is fairly well under-
stood. Given its small scale, such a notiﬁcation can be
conducted with some manual, site-speciﬁc effort. How-
ever, detecting large numbers of vulnerabilities span-
ning several parties has become the norm rather than

2.2 Vulnerability Information
To answer these research questions, we leverage a data
set with concrete instances of Web sites that contain
security-critical ﬂaws. We can use this data set to no-
tify affected parties and monitor their reactions. In the
following, we outline the Web-related vulnerabilities we
consider for our work, separated into well-known and
previously-unknown vulnerabilities.

We establish the data set on well-known vulnerabili-
ties by inspecting WordPress-based Web sites. We se-
lected WordPress since it is the most frequently used

1016  25th USENIX Security Symposium 

USENIX Association

PHP-based web application, deployed by about 25% of
the most popular Web sites [35]. To ﬁnd WordPress vul-
nerabilities, we systematically searched the CVE (Com-
mon Vulnerabilities and Exposures) database [27] for
vulnerabilities which could be veriﬁed with (i) non-
intrusive proof-of-concept (PoC) tests and (ii) without
requiring valid user credentials for the tested site. We
chose two vulnerabilities: one reﬂected XSS from 2013
(CVE-2013-0237) and one Client-Side XSS discovered
in 2015 (CVE-2015-3429).

In addition, we selected a recent vulnerability discov-
ered by security researchers at Sucuri. This third vul-
nerability, which targets the XML-RPC service of Word-
Press prior to version 4.4, allows an attacker to perform
brute-force ampliﬁcation attacks [6]. The ﬂaw is in the
behavior of the XML-RPC service which accepts mul-
tiple remote procedure calls (RPCs) with different user
credentials within a single HTTP request. As a result,
an attacker can forge a request in which she tries several
user passwords at once. In the remainder of this paper,
we refer to this vulnerability as Multicall. All these vul-
nerabilities were already known and patched in current
versions of WordPress when we started our experiments.
In the following, we refer to these domains as DWP.

Our data set on previously-unknown vulnerabilities
contains Web sites from the Alexa Top 10,000 suffer-
ing from one or more Client-Side Cross-Site Scripting
(Client-Side XSS) vulnerabilities. To detect these ﬂaws,
we used a methodology presented in our previous work
(see Lekies et al. [22]) which is based on a taint-aware
browsing engine and an exploit generator to gather veri-
ﬁed exploitable vulnerabilities. To the best of our knowl-
edge, these ﬂaws were not shared with the site operators
before our notiﬁcation. The second data set thus rep-
resents a situation researchers face when discovering a
previously unknown type or instance of Web ﬂaws. We
denote these domains as DCXSS.

3 Methodology

In this section we cover fundamental aspects of our
methodology on large-scale notiﬁcations. We ﬁrst dis-
cuss which communication channels can be used to reach
out to affected parties. Subsequently, we outline how we
prepared the notiﬁcation messages. Third, we present
the metrics that help to answer our research questions.
Finally, we discuss ethical aspects of our methodology.

following, we review potential communication channels
and discuss which of them are suitable in our context.

3.1.1 Direct Channels

We ﬁrst consider and assess direct communication chan-
nels that lead to the responsible contact.
Web contacts (discarded) — One option would be to
browse the Web site and search for contact email ad-
dresses, phone numbers, or contact forms. Naturally,
calling affected parties or interacting with custom Web
forms is not a viable option in a large-scale scenario. Al-
ternatively, we could crawl the domain to extract email
addresses. This process, however, is an unreliable and
error-prone undertaking, and is complicated by anti-
scraping mechanisms such as CAPTCHAs or obfuscated
email addresses. Hence, such contacts are not viable for
large-scale notiﬁcations and we do not consider them.
Generic email aliases — Standardized email aliases for
each domain should ideally redirect to appropriate mail-
boxes and are “to be used when contacting personnel
of an organization” (RFC 2142 [7]). The RFC also
proposes alias categories suitable for our goal. Besides
the security-related aliases, security@ and abuse@, we
chose to contact the support mailbox for the HTTP ser-
vice, i.e., webmaster@.
In addition, we include the
generic info@ alias.
Domain WHOIS information — The Domain WHOIS
protocol can be used to query information about regis-
tered domain names. Depending on the providing server,
however, the structure and content of the provided infor-
mation varies. WHOIS data is optimized for readabil-
ity to humans [8] and thus does not have a consistent
document format [25]. While a human can easily use
WHOIS to retrieve contact information for a single do-
main, it does not scale to large-scale disclosure. WHOIS
providers also rate-limit requests and partially employ
CAPTCHAs to protect contact addresses [17]. Hence,
querying WHOIS at large scale is not feasible. Instead,
to retrieve the WHOIS domain contact, we purchased a
machine-readable WHOIS data set for the Alexa top one
million Web sites as of September, 29th, 2015 1 and aug-
mented the data with additional, on-demand queries. To
select the contact person, ﬁrst priority was given to the
registrant’s email address.
In cases where this did not
exist, we selected the technical contact address instead.

3.1 Communication Channels
The ﬁrst key challenge when disclosing a Web vulnera-
bility is to reach out to an appropriate contact person,
e.g., to the administrator of a vulnerable Web site. In the

3.1.2

Indirect Channels

Apart from direct channels, we can ask intermediaries to
forward information about vulnerabilities on our behalf:

1We bought the data set from http://whoisxmlapi.com

USENIX Association  

25th USENIX Security Symposium  1017

VRPs (discarded) — In recent years, vulnerability re-
ward programs (VRPs) have gained traction and their
success has been studied by researchers [14]. VRPs in-
centivize researchers to responsibly disclose ﬂaws either
directly to the vendor or to a VRP organization. Com-
panies such as Google run their own in-house programs,
whereas others outsource the coordination to organiza-
tions like HackerOne or BugCrowd. Naturally, in-house
programs focus on vulnerabilities that are speciﬁc to the
company, and hence, cannot be used for large-scale dis-
closure. Moreover, VRP organizations usually only ac-
cept and forward reports for their customers. Given
a large body of vulnerable sites from several domains,
VRPs are not a viable option for large-scale notiﬁcations.
We thus exclude VRPs from our study.
Hosting providers — Hosting providers may already
have an infrastructure in place to receive and react to
security complaints. The provider likely has an incen-
tive to use its direct customer contacts to forward the
vulnerability information. While there is no speciﬁc
security-related contact for providers, each provider typ-
ically has an abuse mailbox, which is used to notify op-
erators about malicious activities originating from their
networks. Abuse contacts can be found in Regional In-
ternet Registries (RIRs) contact databases or queried via
the IP WHOIS protocol. Both systems rate-limit requests
and return proprietary formats. To work around this lim-
itation, we query the Abusix Contact IP WHOIS proxy
service [1] to obtain contacts of providers hosting the
vulnerable Web sites.
TTPs — Trusted Third-Party Coordinators (hereafter
TTPs) such as CERTs (Computer Emergency Response
Teams) can act as intermediaries to report software vul-
nerabilities to operators. TTPs either operate on a re-
gional level, i.e., within countries, or on a global scale,
e.g., FIRST (Forum of Incident Response and Security
Teams) [15]. Typically, TTPs already have technical in-
frastructure and procedures to forward vulnerability in-
formation to the administrators within their authority.
To select CERTs, we determined the countries in which
the vulnerable Web applications are hosted. We se-
lected the top-20 countries in our data set and looked up
their national CERTs. As global coordinators, we chose
FIRST [15], and Ops-T [29] (Operations Security Trust),
a closed community of security professionals.

3.2 Notiﬁcation Procedure

In this section, we outline our notiﬁcation procedure.
Our campaign consisted of sending emails to the four
notiﬁcation groups on a bi-weekly basis, i.e., an initial
notiﬁcation and subsequent reminders every two weeks.
In each round, we only notiﬁed Web sites which were

exploitable at least once in the previous 72 hours2.

We split our overall data set of vulnerable Web sites
into ﬁve disjoint groups of equal size, i.e., each domain
is part of exactly one group. We use four notiﬁcation
groups and assign 1/5th of the domains to each of them:
(i) generic email aliases, (ii) domain WHOIS contacts,
(iii) abuse contacts of network providers, and (iv) TTPs.
To reduce possible bias, we did not inform TTPs and net-
work providers that they received only an excerpt of all
affected sites in their constituency (since the rest were in
the other groups). In addition, to set a baseline, we as-
sign the ﬁfth group to the control group, to which we did
not send notiﬁcations.

3.2.1 Notiﬁcation Types

To notify contacts, we carefully aggregated information
to avoid a single contact receiving multiple notiﬁcation
emails, as discussed in the following.
Individual Disclosure — For the Generic and the
WHOIS contact groups, we sent individual emails that
contained a list of discovered ﬂaws for their domain, as
well as instructions to retrieve the technical report. We
left it to the recipient to either view the technical report
on our vulnerability disclosure Web interface, or to use
our mailbot to retrieve the reports. Each domain there-
fore had a unique token assigned to it which could be
used to retrieve the report. Additionally, the email in-
formed the recipient that they could opt out of the exper-
iments or get in touch with us via a dedicated mailbox.
An example of the email is shown in Appendix A.
Aggregated Disclosure — For the network provider and
TTP contact groups, the email contained a message sim-
ilar to the one used for the individual disclosure, kindly
asking the recipient to forward the information to the re-
sponsible domain admin. However, we aggregated vul-
nerability information per authority and prepared a sin-
gle message to disclose multiple vulnerabilities affect-
ing Web sites within the authority of TTPs and network
providers. Speciﬁcally, we attached a CSV ﬁle speci-
fying the domain, IP address, vulnerability types, Web
interface link, and unique token for each site. The email
also contained a note regarding opt-out and reaching us.

3.2.2 Mail Delivery and Anti-Spam Filters

To send out a large number of such notiﬁcation emails,
we opted to set up our own email server. Operating our
own email infrastructure prevents side-effects that may
have arisen when using existing email infrastructure of
the university, e.g., in case an IP-based blacklist starts
blocking our server due to the notiﬁcation emails.

2See Section 3.3.1 for details on these exploitability checks

1018  25th USENIX Security Symposium 

USENIX Association

One of the key challenges for benign email campaigns
is to avoid the emails being ﬂagged as spam, based ei-
ther on a bad sender reputation, or the message content.
To minimize this risk, we implemented both Sender Pol-
icy Framework (SPF) [31] and, starting from the ﬁrst
reminder, DomainKeys Identiﬁed Mail (DKIM) [28].
For each email template, we used SpamAssassin to en-
sure that the message content would not be ﬂagged as
spam. Finally, throughout the mail sending process,
we periodically monitored the reputation of our mail
server by repeatedly querying IP-based blacklists, such
as Spamhaus.org and SpamCop.
In addition, as email
providers may implement custom spam ﬁlters, we also
tested our messages against the ﬁlters of the two most
popular mail providers, i.e., Google Mail and Outlook,
registering new email accounts on both services. In ad-
dition, we signed up for Microsoft’s Junk Mail Reporting
Program (JMRP), which provides feedback on the spam
check for mail from a given host [26].

3.2.3 Report Interface

During the experiment design time, one of the main con-
cerns was the manual effort of our staff to address the
quantity of possible questions that Web site owners might
have. To help us with this type of activity, we built a
web-based system, composed of a back end component
for our staff and a front end for the Web site owner.

We wanted to provide users with as much detail as
possible on the vulnerability, its impact, and ways of
ﬁxing it. Therefore, we created report templates for
each vulnerability. For WordPress, we provided the de-
tails and hints on updating the installation. For Client-
Side XSS, we provided the proof-of-concept URL which
would open an alert box, as well as information on all the
ﬁles which were involved in the exploitable data ﬂow.
Depending on the type of ﬂaw, one of the customized
templates would be presented to users of the front end.

The back end allowed us to retrieve current Web site
statuses and statistics. Additionally, we automatically as-
signed emails to each domain. This allowed us to easily
ﬁnd all emails associated with a domain to give the best
possible information on questions from domain admins.

3.3 Measurements
We broke down our research questions into a number of
measurements that we perform throughout our notiﬁca-
tion campaign. These measurements are:
Global and Per-Group Vulnerable Web Sites — To
measure the number of Web sites that are still ex-
ploitable, we set up a monitoring system which periodi-
cally veriﬁes the exploitability of ﬂaws using PoC tests.

In addition, as groups are mutually disjoint, our moni-
tor naturally provides per-group results. The monitoring
system is presented in Section 3.3.1.
Reachability of Recipients, Viewed Reports, and
Time to Fix — We can directly measure the success of
mail delivery by looking at both email responses and re-
port interface access logs. The logs help to infer that a
message has reached the recipient. We present this reach-
ability analysis in Section 3.3.2.

3.3.1 Web Site Monitoring

Throughout our experiments, we periodically monitored
Web sites to establish the point in time when they were
no longer vulnerable. In the following, we discuss the
different types and frequency of tests, as well as the ap-
proach used to determine that a site was ﬁxed.
WordPress Vulnerabilities Tests — To test for the three
WordPress vulnerabilities, we implemented the follow-
ing vulnerability-speciﬁc probes.
XSS Vulnerabilities — The CVE-2013-0237 vulnera-
bility affects a speciﬁc version of a Flash ﬁle which
is part of the PlUpload component included in default
WordPress installations. Our test retrieves the Flash ﬁle
and compares its checksum against the checksum of the
known vulnerable version. If the checksums match, the
test returns Exploitable.
In all other cases, it returns
Non-Exploitable. Similarly, the presence of the CVE-
2015-3429 vulnerability can be veriﬁed by comparing
the checksum of a speciﬁc HTML page. If the checksum
values match, the Web site is considered Exploitable;
otherwise it is Non-Exploitable. Both these ﬁles have the
same content regardless of Web site language, i.e., we
did not have to implement a checker per site language.
Multicall — The detection of the Multicall vulnerabil-
ity requires further care. In a vulnerable installation, the
XML-RPC API checks all user-provided credentials per
request.
In the patched variant, it skips all credential
checks if one has failed, but still returns a list of invalid
credential error messages. As a result, the output of the
service cannot be used to deduce exploitability. How-
ever, as vulnerable services process all calls—including
the ones with invalid credentials—the processing time is
longer than for the patched version. Based on this obser-
vation, we developed a test which uses this timing side
channel to deduce if a site is vulnerable or not. For the
technical details, we refer the interested reader to Ap-
pendix B. As side channels are susceptible to false posi-
tives, we correlate the results with the deployed version
of WordPress, which we extract by using the testing tool
plecost [18]. If both timing analysis and version reﬂect
a vulnerable service, the site is Exploitable. In all other
cases the Web site is Non-Exploitable.

USENIX Association  

25th USENIX Security Symposium  1019

Web Site Time-Series Analysis — Since the exploitabil-
ity relies on core components of WordPress, it can be
reliably triggered. To keep server loads to the neces-
sary minimum, we only checked for these vulnerabili-
ties once per day. Given the variety and number of Web
sites that we monitor, however, our point-wise observa-
tions are susceptible to temporal errors, such as Web ap-
plications that are temporarily inaccessible or are other-
wise unresponsive at the time of our check. To decide
whether a Web site is no longer exploitable, or just tem-
porarily unavailable, we calculate the conﬁdence of our
tests. The conﬁdence is the complement of the number of
unlikely events (i.e., number of observed transitions from
Non-Exploitable to Exploitable). A site is only marked
as ﬁxed if the conﬁdence is greater than 0.99. For a pre-
cise deﬁnition of our conﬁdence function, we refer the
interested reader to Appendix C.
Client-Side XSS Test — To test for this vulnerability,
we used the set of per-domain exploits discovered with
our methodology from previous work. Each exploit is
a URL including the XSS payload. For more details on
this aspect, we refer the reader to our paper [22]. The
exploits are grouped according to the vulnerability they
trigger. To keep the load on the target server low, we ini-
tially only check one exploit URL. If the exploit works,
we consider the site still vulnerable. If the exploit fails,
we do not consider the Web site as ﬁxed yet. In fact, as
our previous work has shown, a vulnerable page may no
longer exist or the ﬂaw may be caused by rotating adver-
tisements [32]. To rule out such volatility, we re-check
the exploit every three hours. Additionally, if the page no
longer exists, we check other exploits from the same ex-
ploit group and update the PoC if any of them succeeds.
A ﬂaw is only marked as ﬁxed if it was not exploitable
for at least three consecutive days.

3.3.2 Mailbox and Report Access Log Analysis

One of our core research questions is to study the effec-
tiveness of each notiﬁcation group. To measure if we
actually reached someone, we analyzed our mailbox and
the logs of the front end. Our front end allows notiﬁed
parties to retrieve a detailed technical report by clicking
on a link, or, if the owner distrusts URLs in emails, via
our mailbot. In both cases, the recipient has to submit
a unique token. We kept track of all actions by logging
the tokens and access times. This allowed us to perform
ﬁne-grained analyses regarding the access to our vulner-
ability reports. In addition, the mailbox we used to dis-
seminate emails received a variety of automated replies
that provided insights on the status of the email delivery.
We use all this information to classify each contact point
into one of the following categories.

Reached — For individual disclosure, we state that we
reached a contact point when the response message is,
for example, an auto-responder message acknowledging
the receipt of our email, a response by a tracking sys-
tem (e.g., a new ticket), and other messages in which the
recipient unequivocally states that the message was re-
ceived. We say that we reached a contact point also when
we observe an access to corresponding domain’s techni-
cal report. In case of aggregated disclosure, if the email
recipient, i.e., TTP or provider, is reached, then each of
the domains within their constituency is also marked as
reached. Similarly for individual disclosure, if a tech-
nical report for any domain within a constituency is ac-
cessed, we mark all associated domains as reached.
Bounced — Bounce messages are messages sent by a
mail transfer agent to notify the sender that an error oc-
curred and the message could not be delivered. Such er-
rors might stem from the mailbox not existing or being
full. If all emails we sent for a particular domain bounce,
we classify the domain as bounced.
Unreachable — A contact point is unreachable when the
response message indicates that no human will process
our request. Examples of these cases are messages stat-
ing that the mailbox is unattended, or emails asking to
contact Web site personnel only via a web form. Another
example of an unreachable contact point is domains for
which we could not retrieve any email address, e.g., if
such information is missing in the WHOIS data.
Unknown — When we cannot establish whether a mes-
sage was received, bounced, or the contact point was un-
reachable, we mark the contact point as Unknown.

While the identiﬁcation of bounce messages is quite
straightforward based on their content (e.g., SMTP error
codes), automatically assigning emails to the aforemen-
tioned categories is prone to errors. Hence, we manually
assigned incoming emails to one of the categories.

3.4 Ethical Considerations
We addressed ethical concerns from the early stages of
our methodology design.
In general, we design our
experiments to be unobtrusive. This is, e.g., reﬂected
on both the WordPress vulnerabilities selection criteria
and the monitoring frequency. Despite that, our regular
checks may still be undesired by network providers and
Web site owners. For this reason, in our emails, we in-
cluded instructions to opt out of our study. Moreover, we
conﬁgured descriptive reverse DNS names for our infras-
tructure and hosted a website that described our initia-
tive, again detailing contact information (postal address,
email address, phone numbers) and an opt-out procedure.
The second ethical consideration of our experiments
was fairness towards Web site administrators. As a result

1020  25th USENIX Security Symposium 

USENIX Association

of our methodology, there are administrators that were
not made aware of vulnerabilities affecting their sites,
i.e., were contained in the control group. After the end
of our notiﬁcation campaign, we informed them using
the discussed direct channels and shared the list of vul-
nerable domains with the TTPs.

Our experiments are in part related to human opera-
tors on the receiving end of our notiﬁcation emails. Our
organizations, however, neither mandate nor provide an
IRB approval before conducting such experiments.

4 Data Set

In this section, we explain the details of our experiments
such as the time period, data sets of vulnerable applica-
tions, and composition of our notiﬁcation groups.
Vulnerable Domains — In total, our data set included
44,790 Web sites of which 43,865 are WordPress-based
Web sites suffering from at least one vulnerability dis-
cussed in Section 2.2 (DWP). The remaining 925 Web
sites were susceptible to site-speciﬁc Client-Side XSS
exploits (DCXSS).
Notiﬁcation Groups — We randomly split the data sets
of vulnerable Web sites into ﬁve equally-sized groups of
185 DCXSS and 8,773 DWP domains. During the lookup
process, we could not retrieve contact points for several
domains. For the domain group, the WHOIS database
did not contain email addresses for 34 (18.4%) and 1,665
Web sites (19.0%) for DCXSS and DWP, respectively. For
the network provider group, queries to the Abusix servers
did not return a contact for 18 (9.7%) and 254 domains
(2.9%) of DCXSS and DWP, respectively.
In all these
cases, we marked these Web sites as unreachable within
their contact group.

For the TTP group, we followed a different approach.
To select regional coordinators, we extracted the coun-
try code of the ASN hosting each domain, using the
IP-to-ASN database of Team Cymru [33]. Finally, we
selected coordinators for the 20 most frequent country
codes from the list maintained by CERT-CC [4]. These
regional CERTs account for 90.8% of the domains in the
TTP contact group, the remaining 9.2% were hosted in
a country outside of the top 20. To close this gap, we
augmented the set of coordinators with the two global
coordinators FIRST and Ops-T.
Notiﬁcation Campaign — We notiﬁed the affected par-
ties on Jan 14th, 2016. We sent two reminders, one af-
ter two weeks (Jan 28th), and one after four weeks (Feb
11th). For FIRST, we accidentally delayed the initial
mail delivery by two days due to a misunderstanding, but
made sure they received the vulnerability information as
soon as the issue was resolved. In total, our server deliv-
ered 17,819 emails as the initial notiﬁcation, 15,110 as

primary reminders, and 13,588 as secondary reminders.
In each round, the number of emails sent decreased be-
cause administrators ﬁxed the vulnerability, they explic-
itly asked to be excluded from the experiments, or email
addresses were invalidated due to bounces.
Unsubscribed Domains — As discussed in Section 3.4,
we enabled domains to opt out of our analysis. Through-
out the duration of our experiments, we received ﬁve
requests to exclude a total of 187 domains, of which
149 were in a notiﬁcation group and 38 in the control
group. We received an email from a hosting provider
on the second day of our campaign, threatening to sue
our university if we did not immediately stop the analy-
sis on this network. Additionally, we received messages
from domain owners that were contacted by their host-
ing providers, stating that their Web sites would be taken
down if the vulnerabilities were not ﬁxed within a short
timeframe. In these cases, we not only excluded the do-
mains from any further analysis, but also reached out to
the providers to clarify the obvious misunderstanding.

5 Site Vulnerability Evolution

Using the methodology described before, we now instan-
tiate our large-scale notiﬁcation experiment and assess
whether we can affect the prevalence of vulnerabilities
in the wild. We answer this question by looking at the
observed trends of ﬁxed vulnerabilities and the signiﬁ-
cance of our campaign. Finally, we have a closer look at
each data set and discuss the impact in isolation.

5.1 Trend of Fixed Vulnerabilities
Table 1 shows the total number of non-exploitable do-
mains at the end of our measurements (February 16th).
The fraction of non-exploitable Web sites ranges from
about 25.1% (Generic) to 26.5% (WHOIS) for DWP. For
DCXSS, the fraction of domains has a greater variety and
ranges from 8.6% (Provider) to 16.8% (TTP). We ob-
serve a distinctive difference in the ﬁx rates for the con-
trol group for DWP (23.3%) and DCXSS (2.4%). We dis-
cuss the reasons for this in Sections 5.2.1 and 5.2.2.

DWP

DCXSS

Generic
WHOIS
Provider
TTP
Control

2,201
2,325
2,261
2,268
2,043

25.1% 25
26.5% 21
25.8% 16
25.9% 31
4
23.3%

13.5%
11.4%
8.6%
16.8%
2.2%

Table 1: Non-exploitable domains per group by 02/16

USENIX Association  

25th USENIX Security Symposium  1021

Generic
Domain Cont.
Provider
TTP
Control

DWP

DCXSS

Generic
WHOIS
Provider
TTP
Overall Campaign

0.0053449
0.0000009
0.0001308
0.0000796

0.0000012

7.76
24.24
14.63
15.57

23.51

0.0000486
0.0004299
0.0058000
0.0000016

0.0000360

16.50
12.40
7.61
23.00

17.07

Table 2: p-values and raw values from χ2 tests

s
n
i
a
m
o
d
d
e
x
ﬁ
f
o
n
o
i
t
c
a
r
f

s
n
i
a
m
o
d
d
e
x
ﬁ
f
o
n
o
i
t
c
a
r
f

25%

20%

15%

10%

5%

0%

25%

20%

15%

10%

5%

0%

01/14

01/21

01/28

02/04

02/11

(a) WordPress

Generic
WHOIS
Provider
TTP
Control

01/14

01/21

01/28

02/04

02/11

(b) Client-Side XSS

Figure 1: Fixed vulnerabilities over time

Figures 1a and 1b show the timeline and reveal when
the vulnerabilities were ﬁxed. For DWP, we observe
that all groups (including the control group) have a
steady increase in non-exploitable domains. Each group
progresses to the maximum, following a slight “wave”
shape. This shape correlates to a weekly pattern. The
weeks following a notiﬁcation round (denoted as the hor-
izontal lines) are characterized by a slightly steeper in-
crease than the weeks before a notiﬁcation round. For
each of the groups, more than 2,000 of the 8,773 do-
mains were no longer vulnerable at the end of our study.
Overall, all notiﬁcation groups performed better than the
control group.

In contrast to the steady increase we observed for
DWP, no such pattern can be found for DCXSS. Gener-
ally speaking, the difference between control and notiﬁed
groups is much larger for DCXSS. We discuss the results
in Section 5.2.
Result Signiﬁcance — During our experiments, we wit-
nessed an increase in the ﬁx rate for notiﬁed domains
in comparison to the control group for both DWP and

DCXSS. In order to ascertain whether this is due to chance
or an effect of our campaign, we analyze the gathered
data in more detail. To that end, we state the hypothe-
sis H0 that the difference in the results originates purely
from chance and is not an effect of our notiﬁcation. For
both DCXSS and DWP, we use Pearson’s χ2 [30] test to
calculate the p-values for each notiﬁcation group in com-
parison to the control group. This test allows us to deter-
mine whether the differences between the results arose
by chance. Both the resulting p-values and the raw χ2
values for both DWP and DCXSS are shown in Table 2.

In our case, however, we need to account for the com-
parison of the control group to several other groups.
Hence, an error in the control group would bias all com-

parisons. Applying the Holm-Bonferroni method (α=
5−i+1 ,

0.05) [16], we observe that every value pi is below α
i.e., H0 does not hold. Hence, we ﬁnd that the notiﬁed
groups all differ signiﬁcantly from the control group.

For the sake of completeness, in addition to the com-
parison to the control group, Tables 7 and 8 in the ap-
pendix show the p-values when comparing the notiﬁed
groups against each other. While direct comparison be-
tween two groups sometimes reveals signiﬁcant differ-
ences (e.g., DWP WHOIS and Generic), no group per-
formed signiﬁcantly better than all other groups.

Impact Analysis

5.2
In this section, we analyze the collected data in more
depth. More precisely, we discuss the changes for DWP
over time, showing how long-lasting the effect of our no-
tiﬁcation was. Moreover, we explain why the number of
ﬁxed domains in the control group is high, at almost one
ﬁfth. Subsequently, we discuss the impact of our notiﬁ-
cation on DCXSS.

5.2.1 WordPress

Our notiﬁcation campaign increased the number of do-
mains that ﬁxed the WordPress vulnerabilities by 11.2%.
All notiﬁcation groups outperformed the control group.
The WHOIS group was the communication channel with
the highest ﬁx ratio (+15.4%). Next, the TTPs (+12.1%)

1022  25th USENIX Security Symposium 

USENIX Association

and providers (+10.9%) were second and third, respec-
tively. The least effective channel was Generic, which
still showed a 5.9% increase over the control group.

Besides the overall impact, we analyzed our collected
data on a per-week basis, starting on the ﬁrst day of our
campaign. The results of this analysis are shown in Ta-
ble 3. Next to the absolute number, the table also shows
the fraction of domains ﬁxed in each week. Note that this
is relative to the number of domains that was still vulner-
able at the beginning of that week for that group. In the
ﬁrst week, all channels performed better than the control
group. In the second week, only providers still showed
an observable increase in ﬁxed domains. After the re-
minders, only the Generic and WHOIS contact groups
had slightly increased ﬁx numbers. All in all, however,
the most drastic change occurred in the ﬁrst week. Based
on our deﬁnition of ﬁxed domains (see Section 3.3.1),
conclusive results can only be given at least three days
back. As we stopped our experiments on January, 17th,
we can only provide information on the ﬁrst four weeks.
We observe that a substantial fraction of about one
ﬁfth of the control group was ﬁxed during the duration
of our study. This observation can be explained by ana-
lyzing the evolution of WordPress installations. We re-
quire version information to make a decision about the
Multicall ﬂaw, i.e., we had this information readily avail-
able for all days of the experiment. Indeed, out of the
8,773 domains in the control group, 1,134 moved from
a version prior to 4.4 to an updated variant (not suscep-
tible to Multicall) in the timeframe of our experiments.
In addition, we observed that 360 domains no longer
used WordPress or were ofﬂine at the end of our study.
Throughout the remainder of the paper, we refer to these
ﬁxes as the natural decay of vulnerable domains.

It is also clear from Table 3 that in the ﬁrst week of our
campaign, a comparatively higher number of domains
in the control group was marked ﬁrst. While we can-
not conclusively say why this occurred, we have anec-
dotal evidence from emails we received from one ad-
ministrator who was responsible for multiple domains.
Even though we had only notiﬁed him about one do-

14/1-20/1

21/1-27/1

28/1-03/2

04/2-10/2

Control Generic WHOIS
610
(7.2%)
397
(5.1%)
418
(5.6%)
402
(5.7%)

521
(6.1%)
387
(4.8%)
416
(5.5%)
389
(5.4%)

438
(5.1%)
387
(4.8%)
382
(5.0%)
386
(5.3%)

Prov.
631
(7.4%)
416
(5.3%)
380
(5.1%)
368
(5.2%)

TTP
664
(7.8%)
395
(5.0%)
380
(5.1%)
365
(5.2%)

Table 3: WordPress ﬂaws ﬁxed per week

main, he ﬁxed several domains at once. Similarly, the
WHOIS data set we purchased shows that different do-
mains (spread across notiﬁed and control groups) con-
tained the same contact email, i.e., had the same owner.

5.2.2 Client-Side XSS

Contrary to what we observed for DWP, there is no ev-
idence for a natural decay of Client-Side XSS vulner-
abilities. This stems from the fact that updates for the
WordPress ﬂaws are readily available and that sites are
constantly being upgraded. For DCXSS, however, to the
best of our knowledge, developers were not aware of the
ﬂaws and no automated update existed to patch the ﬂaws.
Therefore, the impact of our campaign is much higher in
comparison to DWP.

In total, our campaign on average increased the num-
ber of ﬁxed domains by a factor of almost 6, compared to
the negligible number of three ﬁxed domains in the con-
trol group. The highest ﬁx rate was achieved by Trusted
Third-Parties (16.8%), followed by the Generic channel
with 13.5%. Additionally, 11.4% of the WHOIS and
8.7% of the provider group domains were ﬁxed.

Important to note in this instance is one speciﬁc fea-
ture of Client-Side XSS: such issues are often caused by
third-party scripts [32], which are out of the control of
the administrator of the vulnerable domain. If a vulner-
able third-party component is used across multiple do-
mains, it is sufﬁcient if one affected party reports this to
the third-party vendor. In one particular case, we found
that nine domains suffered from the same ﬂaw. The vul-
nerability was ﬁxed on February 8th, and its effect is vis-
ible in Figure 1b in the increase of ﬁxed domains for
Generic (three domains), WHOIS (four domains), and
TTP (two domains) on that day. Since by chance, none
of the domains was in the control group, this anomaly
had a heavy impact on the overall notiﬁcation campaign.

6 Communication Channel Analysis

In the previous section, we outlined the global picture on
the vulnerability landscape and how much our campaign
impacted it. Although the notiﬁcations for both DWP and
DCXSS showed signiﬁcant improvements over the control
group, the number of domains which were ﬁxed is unsat-
isfactory (25.8% and 12.6%, respectively). This raises
the question whether we succeeded in reaching out to
administrators. Therefore, in this section, we analyze
how both direct and indirect communication channels
performed in terms of successfully reporting the ﬂaws
to the responsible administrators.

USENIX Association  

25th USENIX Security Symposium  1023

6.1 Direct Channels
In this section, we analyze the direct channels, ﬁrst deter-
mining whether we reached the intended recipient. We
then assess how many reports were accessed and how
quickly ﬂaws were ﬁxed after report view.

6.1.1 Reachability Analysis

For the direct channels, i.e., Generic email addresses and
WHOIS contacts, we sent a single email per domain. As
outlined in Section 3.3.2, we then classiﬁed each domain
as to its reachability state. The results of the classiﬁca-
tion are shown in Table 4. Based on the numbers we ob-
serve, several characteristics for the direct channels be-
come apparent. First and foremost, more than half of
all domains are marked as unknown, either because the
emails were silently bounced, delivered to an unmoni-
tored mailbox, or ignored by the recipient. Apart from
this, we observe that the groups have distinct differences,
which we discuss separately in the following.

For the Generic group, we received a large number
of email bounces. More precisely, for 50% and 28% of
DWP and DCXSS domains, respectively, all emails we sent
bounced. The difference in number of bounces between
DCXSS and DWP likely originates from the higher pop-
ularity of DCXSS Web sites (Alexa Top 10,000) in com-
parison to DWP (Alexa Top 1 million). As popular Web
sites may have a more structured staff, they may tend
to adhere to standards like RFC-2142 [7], thus reducing
the number of bounces. Nevertheless, even for the high-
ranked DCXSS Web sites, only 41 (22.2%) were actually
reached. Moreover, for 90 DCXSS domains (48.6%) we
neither received emails acknowledging our reports, nor
saw any hits on our Web site. Similarly, we observe that
more than 45% of the DWP domains are unknown.

The situation for the WHOIS group is slightly differ-
ent: the fraction of bounces is signiﬁcantly lower than for
the Generic channels. This appears natural based on the
fact that a valid email address is typically necessary to
register a domain. However, apart from the large body of
unknown domains, we see that the second-biggest frac-
tion of domains belong to the unreachable bucket. This

is caused by the fact that for 1,699 domains (both DWP
and DCXSS), we could not retrieve a contact address from
the WHOIS information. Additionally, for 37 domains,
our messages were not delivered to the domain owner
because the emails from the WHOIS database are of or-
ganizations that hide email addresses. The remaining 31
domains in that bucket were marked as unreachable since
we received emails redirecting us to a Web-based form.
Given the large volume of emails we sent out for di-
rect notiﬁcations (four on Generic, one on WHOIS), anti-
spam ﬁlters also interfered with reaching out to Web site
administrators. Despite our careful preparation of infras-
tructure and email content, our messages were partially
labeled as spam. Even though our mailserver was never
listed in any well-known blacklist, Microsoft’s JMRP re-
ported that the emails of the ﬁrst two rounds were in parts
ﬂagged as spam. Interestingly, none of the emails of the
second round of reminders were labeled as spam.

Additionally, provider-speciﬁc anti-spam ﬁlters misla-
beled our emails. For 562 domains, we received bounces
stating that our mails were classiﬁed as spam and thus
rejected. In addition, in a handful of cases, we received
feedback from contact points stating that they had only
received our reminders and not the initial notiﬁcation.
This was either caused by silent bounces (the mail server
accepted the email, but dropped it without notifying the
sender), or by our email ending up in the spam folder,
and then being automatically deleted after a few days.

6.1.2 Report Access
As we have seen in the previous section, the number of
reached domains for the direct channels is low, amount-
ing to only 357 and 714 DWP domains for Generic and
WHOIS, respectively. The increase in ﬁxed DWP do-
mains compared to the control group, however, is even
smaller: 158 and 282, respectively (see Table 1). We ob-
serve a similar trend for DCXSS. To investigate this dis-
crepancy, in the following we analyze for how many of
the reached domains a report was accessed on our Web
interface or via the mailbot.

Table 5 shows the number of domains which accessed
In addition, Figures 2a and 2b

a report at least once.

Generic

WHOIS

DCXSS
38
14
36
97

Total
1,150
5,232
1,779
9,755

DWP
357
4,395
10
4,011

DCXSS
41
52
2
90

DWP
714
771
1,731
5,557

8,773

185

8,773

185

17,916

Reached
Bounced
Unreach.
Unknown
Total

Generic
WHOIS
sum direct
Provider
TTP
sum indirect

DWP

DCXSS

273
550
823

477
601
1,078

3.1% 37
6.3% 30
4.6% 67

5.4% 26
6.9% 70
6.1% 96

20%
16.2%
18.1%

14.1%
37.8%
25.9%

Table 4: Success of direct channels

Table 5: Viewed reports for all channels up to 02/16

1024  25th USENIX Security Symposium 

USENIX Association

s
n
i
a
m
o
d
d
e
w
e
i
v

700
600
500
400
300
200
100
0

s
n
i
a
m
o
d
d
e
w
e
i
v

70
60
50
40
30
20
10
0

Generic
WHOIS
Provider
TTP

01/17 01/21 01/25 01/29 02/02 02/06 02/10 02/14

(a) WordPress

01/17 01/21 01/25 01/29 02/02 02/06 02/10 02/14

w
e
i
v

r
e
t
f
a
s
n
i
a
m
o
d
d
e
x
ﬁ
%

w
e
i
v

r
e
t
f
a
s
n
i
a
m
o
d
d
e
x
ﬁ
%

50%

40%

30%

20%

10%

0%

0 days

50%

40%

30%

20%

10%

0%

0 days

Generic
WHOIS
Provider
TTP

5 days 10 days 15 days 20 days 25 days 30 days

(a) WordPress

5 days 10 days 15 days 20 days 25 days 30 days

(b) Client-Side XSS

(b) Client-Side XSS

Figure 2: Accessed reports for different channels

Figure 3: Time from ﬁrst report view to ﬂaws ﬁxed

plot the temporal evolution of the viewed reports for DWP
and DCXSS, respectively. We observe that within a few
days of the initial notiﬁcation, the number of accessed
domain reports stabilizes for both DWP and DCXSS. Both
reminders increased the number of viewed domains, but
interestingly the effect for DWP was larger for the second
reminder, whereas for DCXSS this held true for the ﬁrst.
In total, only 823 of the DWP domains had reports
viewed for the direct channels. For DCXSS, the ratio of
viewed reports was much higher, but still adds up to only
67 (18.1%) of the notiﬁed domains, whereas Generic was
slightly better than WHOIS with 37 viewed reports.

6.1.3 From Report Access to Fix
Even though not all reached domains had a report view,
the number of domains for which a report was viewed
is still larger than the increase in ﬁxed domains. This is
due to the fact that instead of only viewing a report, the
ﬁnal step towards ensuring that the domain is no longer
vulnerable is to understand the speciﬁc issue and patch
it accordingly. In this section, we therefore analyze how
many domains from the direct channels were ﬁxed after
a report was viewed and how long it took.

Figures 3a and 3b show the time between a report
being viewed and the ﬁx of the underlying ﬂaw. For
DWP we observe on the Generic channel about 30% of
the viewed domains are ﬁxed within 5 days. Similarly,
for WHOIS we observe a slightly higher rate of 32.5%
within that timeframe. After this, the increase in ﬁxed

domains aligns with what we what observed for domains
in the control group (roughly 0.5-0.7% per day).
In
essence, domains are either ﬁxed within a very short time
after initial report view or become non-exploitable just
based on the natural decay of vulnerable domains.

For the DCXSS domains, this pattern differs, showing
signiﬁcant increases in the ﬁx rates even after more than a
week. These ﬂaws, in contrast to WordPress, are mostly
site-speciﬁc and, more importantly, a ﬁx has to be devel-
oped ﬁrst. Hence, a longer timeframe for the ﬁx is some-
what expected. Of all channels, the Generic channel had
the highest rate of ﬁxed domains after having viewed a
report with about 38%. Noteworthy in this instance is the
poor conversion rate for the WHOIS group. One possi-
ble explanation for this is the fact that the domain owner
for high-ranked sites might be disconnected from the en-
gineering team. Hence, the information might have been
viewed by this person, but not properly forwarded to the
actual administrator of the site. In contrast, for DWP, we
argue that such installations are mostly used by either
small companies or single persons, and hence no such
disconnect exists.

6.2

Indirect Communication Channels

After the discussion of direct channels, we now follow
up with an in-depth analysis on the indirect channels.

USENIX Association  

25th USENIX Security Symposium  1025

Provider

DWP
3,992
2
271
4,508

DCXSS
75
0
20
90

8,773

185

TTP

DCXSS
138
0
0
47

185

DWP
7,567
0
0
1,206

8,773

total
11,772
2
291
5,851

17,916

Reached
Bounced
Unreach.
Unknown
Total

Table 6: Success of indirect channels

6.2.1 Reachability Analysis

Similarly to direct channels, we also classiﬁed all do-
mains based on their reachability. In this case, however,
reaching the end point does not entail that we reached the
administrator of the site. Instead, since we rely on inter-
mediaries, we can only measure whether they received
the email and not whether they forwarded it to the re-
sponsible party. This is also reﬂected in Table 6 in the
large number of reached domains. As discussed in Sec-
tion 3.3.2, a domain is marked as reached once the inter-
mediary was reached, i.e., either conﬁrmed our email or
viewed at least one report disclosed to them.

In total, we reached 592 network providers responsible
for 3,992 and 75 domains, respectively. Unreachable do-
mains for the indirect channels were providers for which
no contact existed in the Abusix database.
In contrast
to the high number of reached providers, about 50% for
both DWP and DCXSS remain unknown.

For TTPs, such as CERTs or Ops-T, the numbers seem
even more promising. Here, the unknown domains cor-
respond to such domains for which we received no feed-
back from the hosting country’s CERT, or those which
were not located in any of the top 20 countries. Since a
relatively small number of TTPs is responsible for a large
body of vulnerable domains, the fraction of reached do-
mains is comparatively high.

6.2.2 Report Access

The large number of reached domains appears to be
a positive sign for a successful vulnerability notiﬁca-
tion. However, looking at the number of accessed reports
shown in Table 5, we ﬁnd that the improvement over the
direct channels is less signiﬁcant.

In general, the report access pattern for the provider
group (depicted in Figures 2a and 2b) is similar to what
we observed for direct channels: an initial increment of
access to our reports after each notiﬁcation round fol-
lowed by long intervals of a quasi-constant number of ac-
cesses. For the provider group, the percentage of viewed
reports remains low at 5.4% and 14.1% for DWP and
DCXSS, respectively. For the most part, this is caused by
unhelpful providers: the top 5 providers accounted for

2,082 domains, but none of them reviewed any report,
thus effectively stopping the notiﬁcation process dead in
its tracks for more than half of the reached domains.

Compared to the providers, TTPs show a signiﬁcantly
different access pattern. First of all, after the ﬁrst no-
tiﬁcation round, we observe an increase of access after
four days. This can in part be attributed to FIRST receiv-
ing our initial email two days late. Additionally, from
feedback received from the third-largest active regional
CERT, we learned that they follow their own dates to
distribute notiﬁcations. While we sent notiﬁcations ev-
ery other Thursday, this CERT sent their notiﬁcations
on Mondays. In addition, we argue that the CERTs did
not simply forward our messages, but rather vetted them
ﬁrst. Therefore, it is highly likely that the information
was vetted on Friday, and only forwarded to responsible
parties on Monday. This can be observed in Figures 2a
and 2b as the steep increase starting from the fourth day
of our campaign (i.e., Monday, January 18th).

For TTPs, we have a large number of reached do-
mains, but cannot observe an analogous increase in num-
ber of viewed reports. The fractions of viewed reports
are 37.8% for DCXSS and 6.9% for DWP. In contrast to
the direct channels, our measurements could not reveal
direct causes for these low numbers such as bounces or
unreachable contacts. An explanation may be that TTPs
did not forward our notiﬁcation emails to Web site ad-
ministrators. Among the 20 regional CERTs, 18 reacted
to our email. Since we did not receive bounces for the
two non-reactive CERTs, we marked the domains in their
constituency as unknown. 10 CERTs that reacted to our
email did not view a single report. This could happen for
two reasons. First, rather than vetting the information,
these TTPs could have directly forwarded the informa-
tion, but the Web site administrators did not receive them,
or did not act upon them. Second, the CERT might not
have forwarded the information at all. Given the assump-
tion that a TTP would ﬁrst vet the information originating
from an untrusted source, the lack of accesses to the re-
port favors the second explanation, i.e., our notiﬁcation
messages were not forwarded by half of the CERTs.

In total,

the combination of indirect channels per-
formed better in terms of accessed reports than the com-
bination of direct channels. However, providers per-
formed worst of all channels for DCXSS and ranked third
for DWP. In contrast, TTPs were most successful for re-
port access on both types of vulnerable domains. This
result, however, is greatly inﬂuenced by Ops-T: this TTP
alone was exclusively responsible for 135 report accesses
for DWP and 36 for DCXSS. Let us consider a scenario
in which we could have relied only on regional CERTs
and FIRST. In this case, the number of viewed reports
for TTPs would have gone down to 466 and 34 for DWP
and DCXSS, respectively. These numbers are similar to

1026  25th USENIX Security Symposium 

USENIX Association

or even lower than the other groups. Hence, although the
TTPs were of great help in our campaign, a researcher
without access to the vetted Ops-T community could not
have achieved a comparable report access rate.

6.2.3 From Report Access to Fix

For the indirect channels, we also measured the time be-
tween ﬁrst access of a report and ﬁx for the disclosed vul-
nerability. The results are depicted in Figures 3a and 3b.
For DWP, although TTPs perform similar to the direct
channels, they have a distinct lag. More precisely, only
15.4% of domains were ﬁxed within one day of report
access, whereas this number ranged between 20.8% and
22.4% for direct channels. This underlines our hypoth-
esis that TTPs would ﬁrst vet the information we pre-
sented them. Hence, the ﬁrst access to a domain report
would have originated from the TTP, which subsequently
forwarded the information to the responsible party.

As discussed before, there is less of a natural decay
for DCXSS vulnerabilities, hence any ﬁx is more likely
to be caused by our notiﬁcations. However, due to the
speciﬁcs of Client-Side XSS, where a single third-party
script may be the cause for multiple ﬂaws, it is hard to
detect a distinct trend for the vulnerabilities. Similar to
the DWP ﬂaws, we observe a lag for both providers and
TTPs between the initial view of the report and the time
to ﬁx, especially compared to the Generic group. This
again highlights the vetting process of the intermediaries.

6.3 Discussion
As this section highlighted, the most signiﬁcant issue we
were faced with during our notiﬁcation campaign was
reaching the administrators in the ﬁrst place. The issues
depend on both communication channels and character-
istics for the vulnerable domains. Naturally, reaching the
intermediaries was quite straightforward: the email ad-
dresses were well-known and we only needed to send
a comparatively small number of emails to them.
In
contrast, on the direct communication channels, espe-
cially for domains from DWP, we had a large number of
bounces or unreachable contacts to begin with.

While the results for reachability suggest that using in-
termediaries greatly improves the chances of successful
notiﬁcations, the beneﬁt was not carried on to the num-
ber of viewed reports. Although TTPs performed best
for both DWP and DCXSS report views, this was mostly
caused by the closed Ops-T community. Additionally,
our reminders improved on the number of accessed re-
ports, especially for the direct channels.

Once a report was viewed, ﬁx rates for DWP were sim-
ilar across all groups, while the providers had a slightly
higher ﬁx rate. Moreover, we found that with a chance

of approximately 30%, domains were ﬁxed within 5 days
of a report view. After this period, the fraction of ﬁxed
domains only increased by what we observed to be the
natural decay of ﬂaws. For DCXSS, differences between
communication channels were more drastic, with a much
lower performance by the WHOIS channel. Although
the number of ﬁxes is subject to side-effects from vul-
nerabilities caused by third-party scripts, we note that
the Generic channel worked best when considering the
ﬁx rate within the ﬁrst 5 days.

7 Key Insights and Follow-Up Questions

In our work, we not only wanted to measure how suc-
cessful a large-scale vulnerability notiﬁcation campaign
could be, but also aimed at determining what issues re-
searchers would face. In the following, we discuss the
key insights gained in our efforts, and present a number
of follow-up questions which arise out of our ﬁndings.
Establishing Communication Channels — First and
foremost, establishing a direct communication channel is
remarkably challenging. For direct channels, we observe
three main problems: (i) standardized addresses perform
poorly with less popular Web sites; (ii) WHOIS contacts
are a valid alternative for less popular Web sites, but the
WHOIS database is not complete (about 20% domains
lack contact points); and (iii) sending a large number of
emails can be considered a spam campaign. All these
reasons contribute to the low fraction of viewed reports.
Relying on indirect channels may reduce the workload
for disclosure, as it de facto outsources the effort to an
external organization. We found that for a large fraction
of the domains such an intermediary could be reached.
Although judging from the number of viewed reports,
TTPs have the highest success rate, the overall results
are still unsatisfactory. Moreover, we cannot ascertain
how many TTPs forwarded the information or simply
discarded them. We also found that reminders do not
cause signiﬁcant changes for TTPs, but have a slight im-
pact on providers. Given all these facts, we ﬁnd that es-
tablishing a communication channel to Web site admin-
istrators remains a hard problem even in the presence of
intermediaries. Thus, the ﬁrst question that arises for fu-
ture work is: How can the security community come up
with reliable means of establishing communication chan-
nels between researchers and affected parties?
User Distrust — For our experiments it was imperative
that we were able to keep track of delivered and viewed
reports. Therefore, we embedded a link to our web in-
terface into the email. This naturally increases the risk
of improper spam classiﬁcation. Moreover, the security
community trains users not to click on untrusted links or
respond to suspicious emails, i.e., a signiﬁcant fraction

USENIX Association  

25th USENIX Security Symposium  1027

of all reached administrators might not have followed
our link or accessed the report via email. To investigate
to what extent such behavior might have inﬂuenced our
ﬁndings, we sent emails containing the full vulnerability
details to all domains of the control group that were still
vulnerable at the end of our experiments, using only the
direct notiﬁcation channels. While for DCXSS, no signiﬁ-
cant difference could be observed, DWP domains notiﬁed
this way show signiﬁcant differences. Contrary to the
intuition that a report only accessible via a link would
hinder the campaign, however, these domains performed
worse in terms of ﬁx rates. This curious fact might
be caused by the fact that the emails contained multi-
ple links (e.g., to the vulnerable site, the description on
mitre.org, and the information on updating WordPress),
hence triggering more spam ﬁlters. Alternatively, such
long emails might have aroused more suspicions by the
recipients. Hence, this rises another question: To what
extent does the message tone, content, and length inﬂu-
ence the success of notiﬁcation campaigns?

Sender Reputation — When looking at the results for
TTPs in more detail, we ﬁnd that the trusted Ops-T com-
munity was responsible for a large portion of successful
notiﬁcation deliveries, even up to 50% of DCXSS viewed
reports for the TTPs. Thus, we argue that although stud-
ies have shown otherwise [5], trust in the sender of a noti-
ﬁcation message may be important factor to a campaign’s
success. This also holds true for the German CERT,
which (according to our data) was more inclined to for-
ward our messages. In this case, the cause is most likely
the fact that we originate from a German university and
have had interactions with the CERT before. This brings
up another question for future work: What is the impact
of the sender reputation, especially when using interme-
diaries, on the success of a notiﬁcation campaign?

Time to Fix and Need for Reminders — Once a report
was viewed, the ﬁx rate for DWP was around 30% within
ﬁve days, regardless of the channel that was used to orig-
inally transmit the report. After that, the ﬁx rate approxi-
mates what we observe for the control group, i.e., is most
likely not an effect of our notiﬁcation. For DCXSS, the
ﬁx ratio for Generic, Provider, and TTP channel was be-
tween 30% and 40%, while the WHOIS group achieved
a ﬁx rate of less than 20%. In total, ﬁxing these vulnera-
bilities typically took longer, which stems from the lack
of a readily available patch for the custom ﬂaws.

Additionally, as indicated by the increase in viewed
reports right after our reminders, we ﬁnd that they are
necessary and useful. Moreover, considering that a patch
typically only occurred within the ﬁrst ﬁve days of a re-
port being viewed, future work should select a shorter
interval for such reminders.

Results Generality — Our work was a ﬁrst glimpse into
the landscape of vulnerability notiﬁcations. We explic-
itly studied the effects of such a campaign in the context
of Web vulnerabilities which could be veriﬁed without
interfering with the server’s normal operation, i.e., we
did not consider high-impact ﬂaws such as SQL injec-
tions or remote code execution. The impact of our notiﬁ-
cation campaign was statistically signiﬁcant, but smaller
than in other related experiments (e.g., [13, 21]). Judging
from their results, the criticality of the discovered ﬂaws
may also effect the impact of a notiﬁcation campaign.

While in principle we could have applied our method-
ology to other types of ﬂaws, we limited our study specif-
ically to Web vulnerabilities. Contrary to other works
in this space, our methodology to ﬁnd Client-Side XSS
gave us the opportunity to notify domain owners of site-
speciﬁc ﬂaws rather than vulnerabilities which are the
same across multiple installations. Also, to the best of
our knowledge, no other parties had access to such a data
set, and hence, the site administrators were not aware
of the ﬂaws before our notiﬁcation. This data set gave
us the opportunity to study the behavior of administra-
tors when notiﬁed of previously-unknown vulnerabili-
ties, and to perform a comparative analysis with a data
set of known vulnerabilities.

Web vulnerabilities can be attributed to a domain,
therefore allowing us to use additional anchors to reach
administrators, e.g., in comparison to physical devices
such as home routers. We nevertheless believe the
methodology can be applied to other types of ﬂaws,
to determine whether the vulnerability type inﬂuences
the impact of notiﬁcations. Hence, comparing different
means of notifying parties for different types of vulnera-
bilities is an interesting direction for future research.

Even though the WordPress ﬂaws were publicly
known beforehand, they had not received media attention
such as, e.g., Heartbleed or NTP ampliﬁcation attacks.
The vulnerabilities we disclosed also concerned the ap-
plication layer rather than the network layer, i.e., needed
to be ﬁxed by a large number of disjunct site owners
rather than signiﬁcantly fewer network providers. Inves-
tigating these factors therefore is an interesting direction
for future research. This opens new research questions
such as: Are campaigns more successful if the vulnerabil-
ities gained attention in the media (such as Heartbleed)?
Does it matter who needs to ﬁx the vulnerability, be it a
Web site developer, network admins, or end-users?

8 Related Work

In this section, we relate our study to prior work, re-
viewing works on vulnerability notiﬁcations, large-scale
security analysis and an emerging area of disclosing
security-relevant information.

1028  25th USENIX Security Symposium 

USENIX Association

Large-Scale Vulnerability Notiﬁcation — In concur-
rent work, Li et al. [23] investigated the feasibility of
vulnerability notiﬁcations for networked systems, i.e.,
industry control systems, misconﬁgured IPv6 ﬁrewalls,
and DDoS ampliﬁers. Similarly to our work, they dis-
covered that notiﬁcations have a positive impact, but the
global effect is low and thus unsatisfactory. Contrary to
our work, they did not use links to track the reachability
of recipients. They did, however, gain insights into how
message content inﬂuences ﬁx rates. Moreover, from
messages received in a survey they handed out to the no-
tiﬁed parties, they found that such notiﬁcations generally
are welcomed by affected parties, underlining the need
for future work in this problem space.

Prior to this work, Li et al. [24] investigated how noti-
ﬁcation of compromised Web sites can improve the time
to clean-up from malware infestation. They ﬁnd that di-
rectly communicating with administrators via the Google
Webmaster Console increases likelihood of clean-up by
50% and decreases infection lengths by 62%.

Prior to these closely related works, Durumeric et al.
[13] conducted a large-scale analysis of the Heartbleed
bug. This work showed that large-scale notiﬁcation may
increase the number of patched servers by about 50%.
The main differences between this work and our study
are in the composition of the data set. The ﬁrst, impor-
tant one is the type of ﬂaw: the Heartbleed bug was a very
popular, high-impact ﬂaw with outstanding media cover-
age and its own website. Our data set does not contain
ﬂaws of this type, however it contains previously undis-
closed XSS vulnerabilities that, to the best of our knowl-
edge, were unknown to the Web site administrator prior
to our disclosure. As a result, our data set allows us to
study the problem without bias due to popularity. Sec-
ond, the authors used the network operator abuse contact
(retrieved from the IP WHOIS), whereas we use multiple
channels. Finally, our study focuses on Web vulnerabil-
ities, and does not target ﬂaws in the Internet infrastruc-
ture, e.g., SSL/TLS.

Similarly to the previous work, Kührer et al. [21] re-
ported on the vulnerability disclosure process on a data
set of 9 million servers susceptible to becoming unwit-
ting attackers in NTP ampliﬁcation attacks. The authors
reported all ﬂaws using en masse well-established chan-
nels. This allowed them to remove 90% of the vulnerable
servers within 7 weeks. As opposed to our paper, they
relied only on two channels, i.e., TTPs and vendors, and
they did not consider other possible ones such as domain
WHOIS. More importantly, the authors did not perform
a comparative analysis between channels, leaving the re-
search questions of our paper unanswered.
Large-Scale Security Analyses — Recently, we have
witnessed an increasing number of large-scale security
analyses ranging from validation of security testing tech-

niques (e.g., Balduzzi et al. [2], Lekies et al. [22], Doupé
et al. [9]) to Internet-wide analyses of insecure behavior
(e.g., Durumeric et al. [11], Kührer et al. [21]), which
can spot a large number of security issues. While most
of the efforts have been expended on tools and analysis
techniques, little has been done to address the problem
of reporting the discovered issues. For example, Bal-
duzzi et al. [2] tested 5,000 Web sites for HTTP param-
eter pollution (HPP), discovering a vulnerability in 30%
of them. With reference to the disclosure, the authors
left the problem unaddressed, only mentioning that they
could not reach all Web site owners. (For other examples
in the Web domain, please refer to Doupé et al. [9]).

To better support large-scale analysis, new tools have
been developed. For example, ZMap [12] can scan the
entire IPv4 address space in 45 minutes. ZMap has
already been used for Internet-wide analysis. For ex-
ample, Durumeric et al. [11] used ZMap to study the
HTTPS ecosystem, uncovering a variety of issues includ-
ing certiﬁcates with invalid domains and certiﬁcate mis-
use. Similarly, this paper does not address the problem
of reaching operators to solve the problem.
Notiﬁcation of Security-Relevant Information —
This paper can be seen as part of an emerging line of
research that develops the idea of using notiﬁcations
of security-relevant information as a security measure.
Works in this area studied the distribution of security-
relevant information from different angles and with a
major focus on malware reports. For example, Cetin
et al. [5] studied the role of sender reputation in abuse
reports by sending 480 reports to network providers and
Web site owners from senders with different reputations.
Their study found no evidence that reputation improves
cleanup rates, but they observed that, after accessing
an online technical report, network providers performed
better than Web site owners.

Vasek and Moore [34] looked at the problem from the
angle of the quality of the reports, concluding that de-
tailed reports increase the number of cleanups, while re-
ports with minimal details perform better than not send-
ing reports at all. Our paper builds on the results of these
works: we did not consider sender reputation as a vari-
able, and we prepare detailed reports.

Canali et al. [3] studied provider diligence by setting
up compromised Web sites and notifying them about on-
going malicious activities. Their experiments showed
that 64% of complaints were ignored. While this work
shows an alarming attitude towards these problems, the
size of their data set, 22 providers, makes it hard to gen-
eralize to a larger scale. From this point of view, our pa-
per provides a broader view on the issue, including other
notiﬁcation channels and comparative analysis using a
control group as a baseline.

USENIX Association  

25th USENIX Security Symposium  1029

9 Conclusion

With the increase of inter-connectivity on the Internet,
the magnitude and diversity of large-scale vulnerability
incidents will likely rise. We presented our experiences
with a large-scale notiﬁcation process to inform Web site
owners about vulnerable Web apps. While our notiﬁca-
tions have had an statistically signiﬁcant impact on the
vulnerability remediation, the overall ﬁx rate is unsatis-
factory, leaving 74.5% of Web sites exploitable after our
month-long experiment.

This naturally begs the question for the potential rea-
sons for the large fraction of unﬁxed sites. The major
cause is the unsolved challenge to reach out to persons
who can deploy a ﬁx, such as developers or administra-
tors. Of all contacts that we notiﬁed, only 5.8% viewed
our vulnerability report. Out of these, 40% ﬁxed the vul-
nerability within a week. This, but also the ease of ﬁxing
the vulnerabilities (in most cases just update WordPress),
indicates that the main problem is actually to disseminate
the vulnerability information.

How do we inform affected parties about vulnerabil-
ities on large scale? Identifying contact points remains
the main challenge that has to be addressed by the In-
ternet society, including network providers, CERTs, and
registrars. We imagine that this problem could, for ex-
ample, be tackled by centralized contact databases, more
efﬁcient dissemination strategies within hosters/CERTs,
or even a new notiﬁcation channel or trusted party re-
sponsible for such notiﬁcations. Until we ﬁnd solutions
to the reachability problem, the effects of large-scale no-
tiﬁcations are likely to remain low in the future.

Acknowledgements

The authors would like to thank Thomas Schreck and
the Spanish CERT for providing insights into the inner
workings of CERT organizations. Also, we would like
to thank the anonymous reviewers for their helpful com-
ments. In addition, we thank our shepherd Leyla Bilge
for her support in improving the paper for the camera-
ready version. This work was supported by the German
Ministry for Education and Research (BMBF) through
funding for the Center for IT-Security, Privacy and Ac-
countability (CISPA).

References

[1] Abusix GmbH. Abuse contact database. https:

//abusix.com/contactdb.html, 2016.

[2] Marco Balduzzi, Carmen Torrano Gimenez, Da-
vide Balzarotti, and Engin Kirda. Automated dis-
covery of parameter pollution vulnerabilities in

In Proceedings of the Network
web applications.
and Distributed System Security Symposium, 2011.

[3] Davide Canali, Davide Balzarotti, and Aurélien
Francillon. The role of web hosting providers in
detecting compromised websites.
In Proceedings
of the 22nd International World Wide Web Confer-
ence, 2013.

[4] CERT-CC.

List

of National CSIRTs.

http://www.cert.org/incident-managemen
t/national-csirts/national-csirts.cfm,
2016.

[5] Orcun Cetin, Mohammad Hanif Jhaveri, Carlos
Ganán, Michel van Eeten, and Tyler Moore. Un-
derstanding the role of sender reputation in abuse
reporting and cleanup. In Workshop on the Econ-
omy of Information Security (WEIS 2015).

[6] Daniel Cid.

Brute

force
WordPress

against

attacks
https://blog.sucuri.net/2015/10/brut
e-force-amplification-attacks-against
-wordpress-xmlrpc.html.

ampliﬁcation
XMLRPC.

[7] D. Crocker. Mailbox Names for Common Ser-
vices, Roles and Functions.
RFC 2142 (Pro-
posed Standard), http://www.ietf.org/rfc/r
fc2142.txt, May 1997.

[8] L. Daigle. WHOIS Protocol Speciﬁcation. RFC
3912 (Draft Standard), http://www.ietf.org/r
fc/rfc3912.txt, September 2004.

[9] Adam Doupé, Bryce Boe, Christopher Kruegel, and
Giovanni Vigna. Fear the EAR: Discovering and
mitigatfeaing execution after redirect vulnerabili-
ties. In Proceedings of the 18th ACM Conference
on Computer and Communications Security, 2011.

[10] Drupal Security Team. Drupal core - highly critical
- public service announcement - PSA-2014-003. ht
tps://www.drupal.org/PSA-2014-003.

[11] Zakir Durumeric, James Kasten, Michael Bailey,
and J. Alex Halderman. Analysis of the HTTPS
certiﬁcate ecosystem. In Proceedings of the 2013
ACM Internet Measurement Conference, 2013.

[12] Zakir Durumeric, Eric Wustrow, and J. Alex Hal-
derman. ZMap: Fast Internet-wide scanning and
its security applications. In Proceedings of the 22nd
USENIX Security Symposium, 2013.

[13] Zakir Durumeric, James Kasten, David Adrian,
J. Alex Halderman, Michael Bailey, Frank Li,

1030  25th USENIX Security Symposium 

USENIX Association

Nicholas Weaver, Johanna Amann, Jethro Beek-
man, Mathias Payer, and Vern Paxson. The mat-
ter of Heartbleed. In Proceedings of the 2014 ACM
Internet Measurement Conference, 2014.

Paxson. Remedying web hijacking: Notiﬁcation ef-
fectiveness and webmaster comprehension. In Pro-
ceedings of the 25th International World Wide Web
Conference, 2016.

[14] Matthew Finifter, Devdatta Akhawe, and David
Wagner. An empirical study of vulnerability re-
wards programs.
the 22nd
USENIX Security Symposium, 2013.

In Proceedings of

[15] FIRST.org, Inc. Forum of Incident Response and
Security Teams. https://www.first.org/, 2016.

[16] Sture Holm. A simple sequentially rejective multi-
ple test procedure. Scandinavian Journal of Statis-
tics, pages 65–70, 1979.

SAC 023:

[17] ICANN Security and Stability Advisory Com-
mittee.
the WHOIS ser-
vice a source for email addresses for spam-
mers?
https://www.icann.org/en/system/f
iles/files/sac-023-en.pdf.

Is

[25] Suqi Liu, Ian Foster, Stefan Savage, Geoffrey M.
Voelker, and Lawrence K. Saul. Who is .com?:
Learning to parse WHOIS records.
In Proceed-
ings of the 2015 ACM Internet Measurement Con-
ference.

[26] Microsoft Corporation. Services for senders and
ISPs. https://mail.live.com/mail/services
.aspx.

[27] MITRE Corporation. Common Vulnerabilities and

Exposures. http://cve.mitre.org/.

[28] Mutual

Internet Practices Association.

Do-
mainKeys Identiﬁed Mail. http://www.dkim.org
/, 2016.

[18] Iniqua. plecost. https://github.com/iniqua/

plecost, 2016.

[29] OpSecAdmin. Operations Security Trust. https:

//www.ops-trust.net/, 2016.

[19] Joomla!

[20151206] - Core - Session Hardening.
https://developer.joomla.org/security-c
entre/639-20151206-core-session-harde
ning.html.

[20] Aaron Jorbin. WordPress 4.4.1 Security and
Maintenance Release. https://wordpress.org
/news/2016/01/wordpress-4-4-1-securit
y-and-maintenance-release/.

[21] Marc Kührer, Thomas Hupperich, Christian
Rossow, and Thorsten Holz. Exit from hell? re-
ducing the impact of ampliﬁcation DDoS attacks.
In Proceedings of the 23rd USENIX Security Sym-
posium, 2014.

[22] Sebastian Lekies, Ben Stock, and Martin Johns. 25
million ﬂows later: Large-scale detection of DOM-
based XSS. In Proceedings of the 20th ACM Con-
ference on Computer and Communications Secu-
rity, 2013.

[23] Frank Li, Zakir Durumeric, Jakub Czyz, Mo-
hammad Karami, Damon McCoy, Stefan Savage,
Michael Bailey, and Vern Paxson. You’ve got vul-
nerability: Exploring effective vulnerability notiﬁ-
cations. In Proceedings of the 25th USENIX Secu-
rity Symposium, 2016.

[24] Frank Li, Grant Ho, Eric Kuan, Yuan Niu, Lucas
Ballard, Kurt Thomas, Elie Bursztein, and Vern

[30] Karl Pearson. X. On the criterion that a given sys-
tem of deviations from the probable in the case of a
correlated system of variables is such that it can be
reasonably supposed to have arisen from random
sampling. The London, Edinburgh, and Dublin
Philosophical Magazine and Journal of Science, 50
(302):157–175, 1900.

[31] SPF Project. Sender Policy Framework. http://

www.openspf.org/, 2016.

[32] Ben Stock, Stephan Pﬁstner, Bernd Kaiser, Sebas-
tian Lekies, and Martin Johns. From facepalm
to brain bender: Exploring client-side cross-site
scripting. In Proceedings of the 22nd ACM Confer-
ence on Computer and Communications Security,
2015.

[33] Team Cymru.

Team Cymru IP to ASN Map-
ping. http://www.team-cymru.org/IP-ASN-m
apping.html, 2016.

[34] Marie Vasek and Tyler Moore. Do malware reports
expedite cleanup? An experimental study. In 5th
Workshop on Cyber Security Experimentation and
Test, CSET, 2012.

[35] W3Techs. Usage of content management systems
for websites. http://w3techs.com/technolog
ies/overview/content_management/all/.

USENIX Association  

25th USENIX Security Symposium  1031

A Notiﬁcation Email

Subject: Vulnerability Notification for
...com

your domain

Hello,

Primer: All information in and attached to this
email is confidential and should be passed on to
individuals and organizations on a need-to-know
principle only.

We are security researchers from Saarland University,
Germany. In our research, we have been scanning
several web sites for critical vulnerabilities.
We would like to inform you that your website is
susceptible to the following vulnerability(ies):

- XMLRPC Multicall Vulnerability

The XMLRPC API of Wordpress can be abused to execute
numerous commands on the server-side, thereby
allowing an attacker to bruteforce passwords or
perform a Denial-of-Service attack against the
server.

You can review more detailed
information using our web interface at
https://notify.mmci.uni-saarland.de/....
Alternatively, you can retrieve more information
via email. To do so, please respond to this email
and set the subject line to *only* contain the token
72cf.... We will automatically respond with the
vulnerability report via email.

Since this notification is part of an ongoing
research project, we will re-scan your web site to
see if the vulnerability has been fixed. If you wish
us to stop scanning your web site, please contact us
at contact@notify.mmci.uni-saarland.de. Should you
need further information or have any other questions,
please do not hesitate to contact us using the same
email address.

Best Regards,
Ben Stock, Researcher at CISPA
---
Center for IT-Security, Privacy, and Accountability
Saarland University, Building E9 1
Phone +49 681 302 57377

B Multicall Checker

The Multicall checker uses a timing side-channel to de-
termine whether a WordPress XMLRPC service is vul-
nerable or not. First, we estimate network latency with
a probe request. We use the round-trip time of the probe
to rule out network transmission time from the measure-
ment of the multicall request. The resulting value is an
estimation of the CPU time. However, as this value may
be sensitive to ﬂuctuations of the network latency esti-
mation, we increase the execution time with inefﬁcient
user credentials. These strings trigger WordPress sani-
tization procedures, resulting in longer execution time,

and guarantee to always fail at login attempts to prevent
accidental unauthorized access to a WordPress installa-
tion. Our test estimates CPU time of two multicall re-
quests with 40 and 80 calls per request. We measured
that our servers take 1,600 ms and 3,300 ms of CPU time
on an Intel i7 processor for 40 and 80 multicalls, respec-
tively, which we use as indicators for vulnerable services.
Finally, we correlate the time analysis with the version
of the deployed WordPress, which can be extracted from
several sources. If both timing analysis and version indi-
cate a vulnerable service, then we mark the Web site as
Exploitable, otherwise as Non-Exploitable.

C Conﬁdence Function

The monitoring system for WordPress returns a collec-
tion of time series T v
site, v a vulnerability, and si is the result of the checker

ws= s1⋅s2⋅ ...⋅sn where ws is the Web
in a point of time i with 1≤ i≤ n. The value si can be

E if the checker found the vulnerability Exploitable; N
for Non-Exploitable. In our experiments, we need to es-
tablish whether a Web site ws has ﬁxed v. To do that,
we take into account the rate of unlikely events within a
time series in order to establish a conﬁdence level, i.e.,

the number of substrings N⋅ E in the longer preﬁx of the

time series. We deﬁne the conﬁdence that the Web site is
not vulnerable as the complement of this rate. We deﬁne
a Web site as not vulnerable if the conﬁdence is greater
than 0.99. If no errors occur in a time series, we deﬁne a
conservative error of 0.1, i.e., a domain is marked ﬁxed
if it was Non-Exploitable for three consecutive days.

D Comparison of Notiﬁed Groups

Generic
WHOIS
Provider
TTP

Generic
-
0.0323810
0.2982599
0.2456719

WHOIS
0.0323810
-
0.2714901
0.3276381

Provider
0.2982599
0.2714901
-
0.9038795

TTP
0.2456719
0.3276381
0.9038795
-

Table 7: p-values from χ2 tests for DWP

Generic
WHOIS
Provider
TTP

Generic
-
0.5285343
0.1360734
0.3841099

WHOIS
0.5285343
-
0.3862386
0.1346949

Provider
0.1360734
0.3862386
-
0.0191932

TTP
0.3841099
0.1346949
0.0191932
-

Table 8: p-values from χ2 tests for DCXSS

1032  25th USENIX Security Symposium 

USENIX Association

