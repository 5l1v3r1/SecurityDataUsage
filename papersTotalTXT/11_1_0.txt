Toward Online Veriﬁcation of Client Behavior in Distributed Applications

Robert A. Cochran

Michael K. Reiter

Department of Computer Science

Department of Computer Science

University of North Carolina

University of North Carolina

Chapel Hill, NC, USA

rac@cs.unc.edu

Chapel Hill, NC, USA

reiter@cs.unc.edu

Abstract

Existing techniques for a server to verify the correctness
of client behavior in a distributed application suffer from
imprecision, increased bandwidth consumption, or signiﬁ-
cant computational expense. We present a novel method for
a server to efﬁciently search for a code path through the
client that “explains” each client message, even though the
server does not know local inputs to the client that might
have caused the message. This method gives rise to a pre-
cise client veriﬁcation technique that consumes no addi-
tional bandwidth and that validates most legitimate client
messages much faster than previous such techniques. Our
technique can gain even further improvements with a min-
imal increase in bandwidth use. We detail this innova-
tion and use it to verify client behavior in two client-server
games, namely XPilot and TetriNET. In our best conﬁgura-
tion, veriﬁcation often keeps pace with TetriNET gameplay.

1. Introduction

In client-server applications, client misbehavior can pose
dangers to the larger distributed application in a variety of
ways. A manipulated client may be able to compromise
the server directly if the server has an extant vulnerability.
Even if the server has no such vulnerabilities, any applica-
tion state for which the client is authoritative can be altered
by a misbehaving client and then propagated via the server
to the larger distributed application.

A common approach to defend against client misbehav-
ior is for the server to validate client messages using a
model of valid client behavior derived from the sanctioned
client software. For example, Gifﬁn et al. [12] and Guha
et al. [14] developed methods to conﬁrm that requests are
consistent with a control-ﬂow model of the client. This
approach admits false negatives, however — compromised
clients that make calls consistent with their control-ﬂow

models (but that may still manipulate application state) can
escape detection, in a manner analogous to mimicry attacks
on intrusion-detection systems [28, 22]. Greater precision
has been achieved, but with greater expense. For example,
the Ripley system [25] replays each client on the server in
order to validate the client’s requests, but this incurs the
bandwidth overhead of transmitting all client-side inputs
(user inputs, timer values, etc.) to the server to permit re-
play and the computational overhead of replaying the client
on the server side. An approach by Bethea et al. [2] omits
transmitting client-side inputs, thus not incurring bandwidth
overheads, but then must search for whether there exist in-
puts that could have produced the client messages observed
at the server. The resulting computational expense renders
this method of veriﬁcation useful primarily in an ofﬂine
fashion and, even then, only after modifying test applica-
tions to constrain the search spaces they present.

In this paper we develop a client-checking algorithm that
retains precision while permitting better tradeoffs between
bandwidth costs and computational expense in the common
case of a legitimate client. Our algorithm builds from the
aforementioned approach of Bethea et al. [2] but exploits a
training phase to guide a search for a path through the client
program that could have produced a message observed at
the server. One conﬁguration of our algorithm incurs no ad-
ditional bandwidth costs, like Bethea et al.’s, but completes
veriﬁcation much more efﬁciently in the common case of
a legitimate client. Another conﬁguration of our algorithm
consumes minimal additional bandwidth — in our tests, at
most two bytes per client-to-server message — and com-
pletes veriﬁcation even faster in the common case of a le-
gitimate client. Moreover, we reiterate that our algorithm
is precise in the sense of having no false negatives and no
false positives. That is, any sequence of client messages that
our technique declares legitimate actually is, in the sense
that there exist inputs that would have driven the sanctioned
client software to send that sequence of messages,1 and any

1More precisely, the only source of false negatives is the ﬁdelity of
modeling values returned by components with which the client software

sequence of client messages that our technique declares im-
possible is actually inconsistent with the client software.

To deﬁnitively conclude that a sequence of client mes-
sages is impossible (the uncommon case), our algorithm
incurs a cost similar to Bethea et al.’s [2], however. As
such, we expect our algorithm to be useful primarily as an
online data reduction technique that prunes the client mes-
sages that must be logged for ofﬂine analysis by that (or
another) technique. In addition, clients whose messages are
not veriﬁed quickly by our technique can be serviced only
provisionally (e.g., with fewer privileges and/or logging to
enable undoing their effects) while their veriﬁcation is com-
pleted ofﬂine.

We evaluate our algorithm in the context of online
games. Online games provide a useful proving ground for
our techniques due to the frequent manipulation of game
clients for the purposes of cheating [31, 17, 30] and due
to the pressure that game developers face to minimize the
bandwidth consumed by their games [19]. As such, our
techniques are directly useful for cheat detection in this
domain. Moreover, Hoglund and McGraw [15] argue that
“games are a harbinger of software security issues to come,”
suggesting that defenses against game cheats and game-
related security problems will be important techniques for
securing future massive distributed systems of other types.
Our evaluations show, for example, that verifying the be-
havior of a valid client in the TetriNET game can often keep
up with the pace of gameplay. Moreover, our algorithm suc-
ceeds in verifying messages traces of the highly interactive
XPilot game without game restrictions required by previous
techniques [2].

The technique that we develop here is an application
of symbolic execution [3], which has been widely studied
and applied for various purposes (see Section 2). Dynamic
analysis techniques like symbolic execution typically face
scaling challenges as code complexity and execution length
grow, and our case is no exception. We believe that the
technique we develop here to prioritize path analysis on the
basis of historical usage may be more broadly useful, i.e.,
outside of behavior veriﬁcation in distributed systems, to
contain the expense of dynamic analysis.

The rest of this paper is structured as follows. We dis-
cuss related work in Section 2 and necessary background in
Section 3. We present our algorithm in Section 4 and Sec-
tion 5. Evaluation results for this algorithm are presented in
Section 6, and we conclude in Section 7.

2. Related Work

As we will see, the approach that we take to the behavior
veriﬁcation problem that we study is an application of sym-

interacts (e.g., the client OS). This will be discussed further in Section 6.

bolic execution [3], a dynamic analysis technique that “ex-
ecutes” a program with some values unspeciﬁed or “sym-
bolic”, in order to derive the postconditions of the software
on the symbolic state. In our case, we symbolically exe-
cute the client software with client-side inputs unknown to
the server marked symbolic and then determine whether the
messages received from the client violate the postconditions
derived from the software. Symbolic execution has a long
history of study in the security and veriﬁcation communi-
ties, but we believe the optimization problem we study here
to be distinct from prior work, as discussed below.

The applications of symbolic execution that are most re-
lated to our own are in debugging and diagnostics. Zamﬁr et
al. [34] developed a debugging tool that uses symbolic exe-
cution to reconstruct the likely path a program took before
it crashed, from the core dump ﬁle recorded by the operat-
ing system when the crash occurred. Their technique ﬁnds
a feasible path or set of paths through a program that allow
the program to reach the memory and process state that the
core dump ﬁle indicates. SherLog [33] is another error di-
agnosis tool that uses a log ﬁle instead of a core dump ﬁle
to indicate how a program executed. SherLog performs path
analysis (not symbolic execution per se, but a similar tech-
nique) to determine the likely execution paths and variable
values implied by a given set of log ﬁles. Similarly, sym-
bolic execution has been used to discover the constraints for
the paths through a program that reaches a vulnerability or
error condition [4, 5, 7, 32]. Viewed through the lens of
this paper, the core dump ﬁle, log ﬁle, or error condition
in these previous works is analogous to a “client message”,
and these tools similarly seek to ﬁnd an execution that could
explain it. However, the structure of our veriﬁcation task —
namely successively building an execution path to explain
an entire sequence of messages — and the performance de-
mands that we seek to meet in this work give rise to the
technique we propose, which we believe to be novel.

Among applications of symbolic execution, software
testing has received the most research attention. Symbolic
execution can be an effective method of increasing the de-
gree of code coverage in a testing tool by generating test
cases that cover a high percentage of paths in a program.
For example, DART [13] ﬁrst concretely executes a program
with an arbitrary input, recording the path constraint im-
plied by its choice at each branch point. The path constraint
is then modiﬁed by negating a clause and a satisfying as-
signment to the constraint is found to derive a new input
that will cover a different path in the program. More recent
examples of this approach, which is also called concolic
testing or dynamic symbolic execution, include CUTE [21],
JPF [27] and Pex [23, 1]. Our approach expands the veri-
ﬁer’s search for paths to explain client messages as needed,
starting from an initial collection of paths, but it does so
without solving for inputs to exercise a path concretely and

without the goal of achieving high path coverage, per se.

Aside from the behavior veriﬁcation that we study here,
an orthogonal defense against client compromise is to strip
clients of authoritative state. In this approach, any state that
could affect the integrity of the larger distributed applica-
tion is instead managed at the server, outside the reach of
direct manipulation by the client. Tools such as Swift [9]
automatically identify such important state for placement at
the server. This approach, however, is known to increase
the bandwidth consumed by interactive applications such
as distributed games, owing to the need for every access to
authoritative state to reach the server (e.g., [19, p. 112]).
Another defense is to augment the client with monitoring
software (e.g., [10, 18, 20, 11, 16]), but this approach begs
the question of how to defend the monitoring software from
compromise and, in some domains, has suffered resistance
from the user community (e.g., [29]).

3. Background and Goals

As discussed in Section 1, our goal is to build a veriﬁer
to detect a client in a distributed application that exhibits
behavior, as seen by the server, that is inconsistent with the
sanctioned client software and the application state known
at the server. That is, the veriﬁer discerns whether there was
any possible sequence of inputs to the sanctioned client soft-
ware that could have given rise to each message received at
the server, given what the server knew about the client based
on previous messages from the client and the messages the
server sent to the client. In doing so, our approach should
enable an automated, server-side validation procedure for
client messages.

More speciﬁcally, consider a sequence of messages
msg 0, msg 1, . . . that were sent or received by the client,
listed in the order in which the client sent or received them;
we call such a sequence a message trace. Because the server
received or sent, respectively, each of these messages, the
server knows their contents,2 and previous work described
an efﬁcient method for the client to inform the server of
the order in which the client processed these messages [2].
As such, the message trace msg 0, msg 1, . . . is known to the
server and, so, the veriﬁer.

The veriﬁer’s goal is to ﬁnd a sequence of client in-
structions, called an execution preﬁx and denoted Π, that
begins at the client entry point and is consistent with the
message trace msg 0, msg 1, . . ..
In this paper we con-
sider only single-threaded clients, and so Π must represent
single-threaded execution. More speciﬁcally, Πn is consis-
tent with msg 0, msg 1, . . . , msg n if the network I/O instruc-

2We do not consider the loss of client-to-server messages here, though
previous work [2] provided an efﬁcient method to recover from such losses
that we can employ equally well.

tions (SEND and RECV3) in Πn number n + 1 and match
msg 0, msg 1, . . . , msg n by type — i.e., if msg i is a client-
to-server message (respectively, server-to-client message),
then the i-th network I/O instruction is a SEND (respec-
tively, RECV) — and if the branches taken in Πn were pos-
sible given the contents of msg 0, msg 1, . . . , msg n. There
may be many preﬁxes Π consistent with msg 0, msg 1, . . .
(e.g., depending on inputs to the client, such as user in-
puts or system-call return values), but if there are none, then
the trace msg 0, msg 1, . . . is impossible given the sanctioned
client software.

The goal of the veriﬁer is simply to determine if
there exists an execution preﬁx that is consistent with
msg 0, msg 1, . . .; if not, then the veriﬁer detects the client
as compromised. Assuming that client compromise is rare,
our goal is to optimize locating such a preﬁx so that legiti-
mate clients (the common case) can be veriﬁed as quickly as
possible. While ideally both validation of legitimate clients
and detection of compromised clients would be achieved
online (i.e., at the pace of message receipt), the number of
execution preﬁxes to explore through the client will gen-
erally make it infeasible to deﬁnitively detect a compro-
mised client, since doing so requires checking that there
is no preﬁx Π that is consistent with the message trace
msg 0, msg 1, . . .. However, we seek to show that through
judicious design of the veriﬁer, it can validate most legiti-
mate clients quickly. Requests from clients that the server
cannot validate quickly can then be subjected to stricter
(though presumably more expensive) sandboxing and/or
logging for further analysis ofﬂine.

4. Training

The algorithm we present in this paper to meet the goals
described in Section 3 incorporates a training phase that is
used to conﬁgure the veriﬁer.

4.1. Requirements

The training phase uses message traces of client behavior
that should reﬂect to the greatest degree possible the actual
client behavior that will be subjected to veriﬁcation. For ex-
ample, in the case of a client-server game, the training phase
should make use of message traces of valid gameplay. We
stress that the training phase requires only valid message
traces (i.e., for which there exists an execution preﬁx con-
sistent with each), and any invalid message traces will be

3In this paper, we abbreviate call instructions to POSIX select(),
send() and recv() system calls (or their functional equivalents) with
the labels SELECT, SEND and RECV. Our techniques apply to software
written to other interfaces, of course, but would require some of our deﬁ-
nitions to be adapted accordingly.

detected as such during the training process (albeit at sub-
stantial computational expense). As such, there is no risk
of “poisoning” the training process with invalid message
traces, and gathering valid message traces for training pur-
poses can be done by executing the sanctioned client soft-
ware artiﬁcially or by recording message traces from actual
client-server sessions.

4.2. Algorithm

As we will discuss in Section 5, during veriﬁcation the
veriﬁer will attempt to ﬁnd an execution preﬁx Πn that is
consistent with the message trace msg 0, . . . , msg n incre-
mentally, i.e., by appending to an execution preﬁx Πn−1
that is consistent with msg 0, . . . , msg n−1. To do so, it
searches through execution fragments in an effort to ﬁnd
one that it can append to create Πn. The goal of the train-
ing phase, then, is to determine the order in which to search
possible execution fragments.

More speciﬁcally,

let an execution fragment be any
nonempty path (i) beginning at the client entry point, a SE-
LECT, or a SEND in the client software, (ii) ending at a
SEND or RECV, and (iii) having no intervening SEND or
RECV instructions. Training produces a set Φ of execu-
tion fragments. As we will discuss in Section 5, the ver-
iﬁer will examine execution fragments in an order guided
by Φ to extend an execution preﬁx Πn−1 to reach an ex-
ecution preﬁx Πn that is consistent with a message trace
msg 0, . . . , msg n. Ideally, Φ would include the execution
fragments that are commonly exercised during execution or
reasonable approximations thereof.

The algorithm for constructing Φ starts from at least one
message trace msg 0, msg 1, . . . and execution preﬁx Π that
is consistent with it. We do not necessarily require that Π
is the actual execution preﬁx that was executed to produce
the trace, though if that execution preﬁx could be recorded
for the purposes of training, then it will certainly sufﬁce.
Alternatively, Π could be produced from the trace (in an
ofﬂine fashion) using existing techniques [2].

Given the execution preﬁx Π, the algorithm symbolically
executes the sanctioned client software on the path Π, main-
taining the resulting symbolic state throughout this execu-
tion. This symbolic state consists of memory regions pop-
ulated by symbolic values with constraints. The constraints
on symbolic values are those implied by execution of the
path Π; e.g., every branch condition involving a symbolic
value will generally add another constraint on that value,
perhaps in relation to other symbolic values. A memory
region is concrete if it is constrained to be a single value.

From this symbolic execution, the training algorithm
generates a “postcondition” for each distinct execution frag-
ment contained in Π. Speciﬁcally, after each execution of
a fragment in Π, the constraints on the symbolic state form

a “postcondition term” for that fragment. The disjunction
of all postcondition terms collected after execution of the
same fragment then forms the postcondition for that frag-
ment. Moreover, since the same fragment may appear in
other execution preﬁxes ˆΠ, the postcondition terms from all
such executions can contribute to the postcondition of the
fragment.

We use this postcondition to then determine the mes-
sages in each trace with which the fragment is consistent,
where “consistent” has a meaning analogous to, but some-
what more generous than, that for execution preﬁxes with
respect to message traces. Speciﬁcally, an execution frag-
ment is consistent with a message msg if the fragment ends
at an appropriate network I/O instruction — SEND if msg
is a client-to-server message, RECV otherwise — and in the
case of a SEND, if the fragment postcondition does not con-
tradict the possibility that msg was sent in that SEND or, in
other words, if the postcondition and the asserted message
contents do not imply false.

Once the set of execution fragments consistent with each
message is found, the next step of the algorithm divisively
clusters the execution fragments. The fragments are ﬁrst
clustered by the type of their last instructions (SEND or
RECV) and then by their starting instructions; i.e., at the sec-
ond level, all fragments in the same cluster start at the same
instruction and end at the same type of network I/O instruc-
tion. Finally, each of these level-two clusters is clustered
so that fragments that are only small deviations from each
other (in terms of the instructions executed) are in the same
cluster. Speciﬁcally, each level-two cluster is clustered by
(Levenshtein) edit distance using k-medoid clustering to a
ﬁxed number of clusters k (or fewer if there are fewer than k
fragments in a level-two cluster). Once the execution frag-
ments are clustered by edit distance, the medoid of each
cluster is added to Φ.
In addition, all training messages
consistent with any fragment are retained as indicators for
the fragment’s cluster (and the cluster’s medoid).

5. Veriﬁcation

In this section, we discuss how the veriﬁer, for the next
message msg n in a message trace, utilizes the clustering
described in Section 4 to guide its search for an execu-
tion fragment of the client to “explain” the client’s progress
through it sending or receiving msg n. More speciﬁcally,
the veriﬁer does so by ﬁnding an execution fragment to ap-
pend to an execution preﬁx Πn−1 that is consistent with
msg 0, . . . , msg n−1, in order to produce an execution preﬁx
Πn that is consistent with msg 0, . . . , msg n.

Before describing the veriﬁer algorithm, there are two
important caveats to note. First, even if there is an execution
fragment that, appended to Πn−1, yields a Πn that is con-
sistent with msg 0, . . . , msg n, it may be that this fragment is

not contained in Φ. Recall that Φ is only a partial list of all
execution fragments; it includes only the medoid fragments
after clustering the execution fragments from training. As
such, it will not sufﬁce for us to limit our attention only to
the execution fragments in Φ, and indeed a central innova-
tion in our work is how we use Φ to guide the search for
execution fragments without being limited to it.

Second, even if the client is behaving legitimately, there
may be no execution fragment that can be appended to
Πn−1 to produce an execution preﬁx Πn that is consis-
In this case, Πn−1 could
tent with msg 0, . . . , msg n.
not have been the path executed by the client through
msg 0, . . . , msg n−1. So, the veriﬁer will need to back-
track to search for another ˆΠn−1 that is consistent with
msg 0, . . . , msg n−1, which the veriﬁer will then try to ex-
tend to ﬁnd a Πn consistent with msg 0, . . . , msg n. Of
course, backtracking can re-enter previous message veriﬁ-
cations, as well, and in the limit, can devolve into an ex-
haustive search for a path from the client entry point that
is consistent with msg 0, . . . , msg n. If and only if this ex-
haustive search concludes with no consistent path, the client
is detected as behaving inconsistently with the sanctioned
client software [2], and this exhaustive search will gener-
ally be costly. However, for the applications we consider
in Section 6, legitimate clients rarely require backtracking.
Combined with optimizations to backtracking that we de-
scribe in Section 5.3, our algorithm is a step toward making
it possible to quickly verify legitimate clients for such appli-
cations and triage those it cannot for further checking later
(and sandboxing in the interim).

5.1. Basic Veriﬁcation Algorithm

The veriﬁcation algorithm takes as input an execution
preﬁx Πn−1 consistent with msg 0, . . ., msg n−1 and that
ends with the SEND or RECV at which msg n−1 was sent or
received. The veriﬁer can symbolically execute the sanc-
tioned client software on the path Πn−1, using the concrete
messages msg 0, . . ., msg n−1 as those sent or received at the
corresponding network I/O instructions in Πn−1, to yield
the symbolic state σn−1 of the client.

Preprocessing for a server-to-client message
If msg n−1
is a server-to-client message,
then presumably msg n−1
most directly inﬂuenced client execution immediately after
it was received. So, our algorithm to produce a Πn con-
sistent with msg 0, . . . , msg n ﬁrst performs a preprocess-
ing step by symbolically executing σn−1 forward using the
server-to-client message msg n−1 as the message received
in its last instruction (which is a RECV). σn−1 is a sym-
bolic state and so may branch on symbolic variables as it is
executed forward (even though msg n−1 is concrete); pre-
processing explores paths in increasing order of the number

of symbolic variables they include so far. This search con-
tinues until a path encounters an instruction that suggests
that the processing of msg n−1 by the client is complete —
speciﬁcally, upon encountering a SELECT or a SEND. The
path starting from σn−1 until this instruction are used to ex-
tend Πn−1 (and σn−1) to produce Π+

n−1 (and σ+

n−1).

If msg n−1 is a client-to-server message, then no such
n−1 and

preprocessing step is necessary. In this case, let Π+
σ+
n−1 be Πn−1 and σn−1, respectively.

Overview of basic veriﬁcation algorithm The core of
the veriﬁcation algorithm starts from the symbolic state
σ+
n−1 and uses a subset Φn ⊆ Φ to guide a search for an
execution fragment that can be appended to Π+
n−1 to yield
Πn that is consistent with msg 0, . . . , msg n. Intuitively, Φn
includes the execution fragments from Φ that are deemed
likely to be similar to the fragment executed by the client
leading up to it sending or receiving msg n. We defer dis-
cussing the selection of Φn to Section 5.4; here we simply
stipulate that each fragment in Φn begins at the instruction
pointed to by the program counter of σ+
n−1 and ends at a
SEND or RECV if msg n is a client-to-server message or a
server-to-client message, respectively. We stress that de-
spite these constraints, appending a φ ∈ Φn to Π+
n−1 will
not necessarily yield a Πn consistent with msg 0, . . . , msg n.
Our veriﬁcation algorithm executes roughly as follows.
The algorithm builds a strictly binary tree of paths, each
starting from the next instruction to be executed in σ+
n−1.
(Here, by “strictly” we mean that every non-leaf node has
exactly two children, not one.) The root of the tree is the
empty path, and the two children of a node in the tree ex-
tend the path represented by that node through the next sym-
bolic branch (i.e., branch instruction involving a symbolic
variable). One child represents that branch evaluating to
false, and the other represents that branch evaluating to true.
The algorithm succeeds in ﬁnding a fragment with which to
extend Π+
n−1 to yield Πn if, upon extending a path, it en-
counters a network I/O instruction that can “explain” msg n,
i.e., that yields a state with constraints that do not contradict
msg n being the network I/O instruction’s message.

Perhaps the central idea in our algorithm, though, is the
manner in which it selects the next node of the tree to ex-
tend. For this purpose it uses the training fragments Φn.
There are any number of approaches, but the one we eval-
uate here selects the path to extend to be the one that mini-
mizes the edit distance to some preﬁx of a fragment in Φn
(and that has not already been extended or found to be in-
consistent). This strategy naturally leads to ﬁrst examining
the fragments in Φn, then other fragments that are small
modiﬁcations to those in Φn, and ﬁnally other fragments
that are further from the fragments in Φn. This algorithm
will be detailed more speciﬁcally below.

n−1, msg n, Φn)

Algorithm verify (σ+
101. nd ← makeNode()
102. nd.path ← hi; nd.state ← σ+
103. Live ← {nd}
104. while (|Live| > 0) {
105.

nd ← arg min

n−1

nd′∈Live

min
φ∈Φn

min
φ′⊑φ

editDist(nd′.path, φ′)

Live ← Live \ {nd}
σ ← nd.state; π ← nd.path

106.
107.
108. while (σ.next 6= ⊥ and

isNetInstr(σ.next) = false and
isSymbolicBranch(σ.next) = false)

π ← π k hσ.nexti; σ ← execStep(σ)

if (isNetInstr(σ.next) = true and

((σ.constraints ∧ σ.next.msg = msg n) 6⇒ false))

return π k hσ.nexti

// success!

else if (isSymbolicBranch(σ.next) = true) {

nd.child0 ← makeNode()
nd.child0.path ← π k hσ.nexti
nd.child0.state ← [ execStep(σ) |

if (nd.child0.state.constraints 6⇒ false)

σ.next.cond 7→ false ]

Live ← Live ∪ {nd.child0}

nd.child1 ← makeNode()
nd.child1.path ← π k hσ.nexti
nd.child1.state ← [ execStep(σ) |

σ.next.cond 7→ true ]

109.
110.

111.
112.
113.
114.
115.

116.
117.
118.
119.
120.

if (nd.child1.state.constraints 6⇒ false)

Live ← Live ∪ {nd.child1}

121.
122.
123.
124. }
125. return ⊥

}

// failure

Figure 1. Basic veriﬁcation algorithm, de(cid:173)
scribed in Section 5.1

Details of basic veriﬁcation algorithm The algorithm
for verifying a client-to-server message is summarized more
speciﬁcally in Figure 1. This algorithm, denoted verify,
takes as input the symbolic state σ+
n−1 resulting from ex-
ecution of Πn−1 from the client entry point on message
trace msg 0, . . . , msg n−1 and then the preprocessing step
described above if msg n−1 is a server-to-client message;
the next message msg n; and the execution fragments Φn
described above (and detailed in Section 5.4). Its output is
either an execution fragment that can be appended to Π+
n−1
to make Πn that is consistent with msg 0, . . ., msg n, or
undeﬁned (⊥). The latter case indicates failure and, more
speciﬁcally, that there is no execution preﬁx that can ex-
tend Π+
n−1 to make Πn that is consistent with msg 0, . . .,
msg n−1. This will induce the backtracking described above
to search for another ˆΠn−1 that is consistent with msg 0, . . .,
msg n−1, which the veriﬁer will then try to extend to ﬁnd a
Πn consistent with msg 0, . . ., msg n.

The aforementioned binary tree is assembled as a collec-

tion of nodes created in lines 101, 113, and 118 in Figure 1.
Each node has ﬁelds path, state, and children child0 and
child1. The root node nd is initialized with nd.path = hi
and nd.state = σ+
n−1 (102). Initially only the root is created
(101–102) and added to a set Live (103), which includes the
nodes that are candidates for extending. The algorithm ex-
ecutes a while loop (104–124) while Live includes nodes
(104) and the algorithm has not already returned (111). If
the while loop exits because Live becomes empty, then the
algorithm has failed to ﬁnd a suitable execution fragment
and ⊥ is returned (125).

This while loop begins by selecting a node nd from Live
that minimizes the edit distance to some preﬁx of a frag-
ment in Φn; see line 105, where φ′ ⊑ φ denotes that φ′
is a preﬁx of φ. The selected node is then removed from
Live (106) since any node will be extended only once. The
state σ of this node (107) is then executed forward one
step at a time (σ ← execStep(σ), line 109) and the ex-
ecution path recorded (π ← π k hσ.nexti, where k de-
notes concatenation) until this stepwise execution encoun-
ters the client exit (σ.next = ⊥, line 108), a network
I/O instruction (isNetInstr(σ.next) = true), or a sym-
bolic branch (isSymbolicBranch(σ.next) = true). In the
ﬁrst case (σ.next = ⊥), execution of the main while
loop (104) continues to the next iteration.
In the second
case (isNetInstr(σ.next) = true) and if the constraints
σ.constraints accumulated so far with the symbolic state σ
do not contradict the possibility that the network I/O mes-
sage σ.next.msg in the next instruction σ.next is msg n (i.e.,
(σ.constraints ∧ σ.next.msg = msg n) 6⇒ false, line 110),
then the algorithm returns successfully since π k hσ.nexti is
an execution fragment that meets the veriﬁer’s goals (111).
Finally, in the third case (isSymbolicBranch(σ.next) =
true), the algorithm explores the two possible ways of
extending π, namely by executing σ.next conditioned
on the branch condition evaluating to false (denoted
[ execStep(σ) | σ.next.cond 7→ false ] in line 115) and
conditioned on the branch condition evaluating to true
(120).
In each case, the constraints of the resulting state
are checked for consistency (116, 121) and the consistent
states are added to Live (117, 122).

5.2. Reﬁnements

Edit-distance calculations As discussed previously, one
insight employed in our verify algorithm is to explore paths
close to the training fragments Φn ﬁrst, in terms of edit dis-
tance (line 105). Edit distance between strings s1 and s2 can
be computed by textbook dynamic programming in time
O(|s1| · |s2|) and space O(min(|s1|, |s2|)) where |s1| de-
notes the character length of s1 and similarly for s2. While
reasonably efﬁcient, this cost can become signiﬁcant for
large s1 or s2.

For this reason, our implementation optimizes the edit
distance computations. To do so, we leverage an algorithm
due to Ukkonen [24] that tests whether editDist(s1, s2) ≤
if so, computes editDist(s1, s2) in time O(t ·
t and,
min(|s1|, |s2|)) and space O(min(t, |s1|, |s2|)) for a param-
eter t. By starting with a small value for t, we can quickly
ﬁnd nodes nd′ ∈ Live such that for some φ ∈ Φn and φ′ ⊑
φ, editDist(nd′.path, φ′) ≤ t. Only after such nodes are
exhausted, do we then increase t and re-evaluate the nodes
still in Live. By proceeding in this fashion, verify incurs
cost per edit-distance calculation of O(t · min(|s1|, |s2|))
for the distance threshold t when the algorithm returns, ver-
sus O(|s1| · |s2|).

Second, when calculating editDist(nd′.path, φ),

it is
possible to reuse intermediate results from a previous calcu-
lation of editDist(nd′.path, φ′) in proportion to the length
of the longest common preﬁx of φ and φ′. (Since Φn con-
tains only fragments beginning with the instruction to which
the program counter points in σn−1, their common preﬁx is
guaranteed to be of positive length.) To take maximum ad-
vantage of this opportunity to reuse previous calculations,
we organize the elements of Φn in a preﬁx tree (trie), in
which each internal node stores the intermediate results
that can be reused when calculating editDist(nd′.path, φ)
for the execution fragments Φn that share the preﬁx repre-
sented by the interior node. In a similar way, the calcula-
tion of editDist(nd′.path, φ) can reuse intermediate results
from the editDist(nd.path, φ) calculation, where nd′.path
extends nd.path. In this way, the vast majority of edit dis-
tance calculations are built by reusing intermediate results
from others.

Third, though the veriﬁcation algorithm as presented in
Figure 1 assembles each path π instruction-by-instruction
(lines 108–109), the paths nd′.path and fragments Φn are
not represented as strings of instructions for the purposes
of the edit distance calculation in line 105. If they were, it
would not be atypical for these strings to be of lengths in the
tens of thousands for some of the applications we consider
in Section 6, yielding expensive edit-distance calculations.
Instead, nd′.path and Φn are represented as strings of basic
block identiﬁers for the purposes of computing their edit
distance. In our evaluation, this representation resulted in
strings that were roughly an order of magnitude shorter than
if they had been represented as strings of instructions.

Judicious use of edit distance Despite the optimizations
just described, calculating edit distances incurs a degree of
overhead. As such, we have found that for highly interactive
applications, it is important to employ edit distance only
when Φn is likely to provide a useful guide in ﬁnding a π
with which to extend Πn−1 to obtain Πn.

For the applications with which we have experimented,
the primary case where using edit distance is counterpro-

ductive is when minφ∈Φn minφ′⊑φ editDist(nd′.path, φ′) is
large for every nd′ ∈ Live. Because nodes are explored in
increasing order of their edit distances from their nearest
preﬁxes of training fragments, this condition is an indica-
tion that the training fragments Φn are not a good predictor
of what happened in the client application leading up to the
send or receipt of msg n. This condition implies that verify
now has little useful information to guide its search and so
no search strategy is likely to be a clear winner, and thus
in this case we abandon the use of edit distance to avoid
calculating it. That is, we amend verify so that when

min

nd′∈Live

min
φ∈Φn

min
φ′⊑φ

editDist(nd′.path, φ′) > dmax

for a ﬁxed parameter dmax (dmax = 64 in our experiments
in Section 6), verify transitions to selecting nodes nd′ ∈
Live in increasing order of the number of symbolic variables
introduced on nd′.path. The rationale for this choice is that
it tends to prioritize those states that reﬂect fewer user inputs
and is very inexpensive to track.

Selecting nd In each iteration of the main while loop
104–124 of verify, the next node nd to extend is selected
as that in Live with a minimum “weight,” where its weight
is deﬁned by its edit distance to a preﬁx of an element of
Φn. Since the only operations on Live are inserting new
nodes into it (lines 117, 122) and extracting a node of min-
imum weight (line 105), Live is represented as a binary
min-heap. This enables both an insertion of a new element
and the removal of its min-weight element to complete in
O(log |Live|) time where |Live| denotes the number of el-
ements it contains when the operation is performed. This
(only) logarithmic cost is critical since Live can grow to be
quite large; e.g., in our tests described in Section 6, it was
not uncommon for Live to grow to tens of thousands of ele-
ments.

Memory management The veriﬁcation algorithm, upon
traversing a symbolic branch, creates new symbolic states to
represent the two possible outcomes of the branch (lines 115
and 120). Each state representation includes the program
counter, stack and address space contents. While KLEE [6]
(on which we build) provides copy-on-write semantics
for the address-space component, it does not provide for
garbage collection of allocated memory or a method to com-
pactly represent these states in memory. To manage the
considerable growth in memory usage during a long run-
ning veriﬁcation task, we utilize a caching system that se-
lectively frees in-memory representations of a state if neces-
sary. If at a later time a freed state representation is needed
(due to backtracking, for example), our system reconstructs
the state from a previously checkpointed state. This method
adds to the overall veriﬁcation time but reduces the extent
to which memory is a limiting factor.

5.3. Backtracking and Equivalent State Detection

As discussed at the start of Section 5, if verify(σ+

n−1,
msg n, Φn) returns ⊥ (line 125),
then it is not possi-
ble that the client legitimately executed Π+
n−1, producing
state σ+
n−1, and then sent/received msg n. If msg n−1 is a
client-to-server message (and so Π+
n−1 = Πn−1), veriﬁca-
tion must then backtrack into the computation verify(σ+
n−2,
msg n−1, Φn−1) to ﬁnd a different fragment to append to
n−2 to yield a new execution preﬁx ˆΠn−1 consistent with
Π+
msg 0, . . ., msg n−1 and resulting in state ˆσn−1. Once it
does so, it invokes verify(ˆσn−1, msg n, ˆΦn) to try again. To
support this backtracking, upon a successful return from
verify(σ+
n−2, msg n−1, Φn−1) in line 111, it is necessary
to save the existing algorithm state (i.e., its Live set and the
states of the nodes it contains) to enable it to be restarted
from where it left off. If msg n−1 is a server-to-client mes-
sage (and so Π+
n−1 6= Πn−1), then backtracking is per-
formed similarly, except the computation of verify(σ+
n−2,
msg n−1, Φn−1) is resumed only after all possible exten-
sions ˆΠ+
n−1 of Πn−1 have been exhausted, i.e., each corre-
sponding verify(ˆσ+

n−1, msg n, ˆΦn) has failed.

The most signiﬁcant performance optimization that we
have implemented for backtracking is a method to detect
the equivalence of some symbolic states, i.e., for which ex-
ecution from these states (on the same inputs) will behave
identically. If the states σn−1 and ˆσn−1 are equivalent and if
a valid client could not send msg n after reaching σn−1, then
equivalently it could not send msg n after reaching ˆσn−1.
So, for example, if ˆσn−1 was reached due to backtracking
after verify(σn−1, msg n, Φn) failed, then the new execu-
tion preﬁx ˆΠn−1 that produces ˆσn−1 should be abandoned
immediately and backtracking should resume again.

The difﬁculty in establishing the equivalence of σn−1
and ˆσn−1, if they are in fact equivalent, is that they may
not be syntactically equal. This lack of equality arises from
at least two factors. The ﬁrst is that in our present imple-
mentation, the address spaces of the states σn−1 and ˆσn−1
are not the same, but rather are disjoint ranges of the virtual
address space of the veriﬁer. Maintaining disjoint address
spaces for symbolic states is useful to enable their addresses
to be passed to external calls (e.g., system calls) during sym-
bolic execution. It also requires us to assume that the client
program execution is invariant to the range from which its
addresses are drawn, but we believe this property is true
of the vast majority of well-behaved client applications (in-
cluding the ones we use in our evaluation).

A second factor that may cause σn−1 and ˆσn−1 to be
syntactically distinct while still being equivalent is that
the different execution preﬁxes Πn−1 and ˆΠn−1 leading
to these states may induce differences in their pointer val-
ues. Consider, for example, the trivial C function in Fig-

ure 2, which reads an input character and then branches
based on its value; in one branch, it allocates *buf1 and
then *buf2, and in the other branch, it allocates *buf2
and then *buf1. Even if the address spaces of different
states occupied the same ranges, and even if the memory
allocator assigned memory deterministically (as a function
of the order and size of the allocations), the addresses of
buf1 and buf2 would be different in states that differ only
because they explored different directions of the symbolic
branch if (c == ’x’). These states would neverthe-
less be equivalent, assuming that the client application be-
havior is invariant to its state’s pointer values (again, a rea-
sonable assumption for well-behaved applications).

void foo(char **buf1, char **buf2) {

char c;
c = getchar();
if (c == ’x’) {

*buf1 = (char *) malloc(10);
*buf2 = (char *) malloc(10);

} else {

*buf2 = (char *) malloc(10);
*buf1 = (char *) malloc(10);

}

}

Figure 2. Toy example that may induce differ(cid:173)
ent pointer values for variables in otherwise
equivalent states

To detect equivalent states σn−1 and ˆσn−1 that are syn-
tactically unequal due to the above causes, we built a proce-
dure to walk the memory of two states in tandem. The mem-
ory of each is traversed in lock-step and in a canonical order,
starting from each concrete pointer in its global variables
(including the stack pointer) and following each concrete
pointer to the memory to which it points. (Pointers are rec-
ognized by their usage.) Concrete, non-pointer values tra-
versed simultaneously are compared for equality; unequal
values cause the traversal to terminate with an indication
that the states are not equivalent.4 Similarly, structural dif-
ferences in simultaneously traversed memory regions (e.g.,
regions of different sizes, or a concrete value in one where a
symbolic value is in the other) terminate the traversal. Sym-
bolic memory locations encountered at the same point in the
traversal of each state are given a common name, and this
common name is propagated to any constraints that involve
that location. Finally, equivalence of these constraints is
determined by using a constraint solver to determine if each
implies the other. If so, the states are declared equivalent.

4The state could still be equivalent if the differing concrete values do
not inﬂuence execution, but our method does not detect the states as equiv-
alent in this case.

5.4. Conﬁgurations

Thus far, we have not speciﬁed how Φn is populated
from the set Φ of medoids resulting from clustering the exe-
cution fragments witnessed during training (Section 4). We
consider two possibilities for populating Φn in this paper.

Default conﬁguration The default algorithm conﬁgura-
tion constructs Φn from the contents of msg n. If the closest
training message is at distance m from msg n, for a mea-
sure of distance described below, then the algorithm com-
putes the set M α
n of training messages less than distance
αm from msg n, for a ﬁxed parameter α ≥ 1. (In Section 6,
we use α = 1.25.) An execution fragment φ is eligible to
be included in Φn if (i) φ is the medoid of some cluster for
which there is an indicator message msg ∈ M α
n , and (ii)
φ begins at the instruction to which the program counter
in σ+
n−1 is the symbolic state that will
be passed to verify along with msg n and Φn. Then, Φn is
set to include all eligible fragments up to a limit β; if there
are more than β eligible fragments, then Φn consists of an
arbitrary subset of size β. (In Section 6, we use β = 8.)

n−1 points, where σ+

The distance measure between messages that we use in
our evaluation in Section 6 is simply byte edit distance be-
tween messages of the same directionality (i.e., between
server-to-client messages or between client-to-server mes-
sages). If msg and msg n do not have the same direction-
ality, then we deﬁne their distance to be ∞, so that only
training messages of the same directionality as msg n are
included in M α
n .

Hint conﬁguration The “hint” conﬁguration requires that
the client software has been adapted to work with the ver-
iﬁer to facilitate its veriﬁcation. In this conﬁguration, the
client piggybacks a hint on msg n that is a direct indica-
tion of the execution fragment it executed prior to sending
msg n. This extra hint, however, increases the bandwidth
utilized by client-to-server messages, and so it is important
that we minimize this cost.

Speciﬁcally, in this conﬁguration, the client software has
knowledge of the clustering used by the veriﬁer, as de-
scribed in Section 4.2. (For example, the server sends it this
information when the client connects.) The client records
its own execution path and, when sending a client-to-server
message msg n, maps its immediately preceding execution
fragment to its closest cluster in the veriﬁer’s clustering (us-
ing edit distance on execution fragments). The client then
includes the index of this cluster within msg n as a “hint” to
the veriﬁer. The server extracts the cluster index from msg n
and provides this to the veriﬁer.

Intuitively, the medoid φ of the indicated cluster should
be used as the sole element of the set Φn, but only if φ be-
gins at the instruction pointed to by the program counter of

the symbolic state σ+
n−1 to be provided to verify as input.5
For the applications we evaluate in Section 6, however, we
adapt this idea slightly and interpret this cluster index within
the set of all clusters whose fragments begin at that instruc-
tion and end at a SEND. Then, Φn is set to contain only
the medoid of this cluster. (If the cluster index exceeds the
number of clusters whose fragments begin at that instruc-
tion, or if msg n is a server-to-client message, then the de-
fault approach above is used to create Φn, instead.) In this
way, the cluster hint can be conveyed in exactly ⌈log2 k⌉
extra bits on each client-to-server message, where k is the
number of clusters allowed by the veriﬁer in its third level
of clustering (see Section 4.2). While sending a hint does
increase bandwidth cost, it does so minimally; e.g., in Sec-
tion 6, we consider k = 256 (1 byte per client-to-server
message) and k ≤ 65536 (2 bytes per client-to-server mes-
sage).

Despite the fact that the client sends the hint to the server,
the client remains completely untrusted in this conﬁgura-
tion. The hint it provides is simply to accelerate veriﬁcation
of a legitimate client, and providing an incorrect hint does
not substantially impact the veriﬁer’s cost for declaring the
client compromised.

6. Evaluation

To evaluate our technique, we built a prototype that uses
the KLEE [6] symbolic execution engine as a foundation.
Our implementation includes approximately 1000 modiﬁed
source lines of code (SLOC) in KLEE and additional 10,000
SLOC in C++. That said, at present we have not com-
pleted the client-side implementation of the hint conﬁgu-
ration described in Section 5.4, and so we instead simulate
the client-side hint in our evaluation here. We stress, there-
fore, that while we accurately measure the veriﬁer’s perfor-
mance in both the default and hint conﬁgurations, the addi-
tional client overheads implied by the hint conﬁguration are
not reported here. The experiments described in this sec-
tion were performed on a system with 24GB of RAM and a
2.93GHz processor (Intel X5670).

We limit our evaluation to the veriﬁer’s performance, for
two reasons. First, performance is the dimension on which
our algorithm offers a contribution over the most closely
related previous research [2]. Second, by design, our ver-
iﬁcation algorithm has no false positives — i.e., if a mes-
sage trace is declared to be inconsistent with the sanctioned
client software, then it really is (though this is subject to an
assumption discussed in Section 5.3). Similarly, the only

5An alternative is for the veriﬁer to backtrack immediately if φ begins
at a different instruction, since in that case, σ+
n−1 is apparently not repre-
sentative of the client’s state when it executed the fragment leading up to
it sending msg n. For the applications we evaluate in Section 6, however,
backtracking usually incurred more veriﬁcation cost even in this case.

source of false negatives arises from the limited ﬁdelity of
the constraints used to model values returned by compo-
nents with which the client software interacts (e.g., the OS).
We could improve that ﬁdelity by subjecting these compo-
nents to symbolic execution, as well, but here we limit sym-
bolic execution to the client software proper.

To evaluate performance, we apply our algorithm to ver-
ify behavior of legitimate clients of two open-source games,
namely XPilot and TetriNET (described in Section 6.1). We
limit our attention to legitimate clients since this is the case
in which we make a contribution; i.e., our approach is de-
signed to validate legal behavior more quickly than previ-
ous work, but conﬁrms illegal behavior in time comparable
to what previous work [2] would achieve. We employ these
games for our evaluation for numerous reasons:
they are
complex and so pose challenging test cases for our tech-
nique; they are open-source (and our tools require access to
source code); and games is a domain that warrants behav-
ior veriﬁcation due to the invalid-command cheats to which
they are often subjected [30].

6.1. Applications

XPilot XPilot is an open-source, multi-player, client-
server game that has been developed in many revisions over
more than 15 years including, e.g., a version for the iPhone
that was released in July 2009. The version we used in our
evaluation is XPilot NG (XPilot Next Generation) version
4.7.2. Its client consists of roughly 100,000 SLOC. Beyond
this, the scope of symbolic execution included all needed
libraries except Xlib, whose functions were replaced with
minimal stubs, so that the game could be run without dis-
play output. Moreover, uClibc was used in lieu of the
GNU C library.

In the game, the user causes her spaceship to navigate a
two-dimensional world occupied by obstacles, objects such
as power-ups that the user can collect by navigating her
spaceship over them, and both ﬁxed and mobile hostiles
that can ﬁre on her ship (some of which are ships controlled
by other players). Each player’s goal is to earn the high-
est score. Despite its “2D” graphics, the game incorporates
sophisticated physics simulation; e.g., ships with more fuel
have greater mass and thus greater inertia.

Upon startup, the XPilot client reads local ﬁles that, e.g.,
deﬁne the world map. (Our evaluation assumes that these
initialization ﬁles are available to the veriﬁer, as they must
be to the server, as well.) The XPilot client then enters an
event loop that receives user input and server messages, pro-
cesses them (including rendering suitable changes on the
client’s display), and sends an update to the server. These
updates can include information about the current status
of the user’s ship’s shields (whether they are up or down),
weapons (whether any are ﬁring), position, orientation, ac-

celeration, etc. Various limitations imposed by the client,
such as that a client cannot both have its shields up and
be ﬁring at the same time, are obvious targets for a user
to override by modifying the game client in order to cheat.
Our behavior veriﬁcation technique will detect such game
cheats automatically.

The previous work by Bethea et al. that leveraged XPi-
lot to evaluate its techniques found it necessary to modify
the XPilot client in various small ways to make its analy-
sis tractable (see [2, Section 5.2]). We used this modiﬁed
version in our evaluations, as well, though to illustrate cer-
tain improvements enabled by our technique, we reverted
an important modiﬁcation made there. Speciﬁcally, Bethea
et al. inserted bounds to limit the number of user inputs that
would be processed in any given event-loop round, since
otherwise the event loop could theoretically process an un-
bounded number of such inputs. This unboundedness, in
turn, caused symbolic execution to explore arbitrary num-
bers of corresponding input-processing loop iterations. By
inserting bounds, Bethea et al. rectiﬁed this problem but
introduced a potential source of false positives, if the de-
ployed client software is not modiﬁed in the same way. In
our evaluation, we removed these inserted limits so as to
eliminate this risk of false positives and also to highlight
the power of training our veriﬁer on previous executions.
After removing these limits, these input-processing loops
could theoretically iterate an arbitrary number of times, but
nevertheless our veriﬁer does not explore paths including
increasingly large numbers of such iterations until it is done
exploring paths with numbers of iterations similar to those
encountered in the training runs. Aside from highlighting
the strength of our technique, removing these bounds ren-
ders the Bethea et al. approach to veriﬁcation intractable.

TetriNET TetriNET is a multi-player version of the popu-
lar single-player Tetris game. In the Tetris game, one player
controls a rectangular gameboard of squares, at the top of
which a tetromino appears and starts to “fall” toward the
bottom at a constant rate. Each tetromino is of a size to oc-
cupy four connected grid squares orthogonally and has one
of seven shapes. The tetromino retains its shape and size as
it falls, but the user can reorient the tetromino as it falls by
pressing keys to rotate it. The user can also move the tetro-
mino to the left or right by pressing other keys. Once the
tetromino lands on top of another tetromino or the bottom
of the grid, it can no longer be moved or rotated. At that
point, another tetromino appears at the top of the grid and
begins to fall. Whenever a full row of the gameboard is oc-
cupied by tetrominos, the row disappears (potentially frac-
turing any tetrominos occupying a portion of it) and all rows
above the removed row are shifted downward. TetriNET dif-
fers from Tetris by adding an empty row to all other players’
grids when this occurs. The goal of the game is for a player

to place as many tetrominos as possible before no more can
enter her gameboard, and a player wins the multiplayer ver-
sion by playing longer than other players.

The TetriNET client is structured as an event loop that
processes user inputs and advances each tetromino in its fall
down the gameboard. Only once a tetromino has landed
in its resting place does the game client inform the server
of the location of the tetromino and whether its placement
caused any rows to be deleted (and if so, which ones). The
server does not validate the client’s claim that the condition
for deleting the row was met (i.e., that the row was full), and
so the game is very vulnerable to invalid-command cheats.
Again, our technique will automatically detect such cheats.
The TetriNET client version (0.11) that we used in our
evaluation is 5000 SLOC. As in XPilot, the scope of sym-
bolic execution also included all needed libraries, though
again the display output library (ncurses) was disabled
using minimal stub functions and uClibc was used in
place of the GNU C library. Despite its small size, a sin-
gle event-loop iteration in the TetriNET client permits an
unbounded number of user inputs to rotate or horizontally
shift the tetromino, which presents problems for symbolic
execution analogous to those that led Bethea et al. to cap the
number of inputs in a single XPilot event-loop iteration. As
such, in their experimentation with TetriNET, Bethea et al.
limited gameplay so that a tetromino could be placed only
at a location for which only empty squares were above it,
so as to limit the number of user inputs needed for a tetro-
mino placement to half the width of the gameboard plus the
number of possible tetromino rotations — nine user inputs
in total [2]. We emphasize that none of these restrictions
are employed in our evaluation, and again the ability of our
algorithm to verify the behavior of a TetriNET client in its
unconstrained form illustrates its strengths.

6.2. Results

Evaluation of our veriﬁcation algorithm requires traces
of gameplay for both training and testing. For TetriNET, we
generated 20 traces of manual gameplay, each of 240 mes-
sages in length (which corresponds to roughly 6.5 minutes
of gameplay). For XPilot, we generated 40 traces of man-
ual gameplay, each consisting of 2100 messages (roughly
70 seconds of gameplay).

TetriNET Figure 3 shows TetriNET veriﬁcation costs.
Figure 3 includes plots for both the default and hint conﬁg-
urations, as well as for clustering parameter values k = 256
and k = 3790; the latter case ensured a single execution
fragment per cluster.

The numbers represented in Figure 3 were obtained by
a 20-fold cross validation of the TetriNET traces; i.e., in
each test, one of the traces was selected for testing, and

the remainder were used for training. Speciﬁcally, Fig-
ure 3 shows the distribution of veriﬁcation time per mes-
sage, binned into ten-message bins, across all 20 traces. So,
for example, the boxplot labeled “0” shows the distribution
of veriﬁcation times for messages msg 0, . . . , msg 9 in the
20 traces. The data point for message msg n accounts for all
time spent in verify(σ+
n−1, msg n, Φn) and any immediately
preceding preprocessing step (see Section 5.1), including
any backtracking into those functions that occur. (That said,
backtracking in TetriNET is very rare.)
In each boxplot,
the “box” shows the ﬁrst, second (median) and third quar-
tiles, and its whiskers extend to ±1.5 times the interquar-
tile range. Additional outlier points are shown as bullets.
Overlaid on each boxplot is a diamond (✸) that shows the
average of the data points.

Several things are worth noting about Figure 3. In all
cases, the distribution of veriﬁcation times is largely un-
affected by the message index, i.e., where in the trace the
message appears. This conﬁrms that our implementation
is mostly free from sources of increasing veriﬁcation ex-
pense as traces grow longer. This ﬁgure also conﬁrms that
more ﬁne-grained clustering (k = 3790) leads to faster ver-
iﬁcation times than coarse grained (k = 256). Fine-grain
clustering, however, results in greater bandwidth use in the
hint conﬁguration; k = 3790 implies an overhead of 12 bits
or, if sent as two bytes, an average of 17% bandwidth in-
crease per client-to-server message, in contrast to only 9%
per client-to-server message for k = 256. Not surprisingly,
the hint conﬁguration generally outperforms the default.

Figure 3 also suggests that our algorithm is, for the large
majority of messages, fast enough to verify valid TetriNET
gameplay at a pace faster than the game itself: the average
veriﬁcation cost per message, regardless of conﬁguration or
clustering granularity, is easily beneath the inter-message
delay of roughly 1.6s. That said, there are two issues that
require further exploration. First, there are messages that
induce veriﬁcation times in excess of 10s or even 100s,
which unfortunately makes it impossible to reliably keep
pace with gameplay. Nevertheless, as an optimization over
previous work for verifying message traces, and as a data
reduction technique to eliminate some traces (or portions
thereof) from the need to log and analyze ofﬂine, our tech-
nique still holds considerable promise. Second, and work-
ing in favor of this promise, is the slack time between the
arrival of messages that gives veriﬁcation the opportunity to
catch up to the pace of gameplay after a particularly difﬁcult
message veriﬁcation.

To shed light on these issues, Figure 4 instead plots the
distributions of per-message veriﬁcation delay between the
arrival of message msg n at the server (where a server-to-
client message “arrives” when it is sent) and the discovery
of an execution preﬁx Πn that is consistent with msg 0, . . .,
msg n. Delay (Figure 4) differs from veriﬁcation time (Fig-

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

10−3

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

10−3

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

10−3

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

10−3

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(a) Default, k = 256

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(b) Hint, k = 256

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(c) Default, k = 3790

)
s
(
 
y
a
e
D

l

500

400

300

200

100

0

)
s
(
 
y
a
e
D

l

500

400

300

200

100

0

)
s
(
 
y
a
e
D

l

500

400

300

200

100

0

)
s
(
 
y
a
e
D

l

500

400

300

200

100

0

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(a) Default, k = 256

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(b) Hint, k = 256

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(c) Default, k = 3790

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

0

1 0

2 0

3 0

4 0

5 0

6 0

7 0

8 0

9 0

1 2 0

1 1 0

1 0 0

1 3 0
Message Bin

1 4 0

1 5 0

1 6 0

1 7 0

1 8 0

1 9 0

2 0 0

2 1 0

2 2 0

2 3 0

(d) Hint, k = 3790

(d) Hint, k = 3790

Figure 3. TetriNET veriﬁcation times. Cross(cid:173)
validation over 20 traces. Boxplot at x shows
veriﬁcation times for messages msg x,
. . .,
msg x+9 in each trace (after training on the
other traces). “✸” shows the average.

Figure 4. TetriNET veriﬁcation delays. Cross(cid:173)
validation over 20 traces. Boxplot at x shows
veriﬁcation delays for messages msg x,
. . .,
msg x+9 in each trace (after training on the
other traces). “✸” shows the average.

ure 3) by representing the fact that veriﬁcation for msg n
cannot begin until after that for msg n−1 completes. So,
for example, the rightmost boxplot in each graph provides

insight into how long after the completion of the message
trace (in real time) that it took for veriﬁcation for the whole
trace to complete.

i

e
m
T
n
o

 

i
t

a
c
i
f
i
r
e
V

100%

50%

0%

Constraint Solving

Equiv. State Detection

Computing Edit Distance

Operations on Live

Executing insts. in KLEE

Tetrinet
Default

Tetrinet

Hint

XPilot
Default

Xpilot
Hint

Figure 5. Percentage of time spent in each
component of our algorithm.

One item to note about these graphs is that for the hint
conﬁguration with k = 3790 (Figure 4(d)), the median of
the rightmost boxplot is virtually zero — i.e., the most com-
mon case is that veriﬁcation kept pace with gameplay. This
can occur even if veriﬁcation falls behind at some point in
the game, since veriﬁcation commonly “catches up” after
falling behind. This is illustrated, for example, in the gen-
erally downward slope of consecutive outlier points in Fig-
ure 4(d). That said, the cumulative effect of veriﬁcation de-
lays in the other conﬁgurations is more costly, e.g., causing
veriﬁcation to lag behind gameplay by more than 100 sec-
onds by the end of a 240-message trace in the median case
in the default conﬁguration (Figure 4(c)).

A breakdown of veriﬁcation costs for TetriNET is shown
in Figure 5. In our TetriNET experiments, more than 50%
of the veriﬁcation time is spent in KLEE, interpreting client
instructions. Therefore, optimizations that interpret instruc-
tions only selectively (e.g., [8]) may be a signiﬁcant opti-
mization for our tool. The majority of the remaining time
is spent in insertions and deletions on Live and in comput-
ing edit distance, both to update the edit distance for each
path when a symbolic branch is reached and to compute dis-
tances between messages. A very small fraction of time in
our TetriNET experiments is devoted to equivalent state de-
tection (Section 5.3) or in constraint solving. In Figure 5,
constraint solving includes not only the time spent by STP
(the default solver used by KLEE), but also preprocessing
techniques to make queries to STP more efﬁcient (borrowed
from Bethea et al. [2, Section 4.4]) and a canonicalization
step (borrowed from Visser et al. [26]) to improve the hit
rate on cached results for previous queries to STP. These op-
timizations signiﬁcantly reduce the overall constraint solv-
ing time.

XPilot XPilot poses a signiﬁcant challenge for veriﬁca-
tion because its pace is so fast. The tests described here
use an XPilot conﬁguration that resulted in an average of 32
messages per second. The veriﬁcation times per message

vary somewhat less for XPilot than they did for TetriNET,
as shown in Figure 6. Recall that each boxplot in Figure 6
represents 100 × 40 points, versus only 10 × 20 in Figure 3.
As such, though there are larger numbers of outliers in Fig-
ure 6, they constitute a smaller fraction of the data points.

The median per-message veriﬁcation cost of XPilot when
clustering is ﬁne-grained (k = 475, which implied a sin-
gle execution fragment per cluster) is quite comparable to
that in TetriNET, as can be seen by comparing Figure 6(c)
and Figure 6(d) to Figure 3(c) and Figure 3(d), respectively.
However, XPilot veriﬁcation is considerably faster with
coarse clustering, see Figure 6(a) versus Figure 3(a) and
Figure 6(b) versus Figure 3(b). Our deﬁnition of k = 256 as
“coarse” clustering was dictated by the goal of limiting the
bandwidth overhead to one byte per client-to-server mes-
sage in the hint conﬁguration. The better performance of
XPilot veriﬁcation for coarse clustering versus TetriNET is
at least partly because k = 256 is closer to ﬁne cluster-
ing (k = 475) in the case of XPilot than it is for TetriNET
(k = 3790). In the hint conﬁguration, k = 256 increases
bandwidth use by XPilot client-to-server messages by 2%,
and k = 475 (9 bits, sent in two bytes) increases it by 4%.
Though the median per-message veriﬁcation cost of XPi-
lot is generally as good or better than that for TetriNET, the
faster pace of XPilot makes it much more difﬁcult for veri-
ﬁcation to keep pace with the game. This effect is shown in
Figure 7. As shown in this ﬁgure, none of the conﬁgurations
or clustering granularities permitted veriﬁcation to keep up
with gameplay, and the best default conﬁguration (k = 475)
included one run that required 8 minutes past the end of the
trace to complete its veriﬁcation (see Figure 7(c)). Conse-
quently, for an application as fast-paced and as complex as
XPilot, our algorithm does not eliminate the need to save
traces for post hoc analysis.

Nevertheless, we stress that our algorithm accomplishes
— even if with some delay — what is for the most closely
related previous work [2] completely intractable. That is,
recall that Bethea et al. utilized a restricted version of XPi-
lot in which the number of user inputs per event loop iter-
ation was artiﬁcially limited; we have removed that limita-
tion here (see Section 6.1). With these restrictions removed,
the Bethea et al. approach is inherently unbounded for veri-
fying some messages, since it seeks to eagerly ﬁnd all paths
that could explain that message, of which there could be
inﬁnitely many. Our approach, in contrast, succeeds in ver-
ifying all messages in these logs in bounded time and with
per-message cost averaging under 100ms in all conﬁgura-
tions (Figure 6).

A fractional breakdown of veriﬁcation times for XPi-
lot are shown in Figure 5. While a majority of the cost
is still contributed by interpreting client instructions in
KLEE, the majority is smaller in the case of XPilot than
it was for TetriNET. For XPilot, equivalent state detection

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

(a) Default, k = 256

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

(b) Hint, k = 256

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

(c) Default, k = 475

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

)
s
(
 
e
m
T

i

102

101

100

10−1

10−2

)
s
(
 
y
a
e
D

l

800

640

480

320

160

0

)
s
(
 
y
a
e
D

l

800

640

480

320

160

0

)
s
(
 
y
a
e
D

l

800

640

480

320

160

0

)
s
(
 
y
a
e
D

l

800

640

480

320

160

0

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

(a) Default, k = 256

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

(b) Hint, k = 256

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

(c) Default, k = 475

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

0

1 0 0

2 0 0

3 0 0

4 0 0

5 0 0

6 0 0

7 0 0

8 0 0

9 0 0

1 0 0 0

1 2 0 0
1 1 0 0
Message Bin

1 3 0 0

1 4 0 0

1 5 0 0

1 6 0 0

1 7 0 0

1 8 0 0

1 9 0 0

2 0 0 0

(d) Hint, k = 475

(d) Hint, k = 475

Figure 6. XPilot veriﬁcation times. Cross(cid:173)
validation over 40 traces. Boxplot at x shows
veriﬁcation times for messages msg x,
. . .,
msg x+99 in each trace (after training on the
other traces). “✸” shows the average.

Figure 7. XPilot veriﬁcation delays. Cross(cid:173)
validation over 40 traces. Boxplot at x shows
veriﬁcation delays for messages msg x,
. . .,
msg x+99 in each trace (after training on the
other traces). “✸” shows the average.

(Section 5.3) plays a more prominent role than it did for
TetriNET, in part due to XPilot’s more complex memory
structure. Moreover, due to the substantially more complex

constraints generated by XPilot, constraint solving plays a
much more prominent role than it did for TetriNET.

7. Conclusion

In this paper we have presented a novel algorithm to en-
able a server to verify that the behavior of a client in a
client-server application is consistent with the sanctioned
client software. The central challenge that must be over-
come in achieving this goal is that the server does not know
all of the inputs to the client (e.g., user inputs) that induced
its behavior, and in some domains (see [19]) the additional
bandwidth utilized by sending those inputs to the server is
undesirable. We therefore developed a technique by which
the veriﬁer “solves” for whether there exist user inputs that
could explain the client behavior. We overcome the scaling
challenges of this approach by leveraging execution history
to guide a search for paths through the client program that
could produce the messages received by the server. This
approach enables us to achieve dramatic cost savings in the
common case of a legitimate client, and by allowing mini-
mal additional bandwidth use, we can improve performance
even further.
In the best conﬁguration of our algorithm,
veriﬁcation of legitimate TetriNET gameplay often keeps
pace with the game itself. In other cases, veriﬁcation ef-
ﬁciency is adequate to practically handle client applications
that previous work was forced to restrict to make its analy-
sis tractable. We believe that the manner in which we lever-
age execution history can be useful in other applications of
symbolic execution, as well.

Acknowledgements This work was supported in part by
NSF grants 0910483 and 1115948 and by a gift from Intel.
We are grateful to Darrell Bethea for comments on a draft
of this paper.

References

[1] S. Anand, P. Godefroid, and N. Tillmann. Demand-driven
compositional symbolic execution. In Tools and Algorithms
for the Construction and Analysis of Systems, 14th Inter-
national Conference, TACAS 2008, volume 4963 of Lecture
Notes in Computer Science, pages 367–381. Mar. 2008.

[2] D. Bethea, R. A. Cochran, and M. K. Reiter. Server-side ver-
iﬁcation of client behavior in online games. ACM Transac-
tions on Information and System Security, 14(4), Dec. 2011.
[3] R. S. Boyer, B. Elspas, and K. N. Levitt. SELECT – a formal
system for testing and debugging programs by symbolic ex-
ecution. In International Conference on Reliable Software,
pages 234–245, 1975.

[4] D. Brumley, J. Newsome, D. Song, H. Wang, and S. Jha.
Towards automatic generation of vulnerability-based signa-
tures.
In IEEE Symposium on Security and Privacy, May
2006.

[5] J. Caballero, Z. Liang, P. Poosankam, and D. Song. To-
wards generating high coverage vulnerability-based signa-
tures with protocol-level constraint-guided exploration.
In

Recent Advances in Intrusion Detection, 12th International
Symposium, RAID 2009, volume 5758 of Lecture Notes in
Computer Science, pages 161–181. 2009.

[6] C. Cadar, D. Dunbar, and D. Engler. KLEE: Unassisted
and automatic generation of high-coverage tests for complex
systems programs. In 8th USENIX Symposium on Operating
Systems Design and Implementation, Dec. 2008.

[7] C. Cadar, V. Ganesh, P. M. Pawlowski, D. L. Dill, and D. R.
Engler. EXE: Automatically generating inputs of death. In
13th ACM Conference on Computer and Communications
Security, Nov. 2006.

[8] V. Chipounov, V. Kuznetsov, and G. Candea. S2E: a plat-
form for in-vivo multi-path analysis of software systems.
In 16th International Conference on Architectural Support
for Programming Languages and Operating Systems, pages
265–278, 2011.

[9] S. Chong, J. Liu, A. C. Myers, X. Qi, N. Vikram, L. Zheng,
and X. Zheng. Secure web applications via automatic par-
titioning.
In 21st ACM Symposium on Operating Systems
Principles, pages 31–44, Oct. 2007.

[10] M. DeLap, B. Knutsson, H. Lu, O. Sokolsky, U. Sammapun,
I. Lee, and C. Tsarouchis. Is runtime veriﬁcation applicable
to cheat detection? In 3rd ACM SIGCOMM Workshop on
Network and System Support for Games, Aug. 2004.

[11] W. Feng, E. Kaiser, and T. Schluessler. Stealth measure-
ments for cheat detection in on-line games.
In 7th ACM
Workshop on Network and System Support for Games, pages
15–20, Oct. 2008.

[12] J. T. Gifﬁn, S. Jha, and B. P. Miller. Detecting manipulated
remote call streams. In 11th USENIX Security Symposium,
Aug. 2002.

[13] P. Godefroid, N. Klarlund, and K. Sen. DART: Directed
automated random testing.
In 2005 ACM Conference on
Programming Language Design and Implementation, pages
213–223, June 2005.

[14] A. Guha, S. Krishnamurthi, and T. Jim. Using static analysis
In 18th International World

for Ajax intrusion detection.
Wide Web Conference, pages 561–570, Apr. 2009.

[15] G. Hoglund and G. McGraw. Exploiting Online Games:
Cheating Massively Distributed Systems. Addison-Wesley
Professional, 2007.

[16] E. Kaiser, W. Feng, and T. Schluessler. Fides: Remote
In
anomaly-based cheat detection using client emulation.
16th ACM Conference on Computer and Communications
Security, Nov. 2009.

[17] Y. Lyhyaoui, A. Lyhyaoui, and S. Natkin. Online games:
In International Conference on

Categorization of attacks.
Computer as a Tool (EUROCON), Nov. 2005.

[18] C. M¨onch, G. Grimen, and R. Midtstraum. Protecting online
games against cheating. In 5th ACM Workshop on Network
and System Support for Games, Oct. 2006.

[19] J. Mulligan and B. Patrovsky. Developing Online Games:

An Insider’s Guide. New Riders Publishing, 2003.

[20] T. Schluessler, S. Goglin, and E. Johnson.

Is a bot at the
controls? Detecting input data attacks. In 6th ACM Work-
shop on Network and System Support for Games, pages 1–6,
Sept. 2007.

[21] K. Sen, D. Marinov, and G. Agha. CUTE: a concolic unit
testing engine for C. SIGSOFT Software Engineering Notes,
30:263–272, Sept. 2005.

[22] K. Tan, J. McHugh, and K. Killourhy. Hiding intrusions:
From the abnormal to the normal and beyond. In Informa-
tion Hiding, 5th International Workshop, IH 2002, pages 1–
17, 2003.

[23] N. Tillmann and J. D. Halleux. Pex: White box test genera-
tion for .NET. In 2nd International Conference on Tests and
Proofs, pages 134–153, 2008.

[24] E. Ukkonen. Algorithms for approximate string matching.

Information and Control, 64(1–3), Mar. 1985.

[25] K. Vikram, A. Prateek, and B. Livshits. Ripley: Automati-
cally securing Web 2.0 applications through replicated exe-
cution. In 16th ACM Conference on Computer and Commu-
nications Security, Nov. 2009.

[26] W. Visser, J. Geldenhuys, and M. B. Dwyer. Green: reduc-
ing, reusing and recycling constraints in program analysis.
In 20th ACM International Symposium on the Foundations
of Software Engineering, FSE, pages 58:1–11, 2012.

[27] W. Visser, C. S. P˘as˘areanu, and S. Khurshid. Test input gen-
eration with Java PathFinder. SIGSOFT Software Engineer-
ing Notes, 29:97–107, July 2004.

[28] D. Wagner and P. Soto. Mimicry attacks on host-based in-
trusion detection systems. In 9th ACM Conference on Com-
puter and Communications Security, Nov. 2002.

[29] M. Ward. Warcraft game maker in spying row, Oct. 2005.

http://news.bbc.co.uk/2/hi/technology/
4385050.stm.

[30] S. Webb and S. Soh. A survey on network game cheats and
P2P solutions. Australian Journal of Intelligent Information
Processing Systems, 9(4):34–43, 2008.

[31] J. Yan and B. Randell. A systematic classiﬁcation of cheat-
ing in online games. In 4th ACM Workshop on Network and
System Support for Games, Oct. 2005.

[32] J. Yang, C. Sar, P. Twohey, C. Cadar, and D. Engler. Au-
tomatically generating malicious disks using symbolic exe-
cution. In IEEE Symposium on Security and Privacy, May
2006.

[33] D. Yuan, H. Mai, W. Xiong, L. Tan, Y. Zhou, and S. Pasu-
pathy. SherLog: Error diagnosis by connecting clues from
run-time logs. In 15th International Conference on Architec-
tural Support for Programming Languages and Operating
Systems, pages 143–154, Mar. 2010.

[34] C. Zamﬁr and G. Candea. Execution synthesis: a technique
for automated software debugging. In 5th European Confer-
ence on Computer Systems, pages 321–334, Apr. 2010.

