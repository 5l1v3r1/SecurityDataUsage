Measuring PUP Prevalence and PUP Distribution 

through Pay-Per-Install Services

Platon Kotzias, IMDEA Software Institute and Universidad Politécnica de Madrid;  
Leyla Bilge, Symantec Research Labs; Juan Caballero, IMDEA Software Institute
 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/kotzias

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Measuring PUP Prevalence and PUP Distribution through

Pay-Per-Install Services

Platon Kotzias

IMDEA Software Institute &
Universidad Polit´ecnica de

Madrid, Spain

platon.kotzias@imdea.org

Leyla Bilge

Symantec Research Labs
Soﬁa Antipolis, France

leyla bilge@symantec.com

Juan Caballero

IMDEA Software Institute

Madrid, Spain

juan.caballero@imdea.org

Abstract

Potentially unwanted programs (PUP) such as adware
and rogueware, while not outright malicious, exhibit
intrusive behavior that generates user complaints and
makes security vendors flag them as undesirable. PUP
has been little studied in the research literature despite
recent indications that its prevalence may have surpassed
that of malware.

In this work we perform the first systematic study
of PUP prevalence and its distribution through pay-per-
install (PPI) services, which link advertisers that want to
promote their programs with affiliate publishers willing
to bundle their programs with offers for other software.
Using AV telemetry information comprising of 8 billion
events on 3.9 million real hosts during a 19 month period,
we discover that over half (54%) of the examined hosts
have PUP installed. PUP publishers are highly popular,
e.g., the top two PUP publishers rank 15 and 24 amongst
all software publishers (benign and PUP). Furthermore,
we analyze the who-installs-who relationships, finding
that 65% of PUP downloads are performed by other PUP
and that 24 PPI services distribute over a quarter of all
PUP. We also examine the top advertiser programs dis-
tributed by the PPI services, observing that they are dom-
inated by adware running in the browser (e.g., toolbars,
extensions) and rogueware. Finally, we investigate the
PUP-malware relationships in the form of malware in-
stallations by PUP and PUP installations by malware.
We conclude that while such events exist, PUP distribu-
tion is largely disjoint from malware distribution.

1

Introduction

Potentially unwanted programs (PUP) are a category
of undesirable software that includes adware and rogue

software (i.e., rogueware). While not outright malicious
(i.e., malware), PUP behaviors include intrusive adver-
tising such as ad-injection, ad-replacement, pop-ups, and
pop-unders; bundling programs users want with unde-
sirable programs; tracking users’ Internet surfing; and
pushing the user to buy licenses for rogueware of du-
bious value, e.g., registry optimizers. Such undesirable
behaviors prompt user complaints and have led security
vendors to flag PUP in ways similar to malware.

There exist

indications that PUP prominence has
quickly increased over the last years. Already in Q2
2014, AV vendors started alerting of a substantial in-
crease in collected PUP samples [59]. Recently, Thomas
et al. [64] showed that ad-injectors, a popular type of
PUP that injects advertisements into user’s Web surf-
ing, affects 5% of unique daily IP addresses accessing
Google [64]. And, Kotzias et al. [35] measured PUP
steadily increasing since 2010 in (so-called) malware
feeds, to the point where nowadays PUP samples out-
number malware samples in those feeds. Still, the preva-
lence of PUP remains unknown.

A fundamental difference between malware and PUP
is distribution. Malware distribution is dominated
by silent installation vectors such as drive-by down-
loads [22, 53], where malware is dropped through vul-
nerability exploitation. Thus, the owner of the compro-
mised host is unaware a malware installation happened.
In contrast, PUP does not get installed silently because
that would make it malware for most AV vendors. A
property of PUP is that it is installed with the consent
of the user, who (consciously or not) approves the PUP
installation on its host.

In this work, we perform the first systematic study
of PUP prevalence and its distribution through pay-per-
install (PPI) services. PPI services (also called PPI net-

USENIX Association  

25th USENIX Security Symposium  739

works) connect advertisers willing to buy installs of their
programs with affiliate publishers selling installs. The
PPI services used for distributing PUP are disjoint from
silent PPI services studied by prior work [7]. Silent PPI
services are exclusively used for malware distribution,
while the PPI services we study are majoritarily used for
distributing PUP and benign software. In the analyzed
PPI services, an affiliate publisher owns an original pro-
gram (typically freeware) that users want to install. To
monetize installations of its free program, the affiliate
publisher bundles (or replaces) it with an installer from a
PPI service, which it distributes to users looking for the
original program. During the installation process of the
original program, users are prompted with offers to also
install other software, belonging to advertisers that pay
the PPI service for successful installs of their advertised
programs.

To measure PUP prevalence and its distribution
through PPI services we use AV telemetry information
comprising 8 billion events on 3.9 million hosts during
a 19 month time period. This telemetry contains events
where parent programs installed child programs and we
focus on events where the publishers of either parent or
child programs are PUP publishers. This data enables
us to measure the prevalence of PUP on real hosts and
to map the who-installs-who relationships between PUP
publishers, providing us with a broad view of the PUP
ecosystem.

We first measure PUP prevalence by measuring the
installation base of PUP publishers. We find that pro-
grams from PUP publishers are installed in 54% of the
3.9M hosts examined. That is, more than half the ex-
amined hosts have PUP. We rank the top PUP publishers
by installation base and compare them with benign pub-
lishers. The top two PUP publishers, both of them PPI
services, are ranked 15 and 24 amongst all software pub-
lishers (benign or not). The top PUP publisher is more
popular than NVIDIA, a leading graphics hardware man-
ufacturer. The programs of those two top PUP publishers
are installed in 1M and 533K hosts in our AV teleme-
try dataset, which we estimate to be two orders of mag-
nitude higher when considering all Internet-connected
hosts. We estimate that each top 20 PUP publisher is
installed on 10M–100M hosts.

We analyze the who-installs-who relationships in the
publisher graph to identify and rank top publishers play-
ing specific roles in the ecosystem. This enables us to
identify 24 PPI services distributing PUP in our analyzed
time period. We also observe that the top PUP adver-
tisers predominantly distribute browser add-ons involved

in different types of advertising and by selling software
licenses for rogueware. We measure PUP distribution
finding that 65% of PUP downloads are performed by
other PUP, that the 24 identified PPI services are respon-
sible for over 25% of all PUP downloads, and that adver-
tiser affiliate programs are responsible for an additional
19% PUP downloads.

We also examine the malware-PUP relationships, in
particular how often malware downloads PUP and PUP
downloads malware. We find 11K events (0.03%) where
popular malware families install PUP for monetization
and 5,586 events where PUP distributes malware. While
there exist cases of PUP publishers installing malware,
PUP–malware interactions are not prevalent. Overall, it
seems that PUP distribution is largely disjoint from mal-
ware distribution. Finally, we analyze the top domains
distributing PUP, finding that domains from PPI services
dominate by number of downloads.
Contributions:

• We perform the first systematic study of PUP preva-
lence and its distribution through PPI services using
AV telemetry comprising 8B events on 3.9M hosts
over a 19-month period.

• We measure PUP prevalence on real hosts finding
that 54% have PUP installed. We rank the top PUP
publishers by installation base, finding that the top
two PUP publishers rank 15 and 24 amongst all (be-
nign and PUP) software publishers. We estimate
that the top 20 PUP publishers are each installed on
10M-100M hosts.

• We build a publisher graph that captures the who-
installs-who relationships between PUP publishers.
Using the graph we identify 24 PPI services and
measure that they distribute over 25% of the PUP.

• We examine other aspects of PUP distribution in-
cluding downloads by advertiser affiliate programs,
downloads of malware by PUP, downloads of PUP
by malware, and the domains from where PUP is
downloaded. We conclude that PUP distribution is
largely disjoint from malware distribution.

2 Overview and Problem Statement

This section first introduces the PPI ecosystem (Sec-
tion 2.1), then details the datasets used (Section 2.2), and
finally describes our problem and approach (Section 2.3).

740  25th USENIX Security Symposium 

USENIX Association

2

Advertisers

Toolbar

Adware

Rogueware

1

2

3

PPI

Service

4

Affiliate

Publishers

Target
Hosts

Bundle

Program

Payment

Figure 1: Typical transactions in the PPI market.
()
Advertisers provide software they want to have installed,
and pay a PPI service to distribute it. () Affiliate pub-
lishers register with the PPI service, provide their pro-
gram, and receive a bundle of their program with the PPI
installer. () Affiliate publishers distribute their bundle
to target users. () The PPI service pays affiliate pub-
lishers a bounty for any successful installations they fa-
cilitated.

2.1 Pay-Per-Install Overview

The PPI market, as depicted in Figure 1, consists of three
main actors: advertisers, PPI services/networks, and af-
ﬁliate publishers. Advertisers are entities that want to in-
stall their programs onto a number of target hosts. They
wish to buy installs of their programs. The PPI service
receives money from advertisers for the service of in-
stalling their programs onto the target hosts. They are
called advertisers because they are willing to pay to pro-
mote their programs, which are offered to a large num-
ber of users by the PPI service. Advertiser programs can
be benign, potentially unwanted (PUP), and occasionally
malware.

Afﬁliate publishers are entities that sell installs to PPI
services. They are often software publishers that own
programs (e.g., freeware) that users may want to install,
and who offer the advertiser programs to those users in-
stalling their programs. This enables affiliate publishers
to monetize their freeware, or to generate additional in-
come on top of the normal business model of their pro-
grams. They can also be website owners that offer visi-

Avg
Country
United States
$1.30
United Kingdom $0.80
$0.40
Australia
$0.40
Canada
$0.28
France
$0.25
Germany
New Zealand
$0.23
$0.19
Ireland
$0.18
Denmark
$0.16
Austria
Netherlands
$0.16
$0.15
Finland
$0.15
Norway
$0.12
Switzerland
Spain
$0.11

Range

$0.70-$2.00
$0.40-$1.50
$0.30-$0.50
$0.30-$0.50
$0.15-$0.50
$0.10-$0.40
$0.15-$0.35
$0.15-$0.25
$0.15-$0.20
$0.15-$0.20
$0.10-$0.20
$0.10-$0.20
$0.05-$0.20
$0.03-$0.20
$0.03-$0.20

Table 1: Top 15 countries with the highest average price
per install collected from 3 PPI services [8,9,50] on June
2016.

tors to download an installer from the PPI service, thus
selling installs on the visitor’s machines. Affiliate pub-
lishers are often referred simply as publishers, but we use
publishers to refer to software owners, and affiliate pub-
lishers for those signing up to PPI services.

The PPI service acts as a middle man that buys installs
from affiliate publishers and sells installs to advertisers.
The PPI service credits the affiliate publisher a bounty
for each confirmed installation, i.e., affiliate displays an
offer for an advertised program and the user approves
and successfully installs the advertised program.

Affiliate publishers are paid between $2.00 and $0.01
per install depending on the geographic location. Prices
vary over time based on offer and demand and the cur-
rent price is typically only available to registered affiliate
publishers. Table 1 shows the prices paid to affiliate pub-
lishers for the most demanded countries on June 25th,
2016 by 3 PPI services that publicly list their prices to
attract affiliate publishers. The highest paid country is
the United States with an average install price of $1.30,
followed by the United Kingdom ($0.80), Australia and
Canada ($0.40), and European countries starting at $0.30
for France. The cheapest installs are $0.03–$0.01 for
Asian and African countries (typically part of a “Rest of
the World” region). In comparison, prices paid to affiliate
publishers by silent PPI services that distribute malware
range $0.18-–$0.01 per install [7]. This shows that mal-
ware distribution can be an order of magnitude cheaper
for the most demanded countries.

USENIX Association  

25th USENIX Security Symposium  741

3

A common PPI model (depicted in Figure 1) is that the
affiliate publisher provides the PPI service with its pro-
gram executable and the PPI service wraps (i.e., bundles)
the affiliate’s program with some PPI installer software,
and returns the bundle/wrapper to the affiliate publisher.
The affiliate publisher is then in charge of distributing the
bundle to users interested in the affiliate’s program. The
distribution can happen through different vectors such
as websites that belong to the affiliate publisher or up-
loading the bundle to download portals such as Down-
load.com [15] or Softonic [61]. When a user executes the
wrapper, the wrapper installs the affiliate’s program and
during this installation it offers the user to install other
advertised programs. If the user downloads and installs
one of the offers, the PPI service pays a bounty to the
affiliate’s account.

An affiliate publisher can register with a PPI service
even it if it does not own programs that users want to
install. Some PPI services look for affiliate website own-
ers whose goal is to convince visitors of their websites to
download and run an installer from the PPI service. Fur-
thermore, some PPI services offer a pre-wrapped soft-
ware model where the PPI service wraps its own software
titles with the advertiser offers, and provides the bundle
to the affiliate publishers [29]. Some PPI services even
allow affiliate publishers to monetize on third-party free
programs (e.g., GNU).

Some download portals such as Download.com run
their own PPI service. When publishers upload their
programs to the portal (e.g., through Upload.com) they
are offered if they want to monetize their programs. If
so, the download portal wraps the original program and
makes the bundle available for download. In this model
the download portal is in charge of distribution.

Another distribution model are afﬁliate programs
where an advertiser uses affiliate publishers to distribute
its software directly, without a PPI service. This is a one-
to-many distribution model, in contrast with the many-
to-many distribution model of PPI services.

2.2 Datasets

Our paper leverages several datasets to conduct a sys-
tematic investigation about PUP prevalence and distribu-
tion. We analyze WINE’s binary downloads dataset [16]
to trace PUP installations by real users and their par-
ent/child (downloader/downloadee) relationships,
the
list of signed malicious executables from the Malsign
project [35] to cluster together executables signed by
different signers that belong to the same publisher,

Dataset
WINE
01/2013 – 07/2014

Malsign
VirusTotal

Data
Events Analyzed
Events with Parent
Total number of Machines
All Files
Parent Files
Child Files
Signed Files
Publishers
Parent Publishers
Child Publishers
Events with URL
URLs
FQDNs
ESLDs
Signed executables
Reports
Feed Reports
WINE Reports
Malsign Reports

Count
8 B
90 M
3.9 M
2.6 M
657 K
2 M
982 K
6 K
1.4 K
6 K
1.1 M
290 K
13.4 K
7.5 K
142 K
12 M
11 M
1.1 M
142 K

Table 2: Summary of datasets used.

and VirusTotal [67] reports for enriching the previous
datasets with additional file meta-data (e.g., AV detec-
tions, file certificates for samples not in Malsign). Ta-
ble 2 summarizes these datasets.
WINE. The Worldwide Intelligence Network Environ-
ment (WINE) [17] provides researchers a platform to an-
alyze data collected from Symantec customers that opt-
in to the collection. This data consists of anonymous
telemetry reports about security events (e.g., AV detec-
tions, file downloads) on millions of real computers in
active use around the world.

In this work, we focus on the binary downloads dataset
in WINE, which records meta-data about all executable
files (e.g., EXE, DLL) and compressed archives (e.g.,
ZIP, RAR, CAB) downloaded by Windows hosts regard-
less if they are malicious or benign. Each event in the
dataset can correspond to (1) a download of an exe-
cutable file or compressed archive over the network, or
(2) the extraction of a file from a compressed archive.
For our work, we analyze the following fields: the server-
side timestamp of the event, the unique identifier for the
machine where the event happens, the SHA256 hash of
the child file (i.e., downloaded or extracted), the SHA256
hash of the parent process (i.e., downloader program or
decompressing tool), the certificate subject for the parent
and child files if they are signed, and, when available,
the URL from where the child file was downloaded. The
files themselves are not included in the dataset.

742  25th USENIX Security Symposium 

USENIX Association

4

We focus our analysis on the 19 months between Jan-
uary 1st 2013 and July 23rd 2014. As our goal is to an-
alyze PUP (i.e., executables from PUP publishers), we
only monitor the downloads of PUP and the files that are
downloaded by PUP, i.e., events where either the child
or the parent is PUP. This data corresponds to 8 billion
events. The details of the data selection methodology are
explained in Section 3. Out of 8 B events, 90 M events
have information about the parent file that installed the
PUP. Those events comprise 2.6 M distinct executables
out of which 982 K (38%) are signed by 6 K publishers.
A subset of 1.1 M events provide information about
the URL the child executable was downloaded from.
These events contain 290 K unique URLs from 13.4 K
fully qualified domain names (FQDNs). To aggregate the
downloads initiated from the same domain owner, we ex-
tract the effective second-level domain (ESLD) from the
FQDN. For example, the ESLD of www.google.com
is the 2LD google.com, however,
the ESLD of
www.amazon.co.uk is the 3LD amazon.co.uk
since different entities can request co.uk subdomains.
We extract the ESLDs of the domains by consulting
Mozilla’s public suffix list [54].
Malsign. To cluster executables in the WINE binary
downloads dataset signed by different entities that belong
to the same publisher, we leverage a dataset of 142 K
signed malware and PUP from the Malsign project [35].
This dataset includes the samples and their clustering
into families. The clustering results are based on stati-
cally extracted features from the samples with a focus on
features from the Windows Authenticode signature [39].
These features include: the leaf certificate hash, leaf cer-
tificate fields (i.e., public key, subject common name and
location), the executable’s hash in the signature (i.e., Au-
thentihash), file metadata (i.e., publisher, description, in-
ternal name, original name, product name, copyright,
and trademarks), and the PEhash [68]. From the clus-
tering results we extract the list of publisher names (sub-
ject common name in the certificates) in the same cluster,
which should belong to the same publisher.
VirusTotal. VirusTotal [67] is an online service that
analyzes files and URLs submitted by users. One of
its services is to scan the submitted binaries with anti-
virus products. VirusTotal also offers a web API to
query meta-data on the collected files including the AV
detection rate and information extracted statically from
the files. We use VirusTotal to obtain additional meta-
data about the WINE files, as well as from 11 M mali-
cious/undesirable executables from a feed. In particular,
we obtain: AV detection labels for the sample, first seen

timestamp, detailed certificate information, and values of
fields in the PE header. This information is not available
otherwise as we do not have access to the WINE files
that are not in Malsign, but we can query VirusTotal us-
ing the file hash. We consider that a file is malicious if at
least 4 AV engines in the VT report had a detection label
for it, a threshold also used in prior works to avoid false
positives [35].

2.3 Problem Statement

In this paper we conduct a systematic analysis of PUP
prevalence and its distribution through PPI services. We
split our measurements in two main parts. First, we mea-
sure how prevalent PUP is. This includes what fraction
of hosts have PUP installed, which are the top PUP pub-
lishers, and what is the installation base of PUP publish-
ers in comparison with benign publishers. Then, we mea-
sure the PPI ecosystem including who are the top PPI
services and PUP advertisers, what percentage of PUP
installations are due to PPI services and advertiser affil-
iate programs, what are the relationships between PUP
and malware, and what are the domains from where PUP
is downloaded.

We do not attempt to differentiate what behaviors
make a program PUP or malware, but instead rely on
AV vendors for this. We leverage the prior finding that
the majority of PUP (and very little malware) is prop-
erly signed.
In particular, signed executables flagged
by AV engines are predominantly PUP, while malware
rarely obtains a valid code signing chain due to identity
checks implemented by CAs [35]. Using that finding, we
consider PUP any signed file flagged by at least 4 AV en-
gines. Thus, the term PUP in this paper includes different
types of files that AV vendors flag as PUP including un-
desirable advertiser programs, bundles of publisher pro-
grams with PPI installers, and stand-alone PPI installers.
To measure PUP prevalence, we first identify a list of
dominant PUP publishers extracted from the code sign-
ing certificates from the 11M VT reports from the mal-
ware feed (Section 3). Then, we group publisher names
(i.e., subject strings in code signing certificates) from the
same entity into publisher clusters (Section 4). Finally,
we use the WINE binary reputation data to measure the
PUP installation base, as well as the installation base of
individual PUP and benign publisher clusters (Section 5).
Since we focus on signed executables, our numbers con-
stitute a lower bound on PUP and publisher prevalence.
To measure the PPI ecosystem, we build a publisher
graph that captures the who-installs-who relationships

USENIX Association  

25th USENIX Security Symposium  743

5

among PUP publishers. We use the graph for identifying
PPI services and PUP advertisers (Section 6). Then, we
measure the percentage of PUP installations due to PPI
services and advertiser affiliate programs (Section 7).
Next, we analyze the downloads of malware by PUP and
the downloads of PUP by malware (Section 8). Finally,
we examine the domains from where PUP is downloaded
(Section 9).

3

Identifying PUP Publishers

The first step in our approach is to identify a list of dom-
inant PUP publishers. As mentioned earlier, prior work
has shown that signed executables flagged by AV engines
are predominantly PUP, while malware is rarely properly
signed. Motivated by this finding, we identify PUP pub-
lishers by ranking publishers of signed binaries flagged
by AV vendors, by the number of samples they sign.

For this, we obtain a list of 11M potentially malicious
samples from a “malware” feed and query them in Virus-
Total to collect their VT reports. From these reports,
we keep only executables flagged by at least 4 AV ven-
dors to make sure we do not include benign samples in
our study. We further filter out executables with invalid
signatures, i.e., whose publisher information cannot be
trusted. These filtering steps leave us with 2.5M bina-
ries whose signatures validated at the time of signing.
These include executables whose certificate chain still
validates, those with a revoked certificate, and those with
expired certificates issued by a valid CA.

From each of the 2.5M signed executables left, we ex-
tract the publisher’s subject common name from the cer-
tificate information in its VT report. Hereinafter, we will
refer to the publisher’s subject common name as pub-
lisher name. Oftentimes, publisher names have some
variations despite belonging to the same entity. For ex-
ample, MyRealSoftware could use both “MyRealSoft-
ware S.R.U” and “MyRealSoftware Inc” in the publisher
name. Thus, we perform a normalization on the pub-
lisher names to remove company suffixes such as Inc.,
Ltd. This process outputs a list of 1,440 normalized PUP
publisher names. Table 11 in the Appendix shows the top
20 normalized PUP publisher names by number of sam-
ples signed in the feed. These 20 publishers own 56% of
the remaining signed samples after filtering.

Clearly, our list does not cover all PUP publishers in
the wild. This would not be possible unless we ana-
lyzed all existing signed PUP. However, the fact that we
analyze 2.5M of undesirable/malicious signed samples
gives us confidence that we cover the top PUP publishers.

Those 1,440 PUP publisher names are used to scan the
file publisher field in WINE’s binary downloads dataset
to identify events that involve samples from those PUP
publishers, i.e., where a parent or child file belongs to
the 1,440 PUP publishers. As shown in Table 2, there
are 8 B such events.

Note that at this point we still do not know whether dif-
ferent publisher names (i.e., entries in Table 11) belong
to the same PUP publisher. For example, some popular
publisher names such as Daniel Hareuveni, Stepan Ry-
bin, and Stanislav Kabin are all part of Web Pick Internet
Holdings Ltd, which runs the InstalleRex PPI service.
The process to cluster publisher names that belong to the
same publisher is described in Section 4.

4 Clustering Publishers

PUP authors use certificate polymorphism to evade de-
tection by certification authorities and AV vendors [35].
Two common ways to introduce certificate polymor-
phism are applying small variations to reuse the same
identity / publisher name (e.g. apps market ltd, APPS
Market Inc., Apps market Incorporated) and using multi-
ple identities (i.e., companies or persons) to obtain code
signing certificates. We cluster publisher names that be-
long to the same publisher according to similarities on
the publisher names, domain names in events with URLs,
and Malsign clustering results.
Publisher name similarity. This feature aims to group
together certificates used by the same identity that have
small variations on the publisher name. Since the WINE
binary downloads dataset contains the publisher name for
parent and child files, this feature can be used even when
a signed sample has no VT report and we do not have the
executable (i.e., not in Malsign). The similarity between
two publisher names is computed in two parts: first de-
rive a list of normalized tokens from each publisher name
through four steps and then compute similarity between
the token lists.

To obtain the token list of a publisher name, the first
step is to extract parenthesized strings as separate tokens.
For example, given the publisher name “Start Playing
(Start Playing (KnockApps Limited))” this step produces
3 tokens: “Start Playing”, “Start Playing”, and “Knock-
Apps Limited”. The second step converts each token to
lowercase and removes all non-alphanumeric characters
from the token. The third step removes from the tokens
company extensions (e.g., ltd, limited, inc, corp), geo-
graphical locations (e.g., countries, cities), and the string

744  25th USENIX Security Symposium 

USENIX Association

6

Publishers Clusters

Singletons

Largest Median

6,066

5,074

4,534

103

1

5 PUP Prevalence

Table 3: Publisher clustering results.

“Open Source Developer”, which appears in code sign-
ing certificates issued to individual developers of open
source projects. Finally, tokens that have less than 3 char-
acters and duplicate tokens are removed.

To compute the similarity between two token lists, for
each pair of publisher names P1 and P2, we calculate
the normalized edit distance among all token pairs (ti,t j)
where ti belongs to P1 and t j to P2. If the edit distance
between P1 and P2 is less than 0.1, we consider these
two publishers to be the same. We selected this thresh-
old after experimenting with different threshold values
over 1,157 manually labeled publisher names. The edit
distance threshold of 0.1 allowed us grouping the 1,157
publisher names into 216 clusters with 100% precision,
81.9% recall, and 86.4% F1 score.
Child download domains. If child executables signed
by different publisher names are often downloaded from
the same domains, that is a good indication that the pub-
lisher names belong to the same entity. To capture this
behavior, we compute the set of ESLDs from where files
signed by the same publisher name have been down-
loaded. Note that we exclude ESLDs that correspond
to file lockers and download portals as they are typically
used by many different publishers. The publisher names
whose Jaccard Index of their ESLD sets is over 0.5 are
put to the same cluster.
Parent download domains. Similarly, if parent files
signed by different publisher names download from a
similar set of domains, this indicates the publisher names
likely belong to the same entity. This feature first com-
putes the set of ESLDs from where parent files signed by
the same publisher name download (excluding file lock-
ers and download portals). Publisher names whose Jac-
card Index is over 0.5 are put to the same cluster.
Malsign clustering. For each Malsign cluster we extract
the list of distinct publisher names used to sign executa-
bles in the cluster, i.e., Subject CN strings extracted from
certificates for files in the cluster. We consider that two
publisher names in the same Malsign cluster belong to
the same publisher.
Final clustering. We group publisher names into the
same cluster if they satisfy at least one of the first 3 fea-
tures explained above or are in the same Malsign cluster.
Table 3 summarizes the clustering, which produces 5,074
clusters from 6,066 publisher names.

In this Section, we measure the prevalence of PUP, based
on the number of hosts in the WINE binary downloads
dataset (i.e., WINE hosts) that have installed programs
from PUP publishers. We measure the total number of
WINE hosts affected by PUP, rank PUP publishers by in-
stallation base, and compare the installation base of PUP
publishers to benign publishers.

We first compute the detection ratio (DR) for each
cluster, which is the number of samples signed by pub-
lishers in the cluster flagged by at least 4 AVs, divided
by the total number of samples in the cluster for which
we have a VT report. We mark as PUP those clusters
with DR > 5%, a threshold chosen because is the lowest
that leaves out known benign publishers. From this point
on, when we refer to PUP publishers, we mean the 915
publisher clusters with DR > 5%.

Note that the number of WINE hosts with installed
programs from a publisher cluster constitutes a quite con-
servative lower bound on the number of hosts across
the Internet that have programs installed from that pub-
lisher. It captures only those Symantec customers that
have opted-in to share data and have been sampled into
WINE. If we take into account that Symantec only had
8% of the AV market share in January 2014 [47] and that
only 1
16 of Symantec users that opt-in to share telemetry
are sampled into WINE [6], we estimate that the number
of WINE hosts is two orders of magnitude lower than
the corresponding number of Internet-connected hosts.
Furthermore, we do not count WINE hosts with only un-
signed PUP executables installed.
PUP prevalence. We find 2.1M WINE hosts, out of a to-
tal 3.9M WINE hosts in our time period, with at least one
executable installed from the 915 PUP clusters. Thus,
54% of WINE hosts have PUP installed. This ratio is a
lower bound because we only count signed PUP executa-
bles (i.e., we ignore unsigned PUP executables) and also
because our initial PUP publisher list in Section 3 may
not be complete. Thus, PUP is prevalent: more than half
of the hosts examined have some PUP installed.
Top PUP publishers. Table 4 shows the top 20 PUP
publishers by WINE installation base and details the
cluster name, whether the publisher is a PPI service (this
classification is detailed in Section 6), the number of pub-
lisher names in the cluster, detection ratio, and host in-
stallation base. The number of publishers ranks from sin-
gleton clusters up to 48 publishers for IronSource, an Is-
raeli PPI service. The installation bases for the top 20
PUP publishers range from 200K up to over 1M for Pe-

USENIX Association  

25th USENIX Security Symposium  745

7

Bandoo Media

Perion Network

IronSource
Babylon
JDI BACKUP
Systweak

# Cluster
1
2 Mindspark
3
4 Web Pick
5
6
7
8
9 OpenCandy
10 Montiera Technologies
11
Softonic International
12
PriceGong Software
13 Adknowledge
14 Adsology
15 Visual Tools
16
17 Wajam
18 W3i
19
20

BitTorrent

iBario
Tuguu

PPI
✓


✓
✓



✓



✓




✓
✓
✓

Pub
5
1
5
21
48
1
1
3
1
2
2
1
7
2
2
1
2
4
15
14

DR Hosts
52% 1.0M
85% 533K
46% 373K
79% 346K
81% 332K
38% 330K
56% 328K
37% 320K
55% 311K
54% 303K
70% 292K
18% 292K
75% 277K
77% 276K
70% 275K
40% 271K
87% 218K
93% 216K
84% 208K
94% 200K

Table 4: Top 20 PUP publishers by installation base.

rion Network, an Israeli PPI service that bought the op-
erations of the infamous Conduit toolbar in 2013. As
explained earlier, these numbers are a quite conserva-
tive lower bound. We estimate the number of Internet-
connected computers for these publishers to be two or-
ders of magnitude larger, in the range of tens of millions,
and up to a hundred million, hosts. We have found anec-
dotal information that fits these estimates. For example,
an adware developer interviewed in 2009 claimed to have
control over 4M machines [12].
Comparison with benign publishers. Table 5 shows
the top 20 publisher clusters, benign and PUP, in WINE.
The most common publishers are Microsoft and Syman-
tec that are installed in nearly all hosts. The Perion Net-
work / Conduit PPI network ranks 15 overall. That is,
there are only 14 benign software publishers with a larger
installation base than the top PUP publisher. Perion Net-
work is more prevalent than well known publishers such
as Macrovision and NVIDIA. The second PUP publisher
(Mindspark Interactive Network) has the rank 24. This
highlights that top PUP publishers are among the most
widely installed software publishers.

A reader may wonder if we could also compute the in-
stallation base for malware families. Unfortunately, due
to malware being largely unsigned and highly polymor-
phic, we would need to first classify millions of files in
WINE (without having access to the binaries) before we
can perform the ranking.

Intel
Sun Microsystems
Cyberlink

# Cluster
1 Microsoft
2
Symantec
3 Adobe Systems
4 Google
5 Apple
6
7
8
9 GEAR Software
10 Hewlett-Packard
11 Oracle
12
Skype Technologies
13 Mozilla Corporation
14 McAfee
15
16 WildTangent
17 Macrovision Corporation
18
LEAD Technologies
19 NVIDIA Corporation
20 Ask.com
24 Mindspark Interactive Network

Perion Network / Conduit

PUP Hosts
3.9M
3.8M
3.5M
3.1M
1.8M
1.6M
1.6M
1.6M
1.5M
1.5M
1.4M
1.3M
1.0M
1.0M
1.0M
941K
802K
775K
722K
624K
533K















✓





✓

Table 5: Top publishers by install base (benign and PUP).

6 Classifying Publishers

Among the 5,074 PUP publisher clusters obtained in
Section 4 we want to identify important clusters play-
ing a specific role in the ecosystem.
In particular, we
want to identify clusters that correspond to PPI services
and to examine the type of programs distributed by the
dominant advertisers. For this, we first build a publisher
graph that captures the who-installs-who relationships.
Then, we apply filtering heuristics on the publisher graph
to select a subset of publishers that likely hold a specific
role, e.g., PPI service. Finally, we manually classify the
filtered publishers into roles by examining Internet re-
sources, e.g., publisher web pages, PPI forums, and the
Internet Archive [32].
Publisher graph. The publisher graph is a directed
graph where each publisher cluster is a node and an edge
from cluster CA to cluster CB means there is at least
one event where a parent file from CA installed a child
file from CB. Self-edges are excluded, as those indicate
program updates and downloads of additional compo-
nents from the same publisher. Note that an edge cap-
tures download events between parent and child clusters
across all hosts and the 19 months analyzed. Thus, the
publisher graph captures the who-installs-who relation-
ships over that time period, enabling a birds-eye view of
the ecosystem.

746  25th USENIX Security Symposium 

USENIX Association

8

USENIX Association  

25th USENIX Security Symposium  747

Figure2:Clusterin-degreedistribution.Figure3:Clusterout-degreedistribution.In-degreeandout-degree.Wefirstmeasurethein-degreeandout-degreeofeachclusterinthepublishergraph.Thein-degreeisthecountofdistinctparentpub-lisherclustersthatinstallprogramsfromachildpub-lishercluster.Intuitively,publisherswithahighin-degreeareinstalledbymanyotherpublishers,whichin-dicatesthattheyarebuyinginstalls.Theout-degreeisthecountofdistinctchildpublisherclustersinstalledbyaparentpublishercluster.Intuitively,publisherswithahighout-degreeinstallmanyotherpublishers,whichin-dicatesthattheyaresellinginstalls.Tocomputeacluster’sin-degreewefilterout12be-nignparentclustersthatcorrespondtotoolsthatdown-loadlargenumbersofexecutablesfromdifferentpub-lisherssuchasbrowsers,BitTorrentclients,andDrop-box.Tocomputeacluster’sout-degreeweexcludebe-nignchildpublishers(DR<5%)thataretypicallyde-pendencies.Figure2showsthein-degreedistribution.57%oftheclustershavenoparents(i.e.,installedbyunsignedfilesonly).Another21.5%haveone.Thesearetypicallyin-stalledonlybyparentsinthesamecluster.Only224(4.4%)clustershaveanin-degreelargerthan10.Wecallthesehighin-degreeclusters.Figure3showstheout-degreedistribution.572clusters(11%)haveanout-degreelargerthanzeroandonly133(2.6%)clustershaveanout-degreelargerthan10.Wecallthesehighout-degreeclusters.PPIservices.ToidentifyPPIservicesinthepublishergraph,wefirstselectallPUPpublisherclusterswithbothhighin-degreeandhighout-degree(i.e.,DR≥5%∧ID≥10∧OD≥10),whichindicatethesepublish-ersarebuyingandsellinginstalls.Thisrulereducesthe5,074clustersto49candidatepublisherclusters.Next,wemanuallyclassifythose49clustersthroughextensiveanalysisusingPPIforums,publisherwebsites,andtheInternetArchive.Ofthose49clusters,weclassify22asPPIservices,12asadvertisersthatrunanaffiliatepro-gram,8asadvertiserswithoutanaffiliateprogram;3asdownloadportals(Download.com,BrotherSoft,Soft-onic),and4asPUPpublishersthatdistributefreedown-loadtools(e.g.,BitTorrentclients).Thelattertoolsin-flatetheout-degreeoftheirpublishersandwerenotin-cludedinourwhitelistofdownloadtoolsduetothehighDRoftheirpublishers.OurmanualanalysisalsorevealstwoadditionalPPIservices(7installandInstallMonster)thatweremissedbyourrulebecausetheydonotachievehighenoughin-degreeandout-degree,eitherbecauseoflowpopularityorbecausetheyappearattheendofourobservationperiod.Table6summarizesthe24identifiedPPIservicessortedbyinstallationbase.Foreachcluster,itshowsthenameofthePPIservice,in-degree,out-degree,in-stallationbase,detectionratio,andnumberofpublishersinthecluster.Theclassificationrevealsthat3ofthetop5PUPpublishersbyinstallationbaseinTable4arePPIservices.Thus,themostpopularPUPpublishersarePPIservices.SomeofthePPIservicesidentifiednolongerworkatthetimethispaperispublished,e.g.,OneIn-staller,buttheirPPIservicefront-endsarepresentintheInternetArchive.DuringourmanualanalysiswekeeptrackofallPPIserviceswefindadvertisedontheInternet,e.g.,onPPIforums.Inadditiontothe24PPIservicesinTable6weidentifyanother12PPIservices,showninTable12intheAppendix.Thereareseveralreasonsforwhichwedonotobservethose12PPIservicesinourdata.First,someofthemaresimplyresellersthatpayaffiliatepub-lisherstodistributebundlesordownloadersforotherPPIservices.Second,PPIservicesmayhavebeenlaunched9Perion Network/Conduit

# Cluster
1
2 Yontoo
3
iBario
4 Web Pick
5
IronSource
6 OpenCandy
7 Adknowledge
8 W3i
9
10
11
12 Download Admin
13 Air Software
14 Vittalia Internet
15 Amonetize
16
17 OutBrowse
18 Verti Technology Group
19
Blisbury
20 Nosibay
21
22
23
24

ConversionAds
Installer Technology
7install
Install Monster

Somoto
Firseria
Tuguu

SIEN

PPI Service
CodeFuel [10]
Sterkly [63]
RevenueHits [56]
InstalleRex [27]
InstallCore [26]
OpenCandy [46]
Adknowledge [20]
NativeX [41]
BetterInstaller [5]
Solimba [62]
DomaIQ [13]
DownloadAdmin [14]
AirInstaller [3]
OneInstaller [45]
installPath [31]
Installbay [25]
RevenYou [57]
Verti [66]
Smart WebAds [60]
Nosibay [44]
ConversionAds [11]
InstallerTech [28]
7install [1]
Install Monster [30]

ID OD Hosts
168
1 M
601 K
53
479 K
62
346 K
65
332 K
73
311 K
91
53
277 K
216 K
38
209 K
60
209 K
41
49
200 K
192 K
25
191 K
33
155 K
27
154 K
50
34
139 K
86 K
22
47 K
17
46 K
19
19
30 K
24 K
10
11 K
10
75
2
3
9

63
17
36
22
112
36
48
49
70
30
16
16
41
29
63
33
41
39
30
20
38
14
0
1

DR Pub.
5
52%
93%
103
16
84%
21
79%
48
81%
1
55%
75%
7
4
93%
5
96%
9
94%
94%
14
2
73%
1
79%
18
71%
2
93%
80%
2
4
94%
1
44%
2
77%
75%
1
1
72%
1
56%
1
12%
100%
1

Table 6: PPI services services identified sorted by installation base.

(or gained popularity) after the end of our observation
period (e.g., AdGazelle). Third, some PPI services may
distribute unsigned bundles or downloaders. For exam-
ple, we examined over 30K samples that AV engines la-
bel as belonging to the InstallMonetizer PPI service, of
which only 8% were signed. Finally, some PPI services
may have so low volume that they were not observed in
our initial 11 M sample feed.
Advertisers. To identify advertisers in the publisher
graph, we first select PUP clusters with high in-degree,
low out-degree, and for which at least one parent is one
of the 24 PPI services (i.e., DR ≥ 5%∧ ID ≥ 10∧ OD ≤
9∧PPPI > 0). Advertisers pay to have their products in-
stalled (i.e., buy installs) and may not install other pub-
lishers for monetization as they know how to monetize
the machines themselves. Since buying installs costs
money, they need to generate enough income from the
installations to offset that cost. This filtering identifies
77 clusters, which we manually examine to identify the
main product they advertise (they can advertise multiple
ones) and whether they run an affiliate program where
they pay affiliates to distribute their programs. We also
include in this analysis the 20 advertiser clusters manu-
ally identified in the PPI service identification above.

Table 7 shows the top 30 advertiser clusters by instal-
lation base. The table shows the cluster name, whether
it runs an affiliate program, in-degree, out-degree, de-
tection ratio, installation base, the number of parent PPI
service nodes, the number of child PPI service nodes,
the main product they install, and whether they install
browser add-ons (BAO). The latter includes any type of
browser add-ons such as toolbars, extensions, plugins,
browser helper objects, and sidebars.

The data shows that 18 of the 30 top advertisers install
browser add-ons. Those browser add-ons enable moneti-
zation through Web traffic, predominantly through differ-
ent types of advertisement. Common methods are mod-
ifying default search engines to monetize searches (e.g.,
SearchResults, Delta Toolbar, Imminent Toolbar), shop-
ping deals and price comparisons (e.g., PriceGong, Pri-
cePeep, DealPLY, SupremeSavings), and other types of
advertisement such as pay-per-impression and pay-per-
action (e.g., Widgi Toolbar, Inbox Toolbar).

The 12 advertisers that focus on client applications
monetize predominantly through selling licenses and
subscriptions. The main group is 6 publishers adver-
tising rogueware claiming to improve system perfor-
mance (Regclean Pro, Optimizer Pro, SpeedUpMyPC,

748  25th USENIX Security Symposium 

USENIX Association

10

PriceGong Software

Bandoo Media
Babylon
JDI Backup Limited
Systweak

# Cluster
1 Xacti
2 Mindspark
3
4
5
6
7 Montiera Technologies
8
9 Adsology
10 Wajam
11 Visicom Media
12
13 Uniblue Systems
14
15
16
17 DealPly Technologies
18
19 DVDVideoSoft
20
21 Web Cake
22 GreTech
23 Digital River
24 Widdit
25
26
27 DT Soft
28
29 Woolik Technologies
30 Visual Software Systems

Search Results
Bitberry Software
Iminent

Smart PC Solutions

Innovative Apps

EpicPlay
Iobit Information Technology

Linkury

Spigot

Aff
ID OD
9
57

✓ 62
17
✓ 86
108
✓ 83
14
✓ 71
19
✓ 81
24
37
2

0
12

✓ 62
12
5
42

13
2

2
46

✓ 64
13
3
35

✓ 13
64
13
1

0
43

✓ 38
0
2
15

✓ 17
1
2
34

✓ 13
1
✓ 17
0
✓ 20
16
12
4

✓ 18
8
2
14

1
14

9
13

✓ 22
12

DR Hosts
22% 563 K
85% 533 K
46% 373 K
38% 330 K
56% 328 K
37% 320 K
66% 303 K
17% 292 K
77% 276 K
87% 218 K
14% 185 K
54% 174 K
11% 160 K
79% 159 K
88% 130 K
74% 118 K
93% 108 K
32% 106 K
18% 101 K
39% 101 K
97 K
98%
90 K
21%
80 K
10%
79 K
27%
90%
77 K
73 K
6%
68 K
22%
60 K
68%
50 K
70%
62%
42 K

13
3
7
16
17
7
8
6
17
11
4
13
10
12
1
4
16
13
3
1
16
3
1
4
3
3
2
7
4
5

PPPI CPPI Main Product
RebateInformer

PriceGong

Babylon Toolbar

SmartBar
SpeedUpMyPC
SearchResults
BitZipper
Iminent Toolbar

1
5 Mindspark Toolbar
18 MediaBar
3
3 MyPC Backup
2
Regclean Pro
1 Delta Toolbar
0
1 OptimizerPro
2 Wajam
0 VMN Toolbar
0
1
2
7
1
0 DealPly
0
1
1 Widgi Toolbar
2 Desktop OS
1 GOM Player
0 DR Download Manager
2 HomeTab
1
EpicPlay
1 Advanced SystemCare
1 DAEMON Tools
0
Supreme Savings
1 Woolik Search Tool
3 VisualBee

PC Speed Maximizer
Free Studio

BAO
✓
✓
✓
✓


✓
✓

✓
✓
✓

✓

✓
✓


✓
✓

✓
✓



✓
✓


Table 7: Top 30 advertiser clusters by installation base. For each publisher cluster it shows: whether we found an
affiliate program (Aff), the in-degree (IN), out-degree (OD), detection ratio (DR), installation base (Hosts), number
of parent PPI services (PPPI), number of child PPI services (CPPI), the main product advertised, and whether that
product is a browser add-on (BAO) including toolbars, extensions, sidebars, and browser helper objects.

Event Type
All PUP downloads
Unsigned parent
Signed parent

Benign parent
PUP parent

PPI
Adv. affiliate program

Count
40.1M
11.5M
28.6M
7.4M
21.2M
7.3M
5.5M

Table 8: Analysis of PUP download events.

PC Speed Maximizer, Advanced System Care, DAE-
MON Tools). These rogueware try to convince users to
buy the license for the full version. We also observe mul-
timedia tools (Free Studio, GOM Player), backup tools
(MyPC Backup), game promotion (EpicPlay), compres-
sors (BitZipper), and presentation tools (Visual Bee).

7 PUP Distribution Methods.

This section measures the distribution of PUP through
PPI services and affiliate programs. The relevant data is
provided in Table 8. From the 90 M events with par-
ent information, we first find the events with child files
that are signed by PUP publishers (40.1M events). Then,
we investigate the parents that installed them. In 28.6M
(71%) of these events, parents were signed, therefore
allowing us to go further in our search for finding the
parents who are PPIs. 7.4M (35%) of the these parents
correspond to Web browsers and other benign download
programs such as BitTorrent clients and Dropbox. The
remaining 21.2M (65%) events have a PUP parent. This
indicates that the majority of PUP is installed by other
PUP. In particular, for 7.3M out of 21.2M events (34%)

USENIX Association  

25th USENIX Security Symposium  749

11

with PUP parent, the parent corresponds to one of the
24 PPI services identified in Table 6. And, for another
5.5M (26%) events the parent corresponds to one of the
21 affiliate programs identified in Section 6. From these
statistics, we can conclude that PUPs are generally in-
stalled by other PUPs and moreover, over 25% of the
PUP download events are sourced by PPI services, and
another 19% by advertisers with affiliate programs.

8 PUP–Malware Relationships

We are interested in understanding if there is any form
of relationship between PUP and malware and if mal-
ware uses the PPI services we identified. In particular
we would like to measure the percentage of PUP that in-
stalls malware or is installed by malware. Here, the obvi-
ous challenge is to accurately label malware in the WINE
dataset. While the majority of properly signed executa-
bles flagged by AV engines are PUP, unsigned executa-
bles flagged by AV engines can be PUP or malware and
there are a few malware that are signed.

To address these issues, we use AVClass, a recently re-
leased malware labeling tool [58]. Given the VT reports
of a large number of executables, AVClass addresses the
most important challenges in extracting malware family
information from AV labels: label normalization, generic
token detection, and alias detection. For each sample, it
outputs a ranking of the most likely family names ranked
by the number of AV engines assigning that family to
the sample. Since AV labels can be noisy [4], we fo-
cus on executables for which the top family AVClass
outputs is in a precomputed list of 70 malware families
that includes prevalent families such as zbot, zeroaccess,
reveton, virut, sality, shylock, and vobfus. Clearly, our
methodology is not 100% accurate, but allows us to gain
insight on the relationships between malware and PUP.
PUP downloading malware. One way malware authors
could relate to PUP could be by signing up as advertis-
ers to PPI services to distribute their malware. To iden-
tify such cases, we look for PUP publishers that down-
load executables from one of the 70 malware families
considered. What we have found out is that there is a
link between 71 of the PUP publisher clusters to mal-
ware. Those publishers distribute malware from 40 fam-
ilies through 5,586 download events. Out of those 71
clusters, 11 are classified as PPI services in Section 6.
Those PPI services generate 35% of the 5,586 malware
downloads by PUP. For example, Perion Network, the
most popular PPI service, downloads instances of zbot,
shylock, and andromeda trojans. We also observe at the

end of 2013 iBario downloading instances of sefnit click-
fraud malware as reported by TrendMicro [38]. Clearly,
5,586 downloads is a low number, which may indicate
that malware favors silent distribution vectors and that
PPI services are careful to avoid malware to preserve
their reputation towards security vendors. We only ob-
serve occasional events spread amongst multiple PPI ser-
vices, possibly due to insufficient checks by those PPI
services. Another factor of influence may be that installs
through these PPIs can be an order of magnitude more
expensive than those from silent PPIs, as shown in Sec-
tion 2.1.
Malware downloading PUP. Malware authors could
also sign up as affiliate publishers to PPI services to
monetize the compromised machines by selling installs.
To capture this behavior, we analyzed PUP downloaded
by samples from the 70 malware families considered.
We found 11K downloads by malware from 25 fami-
lies. These malware samples downloaded executables
from 98 PUP publisher clusters. 88% of these downloads
were generated by 3 malware families: vobfus, badur,
and delf. 7 of the 98 PUP publisher clusters belong to the
PPI services category. For example, we observe zeroac-
cess installing files from the DomaIQ PPI service. Over-
all, malware downloading PUP is a more common event
than PUP downloading malware, but still rare, affecting
only 0.03% of all events where PUP is downloaded.

The conclusion of this analysis is that while PUP–
malware interactions exist, they are not prevalent and
malware distribution seems disjoint from PUP distribu-
tion. Observed malware–PPI service interactions do not
focus on a few misbehaving PPI services, but rather seem
to occasionally affect many PPI services.

9 Domain Analysis

In this section we analyze the 1.1 M events that contain
a URL, and in particular the domains (ESLDs) in those
URLs. The events that contain a URL allow us to identify
publishers that download from and are downloaded from
a domain. Note that the domains we extract from this
dataset are used for hosting and distributing executables
and do not cover all of the domains used by PUP. We
identify 3 main types of domains from our analysis:

• File lockers. Cloud storage services used for
backup or sharing executables between users. They
exhibit a high number of client publishers being
downloaded from them, most of which are benign
(e.g., Microsoft, Adobe, AutoDesk). These ESLDs
also host a front-end website for users.

750  25th USENIX Security Symposium 

USENIX Association

12

• Download portals. They also distribute programs
from a high number of publishers, predominantly
free software publishers and their own PPI services.
They also host a front-end website.

• PPI services. Used by PPI services to host their
wrappers and advertised programs. These ESLDs
do not host a front-end website as they are accessed
by PPI installers, rather than humans.

Rank by downloaded publishers. Table 9 shows the
top 20 ESLDs by number of child publishers signing files
downloaded from that ESLD. The 4 tick-mark columns
classify the domain as file locker (FL), download portal
(DP), PPI service (PPI), or other (Oth). Of the 20 ES-
LDs, 15 correspond to file lockers, 2 to download portals,
and another 2 to PPI services. The remaining domain is
file.org, a portal where users can enter a file exten-
sion to find a tool that can open files with that extension.
The publisher behind this portal uses it to promote its
own free file viewer tool, which is offered as the best
tool to handle over 200 file extensions.

If we give a vote to the top 3 publishers downloaded
from each of the 15 file lockers (45 votes), Microsoft gets
13, Adobe 11, Cyberlink 4, and AutoDesk 3. The rest are
popular benign publishers such as Ubisoft, VMWare, and
Electronic Arts. Thus, file lockers predominantly dis-
tribute software from reputable publishers.

For the two download portals, the publishers down-
loaded from them correspond to their own PPI ser-
vice (i.e., bundles signed by “CBS Interactive” from
cnet.com), free software publishers, and PPI services.
For edgecastcdn.net all 67 publishers are part of
the same PPI service run by the Yontoo group. The
domain d3d6wi7c7pa6m0.cloudfront.net be-
longs to the Adknowledge PPI service and distributes
their advertiser programs. Among those advertiser pro-
grams we observe bundles signed by other PPI services,
which may indicate arbitrageurs who try to take advan-
tage of pricing differentials among PPI services [7].
Rank by downloads. Table 10 ranks the top 20 do-
mains by number of downloads.
It shows the ESLD,
the type (file locker, download portal, PPI service, ad-
vertiser, other), the cluster that owns the domain, the
number of downloads, the number of publishers of the
downloaded executables, and the number of distinct files
downloaded. We label each domain as belonging to the
cluster that signs most executables downloaded from the
domain. The publisher in the other category is Frostwire,
which distributes a popular free BitTorrent client.

PPI Oth

FL DP
✓

✓

ESLD
uploaded.net
cnet.com
extabit.com
share-online.biz
4shared.com
rapidgator.net
depositfiles.com
mediafire.com
edgecastcdn.net
chip.de
zippyshare.com
uloz.to
file.org
putlocker.com
d3d6wi7c7pa6m0.cf
turbobit.net
freakshare.com
rapidshare.com
ddlstorage.com
bitshare.com

✓
✓
✓
✓
✓
✓

✓
✓

✓

✓
✓
✓
✓
✓

Pub
366
142
128
125
120
90
76
73
67
53
49
48
47
47
44
44
41
40
38
38

✓

✓

✓

✓

Table 9: Top 20 ESLDs by number of distinct publish-
ers of downloaded executables. FL means file locker,
DP download portal, PPI pay-per-install service, and
Oth other. For brevity, d3d6wi7c7pa6m0.cf stands for
d3d6wi7c7pa6m0.cloudfront.net.

Table 10 shows that PPI domains dominate in terms
of downloads, but distribute a smaller number of child
publishers compared to file lockers and download portals
that dominate Table 9. It also shows that it is possible to
link download domains to the publishers that own them
based on the signature of files they distribute, despite the
domains being typically registered by privacy protection
services.

10 Discussion

Unsigned PUP. Our work focuses on signed PUP exe-
cutables based on the prior observation that most signed
samples flagged by AV engines are PUP [35]. However,
this means that we will miss PUP publishers if they dis-
tribute only unsigned executables. Also, our PUP preva-
lence measurements are only a lower bound since there
may be hosts with only unsigned PUP installed. In con-
current work, Thomas et al. [65] infiltrate 4 PPI services
observing that only 58% of the advertiser software they
distribute is signed. Thus, we could be missing as much
as 42% of PUP software, but we expect a much smaller
number of hosts will only have unsigned PUP installed.

USENIX Association  

25th USENIX Security Symposium  751

13

ESLD
conduit.com
edgecastcdn.net
frostwire.com
ask.com
imgfarm.com
ilivid.com
conduit-services.com
adpk.s3.amazonaws.com
airdwnlds.com
ncapponline.info
uploaded.net
storebox1.info
oi-installer9.com
4shared.com
systweak.com
mypcbackup.com
greatfilesarey.asia
incredimail.com
softonic.com
nicdls.com

FL DP

✓

✓

✓

✓
✓
✓

✓

✓
✓

✓

✓
✓

✓
✓

✓
✓

✓

PPI Ad Oth Cluster
✓
✓

✓

Perion Network
Yontoo
Frostwire
Ask
Mindspark
Bandoo Media
Perion Network
Adpeak
Air Software
Web Pick
Cyando
Web Pick
Adknowledge
4shared
Systweak
JDI Backup Limited
Web Pick
Perion Network
Softonic
Tuguu

Downl.
138,480
106,449
53,592
40,939
26,498
25,429
21,149
14,513
14,342
13,974
10,886
10,109
8,360
8,222
8,104
7,837
7,699
7,408
6,980
6,908

Pub. Children
727
1,148
2,511
125
3,209
905
1,345
36
13,389
13,252
7,816
9,561
7,892
5,649
509
43
7,296
2,571
3,869
1,704

2
67
1
6
6
5
8
2
1
11
366
13
4
120
4
1
8
3
36
14

Table 10: Top ESLDs by number of downloads from them. The two rightmost columns are the number of publishers
and files of the downloads.

Affiliate publisher analysis. We have classified pub-
lisher clusters as PPI services and advertisers, but we
have not examined affiliate publisher clusters. One chal-
lenge with affiliate publishers is that when distribution
happens through a stand-alone PPI installer (rather than
bundles) both the advertiser program and the affiliate
publisher program may appear as children of the PPI ser-
vice in the publisher graph. It may be possible to measure
the number of affiliates for some PPI services by analyz-
ing URL parameters of download events. We leave this
analysis to future work.
Other distribution models. We have examined PUP
distribution through PPI services and advertiser affili-
ate programs. However, other distribution models ex-
ist. These include bilateral distribution agreements be-
tween two parties (e.g., Oracle’s Java distributing the
Ask toolbar [34]) and pre-installed PUP (e.g., Superfish
on Lenovo computers [21]). We observe Superfish dis-
tributed through PPI services prior to the Lenovo agree-
ment, which started in September 2014 after our analysis
period had ended. We leave the analysis of such distribu-
tion models to future work.
Observation period. Our observation period covers 19
months from January 2013 to July 2014. Unfortunately,
WINE did not include newer data at the time of our
study. Thus, we miss newer PUP publishers that joined
the ecosystem after our observation period. However, the

vast majority of PUP publishers examined are still alive
at the time of writing.
Internet population. We have measured the installation
base of PUP (and benign) publishers on WINE hosts. We
have also estimated that our measured WINE population
may be two orders of magnitude lower than that of hosts
connected to the Internet. But, we concede that this esti-
mation is rough and could be affected by different factors
such as selection bias.

11 Related Work

PUP. Potentially unwanted programs have received little
attention from academia. In 2005–2007 Edelman stud-
ied the deceptive installation methods by spyware and
other unwanted software [19]. In 2012, Pickard and Mi-
ladinov [52] studied a PUP rogue anti-malware software
concluding that while not malicious, it only detected
0.3% of the malware and its main purpose was convinc-
ing the user to pay the license. Recently, some works
have hinted at the increased prevalence and importance
of PUP. Thomas et al. [64] study ad injectors, a type of
PUP that modifies browser sessions to inject advertise-
ments, finding that 5% of unique daily IP addresses ac-
cessing Google are impacted. In follow up work, Jagpal
et al. [33] design WebEval, a system to identify mali-

752  25th USENIX Security Symposium 

USENIX Association

14

cious extensions at the core of ad injection. Kotzias et
al. [35] analyze abuse in Windows Authenticode by ana-
lyzing 356K samples from malware feeds. They find that
PUP has been quickly increasing feeds since 2010, that
the vast majority of properly signed samples are PUP,
and that PUP publishers use high file and certificate poly-
morphism to evade security tools and CA defenses such
as identity validation and revocation.

In concurrent work, Thomas et al. [65] analyze the ad-
vertiser software distributed to US hosts by 4 PPI ser-
vices (OutBrowse, Amonetize, OpenCandy, InstallMon-
etizer). They also use SafeBrowsing data to measure
that PPI services drive over 60 million download events
every week, nearly three times that of malware. Both
works are complementary in their study of PPI services
and measuring users affected by PUP. They use a top-
to-bottom approach of infiltrating a few PPI services
plus SafeBrowsing data, while we perform a bottom-to-
top approach starting from files installed on end hosts.
We analyze 19 months from January 2013 to July 2014,
while they analyze 12 months from August 2015 to July
2016. By examining download events on 3.9M WINE
hosts in different countries, our approach enables us to
measure PUP prevalence and achieves a broader cover-
age of the PPI ecosystem. We observe 23 PPI services
including 3 of the 4 in their study. The missing PPI
service is InstallMonetizer, which distributes mostly un-
signed installers.

Also in concurrent work, Nelms et al. [42] analyzed
web-based social engineering attacks that use deceiving
advertisements to convince users to download unwanted
software. They find that most programs distributed this
way are bundles of free software with PUP.
Malware distribution. Prior work has studied malware
distribution through different vectors, which differs from
our focus on PUP distribution. Moschuk et al. [40] crawl
18M URLs finding that 5.9% were drive-by downloads
and 13.4% lead to spyware. Provos et al. [53] study the
prevalence of distribution through drive-by downloads.
Grier et al. [22] analyze the commoditization of drive-
by downloads and compare malware distribution through
different vectors, concluding that drive-by downloads
dominate. Caballero et al. [7] study malware distribution
through PPI services. The PPI services we study differ
in that installations are not silent and are mostly used by
PUP and benign software. Kwon et al. [36] recently use
WINE data to investigate malware distribution through
downloaders. Their work differs in that they do not dis-
tinguish malware from PUP and in that they analyze file
download graphs for individual machines. Instead, we

analyze download relationships between publishers on
aggregate over 3.9M machines over a 19 month time pe-
riod, focusing on PUP distribution through PPI services
and affiliate programs.

12 Conclusion

We have performed the first systematic study of PUP
prevalence and its distribution through PPI services. By
using AV telemetry comprising of 8 billion events on 3.9
million hosts over 19 months, we have found that over
half (54%) of the examined hosts have PUP installed.
The top PUP publishers are highly popular; the top PUP
publisher ranks 15 amongst all software publishers (be-
nign or not). We have built the publisher graph that cap-
tures the who-installs-who relationships between PUP
publishers. We have identified that 65% of the PUP is in-
stalled by other PUP and that 24 PPI services distribute
over 25% of the PUP and advertiser affiliate programs
an additional 19%. We have examined the PUP-malware
relationships finding 11K events where popular malware
families install PUP for monetization and 5,586 events
where PUP distributes malware. PUP-malware interac-
tions are not prevalent and seem to occasionally affect
most top PPI services. We conclude that PUP distribu-
tion is largely disjoint from malware distribution.

13 Acknowledgments

We thank Richard Rivera for his help with the cluster-
ing. This research was partially supported by the Re-
gional Government of Madrid through the N-GREENS
Software-CM project S2013/ICE-2731 and by the Span-
ish Government through the Dedetis Grant TIN2015-
7013-R. All opinions, findings and conclusions, or rec-
ommendations expressed herein are those of the authors
and do not necessarily reflect the views of the sponsors.

References

[1] 7install.

https://web.archive.

org/web/20160306081435/http:
//7install.com/.

[2] AdGazelle. http://adgazelle.com/.

[3] AirSoftware.

com/.

https://airinstaller.

USENIX Association  

25th USENIX Security Symposium  753

15

[4] M. Bailey, J. Oberheide, J. Andersen, Z. M. Mao,
F. Jahanian, and J. Nazario. Automated Classifica-
tion And Analysis Of Internet Malware. In Interna-
tional Symposium on Recent Advances in Intrusion
Detection, Queensland, Australia, September 2007.

[5] BetterInstaller. http://betterinstaller.

somotoinc.com/.

[6] L. Bilge and T. Dumitras. Before We Knew It: An
Empirical Study of Zero-day Attacks in the Real
World. In ACM Conference on Computer and Com-
munications Security, 2012.

[7] J. Caballero, C. Grier, C. Kreibich, and V. Paxson.
Measuring pay-per-install: The commoditization of
malware distribution. In USENIX Security, 2011.

[8] CashMyLinks. http://www.cashmylinks.

com/.

[9] Cinstaller. http://cinstaller.com/.

[10] CodeFuel.

7 reasons codefuel beats all other
http://

pay per install companies, 2015.
www.codefuel.com/blog/7-reasons-
perion-codefuel-beats-all-other-
pay-per-install-companies/.

[11] ConversionAds.

https://web.archive.

org/web/20160217095842/http:
//www.conversionads.com/.

[12] S. Davidoff.
2009.

Interview with an adware au-
thor,
http://philosecurity.
org/2009/01/12/interview-with-an-
adware-author.

[13] DomaIQ. http://www.domaiq.com/en/.

[14] Download Admin. https://web.archive.

org/web/20140208040640/http:
//www.downloadadmin.com/.

[15] Download.com.

com/.

http://www.download.

[16] T. Dumitras¸ and D. Shou.

Toward a Stan-
dard Benchmark for Computer Security Research:
The Worldwide Intelligence Network Environment
(WINE). In EuroSys Workshop on Building Analy-
sis Datasets and Gathering Experience Returns for
Security, April 2011.

[17] T. Dumitras and P. Efstathopoulos. The Prove-
nance Of Wine. In European Dependable Comput-
ing Conference, May 2012.

[18] EarnPerInstall.

https://web.archive.

org/web/20160419013909/http:
//www.earnperinstall.com/.

[19] B. Edelman.

Spyware Installation Methods.
http://www.benedelman.org/spyware/
installations/.

[20] M. Geary. Adknowledge apps distribution op-
http://ppitalk.com/

portunities, 2013.
showthread.php/49-Adknowledge-
Apps-Distribution-Opportunities.

[21] D. Goodin. Lenovo pcs ship with man-in-the-
middle adware that breaks https connections, 2015.
http://arstechnica.com/security/
2015/02/lenovo-pcs-ship-with-man-
in-the-middle-adware-that-breaks-
https-connections/.

[22] Grier et al. Manufacturing Compromise: The
Emergence Of Exploit-as-a-service. In ACM Con-
ference on Computer and Communications Secu-
rity, Raleigh, NC, October 2012.

[23] GuppyGo. http://www.guppygo.com/.

[24] Installaxy.

https://web.archive.

org/web/20151105011933/http:
//installaxy.com/.

[25] InstallBay.

installbay.

http://www.visibay.com/

[26] InstallCore.

com/.

https://www.installcore.

[27] InstalleRex. https://installerex.com/.

[28] Installertech.

installertech.com/.

http://www.

[29] InstallMonetizer.

installmonetizer.com/.

http://www.

[30] InstallMonster. http://installmonster.

ru/en.

[31] installPath.

com.

http://www.installpath.

[32] Internet Archive WayBack Machine. https://

archive.org/web/.

[33] N. Jagpal, E. Dingle, J.-P. Gravel, P. Mavrommatis,
N. Provos, M. A. Rajab, and K. Thomas. Trends
and Lessons from Three Years Fighting Malicious
Extensions. In USENIX Security Symposium, 2015.

754  25th USENIX Security Symposium 

USENIX Association

16

[34] O.

Java.

What

are

the Ask Toolbars?

https://www.java.com/en/download/
faq/ask_toolbar.xml.

[35] P. Kotzias, S. Matic, R. Rivera, and J. Caballero.
Certified PUP: Abuse in Authenticode Code Sign-
ing. In ACM Conference on Computer and Com-
munication Security, 2015.

[36] B. J. Kwon, J. Mondal, J. Jang, L. Bilge, and T. Du-
mitras. The Dropper Effect: Insights into Malware
Distribution with Downloader Graph Analytics. In
ACM SIGSAC Conference on Computer and Com-
munications Security, 2015.

[37] Mediakings. https://web.archive.org/

web/20140517213640/http://media-
kings.com/.

[38] T. Micro. On the actors behind mevade/sefnit,
http://www.trendmicro.com/

2014.
cloud-content/us/pdfs/security-
intelligence/white-papers/wp-
on-the-actors-behind-mevade-
sefnit.pdf.

[39] Microsoft. Windows authenticode portable exe-
cutable signature format, Mar. 21 2008. http:
//download.microsoft.com/download/
9/c/5/9c5b2167-8017-4bae-9fde-
d599bac8184a/Authenticode_PE.docx.

[40] A. Moschuk, T. Bragin, S. D. Gribble, and H. Levy.
A Crawler-based Study of Spyware in the Web. In
Network and Distributed System Security Sympo-
sium, San Diego, CA, 2006.

[41] NativeX. http://nativex.com/.

[42] T. Nelms, R. Perdisci, M. Antonakakis, and
M. Ahamad. Towards Measuring and Mitigating
Social Engineering Malware Download Attacks. In
USENIX Security Symposium, August 2016.

[43] Net

Cash

Revenue.

netcashrevenue.com/.

http://

[44] Nosibay. http://www.nosibay.com/.

[45] Oneinstaller.

https://web.archive.

org/web/20150220020855/http:
//oneinstaller.com/.

[47] Opswat Antivirus

and Threat Report,

Jan-
https://www.opswat.com/

uary 2014.
resources/reports/antivirus-
january-2014.org/.

[48] PayPerInstall.

com/.

http://payperinstall.

[49] Perinstallbox. http://www.setupbundle.

com/index.php.

[50] PerInstallBucks.

perinstallbucks.com/.

[51] PerInstallCash.

perinstallcash.com/.

https://

http://www.

[52] C. Pickard and S. Miladinov. Rogue software: Pro-
tection against potentially unwanted applications.
In Malicious and Unwanted Software (MALWARE),
2012 7th International Conference on, pages 1–8.
IEEE, 2012.

[53] N. Provos, P. Mavrommatis, M. A. Rajab, and
F. Monrose. All Your Iframes Point To Us.
In
USENIX Security Symposium, San Jose, CA, July
2008.

[54] Public Suffix List. https://publicsuffix.

org/.

[55] Purebits. http://purebits.net/.

[56] RevenueHits.

https://web.archive.

org/web/20130805140617/http:
//www.revenuehits.com/.

[57] RevenYou. http://www.revenyou.com/.

[58] M. Sebasti´an, R. Rivera, P. Kotzias, and J. Ca-
ballero. AVClass: A Tool for Massive Malware La-
beling. In International Symposium on Research in
Attacks, Intrusions and Defenses, September 2016.

[59] P. Security.

Malware still generated at a
rate of 160,000 new samples a day in Q2
2014.
http://www.pandasecurity.
com/mediacenter/press-releases/
malware-still-generated-rate-
160000-new-samples-day-q2-2014/.

[60] Smart WebAds. http://www.smartwebads.

com/.

[61] Softonic. www.softonic.com.

[46] Open Candy. http://opencandy.com/.

[62] Solimba. https://solimba.com/.

USENIX Association  

25th USENIX Security Symposium  755

17

[63] Sterkly. http://www.sterkly.com/.

[64] K. Thomas, E. Bursztein, C. Grier, G. Ho, N. Jag-
pal, A. Kapravelos, D. McCoy, A. Nappa, V. Pax-
son, P. Pearce, N. Provos, and M. A. Rajab. Ad
Injection at Scale: Assessing Deceptive Advertise-
ment Modifications. In IEEE Symposium on Secu-
rity and Privacy, May 2015.

[65] K. Thomass, J. A. E. Crespo, R. Rastil, J.-
M. Picodi, L. Ballard, M. A. Rajab, N. Provos,
E. Bursztein, and D. Mccoy.
Investigating Com-
mercial Pay-Per-Install and the Distribution of Un-
wanted Software. In USENIX Security Symposium,
Aug. 2016.

[66] Verti.

http://www.

vertitechnologygroup.com.

[67] VirusTotal.

com/.

http://www.virustotal.

[68] G. Wicherski. pehash: A novel approach to fast
malware clustering.
In 2nd USENIX Workshop
on Large-Scale Exploits and Emergent Threats
(LEET), 2009.

A Additional Results

Start Now

Publisher
Popeler System

Rank
1
2 Daniel Hareuveni
3
4 Mail.Ru
Softonic International
5
Bon Don Jov
6
7
Stepan Rybin
8 WeDownload
9
10
11
12
13 Vetaform Developments
14 Outbrowse
15
16
17 Mari Mara
18
19 Give Away software
20

Payments Interactive
Tiki Taka
Stanislav Kabin
Safe Software

appbundler.com
Rodion Veresev

Firseria

Jelbrus

Samples

326,530
138,159
117,930
117,920
69,233
68,937
68,390
66,332
41,128
37,072
36,893
36,602
36,001
35,832
34,895
34,696
31,031
29,940
26,541
23,457

13.2%
5.6%
4.8%
4.8%
2.8%
2.8%
2.8%
2.7%
1.7%
1.5%
1.5%
1.5%
1.5%
1.4%
1.4%
1.4%
1.3%
1.2%
1.1%
0.9%

Table 11: Top 20 publishers in the feed of 11M samples
by number of samples and percentage over all samples
signed and flagged by at least 4 AV engines.

PPI Service

EarnPerInstall [18]

#
1 AdGazelle [2]
2
3 GuppyGo [23]
Installaxy [24]
4
5
InstallMonetizer [29]
6 MediaKings [37]
7 NetCashRevenue [43]
8
9
10
11
12

PayPerInstall [48]
PerInstallBox [49]
PerInstallBucks [50]
PerInstallCash [51]
PureBits [55]

Reseller

✓

✓

✓

✓

Table 12: PPI services found through manual analysis
on PPI forums and other Internet resources that are not
present in our dataset. The reseller data comes from [65].

756  25th USENIX Security Symposium 

USENIX Association

18

