2014 IEEE Symposium on Security and Privacy

ANONIZE: A Large-Scale Anonymous Survey System

Susan Hohenberger

Johns Hopkins University

susan@cs.jhu.edu

Steven Myers

Indiana University
samyers@indiana.edu

Rafael Pass

abhi shelat

Cornell University
rafael@cs.cornell.edu

University of Virginia

abhi@virginia.edu

Abstract—A secure ad-hoc survey scheme enables a
survey authority to independently (without any interac-
tion) select an ad-hoc group of registered users based
only on their identities (e.g., their email addresses), and
create a survey where only selected users can anonymously
submit exactly one response. We present a formalization
of secure ad-hoc surveys and a provably-secure implemen-
tation in the random oracle model, called ANONIZE. Our
performance analysis shows that ANONIZE enables securely
implementing million-person anonymous surveys using a
single modern workstation. As far as we know, ANONIZE
constitutes the ﬁrst implementation of a large-scale secure
computation protocol (of non-trivial functionalities) that
scales to millions of users.

I. INTRODUCTION

We study the basic conﬂict between anonymity and
authenticity in large network settings. Companies, uni-
versities, health providers and government agencies
routinely conduct asynchronous and real-time data col-
lection surveys for targeted groups of users over the In-
ternet. To do so, they aim for authenticity (i.e., ensuring
that only the legitimate users can participate in the data
collections) and anonymity (i.e., ensuring that the there
is no link between the legitimate user and his/her data
so that users are more likely to submit honest feedback).
The intrinsic conﬂict between these two goals may
result in users self-censoring or purposely biasing data
they submit.

A simple example is a course evaluation for a uni-
versity class. A typical implementation of such a survey
requires a trusted third party (such as the university,
or some external party) to ensure that feedback is
collected anonymously from the participants and that
only authorized participants, i.e., the students enrolled
in a particular class, can submit feedback for that class.
In such trusted-party implementations, students are re-
quired to authenticate themselves with their university
IDs and thus leave a link between their evaluation and
their identity; they are trusting the survey collector to
keep such links private.

Assuming that the survey collector acts as a trusted
third party is dangerous. Even if the survey collector
intends to keep the links between users and their surveys
private, its computer may be stolen or broken into,
and the information leaked. For instance, in 2009, a
computer at Cornell was stolen, containing sensitive

personal information, such as name and social security
number, for over 45,000 current and former university
members [1]. Additionally, even if users have full conﬁ-
dence in the the trusted third party, and in particular, its
ability to keep its data secure, developing an anonymous
survey system using such a trusted party still requires
some care. For example, in the implementation of course
reviews at the University of Virginia, side channel infor-
mation indicating who has already ﬁlled out the survey
may leak information about the order in which students
participate. Later, the order of the students’ comments
in the aggregated responses may be correlated to break
anonymity [2].

Furthermore, in many situations, jurisdictional bound-
aries or legal requirements make it unfeasible to rely on
solutions with external trusted third parties: it may be
illegal to store sensitive patient information on a third-
party system; similarly, many countries do not permit
sensitive data to be stored on servers run by foreign
corporations due to the potential for this data to be
seized [3].

For these reasons, we seek cryptographic solutions
to the problem of anonymous surveys that offer secu-
rity guarantees where anonymity and authenticity hold
without needing to trust a third party.

Cryptographic voting techniques described in prior
work may offer a partial solution to this problem (see
e.g., [4], [5], [6], [7], [8]). In such schemes, each survey
consists of two steps: 1) users authenticate themselves
to a server and anonymously check out a single-use
“token”; the token itself carries no link to the user’s
identity. 2) a user can then use her token to participate
in the speciﬁed survey. Such schemes provide good
anonymity assuming that users actually separate steps
1 and 2 with a reasonably long time lag (otherwise
there is a clear time link between the user and its
data). But if users are required to separate the two
steps by, say, a day, the ease-of-use of the survey is
signiﬁcantly hampered and become much less conve-
nient than “non-anonymous” surveys (or anonymous
surveys employing a trusted third party). Additionally,
the extra steps required to authenticate for each survey
may be onerous. Consequently, such techniques have
gained little traction.

© 2014, Susan Hohenberger. Under license to IEEE.
DOI 10.1109/SP.2014.31

375

A. Our innovation: electronic ad-hoc surveys

In this paper, we consider a general solution to the
problem of anonymously collecting feedback from an
authenticated group of individuals by introducing the
notion of an ad-hoc survey. The “ad-hoc” aspect of
this notion means that anyone can select a group of
individuals and create a survey in which those and only
those individuals can complete the survey at most once;
additionally, the survey initiator can initiate this survey
knowing only the identities (e.g., the email addresses) of
the users in the ad-hoc group—no further interaction be-
tween the survey initiator and the users is required.1 As
such, our method provides essentially the same ease-of-
use as traditional (non-anonymous) electronic surveys
(and it thus is expected to increase user participation
and make the feedback submitted more valuable).

As we demonstrate, ad-hoc surveys admit practical
and efﬁcient solutions for very large surveys: we present
an ad-hoc survey scheme, ANONIZE, a proof of secu-
rity for the cryptographic protocols in ANONIZE, and
an implementation of the protocol. ANONIZE supports
millions of “write-in” (i.e., collection of arbitrary strings
of data) surveys in minutes. As far as we know, this
is the ﬁrst implementation of a provably-secure2 multi-
party protocol that scales to handle millions of users.
Additionally, we prove security of our scheme even
if the adversary participates in an arbitrary number of
concurrent surveys.

B. Ad-hoc Surveys in more detail

In more details, there are three parties in an ad-hoc
survey system: a registration authority (RA) that issues
master user tokens, a survey authority (SA) that can
create surveys, and users that provide survey data. A
user must ﬁrst register with the RA and retrieve a secret
“master user token”. This is a single token that can
be used for all future surveys the user participates in.
Anyone can act as an SA by choosing a uniquel survey
ID and publishing a list of identities that are permitted to
participate in that survey. The list of identities that can
participate in a particular survey can grow dynamically,
and the SA can create a survey without any interaction
with others. Finally, a user who is on the list of valid
identities for a survey can non-interactively submit a
response to the survey by simply routing one message
to the SA (through an anonymous network like Tor, or
anonymous proxy relay).

To exemplify this approach and informally discuss
the anonymity/authenticity properties it provides, we
consider the course evaluation scenario.

1) Student Registration: When a student is asked to
set-up his college/university account information (while
proving his identity using traditional, non-electronic,
methods), the student also generates an unlinkable mas-
ter user token that is tied to his school email identity
(e.g., his email address). This step can also be done at a
later stage if the student desires (or if the student loses
his credential), but it only needs to be done once.

2) Course Survey Setup: Whenever a course admin-
istrator wishes to set-up a course survey, she generates
a survey key based only on the actual identities (e.g.,
the email addresses) of the course participants.

3) Survey Execution: Upon ﬁlling out a survey with
its associated survey key, the student’s client (either
computer or smart phone) combines the survey key and
her master user token to generate an unlikable one-time
token that she can use to complete the survey. The one-
time token satisﬁes two properties: 1) it carries no link
to the student’s identity (thus we have anonymity), and
2) for a given survey key, the student can obtain at
most one such token (and thus we ensure that a student
can only complete the survey once3). The results of the
survey can now be tabulated, and, possibly announced.
We emphasize that once Step 1 has been done (pre-
sumably once the students enroll into college), Steps 2
and 3 can be repeatedly performed. The participants do
not need to check-out new single-use tokens for each
survey; rather their client uses the master user token to
create a unique single-use token for this survey without
any interaction (that could deanonymize the student).
Part of our contribution is to precisely deﬁne security
properties of ad-hoc surveys such as anonymity (intu-
itively, that there is no link between users and the sur-
veys they submit), and authenticity (intuitively, that only
authorized users can complete the survey, and they can
complete it only once). As mentioned, we are interested
in providing security not only for a single survey, but
also if an attacker participates in many surveys, be they
in the past, concurrent, or in the future. A common
approach for deﬁning security in such circumstances
is to formalize the notion of secure ad-hoc surveys
within the framework for Universal Composability [9].
Doing so permits one to analyze the protocol under a
single instance and deduce that it also remains secure
under concurrent executions. Unfortunately, there are
well-known inefﬁciencies with this approach. Rather,
to enable an efﬁcient implementation, we provide di-
rect game-based deﬁnitions of security and directly
analyze the security of our protocol under concurrent
executions—this is analogous with other cryptographic

1Before users can complete a survey, we additionally require them
to register their identity. We emphasize that this registration is done
only once and can be used for any number of subsequent surveys.

2By “provably-secure”, we only refer to the cryptographic protocol.

3Our systems support the (optional) ability for the user to change
her response (before the voting deadline) in a manner that replaces
her previous submission, but in no other way leaks any information
about her identity.

376

game-based deﬁnitions, e.g., blind signatures [10]; we
emphasize that although related notions of anonymity
and authenticity have been deﬁned in the literature
for other applications, our setting is considerably more
complex and thus the actual deﬁnitions are different.

C. Anonize in more detail

Our system is constructed in two steps. We ﬁrst
provide an abstract implementation of secure ad-hoc
surveys from generic primitives, such as commitment
schemes, signatures schemes, pseudo-random func-
tions (PRF) and generic non-interactive zero-knowledge
(NIZK) arguments for NP4. We prove the security of the
abstract scheme based on the assumption that all generic
primitives employed are secure. Note that we have taken
explicit care to show that our schemes remain secure
even when the adversary initiates many concurrently
executing sessions with the system.

In a second step we show that (somewhat surpris-
ingly) the generic scheme can be instantiated with
speciﬁc commitment schemes, signatures schemes, PRF
and NIZKs to obtain our efﬁcient secure ad-hoc survey
scheme ANONIZE (which now is based on speciﬁc
computational assumptions related to the security of the
underlying primitives in the Random Oracle Model).
The surprising aspect of this second step is that our
generic protocol does not rely on the underlying prim-
itives in a black-box way; rather, the NIZK is used to
prove complex statements which require code of the
actual commitments, signatures and PRFs used. In this
second step, we rely on ideas similar to those under-
lying efﬁcient constructions of anonymous credentials
in bilinear groups [11], [12], although our constructions
differ in a few ways. As far as we know, our scheme is
also one of the ﬁrst implementations of a cryptographic
scheme that is concurrently-secure.

Let us brieﬂy provide a high-level overview which
omits several important features, but conveys the intu-
ition of our abstract protocol (we assume basic familiar-
ity with the concepts of commitment schemes, signature
schemes, PRFs and NIZKs).

1) Registration: A user with identity id registers with
the RA by sending a commitment to a random seed sid
of a pseudo-random function (PRF) F and providing a
NIZK that the commitment is well-formed. If the user
has not previously been registered, the RA signs the
user’s name along with the commitment. The signature
returned to the user is its “master user token”. The
security property required here is weaker than that of a
blind signature.

2) Survey: To create a survey, an SA publishes a list

of signed user identities along with a survey id, vid.

4As we show, we actually need a new variant of standard NIZKs.

3) Response: To complete a survey for survey id
vid, a user id generates a single-use token Fsid (vid)
(by evaluating the PRF on the seed sid with input vid)
and presents a NIZK that it “knows a signature by the
RA on its identity id and a commitment to a seed sid”
and that it “knows a signature by the SA on its id” and
that the single-use token is computed as Fsid (vid). The
user’s actual survey data will be part of and thereby
authenticated by this NIZK.

Roughly speaking,

the NIZK proof in the survey
completion step ensures that only authorized users can
complete the survey, and that they can compute at most
one single-use token, and thus complete it at most
once. 5 Anonymity, on the other hand, roughly speaking
follows from the fact that neither the RA nor the SA
ever get to see the seed sid (they only see commitments
to it), the zero-knowledge property of the NIZKs, and
the pseudo-randomness property of the PRF.

Proving this abstract protocol secure is non-trivial.
In fact,
to guarantee security under concurrent exe-
cutions, we introduce and rely on a new notion of
a simulation-extractable NIZK (related to simulation-
sound NIZK [13] and simulation-extractable interactive
zero-knowledge arguments [14], [15]).

To enable the second step of our construction (i.e.,
the instantiation of the abstract protocol using speciﬁc
primitives), we demonstrate a simple and efﬁcient way
of implementing simulation-extractable NIZK in the
Random Oracle Model by relying on the Fiat-Shamir
Heuristic [16]. Finally, the key to the construction is
choosing appropriate commitments, signatures and PRF
that can be “stitched together” so that we can provide
an efﬁcient NIZK for the rather complex statement used
in the abstract protocol.

D. Related notions and techniques

Ad-hoc surveys are related to, but different from, a
number of primitives previously considered in the liter-
ature such as group signatures, ring signatures, voting
schemes and anonymous credentials. Roughly speaking,
group [17], [18], [19] and ring [20] signatures allow
members of a set of users to sign messages in a way
that makes it indistinguishable who in the set signed
the message (in the case of group signatures the set is
ﬁxed 6, whereas in the case of ring signatures the set
can be selected “ad-hoc”). This property is similar to the

5If the user wants to replace her survey response before the deadline
and this is allowed by the system, then she can create a new NIZK
with new data for the same Fsid (vid) value. The old survey with this
value can be deleted.

6The desirability of making group signatures dynamic was ad-
dressed by Bellare, Shi and Zhang [21]. Their solution, however,
requires that every group member or potential group member has
their own personal public key, established and certiﬁed, e.g., by a PKI,
independently of any group authority. Our ad-hoc survey solution does
not require this.

377

anonymity property of ad-hoc survey, but unfortunately,
the authentication property these notions provide is
insufﬁcient for our setting—in a ring signature scheme,
a user may sign multiple messages with impunity which
corresponds to the ability to complete the survey mul-
tiple times in our context. Voting schemes [4], [5], [6],
[7], [8] on the other hand do provide both the anonymity
and the authenticity properties we require; however, they
do not allow for the authenticated users to be selected
ad-hoc for multiple elections.

An anonymous credential system [22], [23], [24],
[11] allows users to obtain credentials from authorities
and to anonymously demonstrate possession of these
credentials. In essence such systems provide methods
for providing, a “zero-knowledge proof of knowledge
of a signature on a set of attributes.” As mentioned, the
NIZKs we use rely on intuitions similar to those used
in constructions of anonymous credentials (most closely
related to [11] and the electronic cash/token extensions
in [25], [12]), but we have different goals and rely
on different complexity assumptions. Moreover, since
anonymous credentials typically are not analyzed under
concurrent executions, we must develop new techniques
for the security analysis.
E. Our Implementation

One of the key points of our system is that it can
be implemented and can easily handle large numbers of
users with moderate resources. The computational costs
on the users are quite low as well, with a typical desktop
being able to compute the worst-case scenario in under
a few seconds, using a single core of the machine.
Thus we argue our system scales to manage that vast
majority of practical surveying needs at costs that are
easily affordable.

II. AD-HOC SURVEYS

An Ad-hoc Survey Scheme is a protocol involving

three types of players:
— A single Registration Authority (RA).
— One or multiple Survey Authorities (SA).
— Users; each user is associate with a public user

identity id (e.g., its email address).

An

ad-hoc

We assume that the RA has the ability to set up a
secure session (private and authenticated) with the user
associated with a particular user identity. Each user
additionally has the ability to setup an anonymous
connection to the SA when returning their survey.
tuple

of
U , GenSurvey,
algorithms (GenRA,GenSA,Reg
formalize
Authorized, Submit, Check) which we
shortly. To gain some intuition,
let us ﬁrst explain
how these algorithms are intended to be used in a
system and informally explain what types of security
requirements we want from the algorithms.

is
RA,Reg

scheme

survey

a

System Set-up:

— The RA generates a public key-pair pkRA, skRA ←
GenRA(1n); pkRA is made public and skRA is
secretly stored by the RA.
— Each SA generates a public key-pair pkSA, skSA ←
GenSA(1n); pkSA is made public and skSA is
secretly stored by the SA.7

— For systems that require the use of a Common
Reference String (CRS); a CRS is generated and
made publicly available. For simplicity of notation,
we omit the CRS in all the procedures below and
simply assume that all these procedures get the
CRS as an input. Likewise, for systems in the
Random Oracle model, we assume the procedures
below have access to the Random Oracle.
User Registration: To use the system, users need
to register with the RA; at this point the user and the
) which allows
RA execute the protocol (Reg
the user to check out an unlinkable “master credential”.
A user with identity id proceeds as follows:

, Reg

RA

U

1) The user sets up a secure session with the RA.
2) The RA checks that user identity id previously has
not been registered. If it has, the RA closes the
session. Otherwise, the RA and the user invoke the
) on the common
interactive protocol (Reg
input 1n, id.

, Reg

RA

U

3) If the protocol ends successfully, the RA stores that
user identity id has been registered, and the user
secretly stores the output as credid.
Survey Registration: Whenever an SA wants to set-
up a survey with identiﬁer sid, it generates a “survey
public-key” based on the identities of the participants
(and its own secret key). More precisely, the SA on
input a survey identiﬁer sid and a list L of user identities
(they may be previously registered or not) computes and
makes public pksid ← GenSurvey(1n, sid, L, skSA).

Completing a Survey: Given a registered survey
with identiﬁer sid and its associated public-key pksid,
each “authorized” user idi can combine its master cre-
dential credid with the survey identiﬁer sid and public-
key pksid to generate an unlikable “one-time token” that
it can then use to make a submission in the survey.
Roughly speaking, the “one-time token” satisﬁes two
properties: 1) it carries no link to the students identity
(thus we have anonymity), and 2) for a given “survey
key”, the student can obtain at most one such token (and
thus can only submit one response).

More precisely, user

id with master credential
credid submits the message m as the completed
survey by privately executing the algorithm Sub =
(tok, m, tokauth) ← Submit(1n, sid, pksid, m, credid)

7Our security properties hold even if new SAs are added on-the-ﬂy.

378

and then submitting Sub to the SA through an
anonymous channel;
tok is the “one-time token”,
and tokauth is an authenticator required to bind the
message m to the one-time token, and to ensure
uniqueness of the one-time token. SA checks whether
the submission is correctly computed by executing
Check(pkSA, pkRA, sid, pksid, Sub); if it outputs accept
it stores the submission. If a submission with the same
tok has been previously stored (i.e., if a Sub of the
(cid:2)
) has already been stored, the
form (tok, m
old record is removed. (Or alternatively, the new Sub is
not stored.)

, tokauth

(cid:2)

Announcing the results: Once all the submissions
have been collected, the SA may (depending on exter-
nal privacy requirements) publish a list of all stored
submissions Sub = (tok, m, tokauth).

Audit Procedures: The system also includes au-
dit procedures. First, Users can check that their sub-
mission was “counted” by simply inspecting that
their
submission is output. Second, a User may
use Check(pkSA, pkRA, sid, pksid, Sub) to check whether
Sub is a valid submission (i.e., user can check that
there is no “ballot/survey-stufﬁng”). Finally, to ensure
that a survey is not targeted to a particular user (for
de-anonymization purposes), the user may use function
) to check whether user
Authorized(pkSA, sid, pksid, id
is also authorized for survey sid with public key
id
pksid.

(cid:2)

(cid:2)

Key features and Security Properties: A crucial
aspect of an ad-hoc survey is the privacy property:
even if the RA and SA are arbitrarily corrupted (and
in collusion) they cannot
learn anything about how
particular users answered submissions (or even learn
correlations between groups of users). The key security
property of our ad-hoc survey is that only authorized
users can complete a survey, and furthermore they can
complete it at most once.

A. Deﬁnition of an Ad-hoc Survey

Deﬁnition 1: An ad-hoc survey scheme Γ is an
8-tuple of PPT algorithms and interactive PPTs
U , GenSurvey, Authorized,
(GenRA,GenSA,Reg
Submit, Check) where

RA,Reg

• GenRA(1n) outputs a key-pair pkRA, skRA.
• GenSA(1n) outputs a key-pair pkSA, skSA.
• Reg

(skRA, 1n, pkRA, idi) is an interactive PPT

RA

that outputs either success or fail.

• Reg

U

(1n, pkRA, id) is an interactive PPT that out-

puts a bitstring credid or fail.

• GenSurvey(1n, sid, L, skSA) outputs a bitstring
pksid. Here sid is a unique arbitrary identiﬁer and
L is a description of the set of users eligible to
participate in the survey.

• Authorized(pkSA, sid, pksid, id) outputs either YES

• Submit(1n, sid, pksid, m, credid) outputs Sub =

or NO.

(tok, m, tokauth).

• Check(pkRA, pkSA, sid, pksid, Sub) outputs either

accept or fail.
A remark on the Authorized procedure: We are in-
terested in schemes where the description of the autho-
rized procedure makes it possible to naturally interpret
the set of users that are allowed to complete a survey
(and indeed, our constructions fall into this category).
For instance, the description of the Authorized proce-
dure speciﬁes a list of user identities, or speciﬁes a list
of user identities with wildcard (e.g., ∗@∗.cornell.edu).
In our speciﬁc implementation, the public key for the
survey pksid consists of a list of authorized users.

B. Correctness

We proceed to deﬁne what it means for an ad-hoc
survey scheme to be correct. The following deﬁnition
requires that for every set of users L, and every user
id ∈ L, if an SA sets up a survey for L, and if the
user correctly registers with the RA, then the user will
be authorized to complete the survey; furthermore, for
every submission m, if user id correctly submits m, this
submission will pass the check.
Deﬁnition 2: An ad-hoc survey scheme Γ is correct
if there exists a negligible function μ(·), such that the
following experiment outputs fail with probability at
most μ(n) for every n ∈ N, sid, m ∈ {0, 1}n, set L
of n-bit strings, id ∈ L:
– (vkRA, skRA) ← GenRA(1n)
– (vkSA, skSA) ← GenSA(1n)
– Set (outRA, outU) to the result of the protocol
(Reg
– Output fail if either outRA or outU is fail, otherwise
let credid = outU.
– vksid ← GenSurvey(1n, sid, L, skSA)
– Output fail if Authorized(vkSA, sid, vksid, id) = NO.
– Sub ← Submit(1n, sid, vksid, m, credid)
– Output Check(vkSA, vkRA, sid, vksid, Sub)

(skRA, 1n, vkRA, id), Reg

(1n, vkRA, id))

RA

U

C. Privacy and Security

The following deﬁnition stipulates that the SA(s) and
RA and malicious users, even if arbitrarily corrupted,
cannot distinguish the submissions of two authorized
honest users, even for an adaptively chosen participant
list, user identities and submission messages, and even
if they may see the submission messages of the two
participants for any messages of their choosing, in any
other survey of its choice. Thus, even if an attacker
knows what submissions correspond to which users in
any surveys of its choice (before and after the survey

379

of interest), it still cannot identify what these users
submitted for a survey of interest. The deﬁnition mirrors
the deﬁnition of CCA-secure encryption: we give the
attacker the opportunity to generate an arbitrary public-
key for the RA, pick two user identities id0, id1, ask the
users to register with him, and then make oracle queries
to the users’ Submit procedure. Finally, the attacker
selects a survey consisting of a public-key for a SA, a sid
and a public key for the survey pksid such that id0, id1
are both authorized (for which it has not yet queried
the Submit oracle on sid), a pair of messages m0, m1,
and then sees two submissions. The attacker must guess
whether the two submissions correspond to ones from
id0 and id1 or from id1 and id0 respectively; the attacker
continues to have oracle access to the users’ Submit
procedure during this decision-making phase but cannot
make queries on the sid.

Deﬁnition 3: An ad-hoc survey scheme Γ is unlink-
able if for every non-uniform PPT A the ensembles
(1n, A)}n∈N are compu-
{EXEC
b
(1n, A) is de-
tationally indistinguishable where EXEC
ﬁned as follows:

(1n, A)}n∈N, {EXEC

0

1

b

(1n, A)

U

U

for

any

different

(1n, vkRA, id)

(1n, vkRA, id)

interacts
two

for
(cid:5)= ⊥ completes,

EXEC
– (vkRA, skRA), z ← A(1n)
– A(1n, z)
concurrently
with
ids
Reg
id0 and id1. Whenever an interaction with some
the
Reg
remainder of the experiment, A gets oracle access
to Submit(1n,·,·,·, credid). Next, A outputs a target
survey:
– (vkSA, sid, vksid, id0, id1, m0, m1, z
– Output fail if Authorized(vkSA, sid, vksid, id(cid:2)) = fail
or if A has queried Submit(1n, sid,·, mj, credid(cid:2) ) for
either (cid:2), j ∈ {0, 1}
– Let Sub(cid:2) = Submit(1n, sid, vksid, m(cid:2), credid(cid:2)⊕b )
for both (cid:2) = 0 and (cid:2) = 1 and ﬁnally output
A(1n, (Sub0, Sub1), z

) ← A(1n, z)

)

(cid:2)

(cid:2)

1) Justiﬁcation for the deﬁnition: We want to allow
the adversary to participate in multiple surveys, with
multiple honest submitters, and see the submissions of
as many honest submitters as it wishes. In particular, we
can consider a deﬁnition in which the following changes
are made. The adversary is now permitted to register
an unlimited number of honest users by interacting
U under the condition that no two have the
with Reg
same id. The adversary, for an arbitrary k surveys and
(cid:2) ≥ 2 honest submitters in each survey, is allowed to
output two k × (cid:2) matrices of ids ID
1, a vector of
k sids, (cid:3)sid, a vector of k the surveys’ veriﬁcation-keys
(cid:3)vksid and two k × (cid:2) matrices of messages M 0, M 1. We
require the submissions be legitimate, thus we require

0,ID

380

c, c ∈ {0, 1} be
that all of the ids in a given row of ID
distinct. Similarly, all the sids in (cid:3)sid must be distinct,
corresponding to distinct surveys (if one wanted to
have more ids in a given survey, the adversary could
simply increase the size of (cid:2)). Finally, all of the surveys
need to be “well formed” for every i ∈ [k], j ∈ [(cid:2)],
1
0
both ID
i,j are authorized to participate in
i,j and ID
survey sidi. Finally, of course, we do not permit the
attacker to query the Submit oracle for submissions by
idi,j in survey sidi). We call this notion multi-survey
unlinkability. We note that this is a form of concurrent
security as it guarantees unlinkability no matter how
the adversary generates multiple surveys and schedules
the registration of individuals. In the full version of this
paper, we formally deﬁne this notion and show that it
is implied by Deﬁnition 3.

2) Security: Let us now turn to deﬁne security.
The following deﬁnition stipulates that only authorized
users may complete surveys, and only one of their
submissions is counted. We require that this holds even
if the user attacker may register multiple identities, and
see submissions of the attacker’s choice for any other
user of its choice and in any survey (this one, or any
other survey).

if

to

access

oracles

attacker

submission

To begin, we formalize what

it means to give
for
the
users of its choice by deﬁning the stateful oracle
(cid:2)
(1n, sid, pksid, m, id, pkRA, skRA) that operates
Submit
as follows:
the oracle has not previously been
let (outRA, credid) ←
queried on the identity id,
(1n, pkRA, id));
next
(Reg
output Submit(1n, sid, pksid, m, credid). If the oracle
has previously been queried on the identity id, recover
the previously computed credential credid, and directly
output Submit(1n, sid, pksid, m, credid).

(skRA, 1n, pkRA, id), Reg

RA

U

Deﬁnition 4: An ad-hoc survey scheme Γ is secure
against malicious users if for every non-uniform PPT A,
every polynomial p(·), there exists a negligible function
μ(·), such that the following experiment outputs success
with probability at most μ(n) for every n ∈ N,
MU(A, n)
– (vkRA, skRA) ← GenRA(1n)
SA) ← GenSA(1n)
i
– For i = 1 to p(n), let (vk
SA, sk
– Throughout the rest of the experiment, A has access
to oracle GenSurvey(1n,·,·, sk
i
SA) for any i, and
(1n,·,·,·, vkRA, skRA).
Submit
– Let adversary A(1n) concurrently interact with
(skRA, 1n) with adaptively chosen, but unique,
Reg
user identities id ∈ {0, 1}n of its choice. (That is,
A can only use each user identity id in a single
(cid:2) denote the list of user
interaction with Reg
identities selected by A, and let z denote the output
of A after this interaction ﬁnishes.

RA.) Let L

RA

(cid:2)

i

(cid:2)

(cid:2)

i
SA)

, L, sid, i ← A(1n, z)

– z
– vksid ← GenSurvey(1n, sid, L, sk
– S ← A(1n, z
, vksid)
– Output success if
• |S| > |L ∩ L
(cid:2)| and
• Check(pkSA, pkRA, sid, pksid, Sub) accepts for all
Sub ∈ S,
) ∈ S2,
• For (tok, m, tokauth), (tok
tok (cid:5)= tok
• For all (tok, m, tokauth) ∈ S, (tok, m, tokauth
(cid:2)
)
(cid:2)
was never received as an output from A’s Submit
oracle (where tokauth
is an arbitrary string) when
queried with sid as second input.
These four conditions roughly correspond to the
determining whether A produced more submissions than
allowed, all submissions are valid, all submissions have
different token-numbers, all token-numbers are new, and
no submissions have been modiﬁed.

, tokauth

(cid:2)
, m

.

(cid:2)

(cid:2)

(cid:2)

(cid:2)

Remark: Note that in the above deﬁnition, A is
allowed to talk to p(n) different SAs. It is without loss
of generality to assume that A talks to just a single
SA (that is p(n) = 1). This follows from standard
technique, and is omitted for space reasons.

III. AN AD-HOC SURVEY SCHEME BASED ON

GENERAL ASSUMPTIONS

We assume the reader is familiar with signature
schemes secure against adaptive-chosen message at-
tacks [26], non-interactive commitment schemes [27],
and pseudorandom functions [28]; see [29].

A. Concurrent simulation extractable NIZK

We introduce the new notion of tag-based concurrent
simulation-extractable (cSE) NIZK (a non-interactive
version of tag-based concurrent simulation-extractable
zero-knowledge from [14], [15]); this notion is closely
related to the notion of non-malleability in the explicit
witnesses sense of [30] (which in turn relies on the
notion of simulation-soundness of [13]), and universally
composable UC NIZK of [9]. The former is (a-priori)
weaker than ours in that it only requires extraction from
a single protocol (this notion is referred to as “many-
one” simulation-extractability in [14], [15]) whereas the
latter is stronger in that
it requires extractability to
be done “on-line”. Relying on this new intermediate
notion allows us to strike the right balance between
security and efﬁcient implementability: in particular, we
will present simple and extremely efﬁcient concurrent
simulation-extractable NIZKs in the Random Oracle
model, whereas UC NIZK incurs more overhead.

We ﬁrst start by deﬁning concurrent simulation ex-
tractability. Imagine an attacker A playing man-in-the-
middle between a legitimate prover on the left interac-

381

tion, and a legitimate veriﬁer on the right. More specif-
ically, in the left interaction, attacker A can request
proofs of any true statement x of its choice using any
tag tag of its choice. In the right interaction, A outputs a
list of tags, statements and proofs ( (cid:3)tag, (cid:3)x, (cid:3)π) as well as a
string aux. For every such A, we require the existence
of a simulator-extractor SE that must reconstruct the
view of A and additionally produce witnesses for all
accepting statement-proofs (x, π) ∈ ((cid:3)x, (cid:3)π) on the right
that use a new tag.

(cid:2)

Below, we assume a proof system (D, P, V ) where D
generates a CRS, P is a prover, and V is a veriﬁer. The
function W provides witnesses to theorem statements.
Let real(1n, A, W, z) denote the output of the following
experiment: Run ρ ← D(1n); next give A(1n, z, ρ)
(·,·,·) where P
(cid:2)
(tag, x, ρ) runs
oracle access to P
(cid:2)
(cid:2)
), ρ) where view
is A’s view up
P (tag, x, W (x, view
until this query; ﬁnally, outputs the view of A (that is
a sequence of tag-statement-proof tuples
(tag, x, π) and
the CRS ρ. Given a view view of A, we interpret the
output of A as a sequence of tag-statement-proof tuples
) and some additional output aux. Deﬁne
(tag
the predicate fail(view, (cid:3)w) = 1 if and only if A, when
given the view view, containing the CRS ρ, outputs a
proof π of some statement x with respect to tag tag
such that a) none of the proofs received by A in the
view view use tag tag, b) V accepts the proof π—that
is, V (tag, x, ρ, π) = 1, and c) (cid:3)w does not contain a
witness for x.

, x

, π

(cid:3)

(cid:2)

(cid:2)

(cid:2)

Deﬁnition 5 (Concurrent Simulation-Extractability):
Let (D, P, V ) be a non-interactive proof system for
the language L. We say that (D, P, V ) is concurrently
simulation extractable (cSE) if for every PPT A, there
exists an expected PPT simulator-extractor SE such
that the following two conditions hold:
(Simulatability) For every witness function W (·, view
(cid:2)
)
) ∈ RL(x) for all x ∈ L and
such that W (x, view
, the following ensembles are computationally
all view
indistinguishable

• {real(1n, A, S, W, z)}n∈N,z∈{0,1}∗
• {(view, (cid:3)w) ← SE(1n, z) : view}n,z∈{0,1}∗

(cid:2)

(cid:2)

n

(Extractability) There exists a negligible function μ such
that for every n ∈ N,
Pr[(view, (cid:3)w) ← SE(1
, z) : fail(view, (cid:3)w) = 1] ≤ μ(n)
Additionally, we say that (D, P, V ) is black-box concur-
rently simulation extractable if there exists an expected
˜SE such that for every A, the
PPT oracle-machine
above two conditions hold with respect to SE(1n, z) =
˜SE

A(1n,z,·)

(1n).

1) Simulation extractability in the ROM: The def-
inition of tag-based non-interactive arguments in the
ROM is identical
there

to Deﬁnition 5 except

that

is no need for procedure D;
instead of sampling
ρ ← D(1n), we sample ρ as random function from
{0, 1}poly(n) → {0, 1}poly(n)
for some appropriate
polynomial; furthermore, instead of providing ρ as input
to P and V , both algorithms have oracle access to ρ. We
make the analogous change in the deﬁnition of the real
experiment in the deﬁnition of simulation extractability
(now additionally, A gets oracle access to ρ instead of
getting it as input). Also, the view of A contains all of
the answers to oracle calls to ρ made by A, and thus
the simulator-extractor SE needs to reconstruct those
(as opposed to reconstructing the whole of ρ).

Simulation-extractability from HVZK:

In this
section we show how to transform any 3-round
special-sound special Honest-veriﬁer Zero-knowledge
(HVZK) [31] proof/argument into a black-box concur-
rently simulation-extractable NIZK in the ROM.

Deﬁnition 6 ([31]): A proof system (P, V ) is a
3 round special-sound Honest-veriﬁer Zero-knowledge
(HVZK) proof/argument for binary relation R if:

1) (three-move form) Let α be the common input to
P and V , and β such that (α, β) ∈ R is private
input to P . (P, V ) has the following three-move
form:
a) P sends a message a to V .
b) V sends a random t-bit challenge string c.
c) P replies z, and V accepts if φ(α, a, c, z) = 1

for some polynomial-time predicate φ.

(cid:2)

2) (special soundness) Given accepting transcripts
) for the instance α such that
(cid:2), there exists a polynomial-time algorithm

(a, c, z) and (a, c
c (cid:5)= c
computing β such that (α, β) ∈ R.

, z

(cid:2)

3) (special honest-veriﬁer ZK) There exists a poly-
nomial time simulator Sim, which on input α and
a random challenge c, outputs an accepting con-
versation of the form (a, c, z), which is identically
distributed to transcript generated by P (α, β) and
V (α) for any (α, β) ∈ R.
Given a protocol Π that

is a 3-round special-
sound Honest-veriﬁer
(HVZK)
proof/argument for binary relation R, we obtain the
tag-based NIZK ˜Π for R by applying the Fiat-Shamir
heuristic to Π and additionally requiring that the tag
tag is hashed—that is, the second-message challenge
c is generated by applying the random oracle ρ to the
ﬁrst message a and the tag tag (i.e., b = ρ(a, tag)).

Zero-knowledge

Theorem 1: Let Π be a special-sound special HVZK
argument for L, where the ﬁrst message a of Π has
ω(log n) min-entropy 8 and the second message b is

8Every special-sound special HVZK argument for a hard-on-the-
average language must have this property: if not, with polynomial
probability two honest executions would have the same ﬁrst message,
but different second messages and thus a witness can be extracted
out.

382

of length ω(log n). Then ˜Π is a tag-based black-box
concurrently simulation-extractable argument.

Proof: (Omitted for space.)

B. The construction

Assuming familiarity with basic cryptographic primi-
tives discussed in the previous section, the construction
is easy to understand at a high-level. We assume that all
users have unique string identiﬁers, e.g. email addresses,
to identify them in the protocol. The RA and SA are
each have keys for digital signatures which are consid-
ered the output of GenRA and GenSA respectively.

the RA veriﬁes that

A user’s secret credential is a random string s. The
user generates the credential by generating a commit-
ment to the random string s and proving the correct-
ness of the commitment to the RA in zero-knowledge.
During registration,
this proof
corresponds to the correct identity of the user and then
authorizes the credential by signing the commitment
and the user id with its signing key. The security of
the signature scheme ensures that only the RA can
authorize legitimate credentials. The signature on the
commitment can be interpreted as a very weak form of
blind-signature in which the RA does not learn anything
about the values being signed, but can verify that the
user has knowledge of the underlying secret.

To generate a survey, an SA generates a unique sid
and individually signs the pair (id, sid) for each user
id that can participate in the survey. We call the list
of all generated signatures L. Only those IDs which
are signed by the SA will be able to complete the given
survey, and the unforgeability properties of the signature
scheme ensure that only the SA can modify the list.
Beneﬁcially, SAs do not need to interact with any other
players to create the surveys.

To submit a response to a survey, the user sends her
submission m to the SA along with an NIZK proof that
the she has a valid credential (i.e., she has a commitment
signed by the RA, and she knows the values committed
to), and that her credential corresponds to an identity on
the survey list L (i.e., the ID in her signed commitment
is also in signed in L). Only legitimate users can
submit in the scheme, and clearly the submission is
anonymous to the SA who learns nothing except that
the submitter is on its approved list. However, we need
to achieve two other properties: i) tie the submission
m to the proof and the survey id, and ii) ensure that
the submitter does not submit multiple responses. The
ﬁrst property prevents submissions from replay and is
achieved because the NIZK we use is tag-based; we
can use the sid concatenated to the message m as the
tag for the proof. To prevent multiple submissions, we
include a unique token number created by evaluating
a pseudo-random function on the sid using the user’s

credential secret s as the seed, and we augment the
NIZK proof to show that
the unique token number
is computed correctly and corresponds to the user’s
credential. Thus, every valid submission by a given user
will have the same random token number associated
with it. This token does not reveal any information about
the submitter, but it allows the SA to detect multiple
submissions from the same anonymous user and either
discard all of them, or accept only the latest submission.

1) Primitives used: Let,
• (Gen, Sign, Ver) be a signature scheme.
• {fs}s∈{0,1}∗ be a family of PRFs.
• Com be a commitment scheme.
• Let L1 be the NP language deﬁned as follows:
(1n, c) ∈ L1 iff there exists strings r ∈ {0, 1}∗
, s ∈
{0, 1}n such that c = Com(s; r).
• Let L2 be the NP language deﬁned as follows:
(tok, sid, pkRA, pkSA) ∈ L2 iff there exist strings
s, id, c, r, σs, σsidid such that c = Com(s; r) and
VerpkRA (c||id, σs) = 1 and VerpkSA (sid||id, σsidid ) = 1
and tok = fs(sid)
• Let (D1, P1, V1) and (D2, P2, V2) be black-box cSE
NIZK protocols for L1 and L2 respectively.
2) Abstract ad-hoc survey scheme Γ:
• GenRA(1n) = Gen(1n), GenSA(1n) = Gen(1n).
• (Reg

(skRA), Reg

RA

U

)(1n, idi) proceeds as follows:
– A user with identity id uniformly generates
and stores s ← {0, 1}n, r ← {0, 1}poly(n) and
computes c = Com(s; r).
– i computes a cSE-NIZK π using P1 (given the
CRS or RO) that (1n, c) ∈ L1, using the tag 0n
and using (s, r) as witness.
– The user sends c, id, π to the RA.
– The RA checks that π with tag 0n is an
accepting proof that (1n, c) ∈ L1 (using V2) and
if so returns σs = SignskRA (c||id); otherwise it
simply returns fail.
– The user outputs cred = (c, s, r, σs).

• GenSurvey(1n, sid, L, skSA) proceeds as follows.
For each id ∈ L, compute σsidid = SignSAsk (sid||id)
and output the list of tuples (id, σsidid ).
• Authorized(pkSA, sid, pksid, id) outputs YES if pksid
contains a record of the form (id, σsidid ) such that
VerSApk (sid||id, σsidid ) = 1
• Submit(1n, sid, pksid, m, id, cred) proceeds as:

– Parse cred = (c, s, r, σs).
– Compute token-number tok = fs(sid).
– Recover a tuple of the form (id, σsidid ) from
pksid. If VerSApk (sid||id, σsidid ) (cid:5)= 1, abort.
– Compute a cSE NIZK π using P2 (and the CRS
or RO) that (tok, sid, pkRA, pkSA) ∈ L2 with tag

383

1||sid||m using c, s, r, σs, σsidid as witness.
– Send the tuple Sub = (tok, m, π) to the SA.

• Check(pkRA, pkSA, sid, tok, m, π) outputs accept if
V2 (given the CRS or RO) accepts π as a proof of the
statement (tok, sid, pkRA, pkSA) ∈ L2 with tag sid||m.
Theorem 2: If (Gen, Sign, Ver) is a secure signature
scheme, and {fs}s∈{0,1}∗ is a family of secure PRFs,
and Com is a perfectly hiding, computationally binding
commitment scheme, and (D1, P1, V1) and (D2, P2, V2)
are cSE NIZKs for the languages L1, L2 respectively,
then scheme Γ is a multi-survey unlinkable (Def. 3),
ad-hoc survey scheme that is secure (against malicious
users) (Def. 4).

Proof: (Omitted for space.)

C. Alternative implementations

Our proof for theorem 2 applies to more general im-
plementations of the Reg protocol as well. In particular,
U
the proof allows for the user’s output from the Reg
protocol to be a signature on s||id instead of Com(s)||id
as long as the signature scheme remains unforgeable
(skRA)(·)
even when the user is given access to a Reg
oracle. Recall that the standard security property of a
signature scheme allows the adversary oracle access to
the Sign(·) function; providing oracle access to Reg
RA
instead is a natural generalization. This generalization
allows for more efﬁcient concrete implementations. In
particular, it allows one to exploit natural connections
between speciﬁcally engineered commitment schemes
and signature schemes.

RA

IV. CONCRETE INSTANTIATION

A. Bilinear Groups and Assumptions

Let G and GT be groups of prime order p. A
symmetric bilinear map is an efﬁcient mapping e :
G×G → GT which is both: (bilinear) for all g ∈ G and
a, b ← Zp, e(ga, gb) = e(g, g)ab; and (non-degenerate)
if g generates G, then e(g, g) (cid:5)= 1. A more general
version of the bilinear map is the asymmetric bilinear
map e : G1 × G2 → GT , where G1 and G2 are distinct
groups. We present our constructions in symmetric
groups (which are easier for readers to parse), but
then conduct our implementation in asymmetric groups
(which are more efﬁcient).
Assumption 1 (Decisional Bilinear Difﬁe-Hellman):
Let g generate a group G of prime order p ∈ Θ(2λ)
with an efﬁcient bilinear mapping e : G × G → GT .
For all non-uniform PPT adversaries A, the following
probability is negligible in λ:
a, b, c ← Zp; x ← {0, 1};
T0 ← e(g, g)abc;
T1 ← GT ;
(cid:2) ← A(g, ga, gb, gc, Tx)
x

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)1/2 − Pr

(cid:2)
: x = x

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2) .

⎡
⎢⎢⎣

⎤
⎥⎥⎦

Roughly this assumption states that an adversary cannot
distinguish between e(g, g)abc and a random group
element when given (g, ga, gb, gc).
Assumption 2 (n-Decisional Difﬁe-Hellman Inversion):
Let h generate a group G of prime order p ∈ Θ(2λ).
For all non-uniform PPT adversaries A, the following
probability is negligible in λ:

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)1/2 − Pr

⎡
⎢⎢⎣

b ← Z
p; x ← {0, 1};
∗
T0 ← h1/b; T1 ← G;
(cid:2) ← A(h, hb, hb2
x
x = x

(cid:2)

⎤
⎥⎥⎦

(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2) .

, . . . , hbn

, Tx) :

B. Scheme

The common input for all protocols is a description
of the bilinear mapping, together with generators g, h of
G, and a description of a CRHF H that maps {0, 1}∗ →
Zq. The values g, h can be chosen randomly by the RA.
The elliptic curve library that we use implements the
hash operation H differently depending on the curve
implementation.

Our scheme makes use of the Pedersen commitment
the Dodis-Yampolskiy pseudo-random
scheme [27],
function [32], and a simpliﬁed signature scheme derived
from the Boneh-Boyen IBE [33]; all three are summa-
rized in Fig. 1.

Pedersen

Theorem 3 ([27]): The

commitment
scheme is a perfectly-hiding and computationally-
binding commitment scheme assuming the hardness of
the discrete logarithm problem in G.
Theorem 4 ([32], [12]): (informal)

The Dodis-
Yampolskiy PRF is a secure pseudo-random function
∗
q in the generic group model.9
for input space Z

Theorem 5 ([33]): (informal) Under the Decisional
Bilinear Difﬁe-Hellman assumption in G, the Boneh-
Boyen scheme is adaptively secure for n bit messages
for “large groups” which can withstand a factor of 1/2n
reduction in security. 10

C. Sigma protocols for languages L1 and L2

In order to instantiate the remaining protocols, we
must specify the languages L1 and L2 deﬁned in

inputs”;

9Dodis and Yampolskiy [32] showed that their PRF was secure
under the (parameterized) Decisional-Difﬁe-Hellman Inversion As-
sumption assumption in G for “small
they discuss [32,
Section 4.3] how the input to their PRF can be 160 bits for proper
choice of parameters and that arbitrarily-long strings can ﬁrst be
hashed down to 160 bits using any collision-resistant hash function.
10Suppose that messages of n bits are signed using the scheme,
and recall that one can always sign messages of arbitrary length by
ﬁrst applying a collision-resistant hash function to map them to n
bits. Then the adversary’s advantage in forging a message increases
by a factor of 2n. Thus, to be provably-safe in using this scheme
in applications that demand full security, one has to choose their
parameters carefully. Boneh and Boyen suggest, as one example, that
when n = 160 and the bilinear group is set so that no polynomial-
time adversary can break DBDH with advantage 2−240, then the
resulting signature scheme offers roughly 80-bit security.

(1) COMMITMENT SCHEME

order q with generators g, h.

Common Input: An algebraic group G of prime
Commit(m) S −→ R Sender chooses random s ∈
Open(α): S −→ R Sender sends (m, s) to R.

Zq, and sends α = gmhs to R.

Receiver checks α

?
= gmhs.

(2) DODIS-YAMPOLSKIY PRF Fy THAT MAPS

Setup: An algebraic group G of prime order q with

Z

q → Gt WHERE y ∈ Zq.
∗
generator g and PRF seed y ∈ Zq.
any m (cid:5)= 0 mod q.

Fy(m): The user computes Fy(m) = g1/(y+m) for

(3) BB SIGNATURE SCHEME

Gen(1n) : Sample the secret key sk ← α ∈ Zq.
Sample random group generators u, v, g, h and
compute U = e(g, g)α. The veriﬁcation key is
vk ← (u, v, g, h, U ).
Sign(sk, m0, m1): Choose r ∈ Zq randomly and

compute

σ1 ← g

α

m0 v

m1 h)

r

,

(u

σ2 ← g

r

and output (σ1, σ2) as the signature.

Ver(vk, m0, m1, σ1, σ2): Accept if

e(σ1, g)

?

= U · e(u

m0 v

m1 h, σ2)

Figure 1. A commitment, and PRF family, and signature scheme

the abstract section and provide cSE NIZKs for those
languages. Recall that languages L1 and L2 implicitly
depend on the speciﬁcation of a signature scheme
(Gen, Sign, Ver), a commitment scheme Com, and a
pseudo-random function family {fs}. For the rest of
these sections, assume that these three dependencies are
instantiated with the BB-signature scheme, the Pedersen
commitment, and the Dodis-Yampolskiy function as
described above in Fig. 1. We now provide Σ-protocols
for L1, L2 and then apply the Fiat-Shamir heuristic in
the random oracle model as prescribed in Thm.1 to
produce the required cse-NIZK.

The language L1 corresponds to a standard Schnorr-
like [34] proof for knowledge of a representation of
a discrete logarithm. In the Camenish-Stadler nota-
tion [35], such a protocol is speciﬁed as follows:

(cid:9)

(cid:10)

L1 = P oK

(sid, d) : α = v

d

sid g

This denotes a “zero-knowledge proof of knowledge
of integers sid, d such that α = vsid gd holds” where
α, v, g are elements of some group G. Values not in the
parentheses are considered to be public.

384

In contrast,

the language L2

Theorem 6 ([34]): There exists a 3-round honest-
veriﬁer special-sound zero-knowledge protocol for L1.
is more compli-
cated to specify and requires a non-trivial protocol.
A statement
in this language consists of the tuple
(sid, C, pkRA, pkSA) where pkRA = (u, v, h, e(g, g)x)
and pkSA = (uv, vv, hv, e(g, g)y). The witness for an
instance is the tuple (sid, id, c, r, σ, σsidid ) such that σ =
(σ1, σ2) forms a Boneh-Boyen signature on the values
(id, sid), σsidid = (σsidid,1, σsidid,2) forms a Boneh-
Boyen signature on (sid, id), and C = Fsid (sid) where F
is the Dodis-Yampolskiy PRF, for the signature schemes
above.
In the ﬁrst step of the proof for L2, the prover re-
randomizes (σ, σsidid ) by choosing random d1, d2 ∈ Zq
and computes

d2

d1

,
,

v
sid
v v

sid h)
id
v h)

s2 = σ2 · g
d1 )
s4 = σsidid,2 · g

(s1 = σ1 · (u
(s3 = σsidid,1 · (u
The values s2, s4 are sent to the Veriﬁer, and the
problem reduces to proving a simpler statement: (a)
(s1, s2) form a Boneh-Boyen signature on the values
(id, sid), (b) (s3, s4) form a Boneh-Boyen signature on
(sid, id), and (c) C = Fsid (sid) as follows:

d2 ).

id

(id, sid, s1, s3) :

−1∧
−1∧

P oK

v hv, s4) = e(s3, g)e(vid
−sid = C sid

Exe(h, s2) = e(s1, g)e(uidvsid , s2)
Eye(usid
v , s4)
E · C
where E = e(g, g).
(cid:2)
2, V

(cid:2)
2 ) for this simpler language pro-
2 Prover picks random b1, b2 ∈ Zq and
(cid:2)

The Σ-protocol (P
ceeds as follows:
1) P
J1, J2 ∈ G and computes

2 → V
(cid:2)

⎧⎪⎪⎨
⎪⎪⎩

⎫⎪⎪⎬
⎪⎪⎭

−1

b2 , s2)
−1

b1 v
b2
v , s4)

E1 ← e(J1, g) · e(u
E2 ← e(J2, g) · e(v
E3 ← C
2 Veriﬁer picks a random c ∈ Zq.
(cid:2)
(cid:2)
2 Prover computes a response

b2

z1 ← b1 + c · id
z3 ← s

1 · J1

c

z2 ← b2 + c · sid
z4 ← s

3 · J2

c

2 ← V
(cid:2)
2 → V
(cid:2)

2) P
3) P

4) Veriﬁer checks the following:

E2 · e(g, g)

E1 · e(g, g)

xc · e(h, s2)
sid
c
v hv, s4)
c · C
−c(sid)

yc · e(v
E3 · e(g, g)

c

−1

z2 , s2)
−1

= e(z3, g) · e(u
z1 v
= e(z4, g) · e(v
z1
v , s4)
= C
(cid:2)
(cid:2)
2 ) is an honest-veriﬁer
2, V

z2

Theorem 7: The above (P

special-sound zero-knowledge protocol for L2.

Proof: (sketch) The completeness of the protocol is
standard. First we show honest-veriﬁer zero-knowledge.
On input an instance and a random challenge c, the
simulator ﬁrst chooses a random z1, z2 ∈ Zq and
random z3, z4 ∈ G and computes

−1

e(z3, g) · e(uz1 vz2 , s2)
e(g, g)cx · e(h, s2)c
e(z4, g) · e(vz1
−1
v , s4)
e(g, g)cy · e(vsid
v hv, s4)c
C z2
e(g, g)c · C
−c(sid)

E1 =

E2 =

E3 =

and outputs (E1, E2, E3), c, (z1, z2, z3, z4) as the tran-
script. By inspection, it follows that the distribution of
transcripts is perfectly identical to a transcript from a
successful protocol execution.

the protocol

We now show that

is special-sound.
Consider two transcripts (E1, E2, E3), c, (z1, z2, z3, z4)
(cid:2) that
and (E1, E2, E3), c
both pass the veriﬁcation test. It follows that

4) where c (cid:5)= c
(cid:2)

(cid:2)
1, z

(cid:2)
2, z

(cid:2)
3, z

, (z

(cid:2)

z1 − z
(cid:2)
1
c − c
(cid:2)
z2 − z
(cid:2)
2
c − c
(cid:18)
(cid:2)
z3
(cid:2)
(cid:18)
z
3

(cid:19)c−c(cid:4)
(cid:19)c−c(cid:4)

z4
(cid:2)
z
4

id =

sid =

s1 =

s3 =

since both transcript tuples satisfy the three equations
in Step 4) of the Σ-protocol.

Corollary 8: In the random oracle model, there exists
a BB cse NIZK for languages L1 and L2 for the sig-
nature schemes (Gen, Sign, Ver), commitment scheme
Com and PRF {Fs} describe above.
Proof: Follows from Thm. 1.

D. GenRA and GenSA protocols

The GenRA and GenSA methods are the key genera-
tion methods for the BB signature scheme. More specif-
ically, the RA picks random group elements u, v, h ∈ G
and a secret element x ∈ Zq. The RA’s public key
RAvk = (u, v, h, e(g, g)x) and RAsk = x. (RA will be
signing m1 as the id with u and m2 as the user’s secret
seed with v.)
The SA picks random group elements uv, vv, hv ∈
G and a secret element y ∈ Zq. The SA’s public key
SAvk = (uv, vv, hv, e(g, g)y) and SAsk = y. (m1 will
be the sid and m2 will be the user id of a participant
authorized to submit in the survey.)

385

E. The Reg protocol
Common: Group (G, e, g), RAvk = (u, v, h, e(g, g)x)
RA Secret Key: x
User identity: id
User and RA establish a mutually authenticated secure
communication channel.
U → RA The user chooses a random PRF seed sid ∈
Zq and a random d ∈ Zq, computes α = vsid gd,
and sends (id, α) to RA.
The user also gives a (NI)zero-knowledge proof of
knowledge for (sid, d) ∈ L1 using the Σ-protocol
for L1 described above:

(cid:9)

(cid:10)

P oK

(sid, d) : α = v

d

sid g

to RA.

U → RA User picks a random b1, b2 and sends γ = vb1 gb2
U → RA User generates a random challenge c ∈ Zq by
using the random-oracle H and the tag 0n as
c = H(g, RAvk, id, α, γ, 0n)
U → RA User computes z1 = b1 + csid, z2 = b2 + cd and

sends (z1, z2) to RA.
?
RA veriﬁes vz1 gz2
= αcγ.

U ←− RA RA checks that

the identity id has not
been registered before. RA chooses r ∈ Zq
randomly, computes the signature tuple σ1 ←
gx(uidαh)r, σ2 ← gr and sends R the signature
σid = (σ1, σ2).

U User veriﬁes the signature by checking that

e(σ1, g) = e(g, g)

x · e(u

id

sid g

v

d

h, σ2).

If this veriﬁes, the user removes the commitment
randomness by computing σ
2 and stores
the secret credential (id, sid, σid = (σ1, σ2)).

(cid:2)
1 = σ1/σd

Note that at the end of this protocol, the user stores
a signature on s||id under the veriﬁcation key RAvk
(instead of a signature on c||id where c is a commitment
as per the abstract protocol). As mentioned earlier in
section III-C, this choice of implementation preserves
security as long as the signature scheme remains un-
forgeable even if the adversary has oracle access to
RA function. In this case, it is easy to show
the Reg
that unforgeability holds by showing how to simulate
RA function given access to a signing oracle.
the Reg
At a high level, the simulation works by (a) using the
simulator-extractor to extract (sid, id) from the NIZK
proof that
the user provides, and then submitting a
query for a signature (σ1, σ2) on s||id to the signature
oracle, and ﬁnally, multiplying an extra gdr term into
the σ1 term to produce messages for the adversary
that are indistinguishable from ones received in the
given interaction. The fact that the user must provide

a cse-NIZK with a tag 0n that is different from all
other tags used in all other protocol instances allows
simulation-extraction to function and thus enables a
proper simulation.

F. Survey Registration
SA Input: SAvk = (uv, vv, hv, e(g, g)y), SAsk = y,

sid ∈ Zq

List of identies: L
SA For each id ∈ L, the SA computes the following:

Pick a random r ∈ Zq and compute
, g

sidid = (g

id
v h)

sid
v v

(u

σ

y

r

r

)

Publish the list Lsid = (sid,{idi, σsidid}i∈L)

Authorized: Anyone can verify that a user with identity
id is authorized to submit in survey sid by ﬁnding
the corresponding signature σsidid = (σ1, σ2) in
Lsid and then checking that

?
= e(g, g)

y · e(u

sid
v v

idi
v h, σ2).

e(σ1, g)

G. Submission

The Submit protocol

is instantiated using the Σ-

protocol implementation for the L2 language.
Common Input: (G, e, g),

the public
keys SAvk = (uv, vv, hv, e(g, g)y), and RAvk =
(u, v, h, e(g, g)x)

the list Lsid,

User Secrets: id, submission m, credential (σid, sid)
The user aborts if the user has already participated
in an survey with sid or sid = sid. The user and
SA establish a secure connection in which SA is
authenticated, but the user is anonymous.

U The user identiﬁes the tuple (sid, idi, σ(i)) in Lsid in
which idi = id. The user computes Fsid (sid) =
C ← e(g, g)1/(sid+sid).

sends

(sid, C, m, s2, s4)

an
NIZKPOK of the statement (id, sid, s1, s3) in L2
with tag 1||sid||m to the SA:
replacing any prior occurrence of (C,·).
Theorem 9 (Security of the Survey System):

SA : If the proof veriﬁes, record the submission (C, m)

and

Assuming the security of the Pedersen commitment
∗
q,
scheme, the Dodis-Yampolskiy PRF for input space Z
the adaptive security of the Boneh-Boyen signatures,
and a collision-resistant hash function,
the above
concrete instantiation is a correct
(Def. 2) ad-hoc
survey scheme
(multi-survey) unlinkable
(Def. 3) and secure against malicious users (Def. 4) in
the random oracle model.

that

is

U → SA User

Proof: Security of the each of the primitives fol-
lows from Thm. 5, Thm. 4, Thm. 3, Thm. 6, Thm 7,
and Cor 8. The rest then follows from Thm. 2.

386

V. IMPLEMENTATION OF CONCRETE SCHEME
Because practicality and efﬁciency were major goals,
the concrete instantiation of the system was imple-
mented in C++11 using the MIRACL big number
library [36], which provides support for pairing based
cryptography and is free for educational purposes. We
implemented with curves that MIRACL equates to 128
AES security, using a Barreto-Naehrig pairing friendly
curve, with embedding degree k=12, and the Ate pair-
ing. The implementation uses an asymmetric pairing,
which follows immediately from our protocol.11

We analyzed performance for both types of curves be-
cause large groups are necessary for the survey system
to be provably-secure based on “standard” bilinear as-
sumptions (e.g. DBDH). In particular, for the reduction
to standard assumptions to work, the Dodis-Yampolskiy
PRF needs a group much larger than its input size and
the Boneh-Boyen signature reduction uses a complexity
leveraging argument that also requires a large group
size. However, one can also analyze these building
blocks, and thus the larger system, in the generic group
model [37], which provides evidence that the scheme is
secure against generic attacks and is then traditionally
implemented with smaller groups.

Our implementations, which are not particularly op-
timized, show efﬁciency that is more than sufﬁcient for
all practical surveys. In particular, our implementation
utilizes only 1 core of the CPU; it is straightforward
to parallelize user registration, and survey veriﬁcation
over multiple cores and machines by simply having all
cores run the same processes and balancing the load
(i.e., the number of registrations or surveys to verify)
given to any particular core. Similarly, when generating
new surveys, we can split the participant list among a
number of different cores at the SA, and each would
sign the names of the individuals on its portion of the
list.

Our results show that one or two modern workstations
or server systems are sufﬁcient
to manage surveys
into the millions using the more efﬁcient smaller sized
groups, and a small number of high-performance ma-
chines (on the order of 5 to 10) would easily handle
surveys of larger sizes or similar sizes using the larger
group size. User side computation is reasonably neg-
ligible. Submitting a survey, or verifying a submitted
survey, the most expensive operations a user might want
to do, took in the strongest security setting at most 2.5
seconds.

1) System: All tests were done on a 3.06 GHZ Intel
Core 2 Duo, Late 2009 iMac with 12GB 1067 MHZ

DDR3 RAM with a 5400RPM SATA HD. This machine
is several years old and much slower than a modern
server.

A. Experiments

time over a short

When considering survey life cycles, there are three
actions that are potentially computationally intensive:
i) mass registration of users, ii) generation of large
surveys by the SA, and iii) verifying ballots for large
surveys, as many ballots may need to be veriﬁed in
real
time period. Generating RA
keys and SA keys is computationally efﬁcient on our
system, and moreover they are done once per entity
and unlikely to be generated in large quantity. Similarly,
so long as submitting and user registration are not
so slow as to cause consternation, their performance
is relatively unimportant, as each user performs their
own computation in a decentralized manner. In contrast,
large surveys may be generated and run in a centralized
location, so it is important that the generation of the
survey list be scalable, and a reasonable system be able
to validate a large number of incoming submitters.

We performed the following experiments i) RA Key
Generation, ii) SA Key Generation, iii) User Registra-
tion, iv) survey Generation by the SA, and v) Submis-
sion. RA and SA generation is simple, and we simply
ran the protocols. For user generation we constructed
a large set of unique user names, and registered each
user sequentially. We report on the time taken per regis-
tration. We recorded the computation time for the user
and the RA separately. For survey registration we took
the user-names generated previously, and constructed
survey lists out of them. Since this is one large computa-
tion, we report on the aggregate time for a small survey
of 300 submitters, and the average time per submission.
We have veriﬁed that this time scales linearly with the
number of submitters as one would expect.12 Finally,
we consider actual submission, and measure the time
for the submitter to submit their response, and the time
necessary for the SA to verify the submission. These
measurements are done per submitter.

Each of the experiments below was performed 100
times, with mean and standard deviation of times re-
ported in milliseconds in Table I. The measured times
correspond only to the time necessary to compute the
appropriate cryptography and store the result to disk.
There is no network measurements involved. We discuss
this in the next subsection. The most expensive opera-
tion is the mass veriﬁcation of surveys that should be
done by a survey authority when surveys are submitted,

11During the user registration protocol, the veriﬁer sends back
(cid:2)
another element σ3 = gr, so that the user can compute σ
1 = σ1/σr
3.
This is the only extra information needed to accommodate the
asymmetry, and clearly does not affect security.

12We have created surveys of 1 million users on our machine, but
due to time constraints only computed this once with the smaller
group: it took approximately 42 minutes, inline with the expected
linear extrapolation.

387

TIMING RESULTS FROM THE IMPLEMENTATION OF OUR CONCRETE SYSTEM.

Table I

Operation

RA Key Gen
SA Key Gen

User Side User Registration
RA Side User Registration
User Veriﬁcation User Registration

SA survey Generation (300 submitters)
SA survey Generation (per Questnr.)

User Submission
SA Verify Submission

BN Curve

BLS Curve

Mean (ms)

StdDev (ms) Mean (ms)

StdDev (ms)

55.30
14.54

3.35
7.91
58.25

706.85
2.36

88.20
121.52

2.69
1.93

0.71
2.36
25.62

16.47

4.97
7.03

882.94
224.21

6.11
13.65
69.69

8,116.11

27.05

1,482.98
2,247.29

147.41
60.23

18.67
30.09
103.49

911.62

144.02
251.28

to ensure their legitimacy. In the more practical smaller
group sized implementation (i.e., the less stringent secu-
rity assumptions) we can verify 1 million submissions
in about 33 hours per core on our system. Assuming
a reasonable 4 cores per system gives us a little over
8 hours for 1 system. Or 3 systems could process
in about 2 hours. Even in the most stringent security
case, assuming we had to verify the submissions of 1
million people, we could use about 20 machines with 4
cores each, and compute the results in under 8 hours.
If there is no need to keep the survey results private,
this computing power can be rented from the cloud
(e.g., AWS), making the costs low. Veriﬁcation does
not need private information, so there is less risk in
renting resources. Survey generation and the RA’s side
of user registration are other places where computing
costs are centralized with an authority. Both are at
least an order of magnitude less time intensive than
survey veriﬁcation, and can be distributed over similar
resources efﬁciently.

Storage and Bandwidth Requirements: Storage and
bandwidth requirements are both very reasonable for
such schemes. Each element in the survey list output
during the Survey Registration is less thank 1KB, as
are the users’ secret tokens. The most expensive NIZK
used in the submission of the survey is smaller than
8KB. The above excludes the length of the IDs, which
are system dependent, but are reasonably on the order
of a few hundred bytes at most.

B. Anonymous Communication & Participant Lists

In practice, the user needs to anonymously submit a
single message to the SA during survey submission. In
moderate-security settings, proxy services can be used
to transmit the data, and in high-security settings, onion-

routing such as TOR [38] may be used. Another issue
that arises is the distribution of the survey participant list
for a survey. For small surveys, this is inconsequential,
but when participant rolls get into the millions, the ﬁle
of eligible submitters with corresponding information
can become large. Deploying this to each user is deﬁ-
nitely feasible (a typical OS patch push hits millions of
people), but there are easy alternatives that can slacken
the requirement. E.g., wild-cards can be used to ease en-
rollment, or separate participant lists can be constructed
of smaller size: Anonymity is slightly weakened, but we
are not aware of any surveys where participants scale to
a million submitters with full anonymity, and thus some
weakening may be acceptable.

ACKNOWLEDGMENTS

All opinions expressed and implied in this work are
solely those of the authors and do not represent or reﬂect
the views of their respective universities.

REFERENCES

[1] S.

Staff,

“Security

breach
identity theft,” 2009.

leaves
at
risk of
[Online]. Available:
http://thetruthwillrise.wordpress.com/2009/06/25/security-
breach-leaves-45000-at-risk-of-identity-theft/

45,000

[2] P. C. A. for Submission., “Observations on the Course

Review System at the University of Virginia,” 2013.

[3] M. Riley,

to

swap

agencies
of

“U.s.
thousands

data
[Online].
http://www.bloomberg.com/news/2013-06-

with
Available:
14/u-s-agencies-said-to-swap-data-with-thousands-of-
ﬁrms.html

ﬁrms,”

2013.

said

[4] D. Chaum and T. P. Pedersen, “Wallet databases with

observers,” in CRYPTO, vol. 740, 1992, pp. 89–105.

388

[5] K. Sako and J. Kilian, “Receipt-free mix-type voting
scheme – a practical solution to the implementation of
a voting booth,” in Eurocrypt 1995, 1995.

[22] D. Chaum, “Security without identiﬁcation: Transaction
systems to make big brother obsolete.” Communications
of the ACM, vol. 28(10), pp. 1030–1044, October 1985.

[6] A. Neff, “A veriﬁable secret shufﬂe and its application

to e-voting,” in CCS 2001, 2001.

[7] J. Benaloh, “Simple veriﬁable elections,” in EVT 2006,

2006.

[8] B. Adida, “Helios: Web-based open-audit voting,” in

USENIX 2008, 2008.

[9] R. Canetti, “Universally composable security: A new
paradigm for cryptographic protocols,” in FOCS ’01,
2000, see updated version at Cryptology ePrint Archive:
Report 2000/067.

[10] A. Juels, M. Luby, and R. Ostrovsky, “Security of blind
digital signatures (extended abstract),” in CRYPTO ’97,
1997, pp. 150–164.

[11] J. Camenisch and A. Lysyanskaya, “Signature schemes
and anonymous credentials from bilinear maps,” in
CRYPTO, 2004, pp. 56–72.

[12] J. Camenisch,

S. Hohenberger, M. Kohlweiss,
A. Lysyanskaya, and M. Meyerovich, “How to win
the clonewars: Efﬁcient periodic n-times anonymous
authentication,” in ACM CCS ’06, 2006, pp. 201–210.

[13] A. Sahai, “Non-malleable non-interactive zero knowl-
in

chosen-ciphertext

security,”

and adaptive

edge
FOCS’99, 1999, pp. 543–553.

[14] R. Pass and A. Rosen, “Concurrent non-malleable com-

mitments,” SIAM Journal of Computing, 2008.

[15] ——, “New and improved constructions of non-
malleable cryptographic protocols,” SIAM Journal of
Computing, 2008.

[16] A. Fiat and A. Shamir, “How to prove yourself: Practical
solutions to identiﬁcation and signature problems,” in
CRYPTO ’86, 1986, pp. 186–194.

[17] D. Chaum and E. van Heyst, “Group signatures,” in

EUROCRYPT ’91, 1991, pp. 257–265.

[18] M. Bellare, D. Micciancio, and B. Warinschi, “Founda-
tions of group signatures: Formal deﬁnitions, simpliﬁed
requirements, and a construction based on general as-
sumptions,” in EUROCRYPT, 2003, pp. 614–629.

[19] D. Boneh, X. Boyen, and H. Shacham, “Short group

signatures,” in CRYPTO ’04, 2004, pp. 45–55.

[20] R. L. Rivest, A. Shamir, and Y. Tauman, “How to leak

a secret,” in ASIACRYPT ’01, 2001, pp. 552–565.

[23] J. Camenisch and A. Lysyanskaya, “Efﬁcient non-
transferable anonymous multi-show credential system
with optional anonymity revocation,” in EUROCRYPT
’01, vol. 2045, 2001, pp. 93–118.

[24] ——, “A signature scheme with efﬁcient protocols,” in

SCN, 2002, pp. 268–289.

[25] J. Camenisch, S. Hohenberger, and A. Lysyanskaya,
“Compact e-cash,” in EUROCRYPT ’05, 2005, pp. 302–
321.

[26] S. Goldwasser, S. Micali, and R. L. Rivest, “A digital sig-
nature scheme secure against adaptive chosen-message
attacks,” SIAM J. Computing, vol. 17(2), pp. 281–308,
1988.

[27] T. P. Pedersen, “Non-interactive and information-
theoretic secure veriﬁable secret sharing,” in CRYPTO,
1991, pp. 129–140.

[28] O. Goldreich, S. Goldwasser, and S. Micali, “How to
the ACM,

Construct Random Functions,” Journal of
vol. 33, no. 4, pp. 792–807, 1986.

[29] O. Goldreich, The Foundations of Cryptography. Cam-

bridge University Press, 2001.

[30] A. D. Santis, G. D. Crescenzo, R. Ostrovsky, and G. Per-
siano, “Robust non-interactive zero knowledge,” SIAM
Journal on Computing, vol. 20, pp. 1084–1118, 2001.

[31] R. Cramer, I. Damg˚ard, and B. Schoenmakers, “Proofs
of partial knowledge and simpliﬁed design of witness
hiding protocols,” in CRYPTO, 1994, pp. 174–187.

[32] Y. Dodis and A. Yampolskiy, “A Veriﬁable Random
Function with Short Proofs and Keys,” in PKC ’05, vol.
3386 of LNCS, 2005, pp. 416–431.

[33] D. Boneh and X. Boyen, “Efﬁcient selective-ID secure
Identity-Based Encryption without random oracles.” in
EUROCRYPT ’04, 2004, pp. 223–238.

[34] C.-P. Schnorr, “Efﬁcient signature generation by smart
cards,” Journal of Cryptography, vol. 4, pp. 161–174,
1991.

[35] J. Camenisch and M. Stadler, “Efﬁcient group signature
schemes for large groups,” in CRYPTO ’97, vol. 1296 of
LNCS, 1997, pp. 410–424.

[36] M. Scott, “Multiprecision Integer and Rational Arith-
metic C/C++ Library (MIRACL),” published by Shamus
Software Ltd., http://www.shamus.ie/.

[37] V. Shoup, “Lower bounds of discrete logarithms and
related problems,” in Proceedings of Eurocrypt ’97,
1997, pp. 256–266.

[21] M. Bellare, H. Shi, and C. Zhang, “Foundations of group
signatures: The case of dynamic groups,” in CT-RSA,
2005, pp. 136–153.

[38] R. Dingledine, N. Mathewson, and P. Syverson, “Tor:
The second-generation onion router,” in USENIX 2004,
2004.

389

