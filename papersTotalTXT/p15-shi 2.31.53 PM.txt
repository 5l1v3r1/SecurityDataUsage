Detecting Preﬁx Hijackings in the Internet with Argus

Xingang Shi†§

Yang Xiang‡§

shixg@cernet.edu.cn

sharangxy@gmail.com

Zhiliang Wang†§

wzl@cernet.edu.cn

Xia Yin‡§

yxia@tsinghua.edu.cn

Jianping Wu†‡§

jianping@cernet.edu.cn

†Institute for Network Sciences and Cyberspace, Tsinghua University
‡Department of Computer Science & Technology, Tsinghua University

§Tsinghua National Laboratory for Information Science and Technology (TNList)

ABSTRACT
Border Gateway Protocol (BGP) plays a critical role in the
Internet inter-domain routing reliability. Invalid routes gen-
erated by mis-conﬁgurations or forged by malicious attacks
may hijack the traﬃc and devastate the Internet routing sys-
tem, but it is unlikely that a secure BGP can be deployed in
the near future to completely prevent them. Although many
hijacking detection systems have been developed, they more
or less have weaknesses such as long detection delay, high
false alarm rate and deployment diﬃculty, and no systemat-
ic detection results have been studied. This paper proposes
Argus, an agile system that can accurately detect preﬁx hi-
jackings and deduce the underlying cause of route anomalies
in a very fast way. Argus is based on correlating the con-
trol and data plane information closely and pervasively, and
has been continuously monitoring the Internet for more than
one year. During this period, around 40K routing anoma-
lies were detected, from which 220 stable preﬁx hijackings
were identiﬁed. Our analysis on these events shows that, hi-
jackings that have only been theoretically studied before do
exist in the Internet. Although the frequency of new hijack-
ings is nearly stable, more speciﬁc preﬁxes are hijacked more
frequently. Around 20% of the hijackings last less than ten
minutes, and some can pollute 90% of the Internet in less
than two minutes. These characteristics make Argus espe-
cially useful in practice. We further analyze some represen-
tative cases in detail to help increase the understanding of
preﬁx hijackings in the Internet.

Categories and Subject Descriptors
C.2.0 [Computer-Communication Networks]:
[Gener-
al Security and Protection]; C.2.3 [Network Operations]:
[Network Monitoring]

Keywords
BGP, Security, Preﬁx Hijacking, Hijacking Detection

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.

1.

INTRODUCTION

The Internet is composed of tens of thousands of Au-
tonomous Systems (ASes) which operate individual parts of
the infrastructure. As Border Gateway Protocol (BGP) [27]
controls the packet forwarding path between ASes, it plays
a critical role in the eﬃciency and reliability of the Inter-
net. However, because of the lack of security considerations,
several BGP security problems have not been well resolved
yet [25]. For example, the route information received from
neighbors can not be validated, so invalid routes may cause
packets being forwarded along wrong paths. This is known
as the preﬁx hijacking problem.

Preﬁx hijacking is often generated by accidental miscon-
ﬁgurations, and may cause serious routing problems and e-
conomic losses [24]. For instance, in 2008, Pakistan Telecom
hijacked YouTube for two hours [29], while in 2010, one AS
of China Telecom hijacked more than 50,000 preﬁxes (15%
of the Internet) of 170 diﬀerent countries [28]. Malicious
users also use preﬁx hijacking to intercept or drop certain
traﬃc, or to launch spam or DDoS attacks.

To improve the security of BGP, several methods have
been proposed, which broadly fall into three categories: cryp-
tographic based prevention, anomaly mitigation, and anoma-
ly detection. Cryptographic approaches [17, 21] usually use
the Public Key Infrastructure (PKI) to ensure the authen-
tication of routing announcements and prevent hijacking.
They often consume signiﬁcant router resources due to their
computation and storage complexity, and are unlikely to be
widely deployed very soon [10]. Anomaly mitigation ap-
proaches [30, 18] propose to ignore or demote suspicious
routes once they are detected. These approaches are hard
to deploy, and their misjudgments may disturb the routing
system. At last, anomaly detection approaches [36, 16, 34,
12] aim to discover anomalous information or behavior in
BGP announcements and raise alarm. As a viable secure
scheme in the current stage, they oﬀer valuable information
for the understanding and diagnosis of the routing system,
and help to push ISPs to deploy cryptographic solutions.

This paper focuses on the third category, anomaly de-
tection. Although many workable detection systems have
been developed, more or less, they have weaknesses such as
long detection delay, high false alarm rate and great deploy-
ment diﬃculty. Our solution, Argus, exploits a key observa-
tion about IP preﬁx hijacking: polluted routers (i.e., routers
whose traﬃc is hijacked) usually can not communicate with
the hosts in the victim preﬁx, while normal routers can.
This observation makes hijacking distinguishable from other

15anomalous route events, and let Argus achieve four superi-
or capabilities over existing solutions: (1) Low false positive
rate: Argus closely correlates the control-plane anomaly and
the data-plane reachability information of a large number of
vantage points, so that preﬁx hijacking can be accurately
distinguished from other BGP events.
(2) Low false neg-
ative rate: Argus monitors a much wider range of routing
anomalies, including origin AS and AS-path anomalies, and
considers the sub-preﬁx problem, so the chance of missing a
hijacking event is much lower. (3) Realtime detection: Ar-
gus usually detects a hijacking within a few seconds, while
existing methods often need orders of magnitudes longer.
(4) Agile: Argus is very easy to deploy, and does not need
to upgrade any existing network infrastructure or device.

Based on our earlier prototype [32] of Argus, 1 this paper

makes four new contributions as follows:

• System improvement and service. We carefully eval-
uate the performance of Argus, and continuously im-
prove it from several aspects. In particular, we tune
the system parameters based on our monitoring prac-
tice, and add a scheme to collect and choose live IP
addresses, resulting in better detection accuracy. We
contribute it to the community by providing several
public online services, and by raising alerts in realtime
via diﬀerent channels. We also discuss the limitations
of Argus to facilitate further studies in this ﬁeld.

• Hijacking monitoring and analysis. Since being de-
ployed one year ago, Argus has already identiﬁed 220
stable preﬁx hijackings (i.e., hijackings that last longer
than 10 seconds) from 40K anomalous BGP events.
We systematically analyze these events, and get many
interesting results. In particular, hijackings that have
only been theoretically studied before do exist in the
Internet. Although the frequency of new hijackings is
nearly stable, more speciﬁc preﬁxes are hijacked more
frequently. Around 20% of the hijackings last less than
ten minutes, and some can pollute 90% of the Internet
in less than two minutes. These characteristics make
Argus especially useful in practice, and to the best of
our knowledge, we are the ﬁrst to present these statis-
tics and trend of preﬁx hijackings in the Internet.

• Hijacking conﬁrmation and diagnosis. Starting from
March 2012, we directly contact the corresponding net-
work operators if a stable preﬁx hijacking is detected.
We provide detailed information collected by Argus to
help their diagnosis work. More than 30% of those hi-
jackings have been conﬁrmed, and we did not received
any objection to our judgments.

• Cause analysis of anomalous route events. We extend
Argus to not only detect preﬁx hijackings, but also
deduce the possible cause of anomalous route events
and classify them into diﬀerent categories. We further
analyze several representative cases in detail, in order
to help increase the understanding of hijackings in the
Internet.

1In particular, most of Section 4.1 and Section 4.2, and part
of Section 4.4 are replications of those in [32], with moderate
revisions.

This paper is organized as follows. Section 2 introduces
the necessary background of preﬁx hijacking and some relat-
ed work. Section 3 illustrates our key observation for hijack-
ing detection, and Section 4 describes the design details of
Argus. Section 5 presents our Internet monitoring practice
in the past year, while Section 6 further studies some repre-
sentative hijacking cases and other anomalous route events.
The pros and cons of our system are discussed in Section 7,
and ﬁnally, Section 8 concludes.

2. BACKGROUND AND RELATED WORK

2.1 Preﬁx Hijacking

Each AS in the Internet manages a number of networks,
which can be expressed as IP preﬁxes. BGP propagates
routes (AS-paths) between neighboring ASes to determine
how these networks can be reached, i.e., through which AS-
path. An AS-path p = han, · · · , a0i is a sequence of ASes,
where the last one, a0, is called the origin AS of p. When
the network connectivities change, BGP UPDATEs will be
generated, and new AS-paths will be announced throughout
the Internet.

Figure 1: An example of BGP preﬁx hijacking.

As shown in Figure 1, AS1 announces a route for its preﬁx
f with an AS-path h1i, and AS2 and AS3 will get a route to
f (i.e., h1i and h2, 1i respectively). However, AS4 can also
announce a route for f with a forged but shorter AS-path
h4i. As AS3 considers the shorter path to be better 2 than
the valid path it has previously received (i.e., h2, 1i), it will
forward the traﬃc destined to f to AS4. In this way, AS4
eﬀectively hijacks the traﬃc by forging a route. We call AS3
polluted by the route announced by AS4, and indicate that
by a gray circle in the ﬁgure.

A manipulator hijacks the traﬃc destined to a victim pre-
ﬁx either accidentally or intentionally. Based on how the
hijacked traﬃc is ﬁnally dealt with, hijackings can be clas-
siﬁed into the following two categories:

• Blackholing: the traﬃc is dropped, although the ma-

nipulator can eavesdrop on it at ﬁrst.

• Imposture or Interception: the traﬃc is handled either
by mimicking the victim’s action, or by forwarding to
the victim.

This paper only focuses on detecting blackholing due to
the following reasons. First, mis-conﬁgurations will typical-
ly cause blackholing. Second, Although a malicious attacker
may perform any of these actions, it is very diﬃcult for
him to mimic all behaviors of the victim, or to successfully
forward the traﬃc to the victim, if not impossible. Third,
detecting interception is very hard [9] since any AS can be
viewed as a man-in-the-middle. Last, an end-to-end mech-
anism can be much more eﬀective in protecting traﬃc from
either imposture or interception.
2This is a simpliﬁed example, as the length of an AS-path
is only one factor in BGP’s route decision process.

16Table 1: Pros and Cons of Hijacking Detection Methods

Methods

Detection

Attacker

delay

Information

Control-plane [8, 22, 12, 4] Realtime
Minutes
Data-plane [36, 34]
Minutes
Combination [16]
Correlation (Argus)
Realtime

Yes
No
Yes
Yes

Accuracy

Low

Medium

High
High

Sub-preﬁx
hijacking

Yes
No
Yes
Yes

Scalability Deployment

Good
Poor
Good
Good

Easy
Easy
Hard
Easy

2.2 Related Work

Existing hijacking detection proposals can be classiﬁed in-
to three categories based on the type of information they use,
as compared in Table 1.

The control-plane approaches [8, 22, 12, 4] passively moni-
tor the BGP routing information to collect anomalous events.
They are easy to deploy, react in realtime, and can deduce
information like who the attacker is or when the attack s-
tarts. However, they are fairly inaccurate and usually raise
many unnecessary alarms, since they can not tell normal
route events from hijackings very well [35].

The data-plane approaches [34, 36] continuously probe the
Internet to detect whether any data path changes. The prob-
ing often involves a large number of networks, and the paths
are collected by tools such as traceroute, hence these meth-
ods suﬀer from poor scalability and large latency. Due to a
lack of control-plane information, they can not detect sub-
preﬁx hijacking, and can provide little diagnosis such as who
the attacker is.

Control and data plane information can be combined to

complement each other. In [16], data-plane probing is launched
only after an anomalous UPDATE is received, so the scala-
bility is much better than a pure data-plane method. How-
ever, this system relies on some complicated probing meth-
ods like traceroute, nmap and IP/TCP timestamp, and also
bears large latencies up to several minutes. More impor-
tantly, since customized software have to be installed on its
vantage points, this solution is hard to deploy. Typically,
a limited number of Planetlab nodes are used, which suﬀer
from many side eﬀects. In particular, the Planetlab nodes
are unaware of BGP, so the beneﬁts of combining control
and data plane are limited. For example, the method can
not distinguish preﬁx hijacking from BGP anycast, since
both will result in diﬀerent probing results. The nodes are
mostly located in stub academic networks, so the data paths
that can be probed are not diversiﬁed enough, and the ca-
pability of detecting hijackings is reduced.

We think the deep-rooted reason of their ineﬃciency is a
lack of close and pervasive correlation between the control
and the data plane. Argus makes a step forward, through
correlating the control-plane route and data-plane reacha-
bility on a number of distributedly located diagnosis nodes
in realtime.

There are also many measurement studies on BGP related
problems, for example, analyzing route changes and their
root causes [11, 14], measuring how the Internet end-to-end
performance is impacted by BGP policy, timer or updates
[31, 13], quantifying path exploration and slow convergence
[26], and studying global black-holes in the Internet [20].
We monitor and identify anomalous route events and preﬁx
hijackings, and systematically study the statistics and trend
of these events that occurred over the past year, to help
better understand the characteristics of Internet hijackings.

Figure 2: Diﬀerent forwarding paths from normal
ASes and polluted ASes during a hijacking.

3. KEY OBSERVATION

Preﬁx hijacking can be caused by changing either the ori-
gin AS, or some AS-path segments in a route announcement.
Typically, only a portion of the ASes in the Internet can be
polluted by a hijacking, due to the complexity and diversi-
ty of the Internet. As shown in Fig. 2, the attacker AS3
announces itself as the origin AS of the preﬁxes owned by
the victim AS1,3 and successfully pollutes AS4, AS6, AS7,
AS9 and AS10. 4 These ASes will change their routes and
forward the traﬃc which is originally destined to AS1 along
the dashed line, while the other unpolluted ASes will for-
ward such traﬃc along the solid line as usual. Unless the
attacker forwards the hijacked traﬃc to AS1, a host in a
polluted AS will not be able to communicate with a host in
the victim, AS1, since the traﬃc goes to a black-hole.

Generally speaking, when the preﬁx hijacker acts as a
black-hole, it is likely that a data-plane probe sent from
an unpolluted AS to the victim preﬁx can successfully ar-
rive at the destination and get a reply, while a probe from
a polluted AS will most probably get no reply. This simple
observation is the key basis of Argus, our preﬁx hijacking
detection system. Next, we analyze this data-plane reacha-
bility problem in more detail.

As shown in Fig. 3, after an anomalous AS-path aﬀects
a portion of ASes in the Internet, the reachability to the
aﬀected preﬁx reﬂects diﬀerent scenarios: 5

1. When multi-origin (e.g., due to AS multi-homing, BG-
P anycast or static route) or traﬃc engineering is de-
ployed, a new origin AS or new AS-path segments are
introduced, and traﬃc may reach the destination pre-
ﬁx via diﬀerent paths. In this case, both the normal
ASes and the aﬀected ASes can reach the destination
preﬁx. (Fig. 3(a))

3Other cases, such as announcing false AS-path segments,
will be discussed in Section 4.
4We assume AS6 prefers AS3 to AS1.
5By reachability, we mean one host can communicate with
the other one in both directions, i.e., probe and reply.

17(a) multi-origin, 
traffic engineering

(b) route
failure

(c) route 
migration

(d)

hijacking

Figure 3: Data-plane reachabilities in diﬀerent route
events.

2. When node or link failure happens, there may not exist
a valid route to the destination preﬁx, then no AS can
reach it. Firewalls or inactive hosts may also lead to
this result. (Fig. 3(b))

3. When route migrates (e.g., due to network merge or
preﬁx acquisition, the ownership of a preﬁx changes, or
new AS-path segments are used, either temporarily or
permanently), ASes that have learned the new route
are able to reach the destination preﬁx, while ASes
have not learned the new route are not. (Fig. 3(c))

4. Under a hijacking as explained above, normal ASes
can reach the destination preﬁx while polluted ASes
can not. (Fig. 3(d))

The relation between the routes (control-plane) and the
reachabilities (data-plane) in diﬀerent ASes can be regarded
as a ﬁngerprint of a route event, and by this ﬁngerprint,
we can ﬁgure out whether a route change is actually caused
by a hijacking.
In Argus, we use show ip bgp to get the
BGP routes, and use ping to test the reachability. These
two commands are very simple, and are commonly enabled
in a vast number of public route-servers and looking-glasses.
These diagnosis nodes lie in diﬀerent ASes nearly all over the
Internet, and using them can greatly enhance our detection
capabilities.

However, the real situation in the Internet is more com-
plicated than the four scenarios above. Since there exists a
convergence process after a route event happens, diﬀerent
ASes often experience route change at diﬀerent time, and
the control-plane does not always coincide with the data-
plane. For example, as shown in Fig. 4, AS6 has already
recovered from the pollution but its route UPDATE has not
yet reached AS9. At this moment, probe from AS9 can get
a response, even though AS9 is using a polluted AS-path.

Figure 4: A polluted AS can reach the victim preﬁx
during route convergence.

On the other hand, a normal AS not aﬀected by a route
change may also lose connectivity to certain destinations
due to reasons not related to BGP [20]. Therefore, directly
matching the control-plane status and data-plane probing
results at each diagnosis node is error-prone. Instead, Argus
correlates the control-plane and data-plane information of
a large number of diagnosis nodes in a statistical manner.
The details of this correlation process will be described in
Section 4, and evaluated in Section 5.

4. PREFIX DETECTION SYSTEM - ARGUS

4.1 Overview

Argus is composed of three main modules: the Anomaly
Monitoring Module (AMM ), the Live-IP Retrieving Mod-
ule (LRM ), and the Hijacking Identiﬁcation Module (HIM ).
The whole system is depicted in Figure 5.

The Anomaly Monitoring Module receives live BGP UP-
DATEs from BGPmon [3], a real-time BGP feed in the
Route Views project [33] that collects UPDATEs from router-
s all over the world. When the AMM receives an UPDATE,
it will check whether the embedded AS-path has an anoma-
lous origin AS or an anomalous AS-path segment according
to its local routing information database, as described in
Section 4.2.

The Live-IP Retrieving Module maintains a pool of live
IPs by periodically collecting from various sources. For an
anomalous preﬁx f , it will carefully select an live IP as the
probing target of the identiﬁcation module. Details of the
LRM will be discussed in Section 4.3.

The Hijacking Identiﬁcation Module is responsible for col-
lecting information from a number of vantage points, com-
puting the ﬁngerprint for the anomalous route event, and
making ﬁnal decisions about whether the suspicious preﬁx
is really hijacked. It is the core of Argus, and Section 4.4
will present it in detail.

4.2 Monitor Anomalies

In Argus, we consider three types of route anomalies: ori-
gin anomalies (OA), adjacency anomalies (AA), and policy
anomalies (PA), as illustrated in Fig. 6.

An origin anomaly (OA) happens when the origin AS in
the AS-path of a preﬁx changes to a diﬀerent AS, or a new
preﬁx appears. This is the simplest case of preﬁx hijacking,
and is the focus of all existing hijacking detection solution-
s. For example, in Figure 6(a), AS3 is not the origin AS
of the preﬁx f , thus any AS-path for f ending with h3i is
anomalous. Argus maintains a database which keeps track
of the normal origin AS of each preﬁx to help detect origin
anomalies.

Hijacking can also be caused by changing some AS-path
segments, e.g., by using a command like as-path prepend in-
cautiously, or by intentionally removing some ASes to short-
en the path length. Such hijackings are key security issues
considered by the IETF [5], but have not got enough at-
tentions in measurement studies. To detect such anoma-
lies, it is impractical to maintain all the AS-paths due to
their enormous quantity. Instead, Argus only focuses on the
neighboring ASes pairs and triples that occur in an AS-path.
In an AS-path of a preﬁx, if any pair of neighboring ASes
has not appeared in any UPDATE before, Argus will report
an adjacency anomaly (AA), since such a pair indicates that
the adjacency between two ASes changes. Figure 6(b) illus-

18...

BGPmon

Live
BGP
feed

Daily
traceroute 
archives

Origin ASes
AS pairs
AS triples

Test

Extract

Detect

...

Live IP

i in f

show ip bgp

   Internet

ping

Fingerprint

Identify

HIM: Hijacking Identification Module

Hijacking 

Alarm

Victim
Prefix f

AMM: Anomaly Monitoring Module

Eyes of Argus

public route-servers & looking-glasses

Parse

Stat.

OA / AA / PA

Prefix f, Anomaly pa

CAIDA
iPlane

Live IP

Candidates
LRM: Live-IP Retrieving Module

Figure 5: The architecture of Argus.

2

4

2

4

2

(cid:455)4,3,2,1(cid:456)

4

(cid:455)1(cid:456)

f

1

victim

(cid:455)3(cid:456)
3

f
attacker

(cid:455)1(cid:456)
1

f

(cid:455)3,1(cid:456)
3

(cid:455)1(cid:456)
1
f

(cid:455)3,2,1(cid:456)
3

victim

attacker

victim

attacker

(a) Origin Anomaly (OA)

(b) Adjacency Anomaly (AA)

(c) Policy Anomaly (PA)

Normal UPDATE
Hijacking UPDATE
Customer-Provider
Peer-Peer
Normal AS
Polluted AS

Figure 6: The three kinds of anomalies considered in Argus.

trates such an example, where AS3 does not directly connect
to AS1, but erroneously announces an AS pair h3, 1i in the
AS-path.

On the other hand, since BGP is policy based, it often
cares about whether routes learned from one neighbor should
be propagated to another neighbor. Such a relationship be-
tween one AS with its two neighbors usually constitutes a
BGP policy. For example, in Figure 6(c), although AS3
directly connects to AS2 and AS4, it should not announce
routes learned from its provider AS2 to another provider
AS4, so the triple h4, 3, 2i should not appear in any route.
In case that a new triple of neighboring ASes appears, e.g.,
an AS-path containing h4, 3, 2i is received in this example,
Argus will report a policy anomaly (PA).

In most cases, an AS uses the same policy for all the pre-
ﬁxes learned from the same neighbor, and does not care
about the other non-adjacent ASes, so we think monitoring
adjacency and policy anomalies can be an eﬀective replace-
ment for monitoring the whole AS-path. The latter needs to
maintain all normal AS-paths while the former only needs
to maintain all normal neighboring AS pairs and triples, as
is done in Argus.

By considering the above three kinds of anomalies, Ar-
gus can detect a much wider range of hijackings, as will be
demonstrated in Section 5.

Once the AMM detects an anomaly, it will notify the HIM
to identify whether a hijacking truly happens. If not, it will
add the new origin AS or the AS pair/triple into the local
database since they are normal. The database will also be
refreshed periodically by removing those origin ASs or AS
pairs/triples inactive for a long period (i.e., more than two
months).

Figure 7: Finding an address block covered by
166.111.0.0/16 but not by any of its sub-preﬁxes.

4.3 Retrieve Live IPs

When anomaly is detected for a preﬁx f , the Live-IP Re-
trieving Module (LRM ) tries to ﬁnd a live IP address i in
f . The reachability to this address is a key factor for de-
termining whether f is hijacked. Due to the longest preﬁx
matching mechanism, i should be covered by f , but not by
any sub-preﬁx of f . Fig. 7 shows such an example, where
the anomalous preﬁx 166.111.0.0/16 has three sub-preﬁxes
announced, and our algorithm will try to ﬁnd a live IP in
the range of 166.111.64.0/18.

The LRM accomplishes this task by maintaining a local
database of candidate live IP addresses in all announced pre-
ﬁxes in the Internet. These IPs are collected from CAIDA’s
Ark [2] and iPlane [23] daily traceroute results 6, and from
many DNS records [6].

When a live IP address is asked for, the LRM will ﬁrst
retrieve all live IP addresses in the database according to the
given preﬁx, and then launch parallel probings to select one
that is currently reachable. This process is very quick, and

6These two projects perform traceroute from various van-
tage points to construct a router level atlas of the Internet.

19usually completes within one second. When no reachable
IP can be found, for example, when the server hosting the
LRM is also polluted, the most active IP in the probing
history will be selected. Inevitably, using an IP reachable
in history may introduce false negatives if it is not alive at
the moment, but our experiments show that this probability
tends to be relatively low.

4.4

Identify Hijackings

The Hijacking Identiﬁcation Module (HIM ) employs a
number of public route-servers and looking-glasses, called as
the eyes of Argus, to ﬁnally determine whether an anomaly
detected by the AMM is actually a preﬁx hijacking or not.
At each eye, Argus activates two processes, one for gath-
ering the control-plane route status of the victim preﬁx f ,
and the other for obtaining the data-plane reachability to
the selected live IP i.

Speciﬁcally, Argus uses show ip bgp to extract the best
BGP route pt,j(f ) that its j-th eye chooses for the anoma-
lous preﬁx f , in the t-th second. Then it checks whether
pt,j(f ) is aﬀected by the anomalous origin AS (or AS pair/triple)
reported by the AMM. Meanwhile, Argus uses ping to test
whether the live IP i is reachable from each eye. Both of
the two commands are very fast, so realtime results can be
collected once every second.

After an anomaly is reported, we continuously do that for
W seconds on N eyes. At the t-th second (1 ≤ t ≤ W ), we
compose the control-plane results of all eyes into a binary
vector Ct = {Ct,j|1 ≤ j ≤ N }, where

Ct,j =(cid:26) 0,

1,

if pt,j(f ) is aﬀected by the anomaly
if pt,j(f ) is not aﬀected by the anomaly

and compose the data-plane reachability results into a bina-
ry vector Dt = {Dt,j|1 ≤ j ≤ N }, where

Dt,j =(cid:26) 0,

1,

if the j-th eye gets no reply from the IP i
if the j-th eye gets a reply from the IP i

Our key observation in Section 3 tells that, the relation-
ship between Ct and Dt can expose the underlying cause of
a route event, e.g., users in an unpolluted AS should be able
to get a reply (Ct,j = Dt,j = 1) while users in a polluted
AS should not (Ct,j = Dt,j = 0). Due to the possible incon-
sistency between the control and data plane at a node, we
do not directly compare Ct,j and Dt,j of the same j-th eye
one by one.
Instead, we utilize the correlation coeﬃcient
of the two vectors Ct and Dt to measure this relationship,
mathematically deﬁned as

N

Ft =

(1)

Pj=1(cid:2)(Ct,j − Ct)(Dt,j − Dt)(cid:3)
s N
Pj=1

(Ct,j − Ct)2 ×

N

Pj=1

(Dt,j − Dt)2

where Ct and Dt are the average of Ct,j’s and Dt,j’s (1 ≤
j ≤ N ) on all eyes, respectively. We also call Ft and Dt
the ﬁngerprint and reachability of the route event at time t,
respectively.

Fig. 8 schematically illustrates the ﬁngerprint and reach-
ability distribution of diﬀerent route events. When Ft is
close to 1, Dt and Ct have a strong positive correlation (i.e.,
most polluted eyes cannot get reply from the victim preﬁx,
while most normal eyes can), then very probably a preﬁx
hijacking is going on. Since routing may be inconsistent and

Reachability   Dt

1

TE,

Multi-homing ,

Anycast,

…

Route failure, 

Firewall,

Inactive host,

…

0

Route

migration

-1

Prefix

hijacking

1

Fingerprint   F t

Figure 8: Fingerprint and reachability of diﬀerent
route events.

instable, we raise a hijacking alarm only when Ft is greater
than a threshold µ for at least a period of T seconds. The
choice of µ and T will aﬀect the detection accuracy, as will
be discussed in Section 5. We compute Ft in each second
for a total of 120 seconds.

When Ft is close to -1, a strong negative correlation exists
between Ct and Dt (i.e., most polluted eyes can get reply
while most normal eyes cannot), then the anomaly is very
possibly just a route migration.

When Dt and Ct are not strongly correlated (i.e., Ft is
close to 0), there are two possible situations: (1) if the aver-
age data-plane reachability Dt approaches 1, which means
most eyes can communicate with hosts in the target preﬁx,
then the anomalous route is often a normal backup route,
used for multi-homing, BGP anycast, backup path, or traf-
ﬁc engineering; (2) if Dt approaches 0, which means most
eyes can not reach the target preﬁx, then a route failure or
a ﬁrewall may exist in the middle, or because the probing
target we choose is not alive.

We can see that Argus has very little dependency on ex-
ternal nodes. It only receives live BGP feed, collects active
IP addresses, and logins to route-servers or looking-glasses
to execute two simple commands. All of these resources are
publicly and widely available, thus it is very easy to deploy,
and can monitor the Internet closely and pervasively.

We note that, when the denominator of equation (1) is
zero, we set Ft to be zero. This happens when either Ct or
Dt is a vector of all zero’s or all one’s. In particular, when
Ct is a vector of all one’s, all our eyes are polluted, and
we will not raise hijacking alarms any more. However this
rarely happens, as will be shown in the next section.

Based on Argus, we have built several online services. We
raise realtime hijacking alarms via a public mailing list and
twitter, which network operators can subscribe freely. We
post the information of all anomalous routes and hijackings,
together with their statistics, on our website, to facilitate
further processing and analysis. We also provide web ser-
vice APIs that can access our monitoring system in realtime
so that other systems can integrate the hijacking detection
capability. We make the services robust by deploying them
in diﬀerent ASes, so even when some of them are polluted
under an attack, the victim AS can still be informed as soon
as possible. All the detail of these services can be found at
argus.csnet1.cs.tsinghua.edu.cn.

205.

INTERNET MONITORING PRACTICE

Argus has been continuously monitoring the Internet for
one year, starting from May 2, 2011. During this period,
40K anomalous route events were reported 7, and 220 sta-
ble hijackings were identiﬁed. Due to a lack of the ground
truth, we use several methods to verify our identiﬁcation re-
sults. First, we query all valid Route Origin Authorizations
(ROAs) [17], which are digitally signed and can be used to
verify whether a preﬁx is announced by its authorized own-
er AS. Those anomalies with ROA records can be used as
a validation set to test our algorithm: if any such anomaly
is identiﬁed as a hijacking, then it must be a false positive.
However the ROA records are still rather incomplete, and
only 266 anomaly alarms can be used for validation, so we
also query the Internet Routing Registry (IRR)[7] to get
more preﬁx-origin pairs, where matching records are found
for 3988 anomalies. 8 Although the IRR information is not
guaranteed to be correct, we use it for a rough evaluation.
Second, we announce all the identiﬁed hijackings via several
public channels like twitter and mailinglist, 9 and have re-
cently started to directly contact the corresponding network
operators. Till now, we have not got any objection to our
identiﬁcation results, and 10 out of 31 network operators
being contacted have conﬁrmed our results. Last, we also
query the IRR to get other auxiliary information, such as
import/export policies, and query other databases such as
whois and Cyclops [12] to validate our results. Since that
needs a lot of labor work, the analysis is still on going.

5.1 System Parameters and Performance

The higher the correlation between the control and the
data plane, the more likely a hijacking is going on. When
an anomaly is reported by the Anomaly Monitoring Module
(AMM ), the Hijacking Identiﬁcation Module (HIM ) starts
to compute the ﬁngerprint Ft for this anomaly, in every sec-
ond of a continuous period of W seconds. Since the Internet
often converges in less than two minutes except for some un-
usual cases, and preﬁx hijacking is one kind of Tshort event,
which moves from a longer or less preferred to a shorter or
more preferred path, with convergence time typically less
than 40 seconds [26], we set W = 120 seconds. During this
period, if Ft is larger than a hijacking ﬁngerprint threshold
µ, we say the event is in a suspicious hijacking state, and
if the duration of the suspicious state, denoted by d, is no
smaller than a hijacking duration threshold of T seconds, we
classify this anomaly as a stable hijacking. Using a large hi-
jacking ﬁngerprint threshold µ or duration threshold T may
miss some real hijacking events, while using a small µ or T
may cause unnecessary alarms.

To model the high correlation coeﬃcient a hijacking should
have, µ can not be too small. Fig. 9 shows how the false
positive rate (FPR) changes with µ, where µ varies from 0.4
to 1.0. When we use the 266 route anomalies that have cor-
responding ROAs as the validation set 10, and the threshold

7We have aggregated the raw BGP UPDATEs from diﬀerent
routers into anomalous events, using algorithms like in [26].
8The IRR currently contains about 36% of all the Inter-
net preﬁxes, while the ratio that an origin anomaly can be
matched in it is 20%.
9Full details about
http://argus.csnet1.cs.tsinghua.edu.cn/about/.
10These anomalies are all caused by normal route events, so
FPR is the percentage of hijackings identiﬁed in this set.

these channels can be found at

4%

3%

2%

1%

0%

e
t
a
r

e
v
i
t
i
s
o
p

e
s
l
a

O A 
O A 

= 1)

  10)

= 10)

 

0.4

0.5

0.6

0.7
µ

0.8

0.9

1.0

Figure 9: False Positive Detection Rate v.s. µ.

e
g
a
t
n
e
c
r
e
P

60%

40%

20%

0%

0.60

0.65

0.70

0.75

0.80

ingerprint 

0.90

0.95

1.00

0.85
  )

Figure 10: Fingerprint distribution of all identiﬁed
stable hijackings (µ = 0.6).

T is set as 10 seconds, no anomaly is ever falsely identiﬁed
as a hijacking.
If the 3988 alarms with IRR route origin
records are used as the validation set, only 0.3% alarms are
falsely identiﬁed as hijackings when µ = 0.5, and the error
decreases to 0.2% when µ = 0.6, as represented by the line
with squares. Since IRR records are often outdated and not
guaranteed to be correct, the real error should be even s-
maller. For comparison, the dash line represents the results
using ROAs but without ﬁltering the alarms by their du-
ration (i.e., when T = 1). If µ = 0.5, there are four cases
misclassiﬁed as hijackings, and when µ = 0.6, there is no
false identiﬁcation.

Fig. 10 plots the ﬁngerprint distribution of all identiﬁed
stable hijackings when we use the default threshold µ = 0.6
and T = 10. It is clear that most stable hijackings have a
ﬁngerprint much larger than 0.6, as indicated by the peak
near 1.0. This conﬁrms our conjecture that the control-plane
route status Ct and the data-plane reachability Dt has a very
high positive correlation when hijacking happens.

Fig. 11 shows the cumulative distribution function (CDF)
of the duration of all suspicious hijacking alarms (i.e., when
the ﬁngerprint Ft > µ). Many alarms are transient with
a short lifetime, and the distributions do not change much
when µ varies from 0.6 to 0.9.
In practice, we use T =
10 seconds to ﬁlter those non-stable route events that may
cause µ temporarily high. Even If they are real hijackings,

100%

C

s

m
r
a
l
a

80%

60%

40%

  µ= 0.9
  µ= 0.8
  µ= 0.7
  µ= 0.6

 

0

20

40

D uration 

60

80
( seconds)

100

120

Figure 11: Duration of suspicious alarms (CDF).

21 
R
(
T
 
 
R
(
T
 
=
 
I
R
R
 
(
T
 
F
 
 
F
(
F
t
%
 
 
(
D
F
)
d
 
1.5%

1.0%

0.5%

0.0%

e
t
a
r

e
v
i
t
i
s
o
p

e
s
l
a

0

10

20

30

40

50

60

( seconds)

6%

4%

2%

0%

e
t
a
r

e
v
i
t
i
s
o
p

e
s
l
a

O A 
O A 

= 1)
= 10)
= 10)

5

10

15

20

25

30

35

40

Figure 12: False Positive Detection Rate v.s. T .

Figure 14: False positive detection rate v.s. #eyes.

100%
80%
60%
40%
20%
0%

C

s

m
r
a
l
a

  Stable  hij ackings
  Non-stable  suspicious  alarms

0

5

10

15

20

25

30

  polluted 

Figure 13: The numbers of polluted eyes in stable
hijackings and non-stable suspicious alarms.

they can do little harm to the Internet since the routes can
hardly converge in such a short time.

Fig. 12 shows how the FPR decreases with T , under a
default µ = 0.6. Since there is no false identiﬁcation when
the ROA records are used, this curve is plotted using the
IRR records as the validation set. When T > 10, the false
rate is less than 0.2%, while if we do not use such a duration
threshold, the false rate will increase to 1.1%.

To illustrate the eﬀectiveness of T , we compare the num-
bers of eyes that are polluted by the 220 stable hijackings
and the 570 non-stable suspicious alarms in Fig. 13. The
distributions show that, non-stable hijackings usually aﬀect
a much fewer number of eyes than stable hijackings. For
example, in 81% cases, less than ﬁve eyes are aﬀected if the
alarm duration d < T , while in more than 50% cases, more
than ﬁve eyes are aﬀected if d > T . We note that, it rarely
happens that more than 40 eyes are aﬀected, even for stable
hijackings, and we will elaborate on this point later.

Fig. 14 presents how the false positive rate decreases when
more eyes are used, where the 266 anomalies with ROAs
and the 3988 anomalies with IRR records are used as the
validation set, respectively. It is clear that using more than
40 eyes achieves a fair accurate result, while less than ten
eyes may bring a few errors.

Fig. 15 reports the cumulative distribution of the detec-
tion delay (i.e., from when the ﬁrst anomalous BGP UP-
DATE is received to when the ﬁrst time that Ft exceeds
µ), for the 790 suspicious hijacking alarms and 220 stable
hijackings, respectively. About 50% suspicious alarms, and
60% stable hijacking have a detection delay of no more than
10 seconds. This is considered as much faster than existing
data-plane based hijacking detection methods, which cost at
least a few minutes.

We note that, the speed of Argus can be further improved,
since this delay includes the time used for logging in to the
eyes and the delay of route propagation, which are in aver-
age 6.4 and 4.6 seconds. They can be eﬀectively reduced by
putting Argus in a network of better quality, and by using
more eyes. If these latencies are deducted from the detection

100%

C

s

m
r
a
l
a

80%

60%

40%

20%

0%

( identification  delay)

( identification  delay)

  Stable  hij ackings 
  All  suspicious  alarms 
  Stable  hij ackings 
  All  suspicious  alarms 

( detection  delay)

( detection  delay)

 

0

20

40
D elay 

60

( seconds)

80

100

120

Figure 15: Hijacking detection delay (CDF).

delay, the real identiﬁcation delay costs less than 10 second-
s in 70% suspicious alarms and 80% stable hijackings, and
costs less than one second in 35% suspicious alarms and
50% stable hijackings. In this manner, we claim that Argus
achieves realtime detection.

5.2 Do we miss many real hijackings?

It is very hard to judge whether Argus can detect all or at
least a large fraction of blackholing preﬁx hijackings in the
Internet, since no one knows the ground truth. We make
several eﬀorts to improve its detection capability.

The BGP UPDATEs from BGPmon [3] is considered to
cover a large portion of the Internet [33]. For example, the
number of peers from which BGPmon collected live data
ranged from 110 to 130 in the last year, and these peers
were distributed in more than 70 ASes. To handle the rel-
ative large data volume 11, we used a server with a six-core
Intel Xeon CPU and 16G memory, and experienced no data
loss in the whole year. 12 In these UPDATEs, the anomaly
monitoring module monitors three types of anomalies, in-
cluding OA, AA and PA. To the best of our knowledge, we
are the ﬁrst to monitor hijackings which utilize forged adja-
cency or policy, although they have been theoretically stud-
ied before [15]. The successful detection of such hijackings
demonstrates the superior capabilities of Argus.

Our identiﬁcation method depends on the reachability to a
live host in the target preﬁx. If no such a host can be found,
we just guess one and probe it from our eyes. However,
if no eye can reach it, a possible hijacking may be missed,
and we say this is a blindfolded case. We improve the live-
IP retrieving module by collecting live IPs from multiple
sources, and the number of blindfolded cases decreases from
58% to 19% 13. We also consider the sub-preﬁx problem

11The peak volume exceeded 10MB/s.
12On average, we handled around 10GB BGP data each day,
and the peak volume exceeded 20Mbps.
13This is just an upper bound for missing hijackings, since

22 
I
R
R
F
 
 
T
 
%
 
 
(
D
F
)
#
e
y
e
s
 
R
(
T
 
 
R
(
T
 
 
I
R
R
 
(
T
 
F
 
 
#
 
e
y
e
s
%
 
 
(
D
F
)
12

9

6

3

0

s
g
n
i
k
c
a

i
h

e
l
b
a
t
s

O A 

  AA
  PA

0

8

16

24

32

40

48

Time 

( week)

(a) Stable hijackings

s
e
i
l
a
m
o
n
a

e
t
u
o
r

2k

1k

0

0

O A 

  AA
  PA

8

16

24

32

40

48

Time 

( week)

24

18

12

6

0

s

m
r
a
l
a

s
u
o
i
c
i
p
s
u
s

O A 

  AA
  PA

0

8

16

24

32

40

48

Time 

( week)

(b) Route anomalies

(c) Suspicious hijacking alarms

Figure 16: The weekly numbers of stable hijackings, route anomalies and suspicious alarms.

as explained in Section 4.3 and illustrated in Fig. 7. In our
results, around 10% stable hijackings will not be identiﬁed if
sub-preﬁx is ignored, i.e., the live IP belongs to a sub-preﬁx
of the preﬁx we are interested in.

In the identiﬁcation module, we now keep a pool of 389
route-servers and looking glasses widely distributed in 41
transit ASes, 14 to sense both the control and the data plane
status of the Internet in a pervasive manner. Transit AS-
es, including default-free ASes, can sense the diverse paths
to diﬀerent preﬁxes in the Internet. In contrast, other dis-
tributed monitoring platforms, such as the Planetlab, often
concentrate in stub ASes, such as academic networks, and
often use a default route for their traﬃc. To avoid overload-
ing the eyes, for each anomalous event, we randomly choose
40 ∼ 80 eyes from our server pool, and use them to compute
the corresponding ﬁngerprint and reachability. Using more
than one eye in the same transit AS can improve accuracy
and provide better redundancy, since diﬀerent eyes may ex-
perience diﬀerent paths to the same preﬁx 15 and diﬀerent
inconsistencies between their control and data plane.

When computing the ﬁngerprint Ft, a hijacking may be
missed due to the division-by-zero problem. However, in our
data, the chance that Ct equals 1 (i.e., no eye is polluted) is
only 3%, and the chance that Dt equals 0 (i.e., all eyes are
blindfolded) is less than 20%. 16 The case that Ct = 0 (i.e.,
all eyes are polluted) or Dt = 1 (i.e., all eyes can reach the
live IP) never occurs. So the probability that a hijacking
is missed due to the failure point of Ft is very likely to be
small.

It is worth to note that, the number of ASes in which
eyes are employed is very important. In the early stage of
our system deployment, our eyes covered less than 20 tran-
sit ASes in the Internet, and almost half of the anomalous
events could not be seen by any of our eyes. This is deﬁnite-
ly a major contributor to the false negatives of our system
at that time. However, we kept adding more usable eyes,
especially in more ASes, and now less than 2% anomalous
events may be missed by all the eyes used in identiﬁcation.
Last, we do not use very large µ and T , so hijackings with
unstable ﬁngerprints can also be identiﬁed. As has been
demonstrated, they do not aﬀect the false positive rate very
much.

In conclusion, although there is no direct proof for the

many such cases are indeed not hijackings, but are caused
by route failure, ﬁrewall, no active hosts, etc..
14A complete list of the eyes we employ can be found at
http://argus.csnet1.cs.tsinghua.edu.cn/static/eyes.txt.
15The chance that two eyes in the same AS experience dif-
ferent paths is 39% in our experiments.
16When our eyes cover more than 20 transit ASes and the
improved live IP selection algorithm is used.

false negative possibility of Argus, we believe it can detect
a large fraction of blackholing hijackings in the Internet,
and can liberate network operators from a vast number of
alarms. In the rest of this paper, we will make a systematic
analysis on our monitoring results.

5.3 Monitoring Results

The 40K anomalous route events reported by the AMM
consist of 20K origin anomalies, 6.7K adjacency anomalies
and 13.3K policy anomalies. From these events, the HIM
identiﬁed 220 stable hijackings, in which 122 hijackings in-
troduced origin anomalies, while 71 and 27 hijackings intro-
duced adjacency and policy anomalies, respectively. How-
ever, since the monitoring of the three kinds of anomalies
started at diﬀerent time, these numbers are not directly
comparable. Instead, in Fig. 16(a) and 16(b), we plot the
weekly numbers of stable hijackings and route anomalies of
each type, starting from May 2011. Notice there is no data
for AA and PA anomalies until November 2011. For compar-
ison, we also plot the weekly numbers of the 790 suspicious
hijacking alarms in Fig. 16(c).

As shown in Fig 16(a), the frequencies of diﬀerent types
of stable hijackings are somewhat steady and comparable in
the whole year, with an average of three new hijackings per
week. The higher values in the starting points may just be
caused by accumulation. One notable point is that, adja-
cency and policy based hijackings do exist in the Internet,
and to the best of our knowledge, we are the ﬁrst to detect
and study them.

The trend of anomalies and suspicious hijackings is almost
similar to that of stable hijackings. The only diﬀerence is
that, the number of policy anomalies is far larger than the
other types of anomalies, but the number of policy based hi-
jackings is not that large. It is reasonable because the num-
ber of neighboring AS triples (i.e., policies) is much larger
than the number of origins or neighboring AS pairs 17, while
most anomalies are not hijackings.

Fig. 17 plots the CDF of the hijacking duration for all
stable hijackings. The duration is computed oﬀ-line by ex-
amining when the corresponding route anomalies disappear
from the routing UPDATEs, representing how long a hijack-
ing will aﬀect the Internet. It covers a very large range, from
less than 10 minutes to longer than one week, both of which
have a non-negligible fraction and are worth further studies.
For example, more than 20% hijackings last less than 10
minutes, and these short (but not transient) hijackings ask
for a realtime detector such as Argus. On the other hand,
those long hijackings indicate that, this security problem is
either ignored by or is still unknown to some ISPs, or it is

17In the past year, 925K neighboring AS triples, 606K preﬁx-
origin pairs and 108K AS edges were monitored by Argus.

23#
 
 
j
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
#
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
#
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
100%

80%

60%
40%

20%

0%

C

s
g
n
i
k
c
a

i
h

e
l
b
a
t
s

O A
  AA
  PA
  all

1
1x 10

2

1x 10

3

1x 10

4

1x 10

hij acking  duration 

5

1x 10

1x 10
( seconds)

100%

80%

60%

40%

20%

0%

C

s
g
n
i
k
c
a

i
h

e
l
b
a
t
s

6

7
1x 10

  PA
  AA
  all
O A

0

20

40

60

80

100

120

  polluted  ASes

Figure 17: Duration of stable hijackings (CDF).

Figure 19: The number of polluted ASes (CDF).

c
i
f
i
c
e
p
s

t
s
o
m

100%
80%
60%
40%
20%
0%

s
e

i
f
e
r
p

  stable  hij ackings
  suspicious  alarms
  in  all  UPD ATE s

8

12

16

max imal  prefix

20
  length

24

28

A

s
e
S
A
d
e
t
u
l
l
o
p

Figure 18: Ratio of most speciﬁc preﬁxes at diﬀerent
preﬁx length.

O A 
  AA 

  all
  PA

70

50

30

10

1
10

2
10

3
10

Time 

5
10

4
10
( seconds)

6
10

7

10

Figure 20: Hijacking pollution speed.

very hard to defend against. It should also be noted that, in
order to reduce the workload of the eyes, we only use BGP
UPDATEs to determine when a hijacking event ends, so it
is possible that some long lasting hijackings are just route
migrations which happen to exhibit hijacking characteristics
in their early stage.

In total, we detected around 40K anomalous preﬁxes, of
which 1132 appeared in suspicious alarms, while 263 ap-
peared in stable hijackings. We call a preﬁx most speciﬁc if
it has no sub-preﬁx announced to the Internet. Since routers
prefer most speciﬁc preﬁxes, it is reasonable that hijackings
also prefer them so that they can pollute the Internet more
eﬀectively, as in the Youtube event [29]. Fig. 18 shows the
ratio of such most speciﬁc preﬁxes, in all announced pre-
ﬁxes, hijacked preﬁxes and suspicious preﬁxes, respectively,
where hijackings show a clear favor for most speciﬁc ones.
In stable hijackings, about 91% preﬁxes are most speciﬁc,
while the ratio in all announced preﬁxes is 87%. This fa-
vor is especially evident for shorter preﬁxes whose impact
is greater.
In all the preﬁxes with a length less than 18,
the average percentage of most speciﬁc preﬁxes is only 50%,
while the ratio becomes 100% in stable hijackings (the ratio
is 70% in all suspicious alarms). On the other hand, sub-
preﬁx hijackings (using a more speciﬁc preﬁx than a normal
one) contribute around 10% in stable hijackings.

To illustrate how these hijackings aﬀect the Internet, Fig.
19 depicts how many ASes in the Internet a hijacking can
successfully pollute (hijack), and Fig. 20 depicts how fast
hijackings can pollute them. Since most ASes in the Internet
are stub/customer ASes which use default routes to their
providers for many preﬁxes, they cannot be seen in any of
the UPDATEs for those preﬁxes. The numbers in these two
ﬁgures only cover the transit ASes seen in the UPDATEs
for the corresponding (hijacked) preﬁxes, while the actually
aﬀected area should also include their customers.
In Fig.
19, more than 20% stable hijackings can pollute at least
80 ASes, while in Fig. 20, on average, more than 20 ASes

are polluted within only two minutes. For each hijacking
that aﬀects more than 80 transit ASes, we also compute the
ratio of the number of polluted ASes (in a certain period)
to the number of ASes that can be seen in all UPDATEs
for the corresponding preﬁx. This metric can be regarded
as a rough estimator of what percentage of the Internet is
polluted, and in some cases, more than 50% of the Internet
are polluted within 20 seconds, and more than 90% of the
Internet are polluted in less than two minutes.

On the other hand, in Fig. 19, origin based hijackings usu-
ally can pollute more ASes than adjacency or policy based
hijackings. For example, about 70% in the former case can
pollute at least 50 transit ASes, while only around 30% of
the latter two cases have this capability. Similarly, origin
based hijackings often pollute the Internet in a faster way,
as shown in Fig. 20. For example, on average, an origin
based hijacking can pollute about 26 transit ASes in two
minutes, and can pollute more than 30 in ten minutes. Part
of the reasons may be that, when forging preﬁx-origin pairs,
most speciﬁc preﬁxes are often used, with short AS-paths.

It is also interesting that a hijacking can hardly pollute
all ASes. Due to this reason, the chance that all our eyes
are polluted is also low, which helps them to get a more
accurate detection result.

6. CASE STUDIES

In this section, we analyze the characteristics and root
causes of some interesting hijackings, as well as some non-
hijacking anomalies, in order to help increase the under-
standing of preﬁx hijackings in the Internet.

Table 2 summarizes the hijacking cases discussed in this
section, including ﬁve cases with origin anomalies, three with
adjacency anomalies and two with policy anomalies. Most of
these hijackings have been conﬁrmed by the corresponding
network operators, while for other cases, we will present
enough evidence.

24%
 
 
j
 
(
D
F
)
 
%
 
 
x
%
 
 
j
 
(
D
F
)
#
 
#
 
 
 
 
(
V
G
)
 
 
 
 
 
 
 
Table 2: Case study: ten preﬁx hijackings detected in the past year.

OA 1
OA 2
OA 3
OA 4
OA 5

AA 1
AA 2
AA 3

Time

2011-12-27
2012-03-20
2012-04-04
2011-06-23
2012-03-22

Time

2012-04-23
2012-03-31
2011-12-19

Time

Preﬁx

166.111.32.0/24, ...
193.105.17.0/24
91.217.242.0/24
76.72.238.0/24, ...
12.231.155.0/24

Preﬁx
210.1.38.0/24
184.164.255.0/24
205.153.112.0/22

Preﬁx

Normal Origin

Anomalous Origin

Delay

AS4538
AS50407
AS197279
AS701
AS7018 (12.128.0.0/9)

AS-path

3043 174 38082 38794 24465
4739 6939 2381 47065 19782 47065
3303 174 17368 26263

AS23910
AS15763
AS48559
AS27005
AS13490
Anomalous AS Pair
38794 24465
47065 19782
17368 26263

10
5
9
6
7

Delay

12
4
3

AS-path

Anomalous AS Triple Delay

PA 1
PA 2

2012-04-19
2012-04-16

77.223.240.0/22
195.10.205.0/24

4739 24709 25388 21021 12741 47728
3043 174 20764 31484 3267 3216 35813

21021 12741 47728
20764 31484 3267

9
5

1.2
0.6
0.0
-0.6
-1.2

t
n
i
r
p
r
e
g
n
i
f

1.2
0.6
0.0
-0.6
-1.2

t
n
i
r
p
r
e
g
n
i
f

  fingerprint

  polluted  eyes

30

20

10

0

20

40
time 

60
( seconds)

80

(a) OA 1

  fingerprint

  polluted  eyes

0

20

40
time 

60
( seconds)

80

(d) OA 4

0
120

100

30

20

10

0
120

100

s
e
y
e

d
e
t
u
l
l
o
p

s
e
y
e

d 
e
t
u
l
l
o
p

1.2
0.6
0.0
-0.6
-1.2

t
n
i
r
p
r
e
g
n
i
f

1.2
0.6
0.0
-0.6
-1.2

t
n
i
r
p
r
e
g
n
i
f

0

20

  fingerprint

  polluted  eyes

40
time 

60
( seconds)

80

(b) OA 2

0

20

  fingerprint

  polluted  eyes

40
time 

60
( seconds)

80

(e) OA 5

30

20

10

0
120

100

30

20

10

0
120

100

s
e
y
e

d
e
t
u
l
l
o
p

s
e
y
e

d
e
t
u
l
l
o
p

1.2
0.6
0.0
-0.6
-1.2

t
n
i
r
p
r
e
g
n
i
f

t
n
i
r
p
r
e
g
n
i
f

1.2
0.6
0.0
-0.6
-1.2

  fingerprint

  polluted  eyes

0

20

40
time 

60
( seconds)

80

(c) OA 3

  fingerprint

  polluted  eyes

0

20

40
time 

60
( seconds)

80

(f) AA 1

30

20

10

0
120

100

30

20

10

0
120

100

s
e
y
e

d
e
t
u
l
l
o
p

s
e
y
e

d 
e
t
u
l
l
o
p

Figure 21: Case studies of hijackings: ﬁngerprint and the number of polluted eyes.

In Fig. 21, for each hijacking with origin anomaly, we plot
the corresponding ﬁngerprint and the numbers of polluted
eyes in each second, to demonstrate the timely and accurate
reaction of Argus. We also indicate the time delay when
Argus begins or stops to report hijacking alarms by a dotted
line, if it exists. For other cases, since the curves are very
similar, we just present one of them, and omit the others
due to space limitations.

6.1 Hijackings with Origin Anomalies

Missing route ﬁlters: OA 1 was caused by a route ﬁl-
ter failure.
In this case, AS23910 learned two routes to
166.111.32.0/24 and 166.111.111.0/24, which were owned
by AS4538. The Network operators conﬁrmed that, since
AS23910 accidentally removed its corresponding ﬁlters for a
short period, these two routes were incorrectly redistribut-
ed into BGP, and then announced to the Internet, with
AS23910 as the origin. This corresponds to the period when
Ft > 0.6 in Fig. 21(a).

Network maintenance misplay:

in OA 2, AS50407
was a customer of the victim AS15763. The network opera-
tors of AS50407 said they made a mistake when they were
carrying out network maintenance, and hijacked the preﬁx
193.105.17.0/24 for 12 minutes. In Fig. 21(b), after the hi-
jacking was detected, the ﬁngerprint kept above 0.6 for the
remaining window.

Premature migration attempt: OA 3 was caused by
a premature route migration that was not well planned. In

this case, AS197279 was to migrate 91.217.242.0/24 to an-
other AS AS48559 “in the coming week or so”, as said in
their reply to our alarm. However, before the planned time,
AS48559 announced itself as the owner of this preﬁx, which
AS197279 was still keeping announcing at that time. Since
live hosts have not moved into AS48559, polluted eyes could
not reach them, and Ft increased above 0.6. The hijacking
lasted about 17 minutes and Argus detected it within 9 sec-
onds, as shown in Fig. 21(c). OA 4 is a similar case, where
AS27005 announced the same preﬁx as AS701 did. There is
a little diﬀerence from OA 3: live hosts in AS27005 became
reachable after 70 seconds (still in the detection window),
while live hosts in AS701 also kept reachable until several
hours later, so Ft later decreased to 0 in Fig. 21(d).

Sub-preﬁx hijacking: OA 5 was conﬁrmed by AS7018,
which was the owner of a preﬁx 12.128.0.0/9. One of its
sub-preﬁxes, 12.231.155.0/24, was incorrectly announced by
AS13490 at March 22, 2012, and the hijacking lasted about
16 minutes. As shown in Fig. 21(e), this sub-preﬁx hijacking
polluted around 20 eyes in 20 seconds, which is faster than
the other cases. Interestingly, we also noticed that this sub-
preﬁx was oﬃcially assigned to and announced by AS54357
nine days later, and Argus successfully detected that event
and classiﬁed it as a route migration (i.e., the ﬁngerprint
was close to -1.0).

6.2 Hijackings with Adjacency Anomalies

Mis-conﬁguration in traﬃc engineering: in the case

25 
#
#
 
 
 
#
#
 
 
 
#
#
 
 
 
#
#
 
 
#
#
 
 
 
#
#
 
(a) PA 1: Routing policy of AS21021.

(b) PA 2: Routing policy of AS31484.

Figure 23: IRR records of PA 1 and PA 2.

of AA 1, AS24465 was connecting to two providers, and was
using AS-Path prepending (ASPP) to achieve inbound Traf-
ﬁc Engineering. It normally announced its preﬁx 210.1.38.0/24
to one provider AS4750, but prepended itself for 4 times
in the AS-path announced to the other provider AS7693.
The hijacking happened when AS24465 connected to a new
provider AS38794 and announced the preﬁx to it. However
traﬃc could not go through the new one, and Argus immedi-
ately notiﬁed the operators of AS38794. When they replied
50 minutes later, we found the problem was ﬁxed, and ASPP
was also used in the new route.

AS-path poisoning experiment: AA 2 was caused by
a rerouting experiment launched by Georgia Tech and Uni-
versity of Washington [19], using AS47065. They announced
a looped path h47065, x, 47065i for preﬁx 184.164.255.0/24,
so that AS x would not accept this route later, and the
corresponding traﬃc would not go through x. They repeat-
ed the experiments periodically for many times, and Argus
continuously reported adjacency anomalies. If things went
well, we should have identiﬁed no hijackings, since the desti-
nation should be reachable even when the path changed. 18
However, in an experiment when x was set to 19782, the tar-
get preﬁx became unreachable on our eyes that were using
the new path, but was still reachable on the eyes that were
using the normal path without loop, and Argus reported
hijackings accordingly.

Short-lived neighbor: AA 3 was caused by AS17368
pretending to be a neighbor of AS26263, which was the own-
er of the victim preﬁx 205.153.112.0/22. The hijacking pol-
luted 4 eyes, and lasted 14 minutes. Later, this adjacency
disappeared and was never announced again.

6.3 Hijackings with Policy Anomalies

Import policy violation: PA 1 was caused by an im-
port ﬁlter failure of AS21021. As described by the IRR
records of AS21021 (Fig.
it will import a route
from AS12741 if and only if the corresponding AS-path is
originated by AS12741. However, in this case, it accept-
ed a route originated by AS47728, and the anomalous triple
h21021, 12741, 47728i was detected by Argus. When the traf-
ﬁc was hijacked by this route, Argus reported this case.

23(a)),

Export policy violation: PA 2 was caused by an ex-
port ﬁlter failure of AS31484. According to the IRR record-
s of AS31484, it has two providers, AS20764 and AS3267.
The route ﬁlter in the IRR, as shown in Fig. 23(b), mean-
s AS31484 will accept ANY route announced by the two
providers, but will only announce routes originated from

18Actually Argus reported route migrations, as expected.

AS31484 or AS196931 (its customer) to them. In this case,
AS31484 incorrectly announced routes learned from its provider
AS3267 to the other provider AS20764, so Argus detected
the anomalous triple h20764, 31484, 3267i. Later, it success-
fully identiﬁed the hijacking.

6.4 Non-hijacking Anomalies

As we have mentioned before, Argus can also classify non-
hijacking anomalies into diﬀerent types, including route mi-
gration, traﬃc engineering, etc., as shown in Fig. 8. We an-
alyze three cases to demonstrate this capability. Fig. 22 ex-
plains how they are diﬀerent from hijackings, where for each
case, we plot the corresponding ﬁngerprint Ft, the reachabil-
ity Dt to the anomalous preﬁx, and the number of polluted
eyes.

TE using BGP anycast: Root DNS servers usually use
In
BGP anycast to balance and optimize DNS requests.
this case, the anomalous preﬁx 193.0.16.0/24 was used by
the root DNS server k, and was operated by RIPE NCC.
Argus detected that this preﬁx was suddenly announced by
a new origin AS197000. Since all its eyes, either polluted
or not, could reach the target preﬁx (i.e., Dt = 1), while
the ﬁngerprint Ft was close to 0, it was identiﬁed as traﬃc
engineering. Fig. 22(a) shows the corresponding Ft and Dt.
TE with backup links: In this case, AS12476 announced
an AS-path with ASPP to AS6453, which was its provider
but had never appeared as the its neighbor before. The new
path exposed this backup link accidentally. Similarly to the
ﬁrst case, Ft was always 0 while Dt was always 1, as shown
in Fig. 22(b).

Route migration: AS12653 and AS7700 were operated
by the same ISP (KB Impuls Hellas, Greece). During the
route migration, AS12653 stopped announcing routes, while
AS7700 started to take the place. In the route convergence
process, almost all eyes that had learned the new routes
could reach the target preﬁx, while eyes using the old routes
could not. This led to a negative Ft (i.e., less than -0.6), as
is in Fig. 22(c).

7. DISCUSSION

To show the advantages of Argus, we compare it with some
representative hijacking detection systems proposed earlier.
A control plane based system such as Cyclops [12] will re-
port the 20K OA anomalies, while Argus can identify 122
stable hijackings out of them. This can lower the burden to
handle hijackings by two orders of magnitude. Data plane
methods [34, 36] have to continuously measure the Inter-
net for each preﬁx they care, while Argus only probe the
Internet for two minutes when an anomaly appears. The
measurement overhead in one year can be roughly comput-
ed as (40K anomalies) × (2 minutes) × (80 eyes) for Argus,
and as (400K preﬁxes) × (1 year) × (1 eye) for the system
in [36], resulting in a diﬀerence of four orders of magnitude.
The overhead of iSPY [34] is less since it only monitors the
preﬁxes owned by the organization who deploys the system,
but if the entire Internet is to be protected, the overhead
will be comparable to that in [36]. Moreover, these data
plane methods cannot detect sub-preﬁx hijackings (around
10% in our data), unless every possible sub-preﬁx is moni-
tored. They also cannot distinguish BGP anycast and route
migration from hijackings since they are based on data path
changes. The method utilizing both data and control plane
information [16] relies on host-speciﬁc ﬁngerprints, such as

26t
n
i
r
p
r
e
g
n
i
f

y
t
i
l
i
b
a
h
c
a
e
r

1.2
0.6
0.0
-0.6
-1.2

  reachability
  fingerprint

  polluted  eyes

0

20

40
time 

60
( seconds)

80

(a) BGP anycast

20

10

0
120

100

s
e
y
e

d
e
t
u
l
l
o
p

t
n
i
r
p
r
e
g
n
i
f

y
t
i
l
i
b
a
h
c
a
e
r

1.2
0.6
0.0
-0.6
-1.2

  reachability
  fingerprint

  polluted  eyes

0

20

40
time 

60
( seconds)

80

(b) Backup link

20

10

0
120

100

s
e
y
e

d
e
t
u
l
l
o
p

t
n
i
r
p
r
e
g
n
i
f

y
t
i
l
i
b
a
h
c
a
e
r

1.2
0.6
0.0
-0.6
-1.2

  reachability

  polluted  eyes

  fingerprint

0

20

40
time 

60
( seconds)

80

20

10

0
120

100

s
e
y
e

d
e
t
u
l
l
o
p

(c) Route migration

Figure 22: Case studies of non-hijacking anomalies: ﬁngerprint, reachability and the number of polluted eyes.

OS property, IP ID, timestamp, etc., thus may also fail when
BGP anycast or route migration happens. Besides, its de-
tection delay is at least a few minutes while Argus needs
only a few seconds.

Argus also has some limitations. It relies on ping to de-
tect blackholing behavior, so malicious attackers can evade
the system by actively responding to ping. However, we
believe our earlier measurement results are still reasonable,
and we will integrate other ﬁngerprinting methods into Ar-
gus. A carefully crafted AS-path based on existing path seg-
ments may also evade our detection although building such
a path is very diﬃcult, and advanced detection and protec-
tion methods are still needed. Another weakness may lie in
our metric Ft, which can be speciﬁcally attacked by carefully
choosing the time/preﬁx to hijack, and how to devise more
robust hijacking ﬁngerprints is worth further study. Many
components of Argus can be continuously improved, e.g., by
adding eyes in diﬀerent ASes, and refreshing live hosts [1].
Finally, much more can be done on the classiﬁcation of route
anomalies, and the characterization of realworld hijackings.

8. CONCLUSIONS

In this paper, we present Argus, a system for detecting IP
preﬁx hijackings. Compared with existing methods, Argus
has many advantages, and our one year practice in monitor-
ing the Internet shows it can accurately distinguish preﬁx
hijackings from a vast number of anomalies in a very short
time, and can further deduce the possible root causes. It is
very easy to deploy, and we are now providing it as a public
service, which has already successfully helped many network
operators to diagnose their network operations. In the fu-
ture, we plan to incorporate more diagnosis information and
make it more intelligent.

9. ACKNOWLEDGEMENT

We are grateful to the anonymous IMC reviewers and
our shepherd Mark Crovella for their insightful comments.
We also want to express our gratitude towards the net-
work operators we have contacted for their generous coop-
eration and feedback. This work is supported by the Na-
tional Key Technology R&D Program of China (Grant No.
2008BAH37B03), and the National Basic Research Program
of China (973 Program, Grant No. 2009CB320502).

10. REFERENCES
[1] Ant censuses of the internet address space.

http://www.isi.edu/ant/traces/index.html.

[2] Archipelago Measurement Infrastructure.
http://www.caida.org/projects/ark/.

[3] The BGPmon project.

http://bgpmon.netsec.colostate.edu.

[4] BGPmon.net. http://bgpmon.net/.
[5] Charter of the IETF Secure Inter-Domain Routing

Working Group.
http://tools.ietf.org/wg/sidr/charters.
[6] DNS records collected by Hurricane Electric.

http://bgp.he.net/net/166.111.0.0/16#_dns.

[7] Irr - internet routing registry. http://www.irr.net/.
[8] Ripe myasn system.

http://www.ris.ripe.net/myasn.html.

[9] H. Ballani, P. Francis, and X. Zhang. A study of preﬁx

hijacking and interception in the internet. In
SIGCOMM, 2007.

[10] S. M. Bellovin, R. Bush, and D. Ward. Security

requirements for bgp path validation. http://tools.
ietf.org/html/draft-ymbk-bgpsec-reqs-02, 2011.

[11] M. Caesar, L. Subramanian, and R. H. Katz. Towards

root cause analysis of internet routing dynamics. In
Berkeley EECS Annual Research Symposium, 2004.
[12] Y.-J. Chi, R. Oliveira, and L. Zhang. Cyclops: The
AS-level connectivity observatory. ACM SIGCOMM
Computer Communication Review, pages 7–16, 2008.
[13] N. Feamster, D. G. Andersen, H. Balakrishnan, and

M. F. Kaashoek. Measuring the eﬀects of internet path
faults on reactive routing. In SIGMETRICS, 2003.

[14] A. Feldmann, O. Maennel, Z. M. Mao, A. W. Berger,

and B. M. Maggs. Locating internet routing
instabilities. In SIGCOMM, 2004.

[15] S. Goldberg, M. Schapira, P. Hummon, and

J. Rexford. How secure are secure interdomain routing
protocols? In SIGCOMM, 2010.

[16] X. Hu and Z. M. Mao. Accurate real-time

identiﬁcation of ip preﬁx hijacking. In IEEE
Symposium on Security and Privacy, pages 3–17, 2007.

[17] G. Huston and G. Michaelson. RFC 6483: Validation

of Route Origination Using the Resource Certiﬁcate
Public Key Infrastructure (PKI) and Route Origin
Authorizations (ROAs).
http://tools.ietf.org/html/rfc6483, 2012.

[18] J. Karlin, S. Forrest, and J. Rexford. Pretty good

BGP: Improving BGP by cautiously adopting routes.
In ICNP, pages 290–299, 2006.

[19] E. Katz-Bassett. Announcement of university of

washington routing study. http://mailman.nanog.
org/pipermail/nanog/2011-August/039337.html.

[20] E. Katz-Bassett, H. V. Madhyastha, J. P. John,

A. Krishnamurthy, D. Wetherall, and T. E. Anderson.
Studying black holes in the internet with hubble. In
NSDI, 2008.

[21] S. Kent, C. Lynn, J. Mikkelson, and K. Seo. Secure
border gateway protocol (S-BGP). IEEE Journal on
Selected Areas in Communications, 18:103–116, 2000.

27 
#
(
)
#
 
 
 
#
(
)
#
 
 
 
#
(
)
#
 
 
[22] M. Lad, D. Massey, D. Pei, Y. Wu, B. Zhang, and
L. Zhang. PHAS: A preﬁx hijack alert system. In
USENIX, 2006.

[23] H. Madhyastha, T. Isdal, M. Piatek, C. Dixon,

T. Anderson, and A. Krishnamurthy. iPlane: An
information plane for distributed services. In OSDI,
pages 367–380, 2006.

[30] L. Subramanian, V. Roth, I. Stoica, S. Shenker, and

R. H. Katz. Listen and whisper: Security mechanisms
for BGP. In NSDI, pages 127–140, 2004.

[31] F. Wang, Z. M. Mao, J. Wang, L. Gao, and R. Bush.
A measurement study on the impact of routing events
on end-to-end internet path performance. In
SIGCOMM, 2006.

[24] R. Mahajan, D. Wetherall, and T. Anderson.

[32] Y. Xiang, Z. Wang, X. Yin, and J. Wu. Argus: An

Understanding bgp misconﬁguration. In SIGCOMM,
pages 3–16, 2002.

[25] S. Murphy. Rfc 4272: Bgp security vulnerabilities
analysis. http://tools.ietf.org/html/rfc4272,
2006.

[26] R. Oliveira, B. Zhang, D. Pei, R. Izhak-Ratzin, and

L. Zhang. Quantifying path exploration in the
Internet. In Proc. of the 6th ACM SIGCOMM
Internet Measurement Conference (IMC), Rio de
Janeriro, Brazil, 2006.

[27] Y. Rekhter, T. Li, and S. Hares. RFC 4271: Border

gateway protocol 4.
http://tools.ietf.org/html/rfc4271, 2006.

accurate and agile system to detecting ip preﬁx
hijacking. In Workshop on Trust and Security in the
Future Internet, 2011.

[33] B. Zhang, R. Liu, D. Massey, and L. Zhang. Collecting

the internet as-level topology. SIGCOMM Comput.
Commun. Rev., 35(1):53–61, 2005.

[34] Z. Zhang, Y. Zhang, Y. C. Hu, Z. M. Mao, and

R. Bush. iSPY: Detecting ip preﬁx hijacking on my
own. In SIGCOMM, pages 327–338, 2008.

[35] X. Zhao, D. Pei, L. Wang, D. Massey, A. Mankin,

S. F. Wu, and L. Zhang. An analysis of BGP multiple
origin as (MOAS) conﬂicts. In 1st ACM SIGCOMM
Workshop on Internet Measurement, 2001.

[28] Renesys. China’s 18-minute mystery.

[36] C. Zheng, L. Ji, D. Pei, J. Wang, and P. Francis. A

http://www.renesys.com/blog/2010/11/
chinas-18-minute-mystery.shtml, 2010.

[29] RIPE. Youtube hijacking: A ripe ncc ris case study.

http://www.ripe.net/news/
study-youtube-hijacking.html, 2008.

light-weight distributed scheme for detecting ip preﬁx
hijacks in real-time. In SIGCOMM, pages 324–334,
2007.

28