Automatically Inferring the Evolution of Malicious Activity on the Internet

Shobha Venkataraman
AT&T Labs – Research
shvenk@research.att.com

David Brumley

Carnegie Mellon University

dbrumley@cmu.edu
Oliver Spatscheck

AT&T Labs – Research
spatsch@research.att.com

Subhabrata Sen

AT&T Labs – Research
sen@research.att.com

Abstract

Internet-based services routinely contend with a range of
malicious activity (e.g., spam, scans, botnets) that can po-
tentially arise from virtually any part of the global Internet
infrastructure and that can shift longitudinally over time. In
this paper, we develop the ﬁrst algorithmic techniques to au-
tomatically infer regions of the Internet with shifting secu-
rity characteristics in an online fashion. Conceptually, our
key idea is to model the malicious activity on the Internet as
a decision tree over the IP address space, and identify the
dynamics of the malicious activity by inferring the dynamics
of the decision tree. Our evaluations on large corpuses of
mail data and botnet data indicate that our algorithms are
fast, can keep up with Internet-scale trafﬁc data, and can
extract changes in sources of malicious activity substan-
tially better (a factor of 2.5) than approaches based on us-
ing predetermined levels of aggregation such as BGP-based
network-aware clusters. Our case studies demonstrate our
algorithm’s ability to summarize large shifts in malicious
activity to a small number of IP regions (by as much as two
orders of magnitude), and thus help focus limited operator
resources. Using our algorithms, we ﬁnd that some regions
of the Internet are prone to much faster changes than others,
such as a set of small and medium-sized hosting providers
that are of particular interest to mail operators.

1 Introduction

Business-critical Internet-based services have to rou-
tinely contend with and mitigate a range of malicious ac-
tivity (e.g. spam, scans, botnets) that can arise from vir-
tually any part of the global Internet infrastructure. Iden-
tifying the regions of malicious activity on the Internet is
valuable for enhancing the security of networks, applica-
tions, and end-users along multiple dimensions and time-
scales. However, static snapshots showing malicious activ-

ity at a particular point of time are of limited use because
evil is constantly on the move. Administrators often even-
tually discover and clean up infected hosts, which causes
attackers to target new vulnerabilities and attack new hosts
elsewhere. Indeed, operators care far more about the evolu-
tion of malicious activity than static snapshots, as the evo-
lution provides warning signs of emerging threats from re-
gions previously-considered benign.

However, there has been little work on developing al-
gorithms that can automatically infer how aggregations of
malicious IPs evolve over time. Previous work has either
created static snapshots [28, 29], or has explored the feasi-
bility of using various a priori ﬁxed IP clustering schemes
for spam-ﬁltering over longer periods [9, 13, 22, 27, 30],
among which BGP-based preﬁx clustering schemes, such
as network-aware clusters [19] have been especially popu-
lar. One challenge is it is not obvious a priori what level
of aggregation granularity to use. While we know mali-
cious IP addresses tend to be clustered, e.g., to ISPs with
poorly-managed networks [5, 21, 23, 30], many natural op-
tions for a particular granularity provide inaccurate results.
For instance, the individual IP address is too ﬁne-grained
to provide useful results [16, 23, 30, 31], e.g., DHCP can
cause a single attacker to appear and disappear quickly from
speciﬁc IP addresses. On the other hand, predetermined
aggregations of IP addresses such as by AS or BGP pre-
ﬁx also does not afford the correct granularity. For exam-
ple, network-aware clustering using BGP routing preﬁxes
are likely to cluster the well-managed infrastructure hosts
of an ISP together with its poorly-managed broadband ac-
cess customers. This is highlighted in several recent re-
sults [9, 13, 22, 27], which have illustrated that BGP-based
IP aggregations allow only for a coarse classiﬁcation of ma-
licious activity.

Since there are no obvious natural a priori aggregations
to use, we need to be able to automatically infer the ap-
propriate aggregation levels for detecting changes in dif-

ferent parts of the Internet, based on current observations.
The appropriate aggregation varies drastically from region
to region: some regions, such as small or mid-sized hosting
providers, likely need to be monitored at very ﬁne granu-
larities (such a /24 or smaller preﬁx size), while other re-
gions (e.g., entire countries that appear to be spam havens)
need to be monitored at much coarser granularities. The
problem becomes even more critical as IPv6 starts to get
widely deployed – it is infeasible to even enumerate every
IP address in the IPv6 address space. A practical algorithm
therefore needs to scale as a function of the number of dis-
tinct preﬁx aggregations needed, not as a function of the
size of the address space. A further complication is that
not every change in malicious activity is useful to ﬁnd, e.g.,
newly spamming IPs are of little interest if they belong to
a well-known spam haven, but of substantial interest if they
belong to a well-managed business network. Previous work
has not addressed this problem.

In this paper, we develop the ﬁrst algorithmic techniques
to automatically infer regions of the internet with shifting
security characteristics in an online fashion. We call an IP
preﬁx that turns from good to evil a ∆-bad preﬁx, and a bad
preﬁx that sees the light and becomes good a ∆-good preﬁx.
Our key idea is that shifts in malicious activity will trigger
errors in an accurate classiﬁer of the IP address space’s ma-
licious activity. We model the IP address space as a decision
tree, which when given a particular preﬁx, outputs a label
“good” or “bad”. We also periodicially measure the error in
the decision tree, i.e., measure when it labels an IP preﬁx as
good when it is, in fact, originating malicious trafﬁc. The
intuition is that when the decision tree has such errors on
preﬁxes that it used to label accurately, it is not indicative
of a problem with the decision tree, but instead indicative of
a ∆-good or ∆-bad change. An additional challenge is that
not all preﬁxes need to be modeled at the same granular-
ity, e.g., AT&T’s preﬁx should not be modeled at the same
granularity as MIT, even though both own a /8. A key com-
ponent of our algorithm is it automatically infers the right
granularity to minimize error in labeling IP preﬁxes ∆-good
or ∆-bad.

More speciﬁcally, we present two algorithms to answer
two main questions. First, can we identify the speciﬁc re-
gions on the Internet that have changed their malicious ac-
tivity? Second, are there regions on the Internet that change
their malicious activity much more frequently than others?
The ﬁrst question helps operators quickly focus their atten-
tion on the region of importance, e.g., if one of their net-
works is suddenly compromised. The second question ex-
plores structural properties about the nature of changes in
malicious activity, highlighting the preﬁxes that need to be
“under watch”, as they are among the most likely to be fu-
ture sources of attacks.

We present two algorithms, ∆-Change and ∆-Motion

respectively, that address the above two questions. At a
high-level, ∆-Change answers the ﬁrst question by analyz-
ing how well the different preﬁx aggregations in the static
snapshots model input data. By design, it ensures that every
preﬁx identiﬁed by our algorithms has indeed undergone a
change, i.e., our list of ∆-bad and ∆-good preﬁxes has no
false positives. ∆-Motion answers the second question by
using previously-accurate snapshots to identify individual
IP addresses that have changed their behaviour, and then
partitions the address space into regions that have a high
volume of changes and regions that have few changes. Our
algorithms work without assuming a ﬁxed distribution of
IP addresses (a common assumption in many learning al-
gorithms, which allows for easier learning and inference).
Indeed, part of the data comes from malicious adversaries
who have an incentive to mislead our algorithms and evade
detection.

We evaluate our algorithms experimentally on two dif-
ferent sources of malicious activity from a tier-1 ISP – four
months of mail data labeled with spamming activity, and
three months of network traces labeled with botnet activity,
and we demonstrate that our algorithmic techniques can ﬁnd
changes in spam and botnet activity. In particular, our ex-
periments show we can ﬁnd more shifts in malicious activ-
ity by a factor of 2.5 than by applying extensions of existing
static algorithms such as network aware clusters. Through
case studies, we demonstrate how our algorithms can pro-
vide operators with a network-wide understanding of mali-
cious activity (both internal as well as external), and help
them prioritize scarce manual effort to the most affected re-
gions. For example, in one case study, our algorithm sum-
marized a large shifts in botnet activity into a very small
number of ∆-change preﬁxes (22,000-36,000 new IPs from
DNSChanger and Sality botnets into 19-66 preﬁxes – a drop
of over two orders of magnitude). In another case study,
our algorithm discovered a large number of regional ISPs
whose spamming activity dropped during the takedown of
the Grum botnet.
Finally, we ﬁnd that there are certain
regions of the IP address space that are much more prone to
changes in spamming activity. For example, we found that a
set of small and mid-sized hosting providers (which do not
appear as distinct entities in BGP preﬁxes) are extremely
prone to changes in spam activity – this is an intuitive re-
sult which network operators can easily validate (and then
begin to monitor), and which our algorithm discovered au-
tomatically from noisy decision tree snapshots with nearly
100,000 nodes each.

Our algorithms are also scalable: our current (unopti-
mized) implementation is able to process a day’s worth
of data (30-35 million IPs) in around 20-22 minutes, on a
2.4GHz processor with only a single pass over the data and
uses only 2-3 MB of memory. Further, a switch to IPv6
will have relatively little impact on our algorithm, as the re-

quired size of the decision trees is only a function of the dis-
tinct administrative entities in terms of malicious behaviour,
rather than the size of the address space.

More broadly, our results show that while there is plenty
of change in the malicious (both spamming and botnet) ac-
tivity on the Internet, there is also signiﬁcant structure and
predictability in these changing regions, which may be use-
ful for enhancing mitigation strategies.

2 Deﬁnitions and Preliminaries

Our high-level goal is to design an algorithm that takes
as input a stream of IP addresses ﬂagged malicious or non-
malicious (e.g., spam logs, labeled with spam-ﬁltering soft-
ware), and ﬁnds a set of IP preﬁxes whose IP addresses
have changed from malicious to non-malicious, or vice-
versa, across the stream. In this section, we describe how
important changes can be naturally modeled by monitoring
a decision tree on the IP address space.
Background. We ﬁrst introduce some standard machine
learning terminology. A classiﬁcation function (or a classi-
ﬁer) is a function that takes as input a given IP address, and
outputs a label denoting whether the IP address is malicious
(also denoted by a “-”) or non-malicious (also denoted by a
“+”). The classiﬁcation function makes a mistake whenever
it labels a malicious IP address as non-malicious, or a non-
malicious IP address as malicious. The classiﬁcation error
of a classiﬁcation function is the fraction of the input IP ad-
dresses on which it makes a mistake.

We also introduce some networking background. An IP
address preﬁx (also called IP preﬁx) i/d denotes the part
of the IP address space that is covered by the ﬁrst d bits
of i, e.g., the preﬁx 10.0.0.0/8 indicates the part of the IP
address space whose ﬁrst octet is 10, i.e., all IP addresses
in the set 10. ∗ . ∗ .∗. Note that the preﬁx i/d + 1, (i.e.,
10.0.0.0/9 in our example) denotes a subset of the address
denoted that i/d (i.e., 10.0.0.0/8). The IP address hierarchy
can be naturally interpreted as a binary tree: the leaves of
the tree correspond to individual IP addresses, the internal
nodes correspond to the IP preﬁxes, and IP preﬁx i/d is the
parent of the preﬁx i/d + 1 in this representation. We say
that IP preﬁx x belongs to preﬁx y if x is a parent of y in
this tree, e.g., 10.0.0.0/9 belongs to 10.0.0.0/8.

2.1 Modeling the Problem

We begin with a motivating example. Consider a /23 pre-
ﬁx owned by an access provider, and suppose that a number
of hosts with IP addresses in this /23 get compromised and
start spamming. Now if this /23 preﬁx belongs to a larger
preﬁx (say, a parent /22) that is already a known spam-
haven, this new spamming activity of the /23 is not very
interesting to an operator, since the larger region is known
to spam (i.e., it is not surprising that a smaller region within
a known spam-haven also starts to spam). If, on the other

(a) No change

(b) Change

Figure 1. Example of ∆-bad Changes.
(a) shows a
preﬁx that is not ∆-bad, because /23 starts originating
malicious trafﬁc when its parent /22 is already known to
originate malicious trafﬁc (b) shows a preﬁx that is de-
ﬁned as ∆-bad, because the /23 starts originating mali-
cious trafﬁc when its parent /22 is not known to originate
malicious trafﬁc.

hand, the larger preﬁx (e.g., the parent /22) has originated
only legitimate trafﬁc so far, the new spamming activity be-
comes much more interesting to network operators, because
they previously assumed that the region did not spam. By
notifying operators of the change, they can control or block
the spam from the /23 to their networks. We illustrate this
example in Figure 1.

A key part of this example is having an accurate clas-
siﬁer for the the type of trafﬁc originated by the two /22
preﬁxes – we need to know what kind of trafﬁc a particular
region is expected to originate, before we can understand
when the region has changed its malicious activity. How-
ever, we do not have such a classiﬁer given to us as input,
and we need to infer it dynamically from a stream of IP ad-
dresses and their associated labels. Thus, to infer change,
we ﬁrst have to infer such a classiﬁer for the preﬁxes from
the labeled IP addresses, and then use this classiﬁer to infer
changes. Moreover, the appropriate preﬁx granularity for
such a classiﬁer is different in different parts of the Inter-
net, we need to also infer the required preﬁx granularities.
Because it is likely impossible to infer a classiﬁer with zero
error, we instead will look for changes relative to any clas-
siﬁer that makes no more than τ error on the data, for small
(input) τ > 0. By deﬁnition, all such classiﬁers must clas-
sify most of the data identically. In particular, let st denote
the stream of input < IP, label > pairs appearing in epoch
t; our goal is to detect preﬁxes that have changed in st+1
relative to a classiﬁer that makes no more than an input τ
error on st.

Algorithmic constraints and Adversarial Model The
scale of network trafﬁc makes it infeasible to use compu-
tationally expensive algorithms.
In particular, a solution
should have constant processing time per IP, make only a
single pass over the input streams, and have memory re-
quirements that are sublinear in the input data size. Such al-

0.0.0.0/1

0.0.0.0/2

0.0.0.0/0

128.0.0.0/1

192.0.0.0/2

+

-

+

160.0.0.0/3

+

128.0.0.0/4

152.0.0.0/4

+

-

Figure 2. Example IPtree of size 6, since it has 6 leaves.
Each leaf has a ”+” or a ”-”, denoting whether the asso-
ciated preﬁx originates non-malicious or malicious traf-
ﬁc. Section 3 describes how we learn such a tree from
data.

gorithms are called online, and are among the most desired
(and difﬁcult to create). In addition, our data may have to
have some noise – e.g., an IP may be labeled as produc-
ing spam incorrectly. For example, if our labels are com-
ing from SpamAssassin, and SpamAssassin mislabels legit-
imate mail from an IP as spam, then our algorithm receives
an inaccuracy label for this IP, and must be able to cope with
this inaccuracy. Our algorithm’s performance thus needs to
scale gracefully as the noise increases, and be able to pro-
duce accurate output when the noise in the data is tiny. Fi-
nally, we cannot assume that input IPs are drawn from a
ﬁxed probability distribution over I. Although assuming a
ﬁxed distribution would be easier, it would make the algo-
rithm easier to evade. In particular, we assume an adversary
can pick the addresses from which malicious activity origi-
nates, and therefore, could mislead any algorithm assuming
that all IPs originate from a priori ﬁxed distribution.

Practical considerations There are additional constraints
that make the algorithm more useful by directing atten-
tion towards changes that are most actionable by operators.
First, we aim to detect preﬁxes with at least θ trafﬁc since
(1) data may be occasionally mislabeled, and (2) changes in
preﬁxes with very little trafﬁc may not be noteworthy.

In addition, operators only care about preﬁxes where the
change is directly evident: i.e., if the preﬁx changes from
originating mostly non-malicious activity to mostly mali-
cious activity, or vice versa. 1 To formalize this concept, we
introduce the concept of a state to reﬂect level of malicious
activity of a preﬁx. Formally, a state is deﬁned by an inter-
val in [0, 1]; the set of all states D input to the algorithm is
given by a collection of non-overlapping intervals in [0, 1].
A preﬁx is assigned a state based on the fraction of trafﬁc
it originates that is non-malicious. Thus, for example, the
state deﬁned by the interval [0, 0.2] is assigned to preﬁxes

1There may be situations where a preﬁx undergoes changes, but the
change is not directly observed when trafﬁc is aggregated at that preﬁx,
e.g., a preﬁx could originate roughly the same amount of malicious and
non-malicious trafﬁc in st+1 as it did in st, but misclassify both malicious
and non-malicious activity on st+1 (perhaps because some of its children
preﬁxes have changed). We ignore such changes in this paper as they are
not typically actionable.

sending between 0 − 20% spam. Conceptually, the state
of a preﬁx can be thought of measuring the level of ”bad-
ness” of the preﬁx. We deﬁne a localized change in a preﬁx
to be one where the preﬁx has changed its state, and our
goal is to ﬁnd only localized changes. For example, sup-
pose the set D consists of two intervals [0, 0.2) and [0.2, 1).
A preﬁx that used to send less than 20% spam, but now
sends between 20−100% has undergone a localized change
(in effect, the preﬁx is considered non-malicious if it sends
less than 20% spam, and malicious if it sends at least 20%
spam, and we are only interested in ﬁnding when the preﬁx
changes from malicious to non-malicious, or vice-versa.)
The set D is input to the algorithm. Continuous intervals
provide ﬁner-grained data to operators than just malicious
and non-malicious. Of course, in reports to the operators,
we can always reduce to just malicious and non-malicious
if desired. 2
Modeling Malicious Activity of Preﬁxes as Decision
Tree. We take advantage of the structural properties of
malicious activity in order to design an efﬁcient and ac-
curate algorithm for detecting changes. Prior work has
demonstrated that malicious trafﬁc tends to be concentrated
in some parts of the address space [5, 21, 23, 30] – that is,
the IP address space can be partitioned into distinct preﬁx-
based regions, some of which mostly originate malicious
trafﬁc and some that mostly originate legitimate trafﬁc. We
observe that the IP address space can be represented as a
tree of preﬁxes. Thus, we can model the structure of ma-
licious activity as a decision tree over the IP address space
hierarchy rooted at the /0 preﬁx: the leaves of this tree are
preﬁx-based partitions that send mostly malicious or mostly
non-malicious trafﬁc; this is a decision tree since each leaf
in the tree can be considered as having a ”label” that indi-
cates the kind of trafﬁc that the corresponding preﬁx-based
region originates (e.g., the label might be ”bad” when the
region originates mostly malicious trafﬁc, ”good” when the
region originates mostly legitimate trafﬁc). The changes in
preﬁx behaviour can then be precisely captured by changes
in this decision tree. In Sec. 3, we describe how we learn
this decision tree to model the malicious activity from the
data.

More formally: let I denote the set of all IP addresses,
and P denote the set of all IP preﬁxes. An IPTree TP over
the IP address hierarchy is a tree whose nodes are preﬁxes
P ∈ P, and whose leaves are each associated with a la-
bel, malicious or non-malicious. An IPtree thus serves as a
classiﬁcation function for the IP addresses I. An IP address
i ∈ I gets the label associated with its longest matching
preﬁx in the tree. A k-IPtree is an IPtree with at most k
leaves. By ﬁxing the number of leaves, we get a constant-

2We could also deﬁne changes in terms of the relative shift in the ma-
licious activity of the preﬁx. However, the deﬁnition we use above allows
for a conceptually easier way to explain preﬁx behavior.

sized data structure. The optimal k-IPtree on a stream of
IP address-label pairs is the k-IPtree that makes the small-
est number of mistakes on the stream. Figure 2 shows an
example IPtree of size 6.

We deﬁne preﬁx changes in terms of the IPTree: We de-
ﬁne a ∆-bad preﬁx for an IPTree T as a preﬁx p that starts
to originate malicious trafﬁc when T labels trafﬁc from p
as legitimate. Likewise, a ∆-good preﬁx is a preﬁx p that
starts to originate legitimate trafﬁc when T labels trafﬁc
from p as malicious. In the example of Fig. 1, the /24s in the
ﬁrst and second scenarios are labeled as malicious and non-
malicious respectively. The /25 in the second case sends
trafﬁc that differs from the tree’s label. Fig. 1(b) shows an
example ∆-bad preﬁx. Without loss of generality, we will
use ∆-change preﬁx to refer to either ∆-good or a ∆-bad
preﬁx. We of course report back to an operator whether a
∆-change preﬁx is ∆-bad or ∆-good.

In this paper we use TrackIPTree as a subroutine in our
algorithms in order to infer decision trees from the data
stream, as it meets all our algorithmic requirements for scal-
ably building near-optimal decision trees over adversarial
IP address data [29]. (Note TrackIPTree does not solve the
problem of detecting the changed preﬁxes posed in this pa-
per, even with a number of extensions, as we discuss in Sec-
tion 2.2.) Conceptually, TrackIPTree keeps track of a large
collection of closely-related decision trees, each of which
is associated with a particular weight. It predicts the label
for an IP address by a choosing a decision tree from this set
in proportion to its relative weight in the set; when given
labeled data to learn from, it increases the weights of the
decision trees that make correct predictions, and decreases
the weights of those that make incorrect predictions. Track-
IPTree accomplishes this efﬁciently (from both space and
computation perspectives) by keeping a single tree with the
weights decomposed appropriately into the individual pre-
ﬁxes of the tree.

2.2 Alternate Approaches

We ﬁrst discuss a few previous approaches that may ap-
pear to be simpler alternatives to our algorithms, and ex-
plain why they do not work.
BGP preﬁxes.
A straightforward idea would be to use
BGP preﬁxes such as network-aware clusters [19], a clus-
tering that represents IP addresses that are close in terms
of network topology. BGP preﬁxes have been a popular
choice in measurement studies of spamming activity and
spam-detection schemes [9,13,22,27,30], but have increas-
ingly been shown to be far too coarse to model spamming
activity accurately [22].

Unfortunately, BGP preﬁxes perform poorly because
they do not model the address space at the appropriate
granularity for malicious activity. BGP preﬁxes only re-
ﬂect the granularity of the address space at which routing

happens, but actual ownership (and corresponding security
properties) may happen at ﬁner or coarser preﬁx granu-
larity.
(Likewise, ASes are also not an appropriate rep-
resentation because even though the Internet is clustered
into ASes, there is no one-to-one mapping between ser-
vice providers and ASes [3].) Our experiments in Sec. 4.1
demonstrate this, where network-aware clusters identify
around 2.5 times fewer ∆-change preﬁxes than our algo-
rithms. For example, such an algorithm fails to report ∆-
changes in small to medium hosting providers. These host-
ing providers are located in different regions of the world;
the provider manages small preﬁx blocks, but these preﬁx
blocks do not appear in BGP preﬁxes. Any change in the
hosting provider’s behavior typically just disappears into
the noise when observed at the owning BGP preﬁx, but
can be the root cause of malicious activity that the opera-
tor should know about.
Strawman Approaches based on TrackIPTree. A sec-
ond approach would be to learn IPTree snapshots that can
classify the data accurately for different time intervals, and
simply ”diff” the IPTree snapshots to ﬁnd the ∆-change pre-
ﬁxes. TrackIPTree [29] is a natural choice to construct these
IPTree, as it can build a near-optimal classiﬁer. However,
even with near-optimal IPTrees, we cannot directly com-
pare them to accurate ﬁnd ∆-change preﬁxes.

Let sa, sb be two arbitrary input sequences of IPs on
which we make no a priori assumptions, as described in
Section 2.1. 3 Let Ta and Tb be the resulting IPtrees after
learning over sa and sb respectively using TrackIPTree [29].
There are many immediate ways we could compare Ta and
Tb, but when the trees are large, noisy and potentially error-
prone, most of these lead to a lot of false positives. We use
here small examples to illustrate how these differencing ap-
proaches fail, and in Section 4, we show that these lead to
extremely high false positive rates on real IPTrees.

One possible approach to compare two decision trees is
to compare the labels of their leaves. However, the two trees
may assign different labels to a region even when there is
not a (signiﬁcant) difference in the relevant parts of sa and
sb, e.g., both trees may be inaccurate in that region, making
any differences found to be false positives.

Even if we know which parts of the tree are accurate, and
restrict ourselves to comparing only “mostly accurate” pre-
ﬁxes, we still cannot directly compare the trees. The trees
may still appear different because the tree structure is dif-
ferent, even though they encode almost identical models of

3We make no assumption on the < IP, label > pairs that are present
in sa and sb. This means that there may be some IPs that are common to
both sa and sb, and others that IPs are not present in sa or sb. The labels
of the common IPs do not need to be identical in sa and sb; indeed, we
expect that in real data, some of the common IPs will have the same labels
in sa and sb, but others will differ. Even within a single sequence sa, an
IP i does not need to have the same label throughout, it may have different
labels at different points in the sequence sa.

/0

/1

/16

/17

-

θ

/18

-

0.99θ

+
0.01θ

/0

/1

-
2θ

/16

(a) Learned Ta

(b) Learned Tb

Figure 3. Comparing “Mostly Accurate” Preﬁxes. Ta
and Tb classify 99% of trafﬁc seen identically, but would
be ﬂagged different because of differences in the tree
structure that affect very little trafﬁc.

the malicious activity. We illustrate this with the example in
Figure 3 (assume that each leaf shown in the ﬁgure classiﬁes
over 95% of its respective trafﬁc accurately). The two trees
Ta and Tb (learned over sa and sb respectively) then classify
over 99% of IPs identically, yet would be ﬂagged different
if we simply compared their accurate preﬁxes. Such small
deviations might just be caused by noise since the trees are
learned over different sequences, e.g., sa might have had
more noise than sb. It is of little use to identify such ∆-bad
preﬁxes for operators.

A third possible approach considers only preﬁxes that
are both “mostly accurate” and have sufﬁcient (at least θ)
trafﬁc, but even then, we cannot simply compare the trees.
Consider Figure 4, where the true tree has a /16 preﬁx with
two /17 children, and one /17 originates only malicious IPs,
while the other /17 originates only legitimate trafﬁc. In the
two learned trees Ta and Tb, none of the leaves see sufﬁ-
cient (θ) trafﬁc.4 In this example, the highlighted /16 preﬁx
is the longest parent preﬁx with θ trafﬁc in both Ta and Tb.
If we analyze the interior preﬁx’s activity by the trafﬁc it has
seen, most of the trafﬁc seen by the /16 is non-malicious in
Ta and malicious in Tb. Thus, we would ﬂag it as a ∆-bad
preﬁx. However, this is once again a false positive – note
that all leaf labels in Ta and Tb are identical (i.e., no re-
gion has actually changed its behaviour) – the only change
is that a few leaves send less trafﬁc in Ta and more in Tb
(and vice versa). Such changes in trafﬁc volume distribu-
tion occur routinely without malicious regions becoming
benign. For example, some spam-bots may become quiet
for a few days while they receive new spam templates, and
then restart spamming activities. In Sec. 4.1, we show em-
pirically that this third approach can lead to false positive

4We need to analyze the interior preﬁxes to ensure that we do not miss
legitimate changes. For example, imagine a scenario where most of the
leaves in Ta are negative, while most of the leaves in Tb are positive. The
longest parent preﬁx with at least θ trafﬁc is an interior preﬁx, and it has
clearly undergone a change. If we do not analyze the interior preﬁx, we
will miss such changes.

/0

/1

/16

/17

/0

/1

/16

/17

-
0.09θ

/18

-

0.01θ

+
0.9θ

-
0.9θ

/18

-

0.01θ

+
0.1θ

(a) Learned Ta

(b) Learned Tb

Figure 4. Comparing preﬁxes that are accurate as well
as have sufﬁcient trafﬁc. Ta and Tb are accurate, and
share identical leaf labels; however, none of the leaves
have enough trafﬁc to be compared.

rates of over 47%.

3 Our Algorithms
3.1 Overview of Our Approach

Our key insight is to use the classiﬁcation error between
the two trees in order to infer ∆-change preﬁxes. If a pre-
ﬁx has had low classiﬁcation error in earlier time intervals
with Tz, but now has high classiﬁcation error (on substan-
tial trafﬁc), we can infer that it has undergone a ∆-change.
The (earlier) low classiﬁcation error (on sufﬁcient trafﬁc)
implies our tree Tz used to model this region well in the
past intervals, but and the current high classiﬁcation error
implies does not do so any longer. Thus, we infer that the
preﬁx has changed its behavior – that it is sending trafﬁc that
is inconsistent with its past behaviour – and therefore, is a
∆-change region. As long as we are able to maintain a de-
cision tree with high predictive accuracy for the sequences,
our analysis can discover most preﬁxes changing between
sa and sb. Further, by only selecting preﬁxes that have a
high classiﬁcation error on a substantial fraction of the traf-
ﬁc, we build some noise-tolerance into our approach.

This insight shows that we need to achieve the follow-
ing three simultaneous goals to address the IPTree evolu-
tion problem: (1) keep track of a current model of the ma-
licious activity; (2) measure the classiﬁcation errors of the
current sequence based on a prior accurate model; (3) keep
track of a current model of the frequently changing regions.
We keep multiple decision trees over the address to simul-
taneously achieve these goals. At a high-level, we let one
IPtree learn over the current sequence, so it tracks the cur-
rent malicious activity. We keep second set of IPtrees ﬁxed
(i.e., they cannot change its labels, weights, or structure),
and use them to measure the classiﬁcation accuracy on the
current sequence. We then compare the classiﬁcation errors
of the second set of IPtrees (not the IPtrees themselves) on
the different sequences to compute the speciﬁc changed pre-
ﬁxes (details in Section 3.2). For our third goal, we use our

T

z-1

Update with 
TrackIPTree

T
z

Stream sz
<ip1,+>

<ip2,-> <ip3,+>

...

∆-bad  &
∆-good 
prefixes

Extract 
Changed 
Prefixes

T

old

Classify each 
IP  with T

old

Annotated 

T

old, z

T

old, z-1

Figure 5. High-level sketch of ∆-Change Algorithm

learned IPtrees to discover which of the IP addresses in the
current sequence have changed their labels. We then learn a
third IPtree based on this information, partitions the address
space into regions that are change frequently and those that
do not. (To avoid confusion, we term this third IPtree as
change-IPTree, and deﬁne it in Section 3.3).

3.2 The ∆-Change Algorithm

We now present our ∆-Change algorithm which ad-
dresses the question: can we identify the speciﬁc regions of
changing malicious activity? Recall that a k-IPtree is a de-
cision tree over the IP address space with at most k leaves.
Let s1, s2 . . . denote the sequences of IP addresses at each
time interval, and let Tz denote the IPtree built over the se-
quence sz. For readability, we use Tcurr to denote the tree
that is being learned over the current sequence of IPs, and
Told to denote an older tree that is being kept ﬁxed over the
current sequence of IPs. We use Told,z to denote the tree
Told that is annotated with its classiﬁcation errors on the
sequence sz.

At a high-level, we do the following: As each labelled IP
i arrives in the sequence sz, (i) we predict a label with the
trees Tcurr and Told,z; (ii) we annotate the tree Told,z with
its classiﬁcation error on i, and (iii) we update the model of
Tcurr with i if necessary. At the end of the interval, we com-
pare classiﬁcation errors Told,z−1 with Told,z and Tcurr to
discover the ∆-change preﬁxes, discarding redundant pre-
ﬁxes as appropriate (i.e., when multiple preﬁxes reﬂect the
same change). Told is then updated appropriately (we spec-
ify the details later), so it can used for measuring the clas-
siﬁcation errors of the IPs in the next sequence sz+1. We
sketch the high-level view of ∆-Change in Figure 5.

We describe the construction of Tcurr and Told,z in Sec-
tion 3.2.1, and the comparison between the trees in Sec-
tion 3.2.2. We describe ∆-Change in terms of multiple trees
for conceptual clarity. However, it may be implemented
with just one IPTree (and additional counters) for efﬁciency.

3.2.1 Constructing the IPTrees

At a high-level, TrackIPTree involves all parent preﬁxes of
an IP i in current IPtree in both in classifying IP i, as well

∆-CHANGE Input: sequence sz, Told, Tcurr;

for IP-label pair < i, label > in sz

pi,curr := label predicted on i using

TrackIPTree on Tcurr

pi,old := label predicted on i using

TrackIPTree on Told
AnnotateTree(Told,z, i)
Update (Tcurr, i, label)

ExtractChangedPreﬁxes(Told, Tcurr);

sub ANNOTATETREE

Input: IPTree Told, IP i, label l
for each parent preﬁx j of i in Told

IPs[j, label] += 1
if pi,curr 6= pi,old

mistakes[j, label] += 1

sub EXTRACTCHANGEDPREFIXES

Input: IPTree Told,z, IPTree Told,z−1, IPTree

Tcurr, error threshold γ, IP threshold θ

Output: Set of ∆-changes C
//Step 4: Isolate Candidate Preﬁxes
Candidate Set of ∆-changes C = {}
for each preﬁx j ∈ Told,z

error[j] = (mistakes[j, +] +

mistakes[j, −])/(IPs[j, +] + IPs[j, −]);

if error[j] > γ and IPs[j] > θ and

state[j, Told] 6= state[j, Tcurr]

Add preﬁx j to candidate set C

//Step 5: Prune Redundant Preﬁxes
for each preﬁx c ∈ C

for each parent j of c in Told

childMistakes[j] += mistakes[c];
childIPs[j] += IPs[c]

for each preﬁx c ∈ C

if mistakes[c] - childMistakes[c] < θ

|| IPs[c] - childIPs[c] < γ

discard c from C

//Step 6: Discover New Children
for each preﬁx c ∈ C

for each child node c′ of c in Tcurr
if c′ 6∈ Told

add subtree(c) to C

Figure 6. Pseudocode for ∆-Change

x0

x1

x2

x3

x4

+
-

+
-

+
-

+
-

+
-

Weights

-

-

+

-

+

x0

x1

x2

x3

x4

Prediction 
for IP I: +

-

+

-

-

+

(a) Parents of
in
T , with relative importance
weights

IP i

(b) Each parent chooses “+”
or “-”, based on its own label
predictor weights

(c) Weight parent predictions by relative impor-
tance weights to get ﬁnal prediction for the IP
i

(d) Update Tcurr: Penalize
incorrect parents, and grow or
prune T if needed

Figure 7. ∆-Change Algorithm: Illustrating Steps 1 & 3 for a single IP i. (a)-(c) show Step 1, and (d) shows Step 3. The
shaded nodes indicate the parents of the current IP i in the tree.

as in learning from labeled IP i. Crucially, TrackIPTree de-
composes the main prediction problem into 3 subproblems,
which it treats independently: (a) deciding the prediction of
each individual parent preﬁx, (b) combining the parent pre-
ﬁx predictions by deciding their relative importance, and (c)
maintaining the tree structure so that the appropriate sub-
trees are grown and the unwanted subtrees are discarded.
These subproblems are cast as instances of experts’ prob-
lems [11, 20].

TrackIPTree uses the following data structure, shown in
Figure 7(a) and (b). Each node in the IPtree maintains two
sets of weights. One set, termed label predictors, decide
whether an individual node should predict non-malicious or
malicious, denoted {yj,+, yj,−} for node j (Fig. 7(b)). The
second set, termed relative importance predictors, keeps
track of the weight of the preﬁx’s prediction, in relation to
the predictions of other preﬁxes – we use xj to denote this
weight for node j (Fig. 7(a)). In ∆-Change, we augment
the basic IPTree data structure with a few additional coun-
ters, so that we can keep track of the classiﬁcation error
rates at the different parts of the address space on the cur-
rent sequence sz (we elaborate further in Step 2). Below we
describe how we use this data structure in order to apply the
relevant components of TrackIPTree to construct Tcurr and
Told,z and then discover the ∆-change preﬁxes.
Step 1: Predicting with Told and Tcurr. We compute
predictions of Told and Tcurr using the prediction rules of
TrackIPTree. We ﬁrst allow each preﬁx of i in Told (and
likewise, Tcurr) to make an individual prediction (biased
by its label predictors). Then, we combine the predictions
of the individual nodes (biased by its relative importance
predictor). We illustrate these steps in Fig. 7(a)-(c).

Formally, let P denote the set of preﬁxes of i in a tree
T . We compute each preﬁx j ∈ P ’s prediction pi,j, with a
bias of yj,+ to predict non-malicious, and a bias of yj,− to
predict malicious. We then combine all the predictions pi,j
into one prediction pi for the IP i, by choosing prediction
pi,j of node j with probability xj, its relative importance

predictor. The pi is our ﬁnal output prediction.
Step 2: Annotating Told with Classiﬁcation Errors.
We next describe how we annotate the IPTree Told to pro-
duce Told,z based on the errors that Told makes on sz. For
this, we augment the basic IPTree data structure with four
additional counters at each preﬁx of Told: two counters that
keep track of the number of malicious and non-malicious
IPs on the sequence sz, and two counters that keep track
of the number of mistakes made on malicious and non-
malicious IPs on sz. (This is the only update to the IPtree
data structure of [29] that ∆-Change requires.)

We do the following for each IP i: if the output predic-
tion pi of Told (obtained from Step 1) does not match the
input label of IP i, we increment the number of mistakes
made at each parent preﬁx of i in tree Told,z. We track mis-
takes on malicious and non-malicious IPs separately. We
also update the number of malicious and non-malicious IPs
seen at the preﬁx in the sequence sz. Thus, for example, in
Figure 7, if the input label of IP i is “-” and Told has pre-
dicted “+”, we update the errors for malicious IPs at each
highlighted parent preﬁx of i, and we also update the num-
ber of malicious IPs seen at each highlighted parent preﬁx.
Step 3: Learning Tcurr.
Finally, we update Tcurr with
the labeled IP. This ensures that our model of the stream is
current. This step directly applies the update rules of Track-
IPTree to Tcurr [29], as a subroutine. Effectively, the learn-
ing procedure penalizes the incorrect preﬁxes and rewards
the correct preﬁxes by changing their weights appropriately;
it then updates the tree’s structure by growing or pruning as
necessary. Due to space limits, we omit a detailed descrip-
tion of TrackIPTree’s update rules here.

3.2.2 Extracting Changes from IPTrees

At this point, we have measured the classiﬁcation error of
Told over the sequence sz (denoted by Told,z), and we have
allowed Tcurr to learn over sz. Now, our goal is to extract
the appropriate changes between sz and sz−1 by comparing

/16

IPs: 200
Acc: 40%

/16

IPs: 170
Acc: 13%

/16

IPs: 170
Acc: 13%

A: IPs: 50

Acc: 30%

B: IPs: 150
Acc: 90%

A: IPs: 70

Acc: 20%

B: IPs: 100
Acc: 10%

A: IPs: 70

Acc: 20%

B: IPs: 100
Acc: 10%

B: IPs: 40

Acc: 80%

C: IPs: 110
Acc: 95%

D: IPs: 20

Acc: 20%

C: IPs: 80
Acc: 5%

D: IPs: 20

Acc: 20%

C: IPs: 80
Acc: 5%

(a) Told,z−1: prior IPTree, annotated with
errors on sz−1

(b) Told,z: prior IPTree, annotated with er-
rors on sz

(c) Told,z: ﬁnal ∆-change preﬁx (shaded)

/16

A

B

D

C

(d) Tcurr: new chil-
dren found for ∆-
change preﬁx

Figure 8. ∆-Change Algorithm: Steps 4-6. Running example illustrates how ∆-change preﬁxes are extracted by comparing
Told,z−1, Told,z and Tcurr

the trees Told,z, Told,z−1 and Tcurr.

At a high-level, we do this in three steps: (1) ﬁrst, we
isolate candidate ∆-change preﬁxes, by comparing their
classiﬁcation errors and states between Told,z and Told,z−1;
(2) we prune redundant preﬁxes, which ensures that we do
not include preﬁxes as ∆-change if their children already
account for bulk of the change; (3) ﬁnally, we discover
new children that may have been grown in relation to these
changes by comparing Tcurr and Told.

Speciﬁcally, let D be the set of states that preﬁxes can
be assigned to. Let θ minimum number of IPs that a preﬁx
needs to originate to be considered potentially a ∆-change.
Let τ denote the maximum error a preﬁx may have to still be
considered an accurate model of the region’s trafﬁc.5 Let γ
as the minimum increase in a preﬁx’s error that guarantees
that the preﬁx is indeed ∆-change. We derive γ from the set
D, as we describe later. We will use Figure 8 to illustrate
these three steps with a running example, where we set θ =
50, τ = 0.1, and γ = 0.5.
In the example, we allow a
preﬁx to have one of two states: “good”, which corresponds
to 0-50% of its trafﬁc being malicious, and “bad”, which
corresponds to 51-100% of its trafﬁc being malicious.
Step 4: Isolate Candidate Preﬁxes. We isolate as a can-
didate set C all preﬁxes in Told satisfying the following con-
ditions: (1) its classiﬁcation error in Told,z exceeds γ, and
its classiﬁcation error in Told,z−1 is below τ; (2) at least θ
instances have been seen at the preﬁx. We then compare the
prediction labels of each preﬁx in C to the corresponding
preﬁx in Tcurr to check for a state change. If there is no
change in the preﬁx’s state, the change is not localized, and
we discard the preﬁx from C.

Figure 8(a) shows the original Told,z−1 (the states for
each node are not shown for readability, assume they are all
“good” in Told,z−1) (b) shows Told,z (again, the states of
each node are not shown, here assume all are “bad”). The
shaded preﬁxes (nodes B & C) have both sufﬁcient IPs and
the necessary change in the classiﬁcation error. Node A gets

5τ is typically set to a small value such as 0.01%, but cannot be set to

0% because of noisy data.

discarded because it is not accurate enough in Told,z−1, and
node D gets discarded because it has too few IPs.

Step 5: Prune Redundant Changes.
Not all candidate
preﬁxes isolated in C will represent a change in a distinct
part of the IP address space. Every parent of a ∆-change
preﬁx will also have made the same mistakes.
In some
cases, these mistakes may cause the parent preﬁx to also
have a high overall classiﬁcation error (e.g., when no other
child of that parent originates substantial trafﬁc). However,
some parents of a ∆-change preﬁx may have a high classiﬁ-
cation error due to changes in a different part of the address
space. To avoid over-counting, we include a preﬁx in C
only if the following two conditions hold: (1) it accounts
for an additional θ IPs after the removal of all children ∆-
change preﬁxes; (2) there is at least γ classiﬁcation error on
the IPs from the remaining preﬁxes in Told,z, and at most τ
error in Told,z. Figure 7(c) shows this step: we discard the
parent /17 preﬁx (node B) from the list of ∆-change pre-
ﬁxes, because it does not account for an additional θ = 50
IPs after we remove the contribution of its ∆-change /18
child (node C).

Step 6: Discover New Children.
The tree Tcurr may
have grown new subtrees (with multiple children) to ac-
count for the changes in the input IP stream. We compare
each preﬁx c ∈ C with the corresponding preﬁxes in Tcurr
to see if new subtrees of c have been grown. If these sub-
trees differ from c in their prediction labels, we annotate c
with these subtrees to report to the operator. Figure 8(d)
shows Tcurr and the corresponding subtrees (of depth 1
in this example) of the ∆-change preﬁx (node C) in Told,
which are annotated with node C for output.

To wrap up the ∆-Change algorithm, we discuss the two
parameters we did not specify earlier. First, we need to de-
ﬁne how we obtain Told from Tcurr. Since Told needs to
have its accuracy measured in interval z − 1, it needs to be
learnt no later than z − 2. So, Told = Tz−2 for the sequence
sz, and at every interval, we update Told to be the tree learnt
2 intervals before the current one. We also need to derive
γ from the set of states D. Since each state is deﬁned by

an interval in [0, 1], we can use the interval boundaries to
derive D. Thus, for example, if each state D has the same
interval length, then γ = 1

|D| .

Properties of ∆-Change: Efﬁciency and Correctness
The ∆-Change algorithm meets our goals of operating on-
line on streaming data and our computational requirements
as each step involves only the following operations: learn-
ing an IPtree, comparing two IPtrees or applying an IPtree
on the input data. The ﬁrst operation is performed by the
TrackIPTree algorithm, which is an online learning algo-
rithm, and the remaining operations require storing only the
IPtrees themselves, thus requiring only constant additional
storage.

More precisely, the key data structures of ∆-Change are
three IPtrees, i.e., Told,z−1, Told,z, Tcurr. The basic IPTree
data structure has a space complexity of O(k) for a tree
with k leaves [29], as TrackIPTree only stores a number of
weights and counters per preﬁx. For ∆-Change algorithm,
as described in Step 2, we need to augment the basic IP-
tree structure with four additional counters for each preﬁx.
Thus, the space complexity for ∆-Change remains O(k).

Next, we describe the run-time complexity of ∆-Change.
Steps 1, 2 and 3 are applied to every IP in the input se-
quence, but each step has at most O(log k) complexity: for
each IP, we examine all its parents in Tcurr and Told a con-
stant number of times (only once in Step 2, 2-4 times in
Steps 1 & 3 as part of the subroutines of TrackIPTree), so
the run-time per IP is O(logk). In Step 4, we compare each
pair of preﬁxes in Told,z and Told,z−1, so our run-time for
Step 4 is O(k). In Step 5, we examine potential ∆-change
preﬁx together with its parents, so our run-time is bounded
by O(k log k). For Step 6, we examine each potential ∆-
change preﬁx together with its children subtrees in Tcurr,
and since Tcurr is a k-IPtree, the run-time is bounded by
O(k). Thus, the total run-time of ∆-Change, for an input
sequence of length n, becomes O(n log k + k log k).

We conclude with a note about accuracy: by design, ev-
ery ∆-change preﬁx discovered is guaranteed to reﬂect a
change in the IPs between the sequences sz and sz−1. If
a preﬁx has had high classiﬁcation error in Told,z and low
classiﬁcation error in Told,z−1, then that preﬁx is indeed
originating a different kind of trafﬁc in sz−1 than it did in
sz. Thus, the ∆-Change algorithm will have no false pos-
itives (though it may not ﬁnd all ∆-change preﬁxes, since
the Tcurr and Told are approximate).

3.3 The ∆-Motion Algorithm

In this section, we address the second question posed in
our problem: What regions of the Internet are prone to fre-
quent changes? The answer to this helps us pinpoint struc-
tural properties of the ∆-change preﬁxes.

A straightforward approach might be to use the ∆-
change preﬁxes output by ∆-Change, but as just described

Stream sz:

<ip1,+>

<ip2,-> <ip3,+>

...

Tz-1

Classify each IP  
with Tz-1

Tz-1

Update with 
TrackIPTree

Stream s’z:

<ip1, change>.
<ip2, change>
<ip3, nochange>…

Tz

Change-IPTree Wz-1

Update with 
TrackIPTree

Change-IPTree Wz

Figure 9. High-level approach of ∆-Motion

/0

/1

/16

/17

No Change

No Change Change

Figure 10. Example Change-IPTree: Partitioning the
IP address space into “change” and “no-change” re-
gions. This is just like the regular IPTree in Figure 1, but
with the leaf labels denoting “change” or “no-change”.

in Section 3.2, this list of ∆-change preﬁxes may be incom-
plete: ∆-Change can only ensure that every identiﬁed preﬁx
is truly a ∆-change preﬁx (i.e., there are no false positives),
but not that every ∆-change preﬁx is discovered (i.e., there
may be false negatives). However, there is additional infor-
mation in the structure of the learned IPtree Told as well as
the input data sequence sz that we can exploit.

To answer our question, we need to partition the IP ad-
dress space into regions that change quickly and regions that
change slowly. We ﬁrst observe that this problem may be
modeled as another instance of the problem of learning an
IPtree – we need simply to learn a decision tree over the IP
address space where the leaf labels denote “change” or “no
change”, rather than “malicious” or “non-malicious”. For
clarity, we deﬁne this IPTree as a change-IPTree; Figure 10
shows an example of such an IPtree. Therefore, if we get
access to IPs labelled with “change” or “no change” (rather
than our usual sequences of IPs labelled with “malicious” or
“non-malicious”), and we directly use TrackIPTree to solve
this problem.

Recall that we denote sz to be the part of the stream that
appears in interval z. ∆-Motion uses the IPtree Tz−1 to an-
notate each IP i in sz. If the label of IP i matches the predic-
tion of Tz−1, it pairs IP i with label ”no change”, and if they
do not match, it pairs the IP with a label ”change”. We thus
have a new stream s′
z derived from sz, where the label of
each IP is ”change” or ”no change”. Next, we apply Track-
IPTree on this new stream, and the resulting change-IPtree

differentiates preﬁxes that change frequently from those do
not change frequently. We use Wz to denote this change-
IPtree built on the stream s′
z of IPs labeled with ”change”
or ”no change”. Even though the IPtree Tz−1 we use to
generate the new labels is approximate, it typically has a
very high accuracy and so the new stream will typically
have only a little noise. We note that the space and run-
time complexity of ∆-Motion is identical to TrackIPTree:
its data structure uses only three IPTrees (a change-IPTree
and two regular IPTrees); each step of ∆-Motion applies a
part of TrackIPTree, and the different parts of TrackIPTree
are applied three times in ∆-Motion.

4 Experimental Results
Data.
Our ﬁrst data set uses spam as our source of ma-
licious activity. Our data is collected from the operational
mailservers of a tier-1 ISP which handle mail for total of
over 8 million subscribers. We collected data in two pe-
riods: from mid-April to mid-August 2010 over 120 days,
and from mid June to late July 2012, over 41 days. Our data
set includes the IP addresses of the senders’ mail servers and
the number of spam and legitimate messages that each mail
server sends in a 5-minute interval; we do not collect any
other information. We use the mailserver’s spam-ﬁltering
system (Brightmail) as labels for IP addresses in our learn-
ing algorithm; a single IP address can thus be labeled mali-
cious at one point in time and non-malicious at a different
point, as it may send legitimate messages at some points and
spam at others. In total, the IP addresses in our data have
sent over 5.3 billion spam and 310 million legitimate mes-
sages. While our data may have some noise in labeling (due
to Brightmail mislabeling spam as legitimate mail and vice-
versa), because the algorithm is adaptive and noise-tolerant,
a small fraction of inaccurate labels in the data will not have
a signiﬁcant long-term impact on the tree.

Our second data set is based on botnet activity from Oc-
tober 2011 to January 2012. For this data set, we ﬁrst ob-
tain a distribution of the active IP addresses across the Inter-
net by collecting daily snapshots of ﬂows sampled from IP
backbone trafﬁc. All together, our monitoring points cover
80% of the trafﬁc carried by the IP backbone. On any given
day, our data includes 24-28 million unique IP addresses.
We use botnet activity to label these IP addresses as ma-
licious or non-malicious for our algorithms. In particular,
we obtain a daily snapshot of IP addresses within a tier-1
ISP that are part of a botnet, as identiﬁed by the ISP’s secu-
rity vendors. These security vendors employ a combination
of monitoring algorithms, sinkholes, spam traps and mal-
ware binary analysis to identify and track bot IP addresses,
and the daily snapshot includes all the bot IPs observed by
the vendors on that particular day – speciﬁcally, a bot IP is
included in the list for a particular day only if it has gen-
erated activity matching a signature on that particular day

6 The botnet feed contains around 30,000-100,000 unique
IP addresses daily (these include drones as well as the re-
sponsible C&C servers), and the feed includes over 2.64
million unique bot IP addresses in total across 94 days of
data. We label an IP address as malicious on day i if it ap-
pears in the botnet feed on day i. As in the spam data set,
any noise in the input data stream will be carried over to our
results; however, if there is a only small amount of noise
in the labeling, the adaptive nature of the algorithm ensures
that there will not be a long-term impact on the tree.

Our results demonstrate that our algorithms are able to
discover many changes in the Internet’s malicious activ-
ity, and do so substantially better than alternate approaches.
The exact ∆-change preﬁxes we detect are, of course, spe-
ciﬁc to our data sets, and for conﬁdentiality reasons, we
anonymize the owning entities of all the preﬁxes in the re-
sults. Our results show two examples of how our algorithm
can be applied on real data sets from operational networks,
and discover changes that operators were unaware of.
Experiment Setup.
Throughout our experiments, we
keep the algorithm parameters ﬁxed. We set ǫ = 0.05,
following [29]. We use IPtrees of size k = 100, 000 for
spam data and k = 50, 000 for the botnet data, as they
make accurate predictions on the input stream, and a fur-
ther increase in k does not substantially increase the tree’s
accuracy. We measure the accuracy of our algorithms on
a per-IP basis (following [29]), and the accuracy of our
constructed IPtrees are similar to [29]. All our change-
detection experiments are performed on day-length inter-
vals, i.e., each of the three trees is built, tested and compared
across different days. We use three states for the preﬁxes,
split by legitimate-ratio thresholds: [0, 0.33), [0.33, 0.75),
and [0.75, 1]. We term these states bad, neutral and good
states respectively, and this means that a preﬁx state is as-
signed as “good” if it sends at least 75% non-malicious traf-
ﬁc, “neutral” if it sends 33% − 75% non-malicious trafﬁc,
and “bad” if it sends less than 33% non-malicious trafﬁc.
With the thresholds of the set of states, we derive γ = 33%.
We set allowable error τ = 5% throughout, and the mini-
mum trafﬁc needed θ = 0.01% and 0.05%. We chose these
values for τ and θ because in our experiments, we are able
to obtain a list of ∆-change preﬁxes that is small enough to
be manually analyzed, and yet large enough for us to dis-
cover interesting trends across our data sets. Our parame-
ters remain stable throughout our data set when we seek to
analyze changes across day-long intervals. As operator re-
sources allow, these parameters can be changed to allow for
the discovery of either more ﬁne-grained changes (say, with
smaller of θ or larger values of k) or more coarse-grained

6While there are bound to be inaccuracies – both false positives and
false negatives – in this dataset due to the difﬁculty of identifying botnets,
our results demonstrate that our algorithms are able to highlight those pre-
ﬁxes where signiﬁcant changes occur as a function of the input data.

changes. Our experiments were run on a on a 2.4GHz
Sparc64-VI core. Our current (unoptimized) implementa-
tion takes 20-22 minutes to process a day’s trace (around
30-35 million IP addresses) and requires less than 2-3 MB
of memory storage.

We note that the ground truth in our data provides labels
for the individual IP addresses, but does not tell us the pre-
ﬁxes that have changed. Thus, our ground truth allows us to
conﬁrm that the learned IPTree has high accuracy, but we
cannot directly measure false positive rate and false nega-
tive rate of the change-detection algorithms. Thus, our ex-
perimental results instead demonstrate that our algorithm
can ﬁnd small changes in preﬁx behaviour very early on real
data, and can do so substantially better than competing ap-
proaches. Our operators were previously unaware of most
of these ∆-change preﬁxes, and as a consequence, our sum-
marization makes it easy for operators to both note changes
in behaviour of speciﬁc entities, as well as observe trends in
malicious activity. 7

4.1 Comparisons with Alternate Approaches

We ﬁrst compare ∆-Change with previous approaches
and direct extensions to previous work. We compare two
different possible alternate approaches with ∆-Change: (1)
using a ﬁxed set of network-based preﬁxes (i.e., network-
aware clusters, see Sec. 2.2) instead of a customized IP-
Tree, (2) directly differencing the IPTrees instead of using
∆-Change. We focus here on only spam data for space rea-
sons.
Network-aware Clusters.
As we described in Sec-
tion 3.2, our change-detection approach has no false pos-
itives – every change we ﬁnd will indeed be a change in
the input data stream. Thus, we only need to demonstrate
that ∆-Change ﬁnds substantially more ∆-changes than
network-aware clusters (i.e., has a lower false negative rate),
and therefore, is superior at summarizing changes in mali-
cious activity to the appropriate preﬁxes for operator atten-
tion.

We follow the methodology of [29] for labeling the
preﬁxes of the network-aware clusters optimally (i.e., we
choose the labeling that minimizes errors), so that we can
test the best possible performance of network-aware clus-
ters against ∆-Change. We do this allowing the network-
aware clusters multiple passes over the IP addresses (even
though ∆-Change is allowed only a single pass), as detailed
in [29]. We then use these clusters in place of the learned
IPTree in our change-detection algorithms.

We ﬁrst compare ∆-change preﬁxes identiﬁed by the
network-aware clustering and ∆-Change. This compari-
son cannot be directly on the preﬁxes output by the two ap-

7As discussed in Section 1, our evaluation focuses exclusively on
changes in preﬁx behaviour, since prior work [28, 29] already ﬁnds per-
sistent malicious behaviour.

s
e
x
i
f
e
r
P
 
e
g
n
a
h
c
−
∆
 
f
o

 
.

o
N

120

100

80

60

40

20

0

∆−Change
Network−aware

15

20
Interval in Days

25

30

35

s
e
x
i
f
e
r
P
 
e
g
n
a
h
c
−
∆
n

 

i
 
s
P
I

106

105

104

103

∆−Change
Network−aware

15

20
Interval in Days

25

30

35

(a) ∆-change Preﬁxes

(b) IPs in ∆-change preﬁxes

Figure 11. Comparing ∆-Change algorithm with
network-aware clusters on the spam data: ∆-Change
always ﬁnds more preﬁxes and covers more IPs

proaches, as slightly different preﬁxes may reﬂect the same
underlying change in the data stream, e.g., network-aware
clusters might identify a /24 while ∆-Change identiﬁes a
/25.
In order to account for such differences, we group
together preﬁxes into distinct subtrees, and match a group
from the network-aware clustering to the appropriate group
from ∆-Change if at least 50% of the volume of changed
IPs in network-aware clustering was accounted for in ∆-
Change. In our results, network-aware clustering identiﬁed
no ∆-change preﬁxes that were not identiﬁed by ∆-Change;
otherwise, we would have do the reverse matching as well.
Furthermore, this is what allows us to compare the num-
ber of ∆-changes that were identiﬁed by both algorithms,
otherwise we would not be able to make this comparison.

Fig. 11(a) shows the results of our comparison for 37
days. Network-aware clustering typically ﬁnds only a small
fraction of the ∆-change preﬁxes discovered by ∆-Change,
ranging from 10% − 50%. On average, ∆-Change ﬁnds
over 2.5 times as many ∆-change preﬁxes as network-aware
clusters. We compare also the number of IPs in ∆-change
preﬁxes identiﬁed by the network-aware clustering and ∆-
Change in Fig. 11(b). The ∆-change preﬁxes discovered
by ∆-Change typically account for a factor of 3-5× IP ad-
dresses as those discovered by the network-aware cluster-
ing. It indicates that network-aware clustering does not dis-
cover many changes that involve a substantial volume of the
input data. On many days, especially on days with changes,
the fraction of IP addresses not identiﬁed by network-aware
clusters, however, is still smaller than the fraction of pre-
ﬁxes that it does not identify. This indicates that network-
aware clustering identiﬁes the larger, coarser changes, but
misses the ﬁne-grained changes.

Network-aware clusters perform so poorly because the
preﬁx granularity required to identify ∆-changes typically
does not appear at all in routing tables. Indeed, as our anal-
ysis in Section 4.2 shows, a large number of ∆-change pre-
ﬁxes come from hosting providers, many of which do not
even appear in BGP preﬁx tables.

Possible Differencing of IPTrees. We now show that
the possible differencing approach described in Section 2.2

produces an extremely high false positive rate. For this ex-
periment, we learn two trees (denoted Tx and Ty) over two
consecutive day-long intervals, i, i + 1 respectively. We cal-
culate the differing common preﬁxes in the trees, and then
use a basic mathematical argument to prove that there must
be a very high false positive rate among these preﬁxes.

Each tree Tx and Ty has an overall accuracy rate exceed-
ing 95.2% on each of the days i and i + 1 (we measure this
separately across all IPs in each day i and i + 1). Since each
tree makes less than 5% error, the two trees can differ on at
most 10% of the IPs on each day i and i + 1 (e.g., the trees
may make errors on disjoint sets of IPs on each day); denote
this set of IPs where the trees differ as M . Now, consider
the set of preﬁxes that appear in both trees, and contain at
least 0.01% of the data (and discard the redundant parents
from this set that account for the same trafﬁc). In order for a
preﬁx to qualify as ∆-change, at least 33% of the IPs it sees
must be from the set M . However, by the pigeonhole prin-
ciple, there can be at most 3400 preﬁxes can (1) account for
at least 0.01% of the IPs, and (2) have at least 33% of their
IPs come from the set M . However, when we measured the
number of the preﬁxes present in these two trees that were
different, based either on leaf label or on trafﬁc volume for
interior nodes (ensuring we discard redundant parents), we
found 5021 preﬁxes present in both Tx and Ty, with at least
0.01% of the trafﬁc. Thus, at least 1621 of the preﬁxes have
to be incorrect, giving a 47% false positive rate.

4.2 Characterization: Spam Data

Summary. We present a summary of ∆-changes dis-
covered in the 2010 spam data, as it covers a longer pe-
riod (120 days) compared to the 2012 data. Table 1(a)
(Fig. 12) summarizes the ∆-change preﬁxes discovered by
∆-Change, categorized by the kind of behavioral change
that they have undergone. The table shows results for dif-
ferent values of the threshold θ = 0.05%, 0.01%. As we
expect, when θ decreases, the number of preﬁxes identiﬁed
as ∆-change increases, since there are more preﬁxes with
at least θ IPs. Note that the majority of the changes come
from preﬁxes that progressively originate more spam, i.e.,
nearly 75% ∆-change preﬁxes are ∆-bad. Further, regard-
less of θ, very few spamming preﬁxes actually change for
the better. These observations are consistent with the ear-
lier studies on spam origin and spammer behavior – while
spammers tend to move around the address space, perhaps
dependent on the bots they own, legitimate mail servers tend
to remain stable. Further, when a region stops spamming, it
are much more likely to stop sending mail trafﬁc altogether,
rather than start sending substantial volumes of legitimate
mail. Since ∆-Change does not detect a preﬁx that simply
stops originating trafﬁc, we see very few ∆-good preﬁxes

in Table 1(a). 8

Table 2 (Fig. 13) shows the ∆-change preﬁxes split by
access type of the preﬁx (in this analysis, we include a preﬁx
only once even if it has appeared as a ∆-change preﬁx mul-
tiple times) for θ = 0.05%. The majority of the ∆-change
preﬁxes come from small ISPs and hosting providers, al-
though there are also a few large (tier-1) ISPs. As Table
1 shows, most of these preﬁxes are identiﬁed because they
start to send spam. In Fig. 15(a) we also show the distribu-
tion of preﬁx lengths of the ∆-change preﬁxes: over 60% of
preﬁxes have lengths between /16 and /26, which matches
the preﬁx ranges expected of hosting providers and small
ISPs. Obviously, many of these small ISPs and hosting
providers obtain their IP address ranges from large ISPs,
but ∆-Change identiﬁes the small ISPs distinctly from their
respective owning larger ISP only because their spamming
activity differs signiﬁcantly from the spamming activity of
their respective owning larger ISP. DHCP effects also in-
ﬂuence the preﬁxes that are discovered – they force the
change in spamming activity to be identiﬁed at the gran-
ularity of the owning preﬁx, rather than the individual IP
addresses, and this is likely another factor in the predomi-
nance of small ISPs and hosting providers as frequent ∆-
changes. Indeed, the predominance of small regional ISPs
and hosting providers as frequent ∆-changes emphasizes
the need for techniques that can automatically infer changed
malicious activity – these providers tend to be substantially
more volatile and transient than large ISPs, making it much
harder to track them with pre-compiled lists.
Case Study 1: Individual Provider Spamming Activity.
Fig. 14 illustrates the spamming activity of three differ-
ent providers that we identiﬁed as ∆-bad at θ = 0.05%.
Provider A is a hosting provider (with a /19 preﬁx) based in
south-eastern US, provider B is a virtual web-hosting com-
pany in Netherlands (with a /26 preﬁx), and provider C is a
small ISP in mid-western US. (with a /22 preﬁx). Note that
each one of these providers starts and stops spamming mul-
tiple times over 4 months. ∆-Change identiﬁes all of these
changes, as we highlight in Fig 14 with arrows. Further, we
note that ∆-Change identiﬁes each ∆-bad preﬁx early on,
before their peak spamming activity. None of these three
preﬁxes are detected when BGP preﬁxes are used, as they
are much too small to appear in routing tables. Further, our
mail operators were unaware that these speciﬁc providers
were engaging in spamming activity, and would not have
found them without exhaustive manual analysis.

These three providers are just examples of the many that
were not detected by BGP preﬁxes and of which our opera-
tors were previously unaware. 9 We highlighted these to il-

8Note also the design of TrackIPTree ensures that such preﬁxes even-
tually get discarded from IPtree, and thus after a period of time, these
preﬁxes will not be labeled malicious in the tree forever.

9Maintaining a list of hosting providers and using the list to track their

Original State New State

θ = 0.01% θ = 0.05%

Original State New State

θ = 0.01% θ = 0.05%

Bad

Good

Neutral

Good
Neutral
Neutral

Bad
Good
Bad

31
28
122
205
66
146

11
1
24
33
9
13

Bad

Good

Neutral

Good
Neutral
Neutral

Bad
Good
Bad

134
189
42
78
201
285

Table 1(a) Spam Data Set

Table 1(b) Botnet Data Set

Figure 12. Characterizing the ∆-change preﬁxes discovered for spam and botnet data sets.
ISP Type
Large ISPs
Small ISPs

# Identiﬁed

23
16
17
14
98
43

B

C

A

Hosting Providers

Others

4
11
9
2

Figure 13. Table 2: Spam Data: ISP Types of ∆-
change preﬁxes

lustrate spamming activity from these smaller providers that
repeatedly starts and stops. Our case study also illustrates
how difﬁcult it is to ensure that systems are conﬁgured to
never spam, especially for hosting providers, since hosting
providers typically allow their customers to easily establish
new mail servers on their physical or virtual infrastructure,
and can repeatedly get caught into a cycle of accidentally
hosting spammers and cleaning up spamming activity.
Case Study 2: Drop in Internet-wide Spamming Activ-
ity.
In our next case study, we examine the ∆-good pre-
ﬁxes discovered by ∆-Change during the Grum botnet take-
down in July 2012. The Grum botnet was considered the
third largest spamming botnet and responsible for around
17% of all the spam on the Internet. [12]. This case study
illustrates what an operator would see with the ∆-Change
algorithm during such a large event, with no a priori knowl-
edge that the event was happening.

Figure 15(b) shows the number of ∆-good preﬁxes dis-
covered each day by ∆-Change and network-aware clusters,
and the start of the botnet takedown is indicated (with an ar-
row). (As in Sec. 4.1, we count only ∆-good preﬁxes that
correspond to distinct regions of the address space, in or-
der to have a fair comparison between ∆-Change and the
network aware clusters.) Our ﬁrst observation is that there
is sudden increase in the number of ∆-good preﬁxes right
after the botnet takedown, showing that a number of pre-
ﬁxes have suddenly changed their spamming activity. The
number of ∆-good preﬁxes discovered every day remains
high for a number of days after the takedown – this hap-
pens because our algorithm discovers preﬁxes as ∆-changes
when they actively generate trafﬁc (e.g., by sending legiti-
mate mail instead of spam in this case). Thus, whenever a

spamming activity would be less effective, since hosting providers start
and shut down frequently.

105

m
a
p
S

1

2

4

5

100

20

40

3

80

60

Day

100

120

Figure 14. Case Study 1: Spamming Activity in Small
Providers A, B, C. ∆-Change discovers spamming ac-
tivity early in small ISPs and hosting providers (arrows
indicate every time the preﬁxes are discovered).

(previously) infected region become active after the botnet
takedown, its preﬁx blocks are identiﬁed as ∆-good.

We also observe that ∆-Change discovers far more ∆-
good preﬁxes than the network-aware clusters (anywhere
between a factor of 3-10). Further analysis showed that
these preﬁxes had previously sent 0.01% − 0.1% of the
daily spam volume in our data, and a few of them contained
over two thousand spamming IP addresses. Most of these
preﬁxes range are allocated to small regional ISPs (rang-
ing from /15 to /26), and many of them do not appear in
BGP routing tables, and so they cannot be detected with
network-aware clusters. Thus, ∆-Change highlights to op-
erators where on the Internet a drop in spamming activity
took place.

4.3 Characterization: Botnet Data

Next, we examine the results of ∆-Change on the bot-
net data. Recall that our data only identiﬁes botnet activity
within a single large tier-1 ISP, and thus, ∆-change only de-
tects changes internal to this ISP. This is especially useful
since large ISPs often allocate preﬁx blocks to many smaller
ISPs and other customers, many of which typically are are
managed independently and change over time as business
requirements change, and thus are likely to have very dif-
ferent security properties. In this scenario, ∆-Change was
useful for highlighting to the operators a network-wide view

1

0.8

0.6

0.4

0.2

s
e
x
i
f
e
r
P
 
f
o
n
o
i
t
c
a
r
F

 

0
10

∆−Change
Network−Aware

20

15

10

5

s
e
x
i
f
e
r
p
d
o
o
g
−
∆

 

15

20
25
Prefix Length

30

35

0
15

20

25

Day

30

35

100

50

s
e
x
i
f
e
r
p
 
e
g
n
a
h
c
−
∆

0
20

30

B

A

50

60

70

40

Day

(a) Sizes of ∆-change Preﬁxes

(b) Case Study 2: Drop in Internet-wide Spam-
ming Activity

(c) Case Study 3: New Botnet Activity

Figure 15. (a) shows sizes of ∆-change preﬁxes. (b) shows Case Study 2: ∆-good preﬁxes with drop in spamming activity
during the Grum takedown (arrow indicates when the takedown started). There is a sharp increase in ∆-good preﬁxes
after the takedown. (c) shows Case Study 3: ∆-change Preﬁxes in New Botnet Activity. A and B mark the ∆-bad preﬁxes
discovered when over 22,000-36,000 new bot IPs appeared in the feed.

of the changing malicious activity, since there is likely to be
a diversity of malicious activity when new threats emerge.

Summary.
Table 1(b) (Fig. 12) summarizes the differ-
ent preﬁxes for θ = 0.05%, 0.01%, categorized by the type
of change they have undergone. As in Section 4.2, the
preﬁxes discovered increases sharply when θ is increased.
However, note that in this experiment, there are very signif-
icant numbers of ∆-good preﬁxes discovered as well – over
56% of all the preﬁxes discovered are ∆-good, unlike the
spam data. This is primarily because the active IP address
space changes very little, while bot IP addresses appear in
the feed for much shorter durations (e.g., this may be as bots
get cleaned, or bot signatures get outdated). A former bot
IP would then generate mostly legitimate trafﬁc (its mali-
cious trafﬁc would drop, but its legitimate activity remains
the same, and so it would get labelled as legitimate), and the
corresponding IP regions thus become ∆-good.

Case Study 3: New Botnet Activity.
Our case study
illustrates the value of discovering ∆-bad preﬁxes internal
to a large ISP’s preﬁx blocks. Figure 15(c) shows the time-
series of the ∆-change preﬁxes discovered over two months
of our data set. The highlighted days (A and B) mark two
sharp increases in the number of ∆-change preﬁxes discov-
ered. These correspond to days with dramatic increases in
the number of new bot IPs seen in the data feed – 22.1 &
28.6 thousand at the two days marked as A and 36.8 thou-
sand at B Further analysis showed that on days marked A,
nearly all of of these new bot IPs are from the DNSChanger
botnet [8], and are responsible for 19 & 31 ∆-bad pre-
ﬁxes. On day B, these new bot IPs are from Sality [25]
and Conﬁcker [6], and 66 ∆-bad preﬁxes correspond to the
new IPs from Sality and Conﬁcker. By contrast, network-
aware clusters were only able to discover 5-12 preﬁx blocks
as ∆-bad during these events. These ∆-bad preﬁxes come
from smaller regional ISPs, the tier-1 ISP’s dial-up and DSL
blocks; most of these preﬁxes had little to botnet activity
(as identiﬁed by the vendor) earlier. Thus, in these two in-
stances, ∆-Change effectively reduces the workload for op-

1

0.95

0.9

0.85

0.8

0.75

e
t
a
r
 
e
v
i
t
i
s
o
p
 
e
u
r
T

0.7
0

0.2

TreeMotion

0.4

0.6

False positive rate

0.8

1

Figure 16. ROC curve for ∆-Motion’s accuracy

erator from manually investigating over 22,000-36,000 new
bot IPs to investigating 19-66 new IP preﬁxes, a drop of two
orders of magnitude.

4.4 Structural Analysis of IP Dynamics

Our earlier results demonstrate that there is constant
change in the Internet’s malicious activity. We now explore
the structure underlying these changes with the ∆-Motion
algorithm, focusing our analysis on spam dataset due to
space. We use a snapshot of the change-IPtree W generated
by ∆-Motion, 60 days into the dataset; W ’s high predictive
accuracy indicates it can distinguish frequently-changing
regions well, as shown by the ROC curve in Fig. 16. We
use W to classify every IP in our data set as ”change” or
”non-change”, and then aggregate the IPs by country and
owning company. We deﬁne freq-ratio to be the fraction of
the total IPs of that entity that are marked as change IPs,
and analyze the freq-ratio of different aggregations.

Table 3 (Fig. 17) shows a breakdown for the origin of the
frequently changing IPs. Together, these countries account
for 90% of the data seen at our mail servers. We note that
countries like China, Korea, Russia [23], which are known
to harbor lot of spammers actually change very infrequently,
while countries like US and Canada change 3-4 times more
frequently. This makes sense, as countries where ISPs ag-
gressively ﬁght spammer infestations are likely to experi-
ence a more frequent change in malicious activity. Table
4 shows a breakdown by ISP type. Once again, hosting
providers have a substantially higher ratio than the other cat-

freq-ratio

Country
USA
W. Europe
Brazil
Canada
Russia
Estonia
Poland
Argentina
Korea
Colombia
China

6.9%
2.6%
0.8%
9.1%
2.2%
1.1%
1.5%
3.9%
1.1%
3.4%
2.3%
Table 3: Country

ISP Type
Large ISPs
Small ISPs

freq-ratio

6.6%
4.9%

Hosting
Providers

12.2%
Others
1.1%
Table 4: ISP type

Figure 17. Analyzing the IPtree learnt by ∆-Motion:
the tables show frequently changing regions

egories, consistent with our results in Section 4.2, since it is
much easier to spam out of a hosting provider. We see both
large and small ISPs seem to have roughly the same fre-
quency of change, and that businesses (which constitute the
most of the ”other” category) have a tiny ratio, as expected.
The set of hosting providers discovered by ∆-Motion
(which are the same as those that ∆-Change identiﬁes re-
peatedly as ∆-bad preﬁxes) are of particular interest to mail
operators. As discussed in Section 4.2, hosting providers
are especially vulnerable to changes because they see a
wide variety of users, who sometimes take any opportu-
nity to spam. However, because these providers also have
many legitimate clients, they cannot be entirely blacklisted,
and therefore need to be closely monitored so that they do
not cause a signiﬁcant performance impact. Indeed, this is
likely true of all new hosting providers as they appear on
the market, and it is this kind of structural insight about ma-
licious activity that ∆-Motion could discover, which may
help operators prioritize their resources.

5 Related Work
Spam.
There has recently been a lot of interest in de-
signing non-content based approaches to spam-ﬁltering. Of
these, most closely related to our work are the IP-based
spam ﬁltering approaches. These have included studies on
individual IP addresses, AS numbers and /24 preﬁxes [23],
BGP preﬁxes [27, 30], preﬁxes with dynamic IP assign-
ment [31], highly predictive blacklists [33], using a com-
bination of DNS clusters and BGP preﬁxes [22], and using
well-deﬁned properties of spammers to discover IP address
ranges used by spam gangs [9]. Our work differs from all
of these as we are concerned with automatically discovering
the preﬁxes that change their malicious behavior, using only
a stream of IP addresses labelled spammer or legitimate;
we do not use a priori ﬁxed clusters that originating from
network-based properties. There have also been behavior-
based spam ﬁltering approaches [13, 24], and analysis and

identiﬁcation of spam campaigns [2,18] and spamming bot-
nets [15, 32]; these take a very different angle, comple-
mentary to ours, for analyzing shifting malicious activity.
Lastly, there have been a number of studies showing the
relative inaccuracy of DNS-based blacklists [16, 26] Again,
our results are complementary to (and consistent with) all
these analyses, as we show that even with a near-optimal
partitioning of the IP address space, there are still a large
number of changes in spamming behavior.
Other Related Work.
Xie et al [31] consider the prob-
lem of discovering IP addresses that are dynamically as-
signed. Our problem is different from this work, as we are
interested in dynamic of malicious activity, not of IP ad-
dress assignment. Soldo et al. [28] study the problem of
ﬁltering malicious activity but their algorithms only oper-
ate on ofﬂine data, not streaming data. Finally, note also
that our problem differs from work on identifying hierar-
chical heavy-hitters [7, 10, 34], and discovering signiﬁcant
changes in the multi-dimensional aggregates [1, 4, 14, 17]:
these problems are concerned with volumetric changes on a
hierarchy, not on changes in classiﬁcation of decision tree.

6 Conclusion

In this paper, we formulated and addressed the problem
of discovering changes in malicious activity across the In-
ternet. Our evaluations using a large corpus of mail data and
botnet activity indicate that our algorithms are fast, can keep
up with Internet scale trafﬁc data, and can extract changes
in sources of spam activity substantially better (a factor of
2.5) than approaches based on using predetermined levels
of aggregation such as BGP-based network-aware clusters.
Using our algorithms, we ﬁnd that some regions of the In-
ternet are prone to much faster changes than others, such as
a set of hosting providers that are of particular interest to
mail operators.

References

[1] D. Agarwal, D. Barman, D. Gunopulous, F. Korn, D. Sri-
vastava, and N. Young. Efﬁcient and effective explanations
of change in hierarchical summaries.
In Proceedings of
KDD’07, 2007.

[2] D. Anderson, C. Fleizach, S. Savage, and G. Voelker. Spam-
scatter: Characterizing the internet scam hosting infrastruc-
ture. In Proceedings of Usenix Security ’07, 2007.

[3] B. Augustin, B. Krishnamurthy, and W. Willinger.

Ixps:
mapped? In Proceedings of the 9th ACM SIGCOMM confer-
ence on Internet measurement conference, IMC ’09, 2009.

[4] D. Barman, F. Korn, D. Srivastava, D. Gunopulos, N. Yong,
and D. Agarwal. Parsimonious explanations of change in
hierarchical data. In Proceedings of ICDE 2007, 2007.

[5] M. P. Collins, T. J. Shimeall, S. Faber, J. Naies, R. Weaver,
and M. D. Shon. Using uncleanliness to predict future bot-
net addresses. In Proceedings of the Internet Measurement
Conference, 2007.

[6] http://www.confickerworkinggroup.org/

wiki/.

[7] G. Cormode, F. Korn, S. Muthukrishnan, and D. Srivas-
tava. Diamond in the rough: ﬁnding hierarchical heavy hit-
ters in multi-dimensional data. In SIGMOD ’04: Proceed-
ings of the 2004 ACM SIGMOD international conference on
Management of data, pages 155–166, New York, NY, USA,
2004. ACM.

[8] http://www.fbi.gov/news/stories/2011/

november/malware_110911/.

[9] H. Esquivel, T. Mori, A. Akella, and A. Mutapcic. On the
effectiveness of IP reputation for spam ﬁltering. In Proceed-
ings of COMSNETS’10, 2010.

[10] C. Estan, S. Savage, and G. Varghese. Automatically infer-
ring patterns of resource consumption in network trafﬁc. In
SIGCOMM, 2003.

[11] Y. Freund, R. E. Schapire, Y. Singer, and M. K. Warmuth.
Using and combining predictors that specialize. In STOC,
1997.

[12] http://blog.fireeye.com/research/2012/
07/grum-botnet-no-longer-safe-havens.
html.

[13] S. Hao, N. A. Syed, N. Feamster, A. Gray,

and
S. Krasser. Detecting spammers with SNARE: Spatio-
temporal network-level automatic reputation engine. In Pro-
ceedings of Usenix Security Symposium, 2009.

[14] G. Hulten, L. Spencer, and P. Domingos. Mining time-

changing data streams. In Proceedings of KDD’01, 2001.

[15] J. P. John, A. Moshchuk, S. Gribble, and A. Krishnamurthy.
Studying spamming botnets using botlab. In Proceedings of
NSDI ’09, 2009.

[16] J. Jung and E. Sit. An empirical study of spam trafﬁc and
the use of DNS black lists. In Proceedings of Internet Mea-
surement Conference (IMC), 2004.

[17] D. Kifer, S. Ben-David, and J. Gehrke. Detecting changes

[26] S. Sinha, M. Bailey, and F. Jahanian. Shades of grey: On the
effectiveness of reputation-based ”blacklists”. In Proceed-
ings of Malware 2008, 2008.

[27] S. Sinha, M. Bailey, and F. Jahanian. Improving spam black-
listing through dynamic thresholding and speculative aggre-
gation. In Proceedings of NDSS 2010, 2010.

[28] F. Soldo, A. Markopoulo, and K. Argyraki. Optimal ﬁlter-
ing of source address preﬁxes: Models and algorithms. In
INFOCOM, 2009.

[29] S. Venkataraman, A. Blum, D. Song, S. Sen, and
O. Spatscheck. Tracking dynamic sources of malicious ac-
tivity at internet-scale. In NIPS, 2009.

[30] S. Venkataraman, S. Sen, O. Spatscheck, P. Haffner, and
D. Song. Exploiting network structure for proactive spam
mitigation. In Proceedings of Usenix Security’07, 2007.

[31] Y. Xie, F. Yu, K. Achan, E. Gillum, , M. Goldszmidt, and
T. Wobber. How dynamic are IP addresses? In Proceedings
of ACM SIGCOMM, 2007.

[32] Y. Xie, F. Yu, K. Achan, R. Panigrahy, G. Hulten, and I. Os-
ipkov. Spamming botnets: signatures and characteristics. In
Proceedings of SIGCOMM 2008, 2008.

[33] J. Zhang, P. Porras, and J. Ulrich. Highly predictive black-

lists. In Proceedings of Usenix Security’08, 2008.

[34] Y. Zhang, S. Singh, S. Sen, N. Dufﬁeld, and C. Lund. On-
line identiﬁcation of hierarchical heavy hitters: algorithms,
evaluation, and applications. In IMC ’04: Proceedings of the
4th ACM SIGCOMM conference on Internet measurement,
pages 101–114, New York, NY, USA, 2004. ACM.

in data streams. In Proceedings of VLDB 2004, 2004.

[18] M. Konte, J. Jung, and N. Feamster. Dynamics of online
In Proceedings of PAM ’09,

scam hosting infrastructure.
2009.

[19] B. Krishnamurthy and J. Wang. On network-aware clus-
tering of web clients. In Proceedings of ACM SIGCOMM,
2000.

[20] N. Littlestone and M. Warmuth. The weighted majority
Information and Computation, 108:212–251,

algorithm.
1994.

[21] Z. M. Mao, V. Sekar, O. Spatscheck, J. van der Merwe, and
R. Vasudevan. Analyzing large ddos attacks using multiple
data sources. In ACM SIGCOMM Workshop on Large Scale
Attack Defense, 2006.

[22] Z. Qian, Z. Mao, Y. Xie, and F. Yu. On network-level clus-
ters for spam detection. In Proceedings of NDSS 2010, 2010.
[23] A. Ramachandran and N. Feamster. Understanding the
In Proceedings of

network-level behavior of spammers.
ACM SIGCOMM, 2006.

[24] A. Ramachandran, N. Feamster, and S. Vempala. Filtering
spam with behavioral blacklisting. In Proceedings of ACM
CCS, 2007.

[25] http://www.symantec.com/security_

response/writeup.jsp?docid=
2006-011714-3948-99.

