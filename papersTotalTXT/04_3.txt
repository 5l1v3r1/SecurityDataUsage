Making Argument Systems for Outsourced Computation Practical (Sometimes)

Srinath Setty, Richard McPherson, Andrew J. Blumberg, and Michael Walﬁsh

The University of Texas at Austin

Abstract

This paper describes the design, implementation, and evalu-
ation of a system for performing veriﬁable outsourced com-
putation. It has long been known that (1) this problem can
be solved in theory using probabilistically checkable proofs
(PCPs) coupled with modern cryptographic tools, and (2)
these solutions have wholly impractical performance, ac-
cording to the conventional (and well-founded) wisdom.
Our goal is to challenge (2), with a built system that im-
plements an argument system based on PCPs. We describe
a general-purpose system that builds on work of Ishai et
al. (CCC ’07) and incorporates new theoretical work to im-
prove performance by 20 orders of magnitude. The system
is (arguably) practical in some cases, suggesting that, as a
tool for building secure systems, PCPs are not a lost cause.

Introduction

1
This paper describes progress toward the goal of practi-
cal and general-purpose veriﬁable outsourced computation.
This broad area has seen renewed interest, owing to cloud
computing (a computationally limited device ofﬂoads pro-
cessing to the cloud but does not assume the cloud’s correct-
ness [36]), volunteer computing (some 30 projects on the
BOINC [1] software platform use volunteers’ spare cycles,
but some “volunteers” return wrong answers [6]), peer-to-
peer computing, and high assurance computing (in the lat-
ter cases, remote peers or components are likely to be un-
trusted). Research has resulted in practical solutions, which
depend on various conditions particular to the operating
regime (e.g., they require trusted hardware [27, 62], or as-
sume independent failures and replicate [6, 25, 42, 52, 56]),
and theoretical solutions, which tend toward specialized al-
gorithms for the computation at hand. There is, however, a
strand of theory that is unconditional and general-purpose.
Unfortunately, this theory has so far been totally imprac-
tical, which leads to the question: can we incorporate this
powerful and enticing theory into a built system?

Our focus is on argument systems, which are interactive
protocols with two actors, a prover and a veriﬁer. Assum-
ing that the prover is computationally bounded, such pro-
tocols can convince the veriﬁer that the prover executed
a given computation correctly and that the prover holds a
proof to that effect. This theory dates to the 1980s [24, 39],
and starting with Kilian [48, 49] efﬁcient argument sys-
tems [45] have been based on probabilistically checkable
proofs (PCPs)—which themselves are astonishing. Infor-

mally, the central result is that a veriﬁer can—with a suit-
ably encoded proof and with a negligible chance of re-
garding a wrong answer as correct—check an answer’s
correctness by probing a constant number of locations in
a proof [8, 9]. Unfortunately, PCPs and hence arguments
are wildly impractical: traditional PCPs are too expen-
sive to instantiate at the prover or query from the veriﬁer.
While state-of-the-art PCP schemes are asymptotically efﬁ-
cient [15–17, 30], the constants on their running times are
large, and they seem too intricate to be implemented easily.
This brings us to our animating question: can we con-
struct an argument system for outsourced computation that
has practical performance and is simple? Speciﬁcally, we
require, ﬁrst, that the veriﬁer do less work than if it executed
the outsourced computation locally. Some of the theoretical
schemes meet this requirement asymptotically, but we want
to meet it for reasonable computation sizes. Second, we re-
quire that the prover not do much more work than it would
without veriﬁcation. Last, we strongly favor protocols that
are simple for both veriﬁer and prover: a simple protocol is
easier to implement, check for correctness, and optimize for
performance.

Our starting point in answering the above question is a
powerful and elegant insight of Ishai, Kushilevitz, and Os-
trovsky [45]: some PCPs, though hopelessly impractical to
materialize explicitly, are linear functions for which evalu-
ation at any given point is inexpensive. Ishai et al. use such
linear PCPs to build argument systems, via a novel linear
commitment protocol: the prover commits to a linear func-
tion (the PCP), after which the veriﬁer can inexpensively
“query the proof” by asking the prover to evaluate the lin-
ear function at a veriﬁer-chosen point. Since linear PCPs
are simple (as PCPs go), the resulting argument systems are
too. Nonetheless, they are still not practical. For example,
for m × m matrix multiplication, the veriﬁer would have to
do 109 · m6 work—a factor of 109 · m3 more than executing
the computation locally. This overhead comes from the en-
coding of the computation, a large number of cryptographic
commitments, and substantial setup costs.

This paper describes a built system, called PEPPER, that
goes a long way toward making argument systems practi-
cal. PEPPER reﬁnes the protocol of Ishai et al. to shrink
program encoding (via a concise representation that gen-
eralizes arithmetic circuits), reduce the cost of commit-
ment (via a stronger and streamlined commitment primi-
tive), and amortize the veriﬁer’s costs (via batching). We

prove the soundness of these reﬁnements. The result is a
simple constant-round protocol that gains a factor of over
1017 (no joke) versus a naive implementation of [45].

Much (but not all) of PEPPER’s remaining costs stem
from the computational complexity of the prover’s work.
This problem is shared by all PCP schemes, so a protocol
in which the prover’s total work is not much greater than
the cost of executing the computation would be a major im-
provement. In fact, a key innovation in PEPPER is to meet
this goal for computations of real interest (matrix multipli-
cation, polynomial evaluation, etc.) by tailoring the PCP en-
coding to reduce overhead. The result is roughly three more
orders of magnitude saved, for a total of 20. We note that
the tailoring is systematic, and we believe that it will lend
itself to automation (see §3.6, §4.2, and §6).

The tailored protocols for our examples are close to prac-
tical: at problem sizes of m = 500 variables, for instance,
the veriﬁer beneﬁts from outsourcing degree-2 polynomial
evaluation when working over 25, 000 batched computa-
tions, and the veriﬁcation takes minutes. And with two
heuristic optimizations, we can get these numbers down to
a batch size of 118 and sub-second veriﬁcation time.

Of course, PEPPER is not yet ready for production de-
ployment, but its remaining obstacles, while signiﬁcant, do
not seem insurmountable. Modular exponentiation is a bot-
tleneck, but this primitive occurs in many cryptographic
protocols and will beneﬁt as researchers optimize it. An-
other obstacle is the computation encoding. One might
guess that arithmetic circuits are too inefﬁcient to be useful,
but we discovered that we could tailor circuits until they im-
posed no overhead above a C++ program (§3.3). Of course,
in the real world, people perform computations besides self-
contained numerical functions. However, our work suggests
that it will be possible to build a compiler that transforms a
broader class of computations to efﬁcient tailored protocols.
Also, we had to start somewhere, to move PCPs from the-
ory to technology. Our hope now is that PEPPER opens the
door to an exciting area of systems research.

To explain this paper’s organization, we note that there
is a contrast between the “what” and the “why” of PEP-
PER. The “what” is surprisingly simple: the veriﬁer sub-
mits vectors to the prover and expects dot products in re-
turn. The “why”, however, requires some notation and time
to explain, as PEPPER builds on the theory of PCPs, which
is subtle and counter-intuitive. For this reason, Section 2
is a fairly technical overview of the underlying machinery.
While this background is necessary for the precise speci-
ﬁcation of our protocols, the trusting reader can probably
skip to Section 3, where we discuss the innovations and
details of PEPPER. We experimentally evaluate PEPPER in
Section 4. We survey related work in Section 5. Here, we
just note that while there has been much theoretical work

on unconditional, general-purpose veriﬁable computation,
these works are not yet practical, and there have been few
concerted efforts to make them so.

We originally proposed this research program in a posi-
tion paper [64]. However, that paper gave only a high-level
sketch that we have since heavily modiﬁed; it did not give a
concrete protocol, proofs, an implementation, or an evalua-
tion. The speciﬁc contributions of this paper are (1) a built
PCP-based system that is near practical; (2) a series of re-
ﬁnements, with proofs, to the protocol of Ishai et al. [45]
that save 20 orders of magnitude; (3) tailored PCP proto-
cols that result in a prover whose overhead is only a con-
stant factor; and (4) the implementation and experimental
evaluation of our system, PEPPER.
2 Preliminaries and base protocol
2.1 A crash course in PCPs
Consider a veriﬁer V that wishes to be convinced that a
given problem instance X (e.g., a given 3-CNF logical for-
mula) is in an NP language L (e.g., the set of satisﬁable 3-
CNF formulas). By deﬁnition of NP, if X is in L, then there
is some witness z that V can check in polynomial time to be
convinced of X’s membership in L. Remarkably, there also
exists a proof π that convinces V of X’s membership but
only needs to be inspected in a constant number of places—
yet if X is not in L, then for any purported proof, the prob-
ability that V is wrongly convinced of X’s membership can
be arbitrarily close to zero. This remarkable statement is the
rough content of the PCP theorem [8, 9], and the rest of this
subsection describes the machinery from this theorem that
is relevant to PEPPER.

Following [8], we take L to be Boolean circuit satisﬁa-
bility: the question of whether the input wires of a given
Boolean circuit C can be set to make C evaluate to 1.1 It
sufﬁces to consider this problem because L is NP-complete;
any other problem in NP can be reduced to it. Of course,
a satisfying assignment z—a setting of all wires in C such
that C evaluates to 1—constitutes an (obvious) proof that C
is satisﬁable: V could check z against every gate in C. Note
that this check requires inspecting all of z. In contrast, the
PCP theorem yields a V that makes only a constant number
of queries to an oracle π and satisﬁes:
• Completeness. If C is satisﬁable, then there exists a lin-
ear function π (called a proof oracle) such that, after V
queries π, Pr{V accepts C as satisﬁable} = 1, where the
probability is over V’s random choices.

If

• Soundness.
then
Pr{V accepts C as satisﬁable} <  for all purported
proof functions ˜π. Here,  is a constant that can be
driven arbitrarily low.

satisﬁable,

not

is

C

1A Boolean circuit is a set of interconnected gates, each with input wires
and an output wire, with wires taking 0/1 values.

Note that we are requiring a correct proof π to be a lin-
ear function over ﬁnite ﬁelds.2 Following [45], we call
such proofs linear PCPs. By linear function, we mean that
π(q1 + q2) = π(q1) + π(q2). A linear function π : Fn (cid:55)→ Fb
can be regarded as a b× n matrix M, where π(q) = M· q; in
the case b = 1, π returns a dot product with the input. Be-
low we describe a linear PCP that is used by [8] as a build-
ing block; this linear PCP is also presented in [16, 45], and
we borrow some of our notation from these three sources.

To motivate this linear PCP—that is, the encoding of π,
and how V interacts with it—recall that we must avoid V’s
having to check a purported assignment, z, against every
gate, as that would be equivalent to the polynomial-time
check of membership. Instead, V will construct a polyno-
mial P(Z) that represents C, and π will be carefully con-
structed to allow evaluation of this polynomial. For each
of the s gates, V creates a variable Zi ∈ {0, 1} that repre-
sents the output of gate i. V also creates a set of arithmetic
constraints, as follows. If gate i is the AND of Zj and Zk,
then V adds the constraint Zi − Zj · Zk = 0; if gate i is the
NOT of Zj, then V adds the constraint 1 − (Zi + Zj) = 0;
if gate i is an input gate for the jth input, V adds the con-
straint Zi−inj = 0; and ﬁnally, for the last gate, representing
the output of the circuit, we also have Zs − 1 = 0. V then
obtains the polynomial P(Z) by combining all of the con-
i vi · Qi(Z), where Z = (Z1, . . . , Zs),
each Qi(Z) is given by a constraint (e.g., Zi − ZjZk), and
V chooses each vi uniformly and independently at random
from a ﬁnite ﬁeld F. The reason for the randomness is given
immediately below.

straints: P(Z) = (cid:80)

if vi(cid:48) · Qi(cid:48)(z(cid:48)) = −(cid:80)

we mean π = (π(1), π(2)), where π(1)(·) = (cid:104)·, z(cid:105) and
π(2)(·) = (cid:104)·, z ⊗ z(cid:105). At this point, we have our ﬁrst set of
queries: V checks whether π(2)(γ2) + π(1)(γ1) + γ0 = 0. If
z is a satisfying assignment and π is correctly computed,
the check passes. Just as important, if z(cid:48) is not a satis-
fying assignment—which is always the case if C is not
satisﬁable—then V is not likely to be convinced. To see
this, ﬁrst assume that V is given a syntactically correct but
non-satisfying π(cid:48); that is, π(cid:48) = (z(cid:48), z(cid:48) ⊗ z(cid:48)), where z(cid:48) is a
non-satisfying assignment. The test above—that is, check-
ing whether π(cid:48)(2)(γ2)+π(cid:48)(1)(γ1)+γ0 = 0—checks whether
P(z(cid:48)) = 0. However, there must be at least one i(cid:48) for which
Qi(cid:48)(z(cid:48)) is not 0, which means that the test passes if and only
i(cid:54)=i(cid:48) vi · Qi(z(cid:48)). But the {vi} are con-
ceptually chosen after z(cid:48), so the probability of this event is
upper-bounded by 1/|F|.
The above test is called the circuit test, and it has so far
been based on an assumption: that if π(cid:48) is invalid, it encodes
some (non-satisfying) assignment. In other words, we have
been assuming that π(cid:48)(1) and π(cid:48)(2) are linear functions that
are consistent with each other. But of course a malevolently
constructed oracle might not adhere to this requirement. To
relax the assumption, we need two other checks. First, with
linearity tests [12, 21], V makes three queries to π(1) and
three to π(2), and checks the responses. If the checks pass,
V develops a reasonable conﬁdence that π(1) and π(2) are
linear functions, which is another way of saying that π(1)(·)
is returning (cid:104)·, z(cid:105) for some z and that π(2)(·) is returning
(cid:104)·, u(cid:105) for some u ∈ Fs2. In the second test, the quadratic
correction test, V makes four queries total and checks their
responses; if the checks pass, V develops reasonable conﬁ-
dence that these two linear functions have the required re-
lationship, meaning that u = z ⊗ z. Once these tests have
passed, the circuit test above is valid.

In all, V makes (cid:96) = 14 queries. The details of the queries
and tests, and a formal statement of their completeness and
soundness, are in [8] and Appendix A. Here, we just in-
formally state that if C is satisﬁable, then V will always be
convinced by π, and if C is not satisﬁable, then V’s proba-
bility of passing the tests is upper bounded by a constant κ
(for any ˜π). If the scheme is repeated ρ times, for µ = (cid:96) · ρ
total queries, the error probability  becomes  = κρ.

Notice that P(z) detects whether z is a satisfying assign-
ment: (1) if z is a satisfying assignment to the circuit, then
it also satisﬁes all of the {Qi(Z)}, yielding P(z) = 0; but
(2) if z is not a satisfying assignment to the circuit, then the
randomness of the {vi} makes P(z) unlikely to equal 0 (as
illustrated in the next paragraph). Thus, the proof oracle π
must encode a purported assignment z in such a way that
V can quickly evaluate P(z) by making a few queries to π.
To explain the encoding, let (cid:104)x, y(cid:105) represent the inner (dot)
product between two vectors x and y, and x⊗y represent the
outer product x·yT (that is, all pairs of components from the
two vectors). Observe that V can write

P(Z) = (cid:104)γ2, Z ⊗ Z(cid:105) + (cid:104)γ1, Z(cid:105) + γ0.

The {γ0, γ1, γ2} are determined by the {Qi(Z)} and the
choice of {vi}, with γ2 ∈ Fs2, γ1 ∈ Fs, and γ0 ∈ F. The rea-
son that V can write P(Z) this way is that all of the {Qi(Z)}
are degree-2 functions.
Given this representation of P(Z), V can compute P(z) by
asking for (cid:104)γ2, z ⊗ z(cid:105) and (cid:104)γ1, z(cid:105). This motivates the form
of a correct proof, π. We write π = (z, z ⊗ z), by which
2The PCP theorem permits, but does not impose, this restriction; we need
it for reasons elucidated in the next subsection.

2.2 Arguments
The theory above says that V can be convinced of a circuit’s
satisﬁability by making only a constant number of queries
to the proof oracle π. But how does V query π? Clearly, π
cannot be available for direct inspection by V because it is
tremendous: written out, π would be a list of the function’s
values at every point in an exponentially-sized domain. The
idea of an efﬁcient argument (due to Kilian [48, 49]) is to
use a PCP in an interactive protocol: a separate prover P
computes a PCP and responds to V’s queries. However, P

must be forced to “act like” a ﬁxed proof—P must be pre-
vented from adjusting answers to later queries based on ear-
lier answers. Kilian’s observation is that this can be done
with cryptographic commitments.

In the sections ahead, we build on an elegant scheme by
Ishai, Kushilevitz, and Ostrovsky [45]. They (1) observe
that π is a linear function (determined by z and z ⊗ z) and
(2) develop a commitment to a linear function primitive.
In this primitive, P commits to a linear function by pre-
evaluating the function at a point chosen by V and hidden
from P; then, V submits one query, and the response must
be consistent with the pre-evaluation. Roughly speaking, V
can now proceed as if P’s responses are given by an oracle
π. (More accurately, V can proceed as if P’s responses are
given by a set of non-colluding oracles, one per PCP query.)
In more detail, V obtains a commitment from P by ho-
momorphically encrypting a random vector r and asking P
to compute Enc(π(r)); P can do this without seeing r, by
the linearity of π and the homomorphic properties of the
encryption function (we do not need or assume fully ho-
momorphic encryption [37]). V can then apply the decryp-
tion function to recover π(r). To submit a PCP query q and
obtain π(q), V asks P for π(q) and π(r + αq), for α ran-
domly chosen from F. V then requires that π(r + αq) =
π(r)+απ(q), or else V rejects π(q). By running parallel in-
stances of the commitment protocol (one for each time that
V wants to inspect π), Ishai et al. convert any PCP protocol
that uses linear functions into an argument system [24, 39].
Arguments are deﬁned as follows; we borrow some of
our notation and phrasing from [45], and we restrict the def-
inition to Boolean circuits. An argument (P, V) with sound-
ness error  comprises two probabilistic polynomial time
entities, P and V, that take a Boolean circuit C as input and
meet two properties:
• Completeness. If C is satisﬁable and P has access to the
satisfying assignment z, then the interaction of V(C) and
P(C, z) always makes V(C) accept C’s satisﬁability.
• Soundness. If C is not satisﬁable, then for every efﬁcient
malicious P∗, the probability (over V’s random choices)
that the interaction of V(C) and P∗(C) makes V(C) ac-
cept C as satisﬁable is < .

3 Design and details of PEPPER
Problem statement and threat model. We wish to imple-
ment the following protocol. A computer that we control,
the veriﬁer, sends a program Ψ and an input x to a remote
computer, the prover. The prover returns a result y, and the
veriﬁer issues queries over a small number of interaction
rounds to the prover, whose responses either establish for
the veriﬁer that Ψ was run correctly and that y is the result
of running Ψ on x, or else cause the veriﬁer to reject. If y
is incorrect, the veriﬁer should reject with high probabil-

ity. We do not provide the converse; that is, rejection in our
context implies only that the prover has not given a correct
proof, not that y (cid:54)= Ψ(x). We require the following: (1) this
protocol should be cheaper for the veriﬁer, in computational
resources, than computing y locally, and (2) the guarantee
that the protocol provides to the veriﬁer should make no
assumptions about the prover, other than standard crypto-
graphic ones. That is, the prover can subvert the protocol,
can choose not to follow it, can return wrong answers, etc.

3.1 The promise and perils of PCPs
In principle, the problem above can be solved with PCPs. In
practice, a number of severe obstacles arise, as can be seen
by the following attempt to use PCPs. There is a Boolean
circuit C (which depends on Ψ, x, and y) such that C is sat-
isﬁable (that is, evaluates to 1) if and only if y is the correct
output of Ψ run on x. Assume that the prover and veriﬁer
can efﬁciently derive C, given Ψ, x, and y. Then, the prover
can issue a PCP (as in §2.1) of C’s satisﬁability. At that
point, if y is the correct output, the veriﬁer can efﬁciently
inspect the PCP to be convinced both that Ψ was executed
correctly and that Ψ produces y when run on x; if y is not
the correct output, the probability that the veriﬁer accepts C
as satisﬁable is upper-bounded by a negligible constant—
for any purported PCP. This approach sounds promising;
unfortunately, it is totally impractical:
• The proof is too long. It is much too large for the veriﬁer

to handle or for the prover to write out in full.

• The protocol is too complicated. State-of-the-art PCP
protocols [15–17, 30] partially address the concern about
proof length, but they are intricate to the point of mak-
ing a bug-free implementation difﬁcult. Unfortunately,
in this context, even small bugs can be security-critical.
Complexity also hinders optimization.

• The phrasing of the computation is too primitive. Even
if they have simple control ﬂow, most general-purpose
computations are far longer when expressed as Boolean
circuits than in, say, C++.

• The preparatory work is too high for the veriﬁer. Deriv-
ing C and generating queries to the proof take at least as
much work for the veriﬁer as executing the computation.
• The prover’s overhead is too high. In the base PCP pro-
tocol (§2.1), the prover’s work is at least quadratic in the
number of circuit wires. While this overhead can be re-
duced to a polylogarithmic factor [15–17, 30] (at the cost
of intricacy, as noted above), we ideally want to limit the
prover’s overhead to a small constant factor.

The ﬁrst two obstacles above can be addressed by the argu-
ment system of Ishai et al. [45]. As discussed in Section 2.2,
their approach addresses proof length (since the proof is not
materialized) and proof complexity (since the proof is sim-

FIGURE 1—High-level depiction of PEPPER, a PCP-based argument system for veriﬁed outsourced computation between a veriﬁer and a
prover. We formalize this picture and prove its soundness in the appendices.

ply a linear function to which the prover commits). Proof
length and proof complexity in exchange for commitment:
this is a great trade! However, it brings another obstacle:
• The parallel commitments are too expensive. Commit-
ment requires cryptographic operations and hence mul-
tiprecision arithmetic, and the scheme of [45] invokes
these operations far too much (by several orders of mag-
nitude) to be practical.

We now turn to our system, PEPPER, which builds on [45]
and addresses all of the items above.

3.2 Overview of PEPPER
Figure 1 depicts PEPPER. In the computation phase, V se-
lects a computation3 Ψ and different inputs x1, . . . , xβ, and
P returns outputs y1, . . . , yβ. These computations can hap-
pen iteratively or in a batch. For each computation, P creates
and stores a proof oracle πi establishing that Ψ(xi) = yi.
In the proof commitment phase, V asks P to commit to all
of its proofs. Then V moves to the proof veriﬁcation phase
and issues PCP queries to P, whose responses must be con-
sistent with the commitment phase. Then, V runs the PCP
veriﬁcation checks on P’s responses. At that point, V out-
puts accept or reject for each computation. An output of
accept on yi means that yi = Ψ(xi), with high probability.
The rest of this section describes how PEPPER overcomes
the obstacles mentioned in Section 3.1. PEPPER addresses
proof length and complexity by inheriting from [45]; it
shrinks the program encoding by using arithmetic circuits
instead of Boolean circuits (§3.3); it reduces commitment
costs by requiring fewer commitments while offering better
security (§3.4); it uses batching to reduce V’s costs (§3.5);

3Our implementation supports both preconﬁguring computations and up-
loading binaries online for P to execute.

and it reduces P’s overhead for some problems by reduc-
ing redundancy in the PCP encoding (§3.6). Figure 2 sum-
marizes the costs under these reﬁnements; we explain this
ﬁgure over the course of the section.

3.3 Arithmetic circuits and concise gates
To address the concern about the encoding of the compu-
tation, PEPPER uses arithmetic circuits, instead of Boolean
circuits. In a traditional arithmetic circuit, the input and out-
put wires take values from a large set (e.g., a ﬁnite ﬁeld or
the integers). This extension is a natural one, as the PCP
machinery is already expressed as arithmetic versions of
Boolean circuits. However, we observe that the machinery
also works with what we call concise gates, each of which
encapsulates a function of many inputs (e.g., a dot product
between two large vectors). Note that a gate here does not
represent a low-level hardware element but rather a modu-
lar piece of the computation that enters the veriﬁcation al-
gorithm as an algebraic constraint.

This simple reﬁnement is critical to practicality. First, it
is vastly more compact to represent, say, multiplication with
a single gate than as a Boolean circuit. Beyond that, for
certain computations (e.g., parallelizable numerical ones,
such as matrix multiplication), the circuit model imposes
no overhead; that is, the “circuit” is the same as a C++ pro-
gram, so the only overhead comes from proving and veri-
fying (as demonstrated in §4.3). However, this model has
known limitations; for example, comparison operations re-
quire relatively large circuits. Future work is to address this
problem, perhaps using tailored PCP encodings (§3.6).
Details and an example. Using arithmetic circuits requires
only minor modiﬁcations to the PCP scheme described in
Section 2.1. Here, V produces a set of constraints (there, V

input to the computation:  xoutput of the computation:  y† commitment query:  Enc(r)create π,a PCP† PCP queries: q1, q2, ..., qµ, tverifier (V) prover (P) commit to PCP:  Enc(π(r))PCP scheme(§3.3, §3.6)  batching (§3.5)all messages and checks happen β times in parallel, unless marked with † consistency check  (PCP responses:  π(q1), π(q2), ..., π(qµ), π(t)PCP verification checks (linear commitment(Fig. 3, §3.4) π(q1)+π(q2)=π(q3),  π(q7)·π(q8)= π(q9)−π(q10), .... ??π(t) = π(r) + α1·π(q1) +(cid:7715)+ αµ·π(qµ)?))op

naive impl. of [45]
109m6

batching (§3.5)
109m6

arith. circ. (§3.3)
4m4

new commit (§3.4)
4m4

new PCPs (§3.6)
m3

e + 2c
d
c
f

109m6 · µ(cid:48)
µ(cid:48)
109m6 · µ(cid:48)
(2µ(cid:48) + 96m2 · ρ)

PCP encoding size (|π|)
V’s per-instance work (compare to local, naive computation: f · m3)
109m6 · µ(cid:48)/β
Issue commit queries
µ(cid:48)
Process commit responses
109m6 · µ(cid:48)/β
Issue PCP queries
(2µ(cid:48)+96m2·ρ)
Process PCP responses
P’s per-instance work (compare to local, naive computation: f · m3)
109m6 · µ(cid:48)
Issue commit responses
109m6 · µ(cid:48)
Issue PCP responses
|π|: # of components in matrix associated to linear function π (§2.1)
(cid:96) = 14: # of PCP queries per repetition (Appendix A)
e: cost of homomorphic encryption of a single ﬁeld element (Fig. 3, step 1)
ρ = 70: # of repetitions to drive error low (Appendix A)
µ = (cid:96) · ρ ≈ 1000: # of PCP queries per instance
d: cost of homomorphic decryption of a single ﬁeld element (Fig. 3, step 3)
µ(cid:48) ≈ 3µ: # of PCP queries pre-commit-reﬁnement (§3.4)
f : cost of ﬁeld multiplication (Fig. 3, steps 4–6)
h: cost of ciphertext addition plus multiplication (Fig. 3, step 2)
β: # of computation instances batch veriﬁed (§3.2, §3.5)
c: cost of generating a pseudorandom # between 0 and a 192-bit prime (§4.1)

4m4 · µ(cid:48)/β
µ(cid:48)
4m4 · µ(cid:48)/β
(2µ(cid:48) + 3m2 · ρ)

4m4/β
1
4m4 · µ/β
(2µ + 3m2 · ρ)

m3/β
1
m3 · µ/β
(2µ + 3m2 · ρ)

109m6 · µ(cid:48)
109m6 · µ(cid:48)

4m4 · µ(cid:48)
4m4 · µ(cid:48)

4m4
4m4 · µ

m3
m3 · µ

h
f

FIGURE 2—High-order costs under our reﬁnements, cumulatively applied, compared to naive local execution and a naive implementation
of [45], for our running example of m × m matrix multiplication. Rows for V and P contain operation counts, except for the “op” ﬁeld,
which includes a parameter denoting the cost of the operations in that row. Section 4.5 quantiﬁes d, e, f , h and c; Section 4.6 quantiﬁes β.
The “PCP” rows include the consistency queries and checks (Fig. 3, steps 4–6).

transforms a Boolean circuit into a set of constraints) over s
variables from a ﬁnite ﬁeld F (there, over binary variables)
that can be satisﬁed if and only if y is the correct output
of Ψ(x) (there, if and only if the circuit is satisﬁable); V
then combines those constraints to form a polynomial over
s values in the ﬁeld F (there, in the ﬁeld GF(2)). One way
to look at this use of arithmetic circuits is that it represents
the computation as a set of constraints directly.
To illustrate the above, we use the example of m × m
matrix multiplication. We choose this example because it is
both a good initial test (it is efﬁciently encodable as an arith-
metic circuit) and a core primitive in many applications: im-
age processing (e.g., ﬁltering, rotation, scaling), signal pro-
cessing (e.g., Kalman ﬁltering), data mining, etc.
In this example computation, let A, B, C be m × m ma-
trices over a ﬁnite ﬁeld F, with subscripts denoting entries,
so A = (A1,1, . . . , Am,m) ∈ Fm2 (for F sufﬁciently large we
can represent negative numbers and integer arithmetic; see
§4.1). The veriﬁer V sends A and B to the prover P, who
returns C; V wants to check that A· B = C. Matrix C equals
A · B if and only if the following constraints over variables
m,m) ∈ F2m2 can be satisﬁed:
Z = (Za
i,j − Bi,j = 0, for i, j ∈ [m] ;
i,j − Ai,j = 0, for i, j ∈ [m] ;
Zb
Za
i,k · Zb
Za

Ci,j − m(cid:88)

k,j = 0, for i, j ∈ [m].

1,1, . . . , Zb

1,1, . . . , Za

m,m, Zb

k=1

Note that the third type of constraint, which captures the dot
product, is an example of a concise gate.

V is interested in whether the above constraints can be
met for some setting Z = z (if so, the output of the com-

i,j vc

i,j vb

i,j·(Zb

i,j va
k=1 Za

i,j− Bi,j) +(cid:80)

P(Z) by combining the constraints: P(Z) =(cid:80)
Ai,j) +(cid:80)
i,j·(Ci,j−(cid:80)m

putation is correct; if not, it is not). Thus, V proceeds as
in Section 2.1 and Appendix A. V constructs a polynomial
i,j −
i,j · (Za
i,k · Zb
k,j),
where V chooses the variables {v} randomly from F. As
before, V regards the prover P as holding linear proof ora-
cles π = (π(1), π(2)), where π(1)(·) = (cid:104)·, z(cid:105) and π(2)(·) =
(cid:104)·, z ⊗ z(cid:105) for some z ∈ F2m2. And as before, V issues linear-
ity test queries, quadratic correction test queries, and circuit
test queries (the randomly chosen {v} feed into this latter
test), repeating the tests ρ times. We address V’s cost of
constructing P(Z) and issuing queries in Section 3.5.

The completeness and soundness of the above scheme
follows from the completeness and soundness of the base
protocol. Thus, if C = A · B (more generally, if the claimed
output y equals Ψ(x)), then V can be convinced of that fact;
if the output is not correct, P has no more than  = κρ
probability of passing veriﬁcation.

Savings. Moving from a Boolean to a non-concise arith-
metic circuit saves, for a ﬁxed m, an estimated four orders
of magnitude in the number of circuit “wires” (the “wires”
being {Z}) and thus eight orders of magnitude in the query
size and the prover’s work (which are quadratic in the num-
ber of wires). The dot product gates decrease these quanti-
ties by another factor of m2 (since they reduce the number
of “wires” from m3 + 2m2 to 2m2). In Figure 2, the arith-
metic circuit column reﬂects these two reductions, the ﬁrst
being reﬂected in the elimination of the 109 factor and the
second in the move from the m6 to the m4 term.

Commit+Multidecommit

The protocol assumes an additive homomorphic encryption scheme (Gen, Enc, Dec) over a ﬁnite ﬁeld, F.
Commit phase
Input: Prover holds a vector w ∈ Fn, which deﬁnes a linear function π : Fn → F, where π(q) = (cid:104)w, q(cid:105).
1. Veriﬁer does the following:

• Generates public and secret keys (pk, sk) ← Gen(1k), where k is a security parameter.
• Generates vector r ∈R Fn and encrypts r component-wise, so Enc(pk, r) = (Enc(pk, r1), . . . , Enc(pk, rn)).
• Sends Enc(pk, r) and pk to the prover.

the veriﬁer.

2. Using the homomorphism in the encryption scheme, the prover computes e ← Enc(pk, π(r)) without learning r. The prover sends e to
3. The veriﬁer computes s ← Dec(sk, e), retaining s and r.
Decommit phase
Input: the veriﬁer holds q1, . . . , qµ ∈ Fn and wants to obtain π(q1), . . . , π(qµ).
4. The veriﬁer picks µ secrets α1, . . . , αµ ∈R F and sends to the prover (q1, . . . , qµ, t), where t = r + α1q1 + ··· + αµqµ ∈ Fn.
5. The prover returns (a1, a2, . . . , aµ, b), where ai, b ∈ F. If the prover behaved, then ai = π(qi) for all i ∈ [µ], and b = π(t).
6. The veriﬁer checks: b ?
FIGURE 3—PEPPER’s commitment protocol. V decommits queries q1, . . . , qµ for the price of a single commitment query, Enc(r). This
protocol strengthens one by Ishai et al. [45] and makes only minor changes to their notation and phrasing. The intent is that the µ queries be
the PCP queries and that n be the size of the proof encoding (s2 + s, until §3.6). The protocol assumes an additive homomorphic encryption
scheme but can be modiﬁed to work with a multiplicative homomorphic scheme (such as ElGamal [32]); see Appendix E.

= s + α1a1 + ··· + αµaµ). If so, it outputs (a1, a2, . . . , aµ). If not, it rejects, outputting ⊥.

3.4 Strengthening linear commitment
The commitment protocol in the base scheme of Ishai et
al. [45] relies on an additive homomorphic encryption op-
eration.4 If executed once, this operation is reasonably efﬁ-
cient (hundreds of microseconds; see Section 4.5); however,
the number of times that the base scheme invokes it is pro-
portional to at least the square of the input size times µ,
the number of PCP queries (roughly 1000). For the exam-
ple of m× m matrix multiplication with m = 1000, the base
scheme would thus require at least (1000)4 · 1000 · 100 µs:
over 3000 years, and that’s after the concise representation
given by the previous reﬁnement!

While we would be thrilled to eliminate homomorphic
encryptions, we think that doing so is unlikely to work in
this context. Instead, in this section we modify the commit-
ment protocol to perform three orders of magnitude fewer
encryptions; Appendix B proves the soundness of this mod-
iﬁcation by reducing its security to the semantic security of
the homomorphic encryption scheme. Moreover, our reduc-
tion is more direct than in the base scheme, which translates
into further cost reductions.
Details. In the base scheme [45], each PCP query by V
(meaning each of the µ queries, as described in §2.1, §3.3,
and Appendix A) requires V and P to run a separate in-
stance of commitment. Thus, to check one computation Ψ,
V homomorphically encrypts µ ≈ 1000 (see Figure 2) vec-
tors, and P works over all of these ciphertexts. This factor of
1000 is an issue because the vectors are encrypted compo-

4Note that we do not require fully homomorphic encryption [37]; as we
discuss in Section 5, the costs of such schemes are still prohibitive.

nentwise, and they have many components! (In the example
above, they are elements of Fs2 or Fs, where s = 2 · 106.)
Figure 3 presents our modiﬁed commitment protocol.
It homomorphically encrypts only one vector r ∈ Fs2+s,
called the commitment query, with the encryption work
amortizing over many queries (q1, . . . , qµ). This new pro-
tocol leads to a more direct security reduction than in the
base scheme. In their central reduction, Ishai et al. estab-
lish that commitment allows V to treat P as a set of non-
colluding but possibly malicious oracles. In each repetition,
their V must therefore issue extra queries (beyond the (cid:96)
PCP queries) to ensure that the oracles match. With our
commitment protocol, V can treat P as a single (possibly
cheating) oracle and submit only the PCP queries. Stated
more formally, Ishai et al. reduce linear PCP to linear MIP
(multiprover interactive proof [14]) to the argument model,
whereas we reduce linear PCP directly to the argument
model. We prove the reduction in Appendix B.
Savings. This reﬁnement reduces the homomorphic en-
cryptions and other commitment-related work by three or-
ders of magnitude, as depicted in Figure 2 by the elimina-
tion of the µ(cid:48) term from the “commit” rows in the “new
commit” column. As a second-order beneﬁt, we save an-
other factor of three (depicted in Figure 2 as a move from
µ(cid:48) to µ queries), as follows. The queries to establish the con-
sistency of multiple oracles have error ((cid:96) − 1)/(cid:96) = 13/14.
However, the soundness error of our base PCP protocol is
κ = 7/9. Since (13/14)ρ(cid:48) = (7/9)ρ when ρ(cid:48) ≈ 3ρ, it takes
roughly three times as many repetitions of the protocol to
contend with this extra error. Finally, the direct reduction
yields a qualitative beneﬁt: it simpliﬁes PEPPER.

3.5 Amortizing query costs through batching
Despite the optimizations so far, the veriﬁer’s work remains
unacceptable. First, V must materialize a set of constraints
that represent the computation, yet writing these down is as
much work as executing the computation. Second, V must
generate queries that are larger than the circuit. For exam-
ple, for m×m matrix multiplication (§3.3), the commitment
query has 4m4 + 2m2 components (matching the number
of components in the vector representation of the proof),
in contrast to the O(m3) operations needed to execute the
computation. A similar obstacle holds for many of the PCP
queries. To amortize these costs, we modify the protocols
to work over multiple computation instances and to ver-
ify computations in batch; we also rigorously justify these
modiﬁcations. Note that the modiﬁcations do not reduce V’s
checking work, only V’s cost to issue queries; however, this
is acceptable since checking is fast.
Details. We assume that the computation Ψ (or equiva-
lently, C) is ﬁxed; V and P will work over β instances of
Ψ, with each instance having distinct input. We refer to β
as the batch size. The prover P formulates β proof oracles
(linear functions): π1, . . . , πβ. Note that the prover can stack
these to create a linear function π : Fs2+s → Fβ (one can
visualize this as a matrix whose rows are π1, . . . , πβ).

To summarize the protocol, V now generates one set
of commitment and PCP queries, and submits them to all
of the oracles in the batch.5 The prover now responds to
queries q with π(q) ∈ Fβ, instead of with π(q) ∈ F. By
way of comparison, the previous reﬁnement (§3.4) encrypts
a single r for a set of queries q1, . . . , qµ to a proof π. This
one issues a single r and a single set of queries q1, . . . , qµ
to multiple proofs π1, . . . , πβ.

Appendix C details the protocol and proof-sketches its
soundness. We note that each of the β PCPs has the same
soundness error () as if it were queried individually. How-
ever, the errors for the β PCPs in a batch are correlated.
Savings. The most signiﬁcant beneﬁt is qualitative: with-
out batching, V cannot gain from outsourcing, as the query
costs are roughly the same as executing the computation.
The quantitative beneﬁt of this reﬁnement is, as depicted in
Figure 2, to reduce the per-instance cost of commitment and
PCP queries by a factor of β.

3.6 Optimizing the PCP encoding
In some cases, we can address the obstacle of prover over-
head by tailoring the PCP encoding. The key observations
are that (1) the basic protocol does not require a particular
PCP encoding, as long as the encoding is a linear function,
and (2) some circuits permit a much more streamlined en-

5Early in their paper Ishai et al. brieﬂy mention such an approach, but they
do not specify it. Later in their paper [45, §6.1], in a more general context,
they reuse PCP queries but not commitment queries.

coding. Speciﬁcally, we can tailor the prover’s linear func-
tion so that it contains only terms that the prover had to
compute anyway to return the result of the computation. (In
essence, we are reducing the redundancy in the PCP.) The
result for some computations, such as the examples given
below, is protocols in which the prover’s work is only a con-
stant factor above simply executing the computation.
Details and examples. Under the linear PCPs in Sec-
tions 2.1 and 3.3, the prover computes z ⊗ z, where z is a
satisfying assignment to the circuit (or constraint set). How-
ever, for some computations V’s circuit test (§2.1) interro-
gates only a subset of z⊗ z. Loosely speaking, P thus needs
to compute only that subset to produce the proof oracle.

k=1 Za

i,k·Zb

P(cid:48)(Z) =(cid:80)

i,j·(Ci,j−(cid:80)m

Matrix multiplication. As in Section 3.3, V again com-
bines constraints that represent the computation, again picks
random {v} to be coefﬁcients of those constraints, again
obtains a polynomial (which we will write as P(cid:48)(Z)), and
again submits queries to the prover’s oracle to get P(cid:48)(Z)
evaluated and to test that the prover is holding an oracle
of the correct form. There are two modiﬁcations to the ap-
proach presented in Section 3.3. First, in combining the con-
straints to construct P(cid:48)(Z), V does not include the degree-1
i,j − Ai,j = 0, etc.). Thus, V obtains
constraints (meaning Za
k,j), which, using our no-
tation from before, can be written P(cid:48)(Z) = (cid:104)γ2, Z ⊗ Z(cid:105)+γ(cid:48)
0.
However, we will write P(cid:48)(Z) differently. In Sections 2.1
and 3.3, the form above motivated the deﬁnition of π(2)(q)
as (cid:104)q, z ⊗ z(cid:105), for q ∈ Fs2 = Fm4. There, answering queries
to π(2) required the prover to do work proportional to m4.
This is not only more than we would like to pay, given the
O(m3) naive algorithm, but also more than we have to pay:
P(cid:48)(Z) includes only a subset of Z ⊗ Z. Speciﬁcally, observe
i,k · Zb
that the degree-2 terms in P(cid:48)(Z) all have the form Za
k,j.
The above suggests the following notation: for x, y ∈ Fm2,
x (cid:11) y consists of {xi,k · yk,j} for all i, j, k. The cardinality of
x (cid:11) y is m3. Thus, letting Za = (Za
m,m) and Zb =
(Zb

1,1, . . . , Za

i,j vc

1,1, . . . , Zb

m,m), we write:

P(cid:48)(Z) =(cid:10)γ(cid:48)

2, Za (cid:11) Zb(cid:11) + γ(cid:48)

0,

2 ∈ Fm3 has the same non-zero components as γ2.
where γ(cid:48)
As in the base protocols, V wants to evaluate P(cid:48)(z) since
P(cid:48)(z) is a bellwhether that indicates whether Z = z meets
all constraints (here, z is the satisfying assignment that is
purportedly encoded in the oracle π).

coding is now π = π(c)(·) (cid:44)(cid:10)·, za (cid:11) zb(cid:11), where za = A and

This brings us to the second modiﬁcation: the PCP en-

zb = B. To evaluate P(cid:48)(z), then, V asks for π(c)(γ(cid:48)
2), and V
tests whether π(c)(γ(cid:48)
2)+ γ0 = 0. This is our new circuit test;
observe that it is O(m3) for the prover to answer, and for V
to formulate a query. Like the base PCP protocols, this one
requires two other types of tests. The ﬁrst is again a linear-
ity test, to ensure that π(c) is (nearly) linear. The second is

again a consistency test, to ensure that π(c) indeed repre-
sents A(cid:11) B; this test is modiﬁed from the base scheme. The
details of the queries and tests, and proofs of their correct-
ness, are in Appendix D. Finally, note that π(c) is a linear
function, so it ﬁts into the commit protocol (§3.4).

tion of A at X = x can be written A(x) = (cid:104)AD,(cid:78)D

Low-degree polynomial evaluation. Suppose that we
wish to evaluate a degree-D polynomial A over the vari-
ables X = {X1, X2, . . . , Xm}. If we let Ak denote the vector
of coefﬁcients for the degree-k terms in A, then the evalua-
i=1 x(cid:105) +
··· + (cid:104)A2, x ⊗ x(cid:105) + (cid:104)A1, x(cid:105) + A0. For D = 2, we can repre-
sent the evaluation of A with a single degree-2 concise gate
(§3.3), where the “assignment” z is simply x itself; then,
computing π(2) in the base PCP encoding requires comput-
ing x ⊗ x. Thus, if A is dense (meaning that it has Ω(m2)
monomials), the PCP encoding adds little prover overhead
over computing A(x). However, for D = 3, a naive applica-
tion of the base protocol would include only degree-2 and
degree-1 constraints, requiring prover work and query size
of O(m4)—higher complexity than the O(m3) computation.
We can remove this overhead, if A is dense. We mod-
ify the encoding so that the prover holds not only π(1)
and π(2) (as in §2.1 and §3.3) but also π(3) : Fm3 → F,
where π(3)(·) (cid:44) (cid:104)·, z ⊗ z ⊗ z(cid:105). As above, the “assignment”
z is simply x itself. At this point, V must add several PCP
queries to establish the (near) linearity of π(3) and the con-
sistency of π(3) with (π(1),π(2)). For details of the queries
and tests, see [58, §7.8], which describes a similar construc-
tion. An analogous approach applies for D > 3 when D is
odd; if D is even, there are “circuits” that add no overhead.

Savings and discussion. For matrix multiplication and
degree-3 polynomial evaluation, the tailored PCP encoding
reduces the prover’s work and the query size from O(m4) to
O(m3). In our domain of interest, m is hundreds or thou-
sands, so the savings in V’s querying costs are two or
three orders of magnitude. The same factor is saved in the
prover’s costs. In fact, if the relevant objects (the matrices
or polynomials) are dense, the prover’s work to create the
PCP is the same complexity as executing the computation.
There is a caveat, however. Though the prover is lin-
ear, the constant is not ideal. With matrix multiplication,
for example, the prover’s work is roughly (h + f · µ) · m3
(as depicted in the prover’s rows in Figure 2). Meanwhile,
there is an approach that costs the prover f · m3, namely
Freivalds’s randomized algorithm for verifying matrix mul-
tiplication [58, §7.1]: this algorithm requires O(m2) time
for the veriﬁer and no overhead for the “prover”. More
generally, we know that many computations admit special-
purpose veriﬁcation protocols (see §5). However, we be-
lieve that the work of this subsection is interesting because
it reﬁnes the general-purpose PCP encodings and so might
work for a broad class of other circuits.

Implementation and evaluation

4
We assess our work by answering three high-level ques-
tions, which correspond to the three goals for PEPPER that
we stated in the introduction: (1) Is PEPPER simple enough
to be easily implementable and optimizable? (2) For what
values of the batch size, β, and the input size does PEPPER’s
veriﬁer gain from outsourcing? (3) At these values, how
much does PEPPER cost the prover? We answer these ques-
tions in the context of three model computations: matrix
multiplication, degree-2 polynomial evaluation, and degree-
3 polynomial evaluation. We chose these because they are
self-contained test cases and core primitives in many ap-
plications. The rest of this section describes our implemen-
tation, parameter choices, and further optimizations (§4.1);
then addresses the ﬁrst question (§4.2); and then answers
the latter two with experiments and analysis (§4.3–§4.7).

Implementation and optimizations

4.1
Implementation. Although PEPPER requires that compu-
tations be expressed over a ﬁnite ﬁeld F, we want to simu-
late computations over the integers (which requires simulat-
ing signed values and unbounded magnitudes). To that end,
we use the standard technique of working in Fp (the integers
modulo p), where p is a prime far larger than the actual input
domain of the computation (e.g., see [22, 70]). In particular,
we require the inputs (e.g., the matrix entries) to be 32-bit
quantities and choose p to be either a 128-bit prime (for
matrix multiplication and degree-2 polynomial evaluation)
or a 192-bit prime (for degree-3 polynomial evaluation). To
implement ﬁeld operations (as needed for veriﬁcation and
the computations themselves), PEPPER uses multiprecision
arithmetic, as implemented by the GNU MP library.

The core of the veriﬁer and prover are implemented in
C++. The prover can run as a Web service, with its inter-
faces exposed via HTTP URLs: we run the C++ prover core
and helper PHP utilities as persistent FastCGI processes [2]
to which the Apache Web server delegates HTTP requests.
implementation parallelizes only the
prover’s commit phase, using OpenMP [3]. Parallelizing the
veriﬁer and the rest of the prover, and distributing the prover
over multiple machines, are works in progress.

Currently, our

We implemented both Paillier [59] and ElGamal [32]
homomorphic encryption. Because the ElGamal homomor-
phism is multiplicative, not additive, ElGamal requires mi-
nor modiﬁcations to the commitment protocol (Figure 3);
these are described in Appendix E. Where the algorithms
call for random numbers, we use pseudorandom numbers,
as generated by the ChaCha/8 stream cipher [19], speciﬁ-
cally the amd64-xmm6 variant in its default conﬁguration.
Parameter choices. PEPPER has three security parameters,
which drive its total error of (cid:48) <  + c (as given by Theo-
rem B.1). The ﬁrst parameter is ρ, the number of PCP repe-

titions, which determines the PCP soundness error through
the bound  < κρ. (Per Appendix A, κ = 7/9.) We usu-
ally take ρ = 70, yielding  < 2.3 · 10−8 for the PCP
error. The second two parameters determine c, the com-
mitment soundness error. They are (a) |F|, the size of the
ﬁeld for the PCP and commitment machinery, and (b) the
homomorphic encryption scheme’s key size, which deter-
mines S, the error from encryption. From Appendix B, we
have c < 214 · (1/|F| + S)1/3. We take |F| ≈ 2128 (we
discussed ﬁeld size above) and disregard S (we discuss key
size below), yielding c < 2−28.

We performed all of our experiments with both encryp-
tion schemes but report results only from ElGamal because
its performance is better by almost a factor of 10 (as oth-
ers have also observed [35]). By default, we take the prime
modulus to be 704 bits, though we experiment with other
sizes. Of course, 704 bits is not industrial strength for
usual cryptographic applications. However, homomorphic
encryptions (Figure 3) are a bottleneck for PEPPER, so we
make a considered choice to use this key size. We believe
that this choice is acceptable in our context, as the key need
hold up only for one run of the protocol. Our choice is based
on the RSA factoring challenge.6
Further optimizations: HABANERO. We report results
from both PEPPER, whose design we have treated rigor-
ously, and HABANERO, a PEPPER variant that has two
performance improvements. First, under HABANERO, V
precomputes and installs on P the commitment query,
Enc(pk, r). Under this modiﬁcation, we use an industrial-
strength key length—1280 bits—as we intend to amortize
this ofﬂine step over a long time. The soundness of this
modiﬁcation is counterintuitive; since we don’t have space
for a proof, we call it a heuristic. For intuition, we note that
this modiﬁcation generalizes the way that a single r is used
for the entire batch (Appendix C). The second modiﬁcation
is to lower ρ from 70 to 1. This allows a prover to cheat
with probability as high as κ = 7/9. However, if V and P
interact repeatedly, a cheating prover would be detected.

4.2 Is PEPPER simple to implement and apply?
PEPPER is built on PCP theory, which requires a lot of de-
tail to explain. At the same time, that theory results in a
system whose mechanics are surprisingly simple. The veri-
ﬁer doesn’t do much more than generate and encrypt some
pseudorandomness (Section 3.4), ask the prover to multi-
ply some vectors with a matrix that it holds (Sections 3.3
and 3.6), and perform basic operations on the returned vec-
tors (Appendices A and D). Likewise, the prover doesn’t
need to do much more than determine the assignment z to

6In Nov. 2005 a 640-bit key was factored using “approximately 30
2.2GHz-Opteron-CPU years” and in Dec. 2009 a 768-bit key was fac-
tored using “almost 2000 2.2GHz-Opteron-CPU years” [4].

component

language

lines of code

Crypto library
Core library
Prover library
Veriﬁer library
Data exchange module
Helper utilities
Computation-independent total
matrix multiplication
degree-2 polynomial evaluation
degree-3 polynomial evaluation

C++
C++
C++
C++
PHP
C++

C++
C++
C++

549
323
174
280
43
388
1727
394
462
608

FIGURE 4—PEPPER’s components and their lines of code.

“gates” (which it does anyway as a result of executing the
algorithm), and return dot products.

Our sense of PEPPER’s simplicity is buttressed by three
things. The ﬁrst is its small code size. Figure 4 tabulates
the lines of code in our implementation (using [71]); the
computation-independent modules require only 1727 lines.
Second, applying PEPPER to new computations has
proved easy, in part because the “circuit” model of the com-
putation is not very far from an imperative statement of the
computation in C++ (§3.3). In fact, once our software ar-
chitecture was in place, a single graduate student was able
to implement new computations in less than an hour per
computation. While this is obviously longer than it would
take to code the computation with no veriﬁcation, it is not
a ridiculous amount of time. Moreover, a compiler could
perform this step automatically.

Third, optimizing the implementation has so far been rel-
atively easy. For example, parallelizing the prover’s com-
mitment phase required only three compiler directives and
one C++ statement; this simple change gives a substantial
speedup on multi-core hardware (as quantiﬁed below).

4.3 Experimental evaluation: method and setup
In the sections ahead, we will determine the input sizes
(which we loosely refer to as m) and batch sizes (β) at which
V gains from outsourcing versus computing locally, and we
will report CPU and network costs at these points. We ﬁrst
run experiments to illuminate the prototype’s performance
(§4.4); then use this performance plus microbenchmarks to
calibrate our CPU cost model from Figure 2 (§4.5); and then
use the model to estimate break-even points under PEPPER,
under HABANERO, and under the reﬁnements that lead to
them (§4.6). We treat network costs in §4.7.

Our baseline is local computation, which we assume uses
multiprecision arithmetic. While this assumption deprives
the baseline of native operations and hence may be an
overly optimistic comparison for PEPPER, we note that it
is not totally ridiculous: multiprecision arithmetic is a stan-
dard approach for avoiding overﬂow and roundoff concerns
when multiplying and adding many large numbers.

To measure CPU usage at prover and veriﬁer, we use

FIGURE 5—Measured CPU cost of one instance (β = 1) of PEPPER, compared to local execution, circuit execution, and under different
security parameters (k is the key size, and ρ is the number of PCP repetitions), for veriﬁer (V) and prover (P). For all computations,
m = 100. Much of PEPPER’s overhead is ﬁxed-cost, so it amortizes under batching (see Figure 6).

getrusage(); to measure network costs, we record the
amount of application-level data (not including network
headers) exchanged between the prover and the veriﬁer. We
run our experiments on Utah Emulab’s [72] d710s, which
are 2.4 GHz 64-bit Intel Quad Core Xeon E5530 with 12
GB of memory; they run 64-bit Ubuntu 11.04 Linux.

4.4 What is PEPPER’s end-to-end performance?
Beyond illustrating PEPPER’s overhead, the experiments in
this section are intended to assess the cost of the circuit rep-
resentation; to indicate how the security parameters (§4.1)
affect costs; and to illustrate how PEPPER’s overhead can be
mitigated by batching and parallelizing.

In the ﬁrst set of experiments, our baseline is the CPU
cost of local execution for matrix multiplication and poly-
nomial evaluation (degrees 2 and 3), with m = 100 in all
cases. We compare these baselines to executing the compu-
tation as a “circuit” but without veriﬁcation. We also mea-
sure PEPPER, conﬁgured with smaller (512 bits) and larger
(1024 bits) key sizes than our target (704 bits); these keys
are not suitable for PEPPER (owing to insecurity and inefﬁ-
ciency, respectively), but they give a sense of what PEPPER
pays for its cryptographic guarantees. Finally, we conﬁgure
PEPPER to run with a single repetition (ρ = 1) and with
multiple ones (ρ = 70). We do not depict HABANERO here.
We measure the CPU time at the veriﬁer and prover con-
sumed by PEPPER, end-to-end; this includes originating the
queries, transferring them through the HTTP interface, han-
dling responses, etc. The prover runs with one thread. For
each conﬁguration, we run 5 experiments, reporting average
CPU time in seconds; standard deviations are within 5% of
the means.

Figure 5 depicts the results. As shown in the ﬁgure, the
circuit representation imposes no overhead. (Veriﬁcation
and proving are another matter—more on that soon.) The
effect of PEPPER’s security parameters is as follows. For
matrix multiplication, PEPPER with 512-bit keys and 1024-
bit keys costs, respectively, 1.7 times less and 1.9 times
more than PEPPER with 704-bit keys (this holds for both

FIGURE 6—Measured CPU cost of the veriﬁer and the prover in
HABANERO, compared to local execution, for matrix multiplica-
tion (m = 200) under a batch size of β = 100, degree-2 polyno-
mial evaluation (m = 500) under a batch size of β = 200, and
degree-3 polynomial evaluation (m = 200) under a batch size of
β = 350. At these batch sizes, the veriﬁer gains from outsourcing.

prover and veriﬁer); results for the other computations are
similar. Interestingly, ρ has far less effect, since the crypto-
graphic commitment amortizes over the ρ repetitions (§3.4).
Veriﬁcation and proving clearly impose high overhead:
for example, with degree-2 polynomial evaluation, the over-
head over local computation is a factor of 3 · 104 for V and
104 for P. However, much of this cost is ﬁxed and amortizes
under batching (§3.5), as we demonstrate next.

Batching. We run HABANERO with multiple instances.
We run 3 experiments for each computation, reporting mean
CPU time (standard deviations are again within 5% of
means). The prover runs with four threads; we report its
cost as the sum of the CPU times taken by all four cores.

Figure 6 depicts the results. In these experiments, the ver-
iﬁer’s cost is below the cost of local computation. (We will
investigate break-even points systematically in Section 4.6.)
The prover’s cost is still high, but as we show next, paral-
lelizing mitigates its latency.

Parallelizing. Here, we experiment with HABANERO,
varying the number of threads (and hence cores) used. In
each of the prover’s two phases, we measure the wall clock
time taken by the phase. We report the speedup with N cores
as the ratio of total time taken (the sum of the two phases,
over three trials) when one core is active to the time taken
when N cores are active (again, over three trials).

100102104matrix multiplicationdegree-2 polynomial evaluationdegree-3 polynomial evaluationCPU usagenormalized to local  local  circuit  V (k=512, ρ=1)  V (k=704, ρ=1)  V (k=1024, ρ=1)  V (k=704, ρ=70)  P (k=512, ρ=1)  P (k=704, ρ=1)  P (k=1024, ρ=1)  P (k=704, ρ=70)  local  circuit  V (k=512, ρ=1)  V (k=704, ρ=1)  V (k=1024, ρ=1)  V (k=704, ρ=70)  P (k=512, ρ=1)  P (k=704, ρ=1)  P (k=1024, ρ=1)  P (k=704, ρ=70)  local  circuit  V (k=512, ρ=1)  V (k=704, ρ=1)  V (k=1024, ρ=1)  V (k=704, ρ=70)  P (k=512, ρ=1)  P (k=704, ρ=1)  P (k=1024, ρ=1)  P (k=704, ρ=70)100102104matrix multdegree-2 poly evaldegree-3 poly evalCPU usagenormalized to local  local  verifier  prover  local  verifier  prover  local  verifier  proverβ∗ (break-even
batch size)

V’s computation
time at β∗

P’s computation
time at β∗

computation (Ψ)

batching (§3.5)

matrix multiplication, m = 400
matrix multiplication, m = 1000
degree-2 polynomial eval, m = 200
degree-2 polynomial eval, m = 500
degree-3 polynomial eval, m = 200
degree-3 polynomial eval, m = 500

matrix multiplication, m = 400
matrix multiplication, m = 1000
degree-2 polynomial eval, m = 200
degree-2 polynomial eval, m = 500
degree-3 polynomial eval, m = 200
degree-3 polynomial eval, m = 500

matrix multiplication, m = 400
matrix multiplication, m = 1000
degree-2 polynomial eval, m = 200
degree-2 polynomial eval, m = 500
degree-3 polynomial eval, m = 200
degree-3 polynomial eval, m = 500

Never
Never
Never
Never
Never
1.6 · 1025
Never
Never
Never
Never
Never
5.6 · 1017 yr
Never
Never
Never
Never
Never
2.5 · 1042 yr

arith. circ. (§3.3)
2.8 · 1011
2.0 · 1011
Never
Never
Never
6.0 · 1010
9900 yr
1.1 · 105 yr
Never
Never
Never
2100 yr
1.9 · 1014 yr
5.4 · 1015 yr
Never
Never
Never
3.7 · 1013 yr

new commit (§3.4)
7.1 · 107
1.1 · 108
4.5 · 104
2.5 · 104
9.3 · 106
2.3 · 107
2.5 yr
61 yr
32 s
110 s
7.5 days
290 days
2.1 · 107 yr
1.3 · 109 yr
45 hr
6.2 days
7.1 · 104 yr
6.8 · 106 yr

new PCPs (§3.6)
4.5 · 104
2.7 · 104
4.5 · 104
2.5 · 104
4.6 · 104
4.6 · 104
14 hr
5.4 days
32 s
110 s
55 min
14 hr

8.1 yr
76 yr
45 hr
6.2 days
1.7 yr
27 yr

HABANERO (§4.1)

111
111
180
118
221
220

2.1 min
32 min
0.13 s
0.5 s
15 s
4.0 min

17 days
260 days
24 min
1.6 hr
5.8 days
92 days

FIGURE 8—Estimated break-even points (β∗) and running times at those points under PEPPER’s reﬁnements, to two signiﬁcant ﬁgures,
obtained by (1) setting V’s cost in Figure 2 equal to the cost of computing locally (also in Figure 2) and then (2) using the estimates of
e, d, h, f , c (from Figure 7) to solve for β∗. Batching is required to make outsourcing proﬁtable for V; without our reﬁnements, the batch size
is astronomical. Solving for m∗ using more reasonable values of β also yields extremely large results. Our reﬁnements bring these numbers
into the realm of the conceivable. Both V and P can be parallelized to reduce latency; Section 4.4 describes the effect of parallelizing P.

key size

ﬁeld size

e

d

h

f

c

95 µs
72 µs 18 ns 120 ns
704 bits (PEPPER)
704 bits (PEPPER)
95 µs 110 µs 45 ns 140 ns
1280 bits (HABANERO) 128 bits 660 µs 260 µs 200 µs 18 ns 120 ns
1280 bits (HABANERO) 192 bits 760 µs 260 µs 290 µs 45 ns 140 ns

128 bits 240 µs
192 bits 270 µs

FIGURE 7—Estimated parameters in our cost model (Figure 2),
for the ﬁeld and key sizes in our experiments.

For N = 2, the speedups are 1.99 in all three cases (the
ideal is 2). For N = 4, the prover’s end-to-end latency re-
duces by a factor of 3.7 for matrix multiplication, a factor of
3.7 for degree-3 polynomial evaluation, and a factor of 3.1
for degree-2 polynomial evaluation (the ideal is 4). We hy-
pothesize that the latter computation sees smaller speedup
because the computation is far smaller, so ﬁxed setup costs
are comparatively larger. These results suggest that there is
proﬁt in distributing the prover over multiple machines.

4.5 Calibrating the cost models
We use a cost model for each of our computations; Figure 2
depicts the one for matrix multiplication.7 When making
predictions about HABANERO (versus PEPPER), we adjust
the models to remove the cost of issuing commit queries and
to set ρ = 1. Note that, for simplicity, the models include
ﬁeld multiplication (f ) but not ﬁeld addition. Nevertheless,
for the purposes of estimating break-even points, the models
are pessimistic for PEPPER. First, not counting additions un-
derestimates the number of operations in the baseline com-
putation. Second, the models overestimate PEPPER’s opera-

7Not depicted is an additive 2e term in the “Process PCP responses” row,
from the modiﬁed check under ElGamal (see §4.1 and Appendix E).

computation (Ψ)
matrix multiplication, m = 400
matrix multiplication, m = 1000
degree-2 polynomial eval, m = 200
degree-2 polynomial eval, m = 500
degree-3 polynomial eval, m = 200
degree-3 polynomial eval, m = 500

network costs
17.1 GB
263 GB
11.4 MB
68.4 MB
2.93 GB
45.8 GB

FIGURE 9—Estimated network costs under HABANERO for the
computations and break-even points (β∗) in Figure 8. These costs
are signiﬁcant but amortize under batching.

tions. Speciﬁcally, the models more than compensate for the
omitted ﬁeld additions (which PEPPER performs in equal
number to ﬁeld multiplications) by double-counting ﬁeld
multiplications (which are more expensive).8

To estimate the parameters, we run a program that exe-
cutes each operation at least 5000 times, using 704-bit and
1280-bit keys. Figure 7 shows the means (standard devia-
tions are within 5% of the means). The two ﬁeld sizes yield
different parameter values because in the cryptographic op-
erations, ﬁeld entries appear in exponents.

How well do our models predict the end-to-end empiri-
cal results (§4.4)? The prover’s costs are at most 8% above
the model’s prediction. The veriﬁer’s costs are at most 50%
above what the model predicts. However, much of this dif-
ference can be explained by the cost of I/O operations (to
ﬁles and the network); subtracting this cost from the ver-
iﬁer’s measured performance yields an estimate that is at
most 10% above the model’s prediction. Finally, the base-

8The reason for the double-counting is that we take (cid:96), the number of PCP
queries per repetition, as equal to 14, but in reality only seven of those 14
queries are submitted to the high-order proof (see Appendix A).

line’s empirical costs range between 20% and 100% more
than the model’s predictions. We hypothesize that this di-
vergence results from the model’s omitting ﬁeld additions
(as discussed above) and from adverse caching behavior.

4.6 What are the break-even points?
Given the model’s rough accuracy, it can systematically (if
roughly) make predictions about break-even points—that is,
about PEPPER’s regime of applicability. We set V’s costs in
the (now parameterized) models equal to the cost of local
computation, and solve for β∗, the batch size at which V
gains from outsourcing under PEPPER. We do not account
for the cost of serialization (this part of our implementation
is unoptimized) so may slightly underestimate β∗ (by a fac-
tor nearly equal to the overhead of serialization).

Figure 8 depicts the estimated break-even points. Under
PEPPER (the column marked “new PCPs”), the numbers are
sometimes reasonable for V. The latency from P is, ahem,
somewhat larger. However, we would ask the reader to look
leftward on this table to see what the numbers used to look
like. Under HABANERO, we do not need to appeal to rela-
tivism quite as much: V gains from outsourcing at reason-
able batch sizes, and while P’s latency is surely high, the
work can be parallelized and distributed (see §4.4). For ex-
ample, if P used 128 cores, we would expect its latency to
be on the order of hours or less for all but one of the rows.

4.7 What are the network costs?
The main network expense is from issuing queries (see Fig-
ure 3). To assess this cost, we estimate the sizes of the
queries and responses, applying this simple model to the
computations at the break-even points in Figure 8. (For HA-
BANERO, we count only PCP queries; commitment queries
are assumed to be pre-installed.) We separately validate by
comparing to predictions with various experimental runs,
ﬁnding that the model is within 3% of the measured trafﬁc.
Figure 9 depicts the estimates, under HABANERO. These
costs are obviously signiﬁcant. However, compared to the
prover’s running time, the latency from network costs is not
high. Moreover, PEPPER’s network overhead amortizes, as
the query cost stays ﬁxed with increasing β. By contrast,
some plausible baselines (for example, replicating the com-
putation to multiple workers) have network overhead in pro-
portion to β.

5 Related work
There has been a lot of work on veriﬁed computation, and
the motivation of outsourcing to the cloud has given a new
impetus to this area. In this section we try to situate our
work in this landscape. We note that our work is con-
cerned only with verifying computations, not hiding their
content or input; thus, even though some of the works that

General-purpose approaches intended for practice.
Perhaps the most basic technique, replication [6, 25, 42, 52,
56], relies on assumptions about the independence of the
workers, in contrast to our goal of unconditional veriﬁca-
tion. Trusted computing [27, 62] assumes that the hardware
or a hypervisor works properly. Some attestation work,
though powerful, gives assurance that a remote application
has desired properties but not that it is implemented cor-
rectly [26, 53, 63, 66]. Other attestation work requires a
trusted base [5, 54]. Auditing and spot-checking [31, 42,
46, 50, 57] focus directly on the output, but unless the audit
coverage is nearly perfect (which degenerates to executing
the computation), a worker that alters a key bit (e.g., in an
intermediate step) is unlikely to be detected, in contrast to
the properties of PCPs (§2.1).

Special-purpose approaches from theory and prac-
tice. Recent work by Benabbas et al. [18] and Boneh and
Freeman [22] outsources polynomial evaluation, which in-
spired our use of this computation (§3.6, §4). Ergun et
al. [33] study efﬁcient approximate property testing proto-
cols for polynomials and related computations. Golle [40]
outsources the inversion of one-way functions, and Karame
et al. [47] apply this to detect cheating in a distributed se-
quential computation. Sion [65] and Thompson et al. [68]
outsource database operations. Wang et al. outsource lin-
ear programming [69] and approximating systems of lin-
ear equations [70]. Atallah has protocols for linear algebra
(see [10] and citations therein). Other work [34, 61] han-
dles aggregate statistics computed from distributed sensors.
While some of these works inspired our choice of particular
computations, our focus is on general-purpose approaches.
Homomorphic encryption and secure multiparty pro-
tocols. Homomorphic encryption is a powerful building
block, as it lets the prover compute over ciphertext. Groth
uses homomorphic encryption to produce a zero-knowledge
argument protocol [41]; unfortunately, a preliminary feasi-
bility study that we performed indicated that this was not
efﬁcient enough for our purposes. Gentry’s recent break-
through construction of a fully homomorphic encryption
scheme [37] has led to new protocols for veriﬁable non-
interactive computation [28, 36] with input hiding. How-
ever, fully homomorphic encryption is completely infeasi-
ble on today’s computers.

we cite below achieve such hiding, our comparison will
be silent about this property. Also, we do not summarize
work that adopts a different threat model, such as multiple
provers [10, 43] or assumptions about the difﬁculty of mim-
icking valid program counter values [67].

Closely related are secure multi-party protocols. In such
protocols, parties compute an agreed-upon function of pri-
vate data, revealing only the result [73]. In fact, the scheme
of [36] builds such a protocol based on fully homomor-
phic encryption. Other general-purpose protocols for com-

putation on hidden data using homomorphic encryption in-
clude the work of [7] and the circuit application of the
Boneh-Goh-Nissim cryptosystem [23]. However, in gen-
eral, because of the input hiding requirements, the costs for
the veriﬁer are proportional to the size of the circuit; such
protocols are not really suitable in our context. Moreover,
while general-purpose compilers for such protocols exist
[13, 44, 51], they are not yet practical, despite the striking
improvements reported in [44].

PCPs, argument systems, and efﬁcient interactive
protocols. The potential of PCPs and efﬁcient arguments
to serve as a foundation for veriﬁed computations has long
been known to theorists [8, 9, 11, 14, 20, 39, 48, 49, 55]. We
borrow from this theory, guided by our goals. We turn to ar-
gument systems because advances in short (non-interactive)
PCPs [15–17, 30, 60] seem too intricate to be implemented
easily; e.g., they require recursive application of their own
machinery. And among interactive approaches, we build
upon the scheme of [45], which is simple, instead of upon
an interactive protocol that is asymptotically more efﬁcient
but far more intricate [38]. We now review recent work that
makes the opposite decision.

Following our position paper [64], Cormode, Mitzen-
macher, and Thaler have a recent publication [29] with sim-
ilar positioning. As with our system, they obtain a lot of
mileage from the observation that arithmetic circuits and
concise gates are compatible with the protocols and result
in substantially more efﬁcient encodings. Some of their fo-
cus is on specialized algorithms for linear problems in the
streaming model. However, they also describe a general-
purpose implementation, based on [38] instead of [45]. On
the one hand, the protocol of [38] does not require public-
key cryptography and has better asymptotic overhead than
that of [45]. On the other hand, the protocol of [45] has
better round complexity and does not require uniformity as-
sumptions on the circuit families in question. A more de-
tailed comparison using measurements on benchmark prob-
lems is work in progress.

6 Discussion, next steps, and outlook
This work began from the intuition that the protocol of Ishai
et al. [45] might lead to a simple and potentially practi-
cal built system, and PEPPER appears to have fulﬁlled that
promise: the veriﬁer is relatively inexpensive, the prover is
much better than we expected, the protocol is simple, and
the tailored scheme is not so far from true practicality. A
deployable system is plausibly within view.

Nonetheless, there is still much work to do to get PEP-
PER ready for prime time. Its protocols are still not cheap
enough, particularly for the prover. Its model of compu-
tation is restrictive: we studied problems that admit con-
cise expressions with arithmetic circuits performing multi-
precision arithmetic (§3.3, §4.1), with a focus on prob-

lems that allow decomposition into identical parallel mod-
ules (§3.5) or permit tailored PCPs (§3.6). And while for
arbitrary computations, one can theoretically apply PEP-
PER—by compiling the computation to a circuit with, say,
the compiler developed as part of the Fairplay system
[13, 44, 51]—our estimates indicate that this approach is
unlikely to achieve acceptable performance and that a more
specialized compiler is necessary.

The good news is that substantial further improvements
seem possible. In the short term, there is much to be gained
from engineering: a move to elliptic curve cryptography
will allow us to improve the security parameters while de-
creasing overhead, and we plan to explore special-purpose
hardware for modular exponentiation. We are working on
compilers to automate the manual process described in Sec-
tion 4.2; the goal is to output our non-tailored protocol
for suitable computations and (when applicable) to gen-
erate the tailored PCPs that produce the most practical
scheme (§3.6).

More broadly, the key challenge for this area is to ex-
pand the approach beyond computations that are naturally
speciﬁed as arithmetic circuits over ﬁnite ﬁelds. For in-
stance, a basic issue is handling ﬂoating point numerics ef-
ﬁciently. More generally, handling computations with in-
teresting control ﬂow is a central problem. Satisfactory an-
swers to these questions will help realize the vision of mak-
ing efﬁcient arguments (and PCPs) truly practical.

Acknowledgments
Nikhil Panpalia created the parallel prover implementation. For
helpful comments, we thank Lorenzo Alvisi, Dan Boneh, Allen
Clement, Mike Freedman, Maxwell Krohn, Josh Leners, Antonio
Nicolosi, Bryan Parno, Raluca Popa, Victor Vu, Shabsi Walﬁsh,
Ed Wong, Hao Wu, and the anonymous reviewers. Emulab was
helpful as always. The research was supported by AFOSR grant
FA9550-10-1-0073 and by NSF grants 1055057 and 1040083.

Our implementation and experimental conﬁgurations are avail-

able at: http://www.cs.utexas.edu/pepper

References
[1] Berkeley Open Infrastructure for Network Computing (BOINC).

http://boinc.berkeley.edu.

[2] FastCGI. http://www.fastcgi.com/.
[3] OpenMP. http://openmp.org/.
[4] The RSA Challenge Numbers.

http://www.rsa.com/rsalabs/node.asp?id=2093.

[5] S. Alsouri, ¨O. Dagdelen, and S. Katzenbeisser. Group-based

attestation: Enhancing privacy and management in remote
attestation. In TRUST, 2010.

[6] D. P. Anderson, J. Cobb, E. Korpela, M. Lebofsky, and

D. Werthimer. SETI@home: An experiment in public-resource
computing. CACM, 45(11):56–61, Nov. 2002.

[7] B. Applebaum, Y. Ishai, and E. Kushilevitz. From secrecy to

soundness: efﬁcient veriﬁcation via secure computation. In ICALP,
2010.

[13] A. Ben-David, N. Nisan, and B. Pinkas. FairplayMP: A system for

[40] P. Golle and I. Mironov. Uncheatable distributed computations. In

[8] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. Proof
veriﬁcation and the hardness of approximation problems. J. of the
ACM, 45(3):501–555, May 1998.

[9] S. Arora and S. Safra. Probabilistic checking of proofs: a new

characterization of NP. J. of the ACM, 45(1):70–122, Jan. 1998.

[10] M. J. Atallah and K. B. Frikken. Securely outsourcing linear

algebra computations. In ASIACCS, 2010.

[11] L. Babai, L. Fortnow, L. A. Levin, and M. Szegedy. Checking

computations in polylogarithmic time. In STOC, 1991.

[12] M. Bellare, D. Coppersmith, J. H˚astad, M. Kiwi, and M. Sudan.

Linearity testing in characteristic two. IEEE Transactions on
Information Theory, 42(6):1781–1795, Nov. 1996.

secure multi-party computation. In ACM CCS, 2008.

[14] M. Ben-Or, S. Goldwasser, J. Kilian, and A. Wigderson.

Multi-prover interactive proofs: how to remove intractability
assumptions. In STOC, 1988.

[15] E. Ben-Sasson, O. Goldreich, P. Harsha, M. Sudan, and S. Vadhan.

Short PCPs veriﬁable in polylogarithmic time. In Conference on
Computational Complexity (CCC), 2005.

[16] E. Ben-Sasson, O. Goldreich, P. Harsha, M. Sudan, and S. Vadhan.
Robust PCPs of proximity, shorter PCPs and applications to coding.
SIAM J. on Comp., 36(4):889–974, Dec. 2006.

[17] E. Ben-Sasson and M. Sudan. Short PCPs with polylog query

complexity. SIAM J. on Comp., 38(2):551–607, May 2008.

computation over large datasets. In CRYPTO, 2011.

[19] D. J. Bernstein. ChaCha, a variant of Salsa20.

http://cr.yp.to/chacha.html.

[20] M. Blum and S. Kannan. Designing programs that check their work.

J. of the ACM, 42(1):269–291, 1995.

[21] M. Blum, M. Luby, and R. Rubinfeld. Self-testing/correcting with
applications to numerical problems. J. of Comp. and Sys. Sciences,
47(3):549–595, Dec. 1993.

[22] D. Boneh and D. M. Freeman. Homomorphic signatures for

polynomial functions. In EUROCRYPT, 2011.

[35] S. Garriss, M. Kaminsky, M. J. Freedman, B. Karp, D. Mazi`eres,

and H. Yu. RE: Reliable Email. In NSDI, 2006.

[36] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veriﬁable

computing: Outsourcing computation to untrusted workers. In
CRYPTO, 2010.

[37] C. Gentry. A fully homomorphic encryption scheme. PhD thesis,

Stanford University, 2009.

[38] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating
computation: Interactive proofs for muggles. In STOC, 2008.

[39] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge

complexity of interactive proof systems. SIAM J. on Comp.,
18(1):186–208, 1989.

[41] J. Groth. Linear algebra with sub-linear zero-knowledge arguments.

RSA Conference, 2001.

In CRYPTO, 2009.

[42] A. Haeberlen, P. Kouznetsov, and P. Druschel. PeerReview:

Practical accountability for distributed systems. In SOSP, 2007.
[43] S. Hohenberger and A. Lysyanskaya. How to securely outsource

crytographic computations. In TCC, 2005.

[44] Y. Huang, D. Evans, J. Katz, and L. Malka. Faster secure two-party

computation using garbled circuits. In USENIX Security, 2011.
[45] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. Efﬁcient arguments

without short PCPs. In Conference on Computational Complexity
(CCC), 2007.

Semantic integrity in large-scale online simulations. ACM
Transactions on Internet Technology (TOIT), 10(1), Feb. 2010.

[47] G. O. Karame, M. Strasser, and S. Capkun. Secure remote

execution of sequential computations. In International Conference
on Information and Communications Security (ICICS), 2009.

[48] J. Kilian. A note on efﬁcient zero-knowledge proofs and arguments

(extended abstract). In STOC, 1992.

[49] J. Kilian. Improved efﬁcient arguments (preliminary version). In

CRYPTO, 1995.

[50] L. Kissner and D. Song. Verifying server computations. In ACNS,

[18] S. Benabbas, R. Gennaro, and Y. Vahlis. Veriﬁable delegation of

[46] S. Jha, S. Katzenbeisser, C. Schallhart, H. Veith, and S. Chenney.

[23] D. Boneh, E. J. Goh, and K. Nissim. Evaluating 2-DNF formulas on

2004.

ciphertexts. In TCC, 2005.

[24] G. Brassard, D. Chaum, and C. Cr´epeau. Minimum disclosure

proofs of knowledge. J. of Comp. and Sys. Sciences, 37(2):156–189,
1988.

[51] D. Malkhi, N. Nisan, B. Pinkas, and Y. Sella. Fairplay: A secure

two-party computation system. In USENIX Security, 2004.

[52] D. Malkhi and M. Reiter. Byzantine quorum systems. Distributed

Computing, 11(4):203–213, 1998.

[25] M. Castro and B. Liskov. Practical Byzantine fault tolerance and

[53] J. M. McCune, Y. Li, N. Qu, Z. Zhou, A. Datta, V. Gligor, and

proactive recovery. ACM Trans. on Computer Sys., 20(4):398–461,
2002.

[26] L. Chen, R. Landfermann, H. L¨ohr, M. Rohe, A.-R. Sadeghi,

C. St¨uble, and H. G¨ortz. A protocol for property-based attestation.
In ACM Workshop on Scalable Trusted Computing, 2006.
[27] A. Chiesa and E. Tromer. Proof-carrying data and hearsay

arguments from signature cards. In ICS, 2010.

[28] K.-M. Chung, Y. Kalai, and S. Vadhan. Improved delegation of
computation using fully homomorphic encryption. In CRYPTO,
2010.

[29] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical veriﬁed

computation with streaming interactive proofs. In ITCS, 2012.

[30] I. Dinur. The PCP theorem by gap ampliﬁcation. J. of the ACM,

54(3), June 2007.

[31] W. Du, J. Jia, M. Mangal, and M. Murugesan. Uncheatable grid

computing. In IEEE Intl. Conf. on Dist. Computing Sys. (ICDCS),
2004.

[32] T. ElGamal. A public key cryptosystem and a signature scheme
based on discrete logarithms. IEEE Transactions on Information
Theory, 31:469–472, 1985.

[33] F. Ergun, R. Kumar, and R. Rubinfeld. Approximate checking of

polynomials and functional equations. In FOCS, 1996.

[34] M. Garofalakis, J. M. Hellerstein, and P. Maniatis. Proof sketches:

Veriﬁable in-network aggregation. In ICDE, 2007.

A. Perrig. TrustVisor: Efﬁcient TCB reduction and attestation. In
IEEE Symposium on Security and Privacy, 2010.

[54] J. M. McCune, B. J. Parno, A. Perrig, M. K. Reiter, and H. Isozaki.

Flicker: An execution infrastructure for TCB minimization. In
EuroSys, 2008.

[55] S. Micali. Computationally sound proofs. SIAM J. on Comp.,

30(4):1253–1298, 2000.

[56] N. Michalakis, R. Soul´e, and R. Grimm. Ensuring content integrity
for untrusted peer-to-peer content distribution networks. In NSDI,
2007.

[57] F. Monrose, P. Wycko, and A. D. Rubin. Distributed execution with

[58] R. Motwani and P. Raghavan. Randomized Algorithms. Cambridge

remote audit. In NDSS, 1999.

University Press, 1995.

[59] P. Paillier. Public-key cryptosystems based on composite degree

residuosity classes. In EUROCRYPT. Springer-Verlag, 1999.

[60] A. Polishchuk and D. A. Spielman. Nearly-linear size holographic

proofs. In STOC, 1994.

[61] B. Przydatek, D. Song, and A. Perrig. SIA: Secure information

aggregation in sensor networks. In ACM Sensys, 2003.

[62] A.-R. Sadeghi, T. Schneider, and M. Winandy. Token-based cloud
computing: secure outsourcing of data and arbitrary computations
with lower latency. In TRUST, June 2010.

[63] A. Seshadri, M. Luk, E. Shi, A. Perrig, L. van Doorn, and P. Khosla.

Pioneer: Verifying integrity and guaranteeing execution of code on
legacy platforms. In SOSP, 2005.

[64] S. Setty, A. J. Blumberg, and M. Walﬁsh. Toward practical and

unconditional veriﬁcation of remote computations. In Proc.
Workshop on Hot Topics in Operating Systems (HotOS), 2011.

[65] R. Sion. Query execution assurance for outsourced databases. In

VLDB, 2005.

[66] F. Stumpf, A. Fuchs, S. Katzenbeisser, and C. Eckert. Improving the

scalability of platform attestation. In ACM Workshop on Scalable
Trusted Computing, 2008.

[67] S. Tang, A. R. Butt, Y. C. Hu, and S. P. Midkiff. Lightweight

monitoring of the progress of remotely executing computations. In
International Workshop on Languages and Compilers for Parallel
Computing, 2005.

[68] B. Thompson, S. Haber, W. G. Horne, T. Sander, and D. Yao.
Privacy-preserving computation and veriﬁcation of aggregate
queries on outsourced databases. In PET, 2009.

[69] C. Wang, K. Ren, and J. Wang. Secure and practical outsourcing of
linear programming in cloud computing. In INFOCOM, Apr. 2011.
[70] C. Wang, K. Ren, J. Wang, and K. M. R. Urs. Harnessing the cloud
for securely outsourcing large-scale systems of linear equations. In
IEEE Intl. Conf. on Dist. Computing Sys. (ICDCS), 2011.

[71] D. A. Wheeler. SLOCCount.

http://www.dwheeler.com/sloccount/.

[72] B. White, J. Lepreau, L. Stoller, R. Ricci, S. Guruprasad,

M. Newbold, M. Hibler, C. Barb, and A. Joglekar. An integrated
experimental environment for distributed systems and networks. In
OSDI, Dec. 2002.

[73] A. C.-C. Yao. How to generate and exchange secrets. In FOCS,

1986.

A A linear PCP
We state the queries, then the tests, then the statement of
correctness of the PCP in [8, §5–6]. We use ∈R to mean a
uniformly random selection. The purpose of q10, q12, q14 be-
low is self-correction; see [8, §5] or [58, §7.8.3] for details.
• Generate linearity queries: Select q1, q2 ∈R Fs and
q4, q5 ∈R Fs2. Take q3 ← q1 + q2 and q6 ← q4 + q5.
• Generate quadratic correction queries: Select q7, q8 ∈R
Fs and q10 ∈R Fs2. Take q9 ← (q7 ⊗ q8 + q10).
• Generate circuit queries: Select q12 ∈R Fs and q14 ∈R
Fs2. Take q11 ← γ1 + q12 and q13 ← γ2 + q14.
• Issue queries. Send queries q1, . . . , q14 to oracle π, get-

ting back π(q1), . . . , π(q14).

• Linearity tests: Check that π(q1) + π(q2) = π(q3) and
that π(q4) + π(q5) = π(q6). If not, reject.
• Quadratic correction test: Check that π(q7) · π(q8) =
π(q9) − π(q10). If not, reject.
(π(q11) − π(q12)) +
that
• Circuit
(π(q13) − π(q14)) = −γ0. If so, accept.

test: Check

The γ0, γ1, γ2 above are described in §2.1. The following
lemmas rephrase Lemmas 6.2 and 6.3 from [8]:

Lemma A.2 (Soundness [8]). There exists a constant κ <
1 such that if some proof oracle π passes all of the tests
above on C with probability > κ, then C is satisﬁable.
in [8], we can take κ >
Applying the analysis
max{7/9, 4δ + 2/|F|, 4δ + 1/|F|} for some δ such that
3δ − 6δ2 > 2/9. This ensures soundness for all three tests.
Here, δ relates to linearity testing [21]; to justify the con-
straint on δ and its connection to the 7/9 ﬂoor on κ, see [12]
and citations therein. Taking δ = 1
10, we can take κ =
7/9+neg, where neg can be ignored; thus, for convenience,
we assume κ = 7/9. Applying the lemma, we have that if
the protocol is run ρ = 70 times and C is not satisﬁable, V
wrongly accepts with probability  < κρ < 2.3 · 10−8.
B Reducing linear PCPs to arguments
This section ﬁrst reduces PCPs to arguments directly, us-
ing Commit+Multidecommit (Figure 3); this will formalize
Figure 1. The soundness of the reduction relies on Com-
mit+Multidecommit actually binding the prover after the
commit phase. Thus, the second (bulkier) part of the sec-
tion deﬁnes a new and strengthened commitment proto-
col (Defn. B.1), proves that Commit+Multidecommit imple-
ments this protocol (Lemma B.1), and proves that any such
protocol binds the prover in the way required by the reduc-
tion (Lemma B.2).

The reduction composes a PCP (such as the one in Ap-
pendix A) with Commit+Multidecommit. The protocol, theo-
rem, and proof immediately below are almost entirely a syn-
tactic substitution in [45, §4], replacing “MIP” with “PCP”.
Given a linear PCP with soundness , the following is
an argument system (P(cid:48), V(cid:48)). Assume that (P(cid:48), V(cid:48)) get a
Boolean circuit C and that P(cid:48) has a satisfying assignment.
1. P(cid:48) and V(cid:48) run Commit+Multidecommit’s commit phase,
2. V(cid:48) runs the PCP veriﬁer V on C to obtain µ = (cid:96)·ρ queries

causing P(cid:48) to commit to a function, π.

3. P(cid:48)

q1, . . . , qµ.
and V(cid:48)
run the decommit phase of Com-
mit+Multidecommit. V(cid:48) uses q1, . . . , qµ as the queries.
V(cid:48) either rejects the decommitted output, or it treats the
output as π(q1), . . . , π(qµ). To these outputs, V(cid:48) applies
the PCP veriﬁer V. V(cid:48) outputs accept or reject
depending on what V would do.

Theorem B.1. Suppose (P, V) is a linear PCP with sound-
ness . Then (P(cid:48), V(cid:48)) described above is an argument pro-
tocol with soundness (cid:48) ≤  + c. (c represents the er-
ror from the commitment protocol and will be ﬁlled in by
Lemma B.2.)

Lemma A.1 (Completeness [8]). Assume V is given a sat-
isﬁable circuit C. If π is constructed as in Section 2.1, and if
V proceeds as above, then Pr{V accepts C} = 1. The prob-
ability is over V’s random choices.

Proof. Completeness follows from the PCP and the deﬁni-
tion of Commit+Multidecommit. For soundness, Lemma B.2
below states that at the end of step 1 above, there is an ex-
tractor function that deﬁnes a single (possibly incorrect) or-

acle function ˜π such that, if V(cid:48) didn’t reject during decom-
mit, then with all but probability c, the answers that V(cid:48) gets
in step 3 are ˜π(q1), . . . , ˜π(qµ). But (P, V) has soundness
, so the probability that V(cid:48) accepts a non-satisﬁable C is
bounded by  + c.

We now strengthen the commitment primitive in Ishai
et al. [45], borrowing their framework. We deﬁne a proto-
col: commitment to a function with multiple decommitments
(CFMD). The sender is assumed to have a linear function,
π, given by a vector, w ∈ Fn; that is, π(q) = (cid:104)w, q(cid:105). In our
context, w is normally (z, z⊗ z). The receiver has µ queries,
q1, q2, . . . , qµ ∈ Fn. For each query qi, the receiver expects
π(qi) = (cid:104)w, qi(cid:105) ∈ F.
Deﬁnition B.1 (Commitment to a function with multi-
ple decommitments (CFMD)). Deﬁne a two-phase ex-
periment between two probabilistic polynomial time ac-
tors (S, R) (a sender and receiver, which correspond to our
prover and veriﬁer) in an environment E that generates F, w
and Q = (q1, . . . , qµ). In the ﬁrst phase, the commit phase,
S has w, and S and R interact, based on their random inputs.
In the decommit phase, E gives Q to R, and S and R interact
again, based on further random inputs. At the end of this
second phase, R outputs A = (a1, . . . , aµ) ∈ Fµ or ⊥. A
CFMD meets the following properties:

• Correctness. At the end of the decommit phase, R out-
puts π(qi) = (cid:104)w, qi(cid:105) (for all i), if S is honest.
• B-Binding. Consider the following experiment. The
environment E produces two (possibly) distinct µ-tuples
of queries: Q = (q1, . . . , qµ) and ˆQ = (ˆq1, . . . , ˆqµ). R
and a cheating S∗ run the commit phase once and two
independent instances of the decommit phase. In the two
instances R presents the queries as Q and ˆQ, respectively.
We say that S∗ wins if R’s outputs at the end of the
respective decommit phases are A = (a1, . . . , aµ) and
ˆA = (ˆa1, . . . , ˆaµ), and for some i, j, we have qi = ˆqj but
(cid:54)= ˆaj. We say that the protocol meets the B-Binding
ai
property if for all E and for all efﬁcient S∗, the probabil-
ity of S∗ winning is less than B. The probability is taken
over three sets of independent randomness: the commit
phase and the two runnings of the decommit phase.

Informally, binding means that after the sender commits, it
is very likely bound to a function from queries to answers.

Lemma B.1. Commit+Multidecommit
(Figure 3, Sec-
tion 3.4) is a CFMD protocol with B = 1/|F| + S, where
S comes from the semantic security of the homomorphic
encryption scheme.

π(r)+(cid:80)µ
i=1 π(αi·qi) = s+(cid:80)µ
which implies that b = s +(cid:80)µ

Proof. Correctness: for an honest sender, b = π(t) =
i=1 αi·ai,
i=1 αi · ai, and so veriﬁcation

i=1 αi·π(qi) = s+(cid:80)µ

passes, with the receiver outputting π(q1), . . . , π(qµ).

To show B-binding, we will show that if S∗ can system-
atically cheat, then an adversary A could use S∗ to break the
semantic security of the encryption scheme. Assume that
Commit+Multidecommit does not meet B-binding. Then
there exists an efﬁcient cheating sender S∗ and an environ-
ment E producing Q, ˆQ, i, j such that q (cid:44) qi = ˆqj and S∗ can
make R output ai (cid:54)= ˆaj with probability > B.
We will construct an algorithm A that differentiates be-
tween α, α(cid:48) ∈R F with probability more than 1/|F| + S
when given as input the following: a public key, pk; the en-
cryption, Enc(pk, r), of r for a random vector r ∈ Fn; r+αq;
and r+α(cid:48)q. This will contradict the semantic security of the
encryption scheme. A has Q, q, i, j hard-wired (because A is
working under environment E) and works as follows:
(a) A gives S∗ the input (pk, Enc(pk, r)); A gets back e
(b) A randomly chooses α1, . . . , αi−1, αi+1, . . . , αµ. It
(c) A now leverages Q, q, i, j. A was given r + αq, so it
k∈[µ]\i αkqk = r + Q · α,
where α = (α1, . . . , αi−1, α, αi+1, . . . , αµ). A gives
S∗ the input (Q, r + Q · α); that is, A invokes S∗ in the
decommit phase. A gets back (A, b).

can construct r + αq +(cid:80)
(d) Likewise, A constructs r + α(cid:48)q +(cid:80)

also randomly chooses ˆα1, . . . , ˆαj−1, ˆαj+1, . . . , ˆαµ.

k∈[µ]\j ˆαkˆqk = r +
ˆQ · ˆα, where ˆα = (ˆα1, . . . , ˆαj−1, α(cid:48), ˆαj+1, . . . , ˆαµ). A
gives S∗ (ˆQ, r + ˆQ · ˆα), invoking S∗ in the decommit
phase again. A gets back (ˆA, ˆb).

from S∗ and ignores it.

(cid:80)
k(cid:54)=j ˆαkˆak +(cid:80)
ˆt − t = (cid:80)

When S∗ wins (which it does with probability greater
than B = 1/|F| + S), b = s + α · A and ˆb = s + ˆα · ˆA,
(cid:54)= ˆaj (here, · represents the dot product). Now we
but ai
will get two linear equations in two unknowns. The ﬁrst
is ˆb − b = ˆα · ˆA − α · A, which can be rewritten as:
K1 = α(cid:48)ˆaj − αai , where A can derive K1 = ˆb − b −
k(cid:54)=i αkak. Now, let t = r + Q · α and let
ˆt = r + ˆQ · ˆα. To get the second equation, we start with
k∈[µ]\i αkqk + α(cid:48)q − αq. This
equation concerns a vector. We choose an index (cid:96) in the
vector where q is not zero (if q is zero everywhere, then
r is revealed). At that index, we have the following equa-
tion in scalars: K2 = α(cid:48) − α , where A can derive K2 =
k )/q((cid:96)). Now A can

k∈[µ]\j ˆαkˆqk −(cid:80)

(ˆt((cid:96)) − t((cid:96)) −(cid:80)

solve for α (since the contrary hypothesis gave ai (cid:54)= ˆaj).

k +(cid:80)

k(cid:54)=j ˆαkˆq((cid:96))

k(cid:54)=i αkq((cid:96))

We now prove that after the commit phase, the prover
is effectively bound to a single function. Our articulation
again follows [45], speciﬁcally their Lemmas 3.2 and 3.6.

c = µ · 2 · (2 3(cid:112)9/2 + 1) · 3

Lemma B.2 (Existence of an extractor function). Let
(S, R) be a CFMD protocol with binding error B. Let
B. Let v = (vS∗, vR) represent
the views of S∗ and R after the commit phase (v captures the
randomness of the commit phase). For every efﬁcient S∗ and

√

for every v, there exists a function ˜fv : Fn → F such that the
following holds. For any environment E, the output of R at
the end of the decommit phase is, except with probability
c, either ⊥ or satisﬁes ai = ˜fv(qi) for all i ∈ [µ], where
(q1, . . . , qµ) are the decommitment queries generated by E,
and the probability is over the random inputs of S∗ and R in
both phases.
Proof. We will reuse the ideas in the proof of Lemma 3.2
in [45], but we must also ensure that q yields the same an-
swer independent of its position and the other queries in
the tuple. We begin with a deﬁnition: let Ext(v, q, i,(cid:126)q) (cid:44)
argmaxa Av(q, i,(cid:126)q, a), where Av(q, i,(cid:126)q, a) equals, in view
v = (vS∗, vR), the probability over the randomness of the
decommit phase that R’s ith output is a when the query tu-
ple is (cid:126)q; note that q is the ith component of (cid:126)q and is included
in Ext(·) and Av(·) for convenience. In other words, Ext(·)
is the most likely ai value to be output by R, if the full tuple
of queries is (cid:126)q and if q appears in the ith position. Note that,
after the commit phase, Ext(·) is given deterministically.

Claim B.3. Deﬁne 2 = ( 3(cid:112)9/2 + 1) ·

√

3

something other than ⊥. Deﬁne 1 = 3(cid:112)B9/2. We will
mit phase,(cid:80)

B. For all E
producing (q, i, j,(cid:126)q1,(cid:126)q2), where (cid:126)q1’s ith component is q
and (cid:126)q2’s jth component is also q, we have the following
with probability > 1 − 2 over the commit phase: either
Ext(v, q, i,(cid:126)q1) = Ext(v, q, j,(cid:126)q2), or else the probability over
the decommit phase of outputting ⊥ is greater than 1 − 2.
Proof. Assume otherwise. Then there is an environment E
producing (q, i, j,(cid:126)q1,(cid:126)q2) such that with probability > 2
over the commit phase, Ext(v, q, i,(cid:126)q1) (cid:54)= Ext(v, q, j,(cid:126)q2) and
with probability > 2 over the decommit phase, R outputs
show below that with probability > 1 − 1 over the com-
a∈F\Ext(v,q,i,(cid:126)q1) Av(q, i,(cid:126)q1, a) is < 1. Thus, with
probability > 2−1 over the commit phase, we have (1) the
probability over the decommit phase is > 2− 1 that R out-
puts Ext(v, q, i,(cid:126)q1) in the ith position (since R outputs some-
thing other than ⊥ with probability > 2, yet the probabil-
ity of outputting anything other than Ext(v, q, i,(cid:126)q1) is < 1);
and (2) likewise, the probability of outputting Ext(v, q, j,(cid:126)q2)
in the jth position is > 2 − 1. If we now take Q = (cid:126)q1 and
ˆQ = (cid:126)q2, we have a contradiction to the deﬁnition of CFMD
because with probability > (2 − 1)3 = B over all three
(cid:54)= ˆaj, which generates a contradiction because
phases, ai
the deﬁnition of B-Binding says that this was supposed to
happen with probability < B.
We must now show that, with probability > 1 − 1
a∈F\Ext(v,q,i,(cid:126)q1) Av(q, i,(cid:126)q1, a) is <
1. If not, then with probability > 1 over the commit
a∈F\Ext(v,q,i,(cid:126)q1) Av(q, i,(cid:126)q1, a) ≥ 1. Now, following
Lemma 3.2 in [45], we can partition F into two sets T1, T2
Av(q, i,(cid:126)q1, a) are
each greater than 1/3. (There are two cases; consider a∗ =
Ext(v, q, i,(cid:126)q1). Either Av(q, i,(cid:126)q1, a∗) is greater than 1/3, or

over the commit phase,(cid:80)
phase,(cid:80)
such that(cid:80)

Av(q, i,(cid:126)q1, a) and(cid:80)

a∈T1

a∈T2

it is not. If so, then the partition is (a∗, F \ a∗). If not,
then there is still a partition because the sum of the Av(·) is
greater than 1/3.) This implies that, in the binding exper-
iment, R outputs values from the two partitions with prob-
ability > (2/9) · (1)3 = B over all three phases, which
contradicts the deﬁnition of a CFMD protocol.
Now deﬁne Ext(v, q) = Ext(v, q, i∗,(cid:126)q∗), where i∗ and (cid:126)q∗ are
designated (any choice with q in the i∗ position of (cid:126)q∗ will
do). The next claim says that the response to q is indepen-
dent of its position and the other queries.

Claim B.4. Let 3 = 2 + 1. For all (cid:126)q, i, where q is in the
ith position of (cid:126)q, we have that with probability > 1−3 over
the commit phase, either R’s ith output is Ext(v, q), or else
the probability over the decommit phase of outputting ⊥ is
> 1 − 3.

(cid:80)
and(cid:80)

Proof. Assume otherwise. Then there are (cid:126)q, i such that with
probability > 3 over the commit phase, the probability
of outputting something (non-⊥) besides Ext(v, q, i∗,(cid:126)q∗) is
> 3. But with probability > 1 − 1 over the commit phase,
a∈F\Ext(v,q,i,(cid:126)q) Av(q, i,(cid:126)q, a) < 1 (by the partitioning argu-
ment given in the proof of Claim B.3). Thus, with probabil-
ity > 3 − 1 over the commit phase, the probability of out-
putting something (non-⊥) besides Ext(v, q, i∗,(cid:126)q∗) is > 3
a∈F\Ext(v,q,i,(cid:126)q) Av(q, i,(cid:126)q, a) < 1. Thus, with probabil-
ity > 3−1 = 2 over the commit phase, Ext(v, q, i∗,(cid:126)q∗) (cid:54)=
Ext(v, q, i,(cid:126)q) and R has > 3 > 2 probability of outputting
something other than ⊥. This contradicts Claim B.3.

(cid:54)= ˜fv(qi). By the union bound, c < (cid:80)µ

To complete the proof of the lemma, deﬁne ˜fv(q) (cid:44)
Ext(v, q). Consider the probability c, over both phases, that
the output A (cid:54)= (˜fv(q1), . . . , ˜fv(qµ)), i.e., that at least one
(cid:54)=
of ai
˜fv(qi)}. By Claim B.4, Pr{ai (cid:54)= ˜fv(qi)} < 3 + 3, since this
bounds the probability that either of the two phases goes
badly. Thus, c < µ · 2 · 3, as was to be shown.

i=1 Pr{ai

To compute c, we ignore S (the homomorphic encryp-
tion error); i.e., we set B = 1/|F|. We then get c <
√
2000 · (7 3

B) < 214 · 3(cid:112)1/|F|. For |F| = 2128, c < 2−28.

C Batching
Under batching, V submits the same queries to β different
proofs. Below, we sketch the mechanics and then proofs
of correctness. First, we modify Commit+Multidecommit
(Figure 3) to obtain a new protocol, called BatchedCom-
mit+Multidecommit. The changes are as follows:
• P is regarded as holding a linear function π : Fn → Fβ,
so π(q) = (π1(q), . . . , πβ(q)). One can visualize π as an
β × n matrix, each of whose rows is an oracle, πi. Thus,
P returns vectors instead of scalars.

• Commit phase, steps 2 and 3: instead of receiving from
P the scalar Enc(pk, π(r)), V in fact receives a vector
e = (Enc(pk, π1(r)), . . . , Enc(pk, πβ(r))) and decrypts
to get s = (π1(r), . . . , πβ(r)).

• Decommit phase, steps 5 and 6: P returns a1, . . . , aµ, b,
where ai is supposed to equal (π1(qi), . . . , πβ(qi)) and
b is supposed to equal (π1(t), . . . , πβ(t)); V checks that
b = s + α1a1 + ··· + αµaµ.
Second, we modify the compilation in Appendix B as fol-
lows. P(cid:48) creates β linear proof oracles, and V(cid:48) and P(cid:48) run
BatchedCommit+Multidecommit, causing P(cid:48) to commit to a
linear function π : Fn → Fβ. V(cid:48) then submits the µ PCP
queries and receives vectors π(q1), . . . , π(qµ) in response.
Then V(cid:48) runs the PCP veriﬁer on each instance separately
(e.g., for the kth instance, V(cid:48) looks at the kth component
of each of π(q1), . . . , π(qµ)). V(cid:48) thus returns a vector of β
accept or reject outputs. To argue correctness, we use a
theorem analogous to Theorem B.1:
Theorem C.1. Under (P(cid:48), V(cid:48)) as described above, each of
the β instances is an argument protocol with soundness (cid:48) ≤
 + c. (c is deﬁned in Appendix B.)

Proof. (Sketch.) Nearly the same as for Theorem B.1. We
need an analog of Lemma B.2, described below.

This theorem says that if any of the β instances tries to
encode a “proof” for an incorrect output, the probability that
V outputs accept for that instance is bounded by (cid:48). This
makes intuitive sense because if we ﬁx a given instance, the
probabilities should be unaffected by “extra” instances.

To formalize this intuition, we need BatchedCom-
mit+Multidecommit to yield an extractor function for each of
the β instances. To get there, we deﬁne a general protocol:
batch-CFMD. This protocol has a binding property modi-
ﬁed from the one in Deﬁnition B.1. In the new one, R gives
stacked output A = (a1, . . . , aµ) and ˆA = (ˆa1, . . . , ˆaµ). The
entries of A are denoted ak
i ). We
µ) ∈ Fµ or
allow ak
i = ⊥ for all i ∈ [µ]. We now say that S∗ wins if for some
ak
(cid:54)= ˆak
i, j, k, we have qi = ˆqj and ak
j . We
again say that the protocol meets B-Binding if for all E and
efﬁcient S∗, S∗ has less than B probability of winning.

i ∈ {F ∪ ⊥} but require that (ak

1, . . . , ak
j ∈ F but ak

i ; that is, ai = (a1

i , . . . , aβ

i , ˆak

We can show that BatchedCommit+Multidecommit is a
batch-CFMD protocol by rerunning Lemma B.1, nearly un-
modiﬁed. To complete the argument, we can establish an
analog of Lemma B.2. The analog replaces a single extrac-
tor function ˜fv with β functions ˜f 1
v , one per instance.
The analog says that, viewing each instance k separately, we
have with probability > 1− c that either R’s output for that
instance is ⊥ or else ak
v (qi) for all i ∈ [µ]. The proof
is nearly the same as for Lemma B.2; the main difference is
that Ext(·) and Av(·) receive a per-instance parameter k.

v , . . . , ˜f β

i = ˜f k

i

D Tailored PCP for matrix multiplication
This section expands on the tailored PCP construction for
matrix multiplication, introduced in Section 3.6. Recall that
V wants to verify that C equals A · B, where A, B, C ∈ Fm2.
Further recall that V constructs a polynomial P(cid:48)(Z) from
the constraints in Section 3.3, but V drops the degree-1 con-
straints. Loosely speaking, V is justiﬁed in doing so because
(a) V knows what za
i,j should be, namely the values
of A and B; and (b) the resulting circuit test is still likely to
catch an incorrect output C. Further recall that the modiﬁed
PCP encoding is π = π(c)(·) (cid:44) (cid:104)·, A (cid:11) B(cid:105), where x (cid:11) y =
{xi,k · yk,j} for all i, j, k.

i,j and zb

After stating the queries and tests below, we give proofs
of correctness and estimate costs.
• Generate linearity queries: Select q1, q2 ∈R Fm3. Take
q3 ← q1 + q2.
• Generate quadratic correction queries: select q4, q5 ∈R
Fm2 and q7 ∈R Fm3. Take q6 ← (q4 (cid:11) q5 + q7)
• Generate circuit test queries: select q9 ∈R Fm3 and q8 ←
γ(cid:48)
2 + q9. (γ(cid:48)

2 is deﬁned in Section 3.6.)

• Issue queries. Send q1, q2, q3 and q6, . . . , q9 to π, getting

back π(q1), π(q2), π(q3), π(q6), π(q7), π(q8), π(q9).

(cid:80)m

(cid:10)A∗,k, q4∗,k

(cid:11) ·(cid:10)Bk,∗, q5k,∗(cid:11), where M∗,k ∈ Fm de-

• Linearity test: Check that π(q1) + π(q2) = π(q3). If not,
reject.
• Quadratic correction test: Check that π(q6) − π(q7) =
notes the kth column of matrix M, and Mk,∗ ∈ Fm de-
notes the kth row of matrix M. If not, reject.
• Circuit test: Check that π(q8) − π(q9) = −γ0. (γ(cid:48)
deﬁned in Section 3.6.) If so, accept.

0 is

k=1

Lemma D.1 (Completeness). If V is given C = A · B,
if π = π(c) is constructed as above, and if V proceeds as
above, then Pr{V accepts} = 1. The probability is over V’s
random choices.

k=1

2 and γ(cid:48)
2, A (cid:11) B(cid:105) + γ(cid:48)

(cid:10)A∗,k, q4∗,k

deed equals(cid:80)m

2) =
0 are constructed so that if C =
0 = 0.

(cid:11)·(cid:10)Bk,∗, q5k,∗(cid:11). Finally, the cir-

Proof. If π = π(c) is constructed as above, then the lin-
earity test passes because π(c) is a linear function. The
quadratic correction test also passes because π(c)(q6) −
π(c)(q7) = π(c)(q4 (cid:11) q5) = (cid:104)q4 (cid:11) q5, A (cid:11) B(cid:105), which in-
cuit test passes because π(c)(q8) − π(c)(q9) = π(c)(γ(cid:48)
2, A (cid:11) B(cid:105), and γ(cid:48)
(cid:104)γ(cid:48)
A · B, then (cid:104)γ(cid:48)
Lemma D.2 (Soundness). There exists a constant κ < 1
such that if some proof oracle π passes all of the tests above
with probability > κ, then C = A · B.
Proof. Choose δ such that 3δ − 6δ2 > 2/9, and take
9, 2δ + 2/F|, 2δ + 1/|F|}; with δ = 0.1, we
κ > max{ 7
can take any κ > 7/9. We establish soundness by going
through each of the tests in turn. (This is the same proof

ﬂow as in [8] though the details differ for the quadratic cor-
rection test and circuit test.) First, from the given, we have
that Pr{π passes the linearity test} > 7/9. This, together
with our choice of δ, implies (see [12]) that π(c) is δ-close
to some linear function φ(·) (meaning that the fraction of
inputs on which π(c) and φ(·) disagree is < δ). Second,
we also have from the given that the probability of pass-
ing both the quadratic correction test and the linearity test
is > 2δ + 2/|F|, so we can apply the following claim:
Claim D.3. If π(c) is δ-close to some linear function φ(·)
and if Pr{π(c) passes the quadratic correction test} > 2δ +
2/|F|, then φ(·) is exactly (cid:104)·, A (cid:11) B(cid:105).

(cid:80)m
Proof. We begin with notation. Let NA,B(x, y) =
k=1 (cid:104)A∗,k, x∗,k(cid:105) · (cid:104)Bk,∗, yk,∗(cid:105), where x, y ∈ Fm3. We write
the (i, k) element of q4 and the (k, j) element of q5 as q4
ik
and q5
kj respectively. Let φijk refer to the (i, j, k) element of
the vector that corresponds to φ. Let σijk = φijk − Ai,kBk,j.
Finally, let η be the event {φ(q4 (cid:11) q5) = NA,B(q4, q5)}.
(cid:54)=
Now, assume toward a contradiction that φ(·)
(cid:104)·, A (cid:11) B(cid:105). Then ∃i(cid:48), j(cid:48), k(cid:48) such that σi(cid:48)j(cid:48)k(cid:48)
(cid:54)= 0. Let ν be
(cid:54)= 0}. We can write Pr{η} < Pr{η|ν} +
the event {q5
k(cid:48)j(cid:48)
Pr{(cid:113)ν} = Pr{η|ν} + 1/|F|. To get an expression for
Pr{η|ν}, note that if ν occurs, then (q5
k(cid:48)j(cid:48))−1 is deﬁned.
Also, (σi(cid:48)j(cid:48)k(cid:48))−1 is deﬁned, by contrary assumption. Not-
kjσijk = 0}, we have
Pr{η|ν} = Pr{q4
k(cid:48)j(cid:48))−1 ·
kjσijk) · (q5
ikq5
i,j,k\(i(cid:48),j(cid:48),k(cid:48)) q4
i(cid:48)j(cid:48)k(cid:48)} = 1/|F|, since we can regard q4
σ−1
i(cid:48)k(cid:48) as being cho-
sen after the right-hand side of the equality. Thus, Pr{η} <
2/|F|. We now use the given, to derive a contradiction:
2δ + 2/|F| < Pr{π(q6) + π(q7) = NA,B(q4, q5)}
< Pr{φ(q6) + φ(q7) = NA,B(q4, q5)}

ing that η can be written {(cid:80)
i(cid:48)k(cid:48) = −((cid:80)

i,j,k q4

ikq5

+ Pr{π(q6) (cid:54)= φ(q6)} + Pr{π(q7) (cid:54)= φ(q7)}

< Pr{φ(q4 (cid:11) q5) = NA,B(q4, q5)} + 2δ,

so Pr{η} > 2/|F|. Contradiction.

Third, the probability of passing all three tests is > 2δ +
1/|F| (again from the given), so we can apply the following
claim to complete the lemma.
Claim D.4. If π(c)(·) is δ-close to φ(·) = (cid:104)·, A (cid:11) B(cid:105) and if
Pr{π(c) passes the circuit test} > 2δ+1/|F|, then C = A·B.
Proof. Assume toward a contradiction that C (cid:54)= A· B. Then
there exists i(cid:48), j(cid:48) such that Ci(cid:48),j(cid:48)
k=1 Ai(cid:48),kBk,j(cid:48), which
k=1 Ai,j · Bi,j) = 0
i,j vc
with probability ≤ 1/|F| (see Section 2.1). But

implies that P(cid:48)(A, B) (cid:44)(cid:80)

(cid:54)= (cid:80)m
i,j · (Ci,j −(cid:80)m

P(cid:48)(A, B) = (cid:104)γ(cid:48)
= φ(γ(cid:48)

2, A (cid:11) B(cid:105) + γ(cid:48)
2) + γ(cid:48)

0

0

2, γ(cid:48)
(by choice of γ(cid:48)
0)
(by deﬁnition of φ),

so Pr{φ(γ(cid:48)

2) + γ(cid:48)

0 = 0} ≤ 1/|F|. We now use the given:

2δ + 1/|F| < Pr{π(q8) − π(q9) = −γ(cid:48)
0}
< Pr{φ(q8) − φ(q9) = −γ(cid:48)
0}

+ Pr{π(q8) (cid:54)= φ(q8) or π(q9) (cid:54)= φ(q9)}

2) = −γ(cid:48)

< Pr{φ(γ(cid:48)
0 = 0} > 1/|F|, giving a contradiction.

0} + 2δ,

so Pr{φ(γ(cid:48)

2)+γ(cid:48)

We now brieﬂy cover the costs; upper bounds are in Fig-
ure 2. The PCP encoding is m3 work to produce. V con-
structs 8 queries and submits 7 of them to π; this is the
same as the number of queries to π(2) in the baseline PCP
(Appendix A). V requires 2m2 ﬁeld multiplications for the
quadratic correction test plus m2 multiplications in the cir-
cuit test (to construct γ(cid:48)
0), for a total of 3m2 per repetition.
By comparison, the baseline PCP requires 2 operations for
the quadratic correction test and 3m2 for the circuit test.
E Modiﬁcations for ElGamal
Since ElGamal encryption is multiplicatively homomorphic
(rather than additively homomorphic), small modiﬁcations
to Commit+Multidecommit (Figure 3) and the soundness ar-
guments are necessary. Below, we describe these modiﬁca-
tions and establish that the results of Appendix B still hold.
Fix the ElGamal group G, choose a generator g (known to
both parties), and assume for now that |Fp| = |G| (we revisit
this assumption below). Deﬁne the map ψ : Fp → G by x (cid:55)→
gx. The map ψ is a group homomorphism and in fact an iso-
morphism; furthermore, ψ induces a ring structure on G. By
composing ψ with ElGamal encryption, we get an additive
homomorphism: Enc(pk, gx)Enc(pk, gy) = Enc(pk, gx+y).
Of course, the veriﬁer cannot recover x + y explicitly from
gx+y, but this does not matter for Commit+Multidecommit.
Also, given Enc(pk, gx) and a ∈ Fp, the properties of the
ElGamal protocol imply that one can compute Enc(pk, gax).
Thus, given (Enc(pk, gr1), . . . , Enc(pk, grn)), one can com-
pute Enc(pk, gπ((r1,...,rn))), where π is a linear function.

Therefore, we can modify Figure 3 as follows. First, dur-
ing step 1, the veriﬁer componentwise sends Enc(pk, gr)
rather than Enc(pk, r) to the prover. Next, in step 2, the
prover computes Enc(pk, gπ(r)) (without learning gr), as de-
scribed above. Then in step 3, V decrypts to get gs. Finally,
in step 6, the veriﬁer checks that gb = gs+α1a1+···+αµaµ.

We now need to check that Lemma B.1 still holds. Cor-
rectness applies, by inspection. Binding applies because the
semantic security of the encryption scheme can be formu-
lated in terms of A(pk, Enc(pk, gr), r + αq, r + α(cid:48)q) and
because gx = gy if and only if x = y (since ψ is injective).
Note that when |G| > |Fp|, the same approach works, via
modular arithmetic. Speciﬁcally, although ψ is no longer a
group isomorphism, it is injective. Provided that the compu-
tations never overﬂow, i.e., result in values in the exponent
larger than |G|, the protocol remains correct.

