2012 IEEE Symposium on Security and Privacy

Peek-a-Boo, I Still See You:

Why Efﬁcient Trafﬁc Analysis Countermeasures Fail

Kevin P. Dyer∗, Scott E. Coull†, Thomas Ristenpart‡, and Thomas Shrimpton∗

∗Department of Computer Science, Portland State University, Portland, USA. Email: {kdyer, teshrim}@cs.pdx.edu

† RedJack, LLC., Silver Spring, MD, USA Email: scott.coull@redjack.com

‡Department of Computer Sciences, University of Wisconsin-Madison, USA. Email: rist@cs.wisc.edu

Abstract—
We consider the setting of HTTP trafﬁc over encrypted
tunnels, as used to conceal the identity of websites visited
by a user. It is well known that trafﬁc analysis (TA) attacks
can accurately identify the website a user visits despite the
use of encryption, and previous work has looked at speciﬁc
attack/countermeasure pairings. We provide the ﬁrst com-
prehensive analysis of general-purpose TA countermeasures.
We show that nine known countermeasures are vulnerable to
simple attacks that exploit coarse features of trafﬁc (e.g., to-
tal time and bandwidth). The considered countermeasures
include ones like those standardized by TLS, SSH, and
IPsec, and even more complex ones like the trafﬁc morphing
scheme of Wright et al. As just one of our results, we show
that despite the use of trafﬁc morphing, one can use only
total upstream and downstream bandwidth to identify —
with 98% accuracy— which of two websites was visited. One
implication of what we ﬁnd is that, in the context of website
identiﬁcation, it is unlikely that bandwidth-efﬁcient, general-
purpose TA countermeasures can ever provide the type of
security targeted in prior work.

Keywords-trafﬁc analysis countermeasures; privacy; ma-

chine learning; padding; encrypted trafﬁc

I. INTRODUCTION

Internet users increasingly rely on encrypted tunnels to
keep their web browsing activities safe from eavesdrop-
pers. A typical scenario involves a user establishing an
encrypted tunnel to a proxy that then relays all subsequent
HTTP trafﬁc (in both directions) through the tunnel. An-
other is when one browses the web on a wireless network
that uses WPA to encrypt all trafﬁc. In both cases, the
use of encryption should hide the contents of the trafﬁc
and, intuitively, the identity of the destination website(s).
Yet modern encryption does not obfuscate the length of
underlying plaintexts, nor the number of plaintexts that
are encrypted. This information may seem harmless, but
in fact it enables trafﬁc analysis (TA) attacks. Among other
things, TA attacks can reveal the identity of the websites
viewed by the user [1, 9, 10, 15, 19].

One commonly suggested TA countermeasure is to hide
the plaintext length by adding padding prior to encryption.
Padding countermeasures are standardized in TLS, explic-
itly to “frustrate attacks on a protocol that are based on
analysis of the lengths of exchanged messages” [5]. Simi-
lar allowances for padding appear in SSH and IPSec. More
advanced countermeasures, such as trafﬁc morphing [19],

manipulate whole streams of packets in order to precisely
mimic the distribution of another website’s packet lengths.
The seemingly widespread intuition behind these coun-
termeasures is that they patch up the most dangerous side
channel (packet lengths) and so provide good protection
against TA attacks, including website identiﬁcation. Exist-
ing literature might appear to support this intuition. For
example, Liberatore and Levine [10] show that padding
packets to the network MTU (e.g., 1500 bytes) reduces
the accuracy of one of their attacks from 98% to 7%.

Our results strongly challenge this intuition. We perform
the ﬁrst comprehensive analysis of low-level countermea-
sures (e.g., per-packet padding) for the kind of website
identiﬁcation attacks considered by prior work (c.f., [8, 10,
14, 22]): a closed-world setting for privacy sets, in which
the a priori set of possible websites a user might visit is
known to the attacker, coupled with the ability for the
attacker to train and test on trafﬁc traces that are free
of real-world artifacts (e.g., caching effects, interleaved
ﬂows, and user-speciﬁc content). We consider nine distinct
countermeasures, apply them to two large, independent
datasets of website downloads, and pit the resulting ob-
fuscated trafﬁc against a total of seven different attacks.
The results are summarized in Figure 1. What we uncover
is surprisingly bleak:
the countermeasures are effective. We show
None of
that two classiﬁers —a new na¨ıve Bayes classiﬁer called
VNG++ and a support vector machine classiﬁer due to
Panchenko et al. [14]— achieve better than 80% accuracy
in identifying which of k = 128 websites was visited
in a closed-world experiment. (Random guessing achieves
0.7% accuracy.) When k = 2 these classiﬁers achieve over
98% accuracy. This holds for all nine countermeasures
considered,
including ones inspired by the SSH, TLS
and IPSec RFCs, and state-of-the-art ones such as trafﬁc
morphing [21].
Hiding packet lengths is not sufﬁcient. We initiate a study
of classiﬁers that do not directly use ﬁne-grained features
such as individual packet lengths. The VNG++ classiﬁer
just mentioned uses only “coarse” information, including
overall time, total bandwidth, and size of bursts. In fact,
we provide a na¨ıve Bayes classiﬁer that uses only the total
bandwidth for training and testing, yet still achieves greater

© 2012, Kevin P. Dyer. Under license to IEEE.
DOI 10.1109/SP.2012.28

332

Attack

Classiﬁer

Liberatore and Levine [10] (LL)

na¨ıve Bayes (NB)

Herrmann et al. [8] (H)
Panchenko et al. [14] (P)

multinomial na¨ıve Bayes (MNB)
support vector machine (SVM)

Time (TIME)

Bandwidth (BW)

Variable n-gram (VNG)

VNG++

na¨ıve Bayes
na¨ıve Bayes
na¨ıve Bayes
na¨ıve Bayes

Features Considered

Packet lengths
Packet lengths

Packet lengths, Order, Total bytes

Total trace time

Upstream/Downstream total bytes

Bytes in trafﬁc bursts

Total trace time,

Upstream/Downstream total bytes,

Bytes in trafﬁc bursts

k = 2
85%
71%
99%
82%
98%
99%
99%

k = 128

k = 775

25%
3%
82%
9%
41%
69%
80%

8%
0%
63%
3%
18%
54%
61%

Figure 1. Summary of attacks evaluated in our work. The k = 2, k = 128 and k = 775 columns indicate the classiﬁer accuracy for a privacy set
of size k when using the most effective countermeasure for the Herrmann dataset (see Section II).

than 98% accuracy at k = 2 and 41% accuracy at k =
128. This implies that any effective countermeasure must
produce outputs that consume indistinguishable amounts
of bandwidth.

Coarse information is unlikely to be hidden efﬁciently.
Our coarse-feature attacks, in particular the bandwidth-
only attack, strongly suggest that resource-efﬁcient coun-
termeasures will not (on their own) effectively hide website
identity within a small privacy set. So, we investigate
an inefﬁcient strawman countermeasure, Buffered Fixed-
Length Obfuscation (BuFLO, pronounced “buffalo”), that
combines and makes concrete several previous sugges-
tions: it sends packets of a ﬁxed size at ﬁxed intervals,
using dummy packets to both ﬁll
in and (potentially)
extend the transmission. We subject it to the same analysis
as the other countermeasures. This analysis shows that
should BuFLO fail to obfuscate total time duration and
total bandwidth, then attacks still achieve 27% accuracy
at k = 128. With a bandwidth overhead of over 400%, we
can, in theory, ﬁnally reduce k = 128 accuracy to 5%.

Relevance to other settings. While the adversarial model
that we consider is consistent with previous work, we
admit that there are several factors (e.g., caching, open-
world identiﬁcation) that are not captured. Indeed, these
may reduce the effectiveness of the attacks, and improve
countermeasure efﬁcacy, in practice. There may also be
some other settings, such as Voice over IP (VoIP) traf-
ﬁc [18–21], where the nature of the application-layer
protocol enables some countermeasures to work very well.
That said, the model considered in this paper (and its
predecessors) is one that a general-purpose countermeasure
ought to cover.

Finally, our analysis does not cover application-
layer countermeasures
such as Camouﬂage [8] and
HTTPOS [12], which both make intimate use of spurious
HTTP requests to help obfuscate trafﬁc patterns. We
suspect, however, that the lessons learned here might help
direct future analysis of application-layer countermeasures,
as well.

II. EXPERIMENTAL METHODOLOGY

Like previous works [8, 10, 14, 22], our experiments
simulate a closed-world setting in which an adversary has
access to the timing, lengths, and directionality of packets
sent over an encrypted HTTP tunnel (e.g., to or from a
proxy server). We assume secure encryption algorithms are
used and no information can be learned from the encrypted
contents itself.

We base our simulation on two datasets that have been
widely used by previous works on web page identiﬁcation.
The Liberatore and Levine dataset [10] contains times-
tamped traces from 2,000 web pages. The Herrmann et
al. [8] dataset contains timestamped traces from 775 web
pages. A trace is deﬁned as a record of the lengths and
timings of ciphertexts generated by accessing a web page
using an OpenSSH single-hop SOCKS proxy. Please refer
to the previous works [8, 10] for further details about data
collection methodology.

Each of our experiments is performed with respect to
a particular classiﬁer, a particular countermeasure, and a
speciﬁed set of n web pages. An experiment consists of
a number of trials; we will say in a moment how the
particular number of trials is determined. At the start of
each experimental trial, we uniformly select a subset of
k ≤ n web pages to deﬁne the privacy set for that trial.1
Next we establish k sets of 20 traces, one for each web
page, as follows. For every web page in the data set, there
are m > 20 chronologically sorted sample traces. We
select a random trace index i ∈ {0, 1, . . . , m − 19}, and
take traces i, i + 1, . . . , i + 19 for each of the k web
pages. The ﬁrst t = 16 of the traces from each of the k
sets are used as the training data for the classiﬁer, and
the remaining T = 4 traces form the testing data set.2
The countermeasure is applied to both the training and
testing data, and the classiﬁer is trained and then tested to
determine its accuracy. Classiﬁer accuracy is calculated as

1We do not believe the uniform distribution represents typical user
web-browsing behavior. In practice, we expect that biased sampling from
the privacy set would further aid an attacker.
2We considered values of t ∈ {4, 8, 12, 16} and observed effects con-
sistent with those reported by Liberatore and Levine [10]: as t increases
there was a consistent, modest increase in classiﬁcation accuracy.

333

(c/T k), where c is the number of correctly classiﬁed test
traces and k is our privacy set size.

In each experiment, we perform 2(15−log2(k))

so that

there are a total of T · 215

tri-
als,
test data
points per experiment. We consider values of k ∈
{2, 4, 8, 16, 32, 64, 128, 256, 512, 775} in order to capture
countermeasure performance across a number of scenarios.
Intuitively, smaller values of k present easier classiﬁcation
(attack) settings, and larger values of k present more
difﬁcult classiﬁer settings.

We note that the engineering effort required to produce
our results was substantial. To aid future research efforts,
the Python framework used for our experiments is publicly
available3.

III. TRAFFIC CLASSIFIERS

A sequence of works detail a variety of TA attacks, in
the form of classiﬁers that attempt to identify the web
page visited over an encrypted channel. These classiﬁers
use supervised machine learning algorithms, meaning they
are able to train on traces that are labeled with the
destination website. Each algorithm has a training and
a testing phase. During training, the algorithm is given
a set {(X1, (cid:2)1), (X2, (cid:2)2), . . . , (Xn, (cid:2)n)}, where each Xi
is an vector of features and (cid:2)i is a label. During testing
the classiﬁcation algorithm is given a vector Y and must
return a label. In our case, a vector Xi contains information
about the lengths, timings, and direction of packets in the
encrypted connection containing a web page (cid:2)i, and the
format of a vector Xi is dependent upon the classiﬁer.
In the remainder of this section, we present a high-level
overview of the operation of the three published classiﬁers
that we use in our evaluation, and we refer interested
readers to more detailed descriptions elsewhere [8, 10, 13,
14].

A. Liberatore and Levine Classiﬁer

Pr(Y )

Liberatore and Levine [10] (LL) proposed the use of a
na¨ıve Bayes classiﬁer (NB) to identify web pages using
the direction and length of the packets. The na¨ıve Bayes
classiﬁer determines the conditional probability Pr ((cid:2)i|Y )
for a given vector of features Y using Bayes’ rule:
Pr ((cid:2)i|Y ) = Pr(Y |(cid:2)i) Pr((cid:2)i)
. The probability is computed
for all labels (cid:2)i with i = {1, 2, . . . , k} and k representing
the size of the privacy set (or number of labels being
considered), and the label with the highest probability is
selected as the classiﬁer’s guess. The probability Pr (Y |(cid:2)i)
is estimated using kernel density estimation over the ex-
ample feature vector provided during training, and Pr((cid:2)i)
is assumed to be 1/k. The feature vectors used by the LL
classiﬁer are derived from the count of the lengths of the
packets sent in each direction of the encrypted connection.
Speciﬁcally, the feature vector contains 2 · 1449 = 2898
integers that represent the number of packets seen in the

3http://www.kpdyer.com/

334

given vector with each of the potential direction and packet
length combinations (i.e., {↑,↓} × {52, . . . , 1500}). For
example, if we observe a packet of length 1500 in the ↓
direction (e.g., server to client) we would increment the
counter for (↓,1500).
B. Herrmann et al. Classiﬁer

Herrmann, Wendolsky and Fedarrath [8] (H) take a
similar approach to Liberatore and Levine, however they
make use of a multinomial na¨ıve Bayes (MNB) classiﬁer.
Like the na¨ıve Bayes classiﬁer with density estimation,
the multinomial na¨ıve Bayes classiﬁer attempts to estimate
the probability Pr ((cid:2)i|Y ) for each of the i = {1, 2, . . . , k}
potential labels and the given feature vector Y . The key
difference is that the multinomial classiﬁer does not apply
density estimation techniques to determine the probability
Pr (Y |(cid:2)i), but instead uses the aggregated frequency of the
features (i.e., normalized distribution) across all training
vectors. Thus,
the H classiﬁer uses normalized counts
of (direction, length), whereas the LL classiﬁer exam-
ined raw counts. Furthermore, Herrmann et al. suggest a
number of approaches for normalizing these counts. For
our evaluation, we combine term frequency transformation
and cosine normalization, as these were identiﬁed by
Herrmann et al. to be the most effective in the SSH setting.

C. Panchenko et al. Classiﬁer

Panchenko et al. [14] (P) take a completely different
approach by applying a support vector machine (SVM)
classiﬁer to the problem of identifying web pages. A
support vector machine is a type of binary linear clas-
siﬁer that classiﬁes points in a high-dimensional space by
determining their relation to a separating hyperplane. In
particular, the SVM is trained by providing labeled points
and discovering a hyperplane that maximally separates the
two classes of points. Classiﬁcation occurs by determining
where the point in question lies in relation to the splitting
hyperplane. Due to the complexity of SVM classiﬁers, we
forego a detailed discussion of their various parameters
and options.

We conﬁgure our SVM as follows. We use the same
radial basis function (RBF) kernel as Panchenko et al. with
parameters of C = 217 and γ = 2−19. The P classiﬁer
uses a wide variety of coarse and detailed features of
the network data mostly derived from packet lengths and
ordering. Some of these features include the total number
of bytes transmitted, total number of packets transmitted,
proportion of packets in each direction, and raw counts
of packet lengths. There are also several features known
as “markers” that delineate when information ﬂow over
the encrypted connection has changed direction. These
markers aggregate bandwidth and number of packets into
discrete chunks. Each of the features considered by the P
classiﬁer are rounded and all 52 byte TCP acknowledge-
ment packets are removed to minimize noise and variance
in the training and testing vectors.

IV. COUNTERMEASURES

For ease of exposition and analysis, we organize the
considered countermeasures into three categories: those
that are inspired by the padding allowed within the SSH,
TLS and IPSec standards (Type-1); other padding-based
countermeasures (Type-2); and countermeasures that make
explicit use of source and target packet-length distributions
(Type-3). In what follows, we describe the operation of
the countermeasures we evaluate and discuss the overhead
they generate. Lengths are always measured in bytes.
A. Type-1: SSH/TLS/IPSec-Motivated Countermeasures

A common suggestion, already used in some implemen-
tations, like GnuTLS4, is to obfuscate plaintext lengths
by choosing random amounts of extra padding to append
to the plaintext prior to encryption. SSH, TLS and IPSec
allow up to 255 bytes of padding in order to align the to-
be-encrypted plaintext with the underlying block cipher
boundary, and also to provide some obfuscation of the
original plaintext length. We consider two ways in which
this might be implemented within SSH/TLS/IPSec: (1)
choose a single random amount of padding to be applied
across all plaintexts in the session, or (2) choose a random
amount of padding for each plaintext.
Session Random 255 padding: A uniform value r ∈
{0, 8, 16 . . . , 248} is sampled and stored for the session.5
Each packet in the trace has its length ﬁeld increased by r,
up to a maximum of the MTU.

Packet Random 255 padding: Same as Session Random
255 padding, except that a new random padding length r
is sampled for each input packet.

We note that our simulation of Session Random and
Packet Random padding in this setting are not exactly
what would be implemented in reality because we do not
have access to the size of the plaintext data from the
datasets available to us. Instead, our assumption is that the
plaintext data is sufﬁciently short to ﬁt into a single TCP
packet and therefore is closely approximated by simply
adding the padding to the length of the ciphertext. What we
simulate, therefore, is likely to overstate the efﬁcacy of the
countermeasure since the (at most) 255 bytes of padding
would be dominated by the true size of the plaintext (e.g.,
up to 214 bytes for TLS), thereby providing relatively
little noise. In contrast, our simulation allows for a much
larger ratio of plaintext to padding, which in turn adds
signiﬁcantly more noise.
B. Type-2: Other Padding-based Countermeasures

The second class of countermeasure we consider are
those padding mechanisms that are not easily supported in

4http://www.gnu.org/software/gnutls/
5We assume that the underlying encryption block size is 8 bytes. For
the Liberatore and Levine dataset, we know this assumption is true. We
do not expect classiﬁcation accuracies to be different if, in fact, the block
size was 16 bytes.

existing encrypted network protocol standards due to the
amount of padding added. In this scenario, we assume the
countermeasure will be capable of managing fragmentation
and padding of the data before calling the encryption
scheme. Most of the countermeasures considered by prior
work fall into this category, though we also consider a
randomized scheme that has not been previously explored.

Linear padding: All packet lengths are increased to the
nearest multiple of 128, or the MTU, whichever is smaller.

Exponential padding: All packet lengths are increased
to the nearest power of two, or the MTU, whichever is
smaller.

If the packet length is ≤ 128,
Mice-Elephants padding:
then the packet is increased to 128 bytes; otherwise it is
padded to the MTU.

Pad to MTU: All packet lengths are increased to the MTU.

Packet Random MTU padding: Let M be the MTU and (cid:2)
be the input packet length. For each packet, a value r ∈
{0, 8, 16, . . . , M − (cid:2)} is sampled uniformly at random and
the packet length is increased by r.

C. Type-3: Distribution-based Countermeasures

Wright et al. [22] presented two novel suggestions as
improvements upon traditional per-packet padding coun-
termeasures: direct target sampling (DTS) and trafﬁc mor-
phing (TM). On the surface, both techniques have the same
objective. That is, they augment a protocol’s packets by
chopping and padding such that the augmented packets
appear to come from a pre-deﬁned target distribution (i.e.,
a different web page). Ideally, DTS and TM have secu-
rity beneﬁts over traditional per-packet padding strategies
because they do not preserve the underlying protocol’s
number of packets transmitted nor packet lengths. Al-
though the full implementations details of DTS and TM
are beyond scope of this paper (see [22]), we give a high-
level overview here.

Direct target sampling: Given a pair of web pages A
and B, where A is the source and B is the target, we
can derive a probability distribution over their respective
packet lengths, DA and DB. When a packet of length i
is produced for web page A, we sample from the packet
length distribution DB to get a new length i(cid:2). If i(cid:2) > i,
we pad the packet from A to length i(cid:2) and send the
padded packet. Otherwise, we send i(cid:2) bytes of the original
packet and continue sampling from DB until all bytes
of the original packet have been sent. Wright et al. left
unspeciﬁed morphing with respect to packet timings. We
assume a negligible overhead to perform morphing and
specify a 10ms inter-packet delay for dummy packets.

In our experiments, we select the target distribution
uniformly at random from our set of k potential identi-
ties. The selected web page remains unchanged (i.e., no

335

Countermeasure
Session Random 255
Packet Random 255
Linear
Exponential
Mice-Elephants
Pad to MTU
Packet Random MTU
Direct Target Sampling
Trafﬁc Morphing

Overhead (%)
LL
9.0
9.0
4.2
8.7
41.6
81.2
40.1
86.4
60.8

H
7.1
7.1
3.4
10.3
39.3
58.1
28.8
66.5
49.8

Figure 2. Bandwidth overhead of evaluated countermeasures calculated
on Liberatore and Levine (LL) and Herrmann et al. (H) datasets.

countermeasures applied), while the remaining k − 1 web
pages are altered to look like it. After the source web page
has stopped sending packets, the direct target sampling
countermeasure continues to send packets sampled from
DB until the L1 distance between the distribution of sent
packet lengths and DB is less than 0.3.

Trafﬁc morphing: Trafﬁc morphing operates similarly to
direct target sampling except that instead of sampling from
the target distribution directly, we use convex optimization
methods to produce a morphing matrix that ensures we
make the source distribution look like the target while
simultaneously minimizing overhead. Each column in the
matrix is associated with one of the packet lengths in
the source distribution, and that column deﬁnes the target
distribution to sample from when that source packet length
is encountered. As an example, if we receive a source
packet of length i, we ﬁnd the associated column in the
matrix and sample from its distribution to ﬁnd an output
length i(cid:2). One matrix is made for all ordered pairs of source
and target web pages (A, B). The process of padding
and splitting packets occurs exactly as in the direct target
sampling case. Like the direct target sampling method,
once the source web page stops sending packets, dummy
packets are sampled directly from DB until the L1 distance
between the distribution of sent packet lengths and DB
is less than 0.3. In our simulations we select a target
distribution using the same strategy described for DTS.

D. Overhead

Although the focus of our evaluation lies in understand-
ing the security provided by these countermeasures, we
realize that their cost in terms of bandwidth overhead and
latency is an important factor that determines whether they
are applicable in practice or not. To this end, we present
the bandwidth overhead induced by the countermeasures
for both the Liberatore and Levine and Herrmann et al.
datasets in Figure 2. Overhead is calculated as (bytes sent
with countermeasure)/(bytes sent without countermeasure)
times 100. We note that these overhead measurements
differ from those of earlier work because we do not ap-

k = 2

k = 128

Type-1
Type-2
Type-3
Type-1
Type-2
Type-3

H

P

LL
85% 71% 99%
97% 80% 99%
98% 76% 99%
41% 13% 91%
46%
90%
82%
25%

5%
3%

Figure 3. The lowest average accuracy for each countermeasure class
against LL, H, and P classiﬁers using the Hermann dataset. Random
guessing yields 50% (k = 2) or 0.7% (k = 128) accuracy.

ply countermeasures to TCP acknowledgement (52-byte)
packets. For example, Liberatore and Levine [10] report
a Pad to MTU overhead of 145% and Wright et al. [22]
report 156%. We argue that acknowledgement packets
are present regardless of the content being downloaded
and there is no standard mechanism for application-layer
countermeasures to apply padding to TCP acknowledge-
ment (52-byte) packets. Nevertheless, as we will see in the
following section, there is almost no correlation between
overhead and the level of conﬁdentiality provided by the
countermeasure

V. EXISTING COUNTERMEASURES VERSUS

EXISTING CLASSIFIERS

We pit the LL, H, and P classiﬁers from Section III
against trafﬁc simulated as per the nine countermeasures
of the previous section. The testing methodology used was
described in Section II. We also look at classiﬁability of
the raw trafﬁc, meaning when no countermeasure (beyond
the normal SSH encryption) is applied.

We note that despite the appearance of the LL, H, and
P classiﬁers in the literature, all the results we report
are new. In particular, the H and P classiﬁers were never
tested against any of these countermeasures, while the LL
classiﬁer did look at efﬁcacy against Linear , Exponential,
Mice-Elephants, and Pad to MTU but only at k = 1000.
Figure 3 contains a high-level summary for k = 2 and
k = 128. We refer the interested reader to Appendix A for
comprehensive results.

In the rest of this section we analyze the results from
various points of view, including the role of the dataset,
the relative performance of the classiﬁers, and the relative
performance of the different countermeasures.

A. Comparing the Datasets

Before beginning digging into the results in earnest, we
ﬁrst evaluate the consistency and quality of the two avail-
able datasets. We do so to determine the extent to which
results gathered using them represent the identiﬁability
of the web pages rather than artifacts of the collection
process, such as connection timeouts and general collec-
tion failures. In Figure 4, we show the silhouette of the
accuracy achieved by the three classiﬁers across a number
of universe sizes and countermeasures using each of the

336

Figure 4. Comparison of accuracy silhouettes for the Liberatore and Levine and Herrmann datasets across all countermeasures for the LL, H, and P
classiﬁers, respectively.

datasets. That is, the lower boundary of each silhouette
is the best-performing countermeasure while the upper
boundary represents the worst-performing (which turned
out to always be no countermeasure, as one would expect).
Ideally, the classiﬁer accuracies should be roughly sim-
ilar, or at least show similar trends. Instead, what we
notice is a trend toward strong drops in performance as
the web page universe size increases in the Liberatore
dataset, whereas in the Herrmann dataset we see a much
smoother drop across multiple universe sizes and across
all classiﬁers. This is most notable under the P classiﬁer
(far right of Figure 4).

To take a closer look at the differences between the
datasets, we report some basic statistics in Figure 5. The
fraction of traces that have short duration, particularly ones
that are clearly degenerate (≤ 10 packets), is much higher
in the Liberatore dataset. Such degenerate traces act as
noise that leads to classiﬁcation errors. We suspect that
they arise in the dataset due to collection errors (e.g.,
incomplete website visits), and may imply that some pre-
vious works [10, 22] may underestimate the privacy threat
posed by web page trafﬁc analysis attacks. Despite the
extra noise, the classiﬁers performed well, just consistently
lower at high values of k as compared to the Herrmann
dataset. In addition, the Herrmann dataset was collected
in 2009, as opposed to the Liberatore dataset, which
was collected in 2006. Despite all these differences we
found the high-level trends and conclusions are the same
across both datasets. For these reasons, we will focus our
analysis only on the Herrmann dataset for the remainder
of this paper. Appendix A contains details for classiﬁer
performance using the Liberatore dataset at k = 128.

B. Comparison of Classiﬁers

Figure 6 gives a three-by-three grid of graphs: one
column per classiﬁer and one row for countermeasure type.
We start by quickly comparing the relative performance of
the three classiﬁers, which is observable by comparing the
performance across the three columns.

The ﬁrst thing to notice is that at k = 2, essentially all of
the classiﬁers do well against all of the countermeasures.

Traces with 0 packets in one direction
Traces with ≤ 5 bidirectional packets
Traces with ≤ 10 bidirectional packets
Traces with ≤ 1s duration
Median trace duration
Median bidirectional packet count
Median bandwidth utilization (bytes)

LL
3.1%
5.2%
13.8%
29.4%
2.4 sec.

106

H

0.1%
0.2%
0.4%
6.4%
3.6 sec.

256

78,382

235,687

Figure 5. Statistics illustrating the presence of degenerate or erroneous
traces in the Liberatore and Levine and Hermann datasets.

The LL and P classiﬁers are particularly strong, even
against the DTS and TM countermeasures. The overall best
classiﬁer is clearly the P classiﬁer. It is robust to all the
countermeasures. The H classiﬁer edges out both the P and
LL classiﬁers for raw trafﬁc, but is very fragile in the face
of all but the simplest countermeasure (Linear padding).
The LL classiﬁer proves more robust than the H classiﬁer,
but has more severe accuracy degradation compared to P
as k increases.

C. Comparison of Countermeasures

Consider the ﬁrst row of Figure 6, where we see a com-
parison of the two Type-1 randomized padding schemes.
Curiously, it is better to pick a single random padding
amount to apply to each packet within a trace than to
pick fresh random amounts per packet. Applying a single
random amount across all packets shifts the distribution
of packet lengths in a way that is unlikely to have been
seen during training. On the other hand, randomizing per
packet “averages out” during training and testing.

Common intuition about the Pad to MTU countermea-
sure is that it ought to work well against TA attacks since
it ensures that no individual packet length information is
leaked. However, as we seen in the second row of Figure 6,
we see this intuition is wrong in large part because the
number of packets is still leaked. The LL classiﬁer, for
example, exploits this fact, since it trains on the number
of packets of each (direction, length). When the packets are
padded to the MTU, there are only two numbers, namely
for (↑,1500) and (↓,1500). The LL classiﬁer does well

337

Figure 6. Average accuracy as k varies for the LL (left column), H (middle column), and P (right column) classiﬁers with respect to the Type-1 (top
row), Type-2 (middle row), and Type-3 (bottom row) countermeasures. The dotted gray line in each graph represents a random-guess adversary.

because the number of packets transmitted is relatively
consistent across traces for a particular web page. (We
will investigate this more in the next section.) This also is
our ﬁrst evidence that exact packet-length information is
not necessary for high-accuracy classiﬁcation.

Next, we turn to the Type-3 countermeasures. Recall
that these countermeasures focus on altering a speciﬁc
feature of the web page trafﬁc, namely the distribution
of normalized counts, so that one web page looks like
another with respect to that feature. In theory then, the
distribution of packets produced by the DTS and TM
countermeasures should match that of the target web
page and, unlike Type-1 and Type-2 countermeasures, the
number of packets from the source web page should be
concealed, in part. This is not true in all cases, however,
as Type-3 countermeasures do not substantially change the
total bandwidth of data transmitted in each direction, nor
the duration of the trace with regards to time. In fact, no
countermeasure considered here substantially changes the
total bandwidth. Moreover, these countermeasures do not

hide “burstiness” of the data, which may be correlated
to higher level structure of the underlying HTTP trafﬁc
(e.g., a downstream burst represents a web page object).
Therefore, DTS and TM perform best against the H clas-
siﬁer, which examines the same normalized packet count
distribution, while the P classiﬁer performs particularly
well with its use of packet burst information.

We compare the best countermeasure from each type
in Figure 7: Session Random 255 (Type-1), Pad to MTU
(Type-2), and DTS (Type-3). A few surprises arise in this
comparison. First, Session Random 255 performs better
or about the same as Pad to MTU. This is surprising,
as Session Random 255 is a signiﬁcantly lighter-weight
countermeasure. It has only 7% overhead compared to
Pad to MTU’s 58%, and can potentially be dropped into
existing deployments of SSH and TLS. That said, even at
k = 128, it is unlikely to be satisfying to drop accuracy
only down to 90%. DTS does better than the others across
all values of k against the best classiﬁer (P), but we note
that simpler countermeasures actually can do a better job

338

Figure 7. Comparison of the overall best performing countermeasure of each type against the LL, H, and P classiﬁers.

against the LL and H classiﬁers for lower k values.

VI. EXPLORING COARSE FEATURES

Our study of existing classiﬁers reveals that some ﬁne-
grained features, such as individual packet lengths, are not
required for high-accuracy classiﬁcation. Indeed, the fact
that the P classiﬁer performs so well against the Pad to
MTU countermeasure means that it is using features other
than individual packet lengths to determine classiﬁcation.
This leads us to the following question: Are coarse trafﬁc
features sufﬁcient for high-accuracy classiﬁcation?

total

transmission time,

To answer this question, we explore three coarse fea-
tures:
total per-direction band-
width, and trafﬁc “burstiness”.6 From these features we
build the time (TIME), bandwidth (BW), and the variable
n-gram (VNG) classiﬁer using na¨ıve Bayes as our underly-
ing machine learning algorithm. See Figure 9 for a visual
summary of their performance. Later, we put these three
coarse features together, and build the VNG++ na¨ıve Bayes
classiﬁer. We will see that VNG++ is just as accurate as
the (more complex) P classiﬁer.

A. Total Time

We begin with the most coarse and intuitively least
useful feature, the total timespan of a trace. How much
do traces differ based on total time? The left-most plot in
Figure 8 depicts the time of the ﬁrst 50 traces from ﬁve
websites in the Herrmann dataset. There is clear regularity
within traces from each website, suggesting relatively low
variance for this feature.

To test the usefulness of total time in classiﬁcation, we
implemented a na¨ıve Bayes classiﬁer that uses time as
its only feature. This simple time-only classiﬁer is quite
successful for small k, as shown in Figure 9. At k = 2, it
is able to achieve better than an 80% average accuracy
against the three best countermeasures from each class
as determined by performance on the P classiﬁer. As the
privacy set increases, the likelihood of multiple websites
having similar timing increases, and so the accuracy of

6We note that these features are more coarse than individual packet
lengths, in the sense that knowing the latter likely implies knowing the
former, but not the other way around.

339

the time classiﬁer goes down. At k = 775, it achieves
only about 3% accuracy, although this is still substantially
better than random guessing (0.1%) and may provide value
as a supplementary feature in order to increase a classiﬁer’s
accuracy.

Figure 9 also shows that the time classiﬁer performs
roughly the same against raw trafﬁc (i.e., the “None” coun-
termeasure) and with trafﬁc countermeasures applied. As
one might expect padding-based countermeasures (Type-1
and Type-2), do not directly modify the total time taken
by traces. On the other hand, distribution-based counter-
measures (Type-3) potentially inject dummy packets into
a trace, but this is most often no more than 10-12 packets
sent in quick succession. Thus, these also do not change
the total time signiﬁcantly.

B. Total Per-Direction Bandwidth

Next, we turn to total bandwidth consumed per di-
rection. We see the consistency of total bandwidth in
the center plot in Figure 8, which displays the upstream
and downstream bandwidths of the ﬁrst 50 traces of ﬁve
websites from the Herrmann dataset. This plot shows a
clear clustering of the websites with both very low variance
within website clusters and high degrees of separability
(i.e., spacing) between clusters.

Therefore, we expect bandwidth-based classiﬁcation
will work well as long as websites within the privacy
set do not have too much overlap in terms of total
per-direction bandwidth. Figure 9 shows that, indeed, the
bandwidth classiﬁer performs well. In fact, the real surprise
is just how well the bandwidth-only classiﬁer works for all
privacy set sizes despite the coarse nature of the feature. At
k = 2, the classiﬁer provides close to perfect accuracy of
over 99% against all countermeasures. Moreover, compare
the behavior of the bandwidth-only classiﬁer to that of the
LL and H classiﬁers (c.f., Figure 7), which do not use
bandwidth as a feature, as k increases. The bandwidth clas-
siﬁer is clearly more robust to changes in privacy set size.
This might seem surprising, since countermeasures such as
Pad to MTU and Session Random 255 should, intuitively,
obfuscate bandwidth usage. They do, but these per-packet
paddings only add noise to the low order bits of total

Figure 8. Each scatterplot is a visual representation of the ﬁrst ﬁfty traces, from the ﬁrst ﬁve websites in the Herrmann dataset. Each symbol of the
same shape and color represents the same web page. (left) Distribution of traces with respect to duration in seconds. (middle) Distribution of traces
with respect to bandwidth utilization, where we distinguish the upstream and downstream directions. (right) Distribution of traces with respect to the
number of bursts per trace.

bandwidth. Speciﬁcally, the change to bandwidth usage is
too small relative to what would be needed to make two
websites’ bandwidths likely to overlap signiﬁcantly. This is
true for all of the padding-based countermeasures (Type-1
and Type-2). Distribution-based countermeasures DTS and
TM, however, offer the best resistance to the bandwidth
classiﬁer for higher k values. Here, they outpace other
countermeasures by several percentage points. This seems
to be due to the insertion of dummy packets, which can add
more noise than per-packet padding for total bandwidth
use.

C. Variable n-gram

The time and bandwidth features already provide im-
pressive classiﬁcation ability despite their coarse nature,
but do not yet give the accuracy that
the Panchenko
classiﬁer achieves. We therefore look at a third feature,
that of burst bandwidth. A burst is a sequence of non-
acknowledgement packets sent in one direction that lie
between two packets sent in the opposite direction. The
bandwidth of a burst
is the total size of all packets
contained in the burst, in bytes. For instance, if we have
a trace of the form

(↑, 100), (↓, 1500), (↓, 100), (↑, 200), (↑, 300)

then there are three bursts with bandwidth 100, 1600, and
500. The intuition underlying this is that bursts correlate
with higher-level properties of the trafﬁc, such as indi-
vidual web requests. This observation was ﬁrst made by
Panchenko et al. [14].

The right-most plot in Figure 8 shows the number of
bursts for each of the ﬁrst 50 traces for ﬁve websites in
the Herrmann dataset. Even the number of bursts correlates
strongly with the web page visited. Although this relatively
limited information is capable of providing some classiﬁ-
cation ability, it turns out that burst bandwidths prove even
more powerful.

Recalling that an n-gram model would coalesce n
packets together into one feature, we can view bandwidth

bursts as a variable n-gram model in which n varies across
the trace. Then, our VNG (Variable n-Gram) classiﬁer par-
titions a trace into bursts, coalesces packets into variable
n-grams described by (direction, size) pairs, rounds the
resulting sizes up to the nearest multiple of 600 bytes7,
and then applies a na¨ıve Bayes classiﬁer. Figure 9 shows
how well the VNG classiﬁer performs, already achieving
better than 80% accuracy for all padding-based coun-
termeasures, and achieving signiﬁcantly higher accuracy
levels for distribution-based approaches than any other
classiﬁer except the P classiﬁer.

D. Combining Coarse Features: the VNG++ Classiﬁer

To extract all potential

identifying information from
these coarse features, we combine the time, bandwidth,
and variable n-gram classiﬁers to give a simple, yet
impressively effective, classiﬁer that dispenses with use
of individual packet lengths for classiﬁcation. Speciﬁcally,
we use total time, bandwidth in each direction of the con-
nection, and variable n-grams as features of a na¨ıve Bayes
classiﬁer. A graph of the VNG++ classiﬁer’s accuracy as
k varies is given in Figure 11.

In comparing VNG++ to the P classiﬁer, we note that the
latter uses a large assortment of features (as discussed in
Section III), including ﬁne-grained ones such as frequency
of individual packet lengths. It also applies a more compli-
cated machine learning algorithm in the form of an SVM.
Figure 11 depicts the performance of the P and VNG++
classiﬁers against the best performing countermeasures of
each type, as well as data with no countermeasure applied.
Note that for clarity the y-axis starts at 50%, unlike
other graphs. From this ﬁgure,
two clear trends arise.
First, VNG++’s performance against no countermeasure
degrades slightly faster with k than the P classiﬁer. This
highlights that ﬁne-grained features can provide some
small beneﬁt in classifying unprotected traces. Second,

7Panchenko et al. experimentally determine this rounding value as a

way to maximize classiﬁcation accuracy via dimensionality reduction.

340

Figure 9. The average accuracy against the raw encrypted trafﬁc (None), and the best countermeasures from each type, as established in Section V.
(left) the time-only classiﬁer. (middle) the bandwidth only classiﬁer. (right) the VNG (“burstiness”) classiﬁer.

Countermeasure
None
Session Random 255
Packet Random 255
Linear
Exponential
Mice-Elephants
Pad to MTU
Packet Random MTU
Direct Target Sampling
Trafﬁc Morphing

P

97.2 ± 0.2
90.6 ± 0.3
94.9 ± 0.3
96.8 ± 0.2
96.6 ± 0.3
94.5 ± 0.6
89.8 ± 0.4
92.1 ± 0.3
81.8 ± 0.5
88.7 ± 0.4

Classiﬁer

P-NB

98.2 ± 0.9
59.1 ± 2.3
93.7 ± 1.6
96.9 ± 1.1
97.4 ± 0.9
95.1 ± 0.8
91.7 ± 1.5
84.1 ± 1.7
76.8 ± 2.5
82.6 ± 5.6

VNG++
93.9 ± 0.3
91.6 ± 0.3
93.5 ± 0.3
94.3 ± 0.3
94.8 ± 0.3
91.7 ± 0.4
88.2 ± 0.4
87.6 ± 0.3
80.2 ± 0.5
85.6 ± 0.7

Figure 10. Accuracies (%) of P, P-NB, and VNG++ classiﬁers at k =
128.

when we consider countermeasures, VNG++ matches P in
performance. This holds despite the use of fewer features
and the simpler machine learning algorithm used by the
former. As it turns out, in the face of countermeasures,
the coarse features are the damaging ones and ﬁne-grained
features are not particularly helpful.

A ﬁnal question lingers: does using an SVM provide any
advantage over a na¨ıve Bayes classiﬁer? We implemented a
na¨ıve Bayes version of the P classiﬁer. This P-NB classiﬁer
uses a 1-1 mapping of the features used by P to analogues
suitable for use with a na¨ıve Bayes classiﬁer. A comparison
of performance at k = 128 for P, P-NB, and VNG++ are
given in Figure 10. Overall, we see that the results are
consistent across all three classiﬁers. A single exception
is the accuracy of P-NB for Session Random 255, which
results in a surprisingly low classiﬁer accuracy.

E. Discussion

The nine countermeasures considered so far attempt to
obfuscate leaked features of the trafﬁc via padding and
insertion of dummy packets. As we’ve seen, however,
these fail
to protect signiﬁcant amounts of identifying
information from being leaked from coarse features of
the encrypted trafﬁc, rather than the ﬁne-grained, per-
packet features typically targeted by TA countermeasures.

Unfortunately, these kinds of features are precisely the
ones that are most difﬁcult to efﬁciently hide.

Obfuscating total bandwidth is an obvious case in point.
To prevent this feature from leaking information, a coun-
termeasure must ensure a similar amount of bandwidth
use across all websites in any given privacy set. Since we
do not want to forego functionality (e.g., shutting down
connections prematurely), this translates into a counter-
measure that inserts dummy trafﬁc until we achieve a total
bandwidth close to that of the maximum bandwidth usage
of any website in the privacy set.

Hiding burst bandwidth is also problematic. As seen
in Figure 8, different websites can have quite different
patterns of bursts. A countermeasure must smooth out
these patterns. In theory, a trafﬁc morphing-like coun-
termeasure can attempt to imitate a target trace’s burst
patterns, however this will require buffering packets for
potentially long periods of time. Thus, countermeasures
for preventing website trafﬁc analysis must incur both
bandwidth and latency overheads.

In all, our analyses leaves little wiggle room for coun-
termeasures to operate within. Providing robust protection
against ﬁngerprinting attacks for arbitrary websites in a
closed-world setting, such as the one presented here, is
going to have to be inefﬁcient.

VII. BuFLO: BUFFERED FIXED-LENGTH OBFUSCATOR
Our analysis thus far leaves us with the conclusion that,
despite the long line of work on TA attacks and counter-
measures, we have no packet-oriented countermeasure that
prevents website ﬁngerprinting attacks. We therefore want
to know whether any measure can work, even prohibitively
inefﬁcient ones.

Following the analysis of the last section, we know
that any effective countermeasure must hide the total time,
bandwidth use, and burst patterns. To that end, we consider
a new countermeasure Buffered Fixed-Length Obfuscator,
or BuFLO. It is a realization of the “fool-proof” folk-
lore countermeasure that, intuitively, should defeat any
TA classiﬁer by removing all side-channel information.
BuFLO operate by sending ﬁxed-length packets at a ﬁxed

341

Figure 11. Accuracy of P (left) and VNG++ (right) classiﬁers against the best-performing countermeasures from Section III.

interval for at least a ﬁxed amount of time. If a ﬂow goes
longer than the ﬁxed time out, BuFLO lets it conclude
while still using ﬁxed-length packets at a ﬁxed interval.
In an ideal implementation, BuFLO will not leak packet
lengths or packet timings, and so BuFLO should do a good
job at closing side-channels that enable TA classiﬁers.
This type of countermeasure has been investigated in the
context of other TA attacks, such as those on anonymity
networks [17, 23]

Our simulation-based analysis of BuFLO provides some
positive evidence for packet-level countermeasures, but in
fact our results here are mostly negative, thereby reinforc-
ing the lessons learned in prior sections. BuFLO is, as one
might expect, incredibly inefﬁcient. Moreover, we will see
that even mild attempts to claw back some efﬁciency can
fail: setting the minimum session too aggressively short
opens up vulnerability to our coarse-feature classiﬁers.

A. BuFLO Description

A BuFLO implementation is governed by three integer

parameters d, ρ and τ:

• Parameter d determines the size of our ﬁxed-length

packets.

• Parameter ρ determines the rate or frequency (in

milliseconds) at which we send packets.

• Parameter τ determines the minimum amount of time

(in milliseconds) for which we must send packets.

A BuFLO implementation at the start of communications
will send a packet of length d every ρ milliseconds until
communications cease and at least τ milliseconds of time
have elapsed. Speciﬁcally, data is buffered into discrete
chunks, and these chunks are sent as quickly as possible
via the steady ﬂow of the ﬁxed-length packets. When
no data is in the buffer, dummy data is sent
instead.
This assumes that the application-layer signals the start
and end of communication. Alternatively, we could have
chosen τ as an upper bound on the duration of our
communications session and forcibly close the connection
even if communications are still in progress. This would
disable any websites that take longer to load, making it
unlikely to be a pragmatic choice.

B. Experiments

the very least difﬁcult

In this section, we examine BuFLO for various pa-
rameters using the Hermann dataset and provide detailed
results in Figure 12. Since we are using a simulation-based
experiment, these results reﬂect an ideal implementation
that assumes the feasibility of implementing ﬁxed packet
timing intervals. This is at
in
practice [7] and clearly impossible for some values of
ρ. Simulation also ignores the complexities of cross-layer
communication in the network stack, and the ability for
the BuFLO implementation to recognize the beginning
and end of a data ﬂow. If BuFLO cannot work in this
setting, then it is unlikely to work elsewhere, aiding us in
our exploration of the goal of understanding the limits of
packet-level countermeasures.
We evaluated BuFLO empirically with parameters in
the ranges of τ ∈ {0, 10000}, ρ ∈ {20, 40} and d ∈
{1000, 1500}. The least bandwidth-intensive conﬁgura-
tion, at τ = 0, ρ = 40 and d = 1000 would require at
least 0.2 Mbps of continuous synchronous client-server
bandwidth to operate8. Surprisingly, with this BuFLO
conﬁguration and a privacy set size of k = 128, the P
classiﬁer still identiﬁes sites with an average accuracy of
27.3%. This is compared to 97.5% average accuracy with
no countermeasure applied. At the other extreme of our
experiments with τ = 10000, ρ = 20 and d = 1500 it
would require at least 0.6 Mbps of synchronous client-
server bandwidth to operate. Here, the P classiﬁer can still
identify sites with a privacy set size of k = 128 with an
average 5.1% accuracy.

C. Observations about BuFLO
leak packet

BuFLO cannot

lengths, nor can it

leak
packet timings. Yet, our experiments indicate that an ag-
gressively conﬁgured BuFLO implementation can still leak
information about transmitted contents. This is possible
because BuFLO can leak total bytes transmitted and the
time required to transmit a trace in two circumstances:

(cid:2)

1000

ρ

(cid:3)

(cid:2)

·

(cid:3)

.

8d
106

8Calculated by

342

Parameters
BuFLO (τ=0, ρ=40, d=1000)
BuFLO (τ=0, ρ=40, d=1500)
BuFLO (τ=0, ρ=20, d=1000)
BuFLO (τ=0, ρ=20, d=1500)
BuFLO (τ=10000, ρ=40, d=1000)
BuFLO (τ=10000, ρ=40, d=1500)
BuFLO (τ=10000, ρ=20, d=1000)
BuFLO (τ=10000, ρ=20, d=1500)

Overhead

Bandwidth (%)

Latency (s)

93.5
120.0
140.5
201.3
129.2
197.5
364.5
418.8

6.0
3.6
2.4
1.2
6.0
3.6
2.4
1.2

Classiﬁer Accuracy (%)

LL

18.4 ± 2.9
16.2 ± 1.6
16.3 ± 1.2
13.0 ± 0.8
12.7 ± 0.9
8.9 ± 1.0
5.4 ± 0.8
4.4 ± 0.2

H

0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0
0.8 ± 0.0

P

27.3 ± 1.8
23.3 ± 3.3
20.9 ± 1.6
24.1 ± 1.8
14.1 ± 0.9
9.4 ± 1.3
7.3 ± 1.0
5.1 ± 0.7

VNG++
22.0 ± 2.1
18.3 ± 1.0
15.6 ± 1.2
18.4 ± 0.9
12.5 ± 0.8
8.2 ± 0.8
5.9 ± 1.0
4.1 ± 0.8

P-NB

21.4 ± 1.0
18.8 ± 1.4
17.9 ± 1.7
18.7 ± 1.0
13.2 ± 0.7
9.3 ± 1.3
6.8 ± 0.9
5.3 ± 0.5

Figure 12. Overhead and accuracy results for the BuFLO countermeasure at k = 128.

• The data source continued to produce data beyond the

threshold τ.

• The data source ceases to produce data by the thresh-
old τ, but there is still data in the buffer at time τ.
The ﬁrst situation can occur if our our threshold τ is not
sufﬁciently large to accommodate for all web pages that we
may visit. The latter situation occurs when values ρ and d
are not sufﬁciently conﬁgured to handle our application’s
data throughput, such that we transmit all data by time τ.
What is more, in some circumstances an inappropriately
conﬁgured BuFLO implementation can can actually beneﬁt
an adversary. At k = 128 with τ = 0, ρ = 40
and d = 1000 (see Figure 12) the BuFLO countermeasure
can increase the accuracy of the Time classiﬁer from 9.9%
to 27.3%! In retrospect this is not surprising. If we throttle
the bandwidth of the web page transfer, we will amplify
its timing ﬁngerprint.

These results reinforce the observations of prior sec-
tions. Namely, that TA countermeasures must, in the con-
text of website identiﬁcation, prevent coarse features from
being leaked. As soon as these features leak, adversaries
will gain some advantage in picking out web pages.

VIII. RELATED WORK

Trafﬁc analysis of encrypted data has been studied ex-
tensively. Our focus is on identiﬁcation (or ﬁngerprinting)
of web pages within encrypted tunnels, and we do not
discuss other contexts, such as analysis of encrypted VoIP
trafﬁc [18–21] or revelation of web page contents [2, 3].
Even so, there is a signiﬁcant amount of literature focused
on website identiﬁcation, including a wide diversity of
evaluation methodologies, attacks, and countermeasures.
To the best of our knowledge, the ﬁrst academic dis-
cussion of TA attacks in this context was by Wagner and
Schneier [16]. They relayed an observation of Yee that
SSL might leak the URL of an HTTP get request because
ciphertexts leak plaintext
length. Wagner and Schneier
suggested that per-ciphertext random padding should be
included for all cipher modes of SSL.

Cheng and Avnur [4] provided some of the ﬁrst ex-
perimental evidence of web page ﬁngerprinting attacks
by analyzing pages hosted within one of three websites.
Their attack assumes perfect knowledge of HTML and web

343

page object sizes, which is not always precisely inferred
from ciphertexts. They also suggested countermeasures
including padding of HTML documents, Pad to MTU, and
introduction of spurious HTTP requests. They evaluated
the ﬁrst two in the context of their attack, and claim some
efﬁcacy for the considered websites.

Sun et al. [15] investigated a similar setting, in which
the adversary can precisely uncover the size of individual
HTTP objects in a non-pipelined, encrypted HTTP connec-
tion. They provided a thorough evaluation utilizing a cor-
pus of 100,000 websites. They described a classiﬁer based
on the Jaccard coefﬁcient similarity metric and a simple
thresholding scheme. It was successful against raw trafﬁc,
and while we did not implement their attack, several of the
classiﬁers we consider are likely to outperform it. They
also explored numerous countermeasures, including per-
packet padding, byte-range requests, client-based prefetch-
ing, server-based pushing of content, content negotiation,
web ad blockers, pipelining, and using multiple browsers
in parallel. Their evaluation of the countermeasures only
considered their attack, and the results indicate that the
countermeasures provide improved TA resistance to it.

Hintz [9] discussed a simple attack for identifying which
of ﬁve popular web pages was visited over a single-hop
proxy service called SafeWeb. The proposed attack does
not require exact knowledge of web request sizes, but there
is little evaluation and it remains unclear how the attack
would fair with larger privacy sets.

Bissias et al. [1] demonstrated a weaker adversary than
that of Sun et al. [15], which could observe an SSH tunnel
and view only the length, direction, and timing of each
ciphertext transmitted, rather than web page objects. They
used cross-correlation to determine webpage similarity,
which is a metric commonly used for evaluating the simi-
larity of two time series. They achieved worse performance
than the classiﬁers we consider, and they did not explore
any countermeasures.

Liberatore and Levine [10] showed that it is possible
to infer the contents of an HTTP transaction encapsulated
in an SSH connection by observing only encrypted packet
lengths and the directions of unordered packets. We pro-
vided a detailed description of their classiﬁer in section III,
and we use their publicly-available dataset in our analy-

ses. They quantify the ability of several countermeasures,
including Linear, Exponential, Mice-Elephants, and Pad to
MTU padding schemes, to protect against their attack, but
only report on a privacy set size of k = 1000. These results
cast a positive light on some padding approaches, like Pad
to MTU, which reduces the accuracy of their proposed
classiﬁer from 68% to around 7%. We did not consider
k = 1000 in order to ensure consistency with other datasets
in our evaluation, but projecting out from the observed
trends we expect that, for example, the VNG++ classiﬁer
will do signiﬁcantly better than 7% at k = 1000 (c.f.,
Figure 9).

Herrmann et al. [8] collected encrypted traces from four
different types of single-hop encryption technologies, and
two multi-hop anonymity networks. We use a portion of
their dataset for our analyses. They were the ﬁrst to suggest
the use of a multinomial na¨ıve Bayes classiﬁer for trafﬁc
classiﬁcation that examines normalized packet counts. A
discussion of their classiﬁer was given in Section III.
Their evaluation of countermeasures was restricted to
application-layer countermeasures.

Both Panchenko et al. [14] and Luo et al. [12] suggest
concrete application-layer countermeasures. Panchenko et
al. propose the Camouﬂage countermeasure, which makes
spurious HTTP requests in parallel with legitimate ones,
and show that it renders their classiﬁer signiﬁcantly less
effective. The Luo et al. system is called HTTPOS and uses
a number of client-side mechanisms that take advantage of
existing HTTP functionality to add noise to encrypted web
trafﬁc. For example, HTTPOS randomizes HTTP GET re-
quests by adding superﬂuous data to headers and utilizing
HTTP byte range functionality to request subsets of data

Panchenko et al. [14] presented a support vector ma-
chine classiﬁer as an improvement upon the work of
Herrmann et al. [8]. We discussed details of the Panchenko
classiﬁer in Section III. They apply it to Tor [6] trafﬁc
they generated in both a closed-word and open-world
setting, showing good accuracy, though worse than those
that the classiﬁers we consider achieve. Tor’s encryption
mechanisms already obfuscate some information about
plaintext lengths, making it harder, in general, to classify.
They did not report on their classiﬁer’s efﬁcacy against the
countermeasures we consider.

In an effort to minimize overhead incurred by previously
suggested padding schemes, Wright et al. proposed the
notion of trafﬁc morphing [22]. Their countermeasures
can minimize overhead while still making one web page
“look” like another with respect to speciﬁc features. As
Wright et al. suggested [22, Section 4.1], and Lu et al. later
conﬁrmed with their experimental evaluation [11], trafﬁc
morphing is only effective when the attacker restricts
attention to the same feature(s) targeted by the morphing
routine. Our results likewise indicate that attackers can still
succeed even when trafﬁc morphing is used to ensure the
normalized distribution of packet sizes is similar to some
target web page.

non-sequentially. They evaluate their countermeasure in
the presence of four existing classiﬁers [1, 3, 10, 15] and
show that HTTPOS is effective against all of them. We do
not consider these kinds of application-layer mechanisms,
and indeed our results suggest that such countermeasures
may be better positioned to defend against web page
identiﬁcation attacks.

IX. CONCLUDING DISCUSSION

Although a signiﬁcant amount of previous work has
investigated the topic of TA countermeasures, and speciﬁ-
cally the case of preventing website identiﬁcation attacks,
the results were largely incomparable due to differing
experimental methodology and datasets. Our work syn-
thesizes and expands upon previous ones, and it provides
sharper answers to some of the area’s central questions:
Do TA countermeasures prevent website ﬁngerprinting?
None of the nine countermeasures considered here pre-
vents the kind of website ﬁngerprinting attack addressed
by prior works [8, 10, 14, 22]. From a security perspective
this setting is conservative, and makes several simplifying
assumptions. (The attacker knows the privacy set; it trains
and tests on trafﬁc generated in the same way; the collected
trafﬁc does not account for (potentially) confounding ef-
fects, such as browser caching, interleaved web requests,
etc.) Nevertheless, our negative results suggest that one
should not rely solely upon these countermeasures to
prevent website ﬁngerprinting attacks.
Do TA attacks require individual packet lengths? No. We
implemented three coarse-feature classiﬁers: one using
only total time as a feature, one using only total per-
direction bandwidth, and one tracking only data bursts
(the VNG classiﬁer). These did not make direct use of
individual packet lengths or packet counts as features, yet
attained high accuracy against the countermeasures. This
highlights the point that masking ﬁne-grained information
is insufﬁcient, unless such masking also hides telling large-
scale features (e.g., individual object requests, size of web
objects, etc.).
Does classiﬁcation engine matter? Our experiments sug-
gest it is the features, and not the underlying classiﬁcation
engine, that matters. We implemented a na¨ıve Bayes-based
classiﬁer that used the same features as those exploited by
the SVM-based Panchenko et al. classiﬁer, and our exper-
iments show that these two perform almost identically.
Does the privacy-set size (k) matter? For the considered
setting, it seems not to matter much. When no countermea-
sure is used, attacks can achieve roughly the same accuracy
for k = 2 through k = 775. When countermeasures are
applied, the best classiﬁer’s accuracy does drop slowly
as k increases. This suggests that the countermeasures do
obfuscate some features that can improve accuracy. That
said, at the largest k, the best classiﬁers offer better than
60% accuracy against all of the countermeasures.

344

Our work paints a pretty negative picture of the use-
fulness of efﬁcient, low-level TA countermeasures against
website-ﬁngerprinting attacks. But pessimism need not
prevail. Future work could investigate more detailed mod-
elings of real-world trafﬁc, and investigate applications of
TA countermeasures beyond website ﬁngerprinting. This
may uncover settings in which some countermeasures are
more successful than they were in our experiments. In
addition, the coarse features (e.g. bandwidth) that appear
near impossible to obfuscate efﬁciently at the level of
individual packets might be better handled at the applica-
tion layer. Previous works [8, 12] suggest application-layer
countermeasures with promising initial evaluations. Future
work could provide more extensive investigation of such
countermeasures.

REFERENCES

[1] George Bissias, Marc Liberatore, David Jensen, and
Brian Neil Levine. Privacy Vulnerabilities in Encrypted
HTTP Streams. In Proceedings of the Privacy Enhancing
Technologies Workshop, pages 1–11, May 2005.

[2] Peter Chapman and David Evans. Automated Black-Box
Detection of Side-Channel Vulnerabilities in Web Applica-
tions. In Proceedings of the ACM Conference on Computer
and Communications Security, pages 263–274, November
2011.

[3] Shuo Chen, Rui Wang, XiaoFeng Wang, and Kehuan
Zhang. Side-Channel Leaks in Web Applications: a Reality
Today, a Challenge Tomorrow. In Proceedings of the IEEE
Symposium on Security and Privacy, pages 191–206, May
2010.

[4] Heyning Cheng and Ron Avnur.

Trafﬁc Analysis
of SSL Encrypted Web Browsing, December 1998.
at: http://www.cs.berkeley.edu/∼daw/teaching/
Available
cs261-f98/projects/ﬁnal-reports/ronathan-heyning.ps.

[5] Tim Dierks and Eric Rescorla.

The Transport Layer
Security (TLS) Protocol Version 1.2. RFC 5246, August
2008. Updated by RFCs 5746, 5878, 6176. Available at:
http://www.ietf.org/rfc/rfc5246.txt.

[6] Roger Dingledine, Nick Mathewson, and Paul Syverson.
Tor: The second-generation onion router. In Proceedings of
the 13th conference on USENIX Security Symposium, pages
303–320, 2004.

[7] Xinwen Fu, Bryan Graham, Riccardo Bettati, Wei Zhao,
and Dong Xuan. Analytical and Empirical Analysis of
Countermeasures to Trafﬁc Analysis Attacks. In Proceed-
ings of the International Conference on Parallel Processing,
pages 483–492, October 2003.

[8] Dominik Herrmann, Rolf Wendolsky, and Hannes Feder-
rath. Website Fingerprinting: Attacking Popular Privacy
Enhancing Technologies with the Multinomial Naive-Bayes
Classiﬁer. In Proceedings of the ACM Workshop on Cloud
Computing Security, pages 31–42, November 2009.

[9] Andrew Hintz. Fingerprinting Websites Using Trafﬁc Anal-
ysis. In Proceedings of the Privacy Enhancing Technologies
Workshop, pages 171–178, April 2002.

Inferring the
[10] Marc Liberatore and Brian Neil Levine.
Source of Encrypted HTTP Connections.
In Proceedings
of the ACM Conference on Computer and Communications
Security, pages 255–263, November 2006.

[11] Liming Lu, Ee-Chien Chang, and Mun Chan. Website
Fingerprinting and Identiﬁcation Using Ordered Feature
Sequences. In Proceedings of the European Symposium on
Research in Computer Security, volume 6345 of Lecture
Notes in Computer Science, pages 199–214, September
2010.

[12] Xiapu Luo, Peng Zhou, Edmond W. W. Chan, Wenke Lee,
Rocky K. C. Chang, and Roberto Perdisci. HTTPOS:
Sealing Information Leaks with Browser-side Obfuscation
of Encrypted Flows.
In Proceedings of the Network and
Distributed Security Symposium, February 2011.

[13] Tom M. Mitchell. Machine Learning. McGraw-Hill, New

York, 1997.

[14] Andriy Panchenko, Lukas Niessen, Andreas Zinnen, and
Thomas Engel. Website Fingerprinting in Onion Routing-
based Anonymization Networks.
In Proceedings of the
Workshop on Privacy in the Electronic Society, pages 103–
114, October 2011.

[15] Qixiang Sun, Daniel R. Simon, Yi-Min Wang, Wilf Russell,
Venkata N. Padmanabhan, and Lili Qiu. Statistical Identiﬁ-
cation of Encrypted Web Browsing Trafﬁc. In Proceedings
of the IEEE Symposium on Security and Privacy, pages 19–
30, May 2002.

[16] David Wagner and Bruce Schneier. Analysis of the SSL
3.0 Protocol. In Proceedings of the USENIX Workshop on
Electronic Commerce, pages 29–40, November 1996.

[17] Wei Wang, Mehul Motani, and Vikram Srinivasan. Depen-
dent Link Padding Algorithms for Low Latency Anonymity
Systems.
the ACM Conference on
Computer and Communications Security, pages 323–332,
November 2008.

In Proceedings of

[18] Andrew M. White, Austin R. Matthews, Kevin Z. Snow, and
Fabian Monrose. Phonotactic Reconstruction of Encrypted
VoIP Conversations: Hookt on fon-iks. In Proceedings of
the IEEE Symposium on Security and Privacy, pages 3–18,
May 2011.

[19] Charles V Wright, Lucas Ballard, Scott E. Coull, Fabian
Monrose, and Gerald M Masson. Spot Me if You Can:
Uncovering Spoken Phrases in Encrypted VoIP Conversa-
tions. In Proceedings of the IEEE Symposium on Security
and Privacy, pages 35–49, May 2008.

[20] Charles V. Wright, Lucas Ballard, Scott E. Coull, Fabian
Monrose, and Gerald M. Masson. Uncovering Spoken
Phrases in Encrypted Voice over IP Conversations. ACM
Transactions on Information and Systems Security, 13:1–30,
December 2010.

[21] Charles V. Wright, Lucas Ballard, Fabian Monrose, and
Gerald M. Masson. Language identiﬁcation of encrypted
VoIP trafﬁc: Alejandra y Roberto or Alice and Bob? In
Proceedings of the USENIX Security Symposium, pages 1–
12, August 2007.

[22] Charles V. Wright, Scott E. Coull, and Fabian Monrose.
Trafﬁc Morphing: An Efﬁcient Defense Against Statistical
Trafﬁc Analysis.
the Network and
Distributed Security Symposium, pages 237–250, February
2009.

In Proceedings of

[23] Ye Zhu, Xinwen Fu, Bryan Graham, Riccardo Bettati, and
Wei Zhao. On Flow Correlation Attacks and Countermea-
sures in Mix Networks.
In Proceedings of the Privacy
Enhancing Technologies Workshop, volume 3424 of Lecture
Notes in Computer Science, pages 207–225, May 2004.

345

APPENDIX

Countermeasure
None
Session Random 255
Packet Random 255
Pad to MTU
Packet Random MTU
Exponential
Linear
Mice-Elephants
Direct Target Sampling
Trafﬁc Morphing

LL

98.1 ± 0.1
40.7 ± 0.3
80.6 ± 0.4
63.1 ± 0.5
45.8 ± 0.4
95.4 ± 0.2
96.6 ± 0.2
84.8 ± 0.4
25.1 ± 0.6
31.0 ± 0.7

H

98.9 ± 0.1
13.1 ± 0.2
40.1 ± 0.3
4.7 ± 0.1
11.2 ± 0.2
72.0 ± 0.4
89.4 ± 0.2
20.9 ± 0.3
2.7 ± 0.1
6.3 ± 0.3

P

97.2 ± 0.2
90.6 ± 0.3
94.9 ± 0.3
89.8 ± 0.4
92.1 ± 0.3
96.6 ± 0.3
96.8 ± 0.2
94.5 ± 0.3
81.8 ± 0.5
88.7 ± 0.4

Classiﬁer

BW

80.1 ± 0.6
54.9 ± 0.4
77.4 ± 0.6
62.7 ± 0.6
64.6 ± 0.5
77.1 ± 0.6
79.5 ± 0.6
72.3 ± 0.6
41.2 ± 0.9
43.0 ± 0.9

TIME

9.7 ± 0.1
9.5 ± 0.1
9.4 ± 0.1
9.6 ± 0.2
9.5 ± 0.1
9.6 ± 0.1
9.6 ± 0.2
9.6 ± 0.1
9.7 ± 0.2
9.8 ± 0.2

VNG

93.7 ± 0.2
87.8 ± 0.3
91.6 ± 0.2
82.6 ± 0.4
77.8 ± 0.3
95.1 ± 0.2
93.5 ± 0.2
89.4 ± 0.3
69.4 ± 0.6
81.0 ± 0.5

VNG++
93.9 ± 0.3
91.6 ± 0.3
93.5 ± 0.3
88.2 ± 0.4
87.6 ± 0.3
94.8 ± 0.3
94.3 ± 0.3
91.7 ± 0.4
80.2 ± 0.5
86.0 ± 0.4

Figure 13. Classiﬁer performance for k = 128, using the Herrmann dataset.

Countermeasure
None
Session Random 255
Packet Random 255
Pad to MTU
Packet Random MTU
Exponential
Linear
Mice-Elephants
Direct Target Sampling
Trafﬁc Morphing

LL

87.1 ± 0.6
25.3 ± 0.4
43.6 ± 0.7
41.3 ± 0.6
21.8 ± 0.5
72.9 ± 0.6
79.2 ± 0.7
55.9 ± 0.9
19.4 ± 1.0
20.1 ± 1.2

H

87.4 ± 0.3
9.5 ± 0.1
13.1 ± 0.3
5.0 ± 0.1
7.5 ± 0.1
61.2 ± 0.4
73.9 ± 0.3
25.6 ± 0.3
2.5 ± 0.3
4.1 ± 0.5

P

87.5 ± 0.6
66.1 ± 0.6
74.0 ± 0.7
69.2 ± 0.7
69.1 ± 0.7
82.1 ± 0.8
84.2 ± 0.6
75.6 ± 0.7
47.4 ± 1.4
55.3 ± 1.3

Classiﬁer

BW

55.7 ± 0.7
38.6 ± 0.5
51.5 ± 0.7
41.8 ± 0.6
40.2 ± 0.6
54.8 ± 0.8
54.4 ± 0.9
49.3 ± 0.6
26.8 ± 1.1
25.6 ± 1.1

TIME

11.6 ± 0.7
12.1 ± 0.6
11.8 ± 0.6
11.6 ± 0.7
11.4 ± 0.8
10.5 ± 0.7
12.0 ± 0.7
11.7 ± 0.5
11.1 ± 0.7
12.3 ± 0.7

VNG

72.0 ± 1.1
60.5 ± 1.1
65.6 ± 1.3
56.8 ± 1.2
47.1 ± 1.0
74.1 ± 0.8
70.3 ± 0.9
65.9 ± 1.1
35.7 ± 3.0
45.4 ± 2.1

VNG++
76.3 ± 1.0
68.7 ± 1.2
71.8 ± 1.0
65.7 ± 1.1
60.3 ± 1.0
78.0 ± 0.9
74.3 ± 1.4
71.2 ± 1.0
49.7 ± 1.9
56.7 ± 2.0

Figure 14. Classiﬁer performance for k = 128, using the Liberatore dataset.

Classiﬁer
None
Session Random 255
Packet Random 255
Pad to MTU
Packet Random MTU
Exponential
Linear
Mice-Elephants
Direct Target Sampling
Trafﬁc Morphing

k = 16
96.9 ± 0.1
96.0 ± 0.1
96.6 ± 0.1
95.2 ± 0.1
95.0 ± 0.1
97.1 ± 0.1
96.9 ± 0.1
96.2 ± 0.1
93.1 ± 0.2
94.8 ± 0.2

k = 32
95.9 ± 0.2
94.7 ± 0.2
95.7 ± 0.2
93.2 ± 0.2
93.1 ± 0.2
96.5 ± 0.1
96.0 ± 0.2
95.1 ± 0.2
89.8 ± 0.2
92.8 ± 0.2

k = 64
95.1 ± 0.2
93.4 ± 0.2
94.5 ± 0.2
91.4 ± 0.2
90.8 ± 0.2
95.6 ± 0.2
95.1 ± 0.2
93.6 ± 0.2
85.3 ± 0.3
90.2 ± 0.3

Privacy Set Size

k = 128
93.9 ± 0.3
91.6 ± 0.3
93.5 ± 0.3
88.2 ± 0.4
87.6 ± 0.3
94.8 ± 0.3
94.3 ± 0.3
91.7 ± 0.4
80.2 ± 0.5
85.6 ± 0.7

k = 256
93.3 ± 0.4
89.4 ± 0.4
92.2 ± 0.5
84.2 ± 0.5
83.3 ± 0.5
93.7 ± 0.4
92.8 ± 0.5
90.0 ± 0.5
74.3 ± 0.8
83.3 ± 0.7

k = 512
91.6 ± 0.6
85.6 ± 0.6
89.8 ± 0.7
79.5 ± 0.8
78.6 ± 0.6
92.5 ± 0.6
91.8 ± 0.6
86.5 ± 0.8
65.8 ± 1.8
77.7 ± 2.3

k = 775
90.6 ± 0.9
84.1 ± 0.5
88.5 ± 0.8
77.3 ± 0.7
74.8 ± 0.8
90.8 ± 1.2
89.5 ± 1.1
84.0 ± 0.8
61.0 ± 4.1
75.1 ± 3.1

Figure 15. Performance of the VNG++ classiﬁer, for varying values of k, using the Herrmann dataset.

Classiﬁer
None
Session Random 255
Packet Random 255
Pad to MTU
Packet Random MTU
Exponential
Linear
Mice-Elephants
Direct Target Sampling
Trafﬁc Morphing

k = 16
98.4 ± 0.1
96.8 ± 0.1
97.6 ± 0.1
96.4 ± 0.1
97.0 ± 0.1
98.1 ± 0.1
98.1 ± 0.1
97.5 ± 0.1
94.7 ± 0.2
95.9 ± 0.1

k = 32
98.0 ± 0.1
95.5 ± 0.2
96.9 ± 0.2
94.8 ± 0.2
95.8 ± 0.2
97.9 ± 0.1
97.7 ± 0.1
97.0 ± 0.1
91.7 ± 0.2
94.2 ± 0.2

k = 64
97.7 ± 0.2
93.6 ± 0.2
96.2 ± 0.2
92.7 ± 0.3
94.4 ± 0.2
97.2 ± 0.2
97.6 ± 0.2
95.6 ± 0.2
87.2 ± 0.3
91.6 ± 0.3

Privacy Set Size

k = 128
97.2 ± 0.2
90.6 ± 0.3
94.9 ± 0.3
89.8 ± 0.4
92.1 ± 0.3
96.6 ± 0.3
96.8 ± 0.2
94.5 ± 0.3
81.8 ± 0.5
88.7 ± 0.4

k = 256
97.2 ± 0.3
87.2 ± 0.5
93.9 ± 0.3
86.6 ± 0.5
89.3 ± 0.5
95.6 ± 0.4
95.8 ± 0.5
93.2 ± 0.4
75.9 ± 0.7
85.6 ± 0.6

k = 512
96.4 ± 0.5
83.2 ± 0.5
91.2 ± 0.8
82.4 ± 0.8
85.6 ± 0.7
95.2 ± 0.3
95.0 ± 0.6
89.9 ± 0.9
68.7 ± 0.9
81.0 ± 0.9

k = 775
96.4 ± 0.4
78.7 ± 0.9
90.3 ± 0.7
79.2 ± 0.9
83.2 ± 0.6
94.6 ± 0.4
94.2 ± 0.7
88.7 ± 1.0
62.5 ± 1.3
77.8 ± 1.3

Figure 16. Performance of the Panchenko classiﬁer, for varying values of k, using the Herrmann dataset.

346

