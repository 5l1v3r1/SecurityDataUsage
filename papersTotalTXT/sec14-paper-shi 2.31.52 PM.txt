Cardinal Pill Testing of System Virtual Machines
Hao Shi, Abdulla Alwabel, and Jelena Mirkovic, USC Information Sciences Institute (ISI)

https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/shi

This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXCardinal Pill Testing of System Virtual Machines

USC/Information Sciences Institute

USC/Information Sciences Institute

Abdulla Alwabel

alwabel@usc.edu

Hao Shi

haoshi@usc.edu

Jelena Mirkovic

USC/Information Sciences Institute

mirkovic@isi.edu

Abstract
Malware analysis relies heavily on the use of virtual
machines for functionality and safety. There are subtle
differences in operation between virtual machines and
physical machines. Contemporary malware checks for
these differences to detect that it is being run in a vir-
tual machine, and modiﬁes its behavior to thwart being
analyzed by the defenders. Existing approaches to un-
cover these differences use randomized testing, or mal-
ware analysis, and cannot guarantee completeness.

In this paper we propose Cardinal Pill Testing—a
modiﬁcation of Red Pill Testing [21] that aims to enu-
merate the differences between a given VM and a phys-
ical machine, through carefully designed tests. Cardinal
Pill Testing ﬁnds ﬁve times more pills by running ﬁf-
teen times fewer tests than Red Pill Testing. We further
examine the causes of pills and ﬁnd that, while the ma-
jority of them stem from the failure of virtual machines
to follow CPU design speciﬁcations, a signiﬁcant num-
ber stem from under-speciﬁcation of the effects of certain
instructions by the Intel manual. This leads to divergent
implementations in different CPU and virtual machine
architectures. Cardinal Pill Testing successfully enumer-
ates differences that stem from the ﬁrst cause, but only
exhaustive testing or an understanding of implementa-
tion semantics can enumerate those that stem from the
second cause. Finally, we sketch a method to hide pills
from malware by systematically correcting their outputs
in the virtual machine.

1 Introduction

In today’s practice of analyzing malware [3, 14, 16, 26,
23], system virtual machines are widely used to facilitate
ﬁne-grained dissection of malware functionalities (e.g.,
Anubis [4], TEMU [6, 24], and Bochs [17]). For exam-
ple, virtual machines can be used for dynamic taint anal-
ysis, OS-level information retrieval, and in-depth behav-

ioral analysis. Use of virtual machines also protects the
host, by isolating it from potentially malicious actions.

Malware authors have devised a variety of methods to
hinder automated and manual analysis of their code, such
as anti-dumping, anti-debugging, anti-virtualization, and
anti-intercepting [10, 11]. Recent studies [7, 18] show
that anti-virtualization and anti-debugging techniques
have become the most popular methods of evading
malware analysis. Chen et al. [8], ﬁnd in 2008 that
2.7% and 39.9% of 6,222 malware samples exhibit anti-
virtualization and anti-debugging behaviors respectively.
In 2011, Lindorfer et al. [18] detect evasion behavior in
25.6% of 1,686 malicious binaries. In 2012, Branco et
al. [7] analyze 4 million samples and observe that 81.4%
of them exhibit anti-virtualization behavior and 43.21%
exhibit anti-debugging behavior.

Upon detection of a virtual environment or the pres-
ence of debuggers, malicious code can alternate execu-
tion paths to appear benign, exit programs, crash sys-
tems, or even escape virtual machines. It is critically im-
portant to devise methods that handle anti-virtualization
and anti-debugging, to support future malware analysis.
In this paper we focus only on anti-virtualization han-
dling, and speciﬁcally on CPU semantic attacks.

We observe that malware can differentiate between a
physical and a virtual machine due to numerous subtle
differences that arise from their implementations. Let us
call the physical machine an Oracle. Malware samples
execute sets of instructions with carefully chosen inputs
(aka pills), and compare their outputs with the outputs
that would be observed in an Oracle. Any difference
leads to detection of VM presence.

These attacks are successful because there are many
differences between VMs and physical machines, and
existing research in VM detection [21, 20, 15] uses ad-
hoc tests that cannot fully enumerate these differences.
Since malware is run within a VM, all its actions are
visible to the VM and all the responses are within a
VM’s control. If differences between a physical machine

USENIX Association  

23rd USENIX Security Symposium  271

and a VM could be enumerated, the VM could use this
database to provide expected replies to malware queries,
thus hiding its presence. This is akin to kernel root kit
functionality, where the root kit hides its presence by in-
tercepting instructions that seek to examine processes,
ﬁles and network activity, and provides replies that an
uncompromised system would produce.

In this paper we attempt to enumerate all the differ-
ences between a physical machine and a virtual machine
that stem from their differences in instruction execution.
These differences can be used for CPU semantic attacks
(see Section 2). Our contributions are:

1. We improve on the previously proposed Red Pill
Testing [21, 20] by devising tests that carefully tra-
verse operand space, and explore execution paths in
instructions with the minimal set of test cases. We
use 15 times fewer tests and discover 5 times more
pills than Red Pill Testing. Our testing is also more
efﬁcient, 47.6% of our test cases yield a pill, com-
pared to only 0.6% of Red Pill tests. In total, we dis-
cover between 7,487 and 9,255 pills, depending on
the virtualization technology and the physical ma-
chine being tested.

2. We ﬁnd two root causes of pills: (1) failure of vir-
tual machines to strictly adhere to CPU design spec-
iﬁcation and (2) vagueness of the CPU design spec-
iﬁcation that leads to different implementations in
physical machines. Only 2% of our pills stem from
the second phenomenon.

3. We propose how to modify virtual machines to auto-
matically hide presence of detected pills from mal-
ware, through introduction of additional interrupt
vectors and by utilizing QEMU’s interrupt handling
mechanism for guest systems (Tiny Code Genera-
tion mode).

We emphasize that our testing methodology produces
test cases selected at random from chosen input parame-
ter ranges for each instruction – these ranges are chosen
to exercise all execution paths in the given instruction’s
handling.
If a test case’s execution produces different
outputs in a physical versus a virtual machine we say that
this test case is a pill. While we only test one value from
each parameter’s range, if this test case is a pill, all val-
ues from the same parameter ranges would also lead to
pills because they are all handled by the same path in that
instruction’s execution. Let us call a pill resulting from
a test case a test pill and all related test cases that draw
parameter values from the same input ranges as the test
pill the individual pills. In this paper, all counts of pills
we report are for test pills. Similar practice is adopted by
related work [21, 20, 19]. The counts of individual pills
are many times higher.

In Section 2 we give an overview of various anti-
virtualization techniques. We survey related work in Sec-
tion 3 and propose Cardinal Pill Testing in Section 4.
We provide the details for the pills we ﬁnd in Section 5
and analyze their root causes and completeness. In Sec-
tion 6 we propose how to hide most of these pills from
malware and we conclude in Section 7. All the scripts
and test cases used in our study are publicly released at
http://steel.isi.edu/Projects/cardinal/.

2 Anti-Virtualization Techniques

Anti-virtualization techniques can be classiﬁed into the
following broad categories [8, 15]:
CPU Semantic Attacks. Malware targets certain CPU
instructions that have different effects when executed un-
der virtual and real hardware. For instance, the cpuid
instruction in Intel IA-32 architecture returns the tsc bit
with value 0 under the Ether [9] hypervisor, but outputs 1
in a physical machine [22]. As another example found in
our experiment, when moving hex value 7fffffffh to
ﬂoating point register mm1, the resulting st1 register is
correctly populated as SNaN (signaling non-number) in a
physical machine, but has a random number in a QEMU-
virtualized machine. Malware executes these pills and
checks their output to identify presence of a VM.
Timing Attacks. Malware measures the time needed
to run an instruction sequence, assuming that an opera-
tion takes a different amount of time in a virtual machine
compared to a physical machine [11]. Contemporary vir-
tualization technologies (dynamic translation [5], byte-
code interpretation [17], and hardware assistance [9]) all
add signiﬁcant delays to instruction execution that are
measurable by malware 1.
String Attacks. VMs leave a variety of traces inside
guest systems that can be used to detect their presence.
For instance, QEMU assigns the “QEMU Virtual CPU”
string to the emulated CPU and similar aliases to other
virtualized devices such as hard drive and CD-ROM. A
simple query to Windows registry would reveal the VM’s
presence immediately [8].

In this work we focus on handling the CPU semantic
attacks as they are the most complex category to explore
and enumerate. We note that string attacks can easily be
handled through enumeration and hiding of VM traces,
which can be done by comprehensive listing and com-
parison of ﬁles, processes and Windows registry with
and without virtualization. Also, timing attacks can be
handled through systematic lying about the VM clock,
as proposed in [15]. While neither of these approaches

1This method can also be used to detect debuggers, because step-

ping code adds large delays.

272  23rd USENIX Security Symposium 

USENIX Association

2

is implemented today, both could be implemented as ex-
tensions of our work on lying to applications about CPU
semantics (Section 6).

3 Related Work

Martignoni et al. present the initial Red Pill work in
EmuFuzzer [21]. They propose Red Pill Testing—a
method that performs a random exploration of a CPU
instruction set and parameter spaces looking for pills.
Testing is performed by iterating through the following
steps: (1) initialize input parameters in the guest VM, (2)
duplicate the content in user-mode registers and process
memory in the host, (3) execute a test case, (4) compare
resulting states of register contents, memory and excep-
tions raised—if there are any differences, the test case is
a pill. In KEmuFuzzer [20], Martignoni et al. extend the
state deﬁnition to include the kernel space memory, and
test cases are embedded in the kernel to facilitate test-
ing of privileged instructions. In their recent work [19],
they use symbolic execution to translate code of a high-
ﬁdelity emulator (Bochs) and then generate test cases
that can investigate all discovered code paths. Those test
cases are used to test a lower-ﬁdelity emulator.

While these works are seminal in pill detection they
have several deﬁciencies that we seek to handle in this
paper: (1) EmuFuzzer [21] tests boundary and random
values for explicit input parameters, but does not cover
implicit parameters. Their approach cannot guarantee
that all types of pills will be detected. The symbolic
execution approach [19] will discover differences be-
tween low-ﬁdelity and high-ﬁdelity emulators but not
between an emulator and a physical machine. In addi-
tion, use of symbolic execution precludes test genera-
tion for ﬂoating-point instructions. We improve on these
works by using instruction semantics to carefully craft
test cases that explore all code paths. (2) Martignoni et
al. use QEMU with Intel VT-x (in [21]) or Bochs emu-
lator (in [19]) as an Oracle, while we use physical ma-
chines with no virtualization. This improves ﬁdelity of
testing and ensures detection of more pills.

Dinaburg et al. [9] aim to build a transparent mal-
ware analyzer, Ether, by implementing analysis function-
alities out of the guest, using Intel VT-x extensions for
hardware-assisted virtualization. nEther [22] work ﬁnds
that Ether still has signiﬁcant differences in instruction
handling when compared to physical machines, and thus
anti-virtualization attacks are still possible, i.e., Ether
does not achieve complete transparency.

Kang et al. [15] propose a method to identify anti-
emulation checks and modify virtual system states to
“lie” to the malware, using semi-manual execution trace
analysis. They record the malware trace in Ether, us-
ing it as an Oracle, and utilizing its debugging functions.

They then automatically taint the variables in this trace,
and manually identify those variables whose values are
used in an anti-emulation check under QEMU. Their
method requires manual intervention while we seek to
overcome differences in execution environments auto-
matically. Furthermore, since Ether is not identical to a
physical machine, this approach will fail to detect some
differences between a VM and a physical machine that
we do detect.

Other works [25, 18, 2] focus on detecting anti-
virtualization functions of malicious binaries based on
proﬁling and comparing their behavior in virtual and
physical machines. These works do not uncover the
details of anti-virtualization methods that each indi-
vidual binary employs, and they can only detect anti-
virtualization checks deployed by their malware sam-
ples, while we detect many more differences that could
be used in future anti-virtualization checks.

4 Cardinal Pill Testing

We now describe the architecture, test case generation
and testing methodology for our Cardinal Pill Testing.

4.1 Architecture Overview
Our testing architecture is shown in Figure 1. It consists
of three physical workstations: a master, a slave hosting
a virtual machine (VM), and a slave running Windows 7
Pro x86 on a bare-metal as reference (Oracle). The slaves
are connected to the master through two separate serial
wires. The master is responsible for generating test cases
(Section 4.3) and scheduling their execution in slaves. In
both slaves, we conﬁgure an additional daemon in the
testing system that helps the master set up a speciﬁc test
case in each testing round.

Master

Slaves

VM

Oracle

Figure 1: Architecture Overview

4.2 Logic Execution
The execution logic of our Cardinal Pill Testing is il-
lustrated in Figure 2. The master maintains a debugger
that issues commands to and transfers data back from the
slaves. The Oracle and the VM have the same test case
set and the daemon; we only show one pair of test case

USENIX Association  

23rd USENIX Security Symposium  273

3

and daemon in Figure 2 for clarity. We set the slaves in
kernel debugging mode so that they can be completely
frozen when necessary. At the beginning, the master re-
boots the slave (either VM or Oracle) for fresh system
states. After the slave is online, the daemon signals its
readiness to the master, which then evaluates test cases
one by one in terms of rounds.

idle
system
startup

ready

start

system 
loading

reboot slave

testcase name

ready

copy

Raw State

o
n
e
 
r
o
u
n
d

release

copy

state init.

ready

infinite
loop

Initial State

release

copy

testing
instruction

ready

Final State

break loop

next testcase name

debugger

testcase

daemon

Figure 2: Logic Execution

We deﬁne the state of a physical or virtual machine as
a set of all user and kernel registers, and the data stored
in the part of code, data, and stack segments that our test
case accesses for reading or writing.

In each round, the master interacts with the slave in
three main phases. In the ﬁrst phase, it issues a test case
name to the daemon, which resides in a slave, and the
daemon will ask the slave system to load this test case
stored in its local disk. Then the system starts allocat-
ing memory, handles, and other resources needed by the
test case program. After this system loading completes,
the test case executes an interrupt instruction (int 3),
which notiﬁes the master and halts the slave. At this mo-
ment, the master saves the raw state of the slave locally.

We use this raw state to identify axiom pills (see Sec-
tion 4.3), instead of discarding it, as is done by Emu-
Fuzzer [21] and KEmuFuzzer [20].

In the second phase, the master releases the slave
which then executes the test case’s initialization code and
raises the second interrupt. Instead of using the same ini-
tial system state for all test cases, we carefully tailor reg-
ister and memory bits for each test case, such that all pos-
sible exceptions and semantic branches can be evaluated
(see Section 4.3). The master copies back the resulting
initial state and releases the slave again.

In the third phase, the slave executes the actual instruc-
tion being tested and raises the last interrupt. The master
will store this ﬁnal state and use it to determine whether
the tested instruction along with the initial state is a car-
dinal pill (see Section 5.1). It may happen that a test case
drives the slave into an inﬁnite loop or crashes itself or its
OS. To detect this, we set up an execution time limit for
each test case, so that the master can detect incapacitated
slaves and restore them.

4.3 Test Case Generation
The quality of test cases is the key component of efﬁ-
cient pill discovery. The Red Pill work [21] generates
test cases via two approaches: random generation and
CPU-assisted generation. The former method random-
izes data and code without conforming to any semantic
rules, which may encode invalid instruction sequences.
The latter combines each known opcode with some pre-
deﬁned operand values. Both approaches have the fol-
lowing deﬁciencies: (1) They only consider operands en-
coded in the instruction and fail to consider implicit ar-
guments whose value may lead instruction execution to
a different path in the code. For example, rep stosb
takes no arguments but it depends on multiple register
values. It stores contents of al register at the address
speciﬁed by es:(e)di, and does this ecx times. Dif-
ferent values placed into those registers will result in dif-
ferent scenarios for rep stosb command use, such
as writing into a valid versus invalid memory location,
overwriting the instruction itself, using a zero, negative
or very large positive value for the number of repeti-
tions, etc.
(2) They generate operands for instructions
at random, which also does not explore all possible code
paths. Our test case generation algorithm addresses both
of these challenges.

4.3.1 Testing Goals

We aim to generate a minimal set of test cases for each
instruction that explore all possible code paths in this in-
struction’s handling. We start from the deﬁnitions of in-
struction handling recorded in a CPU manual.
In this

274  23rd USENIX Security Symposium 

USENIX Association

4

; Raw State

push offset handler ; install SEH
assume fs:nothing
push fs:[0]
mov fs:[0], esp

;; populate reg and memory
mov eax, 0000001bh
mov ebx, 00001000h
...
;; double precision floating-point
mov eax, 00403080h
mov dword ptr [eax], 0h
mov dword ptr [eax+4], 7ff00000h ; +Infi
...
;; single precision floating-point
mov eax, 0040318ch
mov dword ptr [eax], 0ff801234h ; SNaN
...
;; double-extended precision FP
...
;; unsupported double-extended precision
...
[state_init]
int 3
[testing_insn]
int 3
call ExitProcess

; specific init
; Initial State
; instruction in test
; Final State

;; push exception information onto stack
mov edx, [esp + 4]
; excep_record
; context
mov ebx, [esp + 0ch]
push dword ptr [edx]
; excep_code
...
push dword ptr [edx + 0c0h] ; eflags
int 3
mov eax, 1h
call ExitProcess

; Final State (exception)

int 3

1 main proc
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31 handler:
32
33
34
35
36
37
38
39
40
41 main endp
42 end main

work we focus on Intel’s x86 CPU processor [13]. The
manual details inputs and outcomes for each instruction,
for normal execution and for exception handling. We call
register modiﬁcations and exceptions whose semantics
are fully deﬁned in the manual deﬁned behaviors. An
instruction may also affect registers and raise exceptions
that are speciﬁed in the manual as affected but the man-
ner of their modiﬁcation by the instruction is not speci-
ﬁed. We call these modiﬁcations undeﬁned behaviors.

For example, the aaa instruction adjusts the sum of
two unpacked binary coded decimal (BCD) values to
create an unpacked BCD result. The al register is the
implied source and destination operand for this instruc-
tion. It also reads the AF ﬂag in the EFLAGS register and
writes to the ah register. Its normal execution will set AF
and CF ﬂags to 1 if the adjustment results in a decimal
carry; otherwise it will set them to 0. This is the deﬁned
behavior for the aaa instruction. In our testing we ﬁnd
that physical machines also set or reset the SF, ZF, and
PF ﬂags. While these ﬂags are listed as affected by the
instruction in the manual, there are no details of how they
are calculated or what semantics they carry for the aaa
instruction. This is the undeﬁned behavior for the aaa
instruction. In our work we explore both deﬁned and un-
deﬁned behaviors for each instruction, because both of
these can be the source of pills.

Based on these observations, we set up the following

goals of our test case generation algorithm:

• For deﬁned behaviors for a given instruction, all
branches should be evaluated. All ﬂag bit states that
are read implicitly or updated using results must be
considered.

• All potential exceptions must be raised, such as

memory access and invalid input arguments.

• Undeﬁned behaviors should be investigated to re-

veal undocumented implementation speciﬁcs.

In the following sections, we ﬁrst illustrate our test case
template and then discuss how we group instructions and
populate the template.

4.3.2 Test Case Template

We program a template to automatically generate test
cases for most instructions, as shown in Figure 3. This
program notiﬁes the master and then halts the slave as
soon as it enters the main function (line 2), so the master
can save the states. The same interaction happens at lines
27, 29, and 38, after the test case completes a certain step.
Then the program installs a structured exception handler
for the Windows system (line 4 – 7). If an exception oc-
curs, the program will ignore Windows’ built-in excep-

Figure 3: Test Case Template (in MASM assembly)

tion handling routine and jump to line 31 directly, so we
can save the system state before exception handling.

From line 9 to 25, we perform general-purpose ini-
tialization. Registers and memory are populated using
pre-deﬁned values, including all ﬂoating point and in-
teger formats. This step occurs in all test cases and the
carefully chosen, frequently used values, are stored in the
registers to minimize the need for speciﬁc initialization.
After this, the speciﬁc initialization (line 26) makes tai-
lored modiﬁcations to the numbers, if needed for a given
test case. For example, the eax is set to 1bh at line
10 for all test cases. One particular test case may need
0ffh value in this register and will update it at line 26.
The actual instruction is being tested at line 29, where all
deﬁned and undeﬁned behaviors use will be evaluated in
various test cases. When compiling test cases, we disable

USENIX Association  

23rd USENIX Security Symposium  275

5

linker optimization and use a ﬁxed base address, which
does not affect testing but eases the interaction between
the master and slaves.

4.3.3

Instruction Grouping

To test each instruction’s behaviors in different execution
stages, we need to vary the content in all registers and
memory that the instruction reads. As discussed earlier
and demonstrated in our evaluation in Section 5, random
test generation cannot guarantee coverage of all code
paths and execution branches. In our method, we manu-
ally analyze instruction execution ﬂows deﬁned in Intel
manuals [13] and classify all possible input parameter
values into ranges that lead to distinct execution ﬂows.

IA-32 CPU architecture contains 906 instruction
codes, and a human must reason about each to identify
its inputs and outputs and how to populate them to test all
execution behaviors. To reduce the scale of this human-
centric operation, we ﬁrst group the instructions into ﬁve
categories: arithmetic, data movement, logic, ﬂow con-
trol and miscellaneous. Arithmetic and logic category
are further subdivided into general-purpose and FPU cat-
egories based on the type of their operands, We then
deﬁne parameter ranges to test per category, and adjust
them to ﬁt ﬁner instruction semantics as described be-
low. This grouping greatly reduces human time invest-
ment and reduces chance of human errors. It took one
person on our team a month and a half to devise all test
cases. Table 1 shows the number of different mnemon-
ics, examples, and parameter ranges we evaluate for each
category.
Arithmetic Group. Instructions in this group ﬁrst fetch
arguments and then perform arithmetic operations. The
arguments include actual data bits they operate on and
certain ﬂag bits that decide execution branches. We clas-
sify instructions in this group into two subgroups, de-
pending on whether they work only on integer registers
(general-purpose group), or also on ﬂoating point regis-
ters (FPU group). The instructions in the FPU group in-
clude instructions with x87 FPU, MMX, SSE, and other
extensions.

Based on the argument types and sizes, branch con-
ditions, and the number of arguments, we divide both
subgroups into ﬁner partitions. For example, aaa, aas,
daa, and das in the general-purpose subgroup all com-
pare the al register (holding one packed BCD argument
8-bits long) with 0fh and check the adjustment ﬂag AF
in the EFLAGS register. This decides the output of the
instruction. To test instructions in this set we initial-
ize the al register to minimal (00h), maximal (0ffh),
boundary (0fh), and random values in different ranges
([01h, 0eh], [10h, 0feh]). We also ﬂip AF be-
tween clear and set for different al values.

If a mnemonic takes two parameters, we select at least
three value pairs to ensure that a greater-than, equal-to,
and less-than relationship between them is satisﬁed in
our test set. For the FPU subgroup, the parameter ranges
are separated based on the sign, biased exponent, and
signiﬁcand, which splits all possible values into 10 do-
mains: ±inﬁ, ±normal, ±denormal, 0, SNaN, QNaN,
and QNaN ﬂoating-point indeﬁnite. We sample values
from all these ranges to test behaviors in the arithmetic
FPU group. For example, fadd, fsub, fmul, and
fdiv each use one operand that can be speciﬁed using
four different addressing modes; one of them is m64fp,
which stands for a double precision ﬂoat stored in mem-
ory. These instructions add/sub/mul/div the st(0) reg-
ister with the operand’s value and store the result in
st(0).
In addition, they also read control bits in the
mxcsr register and fdiv checks the divide-by-zero ex-
ception. In our test cases we generate values for the two
ﬂoating point operands from the 10 identiﬁed ranges and
permute the relevant bits in the mxcsr register. Because
instructions in this subgroup can also access memory to
read operands, we devise additional test cases to evalu-
ate the memory management unit. We place the m64fp
argument in and out of the valid address space of a data
segment, into a segment with and without required priv-
ileges, and into a segment that is paged in and paged out
of memory. By combining these test cases together, all
potential memory access exceptions can be raised along
with all potential arithmetic exceptions.
Data Movement.
Data movement instructions copy
data between registers, main memory, and peripheral de-
vices and usually do not modify ﬂag bits. There are sev-
eral execution branches that we explore in tests. The
source and the destination operands may be located out-
side segment limits. If the effective address is valid but
paged out, a page-fault exception will be thrown.
If
alignment checking is enabled and an unaligned mem-
ory reference is made while the current privilege level is
3, the system will raise an alignment exception. Some in-
structions also check direction and conditional ﬂags, and
a few others validate the format of ﬂoating point values.
All these input parameters and the states that inﬂuence
an instruction’s execution outcome must be tested.

For example, we group 30 conditional movement in-
structions cmovcc r32, r/m32 of distinct cc to-
gether because they move 32 bit signed or unsigned inte-
gers from the second operand (32 bit register or memory)
to the ﬁrst operand (32 bit register). The cc conditions
are determined by the CF, ZF, SF, OF and PF ﬂags. To
access arguments outside the segment limit, we compile
our test cases with the ﬁxed base (Section 4.3.2). The
starting addresses for code, data, and stack segment are
401000h, 403000h, and 12e000h respectively, and
each has a size of 4KB. It is difﬁcult to test page faults

276  23rd USENIX Security Symposium 

USENIX Association

6

Category

Instruction Count

Example Instructions

Parameter Coverage

arithmetic

data mov

logic

ﬂow ctrl

misc

48

336

232

64

128

64

34

aaa, add, imul, shl, sub

addpd, vminss, fmul, fsqrt, roundpd

cmova, fild, in, pushad, vmaskmovps

and, bound, cmp, test, xor

andpd, vcomiss, pmaxsb, por, xorps

call, enter, jbe, loopne, rep stos

clflush, cpuid, mwait, pause, ud2

Table 1: Instruction Grouping

min, max, boundary values, randoms in
different ranges
±inﬁ, ±normal, ±denormal, ±0,
SNaN, QNaN,
QNaN ﬂoating-point indeﬁnite,
randoms
valid/invalid address, condition ﬂags,
different input ranges
min, max, boundary values, >, =, <,
ﬂag bits
±inﬁ, ±normal, ±denormal, ±0,
SNaN, QNaN,
QNaN FP indeﬁnite, >, =, <, ﬂag bits
valid/invalid
condition
ﬂags, privileges
analyze manually and devise dedicated
input

destination,

directly because the Windows system does not provide
APIs for page swapout. To work around this, we run
other memory-consuming programs between test cases
that use memory operands to force the values to be paged
out of memory. In our evaluation, we ﬁnd that this strat-
egy works well and we successfully raise page faults
when we need to test them. To raise the alignment check-
ing exception, we store instruction operands at unaligned
memory addresses. We permute the condition bits in the
same way as we do for testing of arithmetic instructions.

Logic Group. Logic instructions test relationship and
properties of operands and set ﬂag registers correspond-
ingly. We divide these instructions into general-purpose
and FPU depending on whether they use EFLAGS reg-
ister only (general-purpose) or they use both EFLAGS
and mxcsr registers (FPU). We further partition logic
instructions based on the ﬂag bits they read and argument
types and sizes. When designing test cases, in addition to
testing minimal, maximal, and boundary values for each
parameter, for instructions that compare two parameters
we also generate test cases where these parameters sat-
isfy larger-than, equal, and less-than conditions.

For example, one of the subgroups has bt, btc, btr,
and bts instructions because all of them select a bit from
the ﬁrst operand at the bit-position designated by the sec-
ond operand, and store the value of the bit in the carry
ﬂag. The only difference is how they change the selected
bit: btc complements; btr clears it to 0; and bts sets
it to 1. The ﬁrst argument in this subgroup of instructions
may be a register or a memory address of size 16, 32, or
64, and the second must be a register or an immediate
number of the same size. If the operand size is 16, for
example, we generate four input combinations (choosing

the ﬁrst and the second argument from 0h, 0ffffh
values), and we repeat this for CF = 0 and CF = 1.
Furthermore, we produce three random number combi-
nations that satisfy less-than, equal and greater-than re-
lationships. While the operand relationship does not in-
ﬂuence instruction execution in this case, it does for other
subgroups, e.g. the one containing the cmp instruction.
In the FPU subgroup, we apply similar rules to gen-
erate ﬂoating point operands. We further generate test
cases to populate the mxcsr register, which has control,
mask, and status ﬂags. The control bits specify how to
control underﬂow conditions and how to round the re-
sults of SIMD ﬂoating-point instructions. The mask bits
control the generation of exceptions such as the denor-
mal operation and invalid operation. We use ldmxcsr
to load different values into mxcsr and test instruction
behaviors under these scenarios.

Flow Control. Similar to logic instructions, ﬂow con-
trol instructions also test condition codes. Upon satisfy-
ing jump conditions, test cases start execution from an-
other place. For short or near jumps, test cases do not
need to switch the program context; but for far jumps,
they must switch stacks, segments, and check privilege
requirements.

The largest subgroup in this category is the conditional
jump jcc, which accounts for 53% of ﬂow control in-
structions. Instructions in this group check the state of
one or more of the status ﬂags in the EFLAGS register
(CF, OF, PF, SF, and ZF) and, if the required condition
is satisﬁed they perform a jump to the target instruction
speciﬁed by the destination operand. A condition code
(cc) is associated with each instruction to indicate the
condition being tested for. In our test cases we vary the

USENIX Association  

23rd USENIX Security Symposium  277

7

status ﬂags and set the relative destination addresses to
the minimal and maximal offset sizes of byte, word, or
double word as designated by mnemonic formats. For
example, ja rel8 jumps to a short relative destination
speciﬁed by rel8 if CF = 0 and ZF = 0. We per-
mute CF and ZF values in our tests, and generate the
destination address by choosing boundary and random
values from the ranges [0, 7fh] and [8fh, 0ffh].
For far jumps like jmp ptr16:16, the destination
may be a conforming or non-conforming code segment
or a call gate. There are several exceptions that can occur.
If the code segment being accessed is not present, a #NP
(not present) exception will be thrown. If the segment
selector index is outside descriptor table limits, an ex-
ception #GP (general protection) will signal the invalid
operand. We devise both valid and invalid destination
addresses to raise all these exceptions in our test cases.

Miscellaneous.

Instructions in this group provide
unique functionalities and we manually devise test cases
for each of them that evaluate all deﬁned and undeﬁned
behaviors, and raise all exceptions.

5 Detected Pills

We detect pills using our implementation of the archi-
tecture shown in Figure 1. We use two physical ma-
chines in our tests as Oracles: (O1) an Intel Xeon E3-
1245 V2 3.40GHz CPU, 2 GB memory, with Windows 7
Pro x86, and (O2) Xeon W3520 2.6GHz, 512MB mem-
ory, with Windows XP x86 SP3. The VM host has the
same hardware and guest system as the ﬁrst Oracle, but
it has 16 GB memory, and runs Ubuntu 12.04 x64. We
test QEMU (VT-x), QEMU (TCG), and Bochs, which
are the most popular virtual machines deploying different
virtualization technologies: hardware-assisted, dynamic
translation, and interpretation respectively. We allocate
to them the same size memory as in the Oracle. We test
QEMU versions 0.14.0-rc2 (Q1, used by EmuFuzzer),
1.3.1 (Q2), 1.6.2 (Q3), and 1.7.0 (Q4), and Bochs ver-
sion 2.6.2. The master has an Intel Core i7 CPU and
installs WinDbg 6.12 to interact with the slaves. For test
case compilation, we use Microsoft Assembler 10 and
turn off all optimizations. Our test cases take around 10
seconds to run on a physical machine and 15–30 seconds
to run on a virtual machine.

Counting the different addressing modes, there are
1,653 instructions deﬁned in the IA-32 Intel manual [13].
Out of these, there are 906 unique mnemonics. We gen-
erate a total of 19,412 test cases for these instructions.

5.1 Evaluation Process
We classify system states into user registers, exception
registers, kernel registers, and user memory. The user

registers contain general registers such as eax and esi.
The exception registers are eip, esp, and ebp. The
differences in the exception registers imply differences
in the exceptions being raised. The kernel registers are
used by the system and include gdtr, idtr, and oth-
ers. In our evaluation, we do not populate kernel regis-
ters in the initialization step because this may crash the
system or lead it to an unstable status. Further, initial-
ization of kernel registers would require a system reboot
and would make testing prohibitively expensive in a vir-
tual machine. But, kernel register contents are saved as
part of our states and compared to detect differences be-
tween physical and virtual machines.

For each test case, we ﬁrst examine whether the user
registers, exception registers, and user memory are the
same in the Oracle and the virtual machine in the initial
state. If they are different, it means that the VM fails to
virtualize the initialization instructions (line 26 in Fig-
ure 3) to match their implementation in the Oracle. We
mark this test case as “fatal” and discard it. If the initial
values in these locations agree with each other, we then
compare the ﬁnal states. A test case will be tagged as a
pill in two scenarios: (2) when the user registers, excep-
tion registers, and memory in the ﬁnal states are different
and (2) when the values in a certain kernel register are the
same in the initial states but different in the ﬁnal states.

5.2 Results
Table 2 shows the results of comparing various virtual
machines to Oracle1 (O1).

The second column shows the number of pills for dif-
ferent virtual machines. Both QEMU (TCG) and Bochs
exhibit moderate transparency—almost half of the test
cases report different states between O1 and VMs. For
Q2 (VT-x) 38.5% of our test cases result in pills, but
there were no fatal cases. The pills we ﬁnd for Q2 (VT-
x) occur because QEMU does not preserve the ﬁdelity
provided by hardware assistance. Therefore, we should
be careful when using hardware-assisted VMs for ﬁdelity
purposes. Their transparency depends on how they uti-
lize the hardware extension.

The third column counts test cases that crash the sys-
tem. For QEMU (TCG), one test case crashes the Oracle
1 and another one crashes the virtual machine. Another
ﬁve crash both of them. For QEMU (VT-x) and Bochs,
two test cases crash the physical and the virtual machine.
The number of fatal test cases are shown in the last
column. All of them are related to FPU movement in-
structions. In some test cases that use denormals, SNaN,
or QNaN values, the virtual machines could not populate
the operand register as required. We note that we ﬁnd no
fatal test cases for VT-x technology.

Table 3 shows the breakdown of pills per instruction

278  23rd USENIX Security Symposium 

USENIX Association

8

VMs

Q1 (TCG)
Q2 (TCG)
Q1 (VT-x)
Q2 (VT-x)

Bochs

pills

crash

fatal
9,255/47.7% 7/<0.1%
1,378/7%
9,201/47.4% 7/<0.1% 1,376/7.1%
3/<0.1%
7,523/38.7% 2/<0.1%
7,478/38.5% 2/<0.1%
0/0%
950/4.9%
8,958/46.1% 2/<0.1%

Table 2: Results Overview

Category
gen
FPU

arith

data mov
gen
FPU

logic

ﬂow ctrl

misc
total

Q1 (TCG) Q2 (TCG) Q1 (VT-x) Q2 (VT-x) Bochs Total tests

877
4,525
1,788
371
1,446
164
84

9,255

872
4,486
1,780
365
1,447
166
85

9,201

633
3,619
1,539
345
1,132
172
83

7,523

626
3,603
1,524
346
1,127
169
83

7,478

920
4,245
1,804
363
1,362
171
93

8,958

2,702
6,743
4,394
2,185
2,192
1,017
179

19,412

Table 3: Pills per Instruction Category

category from Figure 1. The FPU arithmetic, FPU logic
and data movement categories contain the most pills—
around 83%. Table 4 shows the breakdown of the pills
with regard to the resource that is different between a
physical and a virtual machine in the ﬁnal state. Most
pills occur due to differences in the kernel registers.

5.2.1 Comparison with EmuFuzzer Pills
EmuFuzzer [21] generates 3 million test cases and the
authors select 10% randomly to test in different vir-
tual machines. The authors publish 20,113 red pills for
QEMU 0.14.0-rc2 which is about 7% of the tested cases.
Because they do not publish the entire test case set, we
cannot directly compare our test cases with theirs, but
instead we only compare the pills found by them and by
us.

A unique pill is a pill whose mnemonic and parameter
values do not appear in any other pill. We use the same
QEMU version as EmuFuzzer (Q1 (TCG)) and run all
the 20,113 red pills they found. We successfully extract
operand values for 20,102 pills. After removing dupli-
cate pills, there are 1,850 unique red pills (9%) and 136
different instruction mnemonics found by EmuFuzzer.
Our 9,255 pills for Q1 (TCG) are all unique and there
are 630 different instruction mnemonics. Furthermore,
out of our 19,412 test cases we ﬁnd 9,255 pills, which is
47.6% yield, while EmuFuzzer’s yield is 1,850/300,000
= 0.6%. While direct comparison between our pills and
EmuFuzzer’s is difﬁcult because both approaches select
values of operands to test at random from speciﬁc ranges,
we compare the ranges of the pills. This comparison
shows that we detect all types of pills found by Emu-
Fuzzer.

We conclude that our approach is more comprehen-
sive than EmuFuzzer’s and far more efﬁcient. We cover
all instruction mnemonics in our tests and ﬁnd pills for
494 more instructions than EmuFuzzer. Overall we ﬁnd
ﬁve times more pills running 300,000/19,412 = 15 times
fewer tests than EmuFuzzer. This illustrates the signif-
icant advantage of careful generation of operand values
in tests over random fuzzing.

We further wanted to compare our pills with pills
found by [19]. The Hi-Fi tests for Lo-Fi emulators [19]
generate 610,516 test cases, out of which 60,770 (9.95%)
show different behaviors in QEMU, and 15,219 (2.49%)
show different behaviors in Bochs. Since the tests used
for [19] are not publicly released we could not compare
against them.

5.2.2 Root Causes of Pills
The differences detected by a pill can be due to regis-
ters, memory or exceptions that an instruction was sup-
posed to modify, according to the Intel manual [13]. We
call these instruction targets deﬁned resources. However
there are a number of instructions deﬁned in the Intel
manual that may write to some registers (or to select
ﬂags) but the semantics of these writes are not deﬁned by
the manual. We say that these instructions affect unde-
ﬁned resources. For instance, the aas instruction should
set the AF and CF ﬂags to 1 if there is a decimal bor-
row; otherwise, they should be cleared to 0. The OF, SF,
ZF, and PF ﬂags are listed as affected by the instruction
but their values are undeﬁned in the manual. Thus the
AF and CF ﬂags are deﬁned resources for the instruction
aas and OF, SF, ZF, and PF ﬂags are undeﬁned.

Table 5 shows the number of pills that result from dif-

USENIX Association  

23rd USENIX Security Symposium  279

9

Category Q2 (TCG) Q2 (VT-x) Bochs
1,671
user reg
excp reg
1,566
kerl reg
8,572
mem cont

2,416
1,578
8,398

7,457

34
21

9

46

20

Table 4: Details of Pills with Regard to the Resource Being Different in the Final State—in Some Cases Multiple
Resources Will Differ so the Same Pill May Appear in Different Rows

ferences in undeﬁned and deﬁned resources for each in-
struction category compared to Oracle 1.

We note that a small number of pills that relate to
general-purpose arithmetic and logic instructions occur
because of different handling of undeﬁned resources by
physical and virtual machines. These comprise roughly
2% of all the pills we found.

For pills originating from deﬁned resources, we ana-
lyze their root causes and compare them against those
found by the symbolic execution method [19]. We ﬁnd
all root causes listed in [19] that are related to general-
purpose instructions and QEMU’s memory management
unit.

In this work we do not extensively analyze pills that
originate from differences in kernel-space handling of
instructions, and thus cannot compare their root causes
with those speciﬁed in [19]. Due to the extensive time re-
quired for testing (reboot is required after each test case)
we leave this for future work.

Because the symbolic execution engine in [19] does
not support FPU instructions, we discover additional
root causes that are not captured by their method. First,
we ﬁnd that QEMU does not correctly update 6 ﬂags
and 8 masks in the mxcsr register when no exception
happens,
including invalid operation ﬂag, denormal
ﬂag, precision mask, overﬂow mask.
It also fails to
update 7 ﬂags in fpsw status register such as stack fault,
error summary status, and FPU busy. Second, QEMU
fails to throw ﬁve types of exceptions when it should,
which are: ﬂoat multiple traps, ﬂoat multiple faults,
access violation,
and privi-
leged instruction. Third, QEMU tags FPU registers
differently from Oracles. For example, it sets fptw tag
word to “zero” when it should be “empty”, and sets it to
“special” when “zero” is observed in Oracles. Finally,
the ﬂoating-point instruction pointer (fpip, fpipsel)
and the data pointer (fpdp, fpdpsel) are not set
correctly in certain scenarios. The details of all these
root causes are given on our Web page.

invalid lock sequence,

5.2.3

Identifying Persistent Pills

Differences found in our tests between an Oracle and a
virtual machine may not be present if we use a differ-
ent Oracle or a different virtual machine, i.e. a differ-

ence may stem more from an implementation bug spe-
ciﬁc to that CPU or VM version than from an imple-
mentation difference that persists across versions. Fur-
thermore, outdated CPUs may not support all instruction
set extensions that are available in recent ones. Finally,
recent releases of VM software usually ﬁx certain bugs
and add new features, which may both create new differ-
ences and remove the old differences between this VM
and physical machines. We hypothesize that transient
pills are not useful to malware authors because they can-
not predict under which hardware or under which virtual
machine their program will run, and we assume that they
would like to avoid false positives and false negatives.

To ﬁnd pills that persist across hardware and VM
changes, we perform our testing on multiple hardware
and VM platforms. We select 13 general instructions that
can be executed in all x86 platforms (aaa, aad, aas,
bsf, bsr, bt, btc, btr, bts, imul, mul, shld,
shrd) and generate 2,915 test cases for them to capture
more pills that are caused by modiﬁcation of undeﬁned
resources. We evaluate this set on the two physical ma-
chines (Oracle 1 and Oracle 2), three different QEMU
versions (Q2, Q3, and Q4), and Bochs. We ﬁnd 260 test
cases that result in different values in EFLAGS register
in Oracle 1 and Oracle 2 and will thus lead to transient
pills. Bochs’ behavior for these test cases is identical to
the behavior of Oracle 2. Out of the remaining 2,655 test
cases, we ﬁnd 989 persistent pills that generate different
results in the three QEMU virtual machines when com-
pared to the physical machines. They are all related to
undeﬁned resources. Bochs performs surprisingly well
and does not have a single pill for these particular test
cases. Thus we could not ﬁnd persistent pills that would
differentiate between any physical and any virtual ma-
chine in our tests but we found pills that can differentiate
between any of the QEMU VM versions and conﬁgura-
tions that we tested and any of the physical machines we
tested.

We further investigate the persistence of pills that are
caused by modiﬁcations to undeﬁned resources, across
different physical platforms. We select ﬁve physical ma-
chines with different CPU models in DeterLab [1]. Out
of 195+23 = 218 pills that were found for Oracle 1 and
Q2 (TCG) we were able to map 212 pills to all ﬁve phys-
ical machines (others involved instructions that did not

280  23rd USENIX Security Symposium 

USENIX Association

10

Category
gen
FPU

arith

data mov
gen
FPU

logic

ﬂow ctrl

misc

Q2 (TCG) Q2 (VT-x)
195/677
0/4,486
0/1,780
23/342
0/1,447
0/166
0/85

0/626
0/3,603
0/1,524
0/346
0/1,127
0/169
0/83

Bochs
194/726
0/4,245
0/1804
20/343
0/1,362
0/171
0/93

Table 5: Pills using Undeﬁned/Deﬁned Resources

Instruction

aaa

aad

aam

aas

and, or, xor, text

bsf, bsr

bt, bts, btr, btc

daa, das
div, idiv

mul, imul

rcl, rcr, rol, ror

OF
0
0
F
0
0
0
0

I
0
I
0
I

I
F

sal, sar, shl, shr shld, shrd

OF(1-bit rotation)

I
R
0

CF
0
0
F
0
0
0
0

I
0

I

SF
0
0

ZF

AF

PF

ZF (ax)
ZF (al)

PF (al + 6) or PF (al)

PF (al)

PF (al + 6 or al)

PF (al)

I
0
I

I
I
F
F

0
0

I
0
I

I
I
F
F

ZF (ax)
ZF (al)

I
I
F
0

F
0
0

0
I
F
I

I
I
0
0

I
0
F

Table 6: Undeﬁned EFLAGS Behaviors

exist in some of our CPU architectures). Fifty of those
were persistent pills—the undeﬁned resources were set
to the same values in physical machines. We conclude
that modiﬁcations to undeﬁned resources can lead to pills
that are not only numerous but also persistent in both
physical and virtual machines. This further illustrates the
need to understand the semantics of these modiﬁcations
as this would help enumerate the pills and devise hiding
rules for them without exhaustive tests.

5.2.4 Completeness of Pills

Our test cases were designed to explore effects of input
parameters on deﬁned resources. We thus claim that our
test cases cover all speciﬁed execution branches for user-
space instructions and part for kernel instructions deﬁned
in Intel manuals. Our test pills should thus include all
possible individual pills that can be detected for deﬁned
resources in user space. We cannot claim the same com-

pleteness for test pills that relate to deﬁned or undeﬁned
resources in kernel space since we do not extensively test
instructions that manipulate these resources, due to the
reboot requirement.

We now further explore the pills stemming from mod-
iﬁcations to undeﬁned resources, to evaluate their impact
on the completeness of our pill sets and to attempt to
devise semantics of these modiﬁcations. The only un-
deﬁned resources from the Intel manual are ﬂags in the
EFLAGS register.

We analyze the user-space instructions that affect one
or more ﬂags in the EFLAGS register in an undeﬁned
manner. We generate additional test cases for each in-
struction to explore the semantics of modiﬁcations to un-
deﬁned resources in each CPU. Although the exact se-
mantics differ across CPU models, we consider four se-
mantics of ﬂag modiﬁcations that are the superset of be-
haviors we observed across tested hardware and software
machines: a ﬂag might be (1) cleared, (2) remain intact,

USENIX Association  

23rd USENIX Security Symposium  281

11

(3) set according to the ALU output at the end of an in-
struction’s execution, or (4) set according to an ALU out-
put of an intermediate operation.

We run our test cases on a physical or virtual machine
in the following manner. For each instruction, we set an
undeﬁned ﬂag and execute an operation that yields a re-
sult inconsistent with the ﬂag being set; for example, ZF
is set while the result is 0.
If the ﬂag remains set we
conclude that the instruction does not modify it. Simi-
larly, we can test if the ﬂag is set according to the ﬁnal
result. If none of these tests yield a positive result, we go
through the sub-operations in a given instruction’s imple-
mentation, as deﬁned in the CPU manual, and discover
which one modiﬁes the ﬂag. For example: aaa adds 6
to al and 1 to ah if the last four bits are greater than 9
or if AF is set. The instruction affects OF, SF, ZF and PF
in an undeﬁned manner. We ﬁnd that in some machines
ZF and PF are set according to the ﬁnal result, while in
others PF is set according to an intermediate operation,
which is al = al + 6.

Table 6 shows different semantics for each instruc-
tion, which are consistent across 5 different CPU mod-
els. Empty cells represent deﬁned resources for a given
instruction. Character “I” means the ﬂag value is intact
while “F” means that the ﬂag is set according to the ﬁnal
result. Otherwise, the ﬂag is set to the value in the cell.

To detect pills between a given virtual machine and
one or many physical machines we repeat the same tests
on the virtual machine, and look for differences in in-
struction execution semantics.
If many physical ma-
chines are compared to a virtual machine we look for
such differences where physical machines consistently
handle a given instruction in a way that is different from
how it is handled in a virtual machine. For example in Ta-
ble 6, instruction aad either clears OF, AF and CF ﬂags
or sets them according to the ﬁnal result. If a virtual ma-
chine were to leave these ﬂags intact we could use this
behavior as a pill.

Our test methodology will discover all test pills (and
thus all possible individual pills) related to modiﬁcations
of undeﬁned resources by user-space instructions for a
given physical/virtual machine pair. Since the seman-
tics of undeﬁned resource modiﬁcations vary greatly be-
tween physical CPU architectures, as well as between
various virtual machines and their versions, all possible
test pills cannot be discovered in a general case.

To summarize, our testing reveals pills that stem from
instruction modiﬁcations to user-space or kernel-space
registers. These modiﬁcations can further occur on de-
ﬁned or on undeﬁned resources for a given instruction.
We claim we detect all test pills (and thus all the indi-
vidual pills) that relate to modiﬁcations of deﬁned, user-
space resources. We can claim that because we fully un-
derstand semantics of these modiﬁcations, and all phys-

ical machines we tested strictly adhere to this seman-
tics as speciﬁed in the manual. We cannot claim com-
pleteness for pills that relate to modiﬁcations of unde-
ﬁned resources because physical machine behaviors dif-
fer widely for those. We further cannot claim complete-
ness for pills that relate to modiﬁcations of kernel-space
resources because we do not properly test initialization
of these resources – such testing would require frequent
reboots and would signiﬁcantly prolong testing time.

5.2.5 Axiom Pills
In addition to comparing ﬁnal states across different plat-
forms we also compare raw states upon system loading.
We deﬁne an axiom pill as a register or memory value
whose raw state is consistently different between a phys-
ical machine and a given virtual machine. This pill can
be used to accurately diagnose the presence of the given
virtual machine. We select 15% of our test cases and
evaluate them on Oracle 2, Q2, Q3 and Bochs. The ax-
iom pills are shown in Table 7. For example, the value of
0ffffffffh in the edx register can be used to diag-
nose the presence of Q2 (VT-x).

6

Improving Virtualization Transparency

EmuFuzzer [21] deﬁnes the virtualization transparency
as how closely a virtual machine resembles the physi-
cal one. A perfect transparency means that programs
in guests must not be able to tell if they are being ex-
ecuted in a virtual machine or not. The pills we ﬁnd
reﬂect the ﬂaws of current virtual machine implemen-
tations, and speciﬁcally persistent pills reﬂect persistent
ﬂaws that can be used effectively by malware to detect
virtualization. It would thus be desirable to develop tech-
niques that hide the presence of reliable pills from mal-
ware. This could be achieved via multiple ways: (1)
through patching of the current virtual machine imple-
mentations, (2) through overwriting of values in registers
and memory with values consistent with physical ma-
chine deployment using kernel debuggers, (3) through
modiﬁcation of the guest OS so that malware reads of
registers and memory after execution of pill instructions
are intercepted and values consistent with physical ma-
chine deployment are returned (similar to kernel rootkit
functionality), (4) through modiﬁcations of the host OS.
Out of all these approaches, patching VMs or guest OS
are both time-consuming, may introduce other pills or
bugs and do not apply to closed source implementations.
Modiﬁcations to host OSes cannot hide all pills; for ex-
ample in the TCG mode of QEMU, guest code transla-
tion happens in QEMU’s user space, and the host cannot
directly inspect guest instructions to detect pill execu-
tion. We thus choose to overwrite registers and memory

282  23rd USENIX Security Symposium 

USENIX Association

12

Reg
edx
dr6
dr7
cr0
cr4
gdtr
idtr

O1

vary
0ffff0ff0h
400h
8001003bh
406f9h
vary
vary

Q1 (TCG)
vary
0
0
8001003bh
6f8h
80b95000h
80b95400h

Q2 (TCG)
vary
0
0
8001003bh
6f8h
80b95000h
80b95400h

Q1 (VT-x)

Q2 (VT-x)

Bochs

0ffffffffh
0ffff0ff0h
400h
8001003bh
6f8h
80b95000h
80b95400h

0ffffffffh
0ffff0ff0h
400h
8001003bh
6f8h
80b95000h
80b95400h

vary
0ffff0ff0h
400h
0e001003bh
6f9h
80b95000h
80b95400h

Table 7: Axiom Pills

after pill instructions.

This overwriting can either happen in the virtual ma-
chine, through modiﬁcation of VM code, or it could be
performed by the same environment that is used for mal-
ware analysis, e.g. Anubis or Ether. We explore the
ﬁrst strategy here. We select QEMU TCG mode as our
experiment platform since it has gained great popular-
ity [6, 24, 4, 12]. We ﬁrst explain how QEMU handles
guest code translation and then describe how we inte-
grate our pill hiding strategy into its translation code.

l
o
n
g
j
m
p
(
e
n
v
-
>
j
m
p
_
e
n
v
,
 
1
)

③

1 for (;;)
2   if (setjmp(env->jmp_env) == 0)
3     if (env->exception_index >= 0)
4       do_interrupt()
5     for (;;)
6       if (likely(!env->exit_request))
7         tcg_qemu_tb_exec(env, tc_ptr)
8   else
9     env = cpu_single_env

Translated host code:

TCG translates guest

6.1 The Underhood of QEMU with TCG
Figure 4 describes two pivotal functionalities of QEMU:
how TCG uses translation blocks to organize translated
host code (x86 guest to x86 64 host in the example) and
how QEMU executes translation blocks. A translation
block is a consecutive memory of a few kilobytes located
in a data segment, which consists of translated host code,
prologue, and epilogue. It provides a full function layout
as if generated from a compiler. As the name implies, the
translated host code section stores host opcode generated
by TCG, which acts as a function body. The prologue
prepares the stack and registers for use within the func-
tion, while the epilogue restores the stack and registers
to the state they were in before the function was called.
instructions in two different
ways. Simple guest instructions are mapped to host
opcode directly; for example in Figure 4,
the guest
instruction mov al, 8 is transformed to three host
instructions.
the
opcode level without disassembling and compilation.
For complex guest instructions, TCG uses helper func-
tions to implement their semantics. For example, the
guest int instruction will be replaced by a call to
helper raise int(). Inside this function, QEMU
checks the current CPU mode and then dispatches the
interrupt. In dispatching, QEMU calculates the destina-
tion vector in the interrupt description table that should
be selected. After the desired interrupt service routine
is found, QEMU sets the guest code segment selec-
tor, offset, and instruction pointer, such that the guest
will enter interrupt handling immediately after QEMU

translation operates at

The actual

②

Prologue:

Epilogue:

mov al, 8
(guest code)

mov rbx, r14
mov ecx, 8h
mov bl, cl
...
mov r10, 555555871618h
call r10 ; helper_raise_int()
jmp to epilogue

…

push registers
save env
jmp to tc_ptr

shrink space in stack
pop registers
return

Translation Block

①

④

Figure 4: QEMU with TCG Translation and Execution.

yields control to the guest. Typically, QEMU stops trans-
lation if it encounters an int in the guest code, and
helper raise int() will be the last instruction in
a translation block in this case.

We summarize QEMU’s main execution loop in lines
1–9 in Figure 4. It attempts to deliver all pending inter-
rupts and exceptions and then ﬁnds the next translation
block to execute. It takes advantage of the setjmp()
and longjmp() facility provided by the C standard
library to implement non-local jumps. At line 2, the
QEMU context is saved to jmp env by setjmp().
If this statement is actively called in place, line 3 will
be examined and any pending interrupts and exceptions
will be handled here. Otherwise, if the program ﬂow
returns here from a longjmp(), line 9 will be exe-
cuted to reload CPU environment; then line 1 starts the
next iteration. Lines 5–7 denote an inﬁnite loop inside
which QEMU repeatedly ﬁnds and executes translation
blocks if no exception occurs. The function at line 7
is deﬁned as a function pointer that is assigned to the

USENIX Association  

23rd USENIX Security Symposium  283

13

memory address of the prologue. At run-time, the pro-
logue is cast as a function and executed (x) with pa-
rameters env and tc ptr. The code bytes in the pro-
logue save the current context and arguments to the stack.
Then the program control will be transferred to the gen-
erated host code pointed to by tc ptr (y). If the guest
code contains an interrupt, the execution ﬂow will fol-
low the helper raise int() function generated by
TCG (z); otherwise, this translation block will ﬁnish ex-
ecution and step { is selected. In the ﬁrst case, the helper
function raises an interrupt with the vector number in
the guest code, through setting of the corresponding data
structures in QEMU. Then it calls longjmp() to jump
to the latest context saved by setjmp(), so this func-
tion never returns. When executing line 2 following z,
the condition is not satisﬁed because setjmp() returns
the argument 1 of longjmp(). Therefore, lines 3 – 4
will not be executed and the interrupt will not be repeat-
edly handled, which achieves the exact interrupt seman-
tics. When the execution runs into the next round of the
outside for loop, this pending interrupt will be handled
in do interrupt().

6.2 Pill Hiding
Our proposed pill hiding strategy goes through three
main stages: 1) detect pill instructions in the guest; 2)
freeze the guest after the corresponding host code for
the guest instruction has been executed; and 3) overwrite
register and memory values using correct information
learned from physical machines.

To detect pills, we need to compare the guest code with
known pill instructions in run time. This can be achieved
using either mnemonics or opcode. We choose the ﬁrst
approach since QEMU has a built-in disassembler.

To freeze the guest at the right point, we need to build
a communication mechanism between QEMU and the
guest. Debuggers achieve a similar functionality by re-
placing user-deﬁned breakpoints with interrupt instruc-
tions. We cannot apply the same approach by inserting
interrupts into translated code, since it will cause a trap
between QEMU and the host instead. Actually, this is
the reason why TCG needs to replace the guest interrupts
with a call to the helper function as discussed in the pre-
vious subsection. To address this problem, we modify
the QEMU’s translation mechanism and utilize its inter-
rupt handling mechanism as shown in Figure 5.

We monitor each guest instruction at line 1 by disas-
sembling the current instruction in pc ptr. If this in-
struction is not a pill, we directly translate it at line 11.
If it is a pill, we check if the state before this instruction
is saved. If not, this is the ﬁrst time we encounter this
instruction and we generate a 0x20 interrupt, otherwise
we generate a 0x21 interrupt. Neither of these inter-

if (saved == false)

1 curr_insn = disas(pc_ptr)
2 if (curr_insn is pill)
3
4
5
6
7
8
9

gen_int(0x20)
saved = true

else

// save states

pc_ptr = trans(pc_ptr)
gen_int(0x21)
saved = false

// apply hiding rules

10 else
11

pc_ptr = trans(pc_ptr)

Figure 5: Hooking on QEMU Translation

rupt values are used by Windows. Generation of an in-
terrupt calls helper raise int() in Figure 4 which
brings the control to do interrupt() as it does for
other interrupt vectors. In this function we add new inter-
rupt handlers for 0x20 and 0x21 interrupts. The han-
dler for 0x20 saves the system state. The handler for
0x21 applies the hiding rules by overwriting the regis-
ters and memory with the values that a physical machine
would set. The hiding rules can be devised by grouping
pill instructions based on the resource that is the symp-
tom of the pill (it is different in the physical and the vir-
tual machine) and input parameter ranges. For example,
we ﬁnd 61 FPU instructions that always raise exceptions
different from Oracles if their operands are in speciﬁc
value ranges. When we detect these instructions and their
operands fall in these speciﬁc ranges, we can raise the
exceptions that occur in the Oracles. This would handle
around 1,500 pills. Thus we can hide the presence of the
pills without reimplementing instruction semantics. We
emphasize here that only pills whose symptoms are not
kernel registers can be hidden by our approach.

7 Conclusion

Virtualization is crucial for malware analysis, both for
functionality and for safety. Contemporary malware tests
if it is being run in VMs and applies evasive behaviors
that hinder its analysis. Existing works on detection and
hiding of differences between virtual and physical ma-
chines apply ad-hoc or semi-manual testing to identify
these differences and hide them from malware.

In this paper we propose Cardinal Pill Testing that re-
quires moderate manual action to identify ranges for in-
put parameters for each instruction in a CPU manual,
but then automatically that devises tests to enumerate the
differences between a physical and a virtual machine.
This testing is much more efﬁcient and comprehensive
than state-of-the-art Red Pill Testing. It ﬁnds ﬁve times
more pills running ﬁfteen times fewer tests. We further
claim that for user-space instructions that affect deﬁned
resources, Cardinal Pill testing identiﬁes all test pills that

284  23rd USENIX Security Symposium 

USENIX Association

14

could be used to generate all possible individual pills.
Other categories contain instructions whose behavior is
not fully speciﬁed by the Intel manual, which has led to
different implementations of these instructions in physi-
cal and virtual machines. Such instructions need under-
standing of the implementation semantics to enumerate
all the pills and devise the hiding rules. Our future work
will focus on this direction. Yet other pills we have dis-
covered stem from instructions that modify kernel-level
resources. We do not properly test the initialization of
these instructions because that would require reboot of
machines and would be too time-consuming. Thus, we
cannot claim completeness for pills that relate to kernel-
level resources. We plan to test these extensively in our
future work.

Acknowledgments

This material is based upon work supported by the De-
partment of Homeland Security, and Space and Naval
Warfare Systems Center, San Diego, under Contract No.
N66001-10-C-2018. Any opinions, ﬁndings, and conclu-
sions or recommendations expressed in this material are
those of the author(s) and do not necessarily reﬂect the
views of the Department of Homeland Security for the
Space and Naval Warfare Systems Center, San Diego.

References
[1] BAJCSY, R., BENZEL, T., BISHOP, ET AL. Cyber Defense Tech-
nology Networking and Evaluation. Commun. ACM 47, 3 (2004).
[2] BALZAROTTI, D., COVA, M., KARLBERGER, C., ET AL. Efﬁ-
cient Detection of Split Personalities in Malware. In Network and
Distributed System Security (NDSS) (2010).

[3] BARFORD, P., AND BLODGETT, M. Toward Botnet Mesocosms.
In Proceedings of the First Conference on First Workshop on Hot
Topics in Understanding Botnets (HotBots) (2007).

[4] BAYER, U., KRUEGEL, C., AND KIRDA, E. TTAnalyze: A
Tool for Analyzing Malware. In European Institute for Computer
Antivirus Research (EICAR) Annual Conference (2006).

[5] BELLARD, F. QEMU, a Fast and Portable Dynamic Translator.

In USENIX ATC (2005).

[6] BitBlaze: Binary Analysis for Computer Security. http://

bitblaze.cs.berkeley.edu/.

[7] BRANCO, R. R., BARBOSA, G. N., AND NETO, P. D. Scien-
tiﬁc but Not Academical Overview of Malware Anti-Debugging,
Anti-Disassembly and Anti-VM Technologies.
In Black Hat
(2012).

[8] CHEN, X., ANDERSEN, J., MAO, Z., ET AL. Towards an Under-
standing of Anti-virtualization and Anti-debugging Behavior in
Modern Malware. In IEEE International Conference on Depend-
able Systems and Networks with FTCS and DCC (DSN) (2008).
[9] DINABURG, A., ROYAL, P., ET AL. Ether: Malware Analysis
In Proceedings of the
via Hardware virtualization Extensions.
15th ACM Conference on Computer and Communications Secu-
rity (CCS) (2008).

[10] FERRIE, P.

Anti-Unpacker Tricks.

http://vpn23.

homelinux.org/Anti-Unpackers.pdf.

[11] FERRIE, P. Attacks on Virtual Machine Emulators. Symantec

Security Response (2006).

[12] GOOGLE.

Android Emulator.

http://developer.

android.com/tools/devices/emulator.html.

[13] INTEL.

Intel

64

IA-32 Architectures

and
ware Developers Manuals.
com/content/www/us/en/processors/
architectures-software-developer-manuals.
html.

Soft-
http://www.intel.

[14] JOHN, J. P., MOSHCHUK, A., GRIBBLE, S. D., ET AL. Study-
ing Spamming Botnets Using Botlab. In Proceedings of the 6th
USENIX Symposium on Networked Systems Design and Imple-
mentation (NSDI) (2009).

[15] KANG, M. G., YIN, H., HANNA, S., ET AL. Emulating
Emulation-resistant Malware. In Proceedings of the First ACM
Workshop on Virtual Machine Security (VMSec) (2009).

[16] KREIBICH, C., WEAVER, N., ET AL. GQ: Practical Contain-
ment for Measuring Modern Malware Systems. In Proceedings
of the 2011 ACM SIGCOMM Conference on Internet Measure-
ment Conference (IMC) (2011).

[17] LAWTON, K. P. Bochs: A Portable PC Emulator for Unix/X.

Linux Journal, 29es (1996).

[18] LINDORFER, M., KOLBITSCH, C., AND MILANI COM-
PARETTI, P. Detecting Environment-Sensitive Malware. In Pro-
ceedings of the 14th International Conference on Recent Ad-
vances in Intrusion Detection (RAID) (2011).

[19] MARTIGNONI, L., MCCAMANT, S., POOSANKAM, P., SONG,
D., AND MANIATIS, P. Path-exploration Lifting: Hi-ﬁ Tests for
Lo-ﬁ Emulators. In Proceedings of the 17th International Confer-
ence on Architectural Support for Programming Languages and
Operating Systems (ASPLOS) (2012), pp. 337–348.

[20] MARTIGNONI, L., PALEARI, R., FRESI ROGLIA, G., ET AL.
Testing System Virtual Machines. In Proceedings of the 19th In-
ternational Symposium on Software Testing and Analysis (ISSTA)
(2010).

[21] MARTIGNONI, L., PALEARI, R., ROGLIA, G. F., ET AL. Test-
In Proceedings of the 18th International

ing CPU Emulators.
Symposium on Software Testing and Analysis (ISSTA) (2009).

[22] P ´EK, G., BENCS ´ATH, B., AND BUTTY ´AN, L. nEther: In-guest
Detection of Out-of-the-guest Malware Analyzers. In Proceed-
ings of the Fourth European Workshop on System Security (Eu-
roSec) (2011).

[23] SONG, C., ROYAL, P., AND LEE, W. Impeding Automated Mal-
ware Analysis with Environment-Sensitive Malware. In Proceed-
ings of the 7th USENIX Conference on Hot Topics in Security
(HotSec) (2012).

[24] SONG, D., BRUMLEY, D., YIN, H., CABALLERO, J., JAGER,
I., KANG, M. G., LIANG, Z., NEWSOME, J., POOSANKAM, P.,
AND SAXENA, P. BitBlaze: A New Approach to Computer Secu-
rity via Binary Analysis. In Proceedings of the 4th International
Conference on Information Systems Security. Keynote invited pa-
per. (Hyderabad, India, Dec. 2008).

[25] SUN, M.-K., LIN, M.-J., CHANG, M., ET AL. Malware
Virtualization-Resistant Behavior Detection. In Proceedings of
the 2011 IEEE 17th International Conference on Parallel and
Distributed Systems (ICPADS) (2011).

[26] YAN, L.-K., JAYACHANDRA, M., ZHANG, M., ET AL. V2E:
Combining Hardware Virtualization and Software Emulation for
Transparent and Extensible Malware Analysis. In Proceedings of
the 8th ACM SIGPLAN/SIGOPS Conference on Virtual Execution
Environments (VEE) (2012).

USENIX Association  

23rd USENIX Security Symposium  285

15

