Characterizing Smartphone Usage Patterns

from Millions of Android Users

Huoran Li, Xuan Lu, Xuanzhe Liu ‡
{lihuoran, luxuan, xzl}@pku.edu.cn

Peking University

Tao Xie

University of Illinois
Urbana-Champaign
taoxie@illinois.edu

Kaigui Bian

Peking University
bkg@pku.edu.cn

Felix Xiaozhu Lin
Purdue University
xzl@purdue.edu

Qiaozhu Mei

University of Michigan
qmei@umich.edu

Feng Feng
Wandoujia Lab

jackfeng@wandoujia.com

ABSTRACT
The prevalence of smart devices has promoted the popular-
ity of mobile applications (a.k.a. apps) in recent years. A
number of interesting and important questions remain unan-
swered, such as why a user likes/dislikes an app, how an app
becomes popular or eventually perishes, how a user selects
apps to install and interacts with them, how frequently an
app is used and how much traﬃc it generates, etc. This
paper presents an empirical analysis of app usage behaviors
collected from millions of users of Wandoujia, a leading An-
droid app marketplace in China. The dataset covers two
types of user behaviors of using over 0.2 million Android
apps, including (1) app management activities (i.e., installa-
tion, updating, and uninstallation) of over 0.8 million unique
users and (2) app network traﬃc from over 2 million unique
users. We explore multiple aspects of such behavior data
and present interesting patterns of app usage. The results
provide many useful implications to the developers, users,
and disseminators of mobile apps.

Categories and Subject Descriptors
D.4.8 [Operating Systems]: Performance—Measurement;
Modeling and Prediction; D.2.8 [Software Engineering]:
Metrics—complexity measures, performance measures

General Terms
Performance, Measurement

Keywords
Android apps; app management; app popularity; app per-
formance; app stores.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
IMC’15, October 28–30, 2015, Tokyo, Japan.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3848-6/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2815675.2815686.

1.

INTRODUCTION

The release of iPhone in 2007 has opened a new era of
mobile computing. Eight years later, smart devices such as
iPhones and Android devices have played an indispensable
role in our daily lives. The increasing popularity of mobile
devices and apps has induced an evolution of software in-
dustry. The emergence of online marketplaces and platform
APIs has been a game changer to developers, market in-
termediaries, and consumers, making them more and more
willing to develop, disseminate, and use mobile apps rather
than Web-based services [24].

The prevalence of mobile apps has also generated a huge
volume of app usage data. Understanding user behaviors
of using mobile apps is meaningful to all the stakeholders
mentioned above. For example, marketplace operators can
identify popular or problematic apps and provide eﬀective
app recommender systems; developers can understand why
their apps are liked or disliked by the users and therefore
improve the app design; end-users can have a better knowl-
edge of how particular apps are consuming their time and
bandwidth, and therefore optimize their decisions of select-
ing apps. Due to the lack of a sizable repository of such
behavioral data, most of these important questions remain
unanswered.

Previous studies have shown evidence about diﬀerent users
having diﬀerent patterns of using mobile apps [19, 23, 7, 1].
Most of these studies were conducted using rather small be-
havior datasets, typically collected from a small number of
student volunteers. The analyses also suﬀer from various
selection biases introduced by college students.

Moreover, most behavioral signals were collected through
a monitoring app voluntarily installed on the subjects’ de-
vices. Such a design is diﬃcult to be applied by the variety
of crowd due to the security and privacy concerns. As a
result, very few studies could scale up to millions of users.

We present a comprehensive analysis of app usage behav-
iors collected from millions of Android users1. Our data
comes from a leading Android app marketplace in China,

1All users involved in our dataset are anonymized by removing
the identiﬁers. A sample of dataset has been released on DatCat.
Researchers can search over DatCat by the title of this paper or
directly access our server http://45.56.95.4/description.html.
Contact the corresponding author: xzl@pku.edu.cn for technical
issues.

459called Wandoujia2. Similar to other app marketplace op-
erators in China, such as Baidu, 360Safe, and Tencent, Wan-
doujia provides its own management app that facilitates
users to search, browse, download, install, update, and unin-
stall apps. Once being launched, the Wandoujia manage-
ment app runs as a background system-level service without
requiring the “root” privilege. It also provides the user op-
tion to collect network activity information of each app on
device, e.g., data traﬃc and access time under diﬀerent net-
works.

The dataset that we study covers over 0.2 million (260,172)
Android apps. The data mainly contains two types of user
behaviors: (1) app management activities (i.e., installation,
updating, and uninstallation) of over 0.8 million (8,112,145)
unique users; (2) app network usage of 2 million (2,031,007)
unique users. Based on this dataset, we conduct a system-
atic descriptive analysis that includes the distributions of
app popularity, possible reasons of app selection, life cycles
of abandoned apps, ﬁne-grained network analysis of apps,
and the impact of economic factors on app usage.

To the best of our knowledge, our work is the ﬁrst de-
scriptive analysis of millions of users of Android market-
places. Although most users are Chinese, the usage pat-
terns learned from the millions could generalize to other
populations. Based on such a new dataset, we not only
validate some conclusions from previous eﬀorts, but also ex-
plore some new knowledge of user behaviors on app usage.
The paper aims to answer the following questions:

• How can we characterize the app popularity
among millions of users? Compared to previous
studies that mainly investigated app popularity by down-
loads [17], we explore the app popularity from vari-
ous aspects, including the monthly downloads of an
app, the number of unique devices an app was in-
stalled on, the network traﬃc of an app, and the net-
work access time of an app. Distributions of all these
aspects comply with the Pareto principle [14], i.e., a
small portion of apps account for substantial popular-
ity. These ﬁndings can help marketplace operators and
network providers improve their workloads for serving
the most popular apps, and organize eﬃcient caching
or prefetching mechanisms to enable fast downloads
and delivery of these popular apps.

• How do mobile users choose and manage apps?
Compared to previous studies that usually examined
the co-installed apps [24, 17], we further explore why
the apps are installed and how soon they are likely to
be uninstalled. We try to understand the possible rea-
sons for co-installing apps, i.e., apps provided by the
same vendor/developer or with similar functional-
ities are more likely to be installed together. We ﬁrst
study the uninstallation patterns of apps by devising a
new metric called the temporal installation/uninstallation
ratio to indicate how much an app is likely to be aban-
doned. These ﬁndings can help app marketplace oper-
ators improve their recommendation systems.

• How do diﬀerent apps perform in network ac-
tivity? Compared to previous studies [25, 24, 7], our
network analysis is conducted at ﬁne granularity. We

2http://www.wandoujia.com

study the network activities in terms of the data traﬃc
and the access time under Wi-Fi and cellular, respec-
tively. We further investigate where the network activ-
ity occurs (foreground or background). Besides iden-
tifying some “network intensive” apps, we ﬁnd apps
that may “suspiciously” keep continuous network con-
nections or consume traﬃc at the background. For
example, it is surprising that some tools, such as ﬂash-
light apps and namecard apps, generate unexpected
background traﬃc against their main purposes. We
are also surprised to ﬁnd that a large number of apps
keep long-lived TCP connections at the background
after they are launched. These ﬁndings can help mar-
ketplace operators to locate some “problematic” apps,
and help users choose alternative apps to reduce po-
tential threats caused by these apps.

• How do economic factors aﬀect app selection
and network usage? Compared to previous stud-
ies that relied on free/paid apps to measure economic
factors [23], our study is performed in a quite diﬀerent
way. Based on the hypothesis that the price of a device
model can reﬂect the user’s ﬁnancial background, we
classify users into diﬀerent groups according to their
device models. We make the ﬁrst report on how device
models impact the apps selection and data traﬃc, e.g.,
users with lower-end device models tend to use local
or less network-intensive apps. Based on our ﬁndings,
app marketplace operators can make more accurate
app recommendations, and app developers can target
speciﬁc user groups to optimize user experiences.

The remainder of this paper is organized as follows. Sec-
tion 2 describes the dataset. Sections 3-6 describe the in-
ferred app usage patterns in four aspects, app popularity
patterns, management patterns, network patterns, and price-
sensitive patterns, respectively. Section 7 summarizes the
ﬁndings and implications to diﬀerent stakeholders. Section
8 discusses the threats to validity. Section 9 makes com-
parisons with related work, and Section 10 concludes the
paper.

2. DATASET

In this section, we brieﬂy introduce the Wandoujia mar-
ketplace and describe the features of our dataset collected
by the Wandoujia management app. To protect the user pri-
vacy and assure the ethnics of our research, we also discuss
how the data is processed.
2.1 Wandoujia

Our data is from Wandoujia3, a free Android app mar-
ketplace in China. Wandoujia was founded in 2009 and has
grown to be a leading Android app marketplace. Like other
marketplaces, third-party app developers can upload their
apps to Wandoujia and get them published after authen-
ticated. Compared to other marketplaces such as Google
Play, apps on Wandoujia are all free, although some apps
can still support “in-app purchase”.

Users have two channels to access the Wandoujia market-
place, either from the Web portal, or from the Wandoujia
management app. The Wandoujia management app is a na-
tive Android app, by which people can manage their apps,
3Visit its oﬃcial site via http://www.wandoujia.com.

460or updated via the Wandoujia management app, its instal-
lation counter is automatically increased by one and a log
entry of this activity is created. The logs of uninstallation
via the Wandoujia management app are processed in a sim-
ilar way. In the Wandoujia management app, collecting app
management activities is always enabled.

In our one-month data, we collected the management ac-
tivity logs from 8,112,145 unique users (devices in fact).
We denote the dataset as “Universal User Set”. The logs
of management activities are used to explore an app’s pop-
ularity, and can implicitly reﬂect the app’s quality.

2.2.2 Network Activities
When the advanced features are enabled, the Wandoujia
management app collects daily network statistics of each
app, if the app generates network connections either from
Wi-Fi or cellular (2G/3G/LTE). However, if an app is never
launched or generates no network connections, the app is
not recorded in the network statistic logs.

To reduce the overhead of runtime monitoring, the Wan-
doujia management app does not record network details of
each session of an app.
Instead, it summarizes the total
daily traﬃc and access time of an app by examining ﬂows
at the TCP level. The traﬃc and access time are captured
for Wi-Fi and cellular, respectively.

In particular, the traﬃc and access time generated from
foreground and background are treated separately. The
Wandoujia management app determines whether an app
is running at “foreground” by probing the Android system
stack for every 2 seconds.
In this way, the “foreground”
access time can imply how long the user interacts with an
app. The Wandoujia management app checks whether an
app running at “background” every 2 minutes. If any net-
work activity is detected during this interval, this app is
regarded to be “online” and its “background” access time is
increased by 2 minutes. Such time interval is reasonable to
initiate and release a TCP connection.

In summary, the statistic of network activity provides 8
combinations of information, i.e., 2 metrics (access time
and traﬃc) * 2 modes (Wi-Fi and Cellular) * 2 states (fore-
ground and background).

As the statistic of network activity is an optional fea-
ture for end-users, the covered users are a subset of the
“Universal User Set”. We take into account only the users
who successively contributed the statistics for more than 3
weeks. In our one-month dataset, the network activity cov-
ers 2,031,007 unique users. We denote such a dataset as
“Networked User Set”.

2.2.3 Device Models and Price
The Wandoujia management app also records the model
information of each device, e.g., Samsung Galaxy Note 2,
Google Nexus. We leverage the device models to classify
users. Finally there are 12,091 diﬀerent device models in
total. Such a result implies the heavy fragmentation of An-
droid devices. To better organize these models, we collected
their listing price information when they were ﬁrstly put
onto market.
2.3 User Privacy

We took a series of steps to preserve the privacy of in-
volved users in our dataset. First, all raw data collected for
this study was kept within the Wandoujia data warehouse

(a)

(b)

(c)

Figure 1: Screenshots of advanced settings in the Chinese
version of the Wandoujia management app (the advanced
settings is not supported in the current English version). (a)
is the homepage of the Wandoujia management app, where
users can navigate to “settings” by clicking the text circled
by red; (b) refers to the background management service set-
ting, which is highlighted by the red rectangle; (c) is to toggle
whether to allow Wandoujia to collect the data of network
activities.

e.g., downloading, searching, updating, and uninstalling apps.
The logs of these management activities are all automati-
cally recorded.

Beyond these basic features, the Wandoujia management
app is developed with some advanced but optional features
that can monitor and optimize a device. These features
include network activity statistics, permission monitoring,
content recommendation, etc. All features are developed
upon Android system APIs and do not require “root” priv-
ilege. Users can decide whether to enable these features, as
shown in Figure 1. However, these features are supported
only in the Chinese version.

The Wandoujia management app is automatically launched
and it works as a system-wide service after the device that
installs the app starts up. The data collected on each device
is uploaded to the Wandoujia server every day.
2.2 Data Collection

As of 2015, Wandoujia has over 250 million users. Each
user is actually associated with a unique Android device,
which could be either a smartphone or tablet computer. In
the study of this paper, we collected one-month usage data
from August 4, 2013 to September 2, 2013. The volume of
our data set is 1.2 TB.

Our one-month dataset covers more than 0.2 million (260,172)

Android apps. The data of user behaviors consists of two
types: (1) the data of app management activities (i.e.,
installation, update, and uninstallation) (2) the data of
app network usage (i.e., the traﬃc and access time per
app).

2.2.1 App Management Activities
App management activities consist of downloading4, up-
dating, and uninstalling apps. When an app is installed

4In the Wandoujia management app, a pop-up of installa-
tion wizard is presented to users when an app is downloaded.
So we treat “download” and “installation” equally.

461(a) Percentage of Downloads
against App Rank

(b) Downloads of an App

(a) Percentage of Unique
Subscribers
against App
Rank

(b) Unique Subscribers of an
App

Figure 2: App Popularity by Downloads

Figure 3: App Popularity by Unique Devices

servers (which live behind a company ﬁrewall). Second, our
data collection logic and analysis pipelines were completely
governed by three Wandoujia employees5 to ensure compli-
ance with the commitments of Wandoujia privacy stated in
the Term-of-Use statements. Finally, the Wandoujia em-
ployees anonymized the user identiﬁers. The dataset in-
cludes only the aggregated statistics for the users covered
by our study period.

3. APP POPULARITY

In this section, we make a macro-level analysis on app
distribution.
In most previous studies [17, 19], apps are
usually ranked by their number of downloads on the mar-
ketplaces. To make a comprehensive analysis, we use four
metrics: (1) the number of downloads of the app;
(2) the number of unique devices that download the
app; (3) the aggregated data traﬃc generated by the
app; (4) the aggregated access time that users inter-
act with the app. The former two metrics can indicate
how many users an app has, and the latter two can indicate
how much an app is really used.
3.1 Popularity by Downloads

First, we investigate the most intuitive metric of app pop-
ularity, i.e., the number of downloads of an app. Most app
stores take the number of downloads (i.e., total, monthly,
or weekly) as an indicator to rank app popularity. We then
investigate the app downloads from the management activ-
ities of the Universal User Set. It is a common observa-
tion that people often update their installed apps. Hence,
we compute total downloads of an app by aggregating its
number of downloads and updates in our dataset.

Various evidence reports that the Pareto principle exists in
networked application domains such as web content, audio,
and video downloads [14], i.e., 20% of the objects account
for 80% downloads. Figure 2(a) shows that the cumulative
distribution function (CDF) of the percentage of app down-
loads against the app ranking by downloads. The results
show that the app downloads follow the Pareto principle.
For example, 10% apps account for 96.2% downloads of all
apps. Such ﬁnding validates a similar distribution of app
downloads reported previously [17].

We also explore the distributions of downloads of each
app. Figure 2(b) indicates that about 80% apps are down-
loaded or updated less than 10 times in our one-month dataset.

5One co-author, Feng Feng, is a co-founder and current CTO
of Wandoujia. He supervised the process of data collection
and de-identiﬁcation.

A substantially large number of apps are downloaded, up-
dated, or uninstalled only once. Such ﬁnding indicates a
“long-tail ” of apps that are rarely active.
3.2 Popularity by Unique Subscribers

Although the number of downloads of an app is a natural
indicator for popularity, it is also possible that some apps
are frequently downloaded or updated due to “fraud” be-
havior. For example, apps can be downloaded and updated
by automated programs to increase their ranks on market-
places. To validate whether the “mostly downloaded apps”
also have more users, we aggregate the unique subscribers
(devices) that ever downloaded, updated, or uninstalled an
app. Compared to the number of downloads of an app, each
device is counted only once as a subscriber. Figure 3(a)
shows that the CDF of the percentage of unique subscribers
against app ranking by downloads. We can ﬁnd that the
distribution of subscribers of an app still complies with the
Pareto principle, i.e., about 10% apps account for 95.1%
users. In this way, we could conclude that the more an
app is downloaded, the more users it usually owns.
Meanwhile, we explore how many users an app owns in
Figure 3(b). It shows that about 80% apps have been in-
stalled, updated, or uninstalled by only less than 10 unique
devices.

However, it is observed that some apps may have high
downloads but rather limited users/devices. We ﬁnd that
one app used by only 4 unique subscribers has 973 down-
loads in one month. We further explore its download logs,
and ﬁnd that its downloading actions were all performed in
a quite short interval (within two days). There are two pos-
sible reasons. One is that all of the 4 devices (subscribers)
are testing devices used by the app developers. The other is
that the app developers may purposely increase the down-
loads. Although such kind of apps is rare, the number
of their downloads may mislead end-users or even
bring threats.
3.3 Popularity by Network Trafﬁc

Either downloads or unique devices of an app can just
indicate that an app is downloaded and installed. However,
we cannot judge whether the app is really used by users.
Not surprisingly, mobile users may never use an app
after ﬁrst launching it, but do not uninstall it either.
From the logs of the Networked User Set, an app cannot
generate network logs if it is never launched by users. Hence,
we employ the network activities to examine whether the
app is really used. Although we may miss some apps that

462(a) Percentage
against App Rank

of Traﬃc

(b) Traﬃc of an App

Figure 4: App Popularity by Data Traﬃc

(a) Percentage
Time against App Rank

of Access

(b) Access Time of an App

Figure 5: App Popularity by Access Time

are usually used oﬄine, e.g., PDF readers or dictionaries,
most of currently popular apps heavily rely on network and
can be covered.

For better illustration, we distinguish Wi-Fi, Cellular, and
All (Wi-Fi + Cellular) of each app. The data traﬃc comes
from both foreground and background. In contrast, we take
into account only the access time from foreground, because
such time indicates how long users really interact with the
app.

Figure 4(a) and Figure 5(a) illustrate the CDF of the per-
centage of aggregated traﬃc/access time of apps against app
ranking by downloads, respectively. We can ﬁnd that the
Pareto principle still holds for the network activities of apps.
We also show the aggregated data traﬃc/access time of
an app in Figure 4(b) and Figure 5(b), respectively. We can
observe that about 97% apps consume less than 100 MB
traﬃc volume in one month, and about 95% apps are used
less than 100 hours.
3.4 Summary

From the preceding macro-level analysis of popularity, we
can conclude that the app popularity generally complies
with the Pareto principle in terms of downloads, unique
users, data traﬃc, and access time. This ﬁnding not only
validates results reported in previous studies [24, 17], but
also helps marketplace operators and network providers iden-
tify the “real” popular apps that are frequently downloaded,
updated, and used. To make the apps fast delivered to end-
users, the marketplace operators can leverage this distribu-
tion to allocate resources for serving these apps, design eﬃ-
cient cache mechanisms, or quickly redirect user requests to
the app providers. Knowing which apps are more adopted
by users, network providers can provide better bandwidth,
cache/prefetch contents to users, or explore value-added ser-
vices such as advertisements to increase revenue.

Figure 6: Distribution of Diurnal App Management
Activities. Each point on the cureve represents the per-
centage of activities performed during the one-hour time in-
terval against the total activities, during the whole day. For
example, activities during 10:00 am-11:00 am account
for about 6% of all activities.

4. APP MANAGEMENT PATTERNS

In this section, we investigate how users manage their
apps, e.g., which apps they often install and when they in-
stall these apps, which apps are more likely to be uninstalled,
and why these apps are uninstalled by users.
4.1 Diurnal Management Patterns

App management activities include downloading, updat-
ing, and uninstalling apps. Exploring app management ac-
tivities is motivated for various reasons. As app manage-
ment activities are usually made manually, they can implic-
itly reﬂect the density and frequency of user interactions
with the devices. For marketplace operators, this informa-
tion can help them understand when a large number of con-
current user requests would arrive, so that the marketplace
operators can optimize their servers for faster and more re-
liable network bandwidth. For app developers, they can
leverage such information to publish the latest versions of
apps at a proper time, to attract more downloads and up-
dates.

We investigate the diurnal downloading, updating, and
uninstallation distribution. We aggregate activities of down-
loading and updating an app, because they both reﬂect the
users’ interest towards this app. As shown in Figure 6, the
app management activities are “periodically” per-
formed during a day. The extent of app downloading and
updating activities keeps growing from 6:00 am and reaches
the ﬁrst peak around 11:00 am. The downloading and up-
dating activities decline slightly between 11:00 am to 12:00
pm. It is not very surprising because users may take lunch
at this time. The same observation could be found between
4:00 pm to 6:00 pm, i.e., the time on the way back home
or at dinner. We can also ﬁnd that about 32% download-
ing and updating activities are performed during 7:00 pm to
11:00 pm, where they reach the maximum around 9:00 pm.
Such distribution is quite consistent with human regularity.
After 9:00 pm, the downloading and updating activities de-
cline quite sharply, and reach the minimum around 5:00 am.
However, at the midnight, downloading and updating activ-

463Figure 7 shows the Jaccard Similarity Coeﬃcient of
the top-N apps, where N varies from 100 to 4,000. With
the increasing the number of N , the CDF of λ indicates that
there are a very small fraction of apps being co-installed
together. The λ of 90% app pairs is lower than 0.1, if both
appm and appn have 2,000 unique devices. Given the λ
value of 0.1, appm and appn share only 200 unique devices.
In contrast, we focus on the app pairs that take a higher
value of λ, and explore why these apps are more likely
to be installed together. We choose the pairs whose λ is
more than 0.1. Rather than exploring the detailed textual
descriptions of the apps, we focus on two properties vendor
and category.

The vendor information of an app can reﬂect the devel-
oper, provider, or owner of the app. Usually, the naming
rules of an Android app can reﬂect its vendor information.
For example, the package com.tencent.mm can be processed
by removing the general term “com” and the usage term “mm”,
and the vendor information “tencent” is extracted. By clus-
tering the vendors, we ﬁnd that a number of co-installed
apps with high λ value come from the same vendor.
For example, the pair of < 360Safe (a mobile anti-virus
app used by 719,258 devices), 360 AppStore (a marketplace
app used by 560,600 devices) > has the λ value of 0.358,
and these two apps are both provided by Qihoo6. Further-
more, the λ value could be much higher, if two apps
developed by the same vendor belong to the same
category. For example, the pair of < MI Video (a me-
dia player used by 54,217 devices), MI Voice Assistant (a
voice assistant used by 75,221 devices)> holds the λ value
of 0.604, and the two apps are both provided by XIAOMI7;
the pair of < WeChat (used by 1,567,563 devices), QQ (used
by 1,606,222 devices)> holds the λ value of 0.7, and the two
apps are provided by Tencent.

There are many possible reasons why apps from the same
vendor are often co-installed. A vendor may focus on a spe-
ciﬁc application domain, e.g., Tencent is the largest mes-
saging service provider in China. Tencent QQ is the most
popular instant messaging app in China; WeChat not only
supports instant messaging, but also provides social com-
munication features such as content sharing. Another rea-
son is that there might be “in-app bundled installation”
in some apps. For example, when users install an app, the
app’s vendor may implicitly or explicitly recommend users
to install other apps. For simple validation, we make ﬁeld
studies by selecting 50 apps from well-known app developers
such as Qihoo, Baidu, and Tencent, and install them manu-
ally. 14 apps out of the 50 apps recommend installing other
apps in their installation process, and 8 apps of these 14
“bundled” installations suggest apps provided by the same
provider.

4.2.2 Correlation of App Categories
The category information of an app indicates the func-
tionality and application domains of the app. We can infer
the user needs and interests according to their selected app’s
category. Furthermore, knowing the correlations of app cat-
egories can suggest marketplace operators to organize apps

6Qihoo is one of the largest anti-virus software vendors in
China.
7XIAOMI is one of the largest mobile phone manufacturers
in China.

Figure 7: Coeﬃciency of installed apps.

ities occupy about 7% in total, implying that there are still
a large number of active users.

Activities of uninstallating apps present a similar distri-
bution to the ones of downloading/updating apps. However,
knowing when users uninstall apps may be less meaningful,
because the uninstallation activities do not have interactions
with the marketplace operators or app providers.
4.2 App Selection Patterns

Knowing user interests and needs towards apps is use-
ful. For marketplace operators, such information can help
improve their recommendation systems. For app develop-
ers, such information can help improve their apps to work
better with other co-installed apps, or explore potential col-
laboration opportunities with other developers. For network
providers, such information can help them provide a more
personalized data plan to bundle correlated apps and down-
load them.

In fact, a lot of previous studies investigated how users
select apps [24, 11, 19, 17], and some interesting ﬁndings
were reported. From these studies, a common metric is to
check the “cluster eﬀect”: which apps are more likely to be
selected together. We adopt the same metric, but investigate
it at two levels: the micro-level of co-installed apps, and
the meso-level of correlated app categories.

From our previous analysis, substantial apps are rarely
downloaded (less than 10 times or 10 devices), so we choose
only the top 4,000 apps by their downloads. Each app is
downloaded by at least 20 devices. To better explore the
underlying reasons why apps are selected, we organize the
apps into categories according to the classiﬁcation system of
Wandoujia. Table 1 summarizes the categories ordered by
the number of apps. We also present the number of users
and network summary of each category, which are used for
analysis in Section 5.
4.2.1 Co-Installed Apps
We ﬁrst study co-installed apps. Given two apps appm and
appn, we employ the classical Jaccard Similarity Coeﬃ-
cient (denoted as λ) to measure the possibility how they
are likely to be installed together. We denote the num-
ber of unique devices that install either appm or appn as D
(appm∪appn), and the number of unique devices that install
both appm and appn as D (appm ∩ appn). We then compute
D(appm∩appn)
D(appm∪appn) .

464App Category

GAME
NEWS AND READING
VIDEO
TOOL
SYSTEM TOOL
SOCIAL
EDUCATION
LIFESTYLE
TRAVEL
PERSONALIZATION
FINANCE
COMMUNICATION
SHOPPING
PRODUCTIVITY
MOTHER AND BABY
MUSIC
SPORTS
IMAGE
TRAFFIC

Table 1: Chosen Top Apps by Category.

Apps

Users

(106 devices)

Downloads
(106 times)

Traﬃc

(GB)

Access-

Time

(107 hours)

C-

C-

W-

Traﬃc

Time

Traﬃc

W-

Time

1,227
274
238
227
217
188
172
156
111
104
99
85
78
75
48
43
27
23
14

3.87
1.17
2.86
3.84
3.37
2.18
1.68
1.68
1.62
1.49
0.32
4.09
1.57
0.76
0.10
2.33
0.31
0.14
0.10

15.15
1.97
6.52
9.43
7.54
4.01
2.98
2.85
2.75
3.68
0.50
8.45
3.00
1.17
0.15
3.39
0.36
0.17
0.12

13,669.71
13,143.17
1,196,978.79
77,329.87
34,012.16
35,926.76
13,893.55
2,388.59
8,182.24
7,426.38
382.60
54,394.71
21,808.51
2,712.50
525.72
49,540.12
61.40
801.64
78.10

0.38
0.23
0.38
0.68
0.25
0.35
0.34
0.07
0.03
0.86
0.02
2.85
0.07
0.01
0.01
0.17
0.00
0.00
0.00

0.76%
0.72%

2.98%
3.11%
28.41%
15.63% 10.79%
3.37%
3.05%
4.77%
8.96%
5.35%
1.46%
1.00%
0.72%
0.78%
0.53%
0.85% 12.03%
0.13%
0.24%
24.74% 49.01%
0.65%
0.17%
0.04%
2.47%
0.05%
0.01%
0.03%

6.39%
5.19%
2.91%
3.95%
1.42% 81.08% 10.54%
9.46%
4.40%
4.24%
2.17%
5.66%
1.94%
4.71%
0.87%
1.06%
0.12%
0.52%
0.25%
0.46% 13.67%
0.02%
0.26%
2.26% 35.26%
1.60%
1.32%
0.26%
0.18%
0.12%
0.03%
2.49%
3.08%
0.00%
0.04%
0.03%
0.05%
0.00%
0.01%

3.16%
0.18%
0.07%
5.66%
0.02%
0.06%
0.02%

The users, downloads, traﬃc, and access time are all computed by aggregating the data of each app in
the category
The percentile of W -Traﬃc (C -Traﬃc) and W -Time (C -Time) refer to the data traﬃc and foreground
access time over Wi-Fi (W) and cellular (C) network, respectively.

from diﬀerent categories to enable the fast delivery of po-
tentially co-installed apps to end-users.

Given two app categories M and N, we denote the number
of unique devices that install an app either in M or N as D
(M ∪ N ), and the number of unique devices that install apps
from both in M and N as D (M ∩ N ). We then compute
D(M∪N )
D(M∩N to indicate how likely that the apps in M and N
are installed together. We also take into account the special
case, where M =N , indicating how many users install more
than one app in this category.

Figure 8 shows the probability distribution that apps from
diﬀerent categories are selected together. The categories are
sorted in the descending order of the number of apps. An
immediate observation is that categories having more apps
are more closely correlated. In addition, apps providing re-
lated functionalities are more likely to be selected together.
For example, users may want to share a video from a video-
player app to friends by employing a communication app
(e.g., correlation between COMMUNICATION and VIDEO
is 0.77), or use a viewer app to open a document that is
received by an instant messenger app (e.g., correlation be-
tween TOOL and COMMUNICATION is 0.88 ).

It is not surprising that users may install more than one
app in some categories. For example, in GAME, TOOL, and
COMMUNICATION, the correlations are all more than 0.8.
The result suggests that users have more interests and needs
in these categories.
4.3 Uninstallation Patterns

We next to explore a question: how an app is likely
to be disliked or abandoned by users. Such question
is quite crucial to app developers, marketplace operators,
and end-users. App developers can know how much their
apps are not appreciated by users, so that they can ﬁnd and
ﬁx problems in time to avoid user loss. Marketplace oper-
ators can improve their recommendation systems to ﬁlter
unpopular, low-quality, or even malware apps. End-users
can avoid downloads of frequently abandoned apps and po-
tential threats.

For the question, the absolute number of unistallations of
an app may not be a good indicator. For example, apps
with high uninstallations may also have high downloads. So
we compute the metric of installation/uninstallation ratio,
denoted as Ω(appi), to indicate how likely an app would be
abandoned.

(cid:80) Idevicei and (cid:80) Udevicei represent the number of devices

Given an app appi, we ﬁrst compute

(cid:80) Idevicei
(cid:80) Udevicei

, where

that installed and uninstalled appi, respectively. We extract
all devices that appear in both installation and uninstalla-
tion logs of appi from the Universal User Set. For each
device, we order the appi’s installation and uninstallation log
entries by their timestamps, in the form of < It1, It2, .... >
and < Ut1, Ut2, .... >. Here, ti refers to the timestamp when
the installation or uninstallation action was performed. In
particular, an uninstallation action could not be used unless
an installation action was made previously, i.e., Iti ≺ Uti.
Doing so assures that appi is exactly uninstalled.

The lower value of Ω(appi) an app holds, the higher like-
lihood it is abandoned. For better illustration, Figure 9(a)
shows the scattered distribution of Ω(appi) (denoted as “I/U
ratio”) of top 12,000 apps ranked by their downloads. The
median value of Ω is about 7.46. The Ω of 80% apps’ is less
than 11. In this way, Ω can exactly tell how much an
app is actually abandoned by users. However, Ω(appi)
is not a good signal to comprehensively reﬂect how much
an app is disliked by users, because users may not always
uninstall an app even if they do not need the app any longer.
To better understand the users’ attitude towards apps, we
evaluate the lifecycle of abandoned apps by combining the
temporal information to Ω. Such evaluation is motivated by
an intuition that an app is likely to be a disliked one if it
is uninstalled shortly after installed. To this end, we com-
pute the app’s lifecyle by the timestamps of installation and
uninstallation. We have two immediate observations. First,
from Figure 9(b), if an app is exactly uninstalled, its lifecy-
cle can be identiﬁed. About 40% abandoned apps can
“survive” for only less than one day, and about 93%
abandoned apps can “survive” for less than a week.

465Figure 8: Heatmap of illustrating the relationship of co-installed app categories.

Second, from Figure 9(c), we can ﬁnd a positive corre-
lation among Ω and lifecycle of abandoned apps. In
other words, apps with a lower Ω are more likely to be unin-
stalled within a shorter interval.

5. NETWORK ACTIVITY PATTERNS

Understanding network activities of apps is a highly in-
teresting topic. Previous studies have already revealed some
ﬁndings on network usage of apps, e.g., TCP ﬂows on tier-1
network [24], or usage logs by ﬁeld studies [20, 23]. In con-
trast, our study is performed at a much ﬁner granularity.
First, we distinguish daily data traﬃc and access time from
Wi-Fi and cellular network, respectively. Second, we distin-
guish daily data traﬃc and access time from foreground and
background, respectively.

Based on the granularity of network activities, our study
aims to explore some ﬁndings not covered by previous ef-
forts. End-users can know which apps are network-intensive,
and result in more data traﬃc and battery life. In this way,
end-users can identify “undesirable” apps, optimize improper
network privilege, or even remove these apps. Marketplace
operators can also detect some potentially problematic apps.
App developers can ﬁx possible bugs, and OS-vendors can
patch to avoid threats. Network providers can leverage net-
work behavior and suggest proper data plans for end-users.
5.1 Data Trafﬁc Patterns

First, we identify “network-intensive” apps, i.e., apps that
consume more data traﬃc than others. We aggregate apps
by their categories and summarize the total traﬃc consump-
tion (in GB) from Wi-Fi and cellular, respectively. As shown
in Table 1, VIDEO apps are the most “traﬃc-intensive”.
Apps from the VIDEO category consume 81.08% of Wi-Fi

traﬃc and 28.41% cellular traﬃc against all apps.
Inter-
estingly, apps from TOOL and SYSTEM TOOL consume
a lot of data traﬃc. The apps in these two categories in-
clude apps of input method, anti-virus, app management,
etc. Users heavily rely on these apps to manage, optimize,
and personalize their devices.

We then classify data traﬃc into two dimensions: (1) Wi-
Fi and cellular; (2) foreground and background. Such classi-
ﬁcation can provide us more insights of traﬃc consumption.
We show the detailed summary in Table 2.
5.1.1 Trafﬁc of Wi-Fi and Cellular
In most categories,

it is not surprising that Wi-Fi ac-
counts for more than 60% in total traﬃc. In the categories
of VIDEO, TOOL, MUSIC, SYSTEM TOOL, SHOPPING,
and EDUCATION, more than 80% data traﬃc is from Wi-
Fi. A possible reason is that most of these apps are usually
used in places with stable Wi-Fi connection, e.g., at home
or cafe. The situation is quite diﬀerent in COMMUNICA-
TION. The traﬃc from cellular network accounts for about
39.9%. It is not surprising because users may use COMMU-
NICATION apps whenever a network connection is avail-
able.
5.1.2 Trafﬁc of Foreground and Background
We then identify the foreground and background traﬃc
of an app, respectively. Often, the foreground traﬃc is gen-
erated when users interact with the app.
In an Android
OS, a foreground app can be determined if the app is cur-
rently at the top of the activity stack.
In contrast, the
background traﬃc implies that the app is still connecting
to network even users do not interact with it. From Ta-
ble 2, the foreground traﬃc accounts for more than 60% in
most categories. Foreground traﬃc accounts for about 50%

466(a) Possibility of app abadonment

(b) Lifecyle distribution of abandoned
apps

(c) Lifecycle of
apps

frequently abandoned

Figure 9: Lifecyle of abandoned app.

Table 2: Network Summary by App Category

C -Traﬃc

W -Traﬃc

C -Traﬃc

W -Traﬃc

C -Time

W -Time

C -Time

W -Time

(B)

45.13%
39.13%
15.90%
35.19%
20.65%
51.57%
17.09%
39.38%
43.11%
24.64%

(F)

52.78%
43.14%
44.20%
54.80%
57.47%
40.55%
70.21%
51.40%
37.74%
54.62%

(B)

42.62%
48.57%
48.01%
49.23%
48.43%
50.02%
43.34%
45.57%
48.13%
43.43%

(B)

56.66%
50.42%
46.85%
50.09%
50.41%
49.48%
56.42%
52.83%
51.34%
55.25%

(F)

0.10%
0.57%
3.15%
0.36%
0.57%
0.23%
0.08%
0.90%
0.26%
0.60%

(F)

0.63%
0.43%
1.99%
0.32%
0.59%
0.26%
0.17%
0.69%
0.28%
0.71%

App Category

VIDEO
TOOL
COMMUNICATION
MUSIC
SOCIAL
SYSTEM TOOL
SHOPPING
EDUCATION
GAME
NEWS AND READING

(F)
1.28%
9.56%
27.48%
5.67%
14.63%
2.80%
9.42%
5.46%
8.80%
14.83%
W and C refer to Wi-Fi and Cellular, respectively.
B refers to background and F refers to foreground.

(B)
0.81%
8.16%
12.42%
4.35%
7.26%
5.07%
3.29%
3.76%
10.34%
5.91%

in four categories, i.e., SYSTEM TOOL (43.35%), GAME
(46.54%), TOOL (52.7%), and VIDEO(54.1%). We infer
that some apps in these categories keep consuming
a large amount of traﬃc, when users switch to use other
apps, or the screen-oﬀ traﬃc occurs with device sleeping [9].
This observation draws our attention. Usually, GAME apps
may embed some third-party advertisement libraries (ad-
libs). Besides ad-libs, VIDEO apps may often prefetch con-
tent. Hence, the background traﬃc of these apps should be
necessary. If we can ﬁnd reasonable explanations for back-
ground traﬃc, we denote such behavior as “reasonable”. For
example, some management apps such as Wandoujia and
anti-virus apps often need downloading or updating actions
at background. Otherwise, we annotate an app with “un-
known” if we can not judge whether the background traﬃc
is really necessary. We manually check some top apps with
high traﬃc consumptions to see whether these consumptions
are reasonable. We ﬁnd 14 apps that we are not quite clear
why they need background network privilege8. For example,
on average, an alarm clock app (at.samsung.powersleep)
daily consumes about 13 MB cellular traﬃc and 156 MB Wi-
Fi traﬃc at background for a user among about 300 users;
a LED ﬂashlight app (com.chenlei.flashlightfree) daily
consumes about 7 MB cellular traﬃc and 5 MB Wi-Fi traﬃc
at background for a user among about 20 users. Users may
suﬀer from lots of unnecessary loss of background cellular
data if they use these apps.

There are some reasons for producing background network
activities. One reason is that ad libraries are widely used in
a lot of apps, and may download and update advertisements
according to user contexts. We simply validate such reason
from two aspects. First, we crawl the user reviews of the 14
“suspicious” apps on Wandoujia, and check whether adver-
tisement issues are reported. From user reviews, 3 out of 14
apps are found with complaints about advertisement. Sec-
ond, by disassembling the .apk ﬁles and conducting program
analysis, we ﬁnd that 3 out of 14 apps include at least one
of popular advertisement libraries published on AppBrain9.
Although we are still not sure whether and how much these
advertisement libraries consume background network, we
believe such ﬁnding already brings awareness to end-users
about the potential traﬃc loss.

Another reason is that the misuses or even malicious grant-
ing of network permissions. Since our current case analysis is
manual, we plan to leverage our previously developed WHYPER
tool [15] to further dig out “suspicious” apps by combining
their permissions and descriptions.

In summary, the results show that users may be un-
aware that the traﬃc is “silently but maybe unex-
pectedly” consumed at background. It reminds users
to alert or kill background network activities after launch-
ing these apps. Background network activities may lead to
unnecessary data loss in a data plan, or imply some threats.

8We list these apps and their network activities on http:
//www.sei.pku.edu.cn/~liuxzh/IMC2015/

9http://www.appbrain.com/stats/libraries/ad. AppBrain
is a well-known platform for Android users and developers.

4675.2 Access Time Patterns

We then investigate the access time of network activities.
Intuitively, access time may reﬂect two important insights.
First, the foreground access time of an app indicates how
long a user interacts with it. Therefore, such metric can
imply how much the user likes or needs the app. Second,
similar to background data traﬃc, background access time
indicates how long an app connects to network when users
do not interact with it. Therefore, the background access
time can imply the “liveness” of the app after it is launched.
Similar to the study of data traﬃc, we ﬁrst illustrate the
access time distribution among app categories, as shown in
Table 1. When exploring the foreground access time, it is
not surprising that the COMMUNICATION apps account
for 49% cellular time and 35.26% against all apps. It is also
interesting to ﬁnd that users spend a lot of time on TOOL
(10.79% under cellular and 9.46% under Wi-Fi).

We investigate how much foreground and background ac-
count for network time, respectively. From Table 2, we are
surprised to observe that foreground time accounts for only
less than 2% (by aggregating W -Time(F) and C -Time(F))
in total network access time, whereas the background time
occupies more than 98% (by aggregating W -Time(B) and
C -Time(B)). In other words, most apps still keep “long-
and-live” TCP connection at background after being
launched, although they are not used by users. The
background network time may be reasonable for apps that
heavily rely on network, e.g., COMMUNICATION, and SO-
CIAL. For example, most of these apps require auto synchro-
nization or notiﬁcation. However, it hardly makes sense that
many apps from other categories have continuous network
connection at background. Although background network
activities do not always reﬂect more data traﬃc, they still
occupy network connections and may lead to unnecessary
energy cost.
6. PRICE-SENSITIVE PATTERNS

The preceding measurements provide us information on
some patterns of app selection and network usage. In this
section, we further explore these patterns by classifying users,
i.e., how these patterns are inﬂuenced by the prices
of devices. Our goal is motivated by two concerns: (1) do
users with devices of diﬀerent prices have diﬀerent
needs and interests in using apps? (2) if yes to (1),
how much do the prices of devices matter? In other
words, we would like to investigate whether the user’s usage
patterns are price sensitive.
6.1 Device Model Clustering

We cluster users by their device models from the Net-
worked App Set, that covers about 2 million users. We
ﬁnally have 12,091 device models. We present the num-
ber of users of each device model in Figure 10.
It is ob-
served that 96% device models have less than 500 users.
This number of users accounts for only less than 0.1% in
our dataset.
It demonstrates the heavy fragmentation of
Android devices. Therefore, we take a set of “popular ” de-
vice models, each of which has at least 500 users. We further
manually check these device models and merge some dupli-
cated device models. For example, GT 7100/7102/7108 all
refer to Galaxy Note 2 with the same hardware speciﬁcation,
but customized by diﬀerent network carriers such as China
Mobile and China Unicom. In this way, we ﬁnally label 327

Figure 10: CDF for Number of Users of Device Models

“popular” device models. Then, we categorize the 327 device
models according to their on-market sale prices. Although
the price of a device is cut down gradually after the device is
sold, such categorization could still roughly reﬂect economic
factors. We put each device model into one of ﬁve groups,
which are numbered as 1-5 in Table 3.
6.2 Apps Used Among Groups

We investigate the number of used apps among diﬀerent
groups, and present the distribution in Figure 11. Note that
we examine the apps from the Networked User Set, in-
dicating that they are exactly used by users. An immediate
observation is that the higher price a device model has,
the more apps are used on this device model. Such
ﬁnding might come from two reasons. First, the more expen-
sive device models usually provide more powerful hardware
speciﬁcations, e.g., faster CPU, larger RAM, and higher def-
inition of screen. The computation power should motivate
the users to install and use more apps. Second, more expen-
sive device models usually come from more famous manufac-
turers, such as Samsung, Motorola, LG. Such observation is
attributed to the fact that Android systems customized by
these manufacturers may pre-load more apps than cheaper
devices, and may lead to the problem of “bloatware”. We
download the factory ROM ﬁles of some representative de-
vice models from ROMJD10. For example, the Samsung
Galaxy Note 2 (Group 5) has 18 pre-installed apps that
generate network activities, and the number on Galaxy S4
(Group 4) is 15.
In contrast, Meizu M040 (Group 1) has
only 9 pre-installed apps that generate network activities.
Although we sample only some device models, the ﬁnding
can support our hypothesis to some degree.
6.3 Network Activity Among Groups

Similar to the preceding analysis of network activities, we
show the CDF of data traﬃc and access time from diﬀer-
ent groups in Figure 12. We can ﬁnd that the usage
of Wi-Fi also tends to take a positive correlation
with device model price. In other words, the more ex-
pensive a device model is, the more Wi-Fi traﬃc its users
tend to consume. However, the situation is quite diﬀer-
ent for cellular traﬃc. The diﬀerences of cellular traﬃc
among Group 1-3 are quite marginal, where 80% users con-
sume less than 150 MB cellular traﬃc in one month. From

10ROMJD is a website
http://www.romjd.com/

sharing Android ROM ﬁles.

468Table 3: Device Model by On-Market Price

Group (price in Chinese Yuan) # of Device Models Typical Device Model
Group 1: 1,000-
Group 2: 1,000-1,999
Group 3: 2,000-2,999
Group 4: 3,000-4,999
Group 5: 5,000+

HUAWEI-T8951, HUAWEI-C8812, Samsung SCH-I739
Motorola XT681,Meizu M040, Samsung GT-I9082
Xiaomi MI-1S, Xiaomi MI-2, Samsung GT-S7568, LG-P970
Samsung Galaxy S3, Nexus 4, HTC One
Samsung Galaxy Note 2, Galaxy S4, SCH-N719

57
98
76
69
27

# of Covered Users

216,249
385,811
329,361
517,262
378,504

(a) Wi-Fi traﬃc volume

(b) Cellular traﬃc volume

(c) WiFi time

(d) Cellular time

Figure 12: Network Activity Distribution among User Groups

Figure 11: Number of App Usage Across Diﬀerent Groups

Group 4, the cellular traﬃc and the access time begin to in-
crease. Users from Group 5 consume the most cellular traﬃc
and the most access time. About 5% users from this group
use about 1GB cellular traﬃc. There may be two possible
reasons. First, as device models from Groups 4 and 5 are
more powerful, their users tend to connect to the network
and download more contents. Second, users from these two
groups could be supposed to have better economic back-
ground, so they are likely to aﬀord a higher-cost data plan
to use.
6.4 User Interest on Similar Apps

To explore whether users’ interests are aﬀected by de-
vice prices, we study how users from diﬀerent groups per-
form in selecting apps with the same or similar functional-
ities. We choose two typical types of networked apps: (1)
News Reader: we choose 5 popular apps: Netease, Sohu,
Phoenix, Tencent, and Sina; (2) Browser: we choose 8
popular browsers: Chrome, FireFox, Opera, Maxthon, UCWeb,
360Safe, Baidu, and Sogou. We show the foreground time
against device models. Some preference tendencies could be
found. For news reader apps, users from Groups 4 and 5
tend to use the Netease app, but users from Groups 1-3
tend to use the Sohu app. A similar ﬁnding could be found

(a) News Reader Apps

(b) Browser Apps

Figure 13: Similar App Preferences among User Groups

in Browser. Users from Groups 4 and 5 tend to use Chrome,
but users from Group 1-3 tend to use UCWeb and 360safe.

For better understanding the user preferences, we assume
that the features and performance may impact users from
diﬀerent groups. First, users in Groups 1-3 may prefer lo-
cal apps over international apps. For example, UCWeb and
360safe are both developed by local app providers in China,
and preferred over Chrome. Second, user interface designs
may inﬂuence target user groups. For example, the Ten-
cent news reader often embeds a video that ﬁts the textual
content browsed by users. Considering 42% of its users are
from Group 3, we can suppose that users in this group are
interested in watching videos instead of textual content. In
contrast, users from Groups 4-5 seem to prefer to go through
the textual content, so they prefer the Netease news reader.
Third, some speciﬁc features might motivate diﬀerent user
preferences. For example, Opera Mini is said to save traﬃc
by oﬄoading computation onto cloud, and its 60% users are
from Groups 1, 2, and 3. In summary, such ﬁnding im-
plies that device prices has impacts on app selection
and usage, and reﬂect diﬀerent user interests and
needs.

7.

IMPLICATIONS

We have investigated the user behaviors and infer some
patterns. In this section, we summarize our ﬁndings. We not
only validate some ﬁndings that were reported in previous
studies based on a smaller scale of users, but also identify

469Table 4: Summary of Findings and Implications

Findings in Diverse Usage Patterns
The popularity distribution of apps typically follows the
“Pareto” eﬀect. A large number of smartphone apps are
with only quite few download count and subscriber devices,
and contribute marginally to network usage. Such a ﬁnding
has been mentioned in various previous studies [2, 5, 7, 17].

Diurnal distribution of apps management is quite pe-
riodical during a day. B¨ohmer et al. [2] also reported some
similar results.

It is not surprising that some apps are frequently installed
together such as COMMUNICATION and SOCIAL. Apps
that come from the same vendor or have similar functional-
ities are more likely to be installed together.

An app’s installation/uninstallation ratio performs a pos-
itive correlation to its lifecycle. Most “disliked” apps are
likely to be uninstalled within 2 days.

Some apps are more network intensive than others with sim-
ilar functionalities. Similar ﬁndings were reported previ-
ously [16].

Some apps may consume a large amount of traﬃc volume at
background, but the behaviors might not be reasonable or
necessary, e.g., the flashlight and namecard apps. Some
apps are found using advertisement libraries.

A lot of apps keep long-lived TCP connection when they are
not “used” by users.

Although fragmentation is quite severe in Android devices,
most device models have only few users.
The app selection is diverse among users who take diﬀerent
device models. For example, lower-end device users prefer
the Opera browser as it is said to save traﬃc.
The network usage is diverse among diﬀerent users who have
diﬀerent price levels of device models. Lower-end device
users heavily rely on Wi-Fi. In contrast, higher-end devices
are likely to use more cellular than lower-end device users.

Implications for Relevant Stakeholders
The marketplace operators can identify which apps are
really popular and more frequently downloaded and used.
The marketplace operators should put the .apk ﬁles of
these popular apps “as close as possible” to end-users, e.g.,
by deploying Content Delivery Networks (CDN) servers.
They can further design eﬃcient mechanisms such as cache,
prefetching, and large bandwidth to make these apps fast
delivered. The apps that are downloaded by a limited num-
ber of devices in a short interval could alert marketplace
operators and end-users for further examination.
The marketplace operators can better allocate resources
such as server and bandwidth to adapt the download-
ing/updating requests. The app developers can publish
their up-to-date app versions at proper time to attract more
downloads.
The marketplace operators can improve recommenda-
tion systems, e.g., cluster the frequently co-installed apps
at a close location to allow end-users to fast download them.
The app developers can leverage this knowledge to ﬁnd
“mutual-composition” opportunities and design some APIs,
e.g., navigating to a social networking app from a news
reader app to share content. Some co-installed apps come
from the same vendors. The end-users can be cautious
to avoid undesirable app downloads. The advertisers can
deliver relevant ads in some apps. For example, earphone
advertisers can focus on users who use MUSIC and VIDEO
apps as they are correlated with SHOPPING apps.
The marketplace operators can know which apps are dis-
liked and further explore why they are abandoned. The
end-users can judge an app’s popularity even without user
reviews according to its installation/uninstallation ratio.
The marketplace operators can recommend end-users
proper apps that have similar functionalities but bet-
ter ﬁt the users’ data plan. The network providers
can also leverage this knowledge and provide special data
plan.
For example, some network providers in China
make special data-plan contract with music (such as
Baidu Music (com.ting.mp3.oemc.android) and Kuwo Mu-
sic (cn.kuwo.player)) and video apps (such as Youku
(com.cibn.tv)), and users can pay for this data plan inde-
pendently and enjoy unlimited cellular traﬃc to download
video/audio ﬁles or enjoy them online.
Such ﬁndings can remind the marketplace operators to
pay attention to these apps and warn the end-users and
the app developers. The OS-vendors can beneﬁt from
our ﬁndings by preventing these apps from potential threats.

Background network connections would consume resources
and energy, or even imply some malicious behaviors. Such
a ﬁnding reminds that the end-users should periodically
“clean up” their devices or terminate the threads of unused
apps running at background.
Such ﬁndings can suggest the app developers focus on
mainstream devices and make their apps adaptive to them.
The marketplace
recommend
functionality-similar apps to users with diﬀerent device
models.
Such ﬁndings can predict how much data plan a device will
probably use based on the same or similar device models. In
this way, the marketplace operators can recommend end-
users diﬀerent apps according to their own data plan. The
app developers can also provide some features to adapt
diﬀerent users, e.g., making their apps prefetch contents un-
der Wi-Fi network for the lower-end users.

operators

can

In the left column, we summarize the ﬁndings from our study. In the right column, we suggest some implications for various
stakeholders.

470some new insights and suggest some implications. We list
the ﬁndings and implications in Table 4.

8. THREATS TO VALIDITY

One potential limitation of our work is that the dataset
is collected from a single app marketplace in China. This
limitation may have introduced some biases caused by app
marketplace speciﬁc policies, and some of our ﬁndings may
not always hold in other app marketplaces. Care should be
given to generalize our ﬁndings to another marketplace.

Another limitation is that the users under study are mainly
Chinese, and the region diﬀerences should be considered.
The same limitation also exists in most of previous studies
that were conducted over users from a speciﬁc region, e.g.,
some states in USA [24]. To alleviate this issue, we con-
duct our study over millions of users. We believe that such
scale of users could reduce the threats. In fact, our ﬁndings
such as the Pareto principle of app popularity and user in-
terests of co-installed apps have validated the ﬁndings from
previous studies.

Because the analysis is done on one month of usage data,
some of our ﬁndings may not generalize to a longer period
of time. Mobile apps are updated very frequently, and some
potential security threats of apps, e.g., overprivilege of net-
work permissions, might be already ﬁxed in their up-to-date
versions. Meanwhile, we realize that one-month data is not
suﬃcient to predict app quality in the latest Wandoujia mar-
ketplace. We plan to evaluate our ﬁndings based on a new
half-year dataset and investigate how users and app usage
evolve.

9. RELATED WORK

Understanding user behavior of mobile apps establishes
a foundation for diﬀerent stakeholders in the research com-
munity of mobile computing, e.g., app developers, network
providers, marketplace operators, and OS vendors. A plethora
of studies have been made from diﬀerent perspectives.
Understanding User Behavior by Field Study. Given
that collecting large-scale user data is hardly feasible for
most studies, learning user behavior by ﬁeld study is al-
ways a straightforward way. A lot of studies were per-
formed over speciﬁc user groups. Rahmati et al. [19, 18]
performed a four-month ﬁeld study of the adoption and us-
age of smartphone-based services by 14 novice teenage users.
Tossell et al. [23] applied a naturalistic and longitudinal logs-
based approach to collect real usage data from 24 iPhone
users in the wild. Sanzi et al. [20] collected data from 387
Android users in India, where users pay for cellular data con-
sumed, with little prevalence of unlimited data plans. Falaki
et al. [6] found that web browsing contributed over half of
the traﬃc. Using detailed traces from 255 volunteer users,
Falaki et al. [7] conducted a comprehensive study of smart-
phone use and found immense diversity of users, by char-
acterizing intentional user activities. Lim et al. [12] made
a questionnaire-based study to discover the diverse usages
from about 4,800 users across 15 top GDP countries. Yan et
al. [25] developed and deployed an app to collect usage logs
from over 4,600 users to ﬁnd their similar interests and ex-
plore mobile apps recommendation systems for smartphone
apps. For a study closely to ours, Xu et al. [24] presented
usage patterns by analyzing IP-level traces of thousands of
users from a tier-1 cellular carrier in U.S. They identiﬁed

traﬃc from distinct marketplace apps based on HTTP sig-
natures and present aggregate results on their spatial and
temporal prevalence, locality, and correlation.

Some ﬁeld studies were made on speciﬁc apps. B¨ohmer
et al. [2, 3] made a ﬁeld study over three popular apps such
as Angry Bird, Facebook, and Kindle. Patro et al. [16] de-
ployed a multiplayer RPG app game and an education app,
respectively, and collected diverse information to understand
various factors aﬀecting application revenues.
Mining App Marketplace Data. Some types of app re-
lated data like user reviews, star ratings, and like/dislike
voting are publicly accessible. Chen et al. [4] presented AR-
Miner to extract informative user reviews and group them
using topic modeling. Fu et al. [8] presented WisCom, a
system that can analyze tens of millions user ratings and
comments in mobile app markets. Pestas et al. [17] moni-
tored and mined four popular third-party Android app mar-
ketplaces and showed that the app popularity distribution
deviates from commonly observed Zipf-like model.
Predicting Apps to Use. Some studies target predicting
the “to-be-used ” apps by collecting user logs. Shin et al. [22,
21] collected a wide range of smartphone information from
23 users, extracted and analyzed features related to app pre-
diction. Liao et al. [11, 10] proposed a temporal-based app
predictor to dynamically predict the apps which are most
likely to be used. Montoliu et al. [13] presented a frame-
work to discover places-of-interest from multimodal mobile
phone sensory data. Do et al. [5] presented a framework for
predicting where users will go and which app they are to
use in the next ten minutes from the contextual information
collected by smartphone sensors.

Compared to these studies, the major diﬀerences of our
study include the unique dataset covering millions of users,
some unique information such as app installation, uninstal-
lation, and diverse network usage. Although Chinese users
take up majority of all users, we believe that behavior pat-
terns inferred from millions of users under study should
be more generalized and comprehensive than those from
volunteers. With our dataset, we also validate some re-
sults that were reported over smaller scale of users. For
example, a small set of apps account for substantially a
large portion of downloads [17] and unique users [24], some
apps are more likely to be installed together [24, 6, 7], and
some functionality-similar apps may vary in terms of per-
formance [20]. However, besides using a diﬀerent dataset
collected from millions of users, our study explores uniquely
new ﬁndings that were not covered previously:

1. First, we make comprehensive measurement of the app
popularity from various aspects including downloads,
users, and diverse network activities.

2. Second, we explore which apps are likely to be unin-

stalled and the lifecycle of the abandoned apps.

3. Third, beyond reporting the co-installation of apps, we
further explore the possible reasons why these apps are
selected together.

4. Fourth, we make a ﬁne-granularity analysis of net-
work activities to identify the “network-intensive” apps
and “problematic” apps that consume traﬃc at back-
ground.

4715. Finally, we study the economic factor by the price of
device model, and explore how it impacts on user be-
haviors on apps usage.
10. CONCLUSION

We conducted a systematic descriptive analysis of a large
collection of mobile app usage behaviors from millions of An-
droid users. Interesting usage patterns are with respect to
app popularity, app management, app selection, app aban-
donment, network usage, and so on. Our ﬁndings provide
valuable implications for diﬀerent stakeholders in the mo-
bile app industry and in the research community of mobile
computing.

This paper mainly focuses on the descriptive analysis of
the data. Many ﬁndings of the analysis lead to interesting
research questions that can be immediately explored. Such
research tasks include predicting app quality and popularity,
optimizing app performance, and improving app recommen-
dations, etc. Development of these directions can directly
improve the Wandoujia management app and beneﬁt mil-
lions of users.
Acknowledgment
This work was supported by the National Basic Research Pro-
gram (973) of China under Grant No. 2014CB347701, the Natu-
ral Science Foundation of China (Grant No. 61370020, 61421091,
61222203, 61572051, 61528201). Tao Xie’s work was supported
in part by National Science Foundation under grants no. CCF-
1349666, CCF-1409423, CNS-1434582, CCF-1434590, CCF-1434596,
CNS-1439481, and CNS-1513939. Qiaozhu Mei’s work was sup-
ported in part by the National Science Foundation under grant
no. IIS-1054199.
11. REFERENCES

[1] A. Apaolaza, S. Harper, and C. Jay. Understanding users

in the wild. In Proc. of W4A, page 13, 2013.

[2] M. B¨ohmer, B. Hecht, J. Sch¨oning, A. Kr¨uger, and

G. Bauer. Falling asleep with angry birds, Facebook and
Kindle: a large scale study on mobile application usage. In
Proc. of MobileHCI, pages 47–56, 2011.

[3] M. B¨ohmer and A. Kr¨uger. A study on icon arrangement
by smartphone users. In Proc. of CHI, pages 2137–2146,
2013.

[4] N. Chen, J. Lin, S. C. H. Hoi, X. Xiao, and B. Zhang.

AR-miner: mining informative reviews for developers from
mobile app marketplace. In Proc. of ICSE, pages 767–778,
2014.

[5] T. M. T. Do and D. Gatica-Perez. Where and what: Using
smartphones to predict next locations and applications in
daily life. Pervasive and Mobile Computing, 12:79–91,
2014.

[6] H. Falaki, D. Lymberopoulos, R. Mahajan, S. Kandula,
and D. Estrin. A ﬁrst look at traﬃc on smartphones. In
Proc. of IMC, pages 281–287, 2010.

[7] H. Falaki, R. Mahajan, S. Kandula, D. Lymberopoulos,

R. Govindan, and D. Estrin. Diversity in smartphone
usage. In Proc. of MobiSys, pages 179–194, 2010.

[8] B. Fu, J. Lin, L. Li, C. Faloutsos, J. I. Hong, and N. M.
Sadeh. Why people hate your app: making sense of user
feedback in a mobile app store. In Proc. of KDD, pages
1276–1284, 2013.

[9] J. Huang, F. Qian, Z. M. Mao, S. Sen, and O. Spatscheck.

Screen-oﬀ traﬃc characterization and optimization in
3g/4g networks. In Proc. of IMC, pages 357–364, 2012.

[10] Z. Liao, S. Li, W. Peng, P. S. Yu, and T. Liu. On the

feature discovery for app usage prediction in smartphones.
In Proc. of ICDM, pages 1127–1132, 2013.

[11] Z. Liao, Y. Pan, W. Peng, and P. Lei. On mining mobile

apps usage behavior for predicting apps usage in
smartphones. In Proc. of CIKM, pages 609–618, 2013.

[12] S. L. Lim, P. J. Bentley, N. Kanakam, F. Ishikawa, and
S. Honiden. Investigating country diﬀerences in mobile
app user study behavior and challenges for software
engineering. IEEE Transactions on Software Engineering,
40(5):40–64, 2014.

[13] R. Montoliu, J. Blom, and D. Gatica-Perez. Discovering
places of interest in everyday life from smartphone data.
Multimedia Tools Appl., 62(1):179–207, 2013.

[14] M. E. J. Newman. Power Laws, Pareto Distributions and

Zipf’s Law. Contemporary Physics, 46:323, 2005.

[15] R. Pandita, X. Xiao, W. Yang, W. Enck, and T. Xie.

WHYPER: Towards automating risk assessment of mobile
applications. In USENIX Security, pages 527–542, 2013.
[16] A. Patro, S. K. Rayanchu, M. Griepentrog, Y. Ma, and
S. Banerjee. Capturing mobile experience in the wild: a
tale of two apps. In Proc. of CoNEXT, pages 199–210,
2013.

[17] T. Petsas, A. Papadogiannakis, M. Polychronakis, E. P.
Markatos, and T. Karagiannis. Rise of the planet of the
apps: a systematic study of the mobile app ecosystem. In
Proc. of IMC, pages 277–290, 2013.

[18] A. Rahmati, C. Tossell, C. Shepard, P. T. Kortum, and

L. Zhong. Exploring iphone usage: the inﬂuence of
socioeconomic diﬀerences on smartphone adoption, usage
and usability. In Proc. of MobileHCI, pages 11–20, 2012.
[19] A. Rahmati and L. Zhong. Studying smartphone usage:

Lessons from a four-month ﬁeld study. IEEE Trans. Mob.
Comput., 12(7):1417–1427, 2013.

[20] A. A. Sani, Z. Tan, P. Washington, M. Chen, S. Agarwal,
L. Zhong, and M. Zhang. The wireless data drain of users,
apps, & platforms. Mobile Computing and
Communications Review, 17(4):15–28, 2013.

[21] C. Shin and A. K. Dey. Automatically detecting

problematic use of smartphones. In Proc. of Ubicomp,
pages 335–344, 2013.

[22] C. Shin, J. Hong, and A. K. Dey. Understanding and

prediction of mobile application usage for smart phones.
In Proc. of Ubicomp, pages 173–182, 2012.

[23] C. Tossell, P. T. Kortum, A. Rahmati, C. Shepard, and

L. Zhong. Characterizing web use on smartphones. In
Proc. of CHI, pages 2769–2778, 2012.

[24] Q. Xu, J. Erman, A. Gerber, Z. M. Mao, J. Pang, and

S. Venkataraman. Identifying diverse usage behaviors of
smartphone apps. In Proc. of IMC, pages 329–344, 2011.

[25] B. Yan and G. Chen. Appjoy: personalized mobile

application discovery. In Proc. of MobiSys, pages 113–126,
2011.

472