Access Pattern disclosure on Searchable Encryption:

Ramiﬁcation, Attack and Mitigation

Mohammad Saiful Islam, Mehmet Kuzu, Murat Kantarcioglu

Jonsson School of Engineering

and Computer Science

The University of Texas at Dallas

{saiful, mehmet.kuzu, muratk}@utdallas.edu

Abstract

The advent of cloud computing has ushered in an era of
mass data storage in remote servers. Remote data storage
offers reduced data management overhead for data owners
in a cost effective manner. Sensitive documents, however,
need to be stored in encrypted format due to security con-
cerns. But, encrypted storage makes it difﬁcult to search on
the stored documents. Therefore, this poses a major barrier
towards selective retrieval of encrypted documents from the
remote servers. Various protocols have been proposed for
keyword search over encrypted data to address this issue.
Most of the available protocols leak data access patterns
due to efﬁciency reasons. Although, oblivious RAM based
protocols can be used to hide data access patterns, such
protocols are computationally intensive and do not scale
well for real world datasets.
In this paper, we introduce
a novel attack that exploits data access pattern leakage to
disclose signiﬁcant amount of sensitive information using a
modicum of prior knowledge. Our empirical analysis with
a real world dataset shows that the proposed attack is able
to disclose sensitive information with a very high accuracy.
Additionally, we propose a simple technique to mitigate the
risk against the proposed attack at the expense of a slight
increment in computational resources and communication
cost. Furthermore, our proposed mitigation technique is
generic enough to be used in conjunction with any search-
able encryption scheme that reveals data access pattern.

1. Introduction

Searching over remote encrypted data (commonly re-
ferred to as Searchable Encryption) has been an active area
of research for the last few years. Due to increased popu-
larity of cloud based services, more and more sensitive data
(e.g., health care records, personal emails etc.) are stored

encrypted in the cloud. But, the advantage of cloud data
storage is lost if the user can not selectively retrieve seg-
ments of their data. Therefore, we need secure and efﬁ-
cient search schemes to selectively retrieve sensitive data
from the cloud. The need for such protocols are also rec-
ognized by researchers from major IT companies such as
Microsoft [14].

Although, there are quite a few proposed solutions for
searchable encryption schemes, the basic settings remains
the same. There is a set of clients and an untrusted server. A
client, (e.g., Alice), has a set of sensitive documents which
she wants to store in a remote server owned by Bob. Due to
the sensitive nature of the documents, Alice does not want
Bob to learn the content of any of her documents. Since,
Bob cannot learn the content of the documents, storing the
documents in the server in plaintext is unacceptable. There-
fore, the document set is stored encrypted using a secure
encryption scheme. To facilitate search on encrypted data,
an encrypted index structure is stored in the server along
with the encrypted data. Authorized users in this setting
have access to a trapdoor generation function. Therefore,
they can generate valid trapdoors for any arbitrary keyword.
This trapdoor is used in the server to search for the intended
keyword. It is assumed that the server does not have access
to the trapdoor generation function, and therefore, can not
ascertain the keyword searched for. However, it is imper-
ative to hide the corresponding keyword of a given query1
from an adversary. Otherwise, the adversary learns the set
of documents that contains the given keyword and the set of
documents that does not. In the context of the search over
remote encrypted data, it is generally assumed that Bob is
‘honest but curious’, i.e., Bob tries to learn as much knowl-
edge as he can without deviating from the protocol.

A ‘Searchable Encryption scheme’ is qualiﬁed as secure,

if it satisﬁes the following necessary conditions.

1We use the term ‘query’ to refer to a trapdoor sent by a user to the

remote server as a search request.

1. Query generation function is only known to the autho-

rized data users.

2. The search mechanism works only in conjunction with

a valid query generation function.

The ﬁrst condition speciﬁes that only Alice is able to gen-
erate a valid query for a given keyword. Furthermore, for a
given hkeyword, queryi pair, no entity other than Alice has
a mechanism to predict the validity of the pair with non-
negligible advantage. The second condition guarantees that
the search mechanism only works for a given query only if
the valid query generation mechanism has been used.

There are many proposed solutions to date that satisﬁes
the conditions outlined earlier. Some models like that of
Oblivious ram (e.g., [11]) do not leak any information to
the attacker, but are too expensive to be practical on large
datasets. Other symmetric key encryption based models,
such as [7,8,10,20] proposes efﬁcient solutions to the prob-
lem, but leaks data access pattern. That is, in all of those
search schemes, given a query x of keyword w, an attacker
does not learn w, but she knows which are the documents
that contains w. Although, this fact has been noted in the
literature (e.g., [8, 10]), none of the previous works system-
atically analyzed the implications of revealing data access
pattern. In this paper, we identify the potential risks of ac-
cess pattern disclosure via a novel attack. Our empirical
analysis with a real world email dataset shows that signif-
icant amount of sensitive information can be compromised
by the proposed attack. Finally, we propose a simple noise
addition technique to mitigate risk against this type of at-
tacks.

We summarize the contributions of this paper as follows.

1. To the best of our knowledge, this is the ﬁrst study
that investigates the implications of data access pattern
disclosure in searchable encryption schemes.

2. We formalize a query identity inference attack model

based on access pattern disclosure.

3. We prove that such an inference attack is N P −
complete in general and give a heuristic solution that
can identify approximately 80% of the queries with
minimal background knowledge.

4. Finally, we propose a simple noise addition technique
to limit the effect of inference attacks due to access
pattern disclosures and empirically show the efﬁciency
of our proposed model.

2. Related Work

In [11], Goldreich et. al. presented their oblivious RAM
model, where a user can securely perform search over en-

crypted data without revealing their access patterns. Al-
though, their technique is theoretically sound, it incurs poly-
logarithmic overhead on all parameters. They also proposed
a lighter version of the Oblivious RAM protocol which
works in 2 rounds, but this protocol comes with a very high
square root overhead [8]. Therefore, even this lighter ver-
sion is computationally very expensive for large datasets.
Boneh et. al. proposed a public key encryption based key-
word search in [4], where data access pattern is revealed.
Later, Boneh et. al. presented a public key solution that can
hide access patterns in [5]. Again, these public key encryp-
tion based solutions are computationally expensive and not
always practical for large datasets.

Song et. al. proposed a special symmetric key based
searchable encryption technique in [20]. The authors them-
selves acknowledged the fact that certain statistical analysis
can be performed to successfully leak valuable knowledge
over the encrypted documents but did not provide a detailed
analysis of such attacks.

In [10], Goh et. al. proposed a security deﬁnition to for-
malize the security requirements of Searchable Symmetric
Encryption (SSE), and proposed a search technique based
on Bloom Filters. Unfortunately, Bloom Filters can lead
to false positives, a fact the authors themselves pointed out
in [10]. Also, since this technique requires separate indexes
for each of the documents, it is not very space (or time) ef-
ﬁcient.

At the same time as [10] , Chang et. al. proposed a sim-
ulation based deﬁnition of SSE in [7]. But, their proposed
deﬁnition does not take into account how an adversary can
generate queries adaptively, i.e. an adversary can choose
his subsequent queries after seeing the outcome of all the
queries he has submitted so far. This shortcoming have been
addressed by Curtmola et. al. in [8]. Furthermore, they also
proposed SSE techniques that satisfy their improved deﬁni-
tions. We remark that although their security deﬁnition al-
lows adversaries to generate queries adaptively, it does not
guarantee hiding of access pattens of any particular user. It
has been mentioned in [8, 10] that none of these symmetric
key based SSE hides access pattern from the server.

In [17], Kumar et. al. used statistical techniques to com-
promise the anonymization of query logs using token-based
hashing. The authors used a reference query log to infer sta-
tistical properties of words in the log-ﬁle. They used these
properties to process an anonymized query log and tried to
invert the underlying hash values to their respective tokens.
Although, both their methods and ours employ statistical
properties of words, the inference method is quite differ-
ent. Again, the context of these attacks and even the attack
themselves are quite different.

Again, access pattern is a fundamental issue in the con-
text of Steganographic File Systems. The concept of a
steganographic ﬁle system was ﬁrst proposed by Anderson

et. al. in [1]. The main goal of such a system is to hide the
very existence of the ﬁles it stores from an attacker so that
the users can be protected from compulsion attacks2. Xuan
et. al. presented a steganographic system in [23] that can
hide data access from an attacker who has continuous ac-
cess to the underlying storage system. Unfortunately, it has
been later shown by Troncoso et. al. in [21] that the pro-
posed ﬁle system is susceptible to trafﬁc analysis attacks.
Although, the attack presented in [21] may seem related to
our work, the fundamental objective of these two models
is quite different. In [21], the authors proposed a pattern
recognition model which tries to identify block access pat-
terns in the midst of a seemingly random sequence of block
accesses. That is, their attack model tries to identify the
block access patterns during the repeated access of a given
ﬁle. Once a pattern is identiﬁed, the model successfully ex-
tracts the blocks of that ﬁle, and thus proves the existence
of that ﬁle. Therefore, the scope of this attack model is sig-
niﬁcantly different from ours. Their attack model tries to
discover the data access pattern from a sequence of seem-
ingly random data accesses. Our model, on the other hand,
discovers additional sensitive information using the data ac-
cess patterns. Quite naturally, the attack methodologies are
also quite different for these two attack models.

Therefore, to our best of knowledge, none of the previous
works in the literature analyzed the potential security risks
due to access pattern disclosure in searchable encryption
schemes. We show that an attacker can gain signiﬁcant ad-
vantage by utilizing access patterns with the help of some
background knowledge on the document set. We further
elaborate this point in the following section with an exam-
ple.

A preliminary version of this work has appeared in the
18th ACM Conference on Computer and Communications
Security (CCS ′11) as a 3-page poster abstract [12]. Com-
pared to the CCS paper, we provide a generalized version
of the attack model, a complete mitigation scheme, formal
proofs and additional experiments in this ﬁnal version of the
paper.

3. Motivation

Let us assume Alice stores a set of sensitive documents
regarding Major League Baseball to a remote server (e.g.,
Bob) using a searchable encryption technique that leaks data
access pattern. Furthermore, an attacker Mallory can in-
tercept data access pattern of Alice for an arbitrarily un-
bounded amount of time. Let us also assume that the un-
derlying searchable encryption protocol is safe in the sense
that it does not reveal any information about the document
contents other than the user access patterns. We argue that

2In compulsion attack, the users are forced to hand over the decryption

keys of an encrypted ﬁle.

Mallory can infer some valuable knowledge about query
identities using these access patterns with the help of some
background knowledge on the keyword distribution of the
underlying document set.

Considering the type of the documents stored, let us as-
sume an highly likely scenario, where the words ‘New’,
‘York’ and ‘Yankees’ appear in any given document with a
higher probability than any other subset of words of length 3
in the document set. Now, let us assume Alice sends search
request for these three words interspersed among a set of
other keywords in a particular period of time. After all the
communication rounds are ﬁnished, Mallory sees a list of
trapdoors and the set of documents they appear in. Quite
naturally, Mallory can calculate the probability of any two
of these queried words appearing together in a document
by noticing the number of documents the corresponding
trapdoors appear together. Now, by observing these prob-
abilities, Mallory can easily isolate the three trapdoors rep-
resenting the keyword set {‘New’, ‘York’, ‘Yankees’} be-
cause of their high probabilities. Furthermore, it is likely
that the pair of words ‘New’ and ‘York’ appear together
in some documents to refer to the state or the city, not the
baseball team. Therefore, the probability of both ‘New’ and
‘York’ appearing in a document will be higher than that of
‘New’ and ‘Yankees’ or ‘York’ and ‘Yankees’. This impor-
tant observation enables Mallory to uniquely identify the
trapdoor for the word ‘Yankees’. Furthermore, if Mallory
learns the identity of the trapdoor for ‘New’, she will also
be able to infer the trapdoor for ‘York’. Therefore, it is quite
evident that a modicum of prior knowledge can lead to the
revelation of many encrypted queries and thus lead to sig-
niﬁcant document contents disclosure.

The above mentioned trivial motivating example con-
siders the information revealed by only a few number of
queries. But, an attacker with signiﬁcantly large computing
power can intercept hundreds of hquery, responsei pairs
and combine these access patterns with every piece of in-
formation she has about the document contents to launch a
very successful attack.

In this paper, we show a practical demonstration of such
an attack where an attacker can build a model to identify a
signiﬁcant portion of the queries by combining access pat-
terns with some known background knowledge. Further-
more, we show that conceptually very simple noise addi-
tion techniques can successfully thwart such attacks from
happening.

4. Simpliﬁed Model

To explain the attack concept described in this paper,
we present a simple model to simulate ‘search over re-
mote encrypted data’. A similar type of model was brieﬂy
mentioned in [20]. Before describing the model, we like

various papers including [20] and [10]. Rather, we simply
outline a simple scheme that can simulate the access pattern
disclosures of existing solutions to the ‘search over remote
encrypted data’ so that we may use this scheme to explain
our attack concept.

Now, we can visualize the above scheme as a two step
process. Alice wants to search a keyword w on an en-
crypted document set stored in the server. She evaluates
T rapdoorw and sends it to the server. The server sends her
the document set that contains the word w. It is worth not-
ing that we purposefully omitted some intermediate com-
munication steps between Alice and Bob. The rationale be-
hind this omission is, any third party attacker who has ac-
cess to the communication channel, can omit those interme-
diate communication steps and see the whole protocol as de-
scribed in Fig. 1. Furthermore, we argue that any solution to
the ‘search over encrypted text’ that does not hide the access
pattern of the client, can be viewed as the protocol shown
in Fig. 1. To see why, please note that an attacker, during
keyword search process, can record the documents accessed
to answer the query. Of course, protocols will have differ-
ent processes inside the black box, but when viewed from a
third party attacker, their interaction with Alice will be the
same as Fig. 1.

Hence, we assume that Mallory intercepts messages of
the form hT rapdoorw, {Doc1, · · · Dock}i. As we will
show next, Malory can infer the underlying keyword w of
the query T rapdoorw that appears in each of the documents
in the set {Doc1, · · · , Dock} with the help of some back-
ground knowledge.

5. Notations

Table 1 summarizes a short list of notations we use in

this paper.

In this paper, we informally treat a document as a set of
keywords. So, notations like x ∈ d are extensively used
to mean that keyword x appears in the document d. Fur-
thermore, we assume D and K are a total ordering on the
document set and keyword set respectively. That is why, we
uniquely identify a document by Di for i ∈ [1, n]. Simi-
larly, we can uniquely identify a keyword by specifying Ki
for i ∈ [1, m].

i , K2

i , ..., Km

i ], such that Ki

We mathematically denote the ith keyword Ki as an
m bit row vector [K1
i = 1 and
Kj
i = 0 for ∀j 6= i. Again, we denote Q = hQ1, · · · Qli
be the ordered sequence of queries submitted by Alice for
a given period of time. Here, ∀i ∃j, Qi = T rapdoorKj .
We refer Rq = hd1, · · · , dni as the result sent by the
server in response to a query q = T rapdoorKj such that
di = 1 iff the ith document contains the keyword cor-
responding to the query q and di = 0 otherwise. That
is, if Rq = hd1, · · · , dni be the response for query q and

Figure 1. Simpliﬁed model of search over re(cid:173)
mote encrypted data from Mallory’s point of
view.

to elaborate one very important fact. Our attack model
does not depend on the underlying searchable encryp-
tion scheme. Our attack model succeeds as long as the
searchable encryption scheme reveals data access patterns
to the attacker. Therefore, the model we describe in the
next paragraph is internal to us, and hence should not be
interpreted as a necessary condition for the attack to be suc-
cessful.

In our simpliﬁed model, Alice has a set of keywords she
wishes to search over the document set. At ﬁrst, Alice builds
a modiﬁed Inverted Matrix over the set of documents. That
is, Alice builds a binary matrix, where the rows are indexed
by the keyword set, while the columns are indexed by the
document set. Throughout this paper, we refer to this binary
matrix for an particular instance of ‘search over encrypted
data’ as Index Map (ID). The (i, j)th entry of this Index
Map is 1 iff the ith keyword appears in the jth document,
and 0 otherwise.
In our model, the server Bob performs
searches for different keywords based on this Index M ap.
Since, sending the Index Map in plaintext reveals document
contents, Alice encrypts the rows of this matrix indepen-
dently. Furthermore, she also applies a trapdoor function
on the set of keywords. Finally, Alice sends each of the en-
crypted rows of the matrix along with the trapdoor value of
the corresponding keyword.

When Alice wants to search for a particular keyword, she
applies the keyword to the trapdoor function and sends Bob
the result. Bob performs a simple text matching and sends
Alice the encrypted row of the Index Map. Alice decrypts
the row, and asks for the appropriate set of documents. The
search concludes by Bob sending back the requested docu-
ments.

We like to underscore the statement that we do not pro-
pose a new search scheme by the above discussion. Al-
most identical schemes like this one has been outlined by

Notation

|x|
xT
D
n
K
m
Di
Ki

T rapdoorw

Rq
Q

Table 1. Notations

Meaning
The cardinality of the set x.
The transpose of the matrix x.
An ordered sequence of all the documents stored in the server.
The number of documents in D. That is, n = |D|.
An ordered sequence of all the keywords.
The number of keywords in K. That is, m = |K|.
The ith document in D.
The ith keyword in K.
The output of the trapdoor function with argument w ∈ K.
The result sent by the server in response to a query q.
A sequence of queries in a given time.

q = T rapdoorKj , then each di is deﬁned by the following
function.

does not know the identity of any of the queries in Q,
i.e., k = 0.

di =(cid:26) 0

1

: if Kj /∈ Doci
: if Kj ∈ Doci

Since, Q = hQ1, · · · Qli is the sequence of queries the
client poses to the server at some given interval, the server
sends the corresponding documents as the query answer in
response to each of these queries. It should be noted that in
our settings, the attacker can intercept the queries Qi, can
uniquely identify them, but do not know which keywords
they are associated with. Similarly, he/she can intercept the
documents, but is not able to learn the contents of the docu-
ments.

6. Threat Model

In our model, the attacker, Mallory observes a sequence
of l queries Q = hQ1, · · · Qli submitted by the client to
the server. Naturally, Mallory has also access to the se-
quence of query responses RQi, ∀i ∈ [1, l], since he has
full access to the communication channel. The goal of Mal-
lory is to successfully ascertain the sequence of keywords
KA = hKa1 , · · · Kali, where KA ⊂ K and ∀i ∈ [1, l],
= Qi. That is, Mallory wishes to uniquely
T rapdoorKai
identify the underlying keywords of each of the queries Qi.
In this paper, we show that Mallory has a very high proba-
bility of succeeding if she has access to the following back-
ground knowledge on the document set.

• Mallory knows the underlying keywords for k of
the queries in the sequence Q. That is, Mallory
has access to the set KQ ⊂ KA × Q, where KQ
= {hx, yi |(x ∈ KA) ∧ (y ∈ Q) ∧ (y = T rapdoorx)}
and k = |KQ|. We later show that Mallory can be suc-
cessful with very high probability even when k << l.
Furthermore, we empirically show that Mallory has
high probability of being successful even when she

• Mallory has an m × m matrix M . Please recall
that m is the number of possible keywords in our
model. Each (i, j)th cell in matrix M contains the ex-
pected probability of both ith and jth keywords ap-
pearing in any random document d ∈ D. That is,
Mi,j = P r [(Ki ∈ d) ∧ (Kj ∈ d)], where d is a doc-
ument sampled uniformly from the set D.

An attacker can simulate the matrix M by carrying out
a probabilistic analysis over the large publicly available on-
line datasets. Sophisticated frequency analysis techniques
can also be used to approximate M . Again, an inside at-
tacker may already have access to a sizable subset of the
original dataset in his/her disposal. Therefore, he can cre-
ate the background matrix from this subset. In this case,
there is a signiﬁcant probability that this matrix is a reason-
able approximation of the background matrix M our model
requires. We later empirically show that our model works
reasonably well for a noisy background knowledge matrix.
Therefore, we argue that the background matrix M does not
have to be completely accurate. Rather, any close approxi-
mation of M is sufﬁcient for an successful attack. For ex-
ample, there are quite a substantial number of WikiLeaks
documents in public domain now. An adversary can use
a related subset of documents to come up with a matrix
that can approximate a background matrix M for a dataset
that involves dimplomatic affairs. We plan to explore the
ways to build the background matrix and their effects on
our model in further details in the future.

Again, obtaining a set of known queries might prove
to be a difﬁcult task for an attacker under some scenario.
But, we still ﬁnd it appropriate to add it as a background
knowledge in our model for the following reasons. First,
we empirically show that our model performs quite well
even when the adversary does not have access to a set of
known queries. Therefore, an attacker only uses this known

query set when he has access to it. He still does quite well
when he does not have access to this set. Second, under
some scenario, it is quite possible for an inside attacker to
know a known query set. And ﬁnally, we believe that any
secure searchable encryption scheme should not reveal any
additional query content given a set of known queries. The
Oblivious RAM [11] is one such secure protocol. There-
fore, we ﬁnd it justiﬁed to consider the set of known queries
as a part of the background knowledge the adversary has in
our model.

To best explain our proposed model, we introduce the
attack concept with a simpliﬁed but effective version of the
model in the following section. Later, we proceed to present
a more generalized attack model in the subsequent section
of this paper.

7. Simpliﬁed Attack Model

In this section, we describe how Mallory can formu-
late an attack to identify query identities as an optimiza-
tion problem with constraints. Here, Mallory has access to
the communication channel, and thus intercepts a set of l
queries Q = hQ1, · · · , Qli and has access to KQ and M as
deﬁned earlier. Let us assume that Mallory already knows
the corresponding keywords for each of the queries in the
set S ⊂ Q. That is, S = {y|∃x hx, yi ∈ KQ}. Now, the
goal for Mallory is to assign keywords to all the queries
q ∈ (Q − S) such that the joint keyword distribution as
seen by the message responses Rq ﬁts our prior knowledge,
namely the background knowledge matrix, M .

Hence, Mallory tries to ﬁnd a sequence of l indices
: Qj =
, given the matrix M . We present the sim-

ha1, · · · , ali s.t. Mallory believes that ∀j
T rapdoorKaj
pliﬁed attack model as an optimization problem by Eq. 1.

argmin

ha1,··· ,ali XQi,Qj ∈Q  RQi · RT

Qj

n

−(cid:16)Kai · M · KT

aj(cid:17)!2

(1)

Constraints : ∀j s.t. Qj ∈ S, aj = xj s.t. hKxj , Qji ∈ KQ

∀j, k Qj k= 1

The ﬁrst constraint in Eq. (1) guarantees that the known
queries will be assigned to their correct known keywords.
While the second one makes sure that all the queries in the
set has an assignment of a valid keyword format, i.e., each
query Qj conforms to the query format outlined in section
5.

The result of this constraint satisfying optimization prob-
lem is an assignment of keywords to the queries that

achieves minimum distance from our background knowl-
edge matrix M .

n

To explain the model described in Eq. (1), let us con-
sider the following example. Suppose, Qs and Qt are two
encrypted queries. Therefore, Mallory can calculate the
probability of the underlying keywords appearing together
in a given document by β = RQs ·RQt
, here · operation
denotes the “dot” product between two vectors. Now, for
any two given keywords Kf and Kg, Mallory can calculate
the probability of these two keyword appearing together by
γ = Mf,g. When, the keywords Kf and Kg are presented
by their proper bit-vector representation, γ can be equiva-
lently written as γ = (Kf · M · KT
g ). Here, · operation de-
notes matrix multiplication. Naturally, Mallory will assign
Kf , Kg to the queries Qs, Qt iff the observed probability
from the query response β is close to the known probabil-
ity γ. This closeness can be measured by a simple arith-
metic distance function (β − γ)2
, where a lower value of
this function is preferred over a higher value. So, the aim of
Mallory will be to assign keywords to queries such that this
distance function is minimized. Our model given by Eq.
(1) is just a formalization of this objective function.

8. Generalized Model

In this section, we outline the generalized version of the
proposed attack model. Here, instead of taking the joint
probability distribution of keyword pairs, we consider joint
probability distributions up to r keywords. In this model,
instead of the background matrix M , Mallory has access to
a family of r functions F = {Fi}. The ith function in the
family F , denoted as Fi : Ki → [0, 1] takes i keywords as
arguments and returns the probability of all of these i key-
words appearing in a document d sampled uniformly from
the document set D. That is, Fi can be deﬁned by the fol-
lowing equation.

Fi(K1, · · · , Ki) = P r [(K1 ∈ d) ∧ · · · ∧ (Ki ∈ d)]

(2)

Before we present our generalized attack model, let us
deﬁne a crude version of “dot” product for p equal length
vectors3.

Deﬁnition The MSP (M ulti Scalar P roduct) function, de-
noted by ⊙, takes as argument p equal length binary vectors
V1, · · · , Vp and returns a positive integer. Let us assume
that each vector Vi is a q bit vector s.t. Vi = hV 1
i i.
Then, ⊙ is deﬁned as follows.

i · · · V q

⊙(V1, · · · Vp) =

q

p

Xi=1

Yj=1

(V i
j )

(3)

3The value of p can be arbitrarily greater than 2.

It should be noted that the M SP function deﬁned above
degenerates to the conventional “dot” product operation for
the limiting case of p = 2.

Also in this generalized model, Mallory aims to ﬁnd a
sequence of l indices ha1, · · · , ali s.t. Mallory believes that
∀j : Qj = T rapdoorKaj

, given the function family F .

Let us deﬁne ci for i ∈ [1, k] for a given sequence of

indices ha1, · · · , ali in the following way.

ci = XQ1,···Qi∈Q(cid:18) ⊙(RQ1 · · · RQi)

n

− (Fi(Ka1 , · · · , Kai))(cid:19)2

(4)
Here, ⊙(RQ1 · · · RQi) returns the number of documents
where all of the underlying keywords corresponding to the
query response sequence RQ1 · · · RQi appear in. Again,
let us deﬁne w = (w1, w2..., wk) be a real-valued weight
vector. Our model can be expressed in terms of Eq. (4) in
the following way.

argmin
ha1,··· ,ali

wi · ci

k

Xi=1

(5)

Subject to: ∀i∀j s.t. Qj ∈ S, aj = xj s.t. hKxj , Qji ∈ KQ

∀i∀j, k Qj k= 1

Unfortunately, the optimization problem presented in our
generalized model is N P − Complete. In fact, we show in
T heorem 1 that even a smaller subset of the given problem,
i.e., the optimization problem given for the simpliﬁed model
in Eq. (1), is N P − Complete.

Theorem 1. Finding an optimal assignment of keywords to
a given set of queries w.r.t. the objective function deﬁned by
Eq. (1) is N P − Complete.

For interested readers, the proof of T heorem 1 is pre-

sented in Appendix A.

Therefore, it is quite evident that solving the optimiza-
tion problem outlined earlier is computationally infeasi-
ble for large dataset. Quite naturally, we propose an efﬁ-
cient approximation of this problem that uses Simulated An-
nealing [15]. Simulated Annealing is a probabilistic meta-
heurestic which is frequently used to ﬁnd good approxima-
tion to the global optimum of some given function when the
search space is large. It turns out that if we run the optimiza-
tion problem long enough, a signiﬁcant subset of the query
set Q can be successfully revealed. A detailed description
of the algorithm of our optimizer for the simpliﬁed attack
model is given in Fig. 2 at page 8.

9. Experiment Results

In this section, we present an empirical evaluation of our
proposed simpliﬁed attack model on various instances of
‘search over remote encrypted data’. In our experiments,
we use a real world dataset, namely, the Enron dataset as
our corpus [16]. We also use a well known stemming tech-
nique such as Porter Stemming Algorithm [19] to ascertain
the root of every keyword. Our experimental results sug-
gest that even the simpliﬁed model can predict the identity
of over 80% queries for large datasets. On the other hand,
the execution time of the implemented model suggests that
the proposed approximation of the model is quite efﬁcient.
Rest of this section is organized as follows. We describe our
methodology ﬁrst, then describe various experiments and
explain their results.

9.1. Experimental Setup

9.1.1 Dataset Used

As we have already mentioned, we use Enron dataset as
our corpus [16]. This dataset was originally prepared by
the CALO Project (A Cognitive Assistant that Learns and
Organizes). This dataset has already been extensively used
in various study in the past [3, 6, 9]. Enron dataset contains
emails of about 150 different users. The dataset is organized
into various folders. We have chosen all the 30109 emails
contained in the sent mail folder of all the users as our
experimental dataset. This dataset was made public by the
Federal Energy Regulatory Commission during its investi-
gation.

The most important characteristic of this dataset is that
each of the documents is a real email sent by a person. One
of the motivations [20] behind ‘search over encrypted data’
is to store emails to a remote server in encrypted format
and search the emails from time to time. Therefore, we ﬁnd
it appropriate to run our experiments on real email dataset
like that of enron. The ﬁrst few lines for each of the emails
contains some metadata about that mail. Since, these lines
are not part of the original email, we strip these lines off the
email documents as a preprocessing step.

9.1.2 Stemming Algorithm

Since, most of the emails are personal in nature, they cap-
ture informal communication made between two individu-
als. Therefore, we use a stemming algorithm, namely the
Porter Stemming Algorithm [19] to ﬁnd the root of each
of the words in the document set. Throughout this sec-
tion, it will be implicitly assumed that all the processing
step on the keywords have been done after the keywords
have gone through the porter stemming algorithm. It should

Figure 2. Algorithm for Optimizer.

)

%

(
 
y
c
a
r
u
c
c
A

)

%

(
 
y
c
a
r
u
c
c
A

Accuracy for different Keyword Set Size

Accuracy for different Query Set Size

 100

 80

 60

 40

 20

 0
 500

)

%

(
 
y
c
a
r
u
c
c
A

 100

 80

 60

 40

 20

 0

 1000

 1500

 2000

 2500

 0

 50

 100

 150

 200

 250

 300

Keyword Set Size (m)

(a)

Query Set Size

(b)

Accuracy for different known query size

Accuracy for low known query size

 100

 80

 60

 40

 20

 0

 0

 100

 80

 60

 40

 20

)

%

(
 
y
c
a
r
u
c
c
A

 0

 0

 1

 2

 3

 4

 5

 6

Known Query Size (%)

 5

 10

 15

 20

 25

 30

Known Query Size (%)

(c)

(d)

Figure 3. Accuracy for various (a) Keyword Set Size. (b) Query Set Size. (c) Known Query Set Size.
(d) Low Known Query Set Size.

be noted that we have used an implementation of Porter’s
Stemming [19] written by its author Martin Porter.

9.1.3 Keyword Generation

Our whole corpus of 30109 documents contains 77000
unique keywords after getting rid of most common 200
words like ‘the’, ‘a’, ‘from’ etc. We sort these keywords
based on the decreasing number of their occurrences and
always use the ﬁrst x number of words as our keywords.
We refer to this x as the keyword set size.
It should be
noted that the value of x differs from experiment to exper-
iment. But, unless noted otherwise, the keyword set size
are always chosen as the most frequent x words out of the
77000 unique words.

9.1.4 Query Generation

Query patterns of individual users are expected to vary quite
signiﬁcantly. Therefore, it is hard to adopt a methodology
that is able to capture the idiosyncratic behaviors of all the
users. To make matter worse, we did not ﬁnd any real-world

query set on the Enron dataset. Therefore, we use Zipﬁan
Distribution to create synthetic query sets from our key-
word set. Fortunately, our attack scheme does not use query
frequency. Therefore, our attack can be equally applicable
to any other query distribution. Furthermore, we suppress
query repetition from the attack model to undermine the ef-
fects of our query generation process on the model accu-
racy. That is, we generate the query set in such a way that
no keyword is chosen as a query more than once. It should
be noted that such suppression does not limit the applica-
bility of our model in anyway. This is because, an attacker
can always identify the duplicate queries and discard them
before applying to the attack model.

To generate the query set, we sort the keyword set in
If a particular key-
non-increasing order of occurrences.
word appears in the jth position in this list, we call the rank
of this keyword j. According to the Zipﬁan distribution, the
probability of this keyword being chosen as query (P rj) is
given by the following4.

4If the keyword chosen is already in the query set, we discard it to

suppress query repetition.

P rj =

1
j
Nx

=

1

j × Nx

.

1

i=1

Here, the denominator Nx = Px

j is the normaliza-
tion factor. According to the Zipf’s law, in a corpus of nat-
ural language utterances, the frequency of appearance of an
individual word is inversely proportional to its rank [24].
Since, we run our experiments on natural language corpus,
we argue that the queries might follow zipﬁan distribution.
But, we like to stress that our attack scheme does not use
query frequency. Therefore, our attack can be applicable
to any other query distribution.

9.1.5 Execution Time

We use a serial implementation of our model for all the
experiments mentioned in this paper. This implementation
took no more than 14 hours to ﬁnish for any of the exper-
iments in a AMD Phenom II X6 1045T Windows 7 ma-
chine clocked at 2.70 GHz with 8 GB of system memory.
Our model is supposed to run even faster if we allow paral-
lel computation. Therefore, we argue that the attack model
we present in this paper is quite efﬁcient.

9.2. Experiment & Results

9.2.1 Accuracy over varying Keyword Set Size

Fig. 3(a) in page 9 shows the accuracy (%) for various key-
word set size. Here, we have chosen the keyword set size to
be multiples of 500 with the maximum value of 2500. Key-
words were generated according to the Keyword Generation
step described earlier. The number of queries for this exper-
iment was set at 150 and 15% of the queries were known
beforehand.
It is quite evident that for relatively smaller
keyword set size, the attack model can correctly identify al-
most all the queries. But, as the keyword set size increases,
the identiﬁcation accuracy is decreased. But, even for key-
word set size of 2500, the model can successfully identify
most of the queries.

9.2.2 Accuracy over varying Query Set Size

Fig. 3(b) in page 9 shows the accuracy (%) for various
query set size. Here, we have chosen query set size to the
multiples of 50 with the maximum being 250. Queries were
generated using the Zipiﬁan distribution as described ear-
lier. Our model works fairly well for a small query set size
of 50. But, as the query set size goes up, the accuracy of
the model goes higher as well. This is due to the fact that
higher query set size indicates that higher portion of the
background matrix M is used to predict the query identity.

Accuracy for different values of Scaling Factor (C)

 100

 80

 60

 40

 20

)

%

(
 
y
c
a
r
u
c
c
A

 0

 0

 0.2

 0.4

 0.6

 0.8

 1

Noise Scaling Factor (C)

Figure 4. Accuracy (%) for different Noise
Scaling Factor C.

x, the keyword set size is chosen to be 1500 for this exper-
iment and 15% of the queries were assumed to be known
beforehand.

9.2.3 Accuracy for varying Known Query (%)

In this experiment, we have run experiments for varying
known query (% of Query set size). We start off with 5%
known query and increase it upto 25%. It is quite appar-
ent from Fig. 3-(c) in page 9 that increasing the known
query size does not improve accuracy that much. Rather,
the accuracy measurement are almost similar for different
known query sizes. Fig. 3-(d) in page 9 shows the accuracy
for very low known query percentage. We can see that the
model can successfully identify nearly 80% of the queries
correctly even if there are no known queries. This proves
that the model is quite useful even without the knowledge
of known queries. For this experiment, we ﬁx the keyword
set size to 1500 and the query set size to 150.

9.2.4 Accuracy for Noisy Matrix

All the experiments described up to this point has an im-
plicit assumption that the attacker has access to a perfect
background matrix M . But, getting a perfect matrix M
may proved to be difﬁcult under some scenario, even im-
possible under others. That’s why, we have investigated
the accuracy of our model under a noisy matrix M . Let,
σ2 = V ar{Mi,j}. That is, σ2 is the variance of the set of
elements in the matrix M . We modeled the noise for the
elements of the matrix M as a N ormal Distribution with
mean 0 and variance C × σ2. Here, C is a constant, which
we refer to as ‘noise scaling factor’. That is, the noise will
increase as C increases. We added noise to the element of
the matrix M according to the distribution N (0, C ·σ2). For
this experiment, we ﬁxed our keyword set size to be 1500,

Query set size to be 150 and (%) known query to be 15%.
We varied noise scaling factor C and present the result in
Fig. 4. It can be deduced from Fig. 4 that our model works
fairly well for low values of C. Even when the noise scal-
ing factor is 1.0, our model predicts a reasonable number of
query identities accurately.

10. Preventing Inference Attack

In this section, we develop a framework to thwart ‘In-
ference Attacks’ described earlier. Our proposed frame-
work aims to make query responses as similar as possible
at the expense of a few false positives. We assume, even
a very small false negative rate is unacceptable in the con-
text of search over remote encrypted text. But, a few false
positives, on the other hand, is acceptable in the sense that
the client can easily detect these false positives and discard
them upon decrypting the documents.

It should be noted that our proposed mitigation scheme
only aims to thwart the inference type of attacks described
earlier. It does not guarantee the overall security of a search-
able encryption scheme. For example, even with our mit-
igation scheme in place, an attacker may still be able to
extract some sensitive information by applying a different
attack model that uses query frequencies and some other
useful domain knowledge. Guarantee of the overall secu-
rity requires rigorous study of all the vulnerable aspects of
a searchable encryption schemes. We leave such a study as
a possible future work. Therefore, in the following sections,
we propose a mitigation scheme that provides security only
against the inference attack described earlier in this paper.

10.1. Our Framework

To explain our framework, we like to use the simpliﬁed
model we have described in Section 4. But, it worths not-
ing that the framework, does not depend on the underlying
model in anyway. That is, our concept can be easily applied
to any searchable encryption scheme.

In our simpliﬁed model, we assume that the server holds
a bitmap for each of the query words. Of course, these
bitmaps are stored encrypted for the sake of privacy. Once a
query is serviced by a server, the client decrypts the bitmap
and request the relevant documents. Thus, the server has
a mechanism to relate a particular encrypted keyword and
the list of documents that contain the keyword. Our ap-
proach formulates a mechanism to add fake documents in
the bitmaps so as to prevent attacks described above by the
server, or any third party eavesdropper.

Let us assume ID ∈ m × {0, 1}n be an index matrix s.t.

each (i, j)th entry IDi,j is deﬁned in the following way.

IDi,j =(cid:26) 0 : if Ki /∈ Dj

1 : if Ki ∈ Dj

Here, Ki is the ith keyword and Dj is the jth document.
Again, we denote the ith row of the matrix ID by IDi.
Given two bit strings A and B of same length k, we de-
ﬁne the function dH : {0, 1}k × {0, 1}k → N to be the
function that returns the Hamming Distance between its
arguments.

11. Privacy Deﬁnition

Deﬁnition (α, t) − secure index. We say an m × n binary
index matrix ID is (α, t) − secure for a given α ∈ [1, m]
and t ∈ N , if there exists a set of partitions {Si} s.t. the
following holds.

1. The partition set is complete. That is,Si Si = [1, m].

2. The partitions in the set are non-overlapping. That is,

∀i, j, Si ∩ Sj = ∅.

3. Each partition has at least α rows. That is, ∀j, |Sj| ≥

α.

4. Finally, the hamming distance between any two rows
of a given partition j is at most t. That is, ∀i1, i2 ∈ Sj,
dH (IDi1 , IDi2 ) ≤ t.

It should be noted that an m × n matrix ID is (m, 0) −
secure if all the rows of the matrix ID is identical to each
other. On the other extreme, any matrix ID is (α, n) −
secure for any value of α ≤ m. Informally speaking, an
(α, 0) − secure index matrix guarantees that for each key-
word, there are at least α−1 keywords which appear exactly
in the same set of documents. Therefore, it’s hard for an at-
tacker to distinguish a keyword given the query response of
that particular keyword.

Theorem 2. Let ID be an m × n (α, 0) − secure index
for some 0 < α ≤ m. Given the response of a query
qi = T rapdoorw for some keyword w and the complete ID
matrix, an attacker can successfully identify the keyword w
with probability at most 1
α by just using background infor-
mation related to ID matrix.

Proof The attacker has the complete ID matrix and the
query response of qi. Now, the query response of qi is a
row of ID matrix. Let’s assume, without loss of general-
ity, the response of qi is the jth row of the ID matrix for
some unique j s.t. 1 ≤ j ≤ m. Since, the matrix ID is
(α, 0) − secure, there are at least α − 1 rows of ID which
are exactly identical to each other. Hence, the attacker can
ﬁnd this set S of at least α rows that are exactly similar to
IDj. Since, we assume that our trapdoor function is secure,

the attacker can at best select an element from the set S ran-
domly. Therefore, the attacker can successfully identify w
with probability at most 1
α .

T heorem 2 states that an attacker can successfully iden-
tify a keyword from a query response with probability at
most 1
α even in the unlikely case of having full access to
the index matrix. Here, we assume that the query repetition
is visible to the attacker. Naturally, the attacker has signif-
icantly smaller chance of success when he does not have
full access to the complete index matrix, rather has access
to some partial information, for example, the background
knowledge matrix used in previous sections. Therefore, we
argue that making an index matrix (α, 0)−secure can make
keyword frequency based attack signiﬁcantly harder.

12. Securing Index Matrix

In this section, we outline our approach to transform a
given m × n index matrix into a (α, 0) − secure matrix.
It should be noted that an existing index matrix may not
be modiﬁed by putting 0′s in place of 1′s for any row in-
dexed by a keyword w. Otherwise, search results for this
keyword w will be incomplete. That is, the resultset will
not contain some documents in which the keyword belongs
to, namely, the documents corresponding to those 1′s which
has been made 0′s. Furthermore, the user may well be un-
aware of these documents. Therefore, we assume that f alse
negatives are not allowed, which in turn prohibits replac-
ing 1′s with 0′s in any row of the matrix. On the other hand,
replacing 0′s with 1′s may induce some false positives in
the resultset, which can be detected later by the user upon
decrypting the documents. Therefore, the user can safely
discard these f alse positives. Hence, introducing some
false positives in the resultset will only affect performance,
not accuracy.

Deﬁnition The function tα : {0, 1}m×n → {0, 1}m×n
takes an m × n binary index matrix ID and re-
turns a (α, t) − secure matrix ID′ s.t.
the function
i)) is minimized for a given weight
i,j = 1) holds.

vector w, and if ∀i, j, (IDi,j = 1) =⇒ (ID′

i=1 wi · dH (IDi, ID′

(Pm

It should be noted that in the process of making rows of
the index matrix similar, we are adding false positives. This
will result in increased communication overhead as well as
processing overhead. The function tα is deﬁned in a way
so that it converts a given ID matrix to the closest (α, t) −
secure matrix. We deﬁne the cost of an transformation as
follows.

Deﬁnition If an m×n index matrix ID is transformed into
an m × n (α, 0) − secure index matrix ID′ by applying the

: A index matrix ID

Input
Output: A (α, 0) − secure index matrix ID′

Run clustering algorithm on the rows of ID to get
p clusters.;
while Any cluster Cp have less than α elements do

combine the cluster Cp to the nearest cluster.

end
for each of the cluster Cp do

Feed the set of elements of Cp to the tα
function to obtain a new set of elements S ;
Replace the set Cp by S in ID ;

end
return ID;

Algorithm 1: Approximation algorithm to trans-
form a index matrix into a (α, 0) − secure matrix

function tα, the cost of such a transformation is denoted by
the function ct, deﬁned as follows.

ct(ID, ID′) =

m

Xi=1

dH (IDi, IDi

′).

Informally speaking, the function ct returns the total
number of elements IDi,j where a 0 bit has been changed
to a 1 bit to obtain the matrix ID′. Thus, minimizing the ct
function will ultimately result in a less number of false pos-
itives to be injected into the (α, 0) − secure matrix ID′. It
can be easily showed that tα function converts a given ID
matrix to a (α, 0) − secure matrix s.t. the cost function ct
is minimized.

Based on this observation, we can convert a given index
matrix ID to a (α, 0) − secure matrix ID′ by applying the
tα function on the matrix ID.

The main hurdle of ﬁnding an optimal conversion of
a given matrix to a (α, 0) − secure matrix is that ﬁnd-
ing an optimal partitioning of rows is hard.
It turns out,
the problem of ﬁnding such optimal partitioning belongs to
N P − hard [13]. Therefore, we propose an approximation
algorithm given in Algorithm 1 to convert an index matrix
ID to a (α, 0) − secure index matrix.

Although, Algorithm 1 returns a (α, 0) − secure in-
dex matrix, the ct measure is not optimally minimized. But,
since the optimal reduction of ct is computationally infea-
sible, Algorithm 1 is a very good approximation of the
optimal conversion. To test the efﬁciency of our approach,
we have implemented Algorithm 1 and present our results
in the following section. We use agglomerative hierarchi-
cal clustering algorithm [2] with average distance. Further-
more, we use cosine distance as our distance measure.

Accuracy for different values of α

Cost for different values of α

)

%

(
 
y
c
a
r
u
c
c
A

 30

 25

 20

 15

 10

 5

 0

t
s
o
C

 8

 7

 6

 5

 4

 3

 2

 1

 0

 1

 2

 3

 4

 5

 6

 1

 2

 3

 4

 5

 6

α

(a)

α

(b)

Figure 5. Accuracy and cost for different α values.

13. Experiment & Results

In this section we present the efﬁciency of our approach
of evading attack model described in the earlier sections
for different values of α. We run the experiments for
α ∈ {2, 3, 4, 5}. Fig. 5(a) shows the accuracy for dif-
ferent values of α. For these experiments, we have ﬁxed the
keyword set size to be 1500, query set size to be 150 and
the (%) known query to be 15% (i.e., best possible scenario
for attacker as identiﬁed by previous experimental results).
Furthermore, we assume the background matrix M to be
perfect, that is, no element of M contains any noise (again,
this is optimal from attackers point of view). From Fig. 5-
(a), it is evident that the accuracy is almost equal to that of
the (%) known query. That is, the attacker failed to suc-
cessfully identify queries any other than the known queries.
Fig. 5-(b) presents the increased cost because of the con-
verted ID′ matrix. We deﬁne cost as the ratio of increase in
number of documents retrieved by the new ID matrix to the
number of documents retrieved by the old matrix. That is,
Let, p = (number of documents returned for the old matrix
ID), and q = (number of documents returned for the new
matrix ID′). Then, the cost is deﬁned as, cost = q−p
p . It
is apparent from Fig. 5-(b), that the percent increase in the
cost is increased as the value of α is goes up.

To compare the cost of our proposed mitigation strategy
with ORAM based solutions, we analyzed the ORAM con-
struction given in [22]. To our knowledge, the ORAM solu-
tion proposed by Williams et. al. in [22] is one of the most
efﬁcient ORAM constructions available in the literature.

The protocol in [22] has a computational overhead of
O(log n log log n) per request for n data items. This over-
head includes the constant factor of 1.44c for an allowed
error probability of 2−c along 5 with other constant factors

5If we assume, c = 64, then the constant 1.44c is 92 itself. Please

see [18] for more details.

in the big O [18]. Based on this analysis, we can accurately
approximate the value of the constant associated with this
overhead to be around 100. Now, let us assume the number
of data items to be 1024 or (210). That is, n = 1024. There-
fore, log n = 10. Then, even the most efﬁcient ORAM pre-
sented in [22] requires more than 100 × 10 = 1000 data
items to be retrieved for a single data access. Furthermore,
this overhead grows much larger when the number of data
items (n) increases. In our approach, on the other hand, the
required overhead is only 3 − 5 accesses per request and
does not change as n increases. Therefore, our approach
is more efﬁcient than the ORAM constructions. But, un-
like our case, ORAM approach hides all the access pattern
disclosure.

Therefore, it is evident from the above discussion that
adding noise to the index matrix is quite efﬁcient in thwart-
ing Inference Attacks. But, this approach incurs some ad-
ditional computational overhead. However, this overhead is
still quite negligible when compared to that of the most efﬁ-
cient ORAM constructions. Therefore, we argue that noise-
addition based mitigation scheme is quite useful where ef-
ﬁciency is a major concern. However, if an user is only
concerned about privacy, efﬁcient versions of ORAM is per-
haps a better choice.

14. Conclusions

In this paper, we investigate the potential vulnerabil-
ity posed by the disclosure of data access patterns during
‘search over encrypted text’. We formalize a model that can
be used to launch an inference attack utilizing this vulnera-
bility and empirically show their efﬁciency in successfully
predicting query identities. Furthermore, we present a sim-
ple noise addition scheme to thwart such attacks with the ex-
pense of retrieving a slightly more documents than needed.
We conclude that ‘hiding access pattern’ is extremely im-

portant in encrypted keyword search and therefore is a nec-
essary characteristics of a secure encrypted search scheme.

15. Acknowledgements

This work was partially supported by Air Force Ofﬁce of
Scientiﬁc Research MURI Grant FA9550-08-1-0265, Na-
tional Institutes of Health Grant 1R01LM009989, National
Science Foundation (NSF) Career Grant CNS-0845803,
NSF Grants CNS-0964350,CNS-1016343.

References

[1] Anderson, Needham, and Shamir. The steganographic ﬁle
In IWIH: International Workshop on Information

system.
Hiding, 1998.

[2] P. Berkhin. Survey of clustering data mining techniques.

Technical report, Accrue Software, San Jose, CA, 2002.

[3] M. Berry and M. Browne. Email surveillance using non-
negative matrix factorization. Computational & Mathemat-
ical Organization Theory, 11(3), 2005.

[4] D. Boneh, G. Crescenzo, R. Ostrovsky, and G. Persiano.
Public key encryption with keyword search. In proc. of EU-
ROCRYPT, 2004.

[5] D. Boneh, E. Kushilevitz, and R. Ostrovsky. Public key en-
cryption that allows PIR queries. In proc. of CRYPTO, 2007.
[6] K. Borgwardt, H. Kriegel, and P. Wackersreuther. Pattern
mining in frequent dynamic subgraph. In ICDM, pages 818–
822. IEEE Computer Society, 2006.

[7] Y. Chang and M. Mitzenmacher. Privacy preserving key-
In International
word searches on remote encrypted data.
Conference on Applied Cryptography and Network Security
(ACNS), LNCS, volume 3, 2005.

[8] R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky. Search-
able symmetric encryption: improved deﬁnitions and efﬁ-
cient constructions. In proc. of the 13th ACM Conference on
Computer and Communications Security, CCS 2006, pages
79–88. ACM, 2006.

[9] J. Diesner, T. Frantz, and M. Carley. Communication net-
works from the enron email corpus. Computational & Math-
ematical Organization Theory, 11(3), 2005.

[10] E. Goh. Secure indexes. Cryptology ePrint Archive, (Report

2003/216), 2003.

[11] O. Goldreich and R. Ostrovsky. Software protection and
simulation on oblivious RAMs. JACM: Journal of the ACM,
43, 1996.

[12] M. S. Islam, M. Kuzu, and M. Kantarcioglu. Poster: In-
ference attacks against searchable encryption protocols. In
CCS, pages 845–847. ACM, 2011.

[13] B. Jackson, J. Scargle, C. Cusanza, D. Barnes, D. Kanygin,
R. Sarmiento, S. Subramaniam, and T. Chuang. Optimal
partitions of data in higher dimensions. In proc. of the Con-
ference on Intelligent Data Understanding, pages 98–108.
NASA Ames Research Center, 2010.

[14] S. Kamara and K. Lauter. Cryptographic cloud storage.
In Financial Cryptography Workshops, volume 6054, pages
136–149. Springer, 2010.

[15] S. Kirkpatrick, C. Gelatt, and M. Vecchi. Optimization
by simulated annealing. Science, 220(4598):671–679, May
1983.

[16] B. Klimt and Y. Yang.

Introducing the enron corpus.

In

CEAS, 2004.

[17] R. Kumar, J. Novak, B. Pang, and A. Tomkins. On
anonymizing query logs via token-based hashing.
In Pro-
ceedings of the 16th International Conference on World
Wide Web, WWW, pages 629–638. ACM, 2007.

[18] B. Pinkas and T. Reinman. Oblivious RAM revisited. IACR

Cryptology ePrint Archive, 2010:366, 2010.

[19] M. Porter. An algorithm for sufﬁx striping. Program,

14(3):130–137, 1980.

[20] D. Song, D. Wagner, and A. Perrig. Practical techniques for
searches on encrypted data. In IEEE Symposium on Security
and Privacy, 2000.

[21] C. Troncoso, C. D´ıaz, O. Dunkelman, and B. Preneel. Traf-
ﬁc analysis attacks on a continuously-observable stegano-
graphic ﬁle system.
In Information Hiding, volume 4567,
pages 220–236. Springer, 2007.

[22] P. Williams, R. Sion, and B. Carbunar. Building castles out
of mud: practical access pattern privacy and correctness on
untrusted storage. In Proceedings of the 2008 ACM Confer-
ence on Computer and Communications Security, Alexan-
dria, Virginia, USA, October 27-31, 2008, pages 139–148.
ACM, 2008.

[23] X. Zhou, H. Pang, and K.-L. Tan. Hiding data accesses in
steganographic ﬁle system. In ICDE, pages 572–583. IEEE
Computer Society, 2004.

[24] G. Zipf. Selected studies of the Principle of Relative Fre-

quency in Language. Harvard U.P., 1932.

Appendix A

Proof of Theorem 1 Let C = {e1, e2, ..., en}, P =
{p1, p2, ..., pm} be the encrypted and plain keyword lists
and MC , MP be the pair similarity matrices for E and P
respectively such that n ≤ m. Let B = {(i, j)|f (ei) =
pj, 1 ≤ n, 1 ≤ j} be a set of pairs where f is a bijection
from E to P and cost : B 7→ Integer be the evaluation
function which is deﬁned as follows:

n

n

(MC[i, j] − MP [k, l])2

cost(B) =

s.t.

Xi=1

Xj=i

(i, k) ∈ B, (j, l) ∈ B

Notice that constructed setting is equivalent to formu-
lated optimization problem. We can formulate the decision
version of the problem as follows: Given C, P along with
MC and MP , does there exist any B such that cost(B) ≤
k?

It is easy to see that the problem is in NP. The certiﬁcate
is the mapping set (B) and a certiﬁer can check if the cost(B)
is at most the given bound (k) in polynomial time.

We now show that the problem is NP-Hard by a reduc-
tion from the Hamiltonian path problem. Given an instance
of Hamiltonian path problem speciﬁed by graph G(V, E), we
can construct an input < C, P, MC , MP , k > for decision
version of the optimization problem as follows.

(vi, vj) ∈ E and i < j

otherwise

(6)

(7)

(8)

(9)

(cid:27)

C = V
P = {1, 2, ..., n}, n = |V |

where, 1 ≤ i ≤ n, 1 ≤ j ≤ n

0

MC[i, j] =(cid:26) w if
MP [i, j] =(cid:26) w if

0

j = i + 1

otherwise (cid:27) 1 ≤ i ≤ n, 1 ≤ j ≤ n
otherwise (cid:27)

|E| < |V | − 1

(10)

if

0

(11)

k =(cid:26)

w2(|E| − |V − 1|)

We claim that there is a mapping set B for the input <
C, P, MC , MP , k > such that cost(B) ≤ k if and only if G
has a Hamiltonian path.

Without loss of generality, suppose G has a Hamilto-
nian path v1, v2,
..., vn. Since G has an Hamiltonian
path, it should have at least |V | − 1 edges. Thus, k =
w2(|E| − |V − 1|).
In this case, cost of assignment set
{(1, 1), ...(i, i), ..., (n, n)} is bounded by k. In such a case,

n

n

cost(B) =

s.t.

Xi=1

Xj=i

i = j

(MC[i, j] − MP [k, l])2

case i : j = i + 1
By the construction of MP , MP [i, j] = w, similarly
MC[i, j] = w for this case since there exists an edge
j=i(MC[i, j] −

between (vi, vi+1). Therefore, Pn

MP [i, j])2 = 0 for this case.

i=1Pn

case ii : j 6= i + 1

By the construction of MP , MP [i, j] = 0, MC[i, j] = w
if (vi, vj) ∈ E and i < j, MC[i, j] = 0 otherwise for this
case. There exist |V | − 1 edges (vi, vj) such that j = i + 1
which implies the existence of (|E| − |V − 1|) edges such
that i 6= j +1. Hence, MC[i, j] = w for (|E|−|V −1|)(i, j)
j=i(MC[i, j] − MP [i, j])2 =

pairs. Therefore Pn

w2(|E| − |V − 1|) for this case.

i=1Pn

Cases i and ii covers all possible (i,j) pairs. Therefore

cost(B) = w2(|E| − |V − 1|) = k

Conversely, suppose cost(B) ≤ k for some B, then G
has a Hamiltonian path. For the sake of contradiction, sup-
pose G has no Hamiltonian path, then

case i : |E| < |V | − 1 → k = 0
By the construction of MP , MP [i, i + 1] = w for each
(i, i+1) pair for i, i + 1 ∈ P . If vk is matched with i and
vl is matched with i + 1 for vk, vl ∈ C, then (MC[k, l] −
MP [i, i + 1])2 = 0 if and only if (vk, vl) ∈ E. Since there
exist |V |−1 (i, i+1) pairs, we need (|V −1|) edges to satisfy
cost(B) = 0 for any B. However, |E| < |V | − 1 for this
case and cost(B) > 0

case ii : |E| ≥ |V | − 1 → k = w2(|E| − |V − 1|)
Notice that cost(B) becomes smaller if consecutive el-
ements (i, i + 1) of P is matched with some vk, vl ∈ C
such that (vk, vl) ∈ E. However, there exist at least one
(i, i + 1) pair for i, i + 1 ∈ C, such that i is matched
with vk and (i + 1) is matched with vl for vk, vl ∈ C and
(vk, vl) /∈ E. Otherwise G has a Hamiltonian path which is
not the case. Therefore, at most |V | − 2 consecutive pairs in
P can be matched with some vk, vl for vk, vl ∈ C such that
(vk, vl) /∈ E. Notice that cost(B) ≥ w2(|E| − |V − 1| + 2)
in such a case. Hence cost(B) > w2(|E| − |V − 1|) = k
for this case.

Both case i and ii shows that cost(B) > k for any B
if G has no Hamiltonian path. Therefore, we can conclude
that G should have a Hamiltonian path if there exist some
assignment set B such that cost(B) ≤ k.

