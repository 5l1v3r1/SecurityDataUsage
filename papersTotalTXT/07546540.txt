2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy

Beauty and the Beast: Diverting modern web
browsers to build unique browser ﬁngerprints

Pierre Laperdrix

INSA-Rennes & INRIA

Rennes, France

Walter Rudametkin

University of Lille & INRIA

Lille, France

pierre.laperdrix@insa-rennes.fr

walter.rudametkin@univ-lille1.fr

Benoit Baudry

INRIA

Rennes, France

benoit.baudry@inria.fr

Abstract—Worldwide, the number of people and the time spent
browsing the web keeps increasing. Accordingly, the technologies
to enrich the user experience are evolving at an amazing pace.
Many of these evolutions provide for a more interactive web (e.g.,
boom of JavaScript libraries, weekly innovations in HTML5), a
more available web (e.g., explosion of mobile devices), a more
secure web (e.g., Flash is disappearing, NPAPI plugins are being
deprecated), and a more private web (e.g., increased legislation
against cookies, huge success of extensions such as Ghostery and
AdBlock).

Nevertheless, modern browser technologies, which provide the
beauty and power of the web, also provide a darker side, a rich
ecosystem of exploitable data that can be used to build unique
browser ﬁngerprints.

Our work explores the validity of browser ﬁngerprinting in
today’s environment. Over the past year, we have collected
118,934 ﬁngerprints composed of 17 attributes gathered thanks
to the most recent web technologies. We show that innovations
in HTML5 provide access to highly discriminating attributes,
notably with the use of the Canvas API which relies on multiple
layers of the user’s system. In addition, we show that browser
ﬁngerprinting is as effective on mobile devices as it is on desktops
and laptops, albeit for radically different reasons due to their
more constrained hardware and software environments. We also
evaluate how browser ﬁngerprinting could stop being a threat
to user privacy if some technological evolutions continue (e.g.,
disappearance of plugins) or are embraced by browser vendors
(e.g., standard HTTP headers).

Index Terms—browser ﬁngerprinting; privacy; software diver-

sity

I. INTRODUCTION

The world wide web has revolutionized communication in
just a few decades. The number of users and the time spent on
the web is constantly growing. Accordingly, the technologies
to enrich the user experience are evolving at an amazing
pace. Each technology has its purpose. Modern Javascript
libraries allow creating ever more dynamic and interactive web
applications. Users are bringing the web with them, wherever
they go, by means of mobile devices such as cellphones and
tablets. Browser and protocol speciﬁcations, such as HTML5,
are redeﬁning the limits of what web applications can do. The
browsers themselves are rapidly changing and have become
competitive testing grounds for numerous new technologies.
Surprisingly, what were once ubiquitous technologies, such
as the Flash, Silverlight, QuickTime, and Java plugins, are
quickly becoming relics of the past. At
the same time,

2375-1207/16 $31.00 © 2016 IEEE
© 2016, Pierre Laperdrix. Under license to IEEE.
DOI 10.1109/SP.2016.57
DOI 10.1109/SP.2016.57

878
878

concerned web user’s are becoming more aware of certain
practices that jeopardize their privacy and comfort, as can be
seen by the immense popularity of browser extensions like
AdBlock, Ghostery, Disconnect and many others.

Browsers are our gateway to the web. And to provide rich,
satisfying and beautiful services, websites require knowledge
about the browser and its environment. Through the differ-
ent APIs and technologies that have been created, modern
browsers freely provide websites with detailed information
regarding the hardware and software conﬁguration, allowing
websites to better exploit the user’s resources. Well behaving
websites only ask for what is needed to provide their beautiful
services, but the beast is hiding in the bushes, small differences
between users’ systems can be exploited by attackers by asking
for as much information as possible.

Browser ﬁngerprinting consists in collecting data regarding
the conﬁguration of a user’s browser and system when this user
visits a website. This process can reveal a surprising amount of
information about a user’s software and hardware environment,
and can ultimately be used to construct a unique identiﬁer,
called a browser ﬁngerprint. The privacy implications are
important because these ﬁngerprints can then be used to
track users. This threat to privacy is extremely serious as
assessed by the recent studies of Nikiforakis et al. [1] or
of Acar et al. [2] that show the wide adoption of browser
ﬁngerprinting. Meanwhile, large companies such as Google
implicitly announce its adoption (e.g., Google’s privacy policy
update of June 2015 indicates that they use “technologies to
identify your browser or device” [3], which can be interpreted
as the inclusion of browser ﬁngerprinting in their identiﬁcation
technologies).

Our work provides an in-depth analysis of the extent to
which today’s web provides an effective means to uniquely
identify users through browser ﬁngerprinting. This analysis
relies on more than 118,000 ﬁngerprints, which we collected
through the AmIUnique.org website. The ﬁngerprints are rich
and include the values of 17 attributes. We access some of
these attributes thanks to the most recent web technologies,
such as, the HTML5 canvas element (as initially suggested
by Mowery and colleagues [4]), as well as through the
WebGL API. These ﬁngerprints reveal detailed information
about a browser and its software and hardware environment.
We show that innovations in HTML5 provide access to highly

discriminating data. In addition, we provide the ﬁrst extensive
study about browser ﬁngerprinting on mobile devices, which
are quickly becoming the main platform for browsing the
web [5]. Through empirical evidence, we show that browser
ﬁngerprinting is effective on mobile devices despite having
software environments that are much more constrained than
on desktops and laptops. In fact, the discriminating attributes
for mobile devices differ greatly from their desktop and laptop
counterparts.

that

is most

Our empirical observations indicate that, while recent web
technologies enrich the user experience, they also provide
access to a wide range of information that are easily combined
into a ﬁngerprint
likely unique. The tension
between the comfort of web browsing and the will to remain
anonymous is currently clearly in favor of comfort, to the detri-
ment of privacy. Yet, the disappearance of severely discrim-
inating attributes on desktops (e.g. obtained through Flash),
and the absence of such attributes on mobile devices, allows
us to believe it is possible to improve privacy and anonymity
on the web while still retaining a modern and comfortable web
experience. We speculate on possible technological evolutions
in web browsers and we calculate their impact on browser
ﬁngerprinting. Our scenarios range from the deﬁnitive death
of Flash (49% of the visitors on AmIUnique.org had Flash
disabled),
.
We show that minor changes in web technologies would
have a major effect on the identiﬁcation capacity of browser
ﬁngerprinting.

to the premature disappearance of JavaScript

Our key contributions are:
• We provide a 17-attribute ﬁngerprinting script that uses

modern web technologies.

• We perform the ﬁrst large-scale study of Canvas ﬁnger-
printing by following a test reported by Acar et al. [6]
along with other JavaScript attributes. We show that
canvas ﬁngerprinting is one of the most discriminating
attributes.

• We demonstrate the effectiveness of mobile device ﬁnger-
printing with 81% of unique mobile ﬁngerprints in our
dataset despite the lack of plugins and fonts. We show
that the wealth of mobile models (different vendors with
different ﬁrmware versions) result in very rich user-agents
and very revealing canvas usage.

• We explore scenarios of possible technological evolutions
to improve privacy, and we simulate their impact on
browser ﬁngerprinting using our dataset. Notably, we
ﬁnd out that removing plugins and having generic HTTP
headers could reduce desktop ﬁngerprint’s uniqueness by
a very strong 36%.

The paper is organized as follows. Section II describes our
script and provides descriptive statistics about our dataset.
Section III investigates the impact of the most recent tech-
nology on ﬁngerprint diversity and section IV details the
analysis of mobile ﬁngerprint diversity. Section V evaluates
the impact of possible future scenarios on ﬁngerprint-based
identiﬁcation, section VI discusses the related work while

879879

section VII concludes this paper.

II. DATASET

We launched the AmIUnique.org website in November 2014
to collect browser ﬁngerprints with the aim of performing an
in-depth analysis of their diversity. The ﬁrst part of this section
presents the set of attributes that we collect in our browser
ﬁngerprinting script and the technique we use to collect them.
Then, we give a few general descriptive statistics about the
118,934 ﬁngerprints that serve as our dataset. We ﬁnish this
section with a series of tests to compare our dataset with the
only other available set of ﬁngerprint statistics, provided by
Eckersley in 2010 [7].

A. AmIUnique.org

1) Fingerprinting script: We implemented a browser ﬁn-
gerprinting script that exploits state-of-the-art techniques [4],
[6] as well as some new browser APIs. The complete list of
attributes is given in the ‘Attribute’ column of Table I. The
‘Source’ column indicates the origin of each attribute (HTTP,
JavaScript or Flash). The ‘Distinct values’ and ‘Unique values’
columns give a global overview of the most discriminating
attributes in a ﬁngerprint. Finally, the last column displays
a complete example of a browser ﬁngerprint. The top 10
attributes have been presented by Eckersley. Most of the 7
attributes at the bottom of the table have been discussed in
other works. Yet, we are the ﬁrst to collect them on a large
scale basis and to combine them as part of a ﬁngerprint. We
detail these 7 attributes below

• List of HTTP headers: When connecting to a server,
browsers send the user-agent, the desired language for a
webpage, the type of encoding supported by the browser,
among other headers. Some software and browser exten-
sions modify or add headers, giving extra details about
the device’s conﬁguration. Being deﬁned in the HTTP
protocol, these headers can always be acquired by the
server and do not depend on JavaScript.

• Platform: The value in the “navigator.platform" property
provides information about the user’s operating system.
While this information is already in the user-agent, we
collect the ‘platform’ value to detect modiﬁed or incon-
sistent ﬁngerprints, e.g., in case the returned value is
different from the one in the user-agent.

• Do Not Track/Use of an ad blocker: These two attributes
are directly related to privacy and the values can help us
differentiate privacy-conscious users from others.

• WebGL Vendor and Renderer: Described by Mowery et
al. [4], these two attributes were added with the HTML
WebGL API to give information on the underlying GPU
of the device. We provide extensive details about the
contents of these attributes in section III.

• Canvas: Introduced by Acar et al. [6] and fully explained
in section III-A, the HTML5 Canvas element gives us
the ability to perform tests on both the hardware and
the operating system by asking the browser to render a
picture following a ﬁxed set of instructions.

BROWSER MEASUREMENTS OF AMIUNIQUE FINGERPRINTS WITH AN EXAMPLE

TABLE I

Source

Distinct
values

Unique
values

Example

Attribute

User agent

Accept

Content encoding
Content language

HTTP header

11,237

6,559

HTTP header

HTTP header
HTTP header

131

42
4,694

62

11
2,887

List of plugins

JavaScript

47,057

39,797

Cookies enabled
Use of local/session stor-
age
Timezone
Screen
color depth

resolution

and

JavaScript

JavaScript

JavaScript

JavaScript

2

2

55

0

0

6

2,689

1,666

List of fonts

Flash plugin

36,202

31,007

List of HTTP headers

HTTP headers

1,182

Platform
Do Not Track

Canvas

WebGL Vendor
WebGL Renderer
Use of an ad blocker

JavaScript
JavaScript

JavaScript

JavaScript
JavaScript
JavaScript

187
7

8,375

26
1,732
2

525

99
0

5,533

2
649
0

(X11; Linux
(KHTML,

x86_64) AppleWe-
like Gecko) Chrome/

Mozilla/5.0
bKit/537.36
41.0.2272.118 Safari/537.36
text/html,application/xhtml+xml,application/xml;q=
0.9,image/webp,*/*;q=0.8
gzip, deﬂate, sdch
en-us,en;q=0.5
Plugin 1: Chrome PDF Viewer. Plugin 2: Chrome
Remote Desktop Viewer. Plugin 3: Native Client.
Plugin 4: Shockwave Flash...
yes

yes

-60 (UTC+1)

1920x1200x24

Abyssinica SIL,Aharoni CLM,AR PL UMing
CN,AR PL UMing HK,AR PL UMing TW...
Referer X-Forwarded-For Connection Accept Cookie
Accept-Language Accept-Encoding User-Agent Host
Linux x86_64
yes

NVIDIA Corporation
GeForce GTX 650 Ti/PCIe/SSE2
no

It should be noted that the WebGL Vendor and WebGL
Renderer attributes were added after our site was launched. We
isolated the results obtained from these two attributes (values
collected after ﬁngerprint number 45,474).

We tested other attributes for inclusion in the ﬁngerprints,
but the results were inconclusive and we decided to discard
them. We designed a test that renders 3D volumes through the
WebGL API, as ﬁrst tested by Mowery et al. [4]. However,
after an early analysis of more than 40,000 ﬁngerprints, the
test proved to be too brittle and unreliable since a simple
page reload with a different window size on a single device
could change the value of this test. Appendix B goes into
more details on this WebGL test. We also tested the collection
of information based on the device’s hardware performance,
like the Octane JavaScript benchmark, but they proved to be
too long and too intensive to execute. Finally, we included
other Flash attributes that proved to be useful
to detect
inconsistencies, but did not increase ﬁngerprint uniqueness.
More details can be found in Appendix C.

2) Data collection: AmIUnique.org is a website dedicated
to browser ﬁngerprinting, aimed both at collecting data about
device diversity and at
the privacy
implications of ﬁngerprinting. All visitors are informed of our
goal with links to both our privacy policy and FAQ sections,

informing users about

and they have to explicitly click on a button to trigger the
collection of their device’s ﬁngerprint.

When the user initiates the connection to the page that
contains our ﬁngerprinting script, the server immediately col-
lects the HTTP headers. Then, if the user has not blocked
JavaScript, the browser runs the script that collects the bulk
of the ﬁngerprint data. If Flash is present, we go one step
further and collect additional data. Our script takes a few
hundred milliseconds to create a ﬁngerprint. The contents of
each ﬁngerprint is dependent on the browser, its conﬁguration,
and the hardware and software environment it is running in.
We distinguish three main categories of ﬁngerprints in our
dataset: those with JavaScript and Flash activated (43% of
the ﬁngerprints), those with JavaScript activated but not Flash
(41%), and those with no JavaScript, and hence, no Flash
(16%). Given that our work focuses on ﬁngerprinting modern
browsers and at analyzing the importance of the attributes in
Table I, we do not consider ﬁngerprints with no JavaScript.
Fingerprints without JavaScript only include values for the
HTTP headers (i.e., 5 attributes), which drastically removes
most of the functionality we are studying.

To prevent collecting multiple copies of the same ﬁngerprint
from the same user, we store a cookie on the user’s device with
a unique ID, and we also keep a hashed version of the IP

880880

address. These two pieces of information allow us to identify
returning devices, which represent a negligible part of our
dataset.

We communicated our website on Slashdot, Framasoft,
Clubic, social media channels like Facebook and Twitter, and
newspapers like Le Monde. As of February 15th, 2015, we
collected 142,023 ﬁngerprints, which were then reduced to
118,934 once we removed the ﬁngerprints without JavaScript
for this study. However, because our website focuses on a very
speciﬁc subject, our visitors are likely saavy Internet users who
are aware of potential online privacy issues. Hence, our data is
biased towards users who care about privacy and their digital
footprint, and their devices might have ﬁngerprints different
than those we could collect from a more general audience.

B. Descriptive statistics

Tables I and II summarize the essential descriptive statistics
of the AmIUnique dataset. Table II presents the distribution
of plugins, fonts and headers in our dataset. To obtain these
numbers, we decomposed each list of values into single
elements and we studied how common they are by looking at
the number of ﬁngerprints in which each element is present.
We divided the results from the plugins, fonts and headers
into three categories: the ones that belong to less than 1%
of collected ﬁngerprints, the ones present in less than 0,1%
of ﬁngerprints, and the ones that appear in only one or two
ﬁngerprints.

Unique and distinct values: The ‘Distinct values’ column
in Table I provides the number of different values that we
observed for each attribute, while the ‘Unique values’ column
provides the number of values that occurred a single time in
our dataset. For example, attributes like the use of cookies or
session storage have no unique values since they are limited to
“yes” and “no”. Other attributes can virtually take an inﬁnite
number of values. For example, we observed 6,559 unique
values for the user-agent attribute. This is due to the many
possible combinations between the browser, its version and
the operating system of the device. It is extremely likely that
visitors who use an exotic OS with a custom browser, such as
Pale Moon on Arch Linux, will present a very rare user-agent,
thus increasing the likelihood of being identiﬁed with just the
user-agent.

These numbers show that some attributes are more discrim-
inating than others, but they all contribute to building a unique
and coherent ﬁngerprint.

Plugins: We observed 2,458 distinct plugins, assembled in
47,057 different lists of plugins. They cover an extremely wide
range of activities, as for example, reading an uncommon ﬁle
format in the browser (e.g. FLAC ﬁles with the VLC Browser
plugin), communicating with an antivirus or a download client,
launching a video game directly in the browser, site-speciﬁc
plugins for added functionality, etc. Some plugins are so
speciﬁc that they leak information beyond the computer, like
the company the user works for or the brand of smartphone,
camera or printer he or she uses. 97% of plugins appear in
less than 1% of collected ﬁngerprints and 89% in less then

TABLE II

SUMMARY OF STATISTICS

Attr.
Plugin
Font
Header

Total
2,458
223,498
222

<1% FP
2,383 (97%)
221,804 (99%)
205 (92%)

<0,1% FP
2,195 (89%)
217,568 (97%)
182 (82%)

< 3 FP
950 (39%)
135,468 (61%)
92 (41%)

0,1%. A lot of plugins are created for precise and narrow uses
allowing their users to be easily identiﬁed.

Fonts: We observed 221,804 different fonts, assembled
in 36,202 different lists of fonts. This really high number
shows the incredible wealth that exists: fonts for support
of an additional alphabet, fonts for web designers, fonts for
drawing shapes and forms, fonts for different languages, etc.
On average, a Windows or Mac user has two to three times the
amount of fonts of a Linux user. Also, 97% of fonts appear
in less than 0,1% of ﬁngerprints and a little less than 2/3 of
them are only in one or two ﬁngerprints. These percentages
show how efﬁcient a list of fonts can be for ﬁngerprinting and
transitively how critical it can be for users who want to protect
their privacy. However, this list is provided through the Flash
plugin, which is progressively disappearing from the web. We
will see in section V that removing access to the list of fonts
has a small impact on identiﬁcation.

HTTP headers: We observed 222 different HTTP headers,
assembled in 1,182 different lists of headers. New headers are
added to the standardized ones for different reasons and from
different sources. Some examples include the following:

• The browser. For example, the Opera browser on smart-
phones adds a X-OperaMin-Phone-UA header, and the
Pufﬁn browser adds a X-Pufﬁn-UA header.

• A browser extension. For example, the FirePHP extension
for Firefox adds the x-FirePHP and the x-FirePHP-
Version headers to each HTTP request.

• The network on which you are connected. Some headers

show the use of proxies or protection systems.

As indicated in Table II, 182 headers out of 222 appear in
less than 0,1% of the collected ﬁngerprints, and 92 of them
come from only one or two ﬁngerprints. These statistics mean
that some HTTP headers are highly discriminating and their
presence greatly affects the uniqueness of one’s ﬁngerprint.

C. Statistical validity of the dataset

This section presents a series of tests to compare our dataset
with the ﬁngerprinting statistics provided by Eckersley in
2010.

1) Mathematical treatment:
Entropy: We use entropy to quantify the level of identifying
information in a ﬁngerprint. The higher the entropy is, the
more unique and identiﬁable a ﬁngerprint will be.
Let H be the entropy, X a discrete random variable with
possible values {x1, ..., xn} and P (X) a probability mass
function. The entropy follows this formula:

H(X) = − (cid:2)

P (xi) logb P (xi)

i

881881

NORMALIZED ENTROPY FOR SIX ATTRIBUTES COLLECTED BOTH BY

PANOPTICLICK AND AMIUNIQUE

TABLE III

Attribute
User agent

List of plugins
List of fonts

Screen resolution

Timezone

Cookies enabled

AmIUnique

0.570
0.578
0.446
0.277
0.201
0.042

Panopticlick

0.531
0.817
0.738
0.256
0.161
0.019

We use the entropy of Shannon where b = 2 and the result is
in bits. One bit of entropy reduces by half the probability of
an event occurring.

Normalized Shannon’s entropy: To compare both the AmI-
Unique and Panopticlick datasets, which are of different sizes,
we use a normalized version of Shannon’s entropy:

H(X)
HM

HM represents the worst case scenario where the entropy is
maximum and all values of an attribute are unique (HM =
log2(N ) with N being the number of ﬁngerprints in our
dataset).

The advantage of this measure is that it does not depend
on the size of the anonymity set but on the distribution of
probabilities. We are quantifying the quality of our dataset
with respect to an attribute’s uniqueness independently from
the number of ﬁngerprints in our database. This way, we can
qualitatively compare the two datasets despite their different
sizes.

2) Comparison with Panopticlick:
Entropy: Table III lists the normalized Shannon’s entropy
for six different attributes for both the AmIUnique and the
Panopticlick datasets. For fairness of comparison, we used
our dataset
in its entirety by keeping ﬁngerprints without
JavaScript. We observe that
the entropy values for both
datasets are similar for all attributes except for the list of
plugins and the list of fonts.

For the list of plugins, it is still the most discriminating
attribute but a difference of 0.24 is present. It can be explained
by the absence of plugins on mobile devices which are
increasingly used to browse the web and by the lack of support
for the old NPAPI plugin architecture on Chrome since April
2015 (more details in section V).

For the list of fonts, a noticeable drop of 0.29 occurs
because half of the ﬁngerprints in the AmIUnique dataset
were collected on browsers that do not have the Flash plugin
installed or activated. Since our ﬁngerprinting script collects
the list of fonts through the Flash API, this means half of
our ﬁngerprints do not contain a list of fonts, reducing its
entropy. The absence of Flash can be explained (i) by the lack
of Flash on mobile devices; (ii) by the fact that the visitors
of AmIUnique are privacy conscious and tend to deactivate
Flash. Yet, we notice that the entropy of the list of fonts is
still high.

The small value of entropy for the timezone shows that
our dataset
is biased towards visitors living in the same
geographical areas. A higher level of entropy would have
meant a more spread distribution of ﬁngerprints across the
globe.

Distribution of ﬁngerprints: We compared frequency dis-
tributions w.r.t. anonymity set sizes from both datasets and
observed very similar trends. We also studied each attribute
separately and observed that the most discriminating attributes
are still the ones found by Eckersley with the addition of new
efﬁcient techniques like canvas ﬁngerprinting. More details on
the distributions can be found in Appendix D.

III. FINGERPRINTING WITH THE MOST RECENT WEB

TECHNOLOGIES

AmIUnique collects 17 attributes to form a browser ﬁnger-
print. Out of the 118,934 ﬁngerprints that we study, 89.4% are
unique. In this section, we analyze how the attributes collected
with the most recent technologies (7 attributes at the bottom
of Table I) contribute to the uniqueness of ﬁngerprints.

A. Canvas ﬁngerprinting

The canvas element in HTML5 [8] allows for scriptable
rendering of 2D shapes and texts. This way any website
can draw and animate scenes to offer visitors dynamic and
interactive content. As discovered by Mowery and al. [4] and
investigated by Acar and al. [6], canvas ﬁngerprinting can be
used to differentiate devices with pixel precision by rendering
a speciﬁc picture following a ﬁxed set of instructions. This
technique is gaining popularity in tracking scripts due to the
fact that the rendered picture depends on several layers of
the system (at least the browser, OS, graphics drivers and
hardware).

1) Our test: The ﬁngerprinting script used by AmIUnique
includes a test based on the canvas element. With this image,
we collect information about three different attributes of the
host device, as discussed below.

Figure 1 displays the image that we use, as it is rendered
by a Firefox browser running on Fedora 21 with an Intel i7-
4600U processor. Our test replicates the test performed by
AddThis and described in details by Acar et al [6]: print a
pangram twice with different fonts and colors, the U+1F603
unicode character and rectangle with a speciﬁc color. The only
adaptation is to change the position of the second string so that
it is not intertwined with the ﬁrst one. More details about this
test are discussed below.

Fig. 1. Example of a rendered picture following the canvas ﬁngerprinting test
instructions

882882

the Arial font. Although this font has the same dimensions
across operating systems, there are visible variations of pixels
in the ﬁnal image due to differences in the rendering process.
The process to render an image is complex and depends
on both hardware and software (e.g. GPU, rendering engine,
graphic drivers, anti-aliasing, OS), and this test is affected by
variations in any of these layers. Interestingly, the test is also
relatively stable over time because users do not often change
the conﬁguration of layers in the rendering process.

2) Inﬂuence of canvas ﬁngerprinting for identiﬁcation:

The strength of canvas ﬁngerprinting comes from the fact
that it combines the three tests listed before. Alone, as a
simple rendered picture, the normalized entropy is at 0.491,
putting it in the top 5 of the most discriminating attributes.
However, because emojis reveal information about both the
OS and the device, it is possible to use canvas ﬁngerprinting
to detect inconsistent ﬁngerprints. For example, by checking
if the operating system in the user-agent matches the one
indicated by the emoji, we can verify inconsistencies in the
ﬁngerprint to detect visitors who spoof their ﬁngerprintable
attributes. Thus, the added value of canvas ﬁngerprinting is
to strengthen the identity of a ﬁngerprint. Moreover, one of
the advantages of canvas ﬁngerprinting is that it is stable. You
can run it many times on the same computer and you will
have the same result every time, with little variance over time
(some variations can be observed if the user decides to update
drivers for example). In the end, canvas ﬁngerprinting is an
important addition to browser ﬁngerprinting.

B. WebGL ﬁngerprinting

WebGL [10] uses the Canvas element described before to
render interactive 3D objects natively in the browser, without
the use of plugins. With the ﬁnal speciﬁcations in 2011,
WebGL 1.0 is now supported in all major browsers.

1) Our test: The WebGL API, through the

WEBGL_debug_renderer_info interface (as the name indi-
cates, it is designed for debugging purposes), gives access to
two attributes that take their values directly from the device’s
underlying graphics driver. AmIUnique’s ﬁngerprinting script
collects these two properties, namely:

• the WebGL vendor: name of the vendor of the GPU.
• the WebGL renderer: name of the model of the GPU.
These attributes provide very precise information about the
device. For example, we collected exact GPU names like
“NVIDIA GeForce GTX 660 Ti" or “Intel HD Graphics
3000". These two attributes also indirectly leak information
on your OS and its environment. For example, Chrome uses
the ANGLE backend [11] on Windows to translate OpenGL
API calls to DirectX API calls. Consequently, the following
WebGL renderer string indicates that the browser runs on a
Windows machine: “ANGLE (NVIDIA GeForce GTX 760
Direct3D11 vs_5_0 ps_5_0)". Same type of leak with the
presence of the “OpenGL engine" substring on Mac systems.
2) Inﬂuence of WebGL ﬁngerprinting on identiﬁcation: The
WebGL vendor and renderer had the potential to become a
highly discriminating attribute, but two factors greatly hamper

(a) Windows 7

(b) Windows 10

(c) Linux

(d) iOS

(e) Firefox OS (f) Android 4.3 and

before

(g) Android 4.4

(h) Android 5.0

(j) Android on a
Samsung device

(i) Android on
an LG device
Fig. 2. Comparison of the “Smiling face with open mouth" emoji on different
devices and operating systems

(k) Android on
an HTC device

(l) Emoji not
supported

Font probing: This test captures OS diversity. The script
tells the browser to render the same pangram (a string with
all the letters of the alphabet) twice. For the ﬁrst line we force
the browser to use one of its fallback fonts by asking for a font
with a fake name. Depending on the OS and fonts installed
on the device, the fallback font differs. For the second line
the browser is asked to use the Arial font that is common in
many operating systems and is used for the hardware and OS
ﬁngerprinting described next.

Device and OS ﬁngerprinting: The last character of our
string may be the most important one. This character should
not be confused with an emoticon, which is a succession
of letters, numbers and punctuation marks like “:)" or “<3"
to describe an emotion. The character is an emoji [9].
Ofﬁcially introduced in the Unicode standard 6.0 in 2010,
emojis are ideograms that represent emotions or activities.
The difference with emoticons is that emojis have their own
Unicode character and font developers must provide their
own implementation for a given emoji w.r.t. its description.
Consequently, emojis can be used for ﬁngerprinting because
their actual representation differs between systems.

Figure 2 shows representations of the “Smiling face with
open mouth" emoji on different operating systems and mobile
devices. A square means that the browser has not found a
single font on the device that supports that emoji. The use
of emojis can be a powerful technique to uncover informa-
tion, especially on mobile devices where phone manufacturers
provide their own sets of emojis.

Hardware and OS ﬁngerprinting: As demonstrated by
Mowery et al. [4], small pixel-level differences can be detected
between browsers when rendering images, even on the same
OS and browser. The second line of text of the canvas test uses

883883

its utility. First, not all browsers give the unmasked version of
the vendor and renderer. Chrome provides this information
by default but Firefox has this information locked behind
a browser ﬂag (“webgl.enable-privileged-extensions") and re-
turns a simple “Not supported" with our script. Second, a
non-negligible number of devices share the same hardware.
For example, a lot of laptops do not have a dedicated GPU
and they use the embedded Intel GPU inside their processor.
This reduces the uniqueness of some of the values that we
can observe. In the end, the WebGL API opens the door to
discriminating information but it is not accessible from every
browser.
C. Additional attributes

We collected the following attributes to study their utility to
discriminate browsers, to strengthen a ﬁngerprint by verifying
values, and to detect inconsistencies.

Platform: Even though the platform attribute does not add
new information, it can be used to detect inconsistencies. For
example, on an unmodiﬁed device, if the browser indicates
in its user-agent that it is running on a Linux system, you
expect to see “Linux" as the value of the “platform" property.
Due to the nature of our website that incites users to modify
their browser, we ﬂagged 5,426 ﬁngerprints in our dataset as
being inconsistent. Some browsers gave completely random
values that had no meaning. Others used extensions to mask
the platform value. For example, one ﬁngerprint had the value
"masking-agent", indicating that the Masking Agent extension
for Firefox [12] was installed. Finally, other browsers modiﬁed
their user-agent to mimic one from another operating system.
The problem was that the platform property was not modiﬁed
and the script was able to identify the true operating system
that the user was trying to hide.

Even with its low entropy, the platform property can prove
useful in cases where it is badly modiﬁed because it can make
some devices more prone to identiﬁcation than others with
unique or unusual values.

Do Not Track & Ad blocker: These two attributes have
a very low-level of entropy, their values are either ‘Yes",
“No" or “Not communicated" (for the DNT preference).
Without the Do Not Track attribute, the percentage of unique
ﬁngerprints drops by 0.07% which is negligible. The Ad
Blocker attribute is slightly better, with a drop of 0.5%,
but still insigniﬁcant compared to other attributes like the
user-agent or the list of plugins.

To conclude this section, the additional attributes collected
by AmIUnique are game changers: they strengthen ﬁnger-
prints, allow identiﬁcation through inconsistency detection.
They also allow identiﬁcation even when the list of fonts is
inaccessible because of the absence of Flash, and they provide
essential information about browsers on mobile devices as it
will be detailed in the next section.

IV. MOBILE FINGERPRINT DIVERSITY

Given the growth of mobile devices to browse the web, it is
essential to analyze how browser ﬁngerprinting behaves in this

884884

Size of the anonymity sets
>50

2−50

1

pluginsJS

e

l
i

b
o
M

p
o

t
k
s
e
D

% 0

20

40

60

80

100

Fig. 3. Comparison of anonymity set sizes on the list of plugins between
desktop and mobile devices

context. Our analysis of mobile device ﬁngerprinting is based
on 13,105 mobile ﬁngerprints. We select these ﬁngerprints
from our dataset by analyzing the user-agents. If the user-
agent contains a substring that is present in a predeﬁned set
(’Mobile’, ’Android’, ’iPhone’ or ’iPad’), the ﬁngerprint is
selected as a mobile ﬁngerprint, otherwise, it belongs to the
desktop/laptop category.

In this section, we ﬁrst compare desktop/laptop ﬁngerprints
with mobile ones. Then, we perform a detailed analysis of
mobile ﬁngerprints, looking at differences between browsers
and between mobile operating systems.

A. Mobile and Desktop ﬁngerprint comparison

Using the attributes from Table I, we succeeded in uniquely
identifying 90% of desktop ﬁngerprints. This number is lower
for mobile ﬁngerprints at 81%, yet still quite effective. At ﬁrst
sight, the overall results are close. However, as we discuss in
this section, the discriminating attributes for mobile ﬁnger-
prints are very different from those for desktop ﬁngerprints.
One factor is the lack of plugins in general, and Flash in
particular, for mobile devices. We also discuss the importance
of the new attributes collected through the HTML5 canvas and
WebGL elements on mobile device ﬁngerprinting.

If we take a look at Figure 3, we can clearly notice an
important difference. For desktops, more than 37% of the
collected ﬁngerprints have a unique list of plugins, while it is
at 1% for mobile devices. This is due to the fact that mobiles
were designed to take full advantage of HTML5 functionalities
and do not rely on plugins. For example, Adobe removed the
Flash player from the Google Play store in August 2012 as
part of a change of focus for the company [13]. Plugins are
considered to be unsuitable for the modern web and Google
states in their move to deprecate NPAPI support for their
Chrome browser that these plugins are a source of “ hangs,
crashes, security incidents, and code complexity" [14]. This
choice helps mobile device users gain some privacy with
regards to ﬁngerprint uniqueness. The level of entropy of the
plugin attribute is close to zero (some iOS systems have the
QuickTime plugin and some Android systems reported having
Flash, possibly from legacy installations). The lack of plugins
also reduces information leaks that could come from them. In

Size of the anonymity sets
>50

2−50

1

userAgentHttp

e

l
i

b
o
M

p
o

t
k
s
e
D

userAgentHttp Mobile

S
O

i

i

d
o
r
d
n
A

Size of the anonymity sets
>50

2−50

1

% 0

20

40

60

80

100

% 0

20

40

60

80

100

Fig. 4. Comparison of anonymity set sizes on the user-agent between desktop
and mobile devices

Fig. 5. Comparison of anonymity set sizes on the user-agent between Android
and iOS devices

particular, mobile phones and tablets do not have the Flash
plugin, thus all the ﬁngerprint attributes leaked through the
Flash API are unavailable.

Despite the unavailability of the two most discriminating
attributes from desktop ﬁngerprints (list of fonts and plugins),
mobile ﬁngerprints are still very much recognizable. This is
due to two main factors: very rich and revealing user agents
and very discriminating emojis.

Figure 4 shows that user-agents found on mobiles are
ﬁve times more unique than the ones found on desktops. In
our dataset, about 1 smartphone out of 4 is instantaneously
recognizable with just
the user-agent. This is due to two
factors:

• Phone manufacturers include the model of their phone
and even the version of the Android ﬁrmware directly in
the user-agent.
Example:

Mozilla/5.0 (Linux; Android 5.0.1;

Nexus 5 Build/LRX22C) AppleWebKit
/537.36 (KHTML, like Gecko) Chrome
/40.0.2214.109 Mobile Safari/537.36

• On a smartphone, applications are slowly replacing the
default browser and they have access to a wide range
of personal
information after the user has explicitly
granted speciﬁc permissions. The problem is any of these
information can be exposed for the world to see by
the application. We noticed in our dataset that a lot of
user-agents collected on mobile devices were sent by an
application and not by the native browser.
Example with the Facebook app where the phone car-
rier (Vodafone UK) and the exact model of the phone
(“iPhone7" = iPhone 6 Plus) is included in the user-agent:

Mozilla/5.0 (iPhone; CPU iPhone OS 8

_1_1 like Mac OS X) AppleWebKit
/600.1.4 (KHTML, like Gecko) Mobile
/12B436 [FBAN/FBIOS;FBAV
/20.1.0.15.10;FBBV/5758778;FBDV/
iPhone7,2;FBMD/iPhone;FBSN/iPhone
OS;FBSV/8.1.1;FBSS/2; FBCR/

vodafoneUK;FBID/phone;FBLC/en_GB;
FBOP/5]

Sometimes, even the model of
the phone can give
away your phone carrier. One ﬁngerprint reported “SM-
G900P". It is a Samsung Galaxy S5 and the “P" is unique
to the Sprint phone carrier.

The second highest source of entropy for mobile devices
comes from canvas ﬁngerprinting. Mobiles have unique hard-
ware impacting the ﬁnal rendered picture as explained in
section III-A and emojis can also be really discriminating
between two devices. As seen in Figure 2, some manufacturers
have their own set of emojis and even between different
versions of Android, the emojis have evolved, splitting the
Android user base into recognizable groups.

In the end, desktop and mobile ﬁngerprints are somehow
equally unique in the eyes of browser ﬁngerprinting even
though the discriminating information does not come from
the same attributes.

The complete details of attributes’ entropy between desktop
and mobile devices can be found in Table A of the Appendix.

B. Comparison Mobile OS and browsers

More than 97% of mobile ﬁngerprints collected on AmIU-
nique are either running Android or iOS: 7,416 run on Android
and 5,335 on iOS. How diverse is the set of ﬁngerprints
coming from both of these operating systems?

Figure 5 shows the size of anonymity sets for user-agents on
both Android and iOS devices. We can see that user agents
on Android devices expose more diversity with three times
as many users being in an anonymity set of size 1 (9% for
iOS devices and 35% for Android devices). This is due to the
wealth of Android models available on the market. Moreover,
our dataset may not be representative enough of the global
diversity of Android devices so these percentages may be
even higher in reality. For iOS devices, the diversity is still
high but much less pronounced since users share devices with
identical conﬁgurations. We can notice a trend where half of
the collected iOS ﬁngerprints are in really large anonymity
sets. The fact that Apple is the only manufacturer of iOS
devices shows in this graph.

885885

userAgentHttp Mobile

f

x
o
e
r
i
F

e
m
o
r
h
C

Size of the anonymity sets
>50

2−50

1

Complete fingerprint

Size of the anonymity sets
>50

2−50

1

l

h
s
a
F
o
N

 

h
s
a
F

l

% 0

20

40

60

80

100

% 0

20

40

60

80

100

Fig. 6. Comparison of anonymity set sizes on the user-agent between Chrome
and Firefox on mobile devices

Fig. 7. Comparison of anonymity set sizes between devices with and without
Flash

We saw in the previous section that user-agents can give
really discriminating information on the user’s device. Some
smarpthones running Android give the exact model and
ﬁrmware version of their phone. Looking at Figure 6, user
agents from the Chrome mobile browser are ten times more
unique than user agents from the Firefox browser (40% against
less than 4%). This can be explained by the fact that the
Chrome browser is the default browser on Android and it
is automatically installed on every devices. When a phone
manufacturer builds its tailored ﬁrmware to be delivered to its
clients, the embedded Chrome browser has a user-agent with
information on the corresponding phone model and Android
version. On the other side, Firefox which can be downloaded
from the Google Play Store does not contain this type of
information because the store only offers a generic version
for every Android mobile and it does not change its user-
agent during its installation. Firefox indirectly provides a much
better protection against ﬁngerprint tracking by not disclosing
device-related information.

You can ﬁnd below two ﬁngerprints collected from the same
device but with a different browser: the ﬁrst with Chrome, the
second with Firefox.
Mozilla/5.0 (Linux; Android 4.4.4; D5803

Build/23.0.1.A.5.77) AppleWebKit
/537.36 (KHTML, like Gecko) Chrome
/39.0.2171.93 Mobile Safari/537.36

Mozilla/5.0 (Android; Mobile; rv:34.0)

Gecko/34.0 Firefox/34.0

V. ASSESSING THE ROBUSTNESS OF FINGERPRINTING

AGAINST POSSIBLE TECHNICAL EVOLUTIONS

Web technologies evolve very fast, and we have seen in
previous sections that some recent evolutions limit ﬁngerprint-
based identiﬁcation (e.g., no Flash on mobile devices), while
others open the door to increased identiﬁcation (e.g., WebGL
reveals ﬁne grained information about the GPU).

In this section, we explore 6 potential evolutions that web
technology providers (browsers and app developers, standard-
ization organizations) could set up. We demonstrate that they

would limit
the effectiveness of browser ﬁngerprinting by
simulating their impact on our dataset. The ﬁrst two scenarios
are based on current trends in web technologies, while the
others are more speculative and based on the observations
made in previous sections. It should be noted that we do not
estimate the impact of scenarios no4 and 5 since we can hardly
predict which attributes would be affected and how. We also
treat scenario no6 separately, due to its extreme nature.
Scenario no1 - The deﬁnitive disappearance of Flash

The Flash plugin is progressively disappearing. It has been
deprecated on all smartphones, tablets and mobile devices used
to browse the web. On laptop and desktop browsers, Flash’s
security ﬂaws have progressively created mistrust in its users.
Click-to-play is becoming standard on most browsers. In the
meantime, the number of web applications that replace Flash
with JavaScript and HTML5 is also growing. These phenom-
ena let us plausibly foresee the deﬁnitive disappearance of
Flash.

Interestingly, Flash is still present in 80% of our Desktop
ﬁngerprints. Among these cases, 71.7% have it activated,
26.3% are using click-to-play protections, and 2.0% block
Flash, likely by a browser extension.

Impact of scenario no1: Figure 7 shows the impact of the
Flash plugin on ﬁngerprint uniqueness. The “No Flash” bar
shows statistics over our complete dataset (for the 60,617
ﬁngerprints that have Flash, we simulate its absence by re-
moving the attributes obtained through Flash). The “Flash”
bar is computed with the subset of ﬁngerprints that have Flash,
since it is not possible to simulate the presence of Flash on
ﬁngerprints that don’t have it. We uniquely identify 95% of
the browsers that have Flash, while this is reduced to 88%
for those without Flash. The sizes of the anonymity sets are
notably small, with less than 0.6% of the ﬁngerprints in a
set of size 50 or greater. These numbers conﬁrm that browser
ﬁngerprinting in a Flash-less future is certainly possible, and
that the wealth of ﬁngerprintable attributes compensates for
the lack of access to Flash speciﬁc attributes.

Scenario no2 - The end of browser plugins

In 2013, Google decided to stop supporting NPAPI plugins
in Chrome and to rely exclusively on the technology embedded

886886

0
1

.

8
0

.

6
0

.

4
0

.

2
0

.

i

s
n
g
u
p

l

 
f

o

 
y
p
o
r
t
n
e
d
e
z

 

i
l

a
m
r
o
N

0
0

.

Chrome 43 (May'15)
Chrome 41 (Mar'15)
Chrome 39 (Nov'14)
Chrome 40 (Jan'15)
Chrome 47 (Dec'15)
Chrome 46 (Oct'15)
Chrome 42 (Apr'15)
Chrome 45 (Sep'15)
Chrome 44 (Jul'15)

Firefox 40 (Aug'15)
Firefox 42 (Nov'15)
Firefox 43 (Dec'15)
Firefox 41 (Sep'15)

Browser

Fig. 8. Evolution of the normalized entropy of plugins for different browsers
on desktop computers

in modern browsers and the functionalities offered by HTML5
and JavaScript
to let developers extend the browser [14].
This has forced developers to migrate old plugins to newer
alternatives [15] or to drop their support. Nevertheless, since
its enforcement, it has the advantage of drastically reducing
the entropy of the list of plugins. In 2015, version 42 of
Chrome deprecated the support of NPAPI plugins by default
and version 45 permanently removed their support.

This radical evolution, and the absence of plugins on mobile
platforms,
lets us foresee a more global evolution where
browsers no longer provide a plugin-based architecture. Yet,
this is challenging because plugins currently still provide a
large number of features (as discussed in section II-B, we
observed 2,458 different plugins in our dataset). Mozilla had
plans to hide unpopular plugins with a whitelist [16] but they
did not ﬁnd a satisfying working solution that would not break
websites or functionality. In October 2015, they announced the
removal of NPAPI support by the end of 2016 [17].

Impact of scenario no2: To estimate the impact of this
scenario, we look at the entropy of plugins for Chrome since
Google decided to deprecate the support of NPAPI plugins.
Figure 8 shows the evolution of the normalized entropy of
plugins for the stable releases of Chrome since the launch
of the AmIUnique website. The last 4 stable versions of
Firefox were added for comparison. Up to version 42, the
normalized entropy of the list of plugins was above 0.8. Since
the release of version 42, the entropy of the list of plugins
has dropped below 0.5. This improvement is signiﬁcant and
the effects are getting bigger with the release of version 45
where the NPAPI support is permanently dropped (the entropy
is not at zero since there are small differences in the plugin

NPAPI support

Enabled
Disabled
Removed

list between operating systems). Removing plugin support
deﬁnitely impacts desktop ﬁngerprints and it seems that their
use in browser ﬁngerprinting is becoming limited.

Scenario no3 - Adherence to the standard HTTP headers

A major source of information for browser ﬁngerprinting
comes from application and system developers that add ar-
bitrary information in headers by either modifying existing
headers (e.g., the user-agent) or by adding new ones. Yet,
the Internet Engineering Task Force (IETF) has standardized
a list of ﬁelds for HTTP headers. The current diversity in
the contents of the user-agent ﬁeld results from a very long
history of the ‘browser wars’, but could be standardized today.
This scenario explores the possibility that technology providers
converge on a standard set of HTTP header ﬁelds, and that they
follow the standard.

Impact of scenario no3: To estimate the impact of adherence
to standard HTTP headers, we simulate the fact that they are
all the same in our dataset. On desktops, the improvement is
moderate with a decrease of exactly 8% from 90% to 82%
in overall uniqueness. However, on mobile ﬁngerprints, we
can observe a drop of 21% from 81% to 60%. This illustrates
the importance of headers, and especially the user-agent, for
mobile ﬁngerprinting and the fact that generic user-agents are
essential for privacy.

Combining scenarios no1-2-3: The biggest surprise of this
analysis comes from combining the 3 scenarios. For mobile
devices the results are signiﬁcant but not overwhelming, the
number of unique ﬁngerprints drops by 22%. However for
desktop devices, the percentage drops by a staggering 36%,
from 90% to 54%. This means that if plugins disappear and
if user-agents become generic, only one ﬁngerprint out of two
would be uniquely identiﬁable using our collected attributes,
which is a very signiﬁcant improvement to privacy over the
current state of browser ﬁngerprinting.

Scenario no4 - Reduce the surface of HTML APIs

The potential disappearance of Flash and plugins will oc-
cur only if developers ﬁnd suitable replacements with rich
HTML and JavaScript features. Consequently, HTML APIs
keep growing, providing access to an increasing number of
information about the browser and its environment. As we
saw in section III, the WebGL and canvas elements provide
important information for identiﬁcation. There are potentially
many more APIs that leak identifying information.

Setting the best trade-off between rich features and privacy
is a critical and difﬁcult choice when setting up new APIs.
Developers debate extensively on this kind of trade-off [18].
Yet, it is possible to foresee that future API developments,
combined with informed studies about privacy such as the
recent work by Olejnik and colleagues [19], will
lead to
reduced APIs that still provide rich features.

Scenario no5 - Increase common default content

This scenario explores the possibility that browser or plat-
form developers increase the amount of default elements,

887887

Size of the anonymity sets
>50

2−50

1

Complete fingerprint

S
J
 

o
N

S
J

% 0

20

40

60

80

100

Fig. 9. Comparison of anonymity set sizes on the complete ﬁngerprint
between devices with and without JavaScript

which would be the only ones exposed publicly. For example,
we could envision a whitelist of fonts that are authorized to be
disclosed by the browser, as suggested by Fiﬁeld and Egelman
[20]. Such a list would contain the default fonts provided by
an operating system. This whitelist of fonts would also include
a default encoding for emojis that is common to all versions
of the operating system, or even common to all platforms.

This evolution would aim at reducing the amount of infor-
mation disclosed to external servers. Yet, it should not prevent
the users from adding new fonts or new emoji renderings.
These customization decisions should be allowed without
increasing the risks for privacy.
Scenario no6 - The end of JavaScript

This last scenario explores the eventuality of coming back
to a more static web, without JavaScript. This is the most
unlikely today, as it would drastically reduce the dynamicity
and comfort of browsing. Yet, there are currently millions of
users who have installed the NoScript extension, which gives
control to users on which websites JavaScript is allowed to run.
We believe that it makes sense to explore the impact of such an
evolution on identiﬁcation through ﬁngerprinting. Currently by
disabling JavaScript, some sites do not render at all or render
improperly, while most popular sites lose functionality even if
properly rendered.

Figure 9 shows the impact of the unlikely return to a
more static web. The presence of JavaScript in today’s web
helps make 89.4% of browsers uniquely identiﬁable, while
removing JavaScript reduces the rate down to 29% on our
dataset. This percentage could be even lower if user-agents
become generic, as stated in scenario no3. In that case, only
7% of ﬁngerprints would be unique. The privacy beneﬁts are
undoubtedly signiﬁcant but the cost to developers and to the
users’ comfort would be very high.

Conclusion

Here we have quantiﬁed the impact of possible technology
evolution scenarii. While some of them could become reality
in the not-so-distant future, others are less plausible. Yet, we
demonstrate that they can beneﬁt privacy with a limited impact
on the beauty of current web browsing.

888888

It is important to notice that tools already exist that can
mitigate browser ﬁngerprinting in similar ways as the scenarii
discussed in this section. Ad and script blockers, like Ghostery
[21] or Privacy Badger [22], prevent known ﬁngerprinting
scripts from being executed in the browser. The NoScript [23]
extension blocks the execution of unwanted JavaScript scripts,
which is a direct reﬂection of scenario no6. The Tor browser
team has modiﬁed Firefox to create a large range of defenses
against browser ﬁngerprinting [24]: from the complete removal
of plugins to canvas image extraction blocking, their most
recent addition being a defense against font enumeration by
bundling a set of default fonts with the browser [25]. This
protection illustrates scenario no5 where the set of exposed
fonts is greatly reduced.

VI. RELATED WORK

We distinguish three main areas of the literature on browser
ﬁngerprinting: analysis of client-side diversity, analysis of
ﬁngerprinting adoption on the web and server-side scripts,
and advanced solutions to collect additional ﬁngerprintable
attributes. While our work is mostly related to the ﬁrst
category of work, we discuss the other two since they have
inspired some of the ﬁngerprinting techniques included in
AmIUnique.org.

Client-side diversity: The work by Peter Eckersley is
closely related to our study. In 2010 he launched the Panop-
ticlick website, aimed at collecting device-speciﬁc information
via a script that runs in the browser [7]. The script created
browser ﬁngerprints by collecting 10 different attributes that
characterized the browser and its execution platform. He
observed that 83% of visitors had instantaneously recognizable
ﬁngerprints, and this number rose to 94% for browsers that
had the Flash or Java plugins enabled. He showed that the
list of fonts (collected through the Flash API) and the list of
plugins (collected through the JavaScript API) were the most
distinguishable attributes.

The key novelties of our work with respect to Eckersley’s
study are as follow: the ﬁngerprints we collect are richer and
exploit some of the most recent web technologies (section
III shows the essential role of canvas ﬁngerprinting); Eck-
ersley did not analyze mobile ﬁngerprints separately from
the others, while we perform a detailed analysis of how
ﬁngerprinting behaves for browsers on mobile devices; we
assess the effectiveness of browser ﬁngerprinting against dif-
ferent
technological evolution scenarios. It should also be
noted that the technological changes to the web since 2010
(e.g., the deprecation of the Netscape Plugin API, the steady
disappearance of Flash, the arrival of HTML5) have strongly
impacted browser ﬁngerprinting, changing the importance of
various ﬁngerprintable attributes.

Very few other works have investigated the behavior of
ﬁngerprinting algorithms on client browsers. Yen et al. ana-
lyzed month-long datasets from Hotmail and Bing [26]. They
combined the user-agent with the IP address, and succeeded
in tracing back to a single host with 80% precision. While
this work is also about ﬁngerprinting, it has a much narrower

focus than ours (they consider only the user agent) and they
do not consider the robustness of their approach, e.g., against
agent spoofers. Spooren et al. recently analyzed 59 mobile
device ﬁngerprints [27] and concluded that “the ﬁngerprints
taken from mobile devices are far from unique". Our ﬁndings
on mobile diversity are quite different (cf. section IV): 81%
of our 13,105 mobile ﬁngerprints are unique. We see two
possibles reasons for the different conclusions: the scale effect
(our dataset is two orders of magnitude larger that Spooren’s);
Spooren et al. do not consider canvas ﬁngerprinting, while
we demonstrate that the canvas test is essential to distinguish
mobile ﬁngerprints. Finally, Boda et al. [28] showed that cross-
browser ﬁngerprinting was feasible if enough data on the
underlying operating system was collected. With our study,
we did not explore this possibility since we do not know with
certainty when two different ﬁngerprints are from the same
device but different browsers.

Adoption of ﬁngerprinting on the web and server-side
scripts: Some radically different works investigate the extent
to which browser ﬁngerprinting is adopted by web sites in the
wild. Although these works investigate the same phenomenon
as we do, the perspective is completely different, as are the
conclusions and lessons learnt.

Nikiforakis et al. [1] analyzed the ﬁngerprinting scripts of
three popular commercial companies. They concluded that
user-privacy was on “the losing side" and that commercial
scripts used intrusive techniques to get the most data out of
every browser.

FPDetective [2] was the ﬁrst study about the adoption of
browser ﬁngerprinting on the web. Crawling the million most
popular websites, they demonstrated the wide adoption of
ﬁngerprinting, and that ﬁngerprinters completely disregard the
user’s Do Not Track preference. The same authors showed that
5.5% of the top 100,000 sites actively ran canvas ﬁngerprinting
scripts on their home pages [6].

New techniques for richer ﬁngerprints: Several works have
deﬁned different ways to ﬁngerprint devices or browsers in
order to better differentiate them. Mowery and Schacham
worked on the HTML canvas and WebGL elements [4], Mow-
ery et al. on benchmarking the performance of core JavaScript
operations [29], Mulazzani et al. checked the conformance
of the browsers’ JavaScript engines to the ECMAScript stan-
dard [30], Fiﬁeld et al. measured the onscreen dimensions of
font glyphs [20], and Olejnik et al. used the HTML5 Battery
Status API for ﬁngerprinting purposes [19].

We kept only the work of Mowery and Schacha [4] in our
script because canvas and WebGL tests are light and can be
run in a matter of milliseconds. The other approaches take
either too much time (e.g. more than 3 minutes to test the
performance of JavaScript operations [29]), were too fragile
(e.g., the battery API elements [19]), or did not add any valu-
able information to the pool of attributes that we already had
(e.g. [20], [30]). We note that in general, new ﬁngerprinting
techniques are complementary to our work because they can
be used as new distinguishing attributes in the ﬁngerprinting
algorithm, allowing for better precision in uniquely identifying

889889

browsers.

VII. CONCLUSION

In this work we analyzed 118,934 browser ﬁngerprints col-
lected through the AmIUnique.org web site. Our work focuses
on the impact evolutions in modern web technology have had
on the ability to uniquely identify devices through browser
ﬁngerprinting. We argue that modern web technologies provide
a much improved user experience, albeit to the detriment of
privacy.

The key insights from our study are as follows. First, our
observations conﬁrm the results of previous studies on the ease
of ﬁngerprinting in today’s ecosystem [6], [31]. Second, we
provide novel insights about the impact of the most recent
browser APIs, including the ﬁrst large-scale analysis of the
HTML5 canvas on ﬁngerprinting, as well as the inﬂuence of
recent trends, such as the decreasing presence of Flash and
other plugins on the web.

We also provide the ﬁrst extensive analysis of ﬁngerprints
collected from mobile devices: 81% of the mobile ﬁngerprints
in our dataset are unique. We show that HTTP headers and
HTML5 canvas ﬁngerprinting play an essential role in identi-
fying browsers on these devices. Furthermore, in the absence
of the Flash plugin to provide the list of fonts, there is no
longer any major discriminating attributes, thus identiﬁcation
is based on the collection of many lesser attributes that appear
harmless by themselves, but when aggregated lead to unique
ﬁngerprints.

Our dataset, and the associated observations, allow us to
evaluate the impact of possible evolutions in web technologies
on browser ﬁngerprinting. We show that certain scenarios
would limit the detriment these technologies have on privacy,
while preserving the current
trend towards an ever more
dynamic and rich web. Having generic HTTP headers and
removing browser plugins could reduce ﬁngerprint uniqueness
in desktops by a strong 36%.

ACKNOWLEDGMENT

The authors would like to thank Nick Nikiforakis and
Gildas Avoine for providing insightful feedback while writing
this paper. We also want to thank our shepherd Adrienne
Porter Felt and the anonymous reviewers for their valuable
comments. This work is partially supported by the EU FP7-
ICT-2011-9 No. 600654 DIVERSIFY and the CNRS INS2I
JCJC 2016 FPDefendor projects.

REFERENCES

[1] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel, F. Piessens, and
G. Vigna, “Cookieless monster: Exploring the ecosystem of web-based
device ﬁngerprinting,” in Proc. of the Symp. on Security and Privacy,
2013, pp. 541–555.

[2] G. Acar, M. Juarez, N. Nikiforakis, C. Diaz, S. Gürses, F. Piessens, and
B. Preneel, “Fpdetective: dusting the web for ﬁngerprinters,” in Proc.
of the Conf. on Computer & Communications Security (CCS). ACM,
2013, pp. 1129–1140.

http://www.google.com/policies/privacy/

[3] “Google

Policy,”
archive/20150501-20150605/.

Privacy

[4] K. Mowery and H. Shacham, “Pixel perfect: Fingerprinting canvas in
IEEE

HTML5,” in Proceedings of W2SP 2012, M. Fredrikson, Ed.
Computer Society, May 2012.

[11] “ANGLE: Almost Native Graphics Layer Engine,” https://chromium.

[12] “Masking Agent extension for Firefox,” https://addons.mozilla.org/

latest/1.0/.

googlesource.com/angle/angle.

ﬁrefox/addon/masking-agent/.

[5] “Mobile internet usage soars by 67%,” http://gs.statcounter.com/press/

mobile-internet-usage-soars-by-67-perc.

[6] G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, and
C. Diaz, “The web never forgets: Persistent tracking mechanisms in
the wild,” in Proceedings of the 21st ACM Conference on Computer
and Communications Security (CCS 2014). ACM, 2014.

[7] P. Eckersley, “How unique is your web browser?” in Proceedings of
the 10th International Conference on Privacy Enhancing Technologies,
ser. PETS’10. Berlin, Heidelberg: Springer-Verlag, 2010, pp. 1–18.
[Online]. Available: http://dl.acm.org/citation.cfm?id=1881151.1881152

[8] “HTML Canvas 2D Context,” http://www.w3.org/TR/2dcontext/.
[9] “Emoji and Dingbats,” http://unicode.org/faq/emoji_dingbats.html.
[10] “WebGL Speciﬁcation,” https://www.khronos.org/registry/webgl/specs/

[13] “An Update on Flash Player and Android,” https://blogs.adobe.com/

ﬂashplayer/2012/06/ﬂash-player-and-android-update.html.

[14] J. Schuh, “Saying Goodbye to Our Old Friend NPAPI,” Septem-
ber 2013, https://blog.chromium.org/2013/09/saying-goodbye-to-our-
old-friend-npapi.html.

[15] “NPAPI deprecation: developer guide,” https://www.chromium.org/
developers/npapi-deprecation — The Netscape Plugin API (NPAPI) has
been permanently removed from Google Chrome since version 45. The
Pepper API (PPAPI) is one option but few plugins exist and it is not
proposed in the developer guide as an alternative.

[16] “Disallow enumeration of navigator.plugins (Mozilla bug tracker),”

https://bugzilla.mozilla.org/show_bug.cgi?id=757726.

[17] “NPAPI Plugins

in Firefox,” https://blog.mozilla.org/futurereleases/

2015/10/08/npapi-plugins-in-ﬁrefox/.

[18] “Extensive discussion about reducing the HTML battery API,” https:
//groups.google.com/forum/\#!topic/mozilla.dev.webapi/6gLD78z6ASI.
[19] L. Olejnik, G. Acar, C. Castelluccia, and C. Diaz, “The leaking battery:
A privacy analysis of the html5 battery status api,” Cryptology ePrint
Archive, Report 2015/616, 2015, http://eprint.iacr.org/.

[20] D. Fiﬁeld and S. Egelman, “Fingerprinting web users through font met-
rics,” in Proceedings of the 19th international conference on Financial
Cryptography and Data Security. Berlin, Heidelberg: Springer-Verlag,
2015.

[21] “Ghostery browser extension,” https://www.ghostery.com/our-solutions/

ghostery-browser-extention/.

[22] “Privacy Badger browser extension,” https://www.eff.org/privacybadger.
[23] “NoScript browser extension,” https://noscript.net/.
[24] “Design of

the Tor browser,” https://www.torproject.org/projects/

torbrowser/design/.

[25] “Release of Tor with a new defense against font enumeration,” https:

//blog.torproject.org/blog/tor-browser-55-released.

[26] T.-F. Yen, Y. Xie, F. Yu, R. P. Yu, and M. Abadi, “Host ﬁngerprinting
and tracking on the web: Privacy and security implications.” in NDSS,
2012.

[27] J. Spooren, D. Preuveneers,

“Mobile device
ﬁngerprinting considered harmful for risk-based authentication,” in
Proceedings of the Eighth European Workshop on System Security,
ser. EuroSec ’15. New York, NY, USA: ACM, 2015, pp. 6:1–6:6.
[Online]. Available: http://doi.acm.org/10.1145/2751323.2751329

and W.

Joosen,

[28] K. Boda, A. M. Földes, G. G. Gulyás, and S. Imre, “User tracking
on the web via cross-browser ﬁngerprinting,” in Information Security
Technology for Applications, ser. Lecture Notes in Computer Science,
P. Laud, Ed. Springer Berlin Heidelberg, 2012, vol. 7161, pp. 31–46.
[Online]. Available: http://dx.doi.org/10.1007/978-3-642-29615-4_4

[29] K. Mowery, D. Bogenreif, S. Yilek, and H. Shacham, “Fingerprinting
information in JavaScript implementations,” in Proceedings of W2SP
2011, H. Wang, Ed.

IEEE Computer Society, May 2011.

[30] M. Mulazzani, P. Reschl, M. Huber, M. Leithner, S. Schrittwieser,
E. Weippl, and F. C. Wien, “Fast and reliable browser identiﬁcation
with javascript engine ﬁngerprinting,” in Web 2.0 Workshop on Security
and Privacy (W2SP), vol. 5, 2013.

Technical

[31] “
,”
identiﬁcation-mechanisms.

analysis

identiﬁcation mechanisms
https://www.chromium.org/Home/chromium-security/client-

client

of

[32] “three.js ofﬁcial website, a JavaScript library to create 3D animations

using WebGL,” http://threejs.org/.

APPENDIX A

NORMALIZED SHANNON’S ENTROPY FOR ALL

AMIUNIQUE’S ATTRIBUTES

Attribute
User agent

List of plugins

List of fonts (Flash)
Screen resolution (JS)

Timezone

Cookies enabled

Accept

Content encoding
Content language

List of HTTP headers

Platform (JS)
Do Not Track

Use of local storage
Use of session storage

Canvas

Vendor WebGL
Renderer WebGL

AdBlock

All
0.580
0.656
0.497
0.290
0.198
0.015
0.082
0.091
0.351
0.249
0.137
0.056
0.024
0.024
0.491
0.127
0.202
0.059

Desktop Mobile
0.741
0.550
0.718
0.081
0.033
0.548
0.366
0.263
0.245
0.200
0.011
0.016
0.082
0.105
0.122
0.089
0.424
0.344
0.312
0.247
0.162
0.110
0.058
0.057
0.023
0.036
0.036
0.023
0.512
0.475
0.131
0.125
0.165
0.205
0.060
0.029

APPENDIX B

OUR ATTEMPT AT A WEBGL TEST

As reported by Mowery et al. [4], the WebGL API can be
used to render 3D forms in the browser. With the help of the
three.js JavaScript library [32], we aimed to have a test that
renders three different forms:

• a sphere
• a cube
• a Torus knot
However, after analyzing more than 40,000 ﬁngerprints, we
concluded that the test was too brittle and unreliable to draw
any conclusions from it. Indeed, if the user were to change the
size of its browser window or open the browser console, the
actual dimensions of the rendering context would be updated
inside the library and the rendering would differ with just a
simple page reload. Figure 10 shows three renderings of the
same test with three different window sizes on the same device.

APPENDIX C

ADDITIONAL FLASH ATTRIBUTES

For Flash, we also collected the following four attributes:
• Capabilities.language
• Capabilities.os
• Capabilties.screenResolutionX
• Capabilties.screenResolutionY

The language obtained through Flash is the devices main
language, but it is not as precise as the content language header
collected through HTTP. For the screen resolution, it can be
more interesting than the JavaScript value because Flash will
return the full resolution of a multi-screen setup and not the
resolution of a single screen. Finally, when analyzing the data
from the string collected from the OS property, it conﬁrmed
what has been observed by Nikiforakis et al. [1] in 2013.
Depending on the OS and the browser, the information is often
generic, returning “Windows" or “Linux", but in some cases

890890

on the tail on the right of Graph 11a, AmIUnique presents a
slightly lower number on Graph 11b with 79.4% of ﬁngerprints
that are unique in the database (ﬁngerprints with and without
JavaScript).

B. Distribution of browsers

Figure 12 shows the distribution of surprisal for different
categories of browsers. We can see that the overall trend is
similar in both graphs. The main noticeable difference is the
number of browsers in each category. While the Panopticlick
dataset was constituted of mainly Firefox browsers followed
by Chrome and Internet Explorer, our dataset put Chrome and
Firefox at the same level with all the other browsers behind.
This shows the rapid growth of the Chrome userbase over the
last 5 years and the decline of Internet Explorer.

C. Anonymity set sizes

(a) 1920x1200 window

(b) 960x1200 window

is,

the better it

the bigger an anonymity set

Figure 13 shows the size of anonymity sets for all attributes
if we consider them independently from each other. In our
is for
case,
privacy. If a value is in an anonymity set of size 1,
it
means that the observed value is unique and is not shared by
another ﬁngerprint. With all the attributes that we collected on
AmIUnique, we could not add all of them in Figure 13b for
readability reasons so we focused on attributes with the highest
level of entropy. If we look at the upper left part of both
Figure 13a and Figure 13b, we observe very similar results
and the most discriminating attributes on AmIUnique are still
the same as the ones observed by Eckersley (mainly fonts and
plugins) but with the addition of new efﬁcient techniques like
canvas ﬁngerprinting (see section III-A of the paper for more
information).

(c) 1080x600 window

Fig. 10. Different renderings of the WebGL test on the same device

it returns the type of the OS with the exact version of the
kernel (for example, “Mac OS 10.8.2" or “Linux 3.18.4-1-
ARCH"). This level of detail could be used to forge an attack
against a vulnerable system, and it is surprising that little has
changed since it was originally reported. In the end, we did not
keep this information for our study because it did not increase
the number of unique ﬁngerprints and would mainly serve to
detect inconsistencies (e.g., caused by User-Agent spoofers).

STATISTICS OF ADDITIONAL FLASH ATTRIBUTES

TABLE IV

Flash attribute
Screen resolution XxY
Language
Platform

Distinct
values
584
44
968

Unique
values
329
10
483

APPENDIX D

COMPARISON TO THE PANOPTICLICK STUDY

To complement section 2.3.2 of our paper that compares
our dataset with the one from Panopticlick [7], we recreated
the same graphs to show the impact of 5 years of browser
development on browser ﬁngerprinting.

A. Distribution of ﬁngerprints

If we compare both frequency distributions in Figure 11
w.r.t. anonymity set sizes, we can observe that the overall trend
is similar in both graphs with set sizes quickly dropping to
1. While Panopticlick has 83.6% of its ﬁngerprints located

891891

1000

e
z
i

S
 
t
e
S
 
y
t
i

m
y
n
o
n
A
 
r
o
 
y
c
n
e
u
q
e
r
F

100

10

1

1

10

100
409,296 Distinct Fingerprints
(a) Panopticlick distribution (Fig. 1 of [7])

1000

10000

100000

1000000

e
z
S

i

 
t
e
S
 
y
t
i

m
y
n
o
n
A

 
r
o

 
y
c
n
e
u
q
e
r
F

0
0
0
1

0
0
1

0
1

1

1

10

100

1000

10000

100000

142,023 distinct fingerprints

(b) AmIUnique distribution

Fig. 11. Distribution of ﬁngerprints w.r.t. anonymity set size

892892

Firefox (258,898)
MSIE (57,207)
Opera (28,002)
Chrome (64,870)
Android (1,446)
iPhone (6,907)
Konqueror (1,686)
BlackBerry (259)
Safari (35,055)
Text mode browsers (1,274)

s
r
e
s
w
o
r
b
 
f
o
n
o
i
t
r
o
p
o
r
P

 

1.0

0.8

0.6

0.4

0.2

0.0

8

s
r
e
s
w
o
r
b
 
f
o
 
n
o

i
t
r
o
p
o
r
P

4
.
0

3
.
0

2
.
0

1

.

0

0

.

0

10

12

14

16

18

Surprisal (bits)
(a) Panopticlick distribution (Fig. 2 of [7])

Firefox (52,395)
Chrome (47,698)
Safari (9,464)
IE (5,178)
Opera (2,740)
Others (2,343)

8

10

12

14

16

Surprisal (bits)

(b) AmIUnique distribution

Fig. 12. Surprisal distributions for different categories of browser

893893

v
hhh
s
tt

v

uuuuuuuuuu

v

h
vv
t
p
hh

h
t t
f
hh
s
c
t

vvvvvvvvvv

h

c

s

t

h

s
t t
v
s
f
p

s

u user_agent
p plugins
f fonts
v video
s supercookies
h http_accept
t timezone
c cookie_enabled

f
p

u

h

f
p
u

h

v v

100000

10000

1000

100

10

k
 
e
z
i
S
 
f
o
 
s
t
e
S
 
y
t
i

m
y
n
o
n
A
n

 

i
 
s
r
e
s
w
o
r
B

 
f
o
 
r
e
b
m
u
N

p
f

u

h

v

t

s

1

1

p
f

u

h

v

t

s

v

u

h h

uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu
f
v
hhhh
p
t
vvvvvvvvvvv
f
u uu
t tt
u
f
p
p
hhhhhhhh
p
ff
f f
uuuu
p
tt tt
u
uuuuu
pp
ff
hhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhhh
uuuuuuuuuuuuuuuuuuuuuuu
ffff
v
u
vvvv
pppp
uuu
p
u
uuu
t
f
p
uuuuuuuuuuuuuuuuuuuuuuu
hhhhhh
uu
p
u
u
u
u
u
f
p
u
vvv
f
pp
u
f
uuuu
u
fff
u
fffffffffffff
u
u
u
f
h
f
u
u
f
uuu
u
f
ppp
vvvvvvvvvvvv
uu
uuuuuuuuuuuuuuuuuuuuuu
t t tt
u
u
uu
uuu
hhhhh
u
h
p
uuuu
uu
u
uu
p
u
h
u
ff
ff
u
h
u
f
u
f
hhh
u
f
pppppp
u
h
u
uuuuuuu
uu
u
pp
h
u
h
uuuuuuuuuuuuuuuuuuuuuu
h
uu
u
u
f
f
f
f
u
h
u
u
uuu
h
u
hh
u
ff
p
u
uuu
p
h
f
u
u
u
u
u
h
h
pp
u
p
ffffffffffffffffff
u
p
h
p
h
u
v
h
uu
u
f
f
u
p
u
f
h
p
h
t
p
h
u
u
h
h
u
uu
f
u
u
u
hh
uu
u
uuuuuuuuuuuuuuuuu
f
p
u
h
u
ppppppppppppppp
f
hhh
h
p
pp
fffff
h
uuuu
h
pp
h
u
ff
u
f
u
ff
h
u
h
vvvv
hh
h
hhh
h
f
h
p
h
u
f
u
f
hhhhhh
h
uu
h
u
u
tt
p
u
h
h
u
h
f
u
u
uu
p
ff
h
p
p
u
h
h
h
uuuuuuuuuuuuuuu
ff
f
v
u
p
f
p
uuuu
hhh
pp
f
p
u
pppp
hh
f
hhhhh
u
f
h
uu
f
vvvvvvv
p
f
f
f
hhh
h
p
uu
f
p
h
uuu
p
h
h
uuuuuuuu
f
ffffffffffffffff
pp
hhh
hhhh
u
h
h
p
u
f
p
uu
f
h
hhh
p
uuuuuu
hh
h
f
hh
p
pp
u
v
hhhhhhh
f
p
pppppp
u
vvvvvvvvvvvvv
u
ff
f
h
h
p
v
p
u
hhh
uuu
f
p
hhhhhh
uuu
p
uu
pp
ff
h
v
f
uu
h
uu
v
hhh
p
pppp
u
hhhhhhhh
ffff
t
v
uu
f
pp
h
u
p
u
f
ppppppppp
f
p
u
ff
hh
u
h
uu
ffff
hhhhhh
f
p
v
p
uu
fff
uu
hhhhhhhh
h
p
v
tt
u
ffff
v
p
ppp
vvvvvvvvv
f
p
v
f
p
h
uuu
pppp
f
v
vv
f
ff
hh
p
fffffffff
f
h
h
pp
f
h
h
hh
v
v
p
h
v
h
h
h
vv
ppp
h
ff
p
u
v
h
u
hh
ff
ppp
hh
h
u
vvvvvvvvvv
f
h
pp
f
v
h
ff
pp
v
h
vv
f
v
hh
f
u
pp
v
h
u
ff
vvv
f
pp
vv
f
p
h
f
p
v
ff
v
h
f
v
pp
vv
v
f
p
vvvvvvvv
hh
f
tt

v
v
vv
v

vv

v

v

v
vvv
tt tt

t

ss

t

t

t

t

10

100

1000

10000

100000

Anonymity Set Size, k

(a) Panopticlick distribution (Fig. 3 of [7])

l

f

pp
c
ff

l

ll

cc
u

l
f
c
p
l
uuu

p

uuuuuuuuu
llll
ppppp
f

p
ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc
f
u uu
p
f
p
llllllllllllllllllllllll lllll l lllll ll lll
uuuuuuuuuuu
c
pp
uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu
f
c ccc
l
u
c
ppppppppppppppppppppppppp
u
p
f f
l
u
u
uuu
u
u
u
u
u
c
ppp
u
u
u
uu
c
c
u
u
l l l
u
u
u
uu
c
fffff
u
l
ccc
u
cc
c
cc
uu
c
uu
c
uu
uuuuuuuuuuuuuu
u
ppp
c
ff
uuuuuuuu
u
uuu
c
u
u
c
l
uu
c
uu
u
l llll
uu
uuu
uu
u
u
cccccccc
u
u
uuu
c
uu
u
c
uuuuuuuuuuuuuuuuu
l
c
u
cc
u
u
p
u
p
c
c
u
p
c
c
c
u
p
u
c
pppppp
ff
c
cc
uu
ccccccccccccccccc
l
c
uuuu
p
l
l
fff
l
f
u
u
c
l
uu
cc
u
u
p
u
l
l
f
uu
u
ppp
uu
c
u
c
uu
u
pppp
u
p
uuuuuu
c
l
uu
c
c
u
c
l
c
l
c
fff
uuuuuu
p
ll
l
l
u
c
c
c
u
c
u
l
fffffffffff
c
p
u
ccccc
l
uuuuuuuu
p
l
lll
f
u
l
p
cccc
llllllllllllllllllllll
u
u
uuu
cc
f
ll
c
p
cccccc
l
c
u
u
c
ll
p
p
l
uu
p
ppppppp
uuuu
cc
cc
pp
ccccccccccc
p
u
uu
l
f
f
uuuuu
u
c
l
ff
c
l
l
cc
c
c
f
p
ll
u
p
l
c
ffffff
l
f
p
c
l
f
ccc
cc
p
u
u
pp
pppppppppp
c
c
l
ll
p
c
f
l
lll
u
l
c
p
pp
u
c
u
uu
c
l
ff
l
f
l
u
fff
p
p
lll
l
u
p
c
ffff
u
cc
c
p
l
f
p
lll
l
lllllll
c
u
f
p
uu
c
p
pp
c
l
p
c
ff
c
c
ll
c
cccc
f
pp
l
p
l
l
cc
f
p
fff
lll
c
c
p
ffff
l
l
ffff

l

f

u
p
c
l
f

userAgentHttp
pluginsJS
canvasJS
languageHttp
fontsFlash

p
f

u
c
l

p
f
u
c
l

k
 
e
z
S

i

 
f

o
 
s
t

e
S
 
y
t
i

m
y
n
o
n
A
n

 

i
 
s
r
e
s
w
o
r
B

 
f

o

 
r
e
b
m
u
N

0
0
0
0
0
0
0
0
1
1

0
0
0
0
0
0
1
1

0
0
0
0
1
1

0
0
1
1

1
1

1
1

10
10

100
100

1000
1000

10000
10000

Anonymity Set Size, k

(b) AmIUnique distribution

Fig. 13. Number of users in anonymity sets of different sizes, considering each variable separately

894894

