Efﬁcient Genome-Wide, Privacy-Preserving Similar Patient

Query based on Private Edit Distance

Xiao Shaun Wang1, Yan Huang2, Yongan Zhao2, Haixu Tang2, XiaoFeng Wang2, and Diyue Bu2

1University of Maryland

wangxiao@cs.umd.edu

2Indiana University, Bloomington

{yh33,yongzhao,hatang,xw7}@indiana.edu

ABSTRACT
Edit distance has been proven to be an important and frequently-
used metric in many human genomic research, with Similar Patient
Query (SPQ) being a particularly promising and attractive exam-
ple. However, due to the widespread privacy concerns on revealing
personal genomic data, the scope and scale of many novel use of
genome edit distance are substantially limited. While the problem
of private genomic edit distance has been studied by the research
community for over a decade [5], the state-of-the-art solution [30]
is far from even close to be applicable to real genome sequences.

In this paper, we propose several private edit distance protocols
that feature unprecedentedly high efﬁciency and precision. Our
construction is a combination of a novel genomic edit distance ap-
proximation algorithm and new construction of private set differ-
ence size protocols. With the private edit distance based secure
SPQ primitive, we propose GENSETS, a genome-wide, privacy-
preserving similar patient query system. It is able to support search-
ing large-scale, distributed genome databases across the nation. We
have implemented a prototype of GENSETS. The experimental re-
sults show that, with 100 Mbps network connection, it would take
GENSETS less than 200 minutes to search through 1 million breast
cancer patients (distributed nation-wide in 250 hospitals, each hav-
ing 4000 patients), based on edit distances between their genomes
of lengths about 75 million nucleotides each.
Categories and Subject Descriptors
K.6.0 [Management of Computing and Information Systems]:
Security and Protection

Keywords
Secure Computation; Genomic Computation; Edit Distance

1.

INTRODUCTION

Consider a physician seeking the best clinic decision for her pa-
tients. Invaluable to the effort is the information how other sim-
ilar patients respond to different therapies. As today’s sequenc-
ing technologies have cut the cost of whole genome sequencing

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12-16, 2015, Denver, CO, USA
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813725.

down to roughly $1000 per person [52], it is highly anticipated
that genome-based Similar Patient Queries (SPQ) will be used to
identify similar patients from a large number of Electronic Medi-
cal Records, through a health information exchange (HIE) system
such as PatientsLikeMe (a patient powered resesarch network [1]),
or other emerging systems like the Memphis HIE, Indiana HIE
and Illinois HIE. Among the indicators of genetic similarity, edit-
distance is one of the most important metrics, which is very useful
in the biomedical research for the diagnosis and treatment of can-
cer, Alzheimer’s disease, Schizophrenia, etc [44, 49, 22, 51].
Genome-wide Secure SPQ. Standing in the way of deploying a
national-scale, genome-wide SPQ system, however, is the privacy
and liability concerns in the dissemination of such data. While
unauthorized disclosure of personal genome data could cause seri-
ous harm to patients, such as denial of insurance, employment and
education opportunities or blackmail [29], getting proper authoriza-
tions from millions of patients to share their data is not easy, due
to its complicated procedure. Further, searching disease data solely
relying on signed agreements can be less realistic in the near future,
particularly when it comes to the secondary use (e.g., biomedical
research). As a result, in the absence of scalable techniques that
enable data use without exposing its content to unauthorized par-
ties, the chance for any SPQ system to be deployed in practice is
remote, at least in the near future.

Addressing such privacy challenges in supporting SPQ over dis-
tributed genomic datasets seems right up the alley of Secure Multi-
Party Computation (SMC). Despite continuous performance im-
provements of secure computation in recent years, the scalability
and performance of the state-of-the-art edit-distance based SPQ is
still far from usable in supporting SPQ queries: the most efﬁcient
SMC implementation can only compute the edit distance between
two sequences of a few thousands of base pairs, at a cost of hours
of computing time and tens of gigabytes of bandwidth consump-
tion [30]. This is completely off the scale expected for a nation-
wide SPQ system.
Secure query at the national scale. To enable patients to beneﬁt
from the soon-to-be-available, enormous amount of clinic genomic
data, we propose a suite of novel techniques to offer secure SPQ
based on the edit distance metric. Our approach, called GENSETS
(Genome-wide, Secure Patient Search), is capable of searching 250
hospitals each containing 4000 patients (totally 1 million patients)
across the nation within 200 minutes, by securely thresholding the
edit distances over real genome data from breast cancer patients
(Section 4.1).

Underpinning GENSETS are a few key insights that enables a
simple and effective edit-distance based SPQ design. First, we ob-
serve a unique feature in human genome sequences and exploit it
in developing a highly accurate approximation of edit distance be-

492tween genomes. More speciﬁcally, variations across the genome
sequences of two average human individuals (even those associated
with different genetic diseases) are dominated by nuleotide sub-
stitutions, with sporadic insertions and deletions scattered across
the genome. Second, leveraging a public reference genome (so the
variations of one’s private genome from the reference genome can
be locally computed) and pre-computed private variations, the edit-
distance between two private genomes can be efﬁciently approx-
imated using set difference size from the (much shorter) private
variations. Third, the size of private set difference can be securely
approximated (without ever computing the private set difference)
using probabilistic algorithms; furthermore, secure thresholding on
the size of private set difference can be computed even more efﬁ-
ciently without ever computing even the size of set difference.

Combining those key observations above, we convert the prob-
lem of private edit distance into a much simpler problem of approx-
imating the size of set difference (Section 3.2). We showed, through
running our prototype in realistic continental network environment,
that the edit distance between the whole-genomes of two persons
can be securely calculated in less than 40 seconds, at an error rate
of 1.5%; while comparing the edit distance of two persons’ whole-
genomes with a threshold value can be done even faster, consuming
less than 0.9 seconds to achieve 0.01% false positive/negative rate.
This secure SPQ primitive (based on secure edit-distance) can
potentially be deployed to support two-stage queries, in which hos-
pitals will group their patients into clusters so that the ﬁrst stage
query identiﬁes (by computing private edit distance between the
query and the cluster center, which is a patient in the cluster) can-
didate clusters that contain similar patients; while the second stage
only searches similar patients in those candidate clusters.

We implemented the secure SPQ primitive and evaluated our ap-
proach over a real genome dataset consists of 105 breast cancer pa-
tients (data obtained from dbGaP/TCGA with IRB approval). We
run SPQ experiments over a cross-country network. With a 100
Mbps network connection, GenSets can accurately execute a SPQ
query in less than 200 minutes to search through 1 million patients
distributed in 250 hospitals (assuming each hospital has 4000 pa-
tients’ records and that at most 5 candidate hospitals are selected to
continue to the second stage). This result shows that our techniques
have moved secure SPQ, one of the most important application of
HIE, close to practice use.
Contributions. The contributions of the paper include:
• New techniques. We developed a new approach to realize se-
cure SPQ based on whole-genome edit-distance, attaining un-
precedented high performance. We achieved this by exploiting
intrinsic features of human genome data and efﬁcient probabilis-
tic approximation algorithms. Speciﬁcally, we propose an ef-
ﬁcient, scalable algorithm to approximate edit-distance for hu-
man genomes (Section 3.2), two efﬁcient, probabilistic private
set difference size protocols and an efﬁcient, probabilistic private
set difference size thresholding protocol (Section 3.4). These,
together with a new two-step SPQ search scheme, moves the
privacy-preserving SPQ closer to the national scale than it has
ever been.

• Implementation and evaluation. We implemented our design and
evaluated it in a large-scale experiment using realistic genome
dataset. The experiments demonstrate a promising prospect of
deploying privacy-preserving SPQ systems. Our system will be
made open source to the community at https://github.
com/SPQ-EditDistance/code.

A Note on Security. The proposed approach in this paper faces the
security concern raised by Feigenbaum et al. [23], since we rely

on the two parties to locally compute their sketches using public
hash functions with public randomness. To get around this issue,
we adopted a weaker notion of security deﬁned with respect to a
modiﬁed ideal world execution (see Section 3.1), where, aside from
the approximation outcome, the randomness used in constructing
the sketches is also revealed. It remains an open question whether
our approach is secure (or insecure) with respect to the standard
deﬁnition of ideal world execution (where the randomness is not
revealed).

2. BACKGROUND
Genetic variations and SPQ. The human genome includes two
complementary strands, with 3 billion DNA bases each. Each unit
on the strand is a nucleotide (A, T, C or G). Between two randomly-
selected individuals, over 99% of their nucleotides are identical,
with the rest different due to genetic variations. The most common
variation involves only a single nucleotide, which can be either a
major allele “0”, or a minor one “1”. Such a variation is called Sin-
gle Nucleotide Polymorphism (SNP). About 50 million nucleotides
in human genome are marked as SNPs according to dbSNP [47],
while two average individuals’ genomes typically differ in 4-5 mil-
lion variation sites.

The DNA data produced by the sequencer are in the form of a
large number of short sequences, which are later assembled into
a whole sequence by aligning each short sequence with a public
reference genome. The differences between the sequence and the
reference, including the nucleotide(s) changed, inserted or deleted
at different genetic positions, are documented in a VCF (Variation
Call Format) ﬁle. A genome-wide SPQ actually happens on the
VCF representations of two genome sequences. Note that restrict-
ing the comparison to only a set of genetic markers for certain dis-
eases often leads to inferior medical decisions, because, on the one
hand, the state-of-the-art understanding of the association between
diseases and genetic variations are dynamically improving, and on
the other hand, many other variations, which are not part of the
disease’s genetic markers, could also affect a treatment decision
(e.g., patients’ reaction to a therapy, known as the pharmacoge-
nomic markers [22]).
Secure Computation. The goal of secure computation is to allow
several parties to jointly compute a function over secret input data
supplied by each party, without using a trusted third party. The
theory of secure computation is able to offer a security guarantee
as strong as what can be achieved with a trusted third party, i.e.,
absolutely no information leak beyond what can be inferred from
the desired outcome of the function. Since its inception in early
1980s [53, 28], many constructions have been proposed, reducing
the security guarantee either to the certain computational hardness
assumptions [54, 39], to the dominance of honest participants [12,
8], or to the availability of a source of correlated randomness [9,
10]. In this paper, our construction is built and tested with the gar-
bled circuit protocol. More recently, many cryptographic [41, 36,
46, 11, 55] and implementational [41, 30, 40] optimizations have
been proposed that signiﬁcantly improve the state-of-the-art of gar-
bled circuit protocols.
Threat model. We focus on the honest-but-curious (a.k.a. semi-
honest) model, where the parties are trusted to always follow the
protocol speciﬁcation but would do arbitrary (efﬁcient) side com-
putation in an attempt to violating the security of the system. This
model makes sense in many real-world applications as launching
an instance of a secure computation protocol alone already re-
quires substantial level of trust among the participants, e.g., through
a mutual (but weaker ﬂavor of) agreement. Given a honest-but-

493human genomes are within 0.25∼0.5% of the true values; while
the false positive and false negative rate of our private edit dis-
tance thresholding protocol running on our realistic human genome
dataset are within 0.01%.

Our high level idea is illustrated in Figure 1. First, each party
will agree on a public reference genome Ref and independently
compress local genomes with respect to Ref (by recording the mini-
mum sequence of edits to derive itself from Ref). As a toy example,
given the public reference genome Ref to be GCACTGGCCTT, the
genome sequence A=GCAATAGCCTTC can be denoted as a set A
of operations, {(4, sub, A), (6, sub, A), (12, ins, C)}, i.e., the mini-
mum edits to convert the sequence Ref into A. Due to the informa-
tion redundancy in human genomes, this step can typically com-
press a genome string representation of about 3 billion base pairs
into roughly 5 million edits (stored in a VCF ﬁle). The key in-
sight is that the edit distance between two human genomes A and B
can be approximated both efﬁciently and accurately, through com-
paring only the VCF ﬁle representation of their edits from a single
common Ref. Note that in our simpliﬁed toy example, the set of ed-
its (desirably) contains only single-character operations, while the
VCF ﬁle for a real genome will contain multi-character operations.
Section 3.2 will elaborate the detailed algorithm to handle these
complications and an extensive, empirical study of the accuracy of
this approximation applied to human genomes.

Once the sequence of edits in a VCF ﬁle is converted into a set
of single-character edits, the edit distance of two genomes can be
approximated by the size of the symmetric difference between the
two sets of single-character edits associated with the two genomes.
Note that for the purpose of handling whole-genomes, each single-
character-edit set typically contains 8∼10 million edits. This is,
unfortunately, still a scale too large to be efﬁciently handled by ex-
isting private set difference protocols. To this end, we propose a
highly efﬁcient private set difference size protocol exploiting the
idea of probabilistic sketches (Section 3.3). Additionally, observ-
ing that the most frequent computation in our SPQ application is
actually comparing an edit distance to a threshold value, we intro-
duce a secure set difference size thresholding protocol which runs
another order-of-magnitude faster than (our already fast) private set
difference size protocol. All these protocols related to private set
difference size are generic and readily composable with other se-
cure computation protocols, hence maybe of independent interest.
Infrastructure. Built on top of the primitive is a secure SPQ infras-
tructure, as illustrated in Figure 2. Consider that a physician makes
an SPQ for her breast cancer patients across hundreds of hospitals.
Before the query happens, each hospital can pre-processed their
data, grouping its patients’ DNA sequences into a few clusters. For
each cluster, a synthesized sequence that represents the center of
the cluster is generated to support the query.

With the pre-computed clusters, the whole SPQ happens in two
stages. In the ﬁrst stage, the querier (the physician’s secure SPQ
client) runs the secure SPQ primitive with each hospital who sup-
plies just the cluster centers, in order to identify all the hospitals
that could have the similar patients (i.e., has at least one cluster cen-
ter close to the query). Then, the second stage could be launched
between the querier and all candidate hospitals identiﬁed as a re-
sult of the ﬁrst stage, to securely scan through all patients in these
hospitals.
Ideal World Execution.
The notion of security offered by
GENSETS is deﬁned with respect to a relaxed variant of ideal world
execution: upon receiving a query genome and a threshold t from
the client and a list of genome strings from the database server, the
trusted party generates a random string r and uses the approxima-
tion algorithm (described in Section 3.2) followed by applying a

Figure 1: Secure protocols of human-genome edit distances

curious protocol, Huang et al. [31] give a highly efﬁcient dual exe-
cution protocol that leaks only one extra bit of information in pres-
ence of fully malicious attackers, while many cryptographic tech-
niques [35, 38, 33, 45, 19, 26] could be automated to strengthen
semi-honest protocols to work with active adversaries.

Feigenbaum et al. [23] studied the general problem of secure ap-
proximation. They pointed out that the standard deﬁnition of secu-
rity might not be always achievable if a sketching algorithm is not
fully executed using generic secure computation. The security of
our approach relies on an additional assumption (which is also used
by Lindell and Pinkas [37]) that learning the randomness used by
the sketch algorithm in addition to the approximation results does
not provide non-negligible advantage to the adversary in breaking
the system.

3. DESIGN AND IMPLEMENTATION

GENSETS consists of a highly accurate approximation of edit
distance between human genomes (Section 3.2), efﬁcient private
set difference size protocols and an efﬁcient private set difference
size thresholding protocol (Section 3.3). We will also discuss
genome-wide clustering and two-step secure SPQ infrastructure in
Section 3.5. We begin our description with an high level overview.
3.1 Overview
The SPQ Primitive. GENSETS is built around primitive SPQ pro-
tocols based on secure edit distance, which is arguably one of the
most important biological similarity indicators [49]. The edit dis-
tance between sequences A and B is deﬁned as the minimum num-
ber of edits (insertion, deletion, or substitution of a single character
is counted as one edit) to change A into B. Edit distance computa-
tion over generic input sequences requires O(n2) time, which does
not scale well on large inputs such as human’s whole genome se-
quences. Computing edit distance is especially challenging in the
privacy-preserving setting: the state-of-the-art protocol computing
the distance between two sequences of lengths only 2K and 10K in
a Giga-bits LAN setting requires more than 3.5 hours and 38 GB of
network trafﬁc [30]. This is also the largest problem instance that
has ever been attempted in privacy-preserving setting thus far.

We propose several new secure protocols for edit distance. Our
protocols are order-of-magnitude more efﬁcient — 20 seconds to
securely compute (with an error rate of less than 1%) the edit dis-
tance between two whole-genomes (each containing roughly 3 bil-
lion bases) and merely 0.1 second to securely threshold (with rea-
sonable false positive/negative rates) the edit distance between two
whole-genomes. Our protocol does introduce errors, but only at
very limited scale: we have shown through experiments that er-
rors resulted from the secure edit distance protocol applied to real

GCAATAGCCTTC CACAAGCCATTC Ref = GCACTGGCCTT A =  {( 4, sub, ‘A’),  ( 6, sub, ‘A’),  (12, ins, ‘C’)}B = {( 1, del,  1 ),  ( 5, sub, ‘A’),  ( 6, sub, ‘A’), (10, ins, ‘A’), (12, ins, ‘C’)}|Diff (A, B)| =  ? |Diff (A, B)|     t ?> Compress genome sequences into sets  using a public Ref genome[Section 3.2] Private comparison of sets Private set difference  size [Section 3.4] Threshold of private set  difference size [Section 3.4] 4941. Each party calculates the minimum edit sequences from Ref
to their own genomes. (In practice, edits of one genome (also
known as variations) are stored in a VCF ﬁle.)

2. Each party computes a set of single-character edits from the
minimum edit sequence associated with their private genome.
Namely, every multi-character edit e = (pos, op, aux ) (where
pos is the location of the edit, op is the type (either insert, delete,
or substitute) of the edits, and aux represents operation-speciﬁc
editing information) is decomposed into single-character edits
as follows:
Inserts: Inserting a string c1 . . . cn at location loc, denoted as
(loc, ins, c1 . . . cn), is translated into (loc, ins, 1, c1), (loc, ins,
2, c2), ··· , (loc, ins, n, cn).
Deletes: Deleting a string of length n at location loc, denoted as
(loc, del, n), is translated into (loc, del, 1), (loc+1, del, 1), ··· ,
(loc+n-1, del, 1).
Substitutes: Since substitutes are already deﬁned with respect
to a single character, no special treatment is needed to break
them down.

3. The parties run a secure computation protocol to calculate the
size of symmetric set difference between the two sets and output
it as an approximation of the edit distance between the genomes.
The symmetric set difference between sets A and B, denoted as
Diﬀ (A, B), is deﬁned as (A − B) ∪ (B − A).
Note that the ﬁrst two steps only involve the public Ref and one
party’s genome, hence accomplishable with relatively inexpensive
local computation. Moreover, they are also amortizable in the sense
that they need to be done only once in a preparation stage, no matter
how many queries are to be serviced. Only the third step requires
more expensive secure computation, whose design is detailed in the
next two subsections.
Examples. Suppose
The minimum edits to convert Ref to A is {(1, sub, G), (5, del , 3)},
and to convert Ref to B is {(1, sub, G), (4, del , 3)}. Breaking down
the edits into single-character edits, the two parties can respectively
obtain set A(cid:48) = {(1, sub, G), (5, del , 1), (6, del , 1), (7, del , 1)}
and set B(cid:48) = {(1, sub, G), (4, del , 1), (5, del , 1), (6, del , 1)}.
Therefore,|Diﬀ (A(cid:48), B(cid:48))| = 1, which coincides with the edit dis-
tance between A and B.

Ref = ATTGCCCGA, A = GTTGGA, B = GTTCGA.

Of course, there are cases our algorithm doesn’t approximate

very well. For instance, let

Ref = ATTGCCCGA, A = GTTGGATAA, B = GTTCGATGA.
In this case, the minimal sets of edits to obtain A and B from Ref
{(1, sub, G), (4, ins, C), (5, del , 1), (6, sub, A), (7, sub, T)}
are
and {(1, sub, G), (5, sub, G), (6, sub, A), (7, sub, T), (8, sub, A)},
respectively. As A and B are already sets of single-character
edits, it is obvious that |Diﬀ (A, B)| = 4, whereas the actual
edit distance between A and B is 2. The error is caused when
comparing the 4th and 5th character of A and B— while CG can be
converted to GG with just a single sub operation, the approximation
algorithm essentially accounts it 3 times, namely, (4, sub, C) and
(5, del , 1) for A and (5, sub, G) for B, because they were derived
from Ref in different ways.

Fortunately, these types of "problematic" scenarios happen very
rarely in practice, because on human genomes, most (90% of) edits
obtained in step 1 are short edits (involving 1 ∼ 2 nucleotides and
the more problematic long-string, overlapping inserts and deletes
almost never happen. In order to establish enough conﬁdence over
our approximation algorithm, we report below a comprehensive

Figure 2: Two-stage secure SPQ with local clustering. Based
on (weighted) edit distance metric, every hospital organizes their patients
records in clusters. The ﬁrst stage employs a secure SPQ primitive protocol
to compare the querier’s genome with every cluster center, in order to iden-
tify candidate hospitals that could have a similar patient. The second stage
securely search through all patients in the candidate hospitals to identify all
genetically similar individuals.

sketching algorithm (described in Section 3.4) with random tape r
to compute all matching genomes in the server’s list, and send to
the client both the matches and the random tape r. This security
notion is weaker, comparing to that developed around the standard
ideal world execution where r is not revealed. However, we ar-
gue that, in practice, the additional leakage as result of revealing
r is highly limited, though it remains open to formally prove this
leakage is negligible.
3.2 Private Edit Distance Approximation

Our ﬁrst key observation is that the actual input strings to the
edit distance computation in the SPQ application are distributed in
a very special way. For example, for any two un-related individ-
uals, (1) much (> 99.5%) of their DNA sequences are identical;
(2) most (> 95%) of their edits (from the reference genome) oc-
cur at non-adjacent locations; (3) most (about 80 ∼ 90%) of the
edits between their genomes are substitutions. We exploited these
statistical features in designing an efﬁcient (and also very accurate)
approximation of edit distance between human genomes.

Secondly, we also observe that, assuming a public reference
genome Ref, a signiﬁcant portion of the computational task of
private edit distance between any two human genomes can be
moved into a pre-computable (and also amortizable) local prepa-
ration stage. Basically, each party pre-computes locally the mini-
mum edits from Ref to their respective private genomes, and then
launch a secure computation protocol to approximate edit distance
just from the private edits.

Next, we present detailed approximation algorithms, followed

by examples demonstrating why it works and when it does not.
The Algorithm. The protocol involves two parties, each having
a private human genome as input. The whole approximation
algorithm has three steps:

… … … …… … Local Clustering Stage 1 Stage 2 Query Genome Candidate Hospitals	  … cluster centers patients  genomes 495Length of Number of
segments
80 million

10, 000

tests

Relative Error

0.25%

0.5%

1%

78.15% 99.13% 100%

Figure 3: Accuracy of Approximation algorithm.

empirical study of comparing the end-results of our approximation
with the ground truth distance values obtained from an edit dis-
tance implementation using dynamic programming, over genome
snippets of various lengths.
Overall Accuracy. To understand the accuracy of this approx-
imation, we computed edit distance between the genomes seg-
ments (each segment contains 8, 000 nucleotides) of two randomly
selected individuals in dataset of the Personal Genome Project
(PGP) [17] and compared the values with those produced by the es-
timation algorithm above. We note that because rigorous dynamic
programming is not practical for the global alignment of genomic
sequences with millions of bases, a common practice in genome
comparison is to ﬁrst ﬁnd long identically matched segments in
the input genomic sequences, and then to chain the aligned seg-
ment into global alignment [16, 13]. This is essentially approxi-
mating the global edit distance between two genome sequences by
the sum of the edit distances between corresponding genome sub-
sequences delineated by long identically matched segments. For
comparing two human genomes with more than 99.5% identity,
this sum-of-segment method should give the same edit distance as
that computed by the rigorous dynamic programming algorithm.
Therefore, in our experiment, we used the results of the sum-of-
segment method as the ground truth distance for the comparison
with our approximation. Still, it took 365 hours to compute the edit
distance for 6, 000 tests cases.

In each test, we split long segments into shorter subsequences
of varying lengths (i.e., eight sequences of 1, 000 nucleotides, four
sequences of 2, 000 nucleotides, and two sequences of 4, 000 nu-
cleotides) and then calculated the true edit distance using dynamic
programming algorithm and approximation edit distance using our
algorithm on segments and their subsequences. In our experiments,
we observe that the edit distance between two 8, 000-nucleotide se-
quences is always exactly the same as the sum of the two edit dis-
tance values over its two 4, 000-nucleotide components; and same
observation applies to segments of length 4, 000 and 2, 000 as well.
These results suggest that, over real world human genome data, edit
distance between long sequences can be accurately computed from
sum of distances on its (not too short) subsequences.

Based on the observation above, we studied the accuracy of our
approximation algorithm on longer sequences (each contains 80
million nucleotides), by summing up distance values over 10, 000
random basic segments (each contains 8, 000 nucleotides). Our ex-
perimental results show that 99.13% of 10, 000 tests exhibited an
error rate less than 0.5%, while all tests resulted in less than 1%
error (Figure 3). These results demonstrate the accuracy of our ap-
proximation algorithm on real human genome data.
3.3 Private Set Difference Size

Our approximation algorithm above reduces a private human
genome edit distance problem to a private set difference size prob-
lem. Next, we will describe a basic protocol for private set differ-
ence size, and present in Section 3.4 three variations of the basic
protocol each best suited for certain scenarios.
Problem Deﬁnition. Given two secret sets A and B, output
|Diﬀ (A, B)| without revealing anything else about A and B. In

particular, in the context of our private edit distance approxima-
tion scheme, we hope to efﬁciently handle sets of 5 ∼ 10 million
elements, with accuracy comparable to that of the original approx-
imation algorithm discussed above.
Some Strawman Solutions. Since |Diﬀ (A, B)| = |A| + |B| −
2·|A∩ B| where |A| and |B| (the sizes of A and B) are not secret,
|Diﬀ (A, B)| could be derived from |A ∩ B|. One may attempt
to ﬁrst securely compute the set intersection of A and B using a
Bloom Filter [20, 14] then securely count the number of elements
in the intersection and infer the size of set difference. One could
even leverage a Bloom Filter cardinality estimator [48] to save the
expensive secure counting phase. Alternatively, one may even con-
struct a secure version of the Count-Min sketch [18] or Hyper-
Loglog [25] to directly estimate the intersection size without using
a Bloom Filter. However, these solutions do not work in practice
for SPQ because the error introduced in estimating the intersection
size needs be multiplied |A∩ B|/Diﬀ (A, B) times when it comes
to describing the relative error in estimating set difference size. In
SPQ, the most interesting data points (which indicates matching
patients) actually fall into the category where |A∩ B|/Diﬀ (A, B)
is very large. Tuning up the parameters (which grow at a rate of
O(1/ε) to O(1/ε2) where ε is the error rate) of these intersection
size estimators to achieve reasonably small error relative to set dif-
ference size will degrade SPQ performance to an unusable level.

A Basic Solution. We propose highly efﬁcient and accurate pro-
tocols that directly compute set difference size. For the purpose of
illustration, we ﬁrst present a basic solution (Figure 4), from which
the more efﬁcient variants are later derived.

ments. More concretely, dS is deﬁned to be(cid:80)

Inspired by the seminal work by Alon et al. [2] and Feigen-
baum et al. [24], the basic idea is to ﬁrst “compress” every input
set, say S, into a single integer dS, using a binary hash function
h : U (cid:55)→ {−1, 1}, where U denotes the universe of all set ele-
s∈S h(s). Assum-
ing h can be randomly sampled from a family of pairwise indepen-
dent binary hash functions, so for any element s, s1, s2 (s1 (cid:54)= s2)
and a randomly sampled h, it is easy to see that E[h(s)] = 0,
E[h2(s)] = 1, and E[h(s1)h(s2)] = E[h(s1)] · E[h(s2)] = 0,
with all probabilities taken over the randomness in sampling h.
Thus, for any set S,



h(s1)h(s2)

E(cid:2)d2

S

(cid:3) = E

s∈S

(cid:34)(cid:32)(cid:88)
(cid:88)
(cid:34)(cid:88)

s∈S

s∈S

= E

= E

(cid:33)2(cid:35)

h(s)

h2(s) + 2 · (cid:88)

s1(cid:54)=s2

(cid:35)

h2(s)

= |S|.

Let dA, dB be the sketch integers computed from the two pri-
vate input sets A and B, respectively.
If we further assume
the family of hash functions are four-wise independent (namely,
for all distinct s1, s2, s3, s4, E[h(s1)h(s2)h(s3)h(s4)] =
E[h(s1)]E[h(s2)]E[h(s3)]E[h(s4)]),
then we can show that

E(cid:2)(dA − dB)2(cid:3) = |Diﬀ (A, B)|. This is because

dA − dB =

(cid:88)

s∈A

h(s) −(cid:88)

s∈B

(cid:88)

h(s) − (cid:88)

s∈A−B

s∈B−A

h(s) =

h(s).

496The Basic Protocol

Protocol 1

Input of A: a set A.
Input of B: a set B.
Public Input: a (sufﬁciently long) common random string
Output: |Diﬀ (A, B)|
1. For j from 1 to k

(a) For i from 1 to (cid:96)

ii. A computes dA = (cid:80)
dB =(cid:80)

i. A and B use the (same) random string to randomly pick

a function h from the family of hash functions.

s∈A h(s), whereas B computes

s∈B h(s), independently.

iii. A and B run a secure computation protocol with re-
spective private inputs dA and dB, to compute Di =
(dA − dB)2.

(b) A and B securely compute ˆDj =(cid:80)(cid:96)

i Di/(cid:96).

2. A and B securely compute the median Z of ˆD1, · · · , ˆDk.

Output Z.

Figure 4: The basic protocol to approximate set difference size.

Therefore,

E(cid:2)(dA − dB)2(cid:3) = E

(cid:34)(cid:32) (cid:88)
(cid:32) (cid:88)

s∈A−B

+2 ·

(cid:33)2

(cid:32) (cid:88)
(cid:32) (cid:88)
(cid:33)

s∈B−A

·

h(s)

+

h(s)

(cid:33)2

(cid:33)(cid:35)

h(s1)

h(s2)

s1∈A−B

s2∈B−A

= |A − B| + |B − A| + 2 · 0 = |Diﬀ (A, B)|.
To efﬁciently bound the error, our basic protocol estimates
Diﬀ (A, B) by computing the k-median of (cid:96)-mean of random sam-
pling of (dA − dB)2.

THEOREM 0. For any two sets A, B, let d = |Diﬀ (A, B)| and
X be the output of the Basic Protocol running with A, B. Then for
any positive ε and any positive integer λ, the inequality

P r {|X − d| ≥ εd} ≤ 2

−λ

can be achieved by setting (cid:96) = O(1/ε2), k = O(λ).

PROOF. See the proof in Appendix A.

Cost Analysis.
In this basic protocol, Step 1(a)i and Step 1(a)ii
can be done locally without expensive secure computation. Both
steps are executed k(cid:96) times, while the cost of Step 1(a)ii also grows
linearly with the size of the set. Note that for a whole-genome,
the size of set A (or B) will be 5 ∼ 10 million. Also taking the
factor k(cid:96) (whose exact value depends on the accuracy needed) into
account, the cost of the local hashing step can be substantial. In
Section 3.4, we give several techniques to reduce this cost.

Expensive secure computation is required only at three places
(i.e., the Step 1(a)iii, 1b and 2), of which the Step 1(a)iii dominates
the cost. If dA and dB are ω-bit integers, then overall, it incurs
k(cid:96) ω-bit subtractions, k(cid:96) ω-bit integer squaring, (cid:96) 2ω-bit additions,
and one secure median of k 2ω-bit integers. Thus, while the dom-
inant cost comes from secure squaring, the overall cost of secure
computation also highly depends on the integer bit length ω.
Hashing. A 4-wise universal hash function can be generated by
picking a random polynomial modulo a large prime. This, however,
requires many multiplication operations per element. Therefore,
we customized murmurHash64 (by leaving out several instruc-
tions that don’t affect the accuracy of our approximation algorithm)

Input of A: a set A.
Input of B: a set B.
Public Input: a (sufﬁciently long) common random string
Output: |Diﬀ (A, B)|.
1. For j from 1 to k

(a) A and B use the public common random string to ran-
domly sample a hash function h : U (cid:55)→ {−1, 1} and a
hash function g : U (cid:55)→ {1, 2, · · · , (cid:96)}.

(b) A and B initialize arrays dA and dB (each of length (cid:96),

respectively, to all zeros.

(c) A computes dA[g(s)] := dA[g(s)] + h(s) for every
s ∈ A; while B computes dB[g(s)] := dB[g(s)]+h(s)
for every s ∈ B.

compute Dj =(cid:80)(cid:96)

(d) A and B run a secure computation protocol to securely

i=1(dA[i] − dB[i])2
pute the median Z of D1, · · · , Dk. Output Z.

2. A and B use a secure computation protocol to securely com-

Figure 5: Faster private set difference size through bucketing.
U denotes the universe of all set elements.

and used it in our prototype. In addition, our implementation fully
utilizes all 64 bits of the hash result to compute 64 dA(dB)s at the
same time.
Oblivious Transfer. When this protocol is actually deployed be-
tween hospital servers and health professional querier clients, the
querier provides only one genome sketch per query while a hos-
pital would need to provide thousands of private genome sketches
per query. We take advantage of this asymmetry by setting up the
hospital to be the garbled circuit generator so that only the querier’s
short inputs needs to be oblivious transferred in each query.
3.4 Optimized Protocols

Although our basic protocol above already outperforms the
strawman solutions, there is ample design space to explore to fur-
ther improve efﬁciency and accuracy. Next, we present a few in-
teresting optimizations that aim to reduce the cost of local hashing
and secure computation, while retaining accuracy.

3.4.1 Protocol 1
Inspired by the work of Thorup and Zhang on tabulating hashes
in second moment estimation [50], we improve the basic private
set difference size protocol through random bucketing. The full
protocol is given in Figure 5. The basic idea is to require each
party to associate every set element s with one single (out of (cid:96) in
total) bucket, according to a hash of s, namely g(s) in Figure 5;
and then estimate the number of elements in Diﬀ (A, B) falling
in each bucket simply with (dA[i] − dB[i])2, and ﬁnally sum the
numbers up. Like in the basic protocol, the median function is also
used to bound the estimation error. Now it involves only a single
loop of k iterations, and in each iteration an element will be hashed
only once. The key observation is that although an (cid:96)-times coarser
estimator is used to measure the size of each bucket (hence saving
a factor of (cid:96) hashes), the variance of (dA[i] − dB[i])2 is actually
(cid:96)-times smaller thanks to bucketing. Thus, it achieves the same
level of accuracy with (cid:96)-times less hashing compared to the basic
protocol.

THEOREM 1. For any two sets A, B, let d = |Diﬀ (A, B)| and
X be the output of Protocol 1 running with A, B. Then for any

497Protocol 2

Input of A: a set A.
Input of B: a set B.
Public Input: a (sufﬁciently long) common random string
Output: |Diﬀ (A, B)|.
1. For j from 1 to k

i. A and B use the (same) random string to randomly pick

a function h from the family of hash functions.

s∈A h(s), whereas B computes

s∈B h(s), independently.

iii. Party A and B run a secure computation protocol
to compute

respectively,

(a) For i from 1 to (cid:96)

ii. A computes dA = (cid:80)
dB =(cid:80)
Di =(cid:112)π/2 · |dA − dB|.

with inputs dA and dB,

(b) A and B securely compute ˆDj =(cid:80)(cid:96)

i Di/(cid:96).

2. A and B securely compute the median Z of ˆD1, · · · , ˆDk.

Output Z2.

Figure 6: Faster set difference size without secure squaring.

positive ε and any positive integer λ, the inequality

Pr{|X − d| ≤ εd} ≥ 2

−λ

can be achieved by setting (cid:96) = O(1/ε2), k = O(λ).

PROOF. See the proof in Appendix C.

Remark. The beneﬁts of randomized bucketing actually go be-
yond reducing the number of local hashes. Since the number of
times the accumulators dA[i] and dB[i] are incremented is reduced
by (cid:96) times, the number of bits (ω) in dA[i], dB[i] is then reduced
by log (cid:96), which saves substantial cost (30 ∼ 40%) in the secure
computation stage.

3.4.2 Protocol 2
As is mentioned earlier, secure squaring accounts for the dom-
inant cost of the secure computation part of the protocol. Fortu-
nately, under an extra assumption that (dA − dB) is very close
to normal distribution, it can be shown that E(|dA − dB|) =
cause |dA − dB| is a half-normal distribution [3]. Thus, mea-
suring E(|dA − dB|) sufﬁces to provide a good estimation of

σ(cid:112)2/π (where σ2 = E(cid:2)(dA − dB)2(cid:3) − (E[|dA − dB|])2) be-
E(cid:2)(dA − dB)2(cid:3). Because dA − dB is a binomial distribution, it is

indeed very close to normal distribution as the set difference sizes
observed in our genomic SPQ application all turn out much larger
than 10,000.

Figure 6 describes the improved protocol based on this observa-
tion (and the extra assumption that the size of set difference is not
too small). The protocol resembles that of the basic protocol except
for two changes highlighted with double-underlines in Step 1(a)iii
and Step 2.

THEOREM 2. For any two sets A, B, let d = |Diﬀ (A, B)| and
X be the output of Protocol 2 running with A, B. Then for any
positive ε and any positive integer λ, the inequality

P r {|X − d| ≤ εd} ≥ 2

−λ

can be achieved by setting (cid:96) = O(1/ε2), k = O(λ).

PROOF. See the proof in Appendix C.

i=1 Zi

2(cid:105)

(cid:104)(cid:80)k

We remark that it is unclear whether it is possible to harvest the
savings by combining both ideas in one protocol, as the two opti-
mizations are not compatible when trivially combined. To see the
reason, imagine a third protocol randomly places set elements in (cid:96)
buckets and attempts to use non-squaring approach to estimate the
number of difference elements in each bucket. Because the number
of elements in each bucket needs to be kept secret, the squaring op-
eration of Step 2 in Protocol 2 needs to be done securely. Note that
this per bucket squaring can’t be simply moved to the end because
(where Zi is obtained for the i-th bucket) to be
for E
equal to Diﬀ (A, B), Zi’s need to be at least pairwise independent.
However, this is not the case as each element was hashed into one
and only one (out of (cid:96)) bucket.
3.4.3 Thresholding private set difference size
Although the protocols above are able to securely approximate
the size of set difference with arbitrary precision, the key primitive
that ﬁts best with a secure SPQ system (such as PatientLikeMe)
is actually comparing the set difference size with a given thresh-
old, producing merely 1-bit output. In fact, thresholding the dif-
ference size is more desirable because it limits the potential infor-
mation leak through output. A private set difference size protocol
can be trivially extended to provide the secure thresholding primi-
tive. However, it is worth noting that secure thresholding protocols
generally result in much less error compared to the corresponding
private set difference size protocols from which they are derived,
due to a difference in the notion of error: 1% error in the size of
set difference implies the estimated value is 1% away from the true
value; while 1% error in thresholding the size actually means the
chance to arrive at a wrong decision is 1%. As a result, smaller pa-
rameters (k, (cid:96) values) sufﬁce to achieve the same level of accuracy.
We have done extensive experiments to evaluate the performance
and accuracy of secure thresholding protocols (see Section 4.1).
3.5 SPQ Infrastructure

Based on the secure SPQ primitive described above, we imple-
mented a prototype infrastructure to support a secure SPQ over a
large amount of data across multiple institutions. Such an infras-
tructure could be improved to work in a practical scenario where
hundreds of thousands of genomes (associated with a particular dis-
ease, e.g., the breast cancer) collected by hundreds of hospitals are
scanned to ﬁnd those genetically similar to the patient in the query.
To make this operation efﬁcient at large scales, we design a data
pre-processing mechanism for each hospital to organize its patient
data into clusters.
Clustering. We leverage the complete-linkage hierarchical cluster-
ing algorithm [34] (other more sophisticated algorithms can also be
plugged into our infrastructure) to cluster patient genomes based on
our edit distance approximation (Section 3.2). Note that the notion
of clusters here does not necessarily match up with a known patho-
logical categorization.
In each cluster, a synthesized sequence,
called representative, is generated. Let δ be the radius of each clus-
ter, and  be the threshold used to identify similar patients. Due to
the triangular property of edit distance, if a patient P in a cluster
C is considered similar to the querier’s patient Q, then the distance
between Q and the representative of C should be no more than
δ + ε.
Two-stage search. With these pre-computed clusters, a SPQ search
will be performed in two stages (Figure 2):

1. Compare the edit distance between the query genome and
each cluster representative with threshold δ + ε using a se-

498cure thresholding scheme: if the distance is below the thresh-
old, the hospital owning this cluster will be selected for the
second stage search.

2. Compare the edit distance between the query genome and
each patient in every selected hospital with threshold ε us-
ing a secure thresholding scheme: if the distance is below the
threshold, the pseudo-identiﬁer of the patient will be returned.

In the particular case of SPQ, ε is chosen to be much smaller
than the edit distance between two random patients within the same
cluster, i.e., ε (cid:28) δ. This allows us to use δ as the threshold for
the ﬁrst stage search to efﬁciently eliminate clusters that contain
no patients similar to the query. Note that for a query involving
a similar patient a in cluster A, the distance between the query
genome and the representative of any other cluster is unlikely below
δ + ε (as ε (cid:28) δ) unless the query genome (and its similar patient)
is close to the border of the cluster.

4. EVALUATION

In this section, we present experimental evaluation of both accu-

racy and efﬁciency of GENSETS.
System and network. Unless explicitly speciﬁed otherwise, all
experiments were performed between two machines located more
than 2000 miles apart (one in Bloomington, Indiana and the other
in San Diego, California). The bandwidth is about 100Mbps with
variations. We run the garbled circuit and oblivious transfer pro-
tocols using a single thread. We exploited multi-core parallelism
to compute the amortizable precomputed hashing phase of sketch
construction.

The implementation of the garbled circuit protocol leverages
half-gate garbling [55] and free-XOR technique [36]. The oblivious
transfer is implemented using NPOT [42] with OT extension [32]
of Ishai et al.
Metrics. In our evaluation, we use the following metrics to mea-
sure the accuracy and efﬁciency of our approach.

1. False positive/negative rate. A false positive refers to the
event that a patient dissimilar to the query is returned; while a
false negative happens when a similar patient is not returned.
2. Error rate. Error rate measures the accuracy of private set
difference size protocols. It is deﬁned to be |u−v|/u where u
denotes the true size and v is what the secure protocol outputs.
3. Number of AND gates. With garbled circuit protocol, the
main cost grows linearly with the number of AND gates in
the circuit.

4. Wall-clock time. This is the total elapsed time of a task.

4.1 Thresholding Private Set Difference Size
Private set difference size thresholding protocols are the core
SPQ primitive that enables GENSETS. Figure 7 and Figure 8 show
the performance of our thresholding protocols running over breast
cancer patients’ genomes (each of which is represented by a VCF
ﬁle of roughly 150K variations). The private edit distance protocol
is reduced to thresholding the set difference size of two sets, each
containing 200K ∼ 300K single-character edits.

We observe that the accuracy achieved is generally proportional
to the value of kl (at least when the difference in k is small). Also
note the asymmetry of errors in the range around the threshold.
For instance, comparing the columns d = 0.9t and d = 1.1t, the
false negative rates (on columns with d < t) is always smaller than
the false positive rates (on columns with d > t) on their mirror-
ing columns. This would be desirable in SPQ search as the users

are usually more sensitive on false negatives (i.e., similar patients
are overlooked) while tending to tolerate false positives (irrelevant
patients are returned). Last, note that protocol 1 and 2 performs
comparably in thresholding the set difference size, except that pro-
tocol 2 is about 30% faster, while protocol 1 is slightly better in
terms of accuracy.

In our particular application of secure SPQ, we assume there are
250 hospitals, each of which keeps 4000 patients records organized
in 8 clusters. The ﬁrst stage would check a total of 250× 8 = 2000
clusters. Assuming at most 5 hospitals will be selected as can-
didates to proceed in the second stage search, which amounts to
searching through all 4000 × 5 = 20000 patients in these 5 hospi-
tals. Since cluster centers have the same representation as patient
genomes, the performance of the entire search for similar breast
cancer patients is equivalent to checking 22000 patients. Using
protocol 2 with parameter k = 5, (cid:96) = 512, 22000 edit-distance
comparison can be accomplished within 183 minutes.
4.2 Private Set Difference Size

In an SPQ scenario, calculating the set difference size with high
precision is mostly unnecessary. However, once a similar patient
is found, it may be worthwhile to calculate the edit distance with
high accuracy to conﬁrm the match. Moreover, many other per-
sonal genomic applications (such as genetic diagnosis and medical
treatment risk prediction) may ﬁnd it useful to be able to precisely
estimate edit distance in a privacy-preserving way.

Figure 9 shows the performance of Protocol 1 and Protocol 2
used in private set difference size estimation scenario. For each pro-
tocol, we report the cost to bound 90%-percentile error rate to 1%
and 0.5%, respectively. This means that for 90% of the test cases,
the relative error is less than or equal to 1% or 0.5% respectively.
The results show that the protocols runs signiﬁcantly slower than
private set difference size thresholding protocols. However, since
the number of similar patients returned in the ﬁnal stage is usually
quite low (typically less than 10), users can afford much more time
per candidate patients for obtaining an accurate distance.

Note that, thanks to the optimized conﬁguration of the OT pro-
tocol (Section 3.3), the cost of OT is independent of number of
patients on the hospital server. Therefore, the total running time to
query n patients can be calculated as

TimeTotal = TimeOT + n × (TimeLocal + TimeGC) .

It is easy to verify that the total times reported in the ﬁgure con-
forms to the formula above with n = 10.
4.3 Experiments on Whole Genomes

We have also measured the performance of our protocols over
whole-genomes obtained from the PGP project. Figure 10 shows
the total running time of our approach on whole genomes. First we
ﬁnd that the timings for whole genome data are about 4 ∼ 5 times
slower than those of breast cancer tests, because the genomes con-
sidered in breast cancer tests are only a fraction (1/40) of whole
genomes. The primary cause of the slowdown is the increased cost
of garbled circuit generation and evaluation, since the bit length
ω of the sums of the hashes is increased by a factor of around
log 40 ≈ 5.3). Secondarily, the local hashing and oblivious trans-
fer, whose costs grow linear with the length of the input genomes,
are 40 times more expensive.
5. RELATED WORK
Secure Approximation. Feigenbaum et al. [23] ﬁrst considered
the problem of secure approximation. Generally a streaming algo-
rithm consists of phases to locally compute the sketches and those

499k

(cid:96)

3

5

32
64
128
256
512
32
64
128
256
512

Set Difference Siz (d)

1000 Patients

0.7t

0.8t

0.9t

0.95t

1.05t

1.1t

1.2t

1.3t

False negative rate

False positive rate

Running time Bandwidth

0.01% 0.06% 0.22% 0.33% 0.43% 0.33% 0.17% 0.09%
0.0% 0.02% 0.15% 0.3% 0.37% 0.24% 0.08% 0.02%
0.0%
0.0% 0.09% 0.24% 0.31% 0.15% 0.02% 0.0%
0.0%
0.0% 0.03% 0.18% 0.22% 0.06% 0.0%
0.0%
0.0%
0.0% 0.01% 0.1% 0.12% 0.01% 0.0%
0.0%

0.0% 0.03% 0.17% 0.29% 0.42% 0.29% 0.12% 0.04%
0.0% 0.01% 0.1% 0.25% 0.35% 0.19% 0.04% 0.0%
0.0% 0.05% 0.2% 0.25% 0.09% 0.01% 0.0%
0.0%
0.0%
0.0% 0.01% 0.12% 0.16% 0.03% 0.0%
0.0%
0.0%
0.0%
0.0%
0.0%

0.0% 0.05% 0.08% 0.0%

47.13s
59.84s
92.96s
165.57s
304.16s

54.78s
80.25s
173.34s
244.81s
596.79s

0.17GB
0.34GB
0.67GB
1.35GB
2.69GB
0.29GB
0.57GB
1.13GB
2.25GB
4.49GB

Figure 7: Thresholding set difference size using extended protocol 1. (using breast cancer patients’ genome) When k = 3, (cid:96) = 256,
given a threshold t, this algorithm achieves a false negative rate of 0.03% if the set difference size is 0.9t; and achieves a false positive rate
of 0.06% if the set difference size is 1.1t.

k

(cid:96)

3

5

32
64
128
256
512
32
64
128
256
512

Set Difference Size (d)

1000 Patients

0.7t

0.8t

0.9t

0.95t

1.05t

1.1t

1.2t

1.3t

False negative rate

False positive rate

Running time Bandwidth

0.02% 0.09% 0.26% 0.38% 0.41% 0.32% 0.17% 0.08%
0.0% 0.03% 0.19% 0.33% 0.36% 0.24% 0.09% 0.02%
0.0% 0.01% 0.12% 0.27% 0.3% 0.16% 0.02% 0.0%
0.0%
0.0%
0.0%
0.0%

0.0% 0.04% 0.2% 0.23% 0.07% 0.0%
0.0% 0.01% 0.12% 0.14% 0.02% 0.0%

0.0% 0.05% 0.21% 0.34% 0.38% 0.27% 0.11% 0.04%
0.0% 0.01% 0.13% 0.28% 0.33% 0.19% 0.04% 0.01%
0.0% 0.06% 0.21% 0.27% 0.1% 0.01% 0.0%
0.0%
0.0%
0.0% 0.02% 0.15% 0.17% 0.03% 0.0%
0.0%
0.0%
0.0%
0.0%
0.0%

0.0% 0.07% 0.09% 0.0%

31.7s
44.05s
66.26s
131.98s
226.2s

43.06s
62.83s
99.89s
224.96s
497.51s

0.11GB
0.22GB
0.44GB
0.96GB
1.75GB
0.21GB
0.37GB
0.73GB
1.6GB
3.2GB

Figure 8: Thresholding set difference size using extended Protocol 2. (using breast cancer patients’ genome)

to jointly combine the sketches. Feigenbaum et al. pointed out that
it is unclear how to prove it secure if secure computation protocol
is not used to compute the sketches, (although no actual attacks are
identiﬁed). We get around this issue by relaxing the security def-
inition to allow revealing the randomness used in the sketch com-
putation in the ideal world execution.
Privacy-preserving Genome Analysis. Researchers proposed so-
lutions to privately compare two genomes, either using a private set
intersection (PSI) protocol [6], or a private set intersection size pro-
tocol [15]. These works, however, modeled the similarity by Ham-
ming distance between genomes and could only handle relatively
short genome snippets. In contrast, our work targets at the more
challenging (and also generally more useful) edit distance proto-
col applied to people’s whole-genomes. In addition, the private set
difference size protocol runs many orders of magnitude faster than
those derived from the state-of-the-art PSI or PSI size protocols.
Streaming Algorithms. Streaming algorithms, introduced by the
groundbreaking work of Alon et al. [2], aim to signiﬁcantly im-
prove the (space, communication, and time) efﬁciency of problem
solutions by tolerating a (controlled) small error. We borrowed
many useful ideas from streaming algorithms research in design-
ing the private set difference size protocols. However, different
from the existing research on streaming algorithm, we studied the
problem in secure computation setting, thus exploring the design

√

space under a different set of goals, e.g., efﬁcient joint computation
versus small working space and low plaintext communication.
Approximating Edit Distance Quite a few researchers have con-
sidered approximating edit distance for general input strings, par-
ticularly in the streaming setting [4, 7]. However, the best algo-
n where n
rithms still incur signiﬁcant error (such as a factor of
is the length of the input string), which renders them inapplicable in
practice. In addition, none of the existing work considers the cost
of executing the sketch combining phase with secure computation
protocols.
Approximating Set Difference Size. Feigenbaum et al. [24] pro-
posed an efﬁcient algorithm to compute L-1 norm. But their work
considers the streaming setting and is general enough to compute
weighted L-1 norm over multi-sets. Our basic protocol in Sec-
tion 3.3 was inspired by their work, but is highly customized to-
wards solving the privacy-preserving SPQ problem. For example,
we avoided algebraic computations over ﬁnite ﬁelds required in
their construction. Several other works [27, 43] have further im-
proved the update time of this scheme, but still only considering
the classic streaming model.

Using invertible bloom ﬁlter based approximation, Eppstein et
al. [21] proposed protocols to reconstruct set difference and es-
timate set difference size. Although their set difference size ap-
proximation algorithm achieved a similar asymptotic error bound

500k

5
5
5
5
5
5

Protocol 1
Protocol 1
Protocol 1
Protocol 2
Protocol 2
Protocol 2

(cid:96)

90%

Oblivious Local Hash GC time
Transfer
/ patient

/ patient

8192
16384
65535

8192
16384
65535

5.83s
9.18s
42.06s

1.4%
1.0%
0.5%
1.4%
1.0%
0.5% 125.28s

13.05s
29.8s

0.01s
0.01s
0.01s

0.37s
0.92s
2.83s

9.43s
18.98s
71.4s

7.18s
15.71s
56.52s

#AND gates Bandwidth
/ patient
73.44MB
146.88MB

531MB
52.35MB
104.7MB
419MB

/ patient
3851.0K
7701.0K
27.8M
2745.0K
5489.0K

22M

Total time
/ 10 patients

95.1s

199.08s

756s

76.84s
196.1s
718.78s

Figure 9: Private set difference size using Protocol 1 and Protocol 2. (using breast cancer patients’ genomes) The cost of oblivious
transfer is per query, as it is setup so that their costs are independent of the number of patients in server’s dataset (see Section 3.3).

k

5

(cid:96)

8192

90% Total time
/10 Patients

Total time
/100 Patients

1.42%
1.42%

390s
401s

3970s
4014s

Protocol 1
Protocol 2

Figure 10: Running Protocol 1 and 2 on whole genomes.

(in terms of sketch size), their algorithm is more expensive in the
secure computation model (because their construction focused on
minimizing the size of the sketch while ours aims at reducing the
cost of joint computation).

6. CONCLUSION

Securely computing edit distance between human whole-
genomes promises many interesting applications of personal ge-
nomic data in medical and public health domains. We described
novel techniques that is able to approximate edit distance on hu-
man genomes with unprecedented efﬁciency and accuracy. Based
on the primitives we proposed, we implemented and evaluated
GENSETS, a genome-wide secure SPQ system. The performance
of SPQ demonstrated in our experiments with realistic genomic
data and network setting shows that we have made a big step to-
wards privacy-preserving SPQ at the national scale.

7. ACKNOWLEDGEMEMNT

We would like to thank Jonathan Katz for numerous helpful
discussions. This work is supported by NSF award #1111599,
#1464113, #1117106, #1223477, #1223495, #1408874 and NIH
HG007078.

8. REFERENCES
[1] PatientsLikeMe. https://www.patientslikeme.com. Accessed

on May 8, 2015.

[2] ALON, N., MATIAS, Y., AND SZEGEDY, M. The space
complexity of approximating the frequency moments. In
STOC (1996).

[3] ALTMAN, D. G. Construction of age-related reference
centiles using absolute residuals. Statistics in medicine
(1993).

[4] ANDONI, A., AND ONAK, K. Approximating edit distance

in near-linear time. In 41st STOC (2009).

[5] ATALLAH, M. J., KERSCHBAUM, F., AND DU, W. Secure

and private sequence comparisons. In Proceedings of the
2003 ACM workshop on Privacy in the electronic society
(2003).

[6] BALDI, P., BARONIO, R., DE CRISTOFARO, E., GASTI, P.,

AND TSUDIK, G. Countering gattaca: efﬁcient and secure
testing of fully-sequenced human genomes. In CCS (2011).

[7] BAR-YOSSEF, Z., JAYRAM, T. S., KRAUTHGAMER, R.,

AND KUMAR, R. Approximating edit distance efﬁciently. In
45th FOCS (2004).

[8] BEAVER, D. Secure multiparty protocols and

zero-knowledge proof systems tolerating a faulty minority.
Journal of Cryptology (1991).

[9] BEAVER, D. Correlated pseudorandomness and the

complexity of private computations. In STOC (1996).

[10] BEAVER, D. Commodity-based cryptography (extended

abstract). In STOC (1997).

[11] BELLARE, M., HOANG, V. T., KEELVEEDHI, S., AND

ROGAWAY, P. Efﬁcient garbling from a ﬁxed-key
blockcipher. In IEEE S & P (2013).

[12] BEN-OR, M., GOLDWASSER, S., AND WIGDERSON, A.

Completeness theorems for non-cryptographic fault-tolerant
distributed computation (extended abstract). In STOC (1988).

[13] BLANCHETTE, M., KENT, W. J., RIEMER, C., ELNITSKI,

L., SMIT, A. F., ROSKIN, K. M., BAERTSCH, R.,
ROSENBLOOM, K., CLAWSON, H., GREEN, E. D., ET AL.
Aligning multiple genomic sequences with the threaded
blockset aligner. Genome research (2004).

[14] BLOOM, B. H. Space/time trade-offs in hash coding with

allowable errors. Commun. ACM (1970).

[15] BLUNDO, C., DE CRISTOFARO, E., AND GASTI, P.

Espresso: efﬁcient privacy-preserving evaluation of sample
set similarity. Journal of Computer Security (2014).

[16] BRUDNO, M., DO, C. B., COOPER, G. M., KIM, M. F.,
DAVYDOV, E., GREEN, E. D., SIDOW, A., BATZOGLOU,
S., PROGRAM, N. C. S., ET AL. Lagan and multi-lagan:
efﬁcient tools for large-scale multiple alignment of genomic
dna. Genome research (2003).

[17] CHURCH, G. M. The personal genome project. Molecular

Systems Biology (2005).

[18] CORMODE, G., AND MUTHUKRISHNAN, S. An improved

data stream summary: the count-min sketch and its
applications. Journal of Algorithms (2005).

[19] DAMGÅRD, I., PASTRO, V., SMART, N. P., AND

ZAKARIAS, S. Multiparty computation from somewhat
homomorphic encryption. In CRYPTO (2012).

[20] DONG, C., CHEN, L., AND WEN, Z. When private set

intersection meets big data: an efﬁcient and scalable
protocol. In CCS (2013).

[21] EPPSTEIN, D., GOODRICH, M. T., UYEDA, F., AND

VARGHESE, G. What’s the difference?: efﬁcient set

501[41] MALKHI, D., NISAN, N., PINKAS, B., AND SELLA, Y.

Fairplay — a secure two-party computation system. In
USENIX Security Symposium (2004).

[42] NAOR, M., AND PINKAS, B. Efﬁcient oblivious transfer

protocols. In SODA (2001).

[43] NELSON, J., AND WOODRUFF, D. P. Fast manhattan

sketches in data streams. In PODS (2010).

[44] NETWORK, C. G. A., ET AL. Comprehensive molecular

portraits of human breast tumours. Nature (2012).

[45] NIELSEN, J. B., NORDHOLT, P. S., ORLANDI, C., AND
BURRA, S. S. A new approach to practical active-secure
two-party computation. In CRYPTO (2012).

[46] PINKAS, B., SCHNEIDER, T., SMART, N. P., AND

WILLIAMS, S. C. Secure two-party computation is practical.
In ASIACRYPT (2009).

[47] SHERRY, S. T., WARD, M.-H., KHOLODOV, M., BAKER,

J., PHAN, L., SMIGIELSKI, E. M., AND SIROTKIN, K.
dbsnp: the ncbi database of genetic variation. Nucleic acids
research (2001).

[48] SWAMIDASS, S. J., AND BALDI, P. Mathematical correction

for ﬁngerprint similarity measures to improve chemical
retrieval. Journal of chemical information and modeling
(2007).

[49] TAYLOR, J. G., CHOI, E.-H., FOSTER, C. B., AND

CHANOCK, S. J. Using genetic variation to study human
disease. Trends in molecular medicine (2001).

[50] THORUP, M., AND ZHANG, Y. Tabulation based 4-universal

hashing with applications to second moment estimation. In
SODA (2004).

[51] WADDELL, N., PAJIC, M., PATCH, A.-M., CHANG, D. K.,
KASSAHN, K. S., BAILEY, P., JOHNS, A. L., MILLER, D.,
NONES, K., QUEK, K., ET AL. Whole genomes redeﬁne the
mutational landscape of pancreatic cancer. Nature (2015).
[52] WATSON, M. Illuminating the future of dna sequencing.

Genome Biol (2014).

[53] YAO, A. C.-C. Protocols for secure computations (extended

abstract). In FOCS (1982).

[54] YAO, A. C.-C. How to generate and exchange secrets

(extended abstract). In FOCS (1986).

[55] ZAHUR, S., ROSULEK, M., AND EVANS, D. Two halves
make a whole - reducing data transfer in garbled circuits
using half gates. In EUROCRYPT (2015).

reconciliation without prior context. In ACM SIGCOMM
Computer Communication Review (2011).

[22] EVANS, W. E., AND RELLING, M. V. Moving towards

individualized medicine with pharmacogenomics. Nature
(2004).

[23] FEIGENBAUM, J., ISHAI, Y., MALKIN, T., NISSIM, K.,
STRAUSS, M. J., AND WRIGHT, R. N. Secure multiparty
computation of approximations. In Automata, Languages
and Programming. 2001.

[24] FEIGENBAUM, J., KANNAN, S., STRAUSS, M., AND

VISWANATHAN, M. An approximate l1-difference algorithm
for massive data streams. SIAM Journal of Computing
(2002).

[25] FLAJOLET, P., FUSY, É., GANDOUET, O., AND MEUNIER,

F. Hyperloglog: the analysis of a near-optimal cardinality
estimation algorithm. DMTCS Proceedings (2008).

[26] FREDERIKSEN, T. K., JAKOBSEN, T. P., NIELSEN, J. B.,

NORDHOLT, P. S., AND ORLANDI, C. MiniLEGO: Efﬁcient
secure two-party computation from general assumptions. In
EUROCRYPT (2013).

[27] GANGULY, S., AND CORMODE, G. On estimating

frequency moments of data streams. In Approximation,
Randomization, and Combinatorial Optimization.
Algorithms and Techniques. 2007.

[28] GOLDREICH, O., MICALI, S., AND WIGDERSON, A. How

to play any mental game or A completeness theorem for
protocols with honest majority. In STOC (1987).

[29] HEENEY, C., HAWKINS, N., DE VRIES, J., BODDINGTON,
P., AND KAYE, J. Assessing the privacy risks of data sharing
in genomics. Public health genomics (2011).

[30] HUANG, Y., EVANS, D., KATZ, J., AND MALKA, L. Faster

secure two-party computation using garbled circuits. In
USENIX Security Symposium (2011).

[31] HUANG, Y., KATZ, J., AND EVANS, D.

Quid-Pro-Quo-tocols: Strengthening semi-honest protocols
with dual execution. In IEEE S & P (2012).

[32] ISHAI, Y., KILIAN, J., NISSIM, K., AND PETRANK, E.

Extending oblivious transfers efﬁciently. In CRYPTO 2003.
[33] ISHAI, Y., PRABHAKARAN, M., AND SAHAI, A. Founding
cryptography on oblivious transfer - efﬁciently. In CRYPTO
(2008).

[34] JAIN, A. K., DUBES, R. C., ET AL. Algorithms for

clustering data. 1988.

[35] JARECKI, S., AND SHMATIKOV, V. Efﬁcient two-party

secure computation on committed inputs. In EUROCRYPT
(2007).

[36] KOLESNIKOV, V., AND SCHNEIDER, T. Improved garbled
circuit: Free XOR gates and applications. In ICALP (2008).

[37] LINDELL, Y., AND PINKAS, B. Privacy preserving data

mining. In CRYPTO (2000).

[38] LINDELL, Y., AND PINKAS, B. An efﬁcient protocol for
secure two-party computation in the presence of malicious
adversaries. In EUROCRYPT (2007).

[39] LINDELL, Y., AND PINKAS, B. A proof of security of Yao’s

protocol for two-party computation. Journal of Cryptology
(2009).

[40] LIU, C., HUANG, Y., SHI, E., KATZ, J., AND HICKS,

M. W. Automating efﬁcient RAM-model secure
computation. In IEEE S & P (2014).

502Next, we calculate the expectation and variance of d2
i .

E(cid:2)d2

i

(cid:3) = E

(cid:48)

(cid:48)

(s)

s∈∆

s∈∆

Yish

(cid:33)2(cid:35)
(cid:34)(cid:32)(cid:88)
(cid:35)
(cid:34)(cid:88)
(s)(cid:1)2
(cid:0)Yish
(s)(cid:1)2(cid:105)
(cid:104)(cid:0)Yish
(cid:88)
(cid:88)
(cid:3) E(cid:2)h
E(cid:2)Y 2
(s)2(cid:3)
(cid:88)
(cid:33)4(cid:35)

× 1 =

d
(cid:96)

1
(cid:96)

E

s∈∆

s∈∆

s∈∆

is

(cid:48)

(cid:48)

= E

=

=

=

E(cid:2)d4

i

(cid:3) = E

= E

= E

(cid:48)

s∈∆

s∈∆

Y 4
ish

(cid:34)(cid:32)(cid:88)
(cid:88)
(cid:34)(cid:88)
(cid:32)(cid:32)(cid:88)
(cid:32)(cid:18) d

s∈∆

s∈∆

+ 3 ·

h

(cid:48)

(cid:96)

+ 3

=

d
(cid:96)

(cid:48)

Yish

(s)

(s)4 + 3

(cid:88)

s1(cid:54)=s2

(cid:48)

h

(s1)2h

(cid:48)

(s2)2Y 2

is1 Y 2
is2



(s)4Y 4
is

(cid:33)2
(cid:33)

−(cid:88)
(cid:18) d

s∈∆

(cid:96)

= 3

(cid:33)(cid:35)

(cid:48)

(s)4Y 4
is

h

(cid:19)2 − 2

d
(cid:96)

(cid:48)

h

(s)2Y 2
is

(cid:19)2 − d

(cid:96)

Thus we have E[Di] = (cid:96)E[di] = d, Var [Di] = (cid:96)Var [di] =
(cid:96) . Applying Chebyshev’s and Chernoff’s

(cid:96)×(E[d2
inequalities similar to Appendix A ﬁnishes the rest of the proof.

i ]−E[di]2) ≤ 2d2

C. PROOF OF THEOREM 2

know E[Y ] = σ(cid:112)2/π, and Var [Y ] = σ2 (1 − 2/π).

PROOF. If a random variable X ∼ N (0, σ2) (where N (0, σ2)
denotes a normal distribution with expectation 0 and variance σ2),
then Y = |X| follows half normal distribution, and further we
In protocol 2, assuming dA − dB can be approximated by

d is Di =(cid:112)π/2|dA − dB|, because

N (0, d), the estimator for
E[Di] =

√
d, Var [Di] = (π2 − 2π)d/4 < d.

With similar argument in the proof of Theorem 0 using Cheby-
shev’s and Chernoff’s inequalities, we can show that for any  >
0, λ > 1,

√

(1 − )

Pr

√
d ≤ R ≤ (1 + )

√
d

(cid:111) ≥ 2

−λ.

(cid:110)

can be achieved with k = O(log(1/δ)), and (cid:96) = O(1/2). There-
fore, for any ε > 0, λ > 1, by selecting an ε such that (1 + )2 <

1 + ε we can ﬁnd k, (cid:96) to ensure P r(cid:8)|R2 − ε| ≤ εd(cid:9) ≥ 2−λ.

APPENDIX
A. PROOF OF THEOREM 0

PROOF. Note the Di’s (1 ≤ i ≤ (cid:96)) computed in step 1-(a)-
iii are independent identically distributed random variables and we

already show E[Di] = E(cid:2)(dA − dB)2(cid:3) = d. Further, we can
(cid:33)4(cid:35)

bound the variance of Di. Because

(cid:34)(cid:32) (cid:88)

h(s) − (cid:88)

E[D2

i ] = E[(dA−dB)4] = E

h(s)

.

s∈A−B

s∈B−A

Deﬁne h(cid:48)(s) to be h(s) for every s ∈ A − B, and −h(s) for every
s ∈ B−A. It is easy to verify that E[(h(cid:48)(s))2] = E[(h(cid:48)(s))4] = 1.
Thus, deﬁne ∆ = Diﬀ (A, B),

E[D2

i ] = E

= E

= E

(cid:33)4(cid:35)

(cid:48)

(s)

(s)4 + 3

(s)4

h

s∈∆

(cid:34)(cid:32)(cid:88)
(cid:88)
(cid:34)(cid:88)
(cid:32)(cid:32)(cid:88)

s∈∆

s∈∆

h

h

(cid:48)

(cid:48)



(cid:48)

h

(s1)2h

(cid:48)

(s2)2

(cid:88)

s1(cid:54)=s2

(cid:33)2

−(cid:88)

(cid:33)(cid:35)

(cid:48)

h

(s)4

+ 3

(cid:48)
h

(s)2

s∈∆

s∈∆
= d + 3 · (d2 − d) = 3d2 − 2d

i ] − E[Di]2 = 2d2 − 2d ≤ 2d2.
=

(cid:104) 1

(cid:80)(cid:96)

Therefore Var [Di] = E[D2
Beacause Di’s (1 ≤ i ≤ (cid:96)) are independent, we have E
E
l
2d2/l. Using Chebyshev’s inequality, we know that
√
3)2.

(cid:105)
(cid:40)(cid:12)(cid:12)(cid:12) ˆDi − d

= d, and that Var

(cid:80)l

≤ 1/(

(cid:104) 1

√
3

i=1 Di

= Var

P r

(cid:96)

i=1 Di

(cid:104) ˆDi

(cid:105)
(cid:105) ≤

(cid:104) ˆDi
(cid:105)
(cid:41)
(cid:111) ≤ 1

(cid:114)
(cid:12)(cid:12)(cid:12) ≥ εd

2d2

l

3

.

(cid:12)(cid:12)(cid:12) ≥
(cid:110)(cid:12)(cid:12)(cid:12) ˆDi − d

P r

By setting (cid:96) = 6/ε2, we obtain

Finally, note X = medianj∈[k]

ˆDj, where every ˆDj is bounded
as above. Hence, |X − d| ≥ εd happens if and only if for at least
half of j, | ˆDj − d| ≥ εd. Therefore, using a standard Chernoff
bound, by setting k = O(λ), we can get the desired bound.

B. PROOF OF THEOREM 1

dicator for event g(j) = i. We can rewrite dA[i] =(cid:80)
and that dB[i] =(cid:80)

PROOF. In the i-th iteration, let Yij be the random variable in-
s∈A Yish(s)
s∈B Yish(s). Deﬁne h(cid:48)(s) to be h(s) for every
s ∈ A−B, and −h(s) for every s ∈ B−A. Let di = dA[i]−dB[i]
(cid:88)
Yish(s) − (cid:88)
and deﬁne ∆ = Diﬀ (A, B). Therefore
(cid:88)
(cid:88)

s∈Diﬀ (A,B)

Yish(s)

s∈B−A

s∈A−B

di =

Yish

(s)

=

(cid:48)

(cid:48)

=

Yish

(s)

s∈∆

503