On Your Social Network De-anonymizablity:

Quantiﬁcation and Large Scale Evaluation with Seed

Knowledge

Shouling Ji(cid:3), Weiqing Li(cid:3), Neil Zhenqiang Gongy, Prateek Mittalz and Raheem Beyah(cid:3)

Email: {sji, wli64}@gatech.edu, rbeyah@ece.gatech.edu

(cid:3)Georgia Institute of Technology
yUniversity of California, Berkeley
Email: neilz.gong@berkeley.edu

zPrinceton University

Email: pmittal@princeton.edu

Abstract—In this paper, we conduct the ﬁrst comprehensive
quantiﬁcation on the perfect de-anonymizability and partial de-
anonymizability of real world social networks with seed in-
formation in general scenarios, where a social network can
follow an arbitrary distribution model. This quantiﬁcation pro-
vides the theoretical foundation for existing structure based
de-anonymization attacks (e.g., [1][2][3]) and closes the gap
between de-anonymization practice and theory. Besides that, our
quantiﬁcation can serve as a testing-stone for the effectiveness
of anonymization techniques, i.e., researchers can employ our
quantiﬁed structural conditions to evaluate the potential de-
anonymizability of the anonymized social networks. Based on
our quantiﬁcation, we conduct a large scale evaluation on the
de-anonymizability of 24 various real world social networks by
quantitatively showing: 1) the conditions for perfect and (1 (cid:0) ϵ)
de-anonymization of a social network, where ϵ speciﬁes the
tolerated de-anonymization error, and 2) the number of users of
a social network that can be successfully de-anonymized. Fur-
thermore, we show that, both theoretically and experimentally,
the overall structural information based de-anonymization attack
is much more powerful than the seed knowledge-only based de-
anonymization attack, and even without any seed information,
a social network can be perfectly or partially de-anonymized.
Finally, we discuss the implications of this work. Our ﬁndings
are expected to shed light on the future research in the structural
data anonymization and de-anonymization area, and to help data
owners evaluate their structural data vulnerability before data
sharing and publishing.

I.

INTRODUCTION

Fueled by the rapid advancements in information and
mobile computing technologies, social networks have become
deeply integrated in people’s lives. Further, social networks
produce a signiﬁcant amount of social data that contains their
users’ detailed personal
information. [2][3][19]. To protect

Permission to freely reproduce all or part of this paper for noncommercial
purposes is granted provided that copies bear this notice and the full citation
on the ﬁrst page. Reproduction for commercial purposes is strictly prohibited
without the prior written consent of the Internet Society, the ﬁrst-named author
(for reproduction of an entire paper only), and the author’s employer if the
paper was prepared within the scope of employment.
NDSS ’15, 8-11 February 2015, San Diego, CA, USA
Copyright 2015 Internet Society, ISBN 1-891562-38-X
http://dx.doi.org/10.14722/ndss.2015.23096

users’ privacy, data owners (e.g., companies, government, hos-
pitals) usually anonymize their data before it is shared, trans-
ferred, and/or published. Generally, the data anonymization
techniques can be characterized into three classes: naive ID re-
moval, k-anonymization (including randomly adding/deleting
edges) [11][12], and differential privacy [13][14]. The naive
ID removal method has been proven extremely vulnerable
to state-of-the-art structure based de-anonymization attacks
[2][3]. For k-anonymization, it also cannot be employed to
defend against structure based de-aonymization attacks for
real world social networks due to its limitations, e.g., it is
not scalable (an NP-hard problem [16]), richer information is
available to adversaries. Differential privacy (and its variants)
is initially designed to protect
the privacy of data in an
interactive query [13][14]. However, the structure based de-
anonymization attack is actually a non-interactive query from
the perspective of database interaction. Recent efforts have pro-
posed using differentially private graph models [15]. However,
the differential privacy parameter still has to be determined
before data sharing, which makes this method ineffective in
defending against structure based de-anonymization attacks
[2][3]. Furthermore,
the richer auxiliary information (e.g.,
seeds information) available to adversaries, which is difﬁcult
to control, makes the above anonymization technique more
vulnerable. Consequently, data anonymization is a challenging
and open problem (see more discussion in Section II).

Due to the vulnerability of existing anonymization
schemes, it has been experimentally demonstrated that the
the emerging structure based de-anonymization attacks can
break the privacy of social networks effectively based on-
ly on the data’s structural information, e.g., Narayanan and
Shmatikov’s de-anonymization attack [2], Srivatsa and Hicks’
de-anonymization attack [3]. Although the de-anonymizability
of social networks has been shown by experimental results
(heuristic algorithms) in [2][3], it is still important to under-
stand why social networks are vulnerable to structure based
de-anonymization attacks? how de-anonymizable a social net-
work is? and how many users within a social network can
be successfully de-anonymized? Currently, some preliminary
analysis was conducted on the de-anonymizability of social
networks under the the Erd¨os-R´enyi (ER) random graph model,
the preferential attachment model, or the conﬁguration model

[6][7][8][9]. On one hand, these existing works open the door
to research on quantifying the de-anonymizability of social
networks. On the other hand, all
the existing works have
several limitations, e.g., most do not consider seed information
or overlook other more powerful structural information (e.g.,
the structural information among non-seed users), they assume
an unrealistic network model (e.g., the ER model), and/or they
make unrealistic assumptions (e.g., having a regime of dense
seeds available). These limitations prevent existing analysis
from being applicable to real world social networks (see more
discussion in Section II).

Contributions: Aiming at addressing these open problems,
we study the de-anonymizability of social networks. Speciﬁ-
cally, our contributions can be summarized as follows.

(i) To the best of our knowledge, we conduct the ﬁrst
theoretical quantiﬁcation on the perfect and partial de-
anonymizability of social networks in general scenarios, where
the social network can follow an arbitrary network model.
Therefore, our quantiﬁcation can be applied to real world social
networks to evaluate their perfect or partial de-anonymizability,
i.e., our quantiﬁcation can quantitatively demonstrate the vul-
nerability of real world social networks to existing struc-
ture based de-anonymization attacks (e.g., [1][2][3]). More
importantly, our quantiﬁcation provides the theoretical foun-
dation for existing structure based de-anonymization attacks
(e.g., [1][2][3]), which closes the gap between practice and
theory. Besides that, since our quantiﬁcation speciﬁes the
structural conditions between an anonymized social network
and an auxiliary social network for perfect and partial de-
anonymizability, our quantiﬁcation can serve as a testing-
stone for the effectiveness of anonymization techniques, i.e.,
researchers can employ our quantiﬁed structural conditions to
evaluate the potential de-anonymizability of the anonymized
social networks.

(ii) Based on our quantiﬁcation, we implement

the
ﬁrst
large scale evaluation of the perfect and partial de-
anonymizability of 24 various real world social networks. In
our evaluation, we show the conditions of perfectly and par-
tially de-anonymizing a social network; how de-anonymizable
a social network is according to its topological properties;
and how many users of a social network can be successfully
de-anonymized. Our evaluation results demonstrate that most
social networks, if not all, can be perfectly or at least partially
de-anonymized depending on their structural properties.

(iii) Based on our results, we ﬁnd that compared to the
structural information associated with known seed users, the
other structural information (the structural information among
anonymized users) is also useful in improving structure based
de-anonymization attacks. We show that, both theoretically
and experimentally, the overall structural information based
de-anonymization is more powerful, and a social network
is perfectly or partially de-anonymizable even without any
seed information. As a result, this ﬁnding provides the foun-
dation of the implication that unlike existing seed based
de-anonymization techniques [1][2][3], one can design new
effective de-anonymization attacks without seed information.
(iv) We discuss the implications and future work of this
paper. Our quantiﬁcation and evaluation enable various s-
takeholders (e.g., researchers and practitioners) to understand

the theoretical foundation of structure based de-anonymization
attacks and their effectiveness in attacking various real world
social networks (in other words, the vulnerability of real world
social networks). Therefore, our work can shed light on the
future research of the structural data anonymization and de-
anonymization area, and encourage data owners to develop
better privacy protection policies.

II. RELATED WORK

Due to space limitations, we only discuss the most closely
related work. Readers can ﬁnd more related work on de-
anonymization in [2][3], on de-anonymization quantiﬁcation
in [7][8][9], on anonymization techniques in [11][12], and on
privacy preservation schemes in [13][14].

A. Anonymization

To protect users’ privacy, several anonymization techniques
have been developed which can be placed into three classes:
naive ID removal, k-anonymization [11][12], and differen-
tial privacy [13][14]. The naive ID removal scheme has
proven to be vulnerable to structure based de-anonymization
attacks [1][2][3]. However, naive ID removal
the
most widely used method to anonymize data for publish-
ing/sharing/transferring [2][3]. This is probably because of two
reasons. First, it is the simplest manner to “anonymize” data
and it is scalable so it can be applied to large scale datasets
in a straightforward manner. Second, the lack of education on
the vulnerability of this method leads data owners to choose
this anonymization scheme.

is still

k-anonymization is a sophisticated anonymization tech-
nique, under which each user cannot be distinguished with at
least k−1 other individuals with respect to their local structure
[11][12]. However, several limitations make k-anonymization
fail to defend against the newly designed structure based de-
anonymization attacks (e.g., [2][3]). First, k-aonymization is
not computationally scalable, which implies it cannot be ex-
tended to large scale social networks. Second, k-anonymization
relies on data’s syntactic property. Even if the k-anonymity
is satisﬁed, it is still inefﬁcient against the state-of-the-art
de-anonymization attacks, which are based only on structural
information [2]. Finally, the adversary may have much richer
information than assumed in the k-anonymization. For in-
stance, the known seed information together with the data’s
structure are sufﬁcient to perfectly or at least partially de-
anonymize a social network according to our quantiﬁcation.

Differential privacy (and its variants) aims to provide
means to maximize the accuracy of queries from statistical
databases while minimizing the possibility of leaking privacy
[13][14], i.e., differential privacy is designed to protect data’s
privacy in interactive queries [13][14]. However, the structure
based de-anonymization attacks we studied in this paper are
non-interactive queries from the perspective of databases.
There has also been proposed techniques to share graphs
using differentially private graph models [15]. However, the
differential privacy parameter still has to be determined before
data sharing, which makes this method ineffective in defending
against structure based de-anonymization attacks [2][3].

2

B. Structure based De-anonymization

Structure based de-anonymization was introduced in [1],
where Backstrom et al. introduced both active attacks and
passive attacks to de-anonymize social data. For the active
attack, the adversary should create a number of “sybil” nodes
and build relationships between sybil nodes and target nodes
before data release. Several reasons limit the practicality of
active attacks. A direct limitation is that the active attack
is not scalable and difﬁcult to control because the amount
of social data continues to increase [23]. Furthermore, sybil
defense schemes [24] make this attack even more difﬁcult.
On the other hand, in real world social networks, target nodes
have no reason to respond to the connection requests from
strange sybil nodes. For the passive attack in [1], the adversary
can breach the privacy of users with whom they are linked,
which is again suitable for small social networks and difﬁcult
to extend to large scale social datasets. In [2], Narayanan
and Shmatikov extended the de-anonymization attack to large-
scale directed social networks,
the social data carries
direction information which can be used as auxiliary knowl-
edge. They designed a de-anonymization algorithm with two
phases: seed identiﬁcation and propagation. In [3], Srivatsa and
Hicks presented the ﬁrst de-anonymization attack on mobility
traces while using social networks as a side-channel. However,
scalability is a signiﬁcant limitation of the algorithms in [3]. In
[4], Ji et al. designed an Adaptive De-Anonymization (ADA)
framework for the scenario that the anonymized and auxiliary
graphs have partial overlap. ADA also consists of a seed iden-
tiﬁcation phase and a propagation phase. Recently, Nilizade-
h et al. proposed a community-enhanced de-anonymization
scheme of social networks [5]. Under this scheme, community-
level de-anonymization is ﬁrst conducted. Subsequently, the
obtained information is employed to enhance the user-level
de-anonymization.

i.e.,

In summary, all

are heuristic. None of

the mentioned de-anonymization al-
gorithms
them study the de-
anonymizability of structural data (including social networks,
mobility traces, etc.) quantitatively or theoretically. This moti-
vates us to quantify the perfect and partial de-anonymizability
of social networks, which closes the gap between existing
structure based de-anonymization practice and its theoretical
foundation.

There are also other kinds of de-anonymization attacks
on social networks. For example, in [10], Wondracek et al.
designed a de-anonymization attack on social networks based
on the group membership information. To implement
this
attack, the adversary should collect necessary group member-
ship information (which is semantic information) by “history
stealing” on browsers.

C. Quantiﬁcation of Social Network De-anonymizablity

Recently, the problem of understanding why social net-
works can be de-anonymized based on structural information
has garnered a lot of attention [6][7][8][9]. In [6], Pedarsani
and Grossglauser studied the de-anonymizability of social
networks under the ER random graph model. When using an
ER model to describe social networks, the primary limitation is
that the degree distribution of social networks should follow
the Poisson distribution. However, the degree distribution of

3

it

real world social networks may follow any distribution (e.g.,
power-law distribution) [19]. Furthermore,
is seldom to
see, if not impossible to see, the degree distribution of any
social network following the Poisson distribution [19]. For
example, none of the 24 real world social networks considered
in this paper follow the Poisson distribution. Consequently,
the quantiﬁcation under the ER model
is mathematically
meaningful, however, cannot be applied to real world social
networks. Nevertheless, the ER model is a nice mathematical
tool to simplify the theoretical quantiﬁcation, and thus the
quantiﬁcation under the ER model can shed light on the
quantiﬁcation in general scenarios. Another drawback of [6]
is that it did not consider seed information.

In [7], Ji et al. studied the de-anonymizability of social
networks under the conﬁguration model. They also proposed
a practical optimization-based de-anonymization algorithm.
However, in their quantiﬁcation and analysis, seed information
is not considered. In addition, compared to the employed
conﬁguration model, our results are more general since we
do not make assumption on the data distribution. Finally, the
quantiﬁcation in [7] can be viewed as a special case of our
results in Section V (the Λ = 0 case). Therefore, our results
in this paper are more general and practical.

In [8], Yartseva and Grossglauser studied the performance
of percolation graph matching, which is a correlated problem
of the de-anonymizablity of social networks. However, the
analysis derived in [8] also has some limitations. First, the
analysis in [8] is based on the ER model, which makes it
impractical. Second, the analysis in [8] only considers seed
information. According to our quantiﬁcation and evaluation,
we found that the other structural information (i.e., the struc-
tural information among anonymized users) is more powerful
in improving the performance of de-anonymization attacks. We
also demonstrate in this paper that a social network can be
perfectly or partially de-anonymized even without any seed
information. Third, the analysis in [8] only considers users
with degree no less than 4. However, many real world social
networks may have a large amount of users with degree less
than 4, e.g., from our statistics in Section VI, 17.1% Google+
users, 40.03% LiveJournal users, and 77.33% YouTube users
have degree less than 4.

In [9], Korula and Lattanzi studied the reconciliation
problem for social networks, which is another correlated
problem of the de-anonymizability of social networks (the
reconciliation-ability of social networks is equivalent to their
de-anonymizability). The analysis in [9] is conducted under
the ER model and the Preferential Attachment model. Again,
in [9], only seed information is considered in quantifying
the de-anonymizability of social networks. As we pointed
out before, in this paper, we ﬁnd that the other structural
information is more powerful in a de-anonymization attack,
i.e., even without any seed knowledge, social networks can
be perfectly or partially de-anonymized only based on the
structural information. Another important limitation is that the
quantiﬁcation in [9] is valid under the assumption of having a
regime of dense seeds available. However, this assumption is
usually not true for large scale real world social networks.

In summary, the following aspects distinguish our work
from existing works. First, for the ﬁrst time, we quantiﬁed
the perfect and partial de-anonymizability of social networks

with seed information consideration under an arbitrary model.
Second, compared to seed information, we ﬁnd that the other
structural information is more powerful in de-anonymization
attacks. We demonstrate that, both theoretically and experi-
mentally, even without any seed information, most real world
social networks can also be de-anonymized perfectly or par-
tially only based on the structural
information. Third, we
conduct the ﬁrst large scale evaluation on the perfect and
partial de-anonymizability of 24 various real world social
networks. We quantitatively demonstrate the conditions on de-
anonymizing real world social networks and how many users
can be successfully de-anonymized.

III. SYSTEM MODEL, ASSUMPTION, AND DEFINITION
In this paper, given some seed knowledge, we quantify the
de-anonymizability of social networks based on their structural
information. It is natural to model social networks as graphs
where nodes represent users and edges represent social ties
(friends, contacts, etc.) among the users [1]-[9].

i,j

i,j

Data Model. In our quantiﬁcation and evaluation, we
employ the same graph model as in [1]-[9] to represen-
t social graphs. Speciﬁcally,
the anonymized social net-
work is modeled by graph Ga = (V a, Ea), where V a =
{i|i is an anonymized user} and Ea = {ea
|i, j ∈ V a, a
social tie exists between i and j}. To de-anonymize Ga, we
use an auxiliary social network which has overlap users with
Ga and can be obtained through multiple manners, e.g., data
aggregation, data mining, collaborative information systems,
knowledge/data brokers, etc. [1]-[9][17][18]. The auxiliary
social network is also modeled by a graph Gu = (V u, Eu),
where V u = {i|i is a known user} and Eu = {eu
|i, j ∈ V u,
an social tie exists between i and j}. To conduct the theoret-
ical quantiﬁcation without involving too much mathematical
details, we assume both Ga and Gu are undirected graphs.
Nevertheless, our quantiﬁcation can be extended to directed
graphs with some straightforward technical modiﬁcation. Fur-
thermore, since our quantiﬁcation and evaluation are based on
the graph model, our work can be potentially applied to other
kinds of data which can be modeled by graphs.
i = {j|j ∈
V a ∧ ∃ea
| as the degree
i = |N a
of i. Similarly, for j ∈ V u, we can deﬁne its neighborhood
j and degree du
j .
N u
Graph Sampling. To make the quantiﬁcation mathemati-
cally tractable, we employ the same assumptions on Ga and
Gu in [6]-[9]. First, V a = V u = {1, 2,··· , n} [6]-[9]. If
V a ̸= V u, we can simply satisfy this assumption by adding
the users in V u \ V a to V a and adding the users in V a \ V u
to V u without changing Ea or Eu. Note that this is only a
mathematical assumption without limiting the generality of this
work. Our quantiﬁcation is also valid in the case V a ̸= V u.
Second, based on the ﬁrst assumption, we assume that Ga
and Gu are two sampling versions of an underlying conceptual
graph G = (V, E) in the physical world, where V = V a = V u
and E is the set of the true relationships among users in V
[6][8][9]. Particularly, we assume Ga is sampled from G by
independently and identically sampling each edge in E with
probability sa, i.e., for ∀ei,j ∈ E, Pr(ei,j ∈ Ea|ei,j ∈ E).
Similarly, Gu is another sampled version of G with probability

Given i ∈ V a, its neighborhood is deﬁned as N a

∈ Ea}. Then, we deﬁne da

i,j

i

4

su. This assumption is also reasonable since people usually
involve in multiple social networks and Ga and Gu are some
particular social networks of users in V . For instance, Ga could
be LinkedIn (a professional social network of V ) while Gu is
Facebook (a friendship social network of V ).

De-anonymization. Based on our data model, a de-
anonymization scheme can be formally deﬁned as a mapping:
σ : Ga → Gu. Under σ, ∀i ∈ V a, its mapping is σ(i) ∈ V u.
Since V a = V u, for simplicity, we deﬁne a successful de-
anonymization of i ∈ V a is achieved under σ if i = σ(i). In
addition, we use σ0 to denote the perfect de-anonymization,
i.e., σ0 = {(i, i)|i = 1, 2,··· , n}, and σk to denote any de-
anonymization scheme with k incorrect mappings, i.e., k users
are incorrectly de-anonymized under σk. Evidently, k ∈ [2, n].
Most existing de-anonymization algorithms (e.g., [1][2][3])
consist of two phases: seed identiﬁcation phase which identi-
ﬁes some seed mapping information from V a to V u and map-
ping propagation phase which propagates the seed mapping
information to de-anonymize the rest of the anonymized users.
In this paper, we focus on quantifying the de-anonymizability
of social networks with seed knowledge. Therefore, as in
[1][2][3], we assume we have identiﬁed a seed mapping
set from V a to V u by some technique (e.g., the methods
in [1][2][3]), denoted by S = {(i, σ(i))|i ∈ V a, σ(i) ∈
V u, i = σ(i)}. Furthermore, we deﬁne Λ = |S| as the
number of seed mappings. For convenience, we denote the
seed users in V a and V u as S a = {i|(i, σ(i)) ∈ S} and
S u = {i|(σ
−1(i), i) ∈ S}, respectively. Then, our problem
now is to quantify the de-anonymizability of a social network
Ga given S, Gu, and the existing of G, sa, and su.

To make the quantiﬁcation easy to follow, we further as-
sume sa = su = s. Note that, this assumption does not change
our analysis in any material detail. All our quantiﬁcation results
can be extended to the case sa ̸= su only with more complex
expressions.

| + |σ

−1(Eu

j

i

i,j

i,v

−1(Eu

i (A)} (σ(eu

i,v

i (A ⊆ V a) = {ea

∈ Ea, we deﬁne σ(ea
|v ∈ N a
∈ Ea
i,j), Eu

Measuring σ. Given Ga, Gu, and a de-anonymization
scheme σ, we measure σ by the edge difference between Ga
and Gu under σ. First, ∀ea
i,j) =
∩A},
σ(i),σ(j). Furthermore, let Ea
eu
i,v)|ea
i (A)) = {σ(ea
i
and σ(Ea
i (A),
i (A)) are deﬁned in the same way). Speciﬁcally, let
and σ
j (V u) for convenience. Then, we
i (V a) and Eu
Ea
j = Eu
i = Ea
can deﬁne the edge difference induced by mapping (i, σ(i) =
|, i.e.,
j) ∈ σ as ∆σ:(i,j) = |σ(Ea
i ) \ Eu
∆σ:(i,j) measures the edge difference of users i and j under
σ. Based on ∆σ:(i,j), we measure σ by ∆σ =
∆σ:(i,j),
which indicates the edge difference between Ga and Gu under
σ. Intuitively, since Ga and Gu are strongly correlated (highly
≤ ∆σk for k ∈ [2, n] (we
similar), it is expected that ∆σ0
demonstrate this conclusion in Sections IV and V).
Similar as ∆σ:(i,j) and ∆σ, we deﬁne ∆σ:(i,j)(S) which
measures the the edge difference of a mapping (i, j) with
j (S u)| +
respect
i (S a)|, and ∆σ(S) which measures the edge
|σ
−1(Eu
difference of a de-anonymization scheme σ with respect to S:
∆σ(S) =
∆σ:(i,j)(S).

to S: ∆σ:(i,j)(S) = |σ(Ea
∑
j (S u))\Ea

∑
j ) \ Ea

i (S a)) \ Eu

(i,j)∈σ

(i,j)∈σ

IV. QUANTIFICATION UNDER THE ERD ¨OS-R ´ENYI MODEL
In this section, we quantify the de-anonymizability of Ga
under the ER model, i.e., we assume G(V, E) is a random
graph G(n, p), where n is the number of nodes and p speciﬁes
the probability of an edge existing between two nodes. Al-
though real world social networks rarely satisfy the ER model
[19], the analysis in this section can shed the light on the
quantiﬁcation in general scenarios (Section V).
A. S based Quantiﬁcation
As a warm up, we ﬁrst quantify the de-anonymizability
of Ga only based on the seed information S. For the de-
anonymization scheme σ, we assume σ de-anonymizes each
user i ∈ V a \ S a to some user σ(i) ∈ V u \ S u such that
(i, σ(i)) induces the least ∆σ:(i,σ(i))(S) 1.
We introduce a useful lemma as follows.

Lemma 1. [6] Let X and Y be two binomial random variables
with means λX and λY , respectively. Then, when λX > λY ,
Pr(X − Y ≤ 0) ≤ 2 exp(− (λX−λY )2
8(λX +λY ) ).

Now, we are ready to quantify the de-anonymizability of
Ga as shown in Theorem 1. We omit the proof of Theorem 1
due to the space limitation.
(i.e., Λ ≥
Theorem 1.
If
1
4
4(2 ln n+1)(2−s−ps)
), then it is asymptotically almost surely
ps3(1−p)2
(a.a.s.)2 that ∀i ∈ V a \ S a, i is perfectly de-anonymizable
under any given de-anonymization scheme σ.

· ps3(1−p)2
2−s−ps

≥ 2 ln n+1

(cid:3)

In Theorem 1, we quantify the condition on p, s, and S
for perfectly de-anonymizing any user in V a \ S a. Now, we
quantify the condition requirement for a stronger conclusion in
Theorem 2, which indicates the condition on p, s, and S such
that all the users in V a \ S a are perfectly de-anonymizable.
We omit the proof of Theorem 2 due to the space limitation.
(i.e., Λ ≥
· ps3(1−p)2
Theorem 2. If 1
2−s−ps
4
4(2 ln n+ln(2(n−(cid:3))))(2−s−ps)
), it is a.a.s. that all the users in
ps3(1−p)2
V a \ S a are perfectly de-anonymizable.

≥ 2 ln n+ln(2(n−(cid:3)))

(cid:3)

B. Sophisticated Quantiﬁcation: Considering more Structural
Information

i /Eu

i (S)/Eu

In the previous

subsection, we quantiﬁed the de-
anonymizablity of Ga based only on the seed knowledge.
i (S), all the edges
Actually, besides the edges in Ea
in Ea
i can provide structural information which can be
used for de-anonymization. In this subsection, we consider
to quantify the de-anonymizability of Ga based on all the
adjacent edges of i ∈ V a, i.e., we consider both the structural
information carried by seed mappings in S and the overall
topological information of Ga and Gu. First, we quantify

the structural conditions on Ga and Gu for perfect de-
anonymization in Theorem 3. Theorem 3 has two parts. The
ﬁrst part shows the condition such that ∆σ0 < ∆σk for any
given σk. The second part demonstrates the condition for a
much stronger conclusion such that σ0 is the one and the only
one inducing the least edge difference. Basically, the ﬁrst part
of Theorem 3 can be proven using a similar technique as in
[6]. Here, we obtain a tighter bound by applying more elegant
quantiﬁcation techniques. We omit the proof of Theorem 3 due
to the space limitation.
Theorem 3. (i) If 1
k(n−k/2−1) , it is a.a.s. that
∆σ0 < ∆σk (k ∈ [2, n]), i.e., it is a.a.s. that the perfect
4
de-anonymization scheme σ0 induces less edge difference
than any given de-anonymization scheme σk ̸= σ0; (ii) If
ps3(1−p)2
the
1
2−s−ps
4
perfect de-anonymization scheme σ0 induces the least edge
difference than all the other de-anonymization schemes, i.e.,
it is a.a.s. that σ0 is the only scheme inducing the least edge
difference.

≥ (k+2) ln n+ln(2(n−(cid:3)−1))

≥ 2 ln n+1

ps3(1−p)2
2−s−ps

k(n−k/2−1)

is a.a.s.

that

it

,

Theorem 3 has a strong implication: even without any
seed information, it still possible to perfectly de-anonymize
a large scale social network. We summarize this implication
in Corollary 1.
Corollary 1. If 1
, it is a.a.s.
4
that the perfect de-anonymization scheme σ0 induces the least
edge difference than all the other de-anonymization schemes,
i.e., it is a.a.s. that σ0 is the only scheme inducing the least
edge difference.

≥ (k+2) ln n+ln(2(n−1))

ps3(1−p)2
2−s−ps

k(n−k/2−1)

Based on Theorems 2, 3 and Corollary 1, it is straightfor-
ward to obtain a more accurate (tighter) bound on the structure
condition of Ga and Gu for perfect de-anonymization as shown
in Theorem 4.
≥
Theorem
If
min{ 2 ln n+ln(2(n−(cid:3)))
, (k+2) ln n+ln(2(n−(cid:3)−1))
where
Λ ∈ [0, n], Ga is perfectly de-anonymizable.

1
4
k(n−k/2−1)

ps3(1−p)2
2−s−ps
},

4.

·

(cid:3)

C. Quantiﬁcation with Error Toleration
Now, we study the structural condition on Ga and Gu given
S such that some de-anonymization error is tolerated. Let ϵ ∈
[0, 1 − (cid:3)
n ] be some constant value. We deﬁne Ga is (1 − ϵ)-
de-anonymizable if at least (1 − ϵ)n users in Ga are perfectly
de-anonymizable. Then, we specify the condition such that Ga
is (1 − ϵ)-deanonymizable with or without seed information
in Theorem 5, i.e., the condition that at most ϵn incorrect de-
anonymizations are allowable. We defer the proof to Appendix
for readability.
ps3(1−p)2
Theorem
If
2−s−ps
min{ 2 ln n+ln(2(n−ϵn−(cid:3)))
, (k+2) ln n+ln(2(n−ϵn−(cid:3)))
Λ ∈ [0, n], then Ga is (1 − ϵ)-de-anonymizable.

≥
where

k(n−k/2−1)

},

5.

1
4

·

(cid:3)

1Since our focus is on quantifying the de-anonymizability of Ga, we do not
consider the actual de-anonymization algorithms. Speciﬁcally, we are aiming
at providing the theoretical foundation on the workability of structure based
de-anonymization attacks, e.g., [1][2][3].
probability goes to 1 as n ! 1.

2Asymptotically almost surely (a.a.s.) implies that an event happens with

V. QUANTIFICATION IN GENERAL SCENARIOS

Although the ER model is suitable to enable elegant theo-
retical analysis on the de-anonymizability of social networks,
the fact is that it is extremely rare, if not impossible, to see

5

real world social networks actually follow the ER model [19].
Nevertheless, the analysis under the ER model can shed light
on the theoretical quantiﬁcation of the de-anonymizability of
social networks in general scenarios.

In this section, we quantify the de-anonymizability of Ga
in general scenarios, i.e., unlike in Section IV, we assume
G(V, E) now could be some graph following an arbitrary
network model. To accelerate the quantiﬁcation, we make
some deﬁnitions as follows. Given a graph G(V, E) with
|V | = n and |E| = m,
its graph density is deﬁned as
n(n−1). Let U ⊆ V . The subgraph of G on U is deﬁned
ρ = 2m
as G[U ] = G(U, EU = {ei,j ∈ E|i, j ∈ U}). Furthermore, let
nU = |U| and mU = |EU|. Then, the subgraph density of G on
U is ρU = 2mU
nU (nU−1). Let U and W be two disjoint subsets of
V (U ∩ W = ∅), EU,W = {ei,j ∈ E|i ∈ U, j ∈ W} be the set
of edges connecting U and W , and mU,W = |EU,W|. Then, the
connectivity between U and W is deﬁned as γU,W = mU;W
.
nU·nW
Finally, for the seed mapping set S, we assume it is randomly
identiﬁed. Then, a user in V is selected with probability q = (cid:3)
n .
i.e., S = S a = S u.
We denote seed users as a set S,
Furthermore, let set A = V \ S.
A. S based Quantiﬁcation
In this subsection, we quantify the de-anonymizability of a
social network given a seed mapping set S. First, we show the
condition for perfectly de-anonymizing an anonymized user in
Theorem 6. We defer the proof to Appendix for readability.
Theorem 6. If 1
4
and γS,A = mS;A
de-anonymizable.

, where q = Λ/n
(cid:3)(n−(cid:3)) , it is a.a.s. that ∀i ∈ A, i is perfectly

· qs3(1−γS;A)2
2−s−sγS;A

≥ 2 ln n+1

di

We further quantify the condition to perfectly de-

anonymize all the users in A in Theorem 7.
Theorem 7. If 1
4
Λ/n and γS,A = mS;A
anonymizable.

· qs3(1−γS;A)2
, where q =
2−s−sγS;A
(cid:3)(n−(cid:3)) , it is a.a.s. that Ga is perfectly de-

≥ 2 ln n+ln(2(n−(cid:3)))

di

a.a.s. that the perfect de-anonymization scheme σ0 is the only
scheme inducing the least edge difference, i.e., Ga is perfectly
de-anonymizable.

Similar as Theorem 3, Theorem 8 also implies a large
scale social network is perfectly de-anonymizable without seed
information in general scenarios. We summarize the condition
in Corollary 2.

≥
2.
Corollary
If
(k+2) ln n+ln(2(n−1))
the perfect de-
−k/2 ,
mV0 ;Vk +mVk
anonymization scheme σ0 is the only scheme inducing the
least edge difference, i.e., Ga is perfectly de-anonymizable.

})2
s3(1−max{γV0 ;Vk ,ρVk
2−s−s·max{γV0 ;Vk ,ρVk
}

·
is a.a.s.

that

it

1
4

Based on Theorems 7, 8 and Corollary 2, it is straightfor-

ward to have the following conclusion.
· qs3(1−γS;A)2
Theorem 9. If 1
2−s−sγS;A
4
s3(1−max{γV0 ;Vk ,ρVk
})2
} ≥ (k+2) ln n+ln(2(n−(cid:3)−1))
2−s−s·max{γV0 ;Vk ,ρVk
[0, n], it is a.a.s. that Ga is perfectly de-anonymizable.

≥ 2 ln n+ln(2(n−(cid:3)))

di
−k/2

mV0;Vk +mVk

·
or 1
4
, where Λ ∈

C. Quantiﬁcation with Error Toleration
Now, we quantify the (1 − ϵ)-de-anonymizability of social
networks in general scenarios, where now ϵn (ϵ ∈ [0, 1 −
n ]) users are allowed to be incorrectly de-anonymized. We
(cid:3)
demonstrate the quantiﬁcation in Theorem 10. We defer the
proof to Appendix for readability.
Theorem 10. If (i) 1
4
or (ii) 1
where Λ ∈ [0, n], Ga is (1 − ϵ)-de-anonymizable.
4

≥ 2 ln n+ln(2(n−ϵn−(cid:3)))
})2
· s3(1−max{γV0 ;Vk ,ρVk
} ≥ (k+2) ln n+ln(2(n−ϵn−(cid:3)))
,
2−s−s·max{γV0 ;Vk ,ρVk

· qs3(1−γS;A)2
2−s−sγS;A

mV0 ;Vk +mVk

−k/2

di

VI. LARGE SCALE EVALUATION

In this section, we conduct a large scale evaluation on the
de-anonymizability of 24 real world datasets based on our
quantiﬁcation. Our evaluation consists of two parts: evaluation
of perfect de-anonymizability and evaluation of (1 − ϵ)-de-
anonymizability.

B. Sophisticated Quantiﬁcation: Considering more Structural
Information

A. Datasets and Setup

In the previous subsection, the perfect de-anonymizability
of social networks is quantiﬁed in general scenarios based
on S. As we discussed in Section IV, for i ∈ A, besides
the structural
the structural connection to the users in S,
information between i and other users in A is also helpful
to improve the de-anonymization performance (as shown in
Theorem 3). Similar to the quantiﬁcation under the ER model,
we quantify the de-anonymizability of social networks by
considering the overall structural information in Theorem 8.
We defer the proof to Appendix for readability.

(i)

2 ln n+1
mV0 ;Vk +mVk

})2
s3(1−max{γV0;Vk ,ρVk
2−s−s·max{γV0 ;Vk ,ρVk
}
<

≥
Theorem 8.
−k/2 ,
∆σk
(k ∈ [2, n]),
the perfect de-
that
anonymization scheme σ0
less edge difference
than any given de-anonymization scheme σk ̸= σ0; (ii) If
})2
· s3(1−max{γV0 ;Vk ,ρVk
} ≥ (k+2) ln n+ln(2(n−(cid:3)−1))
is
2−s−s·max{γV0 ;Vk ,ρVk

·
a.a.s.
is a.a.s.
induces

that ∆σ0

mV0;Vk +mVk

it
i.e.,

−k/2

is
it

If

1
4

1
4

In the evaluation, we employ 24 various real world social
datasets that mainly come from the Stanford Large Network
Dataset Collection [20], ASU Social Computing Data Repos-
itory [21], and other sources [22][23]. The employed datasets
are shown in Table I with preliminary statistics, where n is
the number of users (nodes), m is the number of edges among
users, ρ is the graph density, d is the average degree of the
users, and p(k) (k = 1, 5) is the percentage of users with
degree less than or equal to k. We further brieﬂy introduce the
datasets as follows.

Hyves [21] is the most popular social network in the
Netherlands. Douban [21] is a Chinese Web 2.0 site that
provides user review and recommendation services for movies,
books, and music. Friendster [21] is a social gaming site
and was a social networking service website before being
redesigned. YouTube [21] is a well known video sharing
website on which users can upload, share, and view videos.

6

,

it

TABLE I.

DATASET STATISTICS.

n

m

ρ

d

p(1)

p(5)

327,162

45,813
196,591
639,014
33,696

1,402,673 2,777,419 2.82E-06 3.96 56.76% 88.74%
154,908
2.73E-05 4.22 66.57% 90.81%
5,689,498 14,067,887 8.69E-07 4.95 60.19% 91.27%
1,138,499 2,990,443 4.61E-06 5.25 53.16% 85.53%
2,523,386 7,918,801 2.49E-06 6.28 59.49% 87.26%
1,191,812 4,519,340 6.36E-06 7.58 47.27% 81.62%
1.75E-04 8.01 24.18% 60.91%
183,412
950,327
4.92E-05 9.70 25.20% 64.50%
3,214,986 1.57E-05 10.06 51.10% 79.11%
180,811
3.19E-04 10.73 28.09% 67.86%
1,694,616 11,094,209 7.73E-06 13.09 12.80% 55.41%
1.73E-04 14.18 2.19% 64.78%
582,533
82,168
771,229
5,907,413 1.99E-05 15.32 45.64% 77.31%
4,843,953 43,362,750 3.70E-06 17.90 20.99% 50.53%
1.87E-03 21.00 9.95% 49.99%
1.23E-03 22.01 5.34% 33.69%
4.02E-04 25.64 12.71% 36.11%
1,632,803 22,301,964 1.67E-05 27.32 10.04% 30.66%
1,668,647 3.48E-04 34.10 28.24% 59.59%
4,692,671 90,751,480 8.24E-06 38.68 5.44% 27.33%
2,193,083 4.05E-04 42.13 6.56% 27.56%
104,103
456,293
12,508,272 1.20E-04 54.83 5.30% 19.76%
3,072,441 117,185,083 2.48E-05 76.28 2.21% 7.28%
5,899,882 1.82E-03 146.56 0.00% 11.63%

117,649
197,031
817,090

11,204
17,903
63,731

97,884

80,513

Name
Hyves
Douban
Friendster
YouTube
Flixster
Last.fm

FB-NO-wall

Gowalla
Foursquare

Enron
Skitter
Slashdot

Digg

LiveJournal

HepPh
AstroPh

FB-NO-links

Pokec

BlogCatalog

Google+
Livemocha

Twitter
Orkut
Flickr

Flixster [21] is a social movie site allowing users to share
movie ratings, discover new movies and meet others with
similar tastes in movies. Last.fm [21] is a music discovery
service that gives a user personalized recommendations based
on the music that user listens to. Facebook-New Orleans-
links (FB-NO-links) and Facebook-New Orleans-wall (FB-
NO-wall) [22]: Facebook is one of the most popular social
networks, which connects people with friends and others who
work, study, and live around them. The employed FB-NO-
links dataset is a Facebook friendship network at the New
Orleans area and the FB-NO-wall is a Facebook interaction
(wall posts) network at the New Orleans area. Gowalla [20]
is a location-based social networking website where users
share their locations by checking-in. Foursquare [21] helps
people to ﬁnd the places to go with friends and discover food,
nightlife, and entertainment for users. Enron [20] is an email
communication dataset released by Federal Energy Regulatory
Commission during its investigation. Skitter [20] is an Internet
topology graph of Autonomous Systems. Slashdot [20] is a
technology-related news website known for its speciﬁc user
community. Digg [21] is a news aggregator with an editorially
driven front page, aiming to select stories speciﬁcally for the
Internet audience. LiveJournal [20] is social network for jour-
nals and blogs. HepPh [20] is a citation graph of the papers
posted on arXiv in the high-energy physics area. AstroPh [20]
is a collaboration network of the authors of papers posted on
arXiv in the astro physics area. Pokec [20] is the most popular
on-line social network in Slovakia. BlogCatalog is a social
blog directory which manages the bloggers and their blogs.
Google+ [23] is one of the most popular social networking and
identity services. Livemocha [21] is the world’s largest online
language learning community, offering free and paid online
language courses in 35 languages. Twitter [21] is an online
social networking and microblogging service. Orkut [21] is
an on-line social network where users form friendship with
each other. Flickr [21] is an image hosting and video hosting
website.

7

For each employed dataset, we use the raw data except
for removing isolated users (most datasets do not contain any
isolated users). Note that, our quantiﬁcation is not limited
to connected graphs. It
is also applicable to disconnected
social networks. Furthermore, we do not consider the direction
information even if a dataset is a directed network. Again,
this assumption does not limit the evaluation or quantiﬁcation.
Since the direction information can be used to improve the
effectiveness of de-anonymization attacks [2], it is possible that
our quantiﬁcation and evaluation can be improved if we have
more knowledge, e.g., the direction information. One of the
future works is to quantify the de-anonymizability of directed
social networks.

In our quantiﬁcation, the seed mappings are chosen ran-
domly, i.e., the high-degree users are not given preference
as in [8][9] although they may be more helpful as seed
mappings. Consequently, our evaluation results represent the
general results of our quantiﬁcation. Nevertheless, our evalua-
tion demonstrate that most, if not all, of the social datasets are
partially or perfectly de-anonymizable based on their structural
information. We quantitatively show how many users can be
successfully de-anonymized in each social network (i.e., 1− ϵ)
in our evaluation.

We quantify the de-anonymizability of a social network
using seed information and using the overall structural in-
formation, respectively. Therefore, we use sufﬁxes “-S” and
“-A” to distinguish these two scenarios (e.g., Twiiter-A and
Twitter-S), where “-S” and “-A” imply using seed information
and overall structural information, respectively. If we do not
specify the sufﬁx or the particular context, it implies using
the overall structural information by default. Furthermore, due
to the space limitation, we do not show all the experimental
results.

B. Evaluation of Perfect De-anonymizability

In this section, we evaluate the condition for perfect de-

anonymizability of the datasets in Table I.

1) Evaluation on Λ: Based on our quantiﬁcation, we
evaluate the requirements on the size of seed mappings Λ and
the sampling rate s for the perfect de-anonymizability of each
dataset in Fig.1. Since all the datasets have different sizes, for
convenience, we show Θ(Λ/n) instead of Λ directly.
From Fig.1, we have the following observations.
(i) If the overall structural

information is considered,
each dataset is asymptotically perfectly de-anonymizable3 even
without any seed information when s is above some threshold
value, which is consistent with our theoretical quantiﬁcation4.
For instance, the Twitter dataset is asymptotically perfectly
de-anonymizable when s ≥ 0.61 without seed information if
the overall structural information is considered. This implies
that the structure itself is sufﬁcient to break the privacy. The
reason for this result
the perfect de-anonymization
scheme induces the least edge difference as shown in our
quantiﬁcation.

is that

3To be accurately, asymptotically perfectly de-anonymizable here implies

Θ(n) users of each dataset can be successfully de-anonymized.

4Actually, the quantiﬁcation does not implies a computationally efﬁcient
algorithm. It is still an open problem to ﬁnd an efﬁcient (polynomial-time)
algorithm with provable performance guarantee.

category. Recent efforts have proposed using differentially
private graph models [15], however, the differential privacy
parameter still has to be determined before data sharing,
which makes this method ineffective in defending against
structure based de-anonymization attacks [2][3]. In summary,
it is expected that new anonymization techniques against the
structural information based de-anonymization attacks will be
designed. Our quantiﬁcation and evaluation can shed light to
the expected design by demonstrating the theoretical founda-
tion of such attacks and their efﬁcacy on attacking real world
social networks.

Limitations. There are still some limitations of this paper.
(i) To be accurate, we consider both the edges from
anonymized users to seed users and the edges among
anonymized users in the quantiﬁcation of the overall struc-
tural
information based de-anonymization. Actually, some
other global graph properties are also helpful in improving
structure based de-anonymization attacks, e.g., the between-
ness/closeness centrality of a user, the distance from a user to
other users. Although we believe these graph properties can
be used in improving de-anonymization attacks, it is difﬁcult
to involve them in the theoretical quantiﬁcation. The reason
is as follows: all these graph properties represent a user’s
global topological importance/characteristics with respect to
the entire graph. Consequently, even if there is just one edge-
change, it may change the global topological characteristics
(e.g., betweenness/closeness centrality, the distance from an
anonymized user to a seed) of an arbitrary number of users. It
follows that it is very difﬁcult, if not impossible, to quantify
the change on the global topological characteristics of a user.
Even though these global topological characteristics are not
considered in our quantiﬁcation, we demonstrate that
the
neighboring edges are sufﬁcient to perfectly or partially de-
anonymize a social network.

(ii) In this paper, we focus on closing the gap between
existing de-anonymization practices (i.e., heuristic algorithms)
and their theoretical foundation by quantifying the perfect
de-anonymizability and (1 − ϵ)-de-anonymizability of social
networks. We do not speciﬁcally consider how to design struc-
tural data anonymization techniques to defend against such
de-anonymization attacks. Actually, this is still an important
open problem since we have an increasing amount of social
data. We believe our quantiﬁcation and evaluation in this paper
can shed light on the future research in this area by providing
the theoretical foundation of structure based de-anonymization
attacks and their effectiveness in attacking real world social
networks. Furthermore, our quantiﬁcation and evaluation are
expected to draw the attention of data owners and help them
develop more proper policies to protect social data.

Future Work. The future work of this paper will take
the following directions: (i) It is expected that a new mathe-
matical model under which we can theoretically analyze the
change on users’ global topological properties (e.g., between-
ness/closeness centrality, the distance to seed users) will be
developed. Then, we can quantify the de-anonymizability of
social networks more accurately. (ii) In our quantiﬁcation,
we do not explicitly involve the noise level since we do
not involve a speciﬁc noise description model (actually, to
the best of our knowledge, we currently do not have proper
schemes to add noise with data utility preservation). In the

future, we propose to quantify the de-anonymizability of
social networks by involving a function describing the existing
noise. (iii) As pointed out before, we do not have effective
data anonymization techniques against structure based de-
anonymization attacks. We propose to study this open prob-
lem based on our quantiﬁcation and evaluation and develop
a secure data publishing platform which can examine the
data de-anonymizability, anonymize data properly with utility
preservation, and publish data securely. We also propose to
develop new social data protection policies for data owners.

VIII. CONCLUSION

In this paper, we study the de-anonymizability of social net-
works based only on their structural information. We quantify
the perfect and (1 − ϵ)-de-anonymizability of social networks
with seed information in general scenarios, where a social
network can follow an arbitrary network model. To the best of
our knowledge, this is the ﬁrst comprehensive quantiﬁcation
study on the perfect and partial de-anonymizability of social
networks under a general model. Based on our quantiﬁcation,
we conduct a large scale evaluation on the de-anonymizability
of 24 various real world social networks. Finally, we discuss
the implications of this work. Our ﬁndings are expected to shed
light on the future research in the structural data anonymization
and de-anonymization areas, and help data owners evaluate the
vulnerability of their structural data before data publishing.

ACKNOWLEDGMENT

The authors are grateful to Shukun Yang and Xiaojing Liao
for helpful discussions. The authors are also very grateful to
the anonymous reviewers for their time and valuable com-
ments.

This work was partly supported by NSF-CAREER-CNS-
0545667. Neil Zhenqiang Gong was supported by the Na-
tional Science Foundation under Grant No. 0831501 CTL
and by the Ofﬁce of Naval Research under MURI Grant No.
N000140911081. Prateek Mittal was supported in part by the
NSF under the grant CNS-1409415.

REFERENCES

[1] L. Backstrom, C. Dwork, and J. Kleinberg, Wherefore Art Thou R3579X?
Anonymized Social Networks, Hidden Patterns, and Structural Steganog-
raphy, WWW 2007.

[2] A. Narayanan and V. Shmatikov, De-anonymizing Social Networks, S&P

2009.

[3] M. Srivatsa and M. Hicks, Deanonymizing Mobility Traces: Using Social

Networks as a Side-Channel, CCS 2012.

[4] S. Ji, W. Li, M. Srivatsa, J. S. He, and R. Beyah, Structure based Data

De-anonymization of Social Networks and Mobility Traces, ISC 2014.

[5] S. Nilizadeh, A. Kapadia, and Y.-Y. Ahn, Community-Enhanced De-

anonymization of Online Social Networks, CCS 2014.

[6] P. Pedarsani and M. Grossglauser, On the Privacy of Anonymized

Networks, KDD 2011.

[7] S. Ji, W. Li, M. Srivatsa, and R. Beyah, Structural Data De-

anonymization: Quantiﬁcation, Practice, and Implications, CCS 2014.

[8] L. Yartseva and M. Grossglauser, On the Performance of Percolation

Graph Matching, COSN 2013.

[9] N. Korula and S. Lattanzi, An Efﬁcient Reconciliation Algorithm for

Social Networks, PVLDB 2014.

[10] G. Wondracek, T. Holz, E. Kirda, and C. Kruegel, A Practical Attack

to De-Anonymize Social Network Users, S&P 2010.

14

[11] M. Hay, G. Miklau, D. Jensen, D. Towsley, and P.Weis, Resisting Struc-

tural Re-identiﬁcation in Anonymized Social Networks, VLDB 2008.

[12] K. Liu and E. Terzi, Towards Identity Anonymization on Graphs,

SIGMOD 2008.

[13] C. Dwork, Differential Privacy, ICALP 2006.
[14] N. Li, W. Qardaji, D. Su, Y. Wu, and W. Yang Membership Privacy:

A Unifying Framework For Privacy Deﬁnitions, CCS 2013.

[15] A. Sala, X. Zhao, C. Wilson, H. Zheng, and B. Y. Zhao, Sharing Graphs

using Differentially Private Graph Models, IMC 2011.

[16] A. Meyerson and R. Williams, On the Complexisty of Optimal k-

Anonymity, PODS 2004.

[17] C. Shah, R. Capra, and P. Hansen, Collaborative Information Seeking,

Computer, Vol. 47, No. 3, pp. 22-25, 2014.

[18] Z. Xu, J. Ramanathan, and R. Ramnath, Identifying Knowledge Brokers
and Their Role in Enterprise Research through Social Media, Computer,
Vol. 47, No. 3, pp. 26-31, 2014.

[19] M. E. J. Newman, Networks: An Introduction, Oxford University Press,

2010.

[20] Stanford

Large

Network
http://snap.stanford.edu/data/index.html.
Computing

Social

[21] ASU

http://socialcomputing.asu.edu/pages/datasets.

Dataset

Collection,

Data

Repository,

[22] B. Viswanath, A. Mislove, M. Cha, and K. P. Gummadi, On the

Evolution of User Interaction in Facebook, WOSN 2009.

[23] N. Gong, W. Xu, L. Huang, P. Mittal, E. Stefanov, V. Sekar, and D.
Song, Evolution of Social-Attribute Networks: Measurements, Modeling,
and Implications using Google+, IMC 2012.

[24] H. Yu , C. Shi , M. Kaminsky , P. B. Gibbons , and F. Xiao DSybil:

Optimal Sybil-Resistance for Recommendation Systems, S&P 2009.

APPENDIX

4

(cid:3)

·

1
4

if

that

Second,

2 exp(− 1

let E be the event

we
k(n−k/2−1)

≥ 2 ln n+ln(2(n−ϵn−(cid:3)))

Proof Sketch of Theorem 5: First, we prove that
· ps3(1−p)2
2−s−ps

if
, Ga is (1 − ϵ)-de-
anonymizable. Let Vc ⊆ V a \ S a and |Vc| = n −
ϵn − Λ. Furthermore,
have Pr(E) ≤ ∑
there is
least one incorrectly de-anonymized user in Vc. Then,
at
∑
using the similar proof
technique in Theorem 2, we
Pr(i is incorrectly de-anonymized) ≤
i∈Vc
2−s−ps Λ) ≤ 2(n − ϵn − Λ) exp(−2 ln n −
ps3(1−p)2
i∈Vc
n2 . Hence, it a.a.s. that Pr(E) ∼ 0 as
2 ln(2(n− ϵn− Λ))) = 1
n → ∞, i.e., it a.a.s. that Ga is (1 − ϵ)-de-anonymizable.
≥
prove
, Ga is also (1 − ϵ)-de-anonymizable.
(k+2) ln n+ln(2(n−ϵn−(cid:3)))
Now, we do not have to distinguish σ0 and σk when
k ≤ ϵn. Let E now be the event that there is some de-
n−(cid:3)∪
≤ ∆σ0,
anonymization scheme σk such that σk ̸= σ0, ∆σk
≤
and k > ϵn. Then, we have Pr(E) =
Pr(∆σk
2−s−ps (mk − k/2)) ≤ 1
ps3(1−p)2
n2 .
Consequently, it a.a.s. that Pr(E) ∼ 0 as n → 0, i.e., Ga is
(1 − ϵ)-de-anonymizable.

∆σ0) ≤ n−(cid:3)∑

2
Proof Sketch of Theorem 6: To prove this theorem,
to prove that ∀i ∈ A, ∆σ:(i,i)(S) <
is sufﬁcient
it
∆σ:(i,j̸=i)(S) under any given σ (it follows that i is per-
fectly de-anonymizable in terms of ∆σ:(i,σ(i))(S)). Let X =
∆σ:(i,j̸=i)(S) and Y = ∆σ:(i,i)(S) be two random vari-
B(diq, 2s(1 − sγS,A)), Y ∼
ables. We have X

nk · 2 exp(− 1

ps3(1−p)2
2−s−ps

k=ϵn+1

k=ϵn+1

∼

1
4

4

stochastically

15

4

1

4

=

1

n>0

stochastically

stochastically

∑

∑

n2 = π2

n2 . Since

qs3(1−γS;A)2
2−s−sγS;A

8(λX +λY ) ) = 2 exp(− 1

− k/2, 2s(1− s· max{γV0,Vk , ρVk

B(k/2, 2s(1−s)). Deﬁne eX ∼ B(mV0,Vk +mVk
})) andeY ∼ B(mV0,Vk +mVk

B(diq, 2s(1 − s)). Applying Lemma 1, we have Pr(X ≤
Y ) ≤ 2 exp(− (λX−λY )2
di) ≤ 1
n2 .
6 < ∞, it is a.a.s. that i is perfectly de-
Since
anonymizable as n → ∞.
Proof Sketch of Theorem 8: (i) Let Vk ⊆ V \S be the set of
incorrectly de-anonymized users under σk ̸= σ0 and V0 = V \
Vk. Furthermore, let X = ∆σk and Y = ∆σ0 be two random
variables. Then, we have Y ∼ B(m, 2s(1 − s)). Furthermore,
we can consider four cases to quantify X. First, the edge differ-
ence caused by the edges in EV0 follows B(mV0 , 2s(1 − s));
second, the edge difference caused by the edges in EV0,Vk
stochastically follows B(mV0,Vk , 2s(1 − sγV0,Vk )); third, the
edge difference caused by the non-transposition edges in Ek
−x, 2s(1−sρVk )), where x here
stochastically follows B(mVk
is the number of transposition edges under σk; and ﬁnally,
the edge difference caused by the transposition edges in Ek
≥
follows B(x, 2s(1− s)). Since x ≤ k/2, we have X
B(mV0 , 2s(1− s)) + B(mV0,Vk , 2s(1− sγV0,Vk )) + B(mVk
−
k/2, 2s(1 − sρVk )) + B(k/2, 2s(1 − s)) ≥ B(mV0, 2s(1 −
})) +
s)) + B(mV0,Vk + mVk
−k/2, 2s(1−
Pr(eX ≤ eY ) ≤
s·max{γV0,Vk , ρVk
−k/2, 2s(1−
s)). Then, we have Pr(X ≤ Y )
s3(1−max{γV0 ;Vk ,ρVk
})2
− k/2)) ≤
2 exp(− 1
} (mV0,Vk + mVk
2−s−s·max{γV0 ;Vk ,ρVk
6 < ∞, it is
2 exp(−2 ln n − 1) ≤ 1
n2 = π2
a.a.s. that Pr(X ≤ Y ) ∼ 0 as n → ∞, i.e., it is a.a.s. that
∆σ0 < ∆σk given σk ̸= σ0.
(ii)Let E be the event that there exists some σk ̸= σ0
n−(cid:3)∪
≤ ∆σ0. Then, based on the union bound, we have
n−(cid:3)∑
≤ ∆σ0 ) ≤
nk · 2 exp(−(k + 2) ln n − ln(2(n − Λ − 1))) = 1
n2 .
k=2
Consequently, it is a.a.s. that σ0 is the only scheme inducing
the least edge difference, i.e., it is a.a.s. that Ga is perfectly
de-anonymizable.
2
Proof Sketch of Theorem 10: (i) As in Theorem 5, let
we have Pr(E) ≤ ∑
Vc be the set of users that are perfectly de-anonymizable and
|Vc| = n−ϵn−Λ. Furthermore, let E be the event that there ex-
∑
ists at least one incorrectly de-anonymizable user in Vc. Then,
P r(i is incorrectly de-anonymized) ≤
2 exp(−2 ln n−ln(2(n−
2 exp(− 1
qs3(1−γS;A)2
2−s−sγS;A
i∈Vc
n2 . Consequently, it is a.a.s. that Pr(E) ∼ 0 as
ϵn − Λ))) = 1
n → ∞, i.e. it is a.a.s. that Ga is (1 − ϵ)-de-anonymizable.
(ii) As in the proof of Theorem 5, we do not have to
distinguish σk with σ0 when k ≤ ϵn. Let E be the event that
≤ ∆σ0 and k > ϵn. Then,
there exists some σk such that ∆σk
nk ·
2 exp(− 1
−k/2)) = 1
n2 .
Consequently, it is a.a.s. that Ga is (1 − ϵ)-de-anonymizable
as n → ∞.

we have Pr(E) ≤ n−(cid:3)∑

s3(1−max{γV0 ;Vk ,ρVk
})2
} (mV0,Vk +mVk
2−s−s·max{γV0 ;Vk ,ρVk

≤ ∆σ0) ≤ n−(cid:3)∑

≤ ∆σ0 ) ≤ n−(cid:3)∑

di) ≤ ∑

and ∆σk
Pr(E) =

nk · Pr(∆σk

nk · Pr(∆σk

Pr(∆σk

i∈Vc

i∈Vc

k=ϵn+1

k=ϵn+1

n>0

k=2

k=2

4

4

2

2

