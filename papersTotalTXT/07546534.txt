2016 IEEE Symposium on Security and Privacy
2016 IEEE Symposium on Security and Privacy

Riad S. Wahby(cid:2)◦

rsw@cs.stanford.edu

Max Howald†
howald@cooper.edu

Veriﬁable ASICs

Siddharth Garg(cid:2)

sg175@nyu.edu

(cid:2)New York University

◦Stanford University

†The Cooper Union

‡The University of Virginia

abhi shelat‡

abhi@virginia.edu

Michael Walﬁsh(cid:2)
mwalfish@cs.nyu.edu

Introduction

Abstract—A manufacturer of custom hardware (ASICs) can under-
mine the intended execution of that hardware; high-assurance ex-
ecution thus requires controlling the manufacturing chain. How-
ever, a trusted platform might be orders of magnitude worse in per-
formance or price than an advanced, untrusted platform. This pa-
per initiates exploration of an alternative: using veriﬁable computa-
tion (VC), an untrusted ASIC computes proofs of correct execution,
which are veriﬁed by a trusted processor or ASIC. In contrast to
the usual VC setup, here the prover and veriﬁer together must im-
pose less overhead than the alternative of executing directly on the
trusted platform. We instantiate this approach by designing and
implementing physically realizable, area-efﬁcient, high throughput
ASICs (for a prover and veriﬁer), in fully synthesizable Verilog. The
system, called Zebra, is based on the CMT and Allspice interactive
proof protocols, and required new observations about CMT, care-
ful hardware design, and attention to architectural challenges. For
a class of real computations, Zebra meets or exceeds the perfor-
mance of executing directly on the trusted platform.
1
When the designer of an ASIC (application speciﬁc integrated
circuit, a term that refers to custom hardware) and the manufac-
turer of that ASIC, known as a fab or foundry, are separate en-
tities, the foundry can mount a hardware Trojan [19, 35, 105]
attack by including malware inside the ASIC. Government
agencies and semiconductor vendors have long regarded this
threat as a core strategic concern [4, 10, 15, 18, 45, 81, 111].
The most natural response—achieving high assurance by
controlling the manufacturing process—may be infeasible or
impose enormous penalties in price and performance.1 Right
now, there are only ﬁve nations with top-end foundries [69]
and only 13 foundries among them; anecdotally, only four
foundries will be able to manufacture at 14 nm or beyond.
In fact, many advanced nations do not have any onshore
foundries. Others have foundries that are generations old; In-
dia, for example, has 800nm technology [12], which is 25
years older and 108× worse (when considering the product of
ASIC area and energy) than the state of the art.

Other responses to hardware Trojans [35] include post-fab
detection [19, 26, 73, 77, 78, 119] (for example, testing based
on input patterns [47, 120]), run-time detection and disabling
(for example, power cycling [115]), and design-time obfusca-
tion [46, 70, 92]. These techniques provide some assurance
under certain misbehaviors or defects, but they are not sensi-
tive enough to defend against a truly adversarial foundry (§10).
One may also apply N-versioning [49]: use two foundries,

1Creating a top-end foundry requires both rare expertise and billions of dollars,
to purchase high-precision equipment for nanometer-scale patterning and
etching [52]. Furthermore, these costs worsen as the technology node—the
manufacturing process, which is characterized by the length of the smallest
transistor that can be fabricated, known as the critical dimension—improves.

2375-1207/16 $31.00 © 2016 IEEE
© 2016, Riad S. Wahby. Under license to IEEE.
DOI 10.1109/SP.2016.51
DOI 10.1109/SP.2016.51

759
759

deploy the two ASICs together, and, if their outputs differ,
a trusted processor can act (notify an operator, impose fail-
safe behavior, etc.). This technique provides no assurance if
the foundries collude—a distinct possibility, given the small
number of top-end fabs. A high assurance variant is to execute
the desired functionality in software or hardware on a trusted
platform, treating the original ASIC as an untrusted accelerator
whose outputs are checked, potentially with some lag.

This leads to our motivating question: can we get high-
assurance execution at a lower price and higher performance
than executing the desired functionality on a trusted platform?
To that end, this paper initiates the exploration of veriﬁable
ASICs (§2.1): systems in which deployed ASICs prove, each
time they perform a computation, that the execution is correct,
in the sense of matching the intended computation.2 An ASIC
in this role is called a prover; its proofs are efﬁciently checked
by a processor or another ASIC, known as a veriﬁer, that is
trusted (say, produced by a foundry in the same trust domain
as the designer). The hope is that this arrangement would yield
a positive response to the question above. But is the hope
well-founded?

On the one hand, this arrangement roughly matches the se-
tups in probabilistic proofs from complexity theory and cryp-
tography: interactive proofs or IPs [22, 63, 64, 80, 102], efﬁ-
cient arguments [39, 72, 74, 83], SNARGs [62], SNARKs [36],
and veriﬁable outsourced computation [23, 60, 63, 83] all yield
proofs of correct execution that can be efﬁciently checked
by a veriﬁer. Moreover, there is a ﬂourishing literature sur-
rounding the reﬁnement and implementation of these proto-
cols [24, 25, 29, 31–33, 41, 51, 55, 56, 58, 59, 61, 76, 88, 98–
101, 106, 108, 112, 114] (see [117] for a survey). On the other
hand, all of this work can be interpreted as a negative result:
despite impressive speedups, the resulting artifacts are not
deployable for the application of veriﬁable ofﬂoading. The
biggest problem is the prover’s burden: its computational over-
head is at least 105×, and usually more than 107×, greater
than the cost of just executing the computation [117, Fig. 5].
Nevertheless, this issue is potentially surmountable—at
least in the hardware context. With CMOS technology, many
costs scale down super-linearly; as examples, area and en-
ergy reduce with the square and cube of critical dimension,
respectively [91]. As a consequence, the performance improve-
ment, when going from an ASIC manufactured in a trusted,
older foundry to one manufactured in an untrusted, advanced

2This is different from, but complementary to, the vast literature on hardware
veriﬁcation. There, the goal is to statically verify that a circuit design—which
is assumed to be manufactured faithfully—meets an intended speciﬁcation.

foundry, can be larger than the overhead of provers in the
aforementioned systems (as with the earlier example of India).
Given this gap, veriﬁable outsourcing protocols could yield
a positive answer to our motivating question—but only if the
prover can be implemented on an ASIC in the ﬁrst place. And
that is easier said than done. Many protocols for veriﬁable
outsourcing [24, 25, 29, 31–33, 41, 51, 56, 58, 59, 61, 76,
88, 99–101, 114] have concrete bottlenecks (cryptographic
operations, serial phases, communication patterns that lack
temporal and spatial locality, etc.) that seem incompatible
with an efﬁcient, physically realizable hardware design. (We
learned this the hard way; see Section 9.)

Fortunately, there is a protocol in which the prover uses
no cryptographic operations, has highly structured and par-
allel data ﬂows, and demonstrates excellent spatial and tem-
poral locality. This is CMT [55], an interactive proof that
reﬁnes GKR [63]. Like all implemented protocols for veriﬁ-
able outsourcing, CMT works over computations expressed as
arithmetic circuits, meaning, loosely speaking, additions and
multiplications. To be clear, CMT has further restrictions. As
enhanced by Allspice [112], CMT works best for computations
that have a parallel and numerical ﬂavor and make sparing
use of non-arithmetic operations (§2.2). But we can live with
these restrictions because there are computations that have the
required form (the number theoretic transform, polynomial
evaluation, elliptic curve operations, pattern matching with
don’t cares, etc.; see also [55, 88, 99–101, 106, 108, 112]).

Moreover, one might expect something to be sacriﬁced,
since our setting introduces additional challenges to veriﬁable
computation. First, working with hardware is inherently difﬁ-
cult. Second, whereas the performance requirement up until
now has been that the veriﬁer save work versus carrying out
the computation directly [41, 55, 60, 88, 99–101, 112, 114],
here we have the additional requirement that the whole sys-
tem—veriﬁer together with prover—has to beat that baseline.
This brings us to the work of this paper. We design, im-
plement, and evaluate physically realizable, high-throughput
ASICs for a prover and veriﬁer based on CMT and Allspice.
The overall system is called Zebra.

Zebra’s design (§3) is based, ﬁrst, on new observations
about CMT, which yield parallelism (beyond that of prior
work [108]). One level down, Zebra arranges for locality and
predictable data ﬂow. At the lowest level, Zebra’s design is
latency insensitive [44], with few timing constraints, and it
reuses circuitry to reduce ASIC area. Zebra also responds
to architectural challenges (§4), including how to meet the
requirement, which exists in most implemented protocols for
veriﬁable computation, of trusted ofﬂine precomputation; how
to endow the veriﬁer with storage without the cost of a trusted
storage substrate; and how to limit the overhead of the veriﬁer-
prover communication.

The core design is fully implemented (§6): Zebra includes
a compiler that takes an arithmetic circuit description to syn-
thesizable Verilog (meaning that the Verilog can be compiled

to a hardware implementation). Combined with existing com-
pilers that take C code to arithmetic circuit descriptions [31–
33, 40, 41, 51, 56, 88, 99, 101, 112, 114], Zebra obtains a
pipeline in which a human writes high-level software, and a
toolchain produces a hardware design.

Our evaluation of Zebra is based on detailed modeling (§5)
and measurement (§7). Taking into account energy, area, and
throughput, Zebra outperforms the baseline when both of the
following hold: (a) the technology gap between P and V
is a more than a decade, and (b) the computation of inter-
est can be expressed naturally as an arithmetic circuit with
tens of thousands of operations. An example is the number
theoretic transform (§8.1): for 210-point transforms, Zebra is
competitive with the baseline; on larger computations it is
better by 2–3×. Another example is elliptic curve point multi-
plication (§8.2): when executing several hundred in parallel,
Zebra outperforms the baseline by about 2×.

Zebra has clear limitations (§9). Even in the narrowly de-
ﬁned regime where it beats the baseline, the price of veriﬁ-
ability is very high, compared to untrusted execution. Also,
Zebra has some heterodox manufacturing and operating re-
quirements (§4); for example, the operator must periodically
take delivery of a preloaded hard drive. Finally, Zebra does
not have certain properties that other veriﬁable computation
do: low round complexity, public veriﬁability, zero knowl-
edge properties, etc. On the other hand, these amenities aren’t
needed in our context.

Despite the qualiﬁed results, we believe that this work,
viewed as a ﬁrst step, makes contributions to hardware se-
curity and to veriﬁable computation:
• It initiates the study of veriﬁable ASICs. The high-level
notion had been folklore (for example, [50, §1.1]), but there
have been many details to work through (§2.1, §2.3).

• It demonstrates a response to hardware Trojans that works
in a much stronger threat model than prior defenses (§10).
• It makes new observations about CMT. While they are of
mild theoretical interest (at best), they matter a lot for the
efﬁciency of an implementation.

• It includes a hardware design that achieves efﬁciency by
composing techniques at multiple levels of abstraction.
Though their novelty is limited (in some cases, it is none),
together they produce a milestone: the ﬁrst hardware design
and implementation of a probabilistic proof system.

• It performs careful modeling, accounting, and measurement.
At a higher level, this is the ﬁrst work to identify a setting in
which one can simultaneously capture the “cost” of a prover
and veriﬁer together, and to give implementations for which
this quantity is (sometimes) less expensive than having the
veriﬁer compute on its own.

760760

Trust Domain

Supplier
(foundry,
processor

vendor, etc.)

Operator

V

Principal
Ψ → specs
for P , V

Foundry

V

Integrator

P

x

y

proof

P

FIGURE 1—Veriﬁable ASICs. A principal outsources the production
of an ASIC (P) to an untrusted foundry and gains high-assurance
execution via a trusted veriﬁer (V ) and a probabilistic proof protocol.
2 Setup and starting point

2.1 Problem statement: veriﬁable ASICs

The setting for veriﬁable ASICs is depicted in Figure 1. There
is a principal, who deﬁnes a trust domain. The principal could
be a government, a fabless semiconductor company that de-
signs circuits, etc. The principal wishes to deploy an ASIC
that performs some computation Ψ, and wishes for a third
party—outside of the trust domain and using a state-of-the-art
technology node (§1)—to manufacture the chip. After fabri-
cation, the ASIC, which we call a prover P, is delivered to
and remains within the trust domain. In particular, there is a
trusted step in which an integrator, acting on behalf of the
principal, produces a single system by combining P with a
veriﬁer V . The operator or end user trusts the system that the
integrator delivers to it.

The manufacturer or supplier of V is trusted by the principal.
For example, V could be an ASIC manufactured at a less
advanced but trusted foundry located onshore [15, 45]. Or V
could run in software on a general-purpose CPU manufactured
at such a foundry, or on an existing CPU that is assumed to
have been manufactured before Trojans became a concern. We
refer to the technology node of V as the trusted technology
node; likewise, the technology node of P is the untrusted
technology node.

During operation, the prover (purportedly) executes Ψ,
given a run-time input x; P returns the (purported) output
y to V . For each execution, P and V engage in a protocol. If
y is the correct output and P follows the protocol, V must
accept; otherwise, V must reject with high probability.

P can deviate arbitrarily from the protocol. However, it is
assumed to be a polynomial-time adversary and is thus sub-
ject to standard cryptographic hardness assumptions (it cannot
break encryption, etc.). This models multiple cases: P could
have been designed maliciously, manufactured with an arbitrar-

ily modiﬁed design [105], replaced with a counterfeit [10, 65]
en route to the principal’s trust domain, and so on.

Performance and costs. The cost of V and P together
must be less than the native baseline (§1): a chip or CPU, in
the same technology node as V , that executes Ψ directly. By
“cost”, we mean general hardware considerations: energy con-
sumption, chip area and packaging, throughput, non-recurring
manufacturing costs, etc. Also, V and P must be physically
realizable in the ﬁrst place. Note that costs and physical real-
izability depend on the computation Ψ, the design of V , the
design of P, and the technology nodes of V and P.

Integration assumptions. There are requirements that sur-
round integration; our work does not speciﬁcally address them,
so we regard them as assumptions. First, P’s inﬂuence on
V should be limited to the deﬁned communication interface,
otherwise P could undermine or disable V ; similarly, if V
has private state, then P should not have access to that state.
Second, P must be isolated from all components besides V .
This is because P’s outputs are untrusted; also, depending on
the protocol and architecture, exﬁltrating past messages could
affect soundness for other veriﬁer-prover pairs (§4). These two
requirements might call for separate power supplies, shield-
ing V from electromagnetic and side-channel inference at-
tacks [121], etc. However, we acknowledge that eliminating
side and covert channels is its own topic. Third, V may need
to include a fail-safe, such as a kill switch, in case P returns
wrong answers or refuses to engage.

2.2 Interactive proofs for veriﬁable computation
In designing a V and P that respond to the problem statement,
our starting point is a protocol that we call OptimizedCMT.
Using an observation of Thaler [107] and additional simpli-
ﬁcations and optimizations, this protocol—which we are not
claiming as a contribution of this paper—optimizes Allspice’s
CMT-slim protocol [112, §3], which reﬁnes CMT [55, §3;
108], which reﬁnes GKR [63, §3]; these are all interactive
proofs [22, 63, 64, 80, 102]. We start with OptimizedCMT
because, as noted in Section 1, it has good parallelism and
data locality, qualities that ought to lead to physical realizabil-
ity and efﬁciency in energy, area, and throughput. In the rest
of this section, we describe OptimizedCMT; this description
owes some textual debts to Allspice [112].

A veriﬁer V and a prover P agree, ofﬂine, on a computa-
tion Ψ, which is expressed as an arithmetic circuit (AC) C . In
the arithmetic circuit formalism, a computation is represented
as a set of abstract “gates” corresponding to ﬁeld operations
(add and multiply) in a given ﬁnite ﬁeld, F = Fp (the integers
mod a prime p); a gate’s two input “wires” and its output
“wire” represent values in F. OptimizedCMT requires that the
AC be layered: the inputs connect only to ﬁrst level gates, the
outputs of those gates connect only to second-level gates, and
so on. Denote the number of layers d and the number of gates
in a layer G; we assume, for simplicity, that all layers, except
for the input and output, have the same number of gates.

761761

The aim of the protocol is for P to prove to V that, for a
given input x, a given purported output vector y is truly C (x).
The high-level idea is, essentially, cross examination: V draws
on randomness to ask P unpredictable questions about the
state of each layer. The answers must be consistent with each
other and with y and x, or else V rejects. The protocol achieves
the following; the probabilities are over V ’s random choices:

• Completeness. If y = C (x) and if P follows the protocol,
then Pr{V accepts} = 1.
• Soundness. If y (cid:3)= C (x), then Pr{V accepts} < ε, where
ε = ((cid:4)log|y|(cid:5) + 5d logG)/|F| and |F| is typically a large
prime. This is an unconditional guarantee: it holds regard-
less of the prover’s computational resources and strategy.
This follows from the analysis in GKR [63, §2.5,§3.3], ap-
plied to Thaler’s observations [107] (see also [112, §A.2]).
• Efﬁcient veriﬁer. Whereas the cost of executing C directly
would be O(d · G), the veriﬁer’s online work is of lower
complexity: O(d · logG +|x| +|y|). This assumes that V
has access to auxiliary inputs that have been precomputed
ofﬂine; auxiliary inputs are independent of the input to C .
For each run of the protocol, an auxiliary input is of size
O(d · logG); the time to generate one is O(d · G).
• Efﬁcient prover. The prover’s work is O(d · G· logG).

Applicability. Consider a computation Ψ expressed in any
model: binary executable on CPU, Boolean circuit, ASIC
design, etc. Excluding precomputation, OptimizedCMT saves
work for V versus executing Ψ in its native model, provided
(1) Ψ can be represented as a deterministic AC, and (2) the AC
is sufﬁciently wide relative to its depth (G (cid:6) d). Requirement
(2) can be relaxed by executing many copies of a narrow
arithmetic circuit in parallel (§8.2).

Requirement (1) further interferes with applicability. One
reason is that although any computation Ψ can in theory be rep-
resented as a deterministic AC, if Ψ has comparisons, bitwise
operations, or indirect memory addressing, the resulting AC is
very large. Prior work [31, 33, 88, 99, 101, 114] handles these
program constructs compactly by exploiting non-deterministic
ACs, and Allspice [112, §4.1] applies those techniques to the
ACs that OptimizedCMT works over. Provided Ψ invokes a
relatively small number—sub-linear in the running time—of
these constructs, V can potentially save work [112, §4.3].

Also, ACs work over a ﬁeld, usually Fp; if Ψ were expressed
over a different domain (for example, ﬁxed-width integers, as
on a CPU), the AC would inﬂate (relative to Ψ), ruling out
work-savings for reasonably-sized computations. This issue
plagues all built systems for veriﬁable computation [24, 25,
29, 31–33, 41, 51, 55, 56, 58, 59, 61, 76, 88, 98–101, 106,
108, 112, 114] (§9). This paper sidesteps it by assuming that
Ψ is expressed over Fp. That is, to be conservative, we restrict
focus to computations that are naturally expressed as ACs.

Protocol details. Within a layer of the arithmetic circuit,
gates are numbered between 1 and G and have a label corre-
sponding to the binary representation of their number, viewed
as an element of {0,1}b, where b = (cid:4)logG(cid:5).
The AC’s layers are numbered in reverse order of execution,
so its inputs (x) are inputs to the gates at layer d − 1, and its
outputs (y) are viewed as being at layer 0. For each i = 0, . . . ,d,
the evaluator function Vi : {0,1}b → F maps a gate’s label to
the correct output of that gate; these functions are particular to
execution on a given input x. Notice that Vd( j) returns the jth
input element, while V0( j) returns the jth output element.

Observe that C (x) = y, meaning that y is the correct output,
if and only if V0( j) = y j for all output gates j. However, V
cannot check directly whether this condition holds: evaluating
V0(·) would require re-executing the AC, which is ruled out
by the problem statement. Instead, the protocol allows V
to efﬁciently reduce a condition on V0(·) to a condition on
V1(·). That condition also cannot be checked—it would require
executing most of the AC—but the process can be iterated until
it produces a condition that V can check directly.
This high-level idea motivates us to express Vi−1(·) in
terms of Vi(·). To this end, deﬁne the wiring predicate
addi : {0,1}3b → F, where addi(g,z0,z1) returns 1 if g is
an add gate at layer i − 1 whose inputs are z0,z1 at layer
i, and 0 otherwise; multi is deﬁned analogously for multi-
plication gates. Now, Vi−1(g) = ∑z0,z1∈{0,1}b addi(g,z0,z1) ·
(Vi(z0) +Vi(z1)) + multi(g,z0,z1)·Vi(z0)·Vi(z1).
An important concept is extensions. An extension of a
function f is a function ˜f that: works over a domain that
encloses the domain of f , is a polynomial, and matches f
everywhere that f is deﬁned. In our context, given a func-
tion g: {0,1}m → F, the multilinear extension (it is unique)
˜g: Fm → F is a polynomial that agrees with g on its domain
and that has degree at most one in each of its m variables.
Throughout this paper, we notate multilinear extensions with
tildes. Thaler [107], building on GKR [63], shows:

˜Vi−1(q) = ∑

z0,z1∈{0,1}b

Pq(z0,z1), where

Pq(z0,z1) = ˜addi(q,z0,z1)·(cid:2)

(cid:3)
+ ˜multi(q,z0,z1)· ˜Vi(z0)· ˜Vi(z1),

˜Vi(z0) + ˜Vi(z1)

(1)

with signatures ˜Vi, ˜Vi−1 : Fb → F and ˜addi,
˜multi : F3b → F.
Also, Pq : F2b → F. (GKR’s expression for ˜Vi−1(·) sums a 3b-
variate polynomial over G3 terms. Thaler’s 2b-variate polyno-
mial, Pq, summed over G2 terms, reduces the prover’s runtime,
rounds, and communication by about 33%.)
At this point, the form of ˜Vi−1(·) calls for a sumcheck proto-
col [80]: an interactive protocol in which a prover establishes
for a veriﬁer a claim about the sum, over a hypercube, of a
given polynomial’s evaluations. Here, the polynomial is Pq.
For completeness, we give the entire protocol between P
and V , in Figure 2. Many of the details are justiﬁed else-
where [63, §3][55, §A.1–A.2][112, §2.2,§A][107]. Here, our

762762

// see line 71

// see line 56

for j = 1, . . . ,2b do

q0 ← ReceiveFromVeriﬁer()
d ← c.depth

// compute Fj(0),Fj(1),Fj(2)
parallel for all gates g at layer i− 1 do

// each circuit layer induces one sumcheck invocation
for i = 1, . . . ,d do
w0,w1 ← SUMCHECKP(c, i, qi−1)
τi ← ReceiveFromVeriﬁer()
qi ← (w1 − w0)· τi + w0

1: function PROVE(ArithCircuit c, input x)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11: function SUMCHECKP(ArithCircuit c, layer i, qi−1)
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:
32:
33:
34:
35:
36:
37:
38:

for k = 0,1,2 do
// below, s ∈ {0,1}3b. s is a gate triple in binary.
s ← (g, gL, gR) // gL,gR are labels of g’s layer-i inputs
uk ← (qi−1[1], . . . ,qi−1[b],r[1], . . . ,r[ j−1], k)
// notation: χ : F → F. χ1(t) = t, χ0(t) = 1−t
termP ← ∏
if j ≤ b then
termL ← ˜Vi (r[1], . . . ,r[ j− 1], k, gL[ j+1], . . . ,gL[b])
termR ← Vi (gR) // Vi = ˜Vi on gate labels
else
termL ← ˜Vi(r[1], . . . ,r[b])
termR ← ˜Vi (r[b+1], . . . ,r[ j−1], k,
gR[ j−b+1], . . . ,gR[b])

F[g][k] ← termP· (termL + termR)
F[g][k] ← termP· termL· termR

else if g is a mult gate then

for k = 0,1,2 do
Fj[k] ← ∑G

if g is an add gate then

// b < j ≤ 2b

χs[(cid:3)](uk[(cid:3)])

g=1 Fj[g][k]

b+ j
(cid:3)=1

SendToVeriﬁer
r[ j] ← ReceiveFromVeriﬁer()

Fj[0], Fj[1], Fj[2]

// see line 82

// see line 87

// notation
w0 ← (r[1], . . . ,r[b])
w1 ← (r[b+1], . . . ,r[2b])

˜Vi(w0), ˜Vi(w1)

SendToVeriﬁer
for t = {2, . . . ,b}, wt ← (w1 − w0)·t + w0
SendToVeriﬁer

˜Vi(w2), . . . , ˜Vi(wb)

(cid:3)

// see line 99

// see line 67

return (w0,w1)

(cid:3)

(cid:3)

(cid:2)

(cid:2)
(cid:2)

39:
40:
41:
42:
43:
44:
45:
46:
47:
48:
49:
50:
51:
52:

?= ˜Vi(w1) . . .

// ˜Vy(·) is the multilinear ext. of the output y

?= ˜Vi(qi).

// . . . and reduce h0
// we will interpolate H(t) = ˜Vi ((w1 − w0)t + w0), so we want
// H(0), . . . ,H(b). But h0,h1 should be H(0),H(1), so we now
// need H(2), . . . ,H(b)
h2, . . . ,hb ← ReceiveFromProver()
R←− F
τi
qi ← (w1 − w0)· τi + w0
ai ← H∗(τi) // H∗ is poly. interpolation of h0,h1,h2, . . . ,hb
SendToProver(τi)

// see line 50

// see line 8
// ˜Vd(·) is multilin. ext. of the input x

R←− Fb

// see line 2

return reject

return accept

?= ˜Vi(w0),h1

?= ˜Vi−1(qi−1) to h0

if ad = ˜Vd(qd) then

q0
a0 ← ˜Vy(q0)
SendToProver(q0)
d ← c.depth

for i = 1, . . . ,d do
?= ˜Vi(w0), h1
// reduce ai−1
(h0,h1,w0,w1) ← SUMCHECKV(i,qi−1,ai−1)
?= ˜Vi(w1) to ai

53: function VERIFY(ArithCircuit c, input x, output y)
54:
55:
56:
57:
58:
59:
60:
61:
62:
63:
64:
65:
66:
67:
68:
69:
70:
71:
72:
73:
74:
75:
76:
77: function SUMCHECKV(layer i, qi−1,ai−1)
78:
79:
80:
81:
82:
83:
84:
85:
86:
87:
88:
89:
90:
91:
92:
93:
94:
95:
96:
97:
98:
99:
100:
101:
102:
103:

r R←− F2b
e ← ai−1
for j = 1,2, . . . ,2b do
Fj[0], Fj[1], Fj[2] ← ReceiveFromProver()
if Fj[0] + Fj[1] (cid:3)= e then
return reject

SendToProver(r[ j])
reconstruct Fj(·) from Fj[0],Fj[1],Fj[2]
// Fj(·) is degree-2, so three points are enough.
e ← Fj(r[ j])

return (h0,h1,w0,w1)

// see line 41

// notation
w0 ← (r[1], . . . ,r[b])
w1 ← (r[b + 1], . . . ,r[2b])
// P is supposed to set h0 = ˜Vi(w0) and h1 = ˜Vi(w1)
h0,h1 ← ReceiveFromProver()
a(cid:12) ← ˜addi(qi−1,w0,w1)(h0 + h1) + ˜multi(qi−1,w0,w1)h0 · h1
if a(cid:12) (cid:3)= e then
return reject

// see line 47

// see line 40

FIGURE 2—Pseudocode for P and V in OptimizedCMT [55, 63, 107, 112], expressed in terms of the parallelism used by TRMP [108].
Some of the notation and framing is borrowed from Allspice [112]. The protocol proceeds in layers. At each layer i, the protocol reduces
the claim that ai−1 = ˜Vi−1(qi−1) to a claim that ai = ˜Vi(qi); note that equation (1) in the text expresses ˜Vi−1(qi−1) as a sum over a hypercube.
The SumCheck sub-protocol guarantees to V that, with high probability, this sum equals ai−1 if and only if h0= ˜Vi(w0) and h1= ˜Vi(w1); an
additional reduction connects these two conditions to the claim that ai = ˜Vi(qi). See [63, §3][55, §A.1–A.2][112, §2.2,§A][107] for explanation
of all details.

763763

aim is to communicate the structure of the protocol and the
work that P performs. There is one invocation of the sum-
check protocol for each layer of the arithmetic circuit. Within
an invocation, there are 2b rounds (logarithmic in layer width).
In each round j, P describes to V a univariate polynomial:
∗, t j+1, . . . ,t2b),
∗) =

(r1, . . . ,r j−1, t

Fj(t

∑

Pqi−1

t j+1,...,t2b∈{0,1}2b− j

where r j is a random challenge sent by V at the end of round
j, and qi−1 is a function of random challenges in prior in-
vocations. Fj(·) is degree 2, so P describes it by sending
three evaluations—Fj(0),Fj(1),Fj(2)—which V interpolates
to obtain the coefﬁcients of Fj(·). How does P compute these
evaluations? Naively, this seems to require Ω(G3 logG) oper-
ations. However, CMT [55, §A.2] observes that Fj(k) can be
written as a sum with one term per gate, in the form:
termP j,g,k · (termL j,g,k + termR j,g,k)

Fj(k) = ∑
g∈Sadd,i

termP j,g,k · termL j,g,k · termR j,g,k,

+ ∑

g∈Smult,i

where Sadd,i (resp., Smult,i) has one element for each add (resp.,
multiplication) gate g at layer i− 1. The deﬁnitions of termP,
termL, and termR are given in Figure 2; these terms depend
on j, on g, on k, and on prior challenges.

˜addi(qi−1,w0,w1) and

χs[(cid:3)](t(cid:3)), and analogously for

Recall that V receives an auxiliary input for each run
of the protocol. An auxiliary input has two components.
The ﬁrst one is O(d · logG) ﬁeld elements: the evalua-
˜multi(qi−1,w0,w1), for i =
tions of
{1, . . . ,d} (line 100, Figure 2), together with τi, w0, and
˜addi(t1, . . . ,t3b) =
w1. As shown elsewhere [112, §A.3],
˜multi.
∑s∈{0,1}3b : addi(s)=1 ∏3b
Computing these quantities naively would require 3· G· logG
(cid:3)=1
operations; an optimization of Allspice [112, §5.1] lowers this
to between 12·G and 15·G operations and thus O(d·G) for all
layers. The second component comprises Lagrange basis coef-
ﬁcients [16], used to lower the “online” cost of interpolating
H∗ (line 70, Figure 2) from O(log 2G) to O(logG). The size
of this component is O(d · logG) ﬁeld elements; the time to
compute it is O(d · log 2G). We discuss how one can amortize
these precomputations in Section 4.3
2.3 Hardware considerations and metrics
The high-level performance aim was described earlier (§2.1);
below, we delve into the speciﬁc evaluation criteria for Zebra.
With hardware, choosing metrics is a delicate task. One
reason is that some metrics can be “fooled”. For example, per-
chip manufacturing costs are commonly captured by area (the
size of an ASIC in square millimeters). Yet area alone is an in-
complete metric: a design might iteratively re-use modules to

3CMT [55, 106, 108] avoids amortization by restricting focus to regu-
˜multi can be computed in
lar arithmetic circuits, meaning that
O(polylog(G)) time. In that setup, V incurs this cost “online”, at which
point there is no reason to precompute the Lagrange coefﬁcients either.

˜addi and

764764

lower area, but that would also lower throughput. Another is-
sue is that costs are multifaceted: one must also account for op-
erating costs and hence energy consumption (joules/operation).
Finally, physics imposes constraints, described shortly.

We will use two metrics, under two constraints. The ﬁrst
metric is energy per protocol run, denoted E, which captures
both the number of basic operations (arithmetic, communica-
tion, etc.) in each run and the efﬁciency of each operation’s
implementation. The second metric is the ratio of area and
throughput, denoted As/T . The term As is a weighted sum of
area consumed in the trusted and untrusted technology nodes;
the untrusted area is divided by s. We leave s as a parameter
because (a) s will vary with the principal, and (b) comparing
costs across foundries and technology nodes is a thorny topic,
and arguably a research question [43, 82]. For both metrics,
lower is better.

Turning to constraints, the ﬁrst is a ceiling on area for any
chip: P, V , and the baseline. This reﬂects manufacturability:
large chips have low manufacturing yield owing to defects.
Constraining area affects As/T because it rules out, for ex-
ample, designs that abuse some super-linear throughput im-
provement per unit area. The second constraint is a limit on
power dissipation, because otherwise heat becomes an issue.
This constrains the product of E and T (which is in watts),
bounding parallelism by restricting the total number of basic
operations that can be executed in a given amount of time.

In measuring Zebra’s performance, we will try to capture
all costs associated with executing OptimizedCMT. As an
important example, we will include not only V ’s and P’s
computation but also their interaction (§4); this is crucial be-
cause the protocol entails signiﬁcant communication overhead.
We model costs in detail in Section 5.

We discuss non-recurring costs (engineering, creating pho-

tolithographic masks, etc.) in Section 9.

3 Design of prover and veriﬁer in Zebra

This section details the design of Zebra’s hardware prover;
we also brieﬂy describe Zebra’s hardware veriﬁer. The de-
signs follow OptimizedCMT and thus inherit its completeness,
soundness, and asymptotic efﬁciency (§2.2). The exception is
that P’s design has an additional O(logG) factor in running
time (§3.2). To achieve physically realizable, high-throughput,
area-efﬁcient designs, Zebra exploits new and existing obser-
vations about OptimizedCMT. Zebra’s design ethos is:

• Extract parallelism. This does not reduce the total work that
must be done, but it does lead to speedups. Speciﬁcally, for
a given area, more parallelism yields better throughput.

• Exploit locality. This means avoiding unnecessary com-
munication among modules: excessive communication con-
strains physical realizability. Locality also refers to avoiding
dependencies among modules; in hardware, dependencies

Input (x)

y

P

Vi (from previous
sub-prover)

Compute ˜Vi

queries

Sub-prover, layer 0

responses

prove

compute

V

queries

Sub-prover, layer 1

˜Vi evaluations

(cid:4)

Shufﬂe tree

˜Vi routed to gates

r j (from V )

τ (from V )

Store w0 ,
w1 − w0

Compute qi

qi (to
previous
sub-
prover)

prove

.
.
.

compute

.
.
.

gate

provers
(G total)

Sub-prover, layer d − 1
prove

compute

Compute
[g][k],
Fj

k ∈ {0, 1, 2}

[g][k]

Fj

Compute
(w2) ,. . . , ˜Vi

(wb

)

˜Vi

˜Vi

(·) partial products

responses

queries

responses

x

Output (y)

FIGURE 3—Architecture of prover (P) in Zebra. Each logical sub-
prover handles all of the work for a layer in a layered arithmetic
circuit C of width G and depth d.

translate to timing relationships,4 timing relationships cre-
ate serialization points, and serialization harms throughput.
• Reuse work. This means both reusing computation results
(saving energy), and reusing modules in different parts of
the computation (saving area). This reuse must be carefully
engineered to avoid interfering with the previous two goals.

3.1 Overview
Figure 3 depicts the top-level design of the prover. The prover
comprises logically separate sub-provers, which are multi-
plexed over physical sub-prover modules. Each logical sub-
prover is responsible for executing a layer of C and for the
proof work that corresponds to that layer (lines 7–9 in Fig-
ure 2). The execution runs forward; the proving step happens
in the opposite order. As a consequence, each sub-prover must
buffer the results of executing its layer, until those results are
used in the corresponding proof step. Zebra is agnostic about
the number of physical sub-prover modules; the choice is an
area-throughput trade-off (§3.2).

The design of a sub-prover is depicted in Figure 4. A sub-
prover proceeds through sumcheck rounds sequentially, and
reuses the relevant functional blocks over every round of the
protocol (which contributes to area efﬁciency). Within a round,
gate provers work in parallel, roughly as depicted in Figure 2
(line 15), though Zebra extracts additional parallelism (§3.2).
From one round to the next, intermediate results are preserved
locally at each functional unit (§3.3). At lower levels of the
design, the sub-prover has a latency-insensitive control struc-
ture (§3.3), and the sub-prover avoids work by reusing compu-
tation results (§3.4).

4Synthesis is the process of translating a digital circuit design into concrete
logic gates. This translation must satisfy relationships, known as timing
constraints, between signals. Constraints are explicit (e.g., the designer
speciﬁes the frequency of the master clock) and implicit (e.g., one ﬂip-ﬂop’s
input relies on a combinational function of another ﬂip-ﬂop’s output).

765765

Adder tree

[k] (once per round)
(·) (once per sumcheck

Fj
˜Vi

invocation)
FIGURE 4—Design of a sub-prover.

The design of the veriﬁer is similar to that of the prover;
however, the veriﬁer’s work is more serial, so its design aims
to reuse modules, and thus save area, without introducing
bottlenecks (§3.5).

The rest of this section delves into details, highlighting the
innovations; our description is roughly organized around the
ethos presented earlier.
3.2 Pipelining and parallelism
The pseudocode for P (Figure 2) is expressed in terms of the
parallelism that has been observed before [108]. Below, we
describe further parallelism extracted by Zebra’s design.
Exploiting layered arithmetic circuits. The required layer-
ing in the arithmetic circuit (§2.2) creates a textbook trade-off
between area and throughput. At one extreme, Zebra can con-
serve area, by having a single physical sub-prover, which is
iteratively reused for each layer of the AC. The throughput is
given by the time to execute and prove each layer of C .

At the other extreme, Zebra can spend area, dedicate a
physical sub-prover to each layer of the arithmetic circuit,
and arrange them in a classical pipeline. Speciﬁcally, the sub-
prover for layer i handles successive runs, in each “epoch”
always performing the proving work of layer i, and handing its
results to the sub-prover for layer i + 1. The parallelism that
is exploited here is that of multiple runs; the acceleration in
throughput, compared to using a single physical sub-prover,
is d. That is, Zebra’s prover can produce proofs at a rate
determined only by the time taken to prove a single layer.

Zebra also handles intermediate points, such as two logical
sub-provers per physical prover. In fact, Zebra can have more
runs in ﬂight than there are physical sub-provers. Speciﬁcally,
instead of handling several layers per run and then moving to
the next run, a physical sub-prover can iterate over runs while
keeping the layer ﬁxed, then handle another layer and again
iterate over runs.

The source of Zebra’s ﬂexibility is that in both execution and

proving, there are narrow, predictable dependencies between
layers (which itself stems from OptimizedCMT’s requirement
to use a layered AC). As previously mentioned, a sub-prover
must buffer the results of executing a layer until the sub-prover
has executed the corresponding proof step. P’s total buffer
size is the number of in-ﬂight runs times the size of C .
Gate-level parallelism. Within a sub-prover, and within a
sumcheck round, there is parallel proving work not only for
each gate (as in prior work [108]) but also for each (gate, k)
pair, for k = {0,1,2}. That is, in Zebra, the loops in lines 15
and 16 (Figure 2) are combined into a “parallel for all (g,k)”.
This is feasible because, loosely speaking, sharing state read-
only among modules requires only creating wires, whereas in
a traditional memory architecture, accesses are serialized.

(cid:3)=1

The computation of termP (line 22) is an example. To ex-
plain it, we ﬁrst note that each gate prover stores state, which
we notate Pg. Now, for a gate prover g, let s = (g, gL, gR),
where gL,gR are the labels of g’s inputs in C . (We have used
g to refer both to a gate and the gate prover for that gate;
throughout our description, each gate prover will be numbered
and indexed identically to its corresponding gate in C .) Pg
χs[(cid:3)](q[1], . . . ,q[b]); at the end of a sum-
is initialized to ∏b
check round j, each gate prover updates Pg by multiplying it
with χs[b+ j](r[ j]). At the beginning of a round j, Pg is shared
among the (g,0), (g,1), and (g,2) functional blocks, permit-
ting simultaneous computation of termP (by multiplying Pg
with χs[b+ j](k)).
Removing the ˜Vi(w2), . . . , ˜Vi(wb) bottleneck. At the end of
a sumcheck invocation, the prover has an apparent bottleneck:
computing ˜Vi(w2), . . . , ˜Vi(wb) (line 50 in Figure 2). However,
Zebra observes that these quantities can be computed in paral-
lel with the rest of the invocation, using incremental computa-
tion and local state. To explain, we begin with the form of ˜Vi:5

˜Vi(q) =

G
∑
g=1

Vi(g)

b
∏
(cid:3)=1

χg[(cid:3)](q[(cid:3)]),

(2)

[108]

Prior work

where q ∈ Fb, g[(cid:3)] is the (cid:3)th bit of the binary expansion of gate
g, and q[(cid:3)] is the (cid:3)th component of q.
of
performs
evaluations
˜Vi(w2), . . . , ˜Vi(wb) using O(G· logG) operations, at
the
end of a sumcheck invocation. Indeed, at ﬁrst glance, the
required evaluations seem as though they can be done only
after line 42 (Figure 2) because for t > 2, wt depends on
w0,w1 (via wt ← (w1 − w0) · t + w0), which are not fully
available until the end of the outer loop.

the

However, we observe that all of w0 is available after round b,
and w1 is revealed over the remaining rounds. Zebra’s prover
exploits this observation to gain parallelism. The tradeoff is
more work overall: (b−1)· G· b products, or O(G· log 2G).
5One knows that ˜Vi, the multilinear extension of Vi, has this form because this
expression is a multilinear polynomial that agrees with Vi everywhere that Vi
is deﬁned, and because multilinear extensions are unique.

766766

(cid:3)=1

(cid:3)=1

In detail, after round b + 1, P has w1[1] (because this is
just r[b+1], which is revealed in line 41, Figure 2). P also
has w0[1] (because w0 has been fully revealed). Thus, P has,
or can compute, w0[1], . . . ,wb[1] (by deﬁnition of wt). Given
these, P can compute Vi(g)· χg[1] (wt [1]), for g ∈ {1, . . . ,G}
and t ∈ {2, . . . ,b}.
Similarly, after round b + 2, r[b+2] is revealed; thus, us-
ing the (b − 1) · G products from the prior round, P can
perform another (b − 1) · G products to compute Vi(g) ·
χg[(cid:3)] (wt [(cid:3)]), for g ∈ {1, . . . ,G}, t ∈ {2, . . . ,b}. This pro-
∏2
cess continues, until P is storing Vi(g)· ∏b
χg[(cid:3)] (wt [(cid:3)]), for
all g and all t, at which point, summing over the g is enough
to compute ˜Vi(wt ), by Equation (2).

j−b−1
(cid:3)=1

Zebra’s design exploits this observation with G circular
shift registers. For each update (that is, each round j, j > b),
and in parallel for each g ∈ {1, . . . ,G}, Zebra’s sub-prover
reads a value from the head of the gth circular shift register,
multiplies it with a new value, replaces the previous head value
with the product, and then circularly shifts, thereby yielding
the next value to be operated on. For each g, this happens
b− 1 times per round, with the result that at round j, j > b,
Vi(g)· ∏
χg[(cid:3)] (wt [(cid:3)]) is multiplied by χg[ j−b](wt [ j−b]),
for g ∈ {1, . . . ,G}, t ∈ {2, . . . ,b}. At the end, for each t, the
sum over all g uses a tree of adders.
3.3 Extracting and exploiting locality
Locality of data. Zebra’s sub-prover must avoid RAM, be-
cause it would cause serialization bottlenecks. Beyond that,
Zebra must avoid globally consumed state, because it would
add global communication, which has the disadvantages noted
earlier. These points imply that, where possible, Zebra should
maintain state “close” in time and space to where it is con-
sumed; also, the paths from producer-to-state, and from state-
to-consumers should follow static wiring patterns. We have
already seen two examples of this, in Section 3.2: (a) the Pg
values, which are stored in accumulators within the functional
blocks of the gate provers that need them, and (b) the circu-
lar shift registers. Below, we present a further example, as a
somewhat extreme illustration.

A key task for P in each round of the sumcheck protocol is
to compute termL and termR (lines 25 through 30, Figure 2),
by evaluating ˜Vi(·) at various points. Prior work [55, 108, 112]
performs this task efﬁciently, by incrementally computing a
basis: at the beginning of each round j, P holds a lookup
table that maps each of the 2b− j+1 hypercube vertexes Tj =
(t j, . . . ,tb) to ˜V (r[1], . . . ,r[ j−1], Tj), where t1, . . . ,tb denote
bits. (We are assuming for simplicity that j ≤ b; for j > b, the
picture is similar.) Then, for each (g,k), the required termL
can be read out of the table, by looking up the entries indexed
by (k, gL[ j+1], . . . ,gL[b]) for k = 0,1.6 This requires updating,
and shrinking, the lookup table at the end of each round, a
step that can be performed efﬁciently because for all Tj+1 =
6These values (multiplying one by 2 and the other by −1, and summing) also
yield termL for k = 2, which is a consequence of Equation (2).

(t j+1, . . . ,tb) ∈ Fb− j
˜Vi(r[1], . . . ,r[ j],Tj+1) =(1− r[ j])· ˜Vi(r[1], . . . ,r[ j− 1],0,Tj+1)

, Equation (2) implies:

2

+ r[ j]· ˜Vi(r[1], . . . ,r[ j− 1],1,Tj+1).

Zebra must

implement equivalent

logic, meaning on-
demand “lookup” and incremental update, but without random-
access state. To do so, Zebra maintains 2b ≈ G registers; each
is initialized as in prior work, with ˜Vi(t1, . . . ,tb) = Vi(t1, . . . ,tb),
for all (t1, . . . ,tb) ∈ Fb
2. The update step relies on a static wiring
pattern: roughly speaking, each entry T is updated based on
2T and 2T + 1. Then, for the analog of the “lookup,” Zebra
delivers the basis values to the gate provers that need them.
This step uses what we call a shufﬂe tree: a tree of multiplexers
in which the basis values are inputs to the tree at multiple lo-
cations, and the outputs are taken from a different level of the
tree at each round j. The effect is that, even though the basis
keeps changing—by the end, it is only two elements—the
required elements are sent to all of the gate provers.
Locality of control. Zebra’s prover must orchestrate the work
of execution and proving. The naive approach would be a
top-level state machine controlling every module. However,
this approach would destroy locality (control wires would be
sent throughout the design) and create inefﬁciencies (not all
modules have the same timing, leading to idling and waste).
Instead, Zebra’s prover has a latency-insensitive design.
There is a top-level state machine, but it handles only natural
serialization points, such as communication with the veriﬁer.
Otherwise, Zebra’s modules are arranged in a hierarchical
structure: at all levels of the design, parents send signals to
children indicating that their inputs are valid, and children
produce signals indicating valid outputs. These are the only
timing relations, so control wires are local, and go only where
needed. As an example, within a round of the sumcheck proto-
col, a sub-prover instructs all gate provers g to begin executing;
when the outputs are ready, the sub-prover feeds them to an
adder tree to produce the required sum (line 38, Figure 2).
Even though gate provers complete their work at different
times (owing to differences in, for example, mult and add), no
additional control is required.
3.4 Reusing work
We have already described several ways in which a Zebra
sub-prover reuses intermediate computations. But Zebra’s sub-
provers also reuse modules themselves, which saves area. For
example, computing each of Fj(0),Fj(1),Fj(2) uses an adder
tree, as does computing ˜Vi(w2), . . . , ˜Vi(wb) (§3.2). But these
quantities are never needed at the same time during the proto-
col. Thus, Zebra uses the same adder tree.

Something else to note is that nearly all of the sub-prover’s
work is ﬁeld operations; indeed, all multiplications and addi-
tions in the algorithm, not just the AC C , are ﬁeld operations.
This means that optimizing the circuits implementing these
operations improves the performance of every module of P.

767767

3.5 Design of V
In many respects, the design of Zebra’s veriﬁer is similar
to the prover; for example, the approach to control is the
same (§3.3). However, the veriﬁer cannot adopt the prover’s
pipeline structure: for the veriﬁer, different layers impose very
different overheads. Speciﬁcally, the veriﬁer’s ﬁrst and last
layers are costly (lines 55, 73 in Figure 2), whereas the interior
layers are lightweight (§2.2).

To address this issue, Zebra observes that the work of the
ﬁrst and last layers can happen in parallel; this work deter-
mines the duration of a pipeline stage’s execution. Then, within
that duration, interior layers can be computed sequentially. For
example, two or more interior layers might be computed in the
time it takes to compute just the input or output layer; the exact
ratio depends on the length of the input and output, versus
logG. As noted earlier (§3.2), sequential work enables area
savings; in this case the savings do not detract from throughput
because the input and output layers are the bottleneck.
4 System architecture
This section articulates several challenges of system architec-
ture and operation, and walks through Zebra’s responses.
V -P integration. The default
integration approach—a
printed circuit board—would limit bandwidth and impose
high cost in energy for communication between V and P.
This would be problematic for Zebra because the protocol
contains a lot of inter-chip communication (for P, it is lines 8,
40, 41, 47, and 50; for V , lines 67, 71, 82, 87, and 99). Zebra’s
response is to draw on 3D packaging [75, 79], a technology
that enables high bandwidth and low energy communication
between chips (§7.1).

Is it reasonable to assume that the integrator (§2.1) has
access to 3D packaging? We think yes: the precision require-
ments for 3D packaging are much less than for a transistor
even in a very mature technology node. Moreover, this tech-
nology is commercially available and used in high-assurance
contexts [13], albeit for a different purpose [70]. Finally, al-
though 3D packaging is not yet in wide use, related packaging
technologies are in high-volume production for commodity
devices like inertial sensors and clock generators [90, 94].
Precomputation and amortization. All built systems for
veriﬁable computation, except CMT applied to highly reg-
ular ACs, presume ofﬂine precomputation on behalf of the
veriﬁer that exceeds the work of simply executing the compu-
tation [24, 25, 29, 31–33, 41, 51, 55, 56, 58, 59, 61, 76, 88, 98–
101, 106, 108, 112, 114]. They must therefore—if the goal is
to save the veriﬁer work—amortize the precomputation in one
way or another. In Zebra, the precomputation is generating an
auxiliary input (§2.2), which the operator supplies to V along
with the input x. This arrangement raises two questions, which
we answer below: (1) How does the operator get auxiliary
inputs? (2) How does the work of generating them amortize?
We assume that the operator is given auxiliary inputs by

the integrator on a bulk storage medium (for example, a hard
drive). When all auxiliary inputs on the medium are consumed,
the integrator must securely refresh them (for example, by
delivering another drive to the operator). The integrator must
thus select the storage size according to the application. For
example, at a throughput of 104 executions per second, and 104
bytes per auxiliary input, a 10TB drive sufﬁces for 24 hours of
continuous operation. Note that one store of precomputations
can be shared among many instances of Zebra operating in
close proximity (for example, in a data center).

As an optimization, an auxiliary input does not explicitly
materialize τi,w0, and w1 for each layer (§2.2). Instead, V
rederives them from a pseudorandom seed that is included in
the auxiliary input. This reduces V ’s storage costs by roughly
2/3, to d · (logG + 2) + 1 ﬁeld elements per auxiliary input.

To amortize the integrator’s precomputation, Zebra pre-
sumes that the integrator reuses the precomputations over
many V ; for example, over all V chips that are currently mated
with a given P design.7 Since precomputing an auxiliary in-
put requires O(d · G) computation with good constants (§2.2),
the overhead can be amortized to negligible across an entire
deployment provided that there are, say, a few thousand oper-
ating veriﬁers. This assumes that the execution substrate for
the precomputation is similar to V .

Preserving soundness in this regime requires that each
prover chip in an operator’s system is isolated, a stipulation of
the setup (§2.1). We further assume that operators run indepen-
dently of one another, and that operators deploying multiple
provers handle failures carefully. Speciﬁcally, if a veriﬁer V
rejects, then the auxiliary inputs that V has seen must now be
viewed as disclosed, and not reused within the deployment.
To explain, note that a prover P(cid:2) can make its veriﬁer, V(cid:2),
reject in a way that (say) correlates with the challenges that V(cid:2)
has sent. Meanwhile, if failed interactions inﬂuence the inputs
received by other V -P pairs, then P(cid:2) has a (low-bandwidth)
way to communicate information about challenges it has seen.8
If V(cid:2)’s previously consumed auxiliary inputs continued to be
used, then this channel would (slightly) reduce soundness.
Storing precomputations. The privacy and integrity of V ’s
auxiliary inputs must be as trustworthy as V itself. Yet, storing
auxiliary inputs in trustworthy media could impose enormous
cost. Zebra’s solution is to store auxiliary inputs in untrusted
media (for example, a commercial hard drive) and to protect
them with authenticated encryption. To this end, V and the
integrator share an encryption key that V stores in a very
small on-chip memory. When the integrator carries out its
precomputation, it encrypts the result before storing it; upon

7Allspice, for example, handles the same issue with batch veriﬁcation [112,
§4]: the evaluations, and the random values that feed into them, are reused
over parallel instances of the proof protocol (on different inputs). But batch
veriﬁcation, in our context, would require P to store intermediate gate
values (§3.2) for the entire batch.
8This channel is not covert: failures are noticeable to the operator. However,
if the operator expects some random hardware faults, cheating chips may try
to hide a low-bandwidth communication channel in such faults.

768768

receiving an auxiliary input, V authenticates and decrypts,
rejecting the protocol run if tampering is detected. Note that
Zebra does not need ORAM: the pattern of accesses is known.
V ’s interface to the operator. V needs a high-performance
I/O interface to the operator to receive inputs (x) and aux-
iliary inputs, and send outputs (y), at throughput T . This
requires bandwidth T · (|x| +|y| + d · (logG + 2) + 1), some
tens or hundreds of megabits per second. Both area (for V ’s
transceiver circuit) and energy (per bit sent) are concerns; Ze-
bra’s response is to use a high-performance optical backplane,
which gives both good bandwidth per transceiver area and
low, distance-insensitive energy cost [27, 87, 97]. While this
technology is not yet widespread in today’s datacenters, its use
in high-performance computing applications [57, 71] indicates
a trend toward more general deployment.
5 Cost analysis and accounting
This section presents an analytical model for the energy (E),
area (As), and throughput (T ) of Zebra when applied to ACs of
depth d and width G. Figure 5 summarizes the model. It covers:
(1) protocol execution (compute; §2.2, Fig. 2); (2) communi-
cation between V and P (tx; §2.2); (3) storage of auxiliary
inputs for V , including retrieval, I/O, and decryption for V
(store; §4); (4) storage of intermediate pipeline values for
P (store; §3.2); (5) pseudorandom number generation for
V (PRNG; §4); and (6) communication between V and the
operator (V I/O; §4). In Section 7.1, we derive estimates for
the model’s parameters using synthesis and simulation.

The following analogies hold: E captures the number of
operations done by each of components (1)–(6) in a single exe-
cution of OptimizedCMT; As roughly captures the parallelism
with which Zebra executes, in that it charges for the number of
hardware modules and how they are allocated; and T captures
the critical path of execution.
Energy and area costs. For both P and V , all computations
in a protocol run are expressed in terms of ﬁeld arithmetic
primitives (§3.4). As a result, ﬁeld operations dominate energy
and area costs for P and V (§7.2, §8). Many of Zebra’s de-
sign decisions and optimizations (§3) show up in the constant
factors in the energy and area “compute” rows.
Area and throughput trade-offs. Zebra’s throughput is de-
termined by the longest pipeline delay in either V or P; that
is, the pipeline delay of the faster component can be increased
without hurting throughput. Zebra can trade increased pipeline
delay for reduced area by removing functional units (e.g., sub-
provers) in either P or V (§3.2, §3.5). Such trade-offs are
typical in hardware design [84]; in Zebra, they are used to
optimize As/T by balancing V ’s and P’s delays (§7.4).

The model captures these trade-offs with particular param-
eters. For P, these parameters are nP,sc and nP,pl: the num-
ber of physical sub-prover modules and the number of in-
ﬂight runs (§3.2). For V , these parameters are nV ,sc and nV ,io:
roughly, the area apportioned to sumcheck work and comput-

cost
energy

compute
V -P tx
store
PRNG
V I/O

area

compute
V -P tx
store
PRNG
V I/O

(7d logG + 6G)Emul,t + (15d logG + 2G)Eadd,t

(2d logG + G)Etx,t
d logG· Esto,t
2d logG· Eprng,t
2G· Eio,t
(cid:3)

(cid:2)

(cid:3)

(cid:2)

nV ,sc

2Amul,t + 3Aadd,t

Amul,t + Aadd,t

+ 2nV ,io
(2d logG + G)Atx,t
d logG· Asto,t
2d logG· Aprng,t
2G· Aio,t
(cid:3)
(cid:9)(cid:3)
(cid:8)
+(cid:4)(7 + logG) /2(cid:5)λmul,t + 4λadd,t
λmul,t + 2λadd,t
λmul,t +
lognV ,io

λadd,t

(cid:10)

(cid:9)

(cid:2)

(cid:3)

,

(cid:2)

(cid:7)
(cid:2)(cid:8)

max

d/nV ,sc

2logG

3G/nV ,io + lognV ,io

dGlog 2G· Emul,u + 9dGlogG· Eadd,u + 4dGlogG

(7d logG + G)Etx,u
dG· nP,pl · Esto,u

(cid:6)

(cid:5)

Eg,u

nP,sc

(cid:2)
7G· Amul,u +(cid:14)7G/2(cid:15)· Aadd,u
(7d logG + G)Atx,u
dG· nP,pl · Asto,u

(cid:3)

—
—

—
—

(cid:11)
(cid:5)

d/nP,sc

(cid:2)

(cid:3)(cid:12)

3log 2G· λadd,u + 18logG
(cid:6)
: mean per-gate energy of C , untrusted
Eg,u
d,G: depth and width of arithmetic circuit C

λmul,u + λadd,u

veriﬁer

prover

delay: Zebra’s overall throughput is 1/max (P delay, V delay); the expressions for P and V delay are given immediately below:

nV ,io: V parameter; trades area vs i/o delay
nV ,sc: V parameter; trades area vs sumcheck delay
E{add,mul,tx,sto,prng,io},{t,u}: energy cost in {trusted, untrusted} technology node for {+, ×, V -P interaction, store, PRNG, V I/O}
A{add,mul,tx,sto,prng,io},{t,u}: area cost in {trusted, untrusted} technology node for {+, ×, V -P interaction, store, PRNG, V I/O}
λ{add,mul},{t,u}: delay in {trusted, untrusted} technology node for {+, ×}

nP,pl: P parameter; # in-ﬂight runs
nP,sc: P parameter; trades area vs delay

FIGURE 5—V and P costs as a function of C parameters and technology nodes (simpliﬁed model; low-order terms discarded). We assume
|x| = |y| = G. Energy and area constants for interaction, store, PRNG, and I/O indicate costs for a single element of Fp. V -P tx is the cost
of interaction between V and P; V I/O is the cost for the operator to communicate with Zebra (§4). For P, store is the cost of buffering
pipelined computations (§3.2); for V , it is the cost to retrieve and decrypt auxiliary inputs (§4). Transmit, store, and PRNG occur in parallel
with execution, so their delay is not included, provided that the corresponding circuits execute quickly enough (§5, §7.1). Physical quantities
depend on both technology node and implementation particulars; we give values for these quantities in Section 7.1.

ing multilinear extensions of x and y, respectively (§3.5). In
our evaluation we constrain these parameters to keep area at
or below some ﬁxed size, for manufacturability (§2.3).
Storage versus precomputation. With regard to V ’s auxil-
iary inputs, the cost model accounts for retrieving and decrypt-
ing (§4); the cost of precomputing, and its amortization, was
covered in Section 4.

Implementation of Zebra

6
Our implementation of Zebra comprises four components.

The ﬁrst is a compiler toolchain that produces P. The
toolchain takes as input a high-level description of an AC
(in an intermediate representation emitted by the Allspice
compiler [1]) and designer-supplied primitive blocks for ﬁeld
addition and multiplication in Fp; the toolchain produces a
synthesizable SystemVerilog implementation of Zebra. The
compiler is written in C++, Perl, and SystemVerilog (making
heavy use of the latter’s metaprogramming facilities [7]).

Second, Zebra contains two implementations of V . The
ﬁrst is a parameterized implementation of V in SystemVer-
ilog. As with P, the designer supplies primitives for ﬁeld
arithmetic blocks in Fp. Additionally, the designer selects the
parameters nV ,sc and nV ,io (§5, §7.4). The second is a software
implementation adapted from Allspice’s veriﬁer [1].

Third, Zebra contains a C/C++ library that implements V ’s
input-independent precomputation for a given AC, using the
same high-level description as the toolchain for P.

Finally, Zebra implements a framework for cycle-accurate

RTL simulations of complete interactions between V and
P. It does so by extending standard RTL simulators. The
extension is an interface that abstracts communication between
P and V (§2.2), and between V and the store of auxiliary
inputs (§4). This framework supports both the hardware and
software implementations of V . The interface is written in
C using the Verilog Procedural Interface (VPI) [7], and was
tested with the Cadence Incisive [3] and Icarus Verilog [6]
RTL simulators.

In total, our implementation comprises approximately 6000
lines of SystemVerilog, 10400 lines of C/C++ (partially in-
herited from Allspice [1]), 600 lines of Perl, and 600 lines of
miscellaneous scripting glue.

7 Evaluation
This section answers: For which ACs can Zebra outperform
the native baseline? Section 8 makes this evaluation concrete
by comparing Zebra to real-world baselines for speciﬁc appli-
cations. In sum, Zebra wins in a fairly narrow regime: when
there is a large technology gap and the computation is large.
These conclusions are based on the cost model (§5), recent
ﬁgures from the literature, standard CMOS scaling models,
and dozens of synthesis- and simulation-based measurements.
Method. Zebra’s implementation (§6) allows us to evaluate
using both synthesis experiments and cycle-accurate simula-
tions. However, this approach comes with a practical limita-
tion: synthesizing and simulating even a moderately sized chip
design can take thousands of core-hours; meanwhile the aim

769769

350 nm (V )

45 nm (P)

Fp + Fp

Fp × Fp
energy (nJ/op)
0.21
69× 103
area (μm2)
delay (ns)
FIGURE 6—Synthesis data for ﬁeld operations in Fp, p = 261 − 1.

Fp × Fp
220
27× 105

Fp + Fp
0.006
6.5× 103

3.1

2.1× 105

6.2

26

0.7

2.3

350 nm (V )

45 nm (P)

pJ/Fp
1100
48× 103
8700
4200

μm2/(Fp/ns)

3400
380× 106
17× 106
2× 106

pJ/Fp
600
4.2
—
—

V -P tx
store
PRNG
V I/O

μm2/Fp
1900· ns

80
—
—

FIGURE 7—Costs for communication, storage (including decryption,
for V ; §4), and PRNG; extrapolated from published results [27, 66,
68, 75, 79, 87, 89, 93, 97, 109] using standard scaling models [67].

here is to characterize Zebra over a wide range of ACs. Thus,
we leverage the analytical cost model described in Section 5.
We do so in three steps.

First, we obtain values for the parameters of this model by
combining synthesis results with data published in the litera-
ture (§7.1). Second, we validate the cost model by comparing
predictions from the model with both synthesis results and
cycle-accurate simulations; these data closely match the an-
alytical predictions (§7.2). Third, we estimate the baseline’s
costs (§7.3) and then use the validated cost model to measure
Zebra’s performance relative to the baseline, across a range of
arithmetic circuit and physical parameters (§7.4).

7.1 Estimating cost model parameters
In this section, we estimate the energy, area, and delay of
Zebra’s basic operations (§5, (1)–(6)).
Synthesis of ﬁeld operations. Figure 6 reports synthesis data
for both ﬁeld operations in Fp, p = 261−1, which admits an ef-
ﬁcient and straightforward modular reduction. Both operations
were written in Verilog and synthesized to two technology li-
braries: Nangate 45 nm Open Cell [8] and a 350 nm library
from NC State University and the University of Utah [9]. For
synthesis, we use Cadence Encounter RTL Compiler [3].
Communication, storage, and PRNG costs. Figure 7 re-
ports area and energy costs of communication, storage, and ran-
dom number generation using published measurements from
built chips. Speciﬁcally, we use results from CPUs built with
3D packaging [75, 79], SRAM designs [89], solid-state stor-
age [53, 93], ASICs for cryptographic operations [66, 68, 109],
and optical interconnects [27, 87, 97].

For all parameters, we use standard CMOS scaling models

to extrapolate to other technology nodes for evaluation.9

logG

measured

predicted

area
(mm2)

delay
(cycles)

+,× ops

4
5
6
7

4
5
6
7

4
5
6
7

8.76
17.06
33.87
66.07

682
896
1114
1358

9.42
18.57
36.78
73.11

681
891
1115
1353

901, 1204
2244, 3173
5367, 8006
12494, 19591

901, 1204
2244, 3173
5367, 8006
12494, 19591

error

+7.6%
+8.8%
+8.6%
+11%

-0.2%
-0.6%
+0.1%
-0.4%

0%
0%
0%
0%

FIGURE 8—Comparison of cost model (§5) with measured data.
Area numbers come from synthesis; delay and operation counts come
from cycle-accurate RTL simulation.

7.2 Validating the cost model
We use synthesis and simulation to validate the cost model (§5).
To measure area, we synthesize sub-provers (§3.1) for AC lay-
ers over several values of G. To measure energy and through-
put, we perform cycle-accurate RTL simulations for the same
sub-provers, recording the pipeline delay (§5, Fig. 5) and the
number of invocations of ﬁeld addition and multiplication.10
Figure 8 compares our model’s predictions to the data ob-
tained from synthesis and simulation. The model predicts
slightly greater area than the synthesis results show. This is
likely because, in the context of a larger circuit, the synthesizer
has more information (e.g., related to critical timing paths) and
thus is better able to optimize the ﬁeld arithmetic primitives.
Although we have not presented our validation of V ’s costs,

its cost model has similar ﬁdelity.

7.3 Baseline: native trusted implementations
For an arithmetic circuit with depth d, width G, and a fraction
δ of multiplication gates, we estimate the costs of directly
executing the AC in the trusted technology node. To do so, we
devise an optimization procedure that minimizes A/T (under
the constraint that total area is limited to some Amax; §2.3).
Since this baseline is a direct implementation of the arith-
metic circuit, we account E as the sum of the energy for each
operation in the AC, plus the energy for I/O (§4).

Optimization proceeds in two steps. In the ﬁrst step, the
procedure apportions area to multiplication and addition prim-
itives, based on δ and on the relative time and area cost of
each operation. In the second step, the procedure chooses a
pipelining strategy that minimizes delay, subject to sequencing
requirements imposed by C ’s layering.

It is possible, through hand optimization, to exploit the
structure of particular ACs in order to improve upon this op-

9A standard technique in CMOS circuit design is projecting how circuits will
scale into other technology nodes. Modeling this behavior is of great practical
interest, because it allows accurate cost modeling prior to designing and
fabricating a chip. As a result, such models are regularly used in industry [67].

10We use the number of ﬁeld operations as a proxy for the energy consumed
by P’s sub-provers in executing the protocol. This gives a good estimate
because (1) the sub-prover’s area is dominated by these circuits (Fig. 8),
and (2) the remaining area of each sub-prover is dedicated to control logic,
which includes only slowly-varying signals with negligible energy cost.

770770

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o

f
r
e
P

)
r
e

t
t

e
b
 
s
i
 
r
e
h
g
h
(
 

i

e
n

i
l

e
s
a
b

3

1

0.3

 

8

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o
f
r
e
P

)
r
e

t
t

e
b
 
s
i
 
r
e
h
g
h
(
 
e
n

i

i
l

e
s
a
b

3

1

0.3

 

 

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3
28
12
32
d, depth of arithmetic circuit

16

20

24

(a) Performance vs. d.

 

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o

f
r
e
P

)
r
e

t
t

e
b

 
s
i
 
r
e
h
g
h
(
 
e
n

i

i
l

e
s
a
b

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o
f
r
e
P

)
r
e

t
t

e
b
 
s
i
 
r
e
h
g
h
(
 
e
n

i

i
l

e
s
a
b

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o

f
r
e
P

)
r
e

t
t

e
b

 
s
i
 
r
e
h
g
h
(
 
e
n

i

i
l

e
s
a
b

3

1

0.3

 

 

 

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3

6

14

10

22
log2 G, width of arithmetic circuit
(b) Performance vs. G.

18

3

1

0.3

 

3

1

0.3

0.1

0.03

0.01

 

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3

 

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3

0.2

0.4

0.6

0.8

δ, fraction of multipliers in arithmetic circuit

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o
f
r
e
P

)
r
e

t
t

e
b
 
s
i
 
r
e
h
g
h
(
 

i

e
n

i
l

e
s
a
b

(c) Performance vs. δ .

 

3

1

0.3

 

5 20

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3

80

50
maximum chip area, mm2

110 140 170 200

(f) Performance vs. maximum chip area.

180

250

350

trusted process technology, nm
(d) Performance vs. trusted node.

500

7

14

22

35

45

untrusted process technology, nm
(e) Performance vs. untrusted node.

FIGURE 9—Zebra performance relative to baseline (§7.3) on E and As/T metrics (§2.3), varying C parameters, technology nodes, and
maximum chip area. In each case, we vary one parameter and ﬁx the rest. Fixed parameters are: trusted technology node = 350 nm; untrusted
technology node = 7 nm; depth of C , d = 20; width of C , G = 214; fraction of multipliers in C , δ = 0.5; maximum chip area, Amax = 200 mm2;
maximum power dissipation, Pmax = 150 W. In all cases, designs follow the optimization procedures described in Sections 7.1–7.3.

timization procedure, but our goal is a procedure that gives
good results for generic ACs. We note that our optimization
procedure is realistic: it is roughly similar to the one used by
automated hardware design toolkits such as Spiral [84].

7.4 Zebra versus baseline

This section evaluates the performance of Zebra versus the
baseline, on the metrics E and As/T , as a function of C pa-
rameters (width G, depth d, fraction of multiplication gates δ ),
technology nodes, and maximum allowed chip size. We vary
each of these parameters, one at a time, ﬁxing others. Fixed
parameters are as follows: d = 20, G = 214, δ = 0.5, trusted
technology node = 350 nm, untrusted technology node = 7 nm,
and Amax = 200 mm2. We limit Zebra to no more than
Pmax = 150 W, which is comparable to the power dissipation
of modern GPUs [2, 5], and we vary s ∈ {1/3,1,3,10} (§2.3).
For each design point, we ﬁx V ’s area equal to the native
baseline area, and set nP,pl = d. We then optimize nP,sc, nV ,io,
and nV ,sc (§5, Fig. 5). To do so, we ﬁrst set nV ,io and nV ,sc
to balance delay among V ’s layers (§3.5), and to minimize
these delays subject to area limitations. We choose nP,sc so
that P’s pipeline delay is less than or equal to V ’s.

Figure 9 summarizes the results. In each plot, the break-
even point is designated by the dashed line at 1. We observe
the following trends:

771771

• As C grows in size (Figs. 9a, 9b) or complexity (Fig. 9c),
Zebra’s performance improves compared to the baseline.
• As the performance gap between the trusted and untrusted
technology nodes grows (Figs. 9d, 9e), Zebra becomes
increasingly competitive with the baseline, in both E and
As/T .

• As G grows, P’s area increases (§5, Fig. 5), making As/T
worse even as E improves (Fig. 9b). This is evident in the
s = 1/3 curve, which is highly sensitive to P’s area.

• Finally, we note that Zebra’s competitiveness with the base-
line is relatively insensitive to maximum chip area (Fig. 9f).

7.5 Summary
We have learned several things:

Zebra beats the baseline in a narrow but distinct regime. In
particular, Zebra requires more than a decade’s technology gap
between V and P. Zebra also requires that the computation is
“hard” for the baseline, i.e., it involves tens of thousands of op-
erations (Figs. 9a, 9b), with thousands of expensive operations
per layer (Figs. 9b, 9c). At a high level, the technology gap
offsets P’s proving costs, while “hard” computations allow
V ’s savings to surpass the overhead of the protocol (§2.2).

The price of veriﬁability is high. Even when Zebra breaks
even, it is orders of magnitude more costly than executing Ψ
on an untrusted technology node.

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o

f
r
e
P

)
r
e

t
t

e
b
 
s
i
 
r
e
h
g
h
(
 

i

e
n

i
l

e
s
a
b

3

1

0.3

0.1

 

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3

 

6

7

9

8
log2(NTT size)

10 11 12 13

FIGURE 10—Zebra performance relative to baseline (§8.1) on E and
As/T metrics (§2.3), for NTT with a given number of points, over
Fp, p = 263 + 219 + 1. Untrusted technology node = 350 nm; trusted
technology node = 7 nm; maximum chip area, Amax = 200 mm2.

But “there are no hidden fees” (we hope). Although the
stated price is high, we have endeavored to account for all of
the costs that we could think of. Thus, when a computation
falls into Zebra’s break-even zone—as with the examples in
the next section—we can, with reasonable conﬁdence, claim a
genuine win.
8 Applications
This section evaluates Zebra on two concrete computations:
the number theoretic transform over Fp, and Curve25519 point
multiplication.

(cid:7)

8.1 Number theoretic transform over Fp
The number theoretic transform (NTT) is a linear transform
closely related to the FFT. Its input is x = {a0, . . . ,aN−1}, the
(cid:10)
coefﬁcients of a degree N − 1 polynomial p(t); its output is
p(ω0), . . . , p(ωN−1)
, where ω is a primitive Nth root
y =
of unity in Fp. This transform is widely used in signal pro-
cessing, computer algebra packages [103], and even in some
cryptographic algorithms [20].

The fastest known algorithm is iterative, and uses a se-
quence of butterﬂy operations [54, Ch. 30]. A butterﬂy
takes as input x1,x2 ∈ Fp, and outputs y1 = ωi (x1 + x2) and
y2 = ω j (x1 − x2) for some i, j ∈ {0, . . . ,N − 1}.
Implementing NTT in Zebra
The iterative NTT is essentially an arithmetic circuit. However,
if implemented naively in Zebra, that AC would introduce over-
head. The core issue is that, if the AC uses add and multiply
gates, then the x1 − x2 term in a butterﬂy would be computed
as −1× x2, followed by an addition in the next layer.
To avoid increasing the depth of the AC, we take inspi-
ration from CMT’s enhanced gates [55, §3.2] and introduce
subtraction gates. For P, this change implies a new type
of gate prover (§3.1). For V , we deﬁne a new wiring predi-
˜subi; at the end
cate (§2.2), subi, and its multilinear extension,
of each sumcheck invocation (line 100, Fig. 2), V adds the
term ˜subi(qi−1, w0, w1) (h0 − h1). Accordingly, an auxiliary
input includes d more precomputed values (§2.2, §4).

N = 26

N = 210

V

P

V

cost
energy, μJ
compute
V -P tx
store
PRNG
V I/O
area, mm2
compute
V -P tx
store
PRNG
V I/O
delay, μs
n{V ,P},sc

370
0.29
8.6
1.7
0.58

44

< 0.1

24
1.3
0.2

3.1
4
3
—

0.21
0.42
0.11
—
—

2.8
< 0.1
< 0.1

—
—

2700
1.7
19
4.3
8.9

51

< 0.1

9
0.5
0.3

3.1
2
—
12

20
2
6
—

N = 213

V

17 000

10
29
7
71

P

150
6.7
65
—
—

P

10
1.6
4.8
—
—

22

< 0.1
1.6
—
—

51

< 0.1

2
0.1
0.3

175
< 0.1

22
—
—

18
1
—
20

133
1
7
—

32.9

1
—
26

nV ,io
nP,pl
total power, W 121
FIGURE 11—Costs for N-point NTT (§8.1), N ∈ {26,210,213}.

140

133

Another issue is that computing a length-N NTT requires
N/2 powers of ω; thus, an implementation must either receive
these values as inputs or compute them directly. Because V ’s
costs scale linearly with the number of inputs but only logarith-
mically with the size of each layer of C (§2.2, §5), computing
powers of ω in C is the natural approach—but doing so naively
at least doubles the depth of C , erasing any savings. Instead,
Zebra’s C takes as input logN values, {ω,ω2,ω4,ω8, . . .},
and C computes other powers of ω just as they are needed.
This approach reduces costs by 25% or more compared to
taking powers of ω as inputs, and it adds no additional layers
to the iterative NTT’s arithmetic circuit.
Evaluation
Baseline. The baseline is an arithmetic circuit implementing
the iterative algorithm for the NTT, optimized as described
in Section 7.3. We make the conservative assumption that
computing powers of ω is free for the baseline.
Method. We evaluate Zebra versus the baseline on the metrics
E and As/T , for length-N NTTs over Fp, p = 263 + 219 + 1.11
As in Section 7.4, we ﬁx trusted technology node = 350 nm,
untrusted technology node = 7nm, Amax = 200 mm2,
Pmax=150 W, nP,pl = d (§5). We vary s ∈ {1/3,1,3,10}, and
logN ∈ {6, . . . ,13}.
We generate Verilog for P and V using our compiler
toolchain and run cycle-accurate RTL simulations for sizes up
to logN = 6 (§6). We use these simulations to conﬁrm that the
cost model is calibrated for the new ﬁeld (§5, §7.2), and then
use the model to compute costs for larger N.
Comparison with baseline. Figure 10 depicts Zebra’s per-
formance relative to the baseline. As in Section 7.4, Zebra is
not competitive on E for small computations, but it equals or

11We use a different p from §7.1 because the NTT requires a ﬁeld with a
subgroup of size N. This is satisﬁed by p for logN ≤ 19, N a power of 2.

772772

 

K = 170

3

1

e
v
i
t

a
n
o

 

t
 

e
v
i
t

l

a
e
r
 
e
c
n
a
m
r
o

f
r
e
P

)
r
e

t
t

e
b

 
s
i
 
r
e
h
g
h
(
 
e
n

i

i
l

e
s
a
b

0.3

0.1

E
As/T, s=10
As/T, s=3
As/T, s=1
As/T, s=1/3
84   170 340
1147
Parallel Curve25519 point multiplications

682

 

FIGURE 12—Zebra performance relative to baseline (§8.2) on E
and As/T metrics (§2.3), versus number of parallel Curve25519
evaluations. Untrusted technology node = 350 nm; trusted technology
node = 7 nm; maximum chip area, Amax = 200 mm2.

exceeds the baseline when N is large enough; this is consistent
with V ’s asymptotic efﬁciency (§2.2). Relative As/T lags E
because the native computation is only about 30% multiplica-
tions (recall that Zebra’s performance suffers when there are
few multiplications; §7.4). Further, for large NTTs, P’s area
grows large; thus As grows, and As/T worsens.
Concrete costs. Figure 11 tabulates concrete costs for three
NTT designs: N = 26, N = 210, and N = 213. In all three cases,
most of the energy cost is in V ’s computation, because basic
operations are much more expensive in the trusted technology
node. In fact, this energy cost is high enough that it limits
V ’s throughput: it would be possible to add more compute
hardware to V (since its area is less than the maximum), but
doing so would increase T and thus exceed the power budget.
As N increases, V ’s throughput decreases, reducing the area
required for store and PRNG circuits (§4, §7.1). P’s area
requirement increases with N because the size of sub-provers
increases and because the required storage for pipelining in-
ﬂight runs increases (§3.2).

8.2 Curve25519 point multiplication
Curve25519 is a high-performance elliptic curve used in many
cryptographic protocols [14, 34]. An operation of interest for
hardware acceleration is point multiplication [21, Ch. 13].
This operation takes as inputs a 255-bit scalar value v and an
elliptic curve point Q, and computes the point R = [v]Q via a
sequence of 255 double-and-add steps [21], one for each bit
of v. (For efﬁciency and security, point multiplication uses a
Montgomery ladder [21, 34, 85].)
Efﬁcient point multiplication in Zebra
Double-and-add is naturally expressed as an arithmetic circuit
over Fp, p = 2255 − 19, with depth d = 7 and width G ≈ 8.
Thus, a full point multiplication (255 double-and-add steps) is
deep and narrow, both problems for Zebra (§7.4).

Thus, Zebra reformulates the AC, turning the long sequence
of double-and-add steps into shorter sequences. Speciﬁcally,
under Zebra, the depth of the AC is given by 5 double-and-
add steps, and computing a point multiplication requires

cost
energy, μJ
compute
V -P tx
store
PRNG
V I/O
area, mm2
compute
V -P tx
store
PRNG
V I/O
delay, μs
n{V ,P},sc

nV ,io
nP,pl

V

32 000

6
120
27
24

194
< 0.1
4.3
0.3
< 0.1
260
4
9
—

total power, W 123

P

250
8
4
—
—

55

< 0.1
2.2
—
—

190
2
—
35

K = 682

V

P

K = 1147
V

P

92 000

16
140
32
95

192
< 0.1
1.5
< 0.1
< 0.1
840
2
11
—

111

1300
14
15
—
—

110
< 0.1

9
—
—

450
1
—
35

145 000

25
150
35
160

175
< 0.1
0.9
< 0.1
< 0.1
1400

1
11
—

105

2500
19
26
—
—

185
< 0.1

15
—
—

490
1
—
35

FIGURE 13—Costs for Curve25519 (§8.2), for K = 170, K = 682,
and K = 1147 parallel sequences of 5 double-and-add operations.

51 (= 255/ 5) iterated protocol runs; the cost of this change
is that V handles inputs and outputs 51 times. And for width,
the AC contains many parallel double-and-add sequences.

Another issue with the double-and-add arithmetic circuit is
that it uses a “conditional swap” operation, interchanging two
values based on one bit of the scalar v. Conditional swap can be
implemented with only + and ×, but as with subtraction (§8.1),
a more efﬁcient alternative is to introduce a new type of gate,
a multiplexer or mux, which selects either its left or right input
based on a selector bit. The details of mux gates are described
in the extended version of this paper [113].

For efﬁciency, we require that all of the mux gates in any
layer of an arithmetic circuit share one selector bit. For point
multiplication, this means that all parallel double-and-add op-
erations in a protocol run must use the same scalar v. This
restriction is acceptable, for example, for TLS servers us-
ing ECDH_ECDSA key exchange [38], or whose ECDHE
implementations cache and reuse ephemeral keys for many
clients [11; 48, §4.2].

Evaluation
Baseline. Consistent with existing Curve25519 hardware im-
plementations [95, 96], the baseline directly executes a se-
quence of 255 double-and-add steps.
Method. We compare Zebra and the baseline on E and As/T ,
for designs that compute K parallel sequences of double-and-
add, K ∈ {84,170,340,682,1147}. The ﬁrst four values give
(cid:4)logG(cid:5) ∈ {7,8,9,10}; K = 1147 is the largest for which P
ﬁts into Amax. We ﬁx other parameters as in Section 8.1.

As in Sections 7 and 8.1, we synthesize ﬁeld addition and
multiplication primitives, and use cycle-accurate Verilog sim-
ulations to check the cost model’s calibration (§5, §7.2). We
then use the model to compute costs for large K.

773773

Comparison with baseline. Figure 12 depicts Zebra’s per-
formance relative to the baseline. As in previous experiments,
Zebra is competitive on E for large computations. Like NTT,
double-and-add is only about 30% multiplication gates; to-
gether with the area overhead due to P, Zebra is less compet-
itive on As/T , especially for small s.
Concrete costs. Figure 13 tabulates concrete costs for
K = 170, K = 682, and K = 1147. The costs are given for
a run of 5 double-and-add operations; a full point multiplica-
tion entails 51 runs. As in the NTT, V dominates energy cost.
However, in this application, V ’s performance is limited by
area rather than power dissipation because of the design of the
primitive circuits for p = 2255 − 19 ﬁeld operations.
9 Limitations and discussion
Zebra has clear limitations: the manufacturing and operational
requirements are unusual (§4); the overhead is high, compared
to untrusted execution; and, although some real computations
fall within its regime of applicability (§8), that regime is nar-
row (§7). Below, we contextualize these limitations, and then
address some loose ends in the cost analysis.
Zebra’s applicability in context. Recall that, even before
we considered Zebra’s break-even zone (§7), we narrowed
Zebra’s focus to computations Ψ that have natural expressions
as ACs (§2.2). What would happen if Ψ were a Boolean cir-
cuit, or a normal program over ﬁxed-width integers? Then, the
native version would run extremely efﬁciently on an ASIC
or CPU, so getting V ’s O(d · logG) running time to be con-
cretely lower would require an enormous G—in other words,
an unrealistically large number of parallel instances.

This limitation might seem overly restrictive, but something
similar applies to every built system for veriﬁable outsourc-
ing [24, 25, 29, 31–33, 41, 51, 55, 56, 58, 59, 61, 76, 88, 98–
101, 106, 108, 112, 114]. As an example, the state-of-the-art
SNARK implementation is libsnark [17, 33], which is an
optimized implementation of the GGPR-based [61] SNARK
in Pinocchio [88]. Disregarding precomputation and the cost
to handle inputs and outputs, libsnark’s minimum veriﬁca-
tion time is 6 ms on a 2.7 GHz CPU [114, §5.3]. For a native
computation to take longer than 6 ms on the same CPU re-
quires that it perform more than 16 million operations. But
the maximum problem size that libsnark can handle (on a
machine with 32 GB of memory) is 10 to 16 million opera-
tions [33, 114], so breaking even is nearly impossible unless
the operations in the original computation were non-native;
Fp operations work best.
(Some systems report beating native execution on 110×110
matrix multiplication [88], but our experiments—which use
a similar CPU (an Intel Core i5-4440), normal compiler ﬂags
(-O3), and standard environments—yield a sub-millisecond na-
tive cost for this computation, which is an order of magnitude
lower than the reported veriﬁcation time.)

In theory, these issues are surmountable. For example, the

scaling limit on GGPR-based SNARKs can be circumvented
by composition [32, 37, 56]. And, whereas OptimizedCMT is
limited to ACs that are deterministic and wide, GGPR-based
systems handle a much broader class of computations and
offer far more properties (§10). But implementing GGPR in
hardware proved to be a bottleneck, as we describe next.

Experience with other veriﬁable outsourcing machinery.
We began this project by studying machinery based on
GGPR [61], speciﬁcally the Zaatar [99] interactive argument
and the Pinocchio [88] SNARK (§10). However, despite sev-
eral months of work, we were unable to produce a physically
realizable design that achieved reasonable performance.

First, we found it difﬁcult to extract sufﬁcient parallelism. In
Zebra, sub-provers can be arranged in a pipeline because Opti-
mizedCMT’s interaction proceeds layer-by-layer, with narrow
dependencies (§3.2). In contrast, GGPR’s proofs are computed
in stages, but these stages operate over the entire execution of
C ; this made pipelining both difﬁcult and ineffective.

We also had trouble exploiting locality. As an example, both
OptimizedCMT and GGPR require the prover to evaluate poly-
nomials. In OptimizedCMT, these polynomials are small (total
degree at most O(logG); §2.2), and importantly, the evalua-
tions can be computed incrementally (§2.2, §3.3). Meanwhile,
GGPR’s prover both evaluates and interpolates polynomials
that are exponentially larger (total degree O(d · G)).

Finally, we found it difﬁcult to reuse modules in GGPR.
In Zebra this is possible because the prover’s work is just
ﬁeld operations (§3.4). GGPR, on the other hand, has greater
diversity of operations—FFTs and cryptographic primitives—
which have vastly different control and data ﬂow.

There remain other details of GGPR that we did not even
begin to address—for example, how the prover might han-
dle a common reference string with tens of millions of ﬁeld
elements. Of course, this does not imply that an efﬁcient hard-
ware implementation of GGPR is fundamentally out of the
question, and we hope that future work will produce one!

When CPUs are trusted. In evaluating Zebra, we did not
consider the natural baseline of executing Ψ on a CPU that
the principal trusts. This option has the usual advantages of
software: simplicity, ﬂexibility, no non-recurring costs (see
below), ease of programming, etc. If the principal trusts a
CPU in a state-of-the-art technology node, or if expressing
Ψ as an arithmetic circuit entails signiﬁcant overhead (§2.2),
executing Ψ directly on a trusted CPU is likely the best option.
However, the answer is less clear when the trusted CPU is in
a mature technology node and Ψ is naturally expressed as an
AC. Since this is Zebra’s approximate applicability regime,
meaning that Zebra outperforms a native ASIC in the trusted
technology node, Zebra most likely outperforms a CPU in
that same technology node (because ASICs far outperform
general-purpose CPUs).

Other alternative baselines exist; for example, execution
on an untrusted ASIC coupled with auditing or with later re-

774774

execution on a trusted processor. These approaches may be
appropriate in some settings; we leave their investigation and
evaluation to future work.
Non-recurring costs. The major non-recurring costs when
building ASICs are engineering effort and photolithographic
masks. To brieﬂy compare the baseline and Zebra, both need
designs and implementations—of Ψ and V , respectively—that
always work and have no defects. While we do not know the
exact costs of producing such golden implementations—this
is the province of trusted foundries [15, 45], which require
trusted designers, trusted mask productions, etc.—we are sure
that it isn’t cheap.

On top of this, Zebra incurs costs for the prover that are
likely to be high: in the latest technology nodes, a full mask
set costs several million dollars. On the other hand, Zebra has
an advantage that the baseline does not: the work to create V
amortizes over many computations, as explained shortly. Thus,
relative non-recurring costs roughly boil down to the baseline’s
golden Ψ versus Zebra’s untrusted P. We do not know which
one this comparison favors. We note that if the golden Ψ is
much more expensive, then one may wish to use Zebra, even
if it performs worse on the metrics evaluated earlier.
Using one V for different computations. The non-recurring
costs of producing V amortize over multiple computations
because the computation that V is verifying is conﬁgured after
manufacture. Speciﬁcally, the arithmetic circuit, C , appears in
V ’s workload only through the precomputed auxiliary inputs:
aside from line 100 in Figure 2, V ’s algorithm is independent
of C . (In fact, a slightly modiﬁed design for V might even
accept d, G, |x|, and |y| as run-time parameters.) As a result,
V has to be designed only once, or a small number of times
with different design parameters (§3.5,§5).
10 Related work
Zebra relates to two strands of work: defenses against hard-
ware Trojans and built systems for veriﬁable outsourcing.
Hardware Trojans. Tehranipoor and Koushanfar [105] have
surveyed the threat of hardware Trojans; Bhunia et al. [35]
have surveyed defenses. We follow the taxonomy of Bhunia
et al., in which defenses are classiﬁed as post-fabrication
detection, run-time monitoring, or design-time deterrence.

Post-fabrication is sub-divided into logic testing, side-
channel analysis, and golden reference. Logic testing works
within existing IC testing frameworks: these techniques exer-
cise the chip with certain inputs and verify that the outputs
are correct [42]. Wolff et al. [120] and Chakraborty et al. [47]
augment these tests with certain sequences of inputs (or “cheat
codes”), that are likely to trigger a Trojan. However, these
techniques do not provide comprehensive guarantees (untested
inputs could still produce incorrect outputs) or defend against
Trojans designed to stay dormant during post-fabrication test-
ing [105, 115] (for instance, those activated by internal timers).
Side-channel analysis aims to detect changes in the mea-

775775

sured delay and power of chips versus estimates obtained from
pre-fabrication simulations [26, 73, 77, 78, 119]. However,
the approach assumes that the impact of a Trojan on delay
and power is large enough to be distinguished from modeling
inaccuracies and from inherent variability in the chip fabrica-
tion process. Wei et al. [118] exploit this variability to evade
detection by such defenses.

Golden reference approaches [19] depackage, delayer, and
optically image (using a high resolution microscope) a subset
of chips to establish that they are Trojan free, and use the delay
and power proﬁles of these chips as “known good.” However,
such testing of large, complex ICs with billions of nanome-
ter sized transistors is expensive, error prone, and “stretches
analytical capabilities to the limits” [110]. Furthermore, this
approach assumes that malicious modiﬁcations are optically
observable in the ﬁrst place, for instance, as transistors or wires
added to or removed from the circuit. Meanwhile, Becker et
al. [28] design optically undetectable Trojans that change only
the doping concentration of a few transistors in the chip.

Waksman and Sethumadhavan [115] propose a run-time
defense: power cycle the chip in the ﬁeld (disabling timers),
and give the chip encrypted inputs (disabling hard-wired cheat
codes). However, computing on encrypted inputs could have
high cost; also, an adversary can still use a randomly chosen
input sequence, or a chip aging sensor [118].

Design-time techniques apply hardware obfuscation [46, 70,
92], normally used to protect intellectual property, to Trojan
deterrence, the assumption being that if the foundry cannot
infer the chip’s function, it cannot interfere with that function.
A separate line of research studies mechanisms to detect Tro-
jans inserted by a malicious designer pre-fab [104, 116]; this
is complementary to Zebra’s focus on an untrusted foundry.

In the taxonomy, Zebra can be understood as run-time moni-
toring. Compared to the techniques above, Zebra’s requirement
of a correctly manufactured and integrated veriﬁer (§9) may
be more burdensome. However, Zebra also provides much
stronger assurance: it defends against arbitrary misbehavior,
with a formal and comprehensive soundness guarantee.
Veriﬁable outsourcing. The last several years have seen a
ﬂurry of work in built systems based on probabilistic proof
protocols [24, 25, 29, 31–33, 41, 51, 55, 56, 58, 59, 61, 76,
88, 98–101, 106, 108, 112, 114] (see [117] for a survey). For
our present purposes, these works are in two categories. The
ﬁrst category descends from GKR’s [63] interactive proof (IP)
protocol, and includes CMT [55] and Allspice [112], both of
which Zebra builds on (§2.2). The second category includes
arguments: interactive arguments with preprocessing [99–101]
and non-interactive arguments with preprocessing [24, 32, 36,
61, 76, 88]. The latter are sometimes known as SNARKs, for
succinct non-interactive arguments of knowledge.

The IP-based schemes offer information-theoretic security
and, when applicable, have more efﬁcient veriﬁers, with low
(or no) precomputation costs. However, arguments work over
non-deterministic arithmetic circuits and hence apply to a

broader set of computations: ANSI C programs, RAM, cloud
applications, set computations, databases, etc. [24, 29, 31, 33,
41, 51, 56, 76, 114]. In addition, arguments have lower round
complexity than the IP schemes, and SNARKs go further:
they offer non-interactivity, zero knowledge, public veriﬁabil-
ity, etc. The trade-off is that arguments require cryptographic
assumptions (standard ones for interactive arguments, non-
falsiﬁable [86] ones for SNARKs). We were inspired by this
activity: as noted in Section 9, our initial objective was to
accelerate the GGPR/Pinocchio SNARK in hardware.

To our knowledge, there are no prior hardware implemen-
tations of probabilistic proof protocols. An intriguing middle
ground is the GPU implementation of CMT [108]. This work
exploits some of the parallelism in CMT (as noted in Figure 2
and Section 3.2), and achieves speedups versus a CPU imple-
mentation. However, Zebra needs far greater speedups. This is
because Zebra is working in a new (almost: see below) model,
where the requirement is that the prover’s overhead also be
lower than the baseline.

One work, by Ben-Sasson et al. [30], has articulated the
goal of considering both the prover’s and veriﬁer’s costs, when
analyzing performance relative to the native baseline. Their
context is different: theirs is a theory paper, they work with
classical PCPs, and they assume that V has access to a PCP.
By contrast, Zebra explicitly targets an implementation, and
requires precomputation and interaction. Nevertheless, this
is inspiring work, and the combined overhead in their setup
indeed drops below the native baseline asymptotically. How-
ever, the point at which this occurs—the “concrete-efﬁciency
threshold” [30]—is problem sizes on the order of 243, which
is larger than any of the aforementioned works can handle.

11 Summary and conclusion
This paper has deﬁned the problem of veriﬁable ASICs; given
a solution, Zebra, in the form of ASIC implementations of a
probabilistic proof protocol; and modeled, measured, and ac-
counted, to evaluate Zebra’s applicability. Zebra is not perfect.
On the other hand, the performance goals that we articulated
for it were stringent: (1) beat native execution, considering not
just the veriﬁer’s costs but also the prover’s, and (2) instantiate
efﬁcient and physically realizable hardware. In fact, it wasn’t
initially clear that these goals could be met at all. Viewed
in this more forgiving light, Zebra’s performance advantage,
however narrow and modest, is encouraging (at least to us).

There is much future work: relaxing Zebra’s constraints,
including the need for auxiliary inputs; handling broader
classes of computations; evaluating alternative baselines such
as trusted CPUs; investigating other applications; experiment-
ing with FPGA implementations; and perhaps even taping out
an artifact that deﬁnitively shows the feasibility of veriﬁable
ASICs. Most importantly, a grand challenge for the area is to
develop probabilistic proof machinery that handles all relevant
computations, not only in principle but also when translated
to implementation substrates as unforgiving as ASICs.

776776

Acknowledgments
We thank Justin Thaler for optimizing CMT [107]; Greg Shan-
non for an inspiring conversation; Andrew J. Blumberg, Dan
Boneh, and Justin Thaler for thoughtful comments; and the
anonymous reviewers, whose meticulous attention improved
the draft and the work. The authors were supported by NSF
grants CNS-1423249, CNS-1514422, CNS-1505728, CNS-
0845811, TC-1111781, CNS-1527072, and SRC-2015-TS-
2635; AFOSR grant FA9550-15-1-0302; ONR grant N00014-
14-1-0469; a Microsoft Faculty Fellowship; and a Google
Faculty Research Award.

Zebra’s source code is available at:
http://www.pepper-project.org/
References

[1] https://github.com/pepper-project.
[2] AMD Radeon R9 270X. https:

//www.techpowerup.com/gpudb/2466/radeon-r9-270x.html.

[3] Cadence Suite. http://www.cadence.com/.
[4] Dell warns of hardware trojan.

http://http://homelandsecuritynewswire.com/dell-
warns-hardware-trojan.

[5] GeForce GTX 980.

http://www.geforce.com/hardware/desktop-gpus/geforce-
gtx-980/specifications.

[6] Icarus Verilog. http://iverilog.icarus.com/.
[7] IEEE standard 1800-2012: SystemVerilog.

https://standards.ieee.org/findstds/standard/1800-
2012.html.

[8] NanGate FreePDK45 open cell library.

http://www.nangate.com/?page_id=2325.

[9] NCSU CDK. http://www.cs.utah.edu/~elb/cadbook/

Chapters/AppendixC/technology_files.html.
[10] Protecting against gray market and counterfeit goods.

http://blogs.cisco.com/news/protecting_against_gray_
market_and_counterfeit_goods.

[11] Secure channel. https://msdn.microsoft.com/en-

us/library/windows/desktop/aa380123(v=vs.85).aspx.

[12] Semiconductors: markets and opportunities. http:

//www.ibef.org/download/Semiconductors_220708.pdf.

[13] Tezzaron Semiconductor. “Can you trust your chips?".

http://www.tezzaron.com/can-you-trust-your-chips.

[14] Things that use Curve25519.

[15] Trusted foundry program.

https://ianix.com/pub/curve25519-deployment.html.

http://www.dmea.osd.mil/trustedic.html.

[16] Lagrange interpolation formula. In M. Hazewinkel, editor,

Encyclopedia of Mathematics. Springer, 2001.

[17] libsnark. https://github.com/scipr-lab/libsnark, 2016.
[18] S. Adee. The hunt for the kill switch.

http://spectrum.ieee.org/semiconductors/design/the-
hunt-for-the-kill-switch, May 2008.

[19] D. Agrawal, S. Baktir, D. Karakoyunlu, P. Rohatgi, and B. Sunar.

Trojan detection using IC ﬁngerprinting. In IEEE S&P, May 2007.

[20] Y. Arbitman, G. Dogon, V. Lyubashevsky, D. Micciancio, C. Peikert,
and A. Rosen. SWIFFTX: A proposal for the SHA-3 standard. NIST
submission, 2008.

[21] R. M. Avanzi, H. Cohen, C. Doche, G. Frey, T. Lange, K. Nguyen, and

F. Vercauteren. Handbook of Elliptic and Hyperelliptic Curve
Cryptography. Chapman & Hall/CRC, 2005.

[22] L. Babai. Trading group theory for randomness. In STOC, May 1985.
[23] L. Babai, L. Fortnow, L. A. Levin, and M. Szegedy. Checking

computations in polylogarithmic time. In STOC, May 1991.

[24] M. Backes, M. Barbosa, D. Fiore, and R. M. Reischuk. ADSNARK:
Nearly practical and privacy-preserving proofs on authenticated data.
In IEEE S&P, May 2015.

[25] M. Backes, D. Fiore, and R. M. Reischuk. Veriﬁable delegation of

computation on outsourced data. In ACM CCS, Nov. 2013.
[26] M. Banga and M. S. Hsiao. A region based approach for the

identiﬁcation of hardware Trojans. In HOST, June 2008.

[27] C. Batten, A. Joshi, J. Orcutt, A. Khilo, B. Moss, C. Holzwarth,

M. Popovi´c, H. Li, H. Smith, J. Hoyt, F. Kärtner, R. Ram,
V. Stojanovi´c, and K. Asanovi´c. Building manycore
processor-to-DRAM networks with monolithic silicon photonics. In
IEEE HOTI, Aug. 2008.

[28] G. T. Becker, F. Regazzoni, C. Paar, and W. P. Burleson. Stealthy

dopant-level hardware trojans. In CHES, Aug. 2013.

[29] E. Ben-Sasson, A. Chiesa, C. Garman, M. Green, I. Miers, E. Tromer,

and M. Virza. Decentralized anonymous payments from Bitcoin. In
IEEE S&P, May 2014.

[30] E. Ben-Sasson, A. Chiesa, D. Genkin, and E. Tromer. On the

concrete-efﬁciency threshold of probabilistically-checkable proofs. In
STOC, June 2013.

[31] E. Ben-Sasson, A. Chiesa, D. Genkin, E. Tromer, and M. Virza.

SNARKs for C: Verifying program executions succinctly and in zero
knowledge. In CRYPTO, Aug. 2013.

[32] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Scalable zero

knowledge via cycles of elliptic curves. In CRYPTO, Aug. 2014.

[33] E. Ben-Sasson, A. Chiesa, E. Tromer, and M. Virza. Succinct

non-interactive zero knowledge for a von Neumann architecture. In
USENIX Security, Aug. 2014.

implementations. In USENIX Security, Aug. 2014.

[49] L. Chen and A. Avizienis. N-version programming: A fault-tolerance

approach to reliability of software operation. In Intl. Conf. on Fault
Tolerant Computing, June 1978.

[50] A. Chiesa and E. Tromer. Proof-carrying data and hearsay arguments

from signature cards. In ICS, Jan. 2010.

[51] A. Chiesa, E. Tromer, and M. Virza. Cluster computing in zero

knowledge. In EUROCRYPT, Apr. 2015.

[52] C. Christensen, S. King, M. Verlinden, and W. Yang. The new

economics of semiconductor manufacturing.
http://spectrum.ieee.org/semiconductors/design/the-
new-economics-of-semiconductor-manufacturing.

[53] E.-Y. Chung, C.-I. Son, K. Bang, D. Kim, S.-M. Shin, and S. Yoon. A
high-performance solid-state disk with double-data-rate NAND ﬂash
memory. arXiv:1502.02239, 2009.

[54] T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein.

Introduction to Algorithms. The MIT Press, 3rd edition, 2009.

[55] G. Cormode, M. Mitzenmacher, and J. Thaler. Practical veriﬁed

computation with streaming interactive proofs. In ITCS, Jan. 2012.

[56] C. Costello, C. Fournet, J. Howell, M. Kohlweiss, B. Kreuter,

M. Naehrig, B. Parno, and S. Zahur. Geppetto: Versatile veriﬁable
computation. In IEEE S&P, May 2015.

[57] F. Doany. Power-efﬁcient, high-bandwidth optical interconnects for

high-performance computing.
http://www.hoti.org/hoti20/slides/Fuad_Doany_IBM.pdf,
2012. IEEE HOTI Keynote.

[58] D. Fiore, R. Gennaro, and V. Pastro. Efﬁciently veriﬁable computation

on encrypted data. In ACM CCS, Nov. 2014.

[34] D. J. Bernstein. Curve25519: new Difﬁe-Hellman speed records. In

[59] M. Fredrikson and B. Livshits. ZØ: An optimizing distributing

PKC, Apr. 2006.

zero-knowledge compiler. In USENIX Security, Aug. 2014.

[35] S. Bhunia, M. Hsiao, M. Banga, and S. Narasimhan. Hardware Trojan

[60] R. Gennaro, C. Gentry, and B. Parno. Non-interactive veriﬁable

attacks: threat analysis and countermeasures. Proceedings of the
IEEE, 102(8):1229–1247, Aug. 2014.

computing: Outsourcing computation to untrusted workers. In
CRYPTO, Aug. 2010.

[36] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. From extractable

[61] R. Gennaro, C. Gentry, B. Parno, and M. Raykova. Quadratic span

collision resistance to succinct non-interactive arguments of
knowledge, and back again. In ITCS, Jan. 2012.

[37] N. Bitansky, R. Canetti, A. Chiesa, and E. Tromer. Recursive

composition and bootstrapping for SNARKs and proof-carrying data.
In STOC, 2013.

[38] S. Blake-Wilson, N. Bolyard, V. Gupta, C. Hawk, and B. Moeller.
Elliptic eurve cryptography (ECC) cipher suites for transport layer
security (TLS), May 2006.

[39] G. Brassard, D. Chaum, and C. Crépeau. Minimum disclosure proofs

of knowledge. J. of Comp. and Sys. Sciences, 37(2):156–189, Oct.
1988.

[40] B. Braun. Compiling computations to constraints for veriﬁed
computation. UT Austin Honors thesis HR-12-10, Dec. 2012.
[41] B. Braun, A. J. Feldman, Z. Ren, S. Setty, A. J. Blumberg, and

M. Walﬁsh. Verifying computations with state. In SOSP, Nov. 2013.

[42] M. Bushnell and V. D. Agrawal. Essentials of electronic testing for

digital, memory and mixed-signal VLSI circuits, volume 17. Springer
Science & Business Media, 2000.

[43] D. Byrne, B. Kovak, and R. Michaels. Offshoring and price

measurement in the semiconductor industry. In Measurement Issues
Arising from the Growth of Globalization, Nov. 2009.

[44] L. Carloni, K. McMillan, and A. Sangiovanni-Vincentelli. Theory of
latency-insensitive design. IEEE TCAD, 20(9):1059–1076, Sept. 2001.

[45] G. Carlson. Trusted foundry: the path to advanced SiGe technology.

In IEEE CSICS, Nov. 2005.

[46] R. S. Chakraborty and S. Bhunia. HARPOON: an obfuscation-based

SoC design methodology for hardware protection. IEEE TCAD,
28(10):1493–1502, Oct. 2009.

[47] R. S. Chakraborty, F. Wolff, S. Paul, C. Papachristou, and S. Bhunia.

MERO: A statistical approach for hardware Trojan detection. In
CHES, Sept. 2009.

[48] S. Checkoway, M. Fredrikson, R. Niederhagen, A. Everspaugh,

M. Green, T. Lange, T. Ristenpart, D. J. Bernstein, J. Maskiewicz, and
H. Shacham. On the practical exploitability of Dual EC in TLS

programs and succinct NIZKs without PCPs. In EUROCRYPT, 2013.

[62] C. Gentry and D. Wichs. Separating succinct non-interactive

arguments from all falsiﬁable assumptions. In STOC, June 2011.

[63] S. Goldwasser, Y. T. Kalai, and G. N. Rothblum. Delegating

computation: Interactive proofs for muggles. J. ACM,
62(4):27:1–27:64, Aug. 2015. Prelim version STOC 2008.

[64] S. Goldwasser, S. Micali, and C. Rackoff. The knowledge complexity
of interactive proof systems. SIAM J. on Comp., 18(1):186–208, 1989.

[65] B. Grow, C.-C. Tschang, C. Edwards, and D. Burnsed. Dangerous

fakes. Business Week, Oct. 2008.

[66] L. Henzen, P. Gendotti, P. Guillet, E. Pargaetzi, M. Zoller, and

F. Gürkaynak. Developing a hardware evaluation method for SHA-3
candidates. In CHES. Aug. 2010.

[67] B. Hoefﬂinger. ITRS: The international technology roadmap for

semiconductors. In Chips 2020. Springer, 2012.

[68] D. Hwang, K. Tiri, A. Hodjat, B. Lai, S. Yang, P. Shaumont, and
I. Verbauwhede. AES-based security coprocessor IC in 0.18-μm
CMOS with resistance to differential power analysis side-channel
attacks. IEEE JSSC, 41(4):781–792, Apr. 2006.

[69] Top 13 foundries account for 91 percent of total foundry sales in 2013.

http://www.icinsights.com/news/bulletins/top-13-
foundries-account-for-91-of-total-foundry-sales-in-
2013/, Jan. 2014.

[70] F. Imeson, A. Emtenan, S. Garg, and M. V. Tripunitara. Securing

computer hardware using 3D integrated circuit (IC) technology and
split manufacturing for obfuscation. In USENIX Security, Aug. 2013.

[71] M. Immonen. Development of optical interconnect PCBs for

high-speed electronic systems—fabricator’s view.
http://www-03.ibm.com/procurement/proweb.nsf/
objectdocswebview/file2011+ibm+pcb+symposium+ttm/
$file/ttm_optical+interconnect_ext.pdf, 2011. IBM PCB
Symposium 2011.

[72] Y. Ishai, E. Kushilevitz, and R. Ostrovsky. Efﬁcient arguments

without short PCPs. In IEEE CCC, June 2007.

777777

[73] Y. Jin and Y. Makris. Hardware Trojan detection using path delay

ﬁngerprint. In HOST, June 2008.

[74] J. Kilian. A note on efﬁcient zero-knowledge proofs and arguments

(extended abstract). In STOC, May 1992.

[75] D. H. Kim, K. Athikulwongse, M. B. Healy, M. M. Hossain, M. Jung,

I. Khorosh, G. Kumar, Y.-J. Lee, D. L. Lewis, T.-W. Lin, C. Liu,
S. Panth, M. Pathak, M. Ren, G. Shen, T. Song, D. H. Woo, X. Zhao,
J. Kim, H. Choi, G. H. Loh, H.-H. S. Lee, and S. K. Lim. Design and
analysis of 3D-MAPS. IEEE Trans. Computers, 64(1):112–125, Jan.
2015.

[76] A. E. Kosba, D. Papadopoulos, C. Papamanthou, M. F. Sayed, E. Shi,
and N. Triandopoulos. TRUESET: Faster veriﬁable set computations.
In USENIX Security, Aug. 2014.

[77] F. Koushanfar and A. Mirhoseini. A uniﬁed framework for

multimodal submodular integrated circuits trojan detection. IEEE
TIFS, 6(1):162–174, Dec. 2011.

[78] J. Li and J. Lach. At-speed delay characterization for IC

authentication and trojan horse detection. In HOST, June 2008.

[79] S. K. Lim. 3D-MAPS: 3D massively parallel processor with stacked

memory. In Design for High Perf., Low Power, and Reliable 3D
Integrated Circuits. Springer, 2013.

[80] C. Lund, L. Fortnow, H. J. Karloff, and N. Nisan. Algebraic methods

for interactive proof systems. J. ACM, 39(4):859–868, Oct. 1992.
[81] J. Markoff. Old trick threatens the newest weapons. The New York

Times, Oct. 2009.

[97] C. L. Schow, F. E. Doany, C. Chen, A. V. Rylyakov, C. W. Baks, D. M.

side-channel–protected elliptic curve cryptography. ACM TRETS,
9(1):3:1–3:15, Nov. 2015.
Kuchta, R. A. John, and J. A. Kash. Low-power 16× 10 Gb/s
bi-directional single chip CMOS optical transceivers operating at
< 5 mW/Gb/s/link. IEEE JSSC, 44(1):301–313, Jan. 2009.

[98] S. Setty, A. J. Blumberg, and M. Walﬁsh. Toward practical and

unconditional veriﬁcation of remote computations. In HotOS, May
2011.

[99] S. Setty, B. Braun, V. Vu, A. J. Blumberg, B. Parno, and M. Walﬁsh.
Resolving the conﬂict between generality and plausibility in veriﬁed
computation. In EuroSys, Apr. 2013.

[100] S. Setty, R. McPherson, A. J. Blumberg, and M. Walﬁsh. Making

argument systems for outsourced computation practical (sometimes).
In NDSS, Feb. 2012.

[101] S. Setty, V. Vu, N. Panpalia, B. Braun, A. J. Blumberg, and M. Walﬁsh.

Taking proof-based veriﬁed computation a few steps closer to
practicality. In USENIX Security, Aug. 2012.

[102] A. Shamir. IP = PSPACE. J. ACM, 39(4):869–877, Oct. 1992.
[103] V. Shoup. NTL: A library for doing number theory.

http://www.shoup.net/ntl/.

[104] C. Sturton, M. Hicks, D. Wagner, and S. T. King. Defeating UCI:

Building stealthy and malicious hardware. In IEEE S&P, May 2011.

[105] M. Tehranipoor and F. Koushanfar. A survey of hardware Trojan

taxonomy and detection. IEEE DT, 27(1):10–25, Jan. 2010.

[82] S. Maynard. Trusted manufacturing of integrated circuits for the

[106] J. Thaler. Time-optimal interactive proofs for circuit evaluation. In

Department of Defense. In National Defense Industrial Association
Manufacturing Division Meeting, 2010.

[83] S. Micali. Computationally sound proofs. SIAM J. on Comp.,

30(4):1253–1298, 2000.

[84] P. Milder, F. Franchetti, J. Hoe, and M. Püschel. Computer generation

of hardware for linear digital signal processing transforms. ACM
TODAES, 17(2):15:1–15:33, Apr. 2012.

[85] P. L. Montgomery. Speeding the Pollard and elliptic curve methods of

factorization. Math. of Computation, 48(177):243–264, Jan. 1987.

[86] M. Naor. On cryptographic assumptions and challenges. In CRYPTO,

2003.

CRYPTO, Aug. 2013.

[107] J. Thaler. A note on the GKR protocol.

http://people.seas.harvard.edu/ jthaler/GKRNote.pdf, 2015.

[108] J. Thaler, M. Roberts, M. Mitzenmacher, and H. Pﬁster. Veriﬁable
computation with massively parallel interactive proofs. In USENIX
HotCloud Workshop, June 2012.

[109] K. Tiri, D. Hwang, A. Hodjat, B. Lai, S. Yang, P. Shaumont, and
I. Verbauwhede. AES-based cryptographic and biometric security
coprocessor IC in 0.18-μm CMOS resistant to side-channel power
analysis attacks. In VLSI Circuits, June 2005.

[110] R. Torrance and D. James. The state-of-the-art in IC reverse

[87] M. H. Nazari and A. Emami-Neyestanak. A 24-Gb/s double-sampling

engineering. In CHES, Sept. 2009.

receiver for ultra-low-power optical communication. IEEE JSSC,
48(2):344–357, Feb. 2013.

[88] B. Parno, C. Gentry, J. Howell, and M. Raykova. Pinocchio: Nearly

practical veriﬁable computation. In IEEE S&P, May 2013.

[89] H. Pilo, J. Barwin, G. Braceras, C. Browning, S. Burns, J. Gabric,

S. Lamphier, M. Miller, A. Roberts, and F. Towler. An SRAM design
in 65nm and 45nm technology nodes featuring read and write-assist
circuits to expand operating voltage. In IEEE VLSI, June 2006.

[111] S. Trimberger. Trusted design in FPGAs. In DAC, June 2007.
[112] V. Vu, S. Setty, A. J. Blumberg, and M. Walﬁsh. A hybrid architecture

for interactive veriﬁable computation. In IEEE S&P, May 2013.

[113] R. S. Wahby, M. Howald, S. Garg, a. shelat, and M. Walﬁsh. Veriﬁable

ASICs. Cryptology ePrint Archive, Report 2015/1243, 2015.

[114] R. S. Wahby, S. Setty, Z. Ren, A. J. Blumberg, and M. Walﬁsh.

Efﬁcient RAM and control ﬂow in veriﬁable outsourced computation.
In NDSS, Feb. 2015.

[90] E. P. Quevy. CMEMS technology: Leveraging high-volume CMOS

[115] A. Waksman and S. Sethumadhavan. Silencing hardware backdoors.

manufacturing for MEMS-based frequency control. Technical report,
Silicon Laboratories.

[91] J. M. Rabaey, A. P. Chandrakasan, and B. Nikolic. Digital integrated

circuits, volume 2. Prentice Hall Englewood Cliffs, 2002.

[92] J. A. Roy, F. Koushanfar, and I. L. Markov. EPIC: Ending piracy of

integrated circuits. In DATE, Mar. 2008.

[93] M. Sako, Y. Watanabe, T. Nakajima, J. Sato, K. Muraoka, M. Fujiu,

F. Kouno, M. Nakagawa, M. Masuda, K. Kato, Y. Terada, Y. Shimizu,
M. Honma, A. Imamoto, T. Araya, H. Konno, T. Okanaga,
T. Fujimura, X. Wang, M. Muramoto, M. Kamoshida, M. Kohno,
Y. Suzuki, T. Hashiguchi, T. Kobayashi, M. Yamaoka, and
R. Yamashita. A low-power 64Gb MLC NAND-ﬂash memory in
15nm CMOS technology. In IEEE ISSCC, Feb. 2015.

In IEEE S&P, May 2011.

[116] A. Waksman, M. Suozzo, and S. Sethumadhavan. FANCI:

identiﬁcation of stealthy malicious logic using boolean functional
analysis. In ACM CCS, Nov. 2013.

[117] M. Walﬁsh and A. J. Blumberg. Verifying computations without
reexecuting them: from theoretical possibility to near practicality.
Communications of the ACM, 58(2):74–84, Feb. 2015.

[118] S. Wei, K. Li, F. Koushanfar, and M. Potkonjak. Hardware Trojan
horse benchmark via optimal creation and placement of malicious
circuitry. In DAC, June 2012.

[119] S. Wei, S. Meguerdichian, and M. Potkonjak. Malicious circuitry

detection using thermal conditioning. IEEE TIFS, 6(3):1136–1145,
Sept. 2011.

[94] K. Sakuma, S. Skordas, J. Zitz, E. Perfecto, W. Guthrie, L. Guerin,

[120] F. Wolff, C. Papachristou, S. Bhunia, and R. S. Chakraborty. Towards

R. Langlois, H. Liu, K. Ramachandran, W. Lin, K. Winstel, S. Kohara,
K. Sueoka, M. Angyal, T. Graves-Abe, D. Berger, J. Knickerbocker,
and S. Iyer. Bonding technologies for chip level and wafer level 3D
integration. In IEEE ECTC, May 2014.

[95] P. Sasdrich and T. Güneysu. Efﬁcient elliptic-curve cryptography
using Curve25519 on reconﬁgurable devices. In ARC, Apr. 2014.

[96] P. Sasdrich and T. Güneysu. Implementing Curve25519 for

Trojan-free trusted ICs: Problem analysis and detection scheme. In
DATE, Mar. 2008.

[121] Y. Zhou and D. Feng. Side-channel attacks: Ten years after its

publication and the impacts on cryptographic module security testing.
Cryptology ePrint Archive, Report 2005/388, 2005.

778778

