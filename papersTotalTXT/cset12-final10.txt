Collaborative Red Teaming for Anonymity System Evaluation

Sandy Clark◦ Chris Wacek• Matt Blaze◦

Boon Thau Loo◦ Micah Sherr• Clay Shields•

Jonathan Smith◦

◦University of Pennsylvania

•Georgetown University

Abstract

This paper describes our experiences as researchers
and developers during red teaming exercises of the
SAFEST anonymity system. We argue that properly
evaluating an anonymity system — particularly one that
makes use of topological information and diverse relay
selection strategies, as does SAFEST— presents unique
challenges that are not addressed using traditional red
teaming techniques. We present our efforts towards
meeting these challenges, and discuss the advantages of a
collaborative red teaming paradigm in which developers
play a supporting role during the evaluation process.

1

Introduction

The need for secure, dependable, and high performance
systems to enable anonymous communication in the
presence of eavesdroppers has been the focus of much
research in the past several years (cf. the survey by
Sampigethay and Poovendran [15]). Perhaps the most
successful of these efforts is the volunteer-operated Tor
network [7], recently estimated to enhance the privacy of
as many as hundreds of thousands of daily users [9].

Unfortunately, as has been pointed out by the net-
work’s operators [8], Tor suffers from signiﬁcant conges-
tion, leading to latencies and bandwidths that are an order
of magnitude worse than those offered by unprotected
direct communication. As has been noted in previous
work, Tor’s performance problems are due in part to the
asymmetry between the number of clients and anonymiz-
ing relays [8], the presence of bandwidth-intensive ﬁle-
sharers on the network [13], and the use of latency-
agnostic relay selection strategies [2, 17, 18].

In this paper, we describe our experiences as develop-
ers during recent red teaming efforts to test and analyze
Selectable Anonymity for Enabling SAFER Telecommu-

nications (SAFEST) – a tunable and latency-aware en-
hancement to Tor that attempts to alleviate this latter
cause of Tor’s slowness. SAFEST extends existing work
on link-based routing [17, 18] in which clients (some-
times called initiators) weigh relay selection based on
the expected end-to-end (e2e) cost of link performance
indicators such as latency, AS hop count, and jitter.

SAFEST differs from existing anonymity systems in
its ability to establish reliable channels with predictable
QoS characteristics.
In contrast to existing anonymity
systems which rely on immutable relay selection algo-
rithms, SAFEST allows the sender to provide a relay se-
lection policy that precisely deﬁnes the manner in which
relays are chosen for anonymous paths. This effec-
tively lets the initiator control the e2e performance of her
anonymous paths, since a path’s performance is dictated
in large part by the network conditions and available re-
sources at its constituent segments. Built on top of the
existing Tor platform, SAFEST leverages distributed In-
ternet embedding systems [5] to provide compact encod-
ings of network state. Using these embedding systems,
SAFEST provides a mechanism for initiators to make in-
formed choices when selecting relays. This ﬂexibility
permits more ﬁne-tuned relay selection and better con-
forms to applications’ speciﬁc performance requirements
(e.g., latency, bandwidth, jitter, etc.).

SAFEST’s features — in particular, its use of net-
work topology information to construct better perform-
ing anonymous paths — present a number of interest-
ing challenges for experimentation and evaluation. Since
SAFEST permits a variety of relay selection strategies
whose performance depends on dynamic network con-
ditions, accurately modeling realistic deployments be-
comes critically important for evaluating the system’s ef-
fectiveness. Drawing on our experiences as SAFEST de-
velopers and as observers of its red teaming evaluation,

1

the focus of this paper is on (1) the challenges inherent in
analyzing the security properties of an anonymity system
and (2) best practices that may be applied to meet these
challenges.

Contributions. We present our initial efforts towards
mitigating the challenges associated with evaluating a
system such as SAFEST. In particular, we describe the
development of a clonable and scalable network topol-
ogy that accurately models network characteristics as
well as client behavior.

We additionally describe our experiences, from our
vantage point as “Blue Team” researchers and develop-
ers, participating in interactive red teaming exercises.
During the red team evaluation, we operated in concert
with an independent and external team of “attackers” to
discover possible weaknesses in our design and imple-
mentation. We argue that this collaborative model in
which the Red Team does not act in strict isolation is cru-
cial for framing realistic attack scenarios and analyzing
a complex and topology-aware anonymity system.

Finally, we describe how our combined Red
Team/Blue Team exercises led to the discovery of a new
variation in a class of attacks on Internet embedding sys-
tems that may not otherwise have been found by the Red
Team working alone.

We begin by describing in more detail the unique chal-
lenges of evaluating a performance-driven anonymity
system.

2 Challenges

Measuring the performance and anonymity characteris-
tics of an Internet-based anonymity system presents a
number of interesting research challenges. We highlight
some of these challenges below.
Challenge 1: Utilizing an expressive measurement
framework.
We require an effective measurement
framework that enables controlled testing of the system.
This framework should provide a number of capabilities:
• Conﬁgurable: The design of the network and the
nodes within it can be precisely speciﬁed with as
few constraints as possible;
• Controlled: Inputs are limited to those speciﬁed by
the experimenter. This isolation is necessary to al-
low developers and testers to better reason about the
system’s behavior;
• Measurable: Traces, logs, and other data can be

obtained from any point of the network; and

2

• Reproducible: An experiment can be run multiple

times and produce similar results.

Conﬁgurability and controllability enable a researcher
to rapidly iterate through experiments, validating differ-
ent attack vectors or tweaking system parameters. At
the same time, controllability, measurability, and repro-
ducibility allow data from separate experiments to be
comparable.

Perhaps counterintuitively, we argue that

live de-
ployments are not well-suited for regularly conduct-
ing anonymity experiments. Although they offer max-
imum realism, live networks are difﬁcult to conﬁgure,
making it difﬁcult to generalize the results of any par-
ticular experiment beyond the tested network. More-
over, a live anonymity network does not exist in isola-
tion and may be affected by uncontrollable and unpre-
dictable events that occur on the Internet (e.g., routing
changes, trafﬁc bursts, etc.), making it more difﬁcult
to reproduce experimental results. Finally, experiment-
ing on live anonymity networks may expose its users
to risk [3, 19], since experimental changes may detri-
mentally affect user’s anonymity. There are no currently
widely accepted community standards for conducting re-
search on live anonymity networks [19].
Challenge 2: Constructing realistic topologies.
The
performance of any network overlay is partially de-
pendent on the conﬁguration of the network on which
it is deployed.
In particular, an anonymity network’s
throughput is a function of the bandwidth available at
its anonymizing relays; e2e path latencies are comprised
in part from the latencies between relays; and jitter on
the overlay results from both transient network effects
as well as changing workloads on the network’s nodes.
Studies that rely on overly simplistic topologies risk
missing effects that may produce degraded performance
or anonymity under more realistic conditions. Even for
anonymity systems in which performance is less critical,
the failure to consider network characteristics may cause
researchers to overlook attacks that leverage network ef-
fects (e.g., the loss or delay of a particular message).

Carefully constructing topologies is necessary to un-
derstand (1) how an anonymity protocol will function un-
der various network conditions and (2) how attackers can
exploit topological information to decrease participants’
anonymity. This is particularly critical for evaluating
“network-aware” anonymity systems such as SAFEST
where relay selection is fully dependent on the perceived
network topology.
Challenge 3: Accurately modeling client behavior.
Accurately modeling client behavior is especially chal-

lenging when experimenting with anonymity systems.
A correct anonymity system will, by design, thwart at-
tempts at understanding the (potentially highly variant)
behavior of its users. Hence, previous efforts at quan-
tifying client behavior on live networks rely on statisti-
cal sampling [13, 20]. Although such approaches may
be used to approximate user behavior, they are inher-
ently biased toward existing behavior on current net-
works rather than on desired usage. For example, al-
though the latencies on Tor are too high to permit real-
time video communication, users of the anonymity ser-
vice may appreciate such a capability and might partic-
ipate in anonymous video conferencing if it were possi-
ble.

Enumerating and characterizing client behavior is par-
ticularly challenging for SAFEST. Since the anonymity
system enables clients to choose diverse relay selection
strategies, a signiﬁcant challenge during SAFEST’s red
teaming exercises was determining appropriate client be-
havior according to a variety of communication require-
ments.
Challenge 4: Accurately modeling adversarial be-
havior.
There is a large body of work that con-
siders attacks against anonymity systems (cf. the sur-
vey by Sampigethaya and Poovendran [15]). Attack-
ers can be classiﬁed both according to their abilities —
e.g., administrators of large networks, botmasters, in-
dividual rogue operators, etc. — as well as their mo-
tives — e.g., to break anonymity, to disrupt the network,
and (for performance-centric anonymity services such as
SAFEST) to degrade performance. Moreover, compared
to closed distributed systems with more stringent ac-
cess controls, anonymity systems that rely on volunteer-
operated relays have a comparatively large attack sur-
face: attackers can be either external to the network, or
may operate as malicious insiders (e.g., relay operators).
A signiﬁcant challenge of red-teaming an anonymity sys-
tem is thus to model realistic adversaries and quantify the
risk they pose to the network.

3 Methodology

In what follows, we present our experiences before and
during the red teaming SAFEST exercises, and in partic-
ular, describe the methods we applied as developers to
meet the above challenges.

3.1 Experimental Framework
Recently, the ExperimenTor [3] and Shadow [11] frame-
works have been proposed for anonymity system ex-

Framework
DETER

ExperimenTor

Shadow

Advantage(s)
Actual
hardware,
on-the-ﬂy conﬁgura-
tion changes
Unmodiﬁed binary
emulation, real time
experiments
Low hardware costs,
scalable

Disadvantage(s)
Limited
and contention

resources

Limited scalability

Modiﬁed
binaries,
slower than real time

Table 1: Experimental frameworks for Internet testing. We re-
lied on ExperimenTor for SAFEST development and DETER
for the red teaming exercises.

perimentation. Both frameworks are designed for mea-
suring performance characteristics on large virtual de-
ployments, and support the execution of unmodiﬁed (or
slightly modiﬁed) binaries on top of emulated [3] or sim-
ulated [11] network topologies.

For the SAFEST exercises, we utilized ExperimenTor
for system development and the DETER testbed [6, 14]
for the red teaming exercises. The DETER testbed is a
public facility for medium-scale repeatable experiments
in computer security. Built using the University of Utah’s
Emulab software, the DETER testbed has been conﬁg-
ured and extended to provide effective containment for
a variety of computer security experiments. In our set-
ting, DETER allows us to run SAFEST code on reserved
(i.e., not shared) machines and reconﬁgure the topology
according to our needs.

Table 1 presents a high-level comparison of experi-
mental frameworks for testing anonymity systems. A
more thorough discussion of the advantages and disad-
vantages of various experimental frameworks is beyond
the scope of this paper; interested readers may refer to the
arguments motivating the development of ExperimenTor
and Shadow [3, 11].

3.2 Topology Generation
Accurate testing depends upon a network topology that
captures certain characteristics of the real world Internet:
it must have a diversity of link latencies and link band-
widths, as well as a sufﬁcient number of nodes to instan-
tiate a diverse set of paths within the overlay network.

In our testing of SAFEST on DETER, we made use
of a three tier “core-stub-node” topology. Our topology,
depicted in Figure 1, is a three level tree in which all ap-
plication nodes operate at the leaves of the tree, the ‘core’
is the root of the tree, and ‘stubs’ are branches. The root
of our experimental topology consisted of three core root
nodes, each of which connects to three stub nodes. Each
stub contains ﬁve application nodes. The resulting topol-

3

DETER testbed. The redundancy in the experimental
setups provides independent control and experiment set-
tings for better measuring the effects of conﬁguration or
protocol changes. In a time-constrained evaluation ses-
sion, the dual setups have the additional advantage of
providing a failover instance if aggressive experimenta-
tion results in the primary experimental instance becom-
ing non-functional.

3.3 Client Behavior
Many different types of trafﬁc ﬂow through the Tor net-
work today. The vast majority is standard HTTP web
trafﬁc [13]. Despite the fact that HTTP trafﬁc com-
prises a signiﬁcant fraction of Tor trafﬁc, additional
types of trafﬁc should be considered when evaluating an
anonymity system such as Tor. For instance, modiﬁca-
tions which exclusively aim to enhance the performance
of one particular class of applications may have an ad-
verse effect on other application classes.

When evaluating SAFEST, we sought to model a vari-
ety of potential uses for a performance-driven anonymity
system. Our clients engaged in several behaviors in-
tended to capture the performance characteristics asso-
ciated with these uses.

First, each client uses curl to request ﬁles of various
sizes from a remote web server. We use a range of ﬁle
sizes intended to capture regular web browsing activity,
where most ﬁles are under 500K; we additionally model
“bulk” downloaders who regularly transfer large ﬁles.

Second, clients periodically engage in ﬁxed bit-rate
communication with a destination server for a randomly-
selected period of time. This is designed to capture the
characteristics important to low-latency applications (in
particular, VoIP clients).

3.4 Evaluation Methodology
The need for red teaming a security application is well
understood, and there has been much work to develop
standards for assessing information security [10, 16]. As
early as 1973 Clark Weissman [21] developed a ‘Flaw
Hypothesis Methodology’ which delineated the steps in-
volved in a successful penetration test, and this method-
ology is still used in some form today. Two early stud-
ies [1, 12] explored the beneﬁts of penetration testing
systems security using this methodology. However, both
studies viewed the ‘testing phase’ of penetration testing
as best done as a “Gedanken” or thought experiment,
rather than something performed by active red team at-
tackers.

Figure 1: Experiment topology on DETER. The disconnected
node in the top-right corner is used to control the experiments
and does not participate in the anonymity network.

ogy contains 45 application nodes, providing a wide va-
riety of possible paths through the overlay network while
minimizing the hardware required.

To create a diversity of link latencies and bandwidths,
we randomly select bandwidths and latencies from a dis-
tribution that approximates the variety of latencies and
bandwidths present on the Internet. Core and core-
stub connections are high bandwidth and low latency
to simulate the Internet backbone, while leaf connec-
tions are lower bandwidth and higher latency to simulate
last-mile connections. Core latencies were chosen uni-
formly at random from [10, 18] ms; leaf latencies were
selected uniformly at random from [20, 68] ms. The core
bandwidths were sampled from a distribution that cross
references the geographic distribution of Tor clients in
early 2011 with bandwidth rates from those countries.
The bandwidth data were obtained from NetIndex.com,
which aggregates SpeedTest.net data1.

These sample distributions, while not exact represen-
tations of real-world bandwidths and latencies, provide
a varied performance experience for nodes within the
topology, and permits anonymous paths with diverse per-
formance characteristics.
Utilizing dual-frameworks. We deployed two dupli-
cate instances of the experimental conﬁguration on the

1Speedtest.net [http://speedtest.net] is a service that per-
mits end users to identify the speed of their network connections
by downloading ﬁles from known ‘fast’ servers and measuring the
throughput.

4

Today red teaming usually takes one of two forms:
overt and covert. Overt testing involves internal and/or
external evaluation of a system with the knowledge and
support of the system’s operators. In contrast, covert test-
ing occurs without the knowledge of the developers or
IT staff. Traditionally, neither overt nor covert testing is
performed with the active participation or cooperation of
system developers.

The majority of literature concerning security testing
focuses on red teaming a particular instance of a sys-
tem, network, or corporate entity, rather than on testing
the design of a system. For example, in recommending
whether to choose overt or covert testing, NIST states:

Overt testing is less expensive, carries less
risk than covert testing, and is more frequently
used– but covert testing provides a better indi-
cation of the everyday security of the target or-
ganization because system administrators will
not have heightened awareness. [16]

Importantly, this distinction does not apply to testing a
design, since a design, unlike an instance, has no system
administrators. When evaluating the design of a system
— as is the case in the SAFEST exercises — there is little
beneﬁt for the red teaming to be covert.

While the attack vectors are slightly different when
focusing on a distributed anonymity system, a success-
ful evaluation and red team exercise for an anonymity
system retains many of the elements from standard red
team exercises. Below, we describe the components of
the SAFEST red teaming exercises, including the addi-
tion of the Sandboxing phase that emphasizes the non-
adversarial relationship between the system developers
and the Red Team.

• Scope Setting and Brainstorming: System design-
ers and Red Team members meet prior to the eval-
uation exercises to identify attack surfaces that are
in scope and discuss potential attack vectors. This
aids the Red Team, who may be unfamiliar with the
particulars of a new anonymity system.
• Independent Vulnerability Analysis: The Red Team
analyzes the applicable attack surface of the system,
documents potential vulnerabilities, and develops a
plan of attack for evaluating those vulnerabilities.
(Vulnerabilities in the baseline Tor software were
treated as “out-of-scope” for the purpose of this
red teaming exercise since any released Tor patches
could be applied to the SAFEST codebase.)
• Exploitation: During the evaluation period, the Red
Team attempts to independently implement the at-
tacks that they have developed against the system.

• Sandboxing: During the evaluation period, post-
Exploitation, the Red Team and co-located system
developers discuss the vulnerabilities discovered by
the Red Team. During this stage, system developers
and Red Team members discuss and tweak param-
eters in the running experimental instance to bet-
ter characterize the vulnerabilities and measure their
severity. As we argue in what follows, the intersec-
tion of Red Team focus and system developer ex-
pertise can perceive more speciﬁc issues than either
independently.
• Risk Analysis and Quantiﬁcation: Red Team mem-
bers quantify their assessment of the risks posed by
the identiﬁed vulnerabilities. These assessments are
validated by the system developers.

This enhanced evaluation methodology can provide
greater clarity into the vulnerabilities exposed by a sys-
tem, while the system developer involvement in the pro-
cess engenders greater ownership of the identiﬁed issues.
Critically, the organization overseeing the develop-
ment and evaluation effort must reinforce that identiﬁed
vulnerabilities do not affect project performance, or eval-
uation processes can swiftly turn antagonistic.
4 The School of Fish Attack: An Example

of Collaborative Red Teaming

The Red Team identiﬁed several previously unknown
vulnerabilities in the tested SAFEST implementation. In
what follows, we describe one such exploit — the School
of Fish attack — and discuss how the attack’s discovery
was made possible due to the interactions between the
system’s designers and its evaluators. We emphasize that
the main contribution of this paper is not the discovery
of the School of Fish attack, but rather the argument that
collaborative red teaming offers advantages over more
traditional and isolated red teaming approaches. The ex-
ample below is intended to highlight these advantages.
Background.
To provide low latency anonymous cir-
cuits, SAFEST makes use of a virtual coordinate embed-
ding system. Each relay is assigned an n-dimensional
virtual coordinate such that the Euclidean distance be-
tween any two relays’ coordinates should serve as a use-
ful estimate of the latency between the pair. SAFEST
currently uses a slightly modiﬁed version of the Vivaldi
virtual coordinate system [5]: each relay selects another
relay at random, requests its coordinate, and empirically
measures the roundtrip time between them; the request-
ing relay then adjusts its coordinate to reduce the differ-
ence between the virtual and empirical distances.

Since SAFEST uses virtual distances to estimate the
costs of routing between relays, an adversary who games

5

Figure 2: A malicious relay (red circle)
joins the network and is located next
to a number of targeted honest relays
(grey circles).

its coordinates,

Figure 3: The malicious relay slowly
adjusts
causing a
“School of Fish” effect in which the
victims (grey nodes) follow it to an
undesirable location in the coordinate
space.

Figure 4: Even after the malicious re-
lay stops its attacks, the SAFEST se-
curity mechanism (police ofﬁcer) pre-
vents the honest relays from migrating
back to their original positions.

the coordinate system can harm anonymity by causing
malicious relays to appear more attractive (or conversely,
non-malicious relays to appear less attractive). To miti-
gate such attacks, SAFEST implements a simple security
mechanism: before a relay accepts an advertised coordi-
nate from a peer, it assesses whether updating its own co-
ordinate based on the advertised coordinate will increase
or decrease its error using the most recently observed
coordinates and empirical measurements. Here, error
is deﬁned as the median difference between the virtual
(v1, . . . , vk) and actual (d1, . . . , dk) distances between it-
self and k of its neighbors.
That is,

k(cid:91)

error = median(

|vi − di|)

i=1

If the error increases by more than a threshold amount,
the requesting relay does not update its coordinate. Con-
ceptually, the security measure ensures that an advertised
coordinate will not too adversely inﬂuence a relay’s own
coordinate.

Discovering the School of Fish attack.
During the
red teaming exercises, the Red Team attempted to isolate
a targeted honest relay to make it appear less attractive.
The attack consisted of using malicious relays to adver-
tise carefully selected but incorrect virtual coordinates in
order to “push” the targeted relay to a far off region of
the coordinate space. Due to SAFEST’s coordinate pro-
tection mechanism, the attack was unsuccessful.

Importantly, however, the presence and participation
of SAFEST developers during the red teaming exercises
helped lead to the discovery of a novel attack. When the
above described attack failed, the developers were able
to explain why it failed during the Sandboxing process.

6

In collaboration with the Red Team, the developers were
able to reason about the behavior of the system during
the tested attack.

The interaction between the two teams aided the Red
In particular, with input
Team in reﬁning their attack.
from the developers, the Red Team discovered that our
simple coordinate security check could be exploited to
worsen an attack against the coordinate system, under
certain network conditions. By introducing a “choke
point” in the network — a capability available to a mod-
erately advanced attacker — the adversary was able to
cause a School of Fish effect in which many honest re-
lays in a network partition slowly followed a malicious
relay to far off regions of the coordinate space (Figures 2
and 3). After the adversary halted the attack and the
network became unpartitioned, the coordinate protection
mechanism prevented the system from re-stabilizing for
a period of time (Figure 4) since the affected relays did
not trust the now far-away coordinates offered by their
unaffected (but still honest) peer relays.

Our current research efforts explore strategies to de-
feat this newly identiﬁed attack, including the use of re-
cently proposed coordinate protection schemes [4].

5 Lessons Learned

Successfully evaluating a distributed network anonymity
system is a difﬁcult task. The evaluation framework,
the tested topologies, and the behavior of the clients, re-
lays, and adversaries must be carefully conﬁgured in or-
der to thoroughly exercise the elements of the anonymity
system. These challenges are especially pronounced
for network-aware anonymity systems such as SAFEST

where the behavior of the system depends on the per-
ceived network environment.

The SAFEST red teaming exercises were successful
because we used an experimental framework (DETER)
that allows on-the-ﬂy adjustments and effective measure-
ment. We developed a topology and client behavior
model that tested the elements of the SAFEST system.
And perhaps most importantly, the collaborative organi-
zation of the red teaming exercises and the high level of
interaction between the system developers and the Red
Team enabled the discovery of a vulnerability located
within a security mechanism that might not otherwise
have been detected.

From our experiences as developers during the
SAFEST red teaming process, we can extract several
lessons from our methodology that may be applied to
other red teaming exercises:

Lesson 1: Developer participation in red teaming
should not be verboten.
Conventional red teaming
exercises are usually carried out without developers’ par-
ticipation, and sometimes without their knowledge [16].
There is obvious and well-established value in maintain-
ing independence between system designers and evalua-
tors: the persons testing a system should not abide by the
same set of assumptions and prejudices as the system’s
developers.

However, we argue that testers can beneﬁt from the
insights and experiences that may be offered by the sys-
tem’s designers. We highlighted one such example in
the case of SAFEST in which interactions between de-
velopers and evaluators led to the discovery of a novel
attack. But more generally, there is a deﬁnite beneﬁt to
gaining feedback of attacks (both successful and unsuc-
cessful) from developers (i.e., the “sandboxing” process
described in Section 3.4). Given the time constraints im-
posed on any realistic red teaming scenario, the behav-
ior of complex and oftentimes distributed systems is best
explained by the system’s architects. The availability of
this knowledge only beneﬁts the red team.

Lesson 2: The network should be considered an at-
tack surface.
The attack surface of an anonymity sys-
tem differs somewhat from that of a standard computer
system. Red teams and penetration exercises are typi-
cally focused on gaining unauthorized access and sub-
verting intended behavior. However, in a distributed
anonymity system such as SAFEST, compromising a sin-
gle element of the network may be insufﬁcient to break
anonymity, and common attack vectors such as social en-
gineering and phishing to obtain passwords have little
meaning.

The focus of red teaming exercises against distributed
anonymity systems should not exclude the ability to sub-
vert the network, since sufﬁcient vulnerabilities may
compromise the system in the aggregate (for example,
the ability to partition the network permits the discovered
School of Fish attack). Red teams should pay particu-
lar focus on the areas where the behavior of an attacker
may compromise anonymity without necessarily assum-
ing complete control.

Lesson 3: A successful collaborative red teaming ex-
ercise requires careful organization.
The advantages
of having a third-party evaluate the security of a system
depend on the ability of the evaluators to freely assess
the system without biases from the developers. In a col-
laborative red team exercise, this independence should
be strictly maintained: the red team should operate ac-
cording to their own plans and without inﬂuence from
developers. During the red teaming process, the devel-
opers should maintain only a supporting role, answering
questions and helping to explain system behavior.

The relationship between the red team and the devel-
opers should not be adversarial. In particular, it should
be the common goal of each group to identify (and pos-
sibly resolve) vulnerabilities. To enable participants to
communicate freely without the need for self-censorship,
there should be no repercussions to the developers for de-
tected vulnerabilities.

Lesson 4: Physical presence matters.
During
SAFEST testing, the Red Team and SAFEST develop-
ers were co-located for the duration of the evaluation
stage. This made possible the sandboxing phase of the
evaluation methodology and likely reduced any confu-
sion that would have been due to high latency commu-
nication. We advocate that future red teaming exercises
adopt this model. Onsite access to developers enables
more immediate and unfettered collaborations, and pro-
motes the use of developers as available resources during
the red teaming process.

6 Conclusion

This paper recounts our experiences as SAFEST develop-
ers during the system’s red teaming exercises. We argue
that a network-aware anonymity system such as SAFEST
presents new and interesting challenges for red teaming,
and that a useful tool for meeting these challenges is the
inclusion of system developers and designers in the red
teaming process.

7

Acknowledgments

We thank our shepherd, Stephen Schwab, and the anony-
mous reviewers for their comments and suggestions. We
are particularly grateful to Brian Caswell and the other
members of the Raytheon SI red team for their exper-
tise and tutelage, and for allowing us to participate in the
red teaming process. We would also like to express our
thanks to the members of the DETER team for helping
us design, model, and test our topology.

This material

This work is partially supported by NFS CAREER
CNS-1149832.
is based upon work
supported by the Defense Advanced Research Project
Agency (DARPA) and Space and Naval Warfare Systems
Center Paciﬁc under Contract No. N66001-11-C-4020.
Any opinions, ﬁndings and conclusions or recommenda-
tions expressed in this material are those of the author(s)
and do not necessarily reﬂect the views of the Defense
Advanced Research Project Agency and Space and Naval
Warfare Systems Center Paciﬁc.

References

[1] M. D. Abrams, S. G. Jajodia, and H. J. Podell, editors.
Information Security: An Integrated Collection of Essays.
IEEE Computer Society Press, Los Alamitos, CA, USA,
1st edition, 1995.

[2] M. Akhoondi, C. Yu, and H. V. Madhyastha. LASTor: A
Low-Latency AS-Aware Tor Client. In IEEE Symposium
on Security and Privacy (Oakland), 2012.

[3] K. Bauer, M. Sherr, D. McCoy, and D. Grunwald. Ex-
perimenTor: A Testbed for Safe and Realistic Tor Exper-
imentation. In USENIX Workshop on Cyber Security Ex-
perimentation and Test (CSET), 2011.

[4] S. Becker, J. Seibert, C. Nita-Rotaru, and R. State. Secur-
ing Application-Level Topology Estimation Networks:
Facing the Frog-Boiling Attack. In International Sympo-
sium on Recent Advances in Intrusion Detection (RAID),
2011.

[5] F. Dabek, R. Cox, F. Kaashoek, and R. Morris. Vivaldi: A
Decentralized Network Coordinate System. SIGCOMM
Comput. Commun. Rev., 34(4):15–26, 2004.

[6] DETER Network Security Testbed.

http://www.

isi.deterlab.net/.

[7] R. Dingledine, N. Mathewson, and P. Syverson. Tor: The
In USENIX Security

Second-Generation Onion Router.
Symposium (USENIX), 2004.

[8] R. Dingledine and S. Murdoch.

provements on Tor,
What We’re Going to Do About

or, Why Tor

Performance Im-
is Slow and
https:

It.

//svn.torproject.org/svn/projects/
roadmaps/2009-03-11-performance.pdf,
March 2009.

[9] S. Hahn and K. Loesing. Privacy-preserving Ways to Es-
timate the Number of Tor Users, November 2010. Avail-
able
at https://metrics.torproject.org/
papers/countingusers-2010-11-30.pdf.

[10] P. Herzog. Open-Source Security Testing Methodology
Manual 2.1. Special Publication 2.1, Institute for Security
and Open Methodologies, August 2003.

[11] R. Jansen and N. Hopper. Shadow: Running Tor in
a Box for Accurate and Efﬁcient Experimentation.
In
Network and Distributed System Security Symposium
(NDSS), 2012.

[12] R. R. Linde. Operating system penetration. In Proceed-
ings of the May 19-22, 1975, national computer confer-
ence and exposition, AFIPS ’75, pages 361–368, New
York, NY, USA, 1975. ACM.

[13] D. McCoy, K. Bauer, D. Grunwald, T. Kohno, and
D. Sicker. Shining Light in Dark Places: Understand-
ing the Tor Network. In Privacy Enhancing Technologies
Symposium (PETS), 2008.

[14] J. Mirkovic, T. Benzel, T. Faber, R. Braden, J. Wro-
clawski, and S. Schwab. The DETER Project: Advanc-
ing the Science of Cyber Security Experimentation and
Test. In IEEE International Conference on Technologies
for Homeland Security (HST), 2010.

[15] K. Sampigethaya and R. Poovendran. A Survey on Mix
Networks and Their Secure Applications. Proceedings of
the IEEE, 94(12):2142–2181, December 2006.

[16] K. Scarfone, M. Souppaya, A. Cody, and A. Orebaugh.
Technical Guide to Information Security Testing and As-
sessment. Special Publication 800-115, National Institute
of Standards and Technology, September 2008.

[17] M. Sherr, M. Blaze, and B. T. Loo. Scalable Link-Based
Relay Selection for Anonymous Routing. In Privacy En-
hancing Technologies Symposium (PETS), August 2009.
[18] M. Sherr, A. Mao, W. R. Marczak, W. Zhou, B. T.
Loo, and M. Blaze. A3: An Extensible Platform for
In Network and Dis-
Application-Aware Anonymity.
tributed System Security Symposium (NDSS), 2010.

[19] C. Soghoian. Enforced Community Standards For Re-
search on Users of the Tor Anonymity Network. In Work-
shop on Ethics in Computer Security Research (WECSR),
2011.

[20] Tor Project, Inc.

Tor Metrics Portal.

https://

metrics.torproject.org/.

[21] C. Weissman. System Security Analysis/Certiﬁcation
Methodology and Results. Technical report, October
1973.

8

