Measuring and Applying Invalid SSL Certiﬁcates:

The Silent Majority

Taejoong Chung∗ Yabing Liu∗ David Choffnes∗ Dave Levin†

Bruce M. Maggs‡ Alan Mislove∗ Christo Wilson∗

∗Northeastern University

†University of Maryland

‡Duke University and Akamai Technologies

ABSTRACT
SSL and TLS are used to secure the most commonly-
used Internet protocols. As a result, the ecosystem of
SSL certiﬁcates has been thoroughly studied, leading
to a broad understanding of the strengths and weak-
nesses of the certiﬁcates accepted by most web browsers.
Prior work has naturally focused almost exclusively on
“valid” certiﬁcates—those that standard browsers ac-
cept as well-formed and trusted—and has largely disre-
garded certiﬁcates that are otherwise “invalid.” Surpris-
ingly, however, this leaves the majority of certiﬁcates
unexamined: we ﬁnd that, on average, 65% of SSL cer-
tiﬁcates advertised in each IPv4 scan that we examine
are actually invalid.

In this paper, we demonstrate that despite their inva-
lidity, much can be understood from these certiﬁcates.
Speciﬁcally, we show why the web’s SSL ecosystem is
populated by so many invalid certiﬁcates, where they
originate from, and how they impact security. Using a
dataset of over 80M certiﬁcates, we determine that most
invalid certiﬁcates originate from a few types of end-
user devices, and possess dramatically diﬀerent proper-
ties than their valid counterparts. We ﬁnd that many of
these devices periodically reissue their (invalid) certiﬁ-
cates, and develop new techniques that allow us to track
these reissues across scans. We present evidence that
this technique allows us to uniquely track over 6.7M de-
vices. Taken together, our results open up a heretofore
largely-ignored portion of the SSL ecosystem to further
study.

Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than the author(s) must be honored. Abstracting with credit is
permitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
IMC 2016, November 14–16, 2016, Santa Monica, CA, USA
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to
ACM. ISBN 978-1-4503-4526-2/16/11. . . $15.00
DOI: http://dx.doi.org/10.1145/2987443.2987454

1.

INTRODUCTION

Secure Sockets Layer (SSL) and Transport Layer Se-
curity (TLS)1 are responsible for securing Internet traf-
ﬁc for a variety of common protocols (HTTP, SMTP,
IMAP, etc.). Coupled with a Public Key Infrastructure
(PKI), SSL provides authenticated identities via certiﬁ-
cate chains and private communication via encryption.
The web’s SSL certiﬁcate ecosystem has been stud-
ied extensively [13, 14, 17, 25, 30, 53], with the broad
goal of better understanding how resilient websites and
browsers are to attacks on end-to-end authentication
and conﬁdentiality. As such, the vast majority of these
studies (we discuss some exceptions in §3) naturally fo-
cus on the valid certiﬁcates found on the web, that is,
the certiﬁcates that are well-formed, are within their
validity periods, have a certiﬁcate chain that veriﬁes
at each level, and are rooted in a widely-trusted set of
root certiﬁcates [8]. The prior studies focused almost
exclusively on valid certiﬁcates because, after all, if a
certiﬁcate is not valid, one cannot conﬁdently attribute
it to the websites under study.

In this paper, we take another look at the SSL cer-
tiﬁcate ecosystem, focusing not only on the valid cer-
tiﬁcates, but also the invalid ones. Using a dataset
of over 80M certiﬁcates collected from 222 full IPv4
scans over three years, we ﬁnd, surprisingly, that almost
88% of certiﬁcates we observe across all these IPv4-wide
scans are invalid. In other words, most prior studies of
the SSL certiﬁcate ecosystem have focused on a mere
12% of the overall space of SSL certiﬁcates. The broad
goal of this paper is to understand why so much of the
web’s PKI consists of invalid certiﬁcates, to evaluate
from where these certiﬁcates originate, to understand
the security implications of these certiﬁcates, and to
demonstrate the value in this long-overlooked portion
of the certiﬁcate ecosystem.

We make the following contributions. First, we per-
form a study of all invalid SSL certiﬁcates collected from
full IPv4 port 443 scans over three years. We ﬁnd that
invalid certiﬁcates have considerable diﬀerences from

1TLS is the successor of SSL, but both use the same cer-
tiﬁcates. We refer to “SSL certiﬁcates,” but our ﬁndings apply
equally to both.

527their valid counterparts in terms of validity periods, life-
times, expiration dates, and sharing of public keys.

Second, we evaluate the origins of these invalid certiﬁ-
cates, and ﬁnd that they largely originate from users’
end-devices, including wireless access points, printers,
VoIP phones, and cable modems (for which the cer-
tiﬁcates are used to enable “secure” remote administra-
tion). Moreover, we ﬁnd that invalid certiﬁcates tend
to be advertised by many fewer hosts, and that they are
advertised in a very diﬀerent portion of the IP address
space than valid certiﬁcates.

Third, we ﬁnd that many of these devices periodi-
cally reissue new (invalid) certiﬁcates, and we evalu-
ate the behavior of such reissues. Tracking reissues of
invalid certiﬁcates proves to be considerably more dif-
ﬁcult than for valid ones, as invalid certiﬁcates often
have non-unique Common Names or modify their Common
Name on each reissue (whereas a valid website generally
maintains its domain name as its Common Name in all of
its certiﬁcates). We develop a set of techniques that al-
low us to link multiple invalid certiﬁcates that are likely
to come from a single device.

Fourth, applying our techniques to link together dif-
ferent certiﬁcates, we demonstrate that invalid certiﬁ-
cates can be used as a means to track millions of user
devices as they change IP addresses. Our techniques
oﬀer a complementary view to those provided by other
device-tracking schemes [1, 2, 40, 47] in that our tech-
niques do not require us to recruit users, and can be
performed at scale; we show that we are able to track
6.7M unique end-user devices for over a year.

We make all of our code and data publicly available

to the research community at

https://securepki.org

The remainder of this paper is organized as follows:
we provide background in §2 and an overview of related
work in §3. We describe our dataset and methodology
in §4. In §5, we evaluate the properties of the invalid
certiﬁcates and compare them to those of valid certiﬁ-
cates. We present and evaluate our methodology for
detecting reissues of invalid certiﬁcates in §6. In §7, we
explore using our techniques to track end-user devices,
and we conclude in §8.
2. BACKGROUND

SSL and TLS now secure the vast majority of online
communication. Combined with the use of a PKI, they
provide authentication between clients and servers, and
guarantee the privacy of the communication.

SSL certiﬁcates. A certiﬁcate is a signed attestation
binding a subject (called a Common Name in practice) to
a public key. Typically, SSL certiﬁcates are issued by a
trusted Certiﬁcate Authority (CA), which has its own
certiﬁcate(s); these CA certiﬁcates are further signed by
other CA certiﬁcates, terminating at a small set of self-
signed root certiﬁcates. Thus, there is a logical chain of

certiﬁcates, starting from a root certiﬁcate through zero
or more intermediate certiﬁcates, to a leaf certiﬁcate.
Each certiﬁcate is signed with the private key corre-
sponding to the certiﬁcate in the higher level, except
the self-signed root certiﬁcate. When a client connects
to an HTTPS-secured site, it must verify that the cer-
tiﬁcate advertised by the server is valid.

On the Internet, X.509 [8] is the most commonly
used certiﬁcate management standard. X.509 certiﬁ-
cates typically include a subject and public key, a serial
number (unique for the issuer), a validity period, ac-
ceptable usage of the key, and ways to check whether
the certiﬁcate has been revoked [30].

Invalid certiﬁcates. The X.509 RFC [8] deﬁnes a cer-
tiﬁcate as invalid if a client is unable to validate it at
some point in time. There are multiple reasons that
a client could ﬁnd a certiﬁcate to be invalid:
it could
be outside of its validity period, it could have been re-
voked by its CA, its subject could be incorrect, its sig-
nature could be wrong, and so on. Because our dataset
spans years (§4), we deﬁne a certiﬁcate as invalid if no
client with a standard set of root certiﬁcates would ever
be able to validate it (i.e., we ignore expiry warnings).
The most common reason for invalidity that we have
observed is certiﬁcates signed by an unknown or un-
trusted root; if the client does not trust the root of a
certiﬁcate chain, it transitively does not trust the rest
of the chain. Speciﬁcally, in our dataset, we found that
88.0% of invalid certiﬁcates are self-signed (i.e., the root
of the chain is the leaf certiﬁcate itself) and a further
11.99% are signed by a diﬀerent, untrusted certiﬁcate
(i.e., the root of the chain is some other certiﬁcate that
is not in the set of trusted root certiﬁcates).2

Internet-connected devices. Internet-connected de-
vices are widely popular today,
including end-user
routers, printers, cable/DSL modems, IP cameras, VoIP
telephones, thermostats, and network-attached storage
devices. Many of these devices provide a web server to
allow end users to access and manage the device. A
recent trend is to enable both HTTP and HTTPS ver-
sions of this web server; devices that do so need an SSL
certiﬁcate for the HTTPS site.

While some devices allow users to upload a certiﬁcate,
we ﬁnd that most generate and use an invalid certiﬁcate
by default. There are several reasons for this behavior.
First, until recently [31], obtaining valid SSL certiﬁ-
cates cost money. Given that many of these devices are
not expensive, providing valid SSL certiﬁcates might
substantially raise costs. Second, the Common Name of
HTTPS certiﬁcates are domain names or IP addresses.
However, not all users have a domain name or a static IP
address to provide for a certiﬁcate. Third, using an in-
valid certiﬁcate allows the device to function “out of the
box,” as most users tend to click through “invalid cer-

2The other 0.01% are found invalid predominantly due to sig-

nature errors and openssl parsing errors.

528tiﬁcate” warnings presented by their browsers [3]; this
unfortunately results in weaker security.3

3. RELATED WORK

In this section, we discuss related studies of the SSL
certiﬁcate ecosystem. As we show here, however, we are
the ﬁrst to study invalid certiﬁcates in depth.

SSL certiﬁcate ecosystem. There is a long thread of
work on the SSL certiﬁcate ecosystem, ranging from
measurements of CAs, certiﬁcates they issued, and
client root stores [14, 25, 38, 50] to new techniques that
can improve the existing SSL ecosystem [28, 34, 42, 45]
to alternate architectures to the current CA-based sys-
tems [7, 12, 48]. Several closely related papers [13, 30,
52, 53] have explored the patterns of reissuing and re-
voking certiﬁcates, many using the Heartbleed vulnera-
bility incident as a way to obtain visibility into system
administrators’ behavior.

Our work complements these, as they are focused
largely on valid certiﬁcates. Instead, we focus primarily
on the invalid certiﬁcates, explore how their properties
diﬀer, and understand why the ecosystem is dominated
by invalid, rather than valid, certiﬁcates. Moreover,
the dataset we use is considerably broader, including
all certiﬁcates advertised on public IPv4 address over
three years.

Invalid certiﬁcates. Many of the studies of the SSL
ecosystem discussed above also brieﬂy looked at invalid
certiﬁcates. For example, Holz et al. [25] demonstrated
in 2011 that 40% of certiﬁcates were invalid, and Du-
rumeric et al. [14] demonstrated in 2013 that this frac-
tion had grown to 60%. Neither study, however, focused
extensively on such invalid certiﬁcates (e.g., Durumeric
et al. noted that invalid certiﬁcates tend to have shorter
lifetimes, but did not explore why this was the case).

There has been extensive work on examining the
SSL certiﬁcate validation code implemented by diﬀer-
ent non-browser software and native mobile applica-
tions [18, 19, 21]. These eﬀorts have demonstrated that
many implementations silently accept invalid certiﬁ-
cates. Similarly, our recent work [30] has discovered
several bugs and omissions when major browsers and
operating systems attempt to validate revoked certiﬁ-
cates. Another study [3] has found that many users ig-
nore browsers’ warnings that invalid certiﬁcates are en-
countered. Huang et al. studied the usage of forged SSL
certiﬁcates [23], which have been used in man-in-the-
middle attacks on Facebook. They showed that 0.2%
of the SSL connections analyzed were tampered with
forged SSL certiﬁcates, mostly by anti-virus software
and corporate content ﬁlters. Taken together, these
results show that, although invalid certiﬁcates are ig-
nored by most studies of the SSL ecosystem, they are

3Invalid certiﬁcates make it signiﬁcantly easier for an attacker
to conduct a man-in-the-middle attack, as the browser is unable
to verify it is communicating directly with the device.

not ignored by all browsers and users. In this paper, we
seek to understand where invalid certiﬁcates come from,
what role they play in today’s SSL ecosystem, and how
they can be used as a measurement tool.

4. DATA AND METHODOLOGY

In this section, we describe the datasets we collected
and our methodology to isolate the invalid certiﬁcates
used in the remainder of this study.
4.1 Certiﬁcate Dataset

We obtain our collection of SSL certiﬁcates from two
sets of full IPv4 port 443 scans. Our ﬁrst dataset was
collected by the University of Michigan [49], with 156
scans conducted between June 10, 2012 and January
29, 2014. These scans were not conducted at regular in-
tervals: while there were an average 3.83 days between
scans, there were periods of up to 24 days with no scans
at all, as well as a set of 42 sequential days during which
we have daily scans. Our second dataset was collected
by Rapid7 [44], with 74 scans conducted between Oc-
tober 30, 2013 and March 30, 2015 (an average of 7.73
days between scans). Unlike the University of Michigan
scans, the Rapid7 scans were almost always conducted
seven days apart. On eight days, both datasets have
scans, resulting in scans on 222 unique days.

The scans found an average of 28M unique IP ad-
dresses responding to SSL handshakes per scan, and a
total of 192M unique IP addresses responding to SSL
handshakes across all scans (4.49% of the entire IPv4
address space). Across all scans, we observe 80,366,826
unique certiﬁcates; 39,147,006 of these are version 3
leaf certiﬁcates, 28,997,853 are version 3 CA certiﬁcates,
and 12,132,294 are version 1 certiﬁcates.4,5

Dataset inconsistency. While both datasets claim
to be full IPv4 scans, we observed that the two scans
actually had diﬀerent sizes: the Rapid7 scans consis-
tently contained approximately 20% fewer IP addresses
than the University of Michigan scans. Looking more
closely, we found that the Rapid7 scans were not a strict
subset of the University of Michigan scans: there were
also a signiﬁcant number of IP addresses that only ap-
peared in the Rapid7 scans. Figure 1 selects one of the
days where both data sources have a scan, and plots the
fraction of hosts in each /8 network that only appear
in one of the scans. We can immediately observe that
the “missing” hosts from each scan appear to be spread
across the entire IP space.6 After communicating this
observation to Rapid7 [26], they were unable to track
down the source of this discrepancy.

4Valid SSL version 1 certiﬁcates are largely deprecated as they
cannot distinguish between leaf and CA certiﬁcates; the only valid
version 1 certiﬁcates are a few older root certiﬁcates.

5We also found 89,667 certiﬁcates that contain invalid version
numbers, including 2, 4, and 13. We disregarded such certiﬁcates.
6We provide a more detailed examination of the inconsistency

at the level of /24 preﬁxes at https://securepki.org.

529Figure 1: The fraction of hosts unique to each scan, for
each /8 network, on a day with both a University of Michi-
gan and a Rapid7 scan. The “missing” hosts in each scan
appear to be spread throughout the IP space.

To explore this discrepancy further, we ﬁrst examine
whether the discrepancy might be explained by black-
listing by either the scan operators or the target net-
works (Rapid7 conﬁrmed to us that they have a growing
list of networks that requested to not be scanned). If
blacklisting were the cause, we would expect to see cer-
tain networks (i.e., BGP preﬁxes) consistently missing
from one or both scans.

To test our blacklisting hypothesis, we focus on the
eight days where both Rapid7 and the University of
Michigan performed full IPv4 scans. We group the
IP addresses into their advertised BGP preﬁxes using
historic RouteViews data [9]. While there was an av-
erage of 285,519 BGP preﬁxes that were covered by
both scans, we found that 1,906 BGP preﬁxes were al-
ways missing from the University of Michigan scans but
present in the Rapid7 scans, and 11,624 BGP preﬁxes
were always missing from the Rapid7 scans but present
in the University of Michigan scans. Moreover, these
missing BGP preﬁxes account for much of the discrep-
ancy between the two scans: On average, the Univer-
sity of Michigan scans contained 282,620 IP addresses
that the Rapid7 scans did not; on average, 74.0% of
these came from the BGP preﬁxes that Rapid7 never
covered. Similarly, on average, the Rapid7 scans con-
tained 84,646 IP addresses that the University of Michi-
gan scans did not; on average, 62.6% of these came from
the BGP preﬁxes that University of Michigan never cov-
ered. Thus, it appears that much of the discrepancy is
due to blacklisting of diﬀerent BGP preﬁxes, either by
the scan operators or by the destination network.
4.2 Isolating Invalid Certiﬁcates

Recall that a certiﬁcate is invalid when it is outside
its validity period, it is signed by an untrusted certiﬁ-
cate, its signature is incorrect, etc. To isolate invalid
certiﬁcates, we run openssl verify on each certiﬁcate.
Because the scans and validation processes occurred at
diﬀerent points of time, we ignore certiﬁcate validation
errors only due to expiration times (i.e., we consider
a certiﬁcate to be valid if it was valid at some point
in time). We also conﬁgure OpenSSL to trust the set

Figure 2: The number of invalid and valid certiﬁcates in
University of Michigan and Rapid7 datasets.

of 222 root CA certiﬁcates included by default in the
OS X 10.9.2 root store [37]. Finally, we validate all
intermediate certiﬁcates before validating leaf certiﬁ-
cates; this process allows us to construct a valid chain
even if the server presented an incorrect chain (so-called
“transvalid” certiﬁcates [29]).

Through this process, we isolate 70,637,981 invalid
certiﬁcates (87.9% of all certiﬁcates) and 9,728,845 valid
certiﬁcates (12.1%). Examining openssl’s output, we
observe that 88.0% of the invalid certiﬁcates fail vali-
dation because they are self-signed,7 11.99% are invalid
because they are signed by another, untrusted certiﬁ-
cate, and 0.01% are invalid for a variety of other rea-
sons. We use this group of invalid certiﬁcates as the
basis for the analysis in the rest of our paper.

Inspecting the invalid certiﬁcates’ Common Name lends
some insight into their origins; many have domain
names corresponding to Internet Service Providers
(ISPs, such as FRITZ!Boxes’ fritz.net) and cloud-
accessible storage devices (such as the domain of West-
ern Digital’s My Cloud, wd2go.com). This provides an
initial indication of end-user devices; we explore the ori-
gins of invalid certiﬁcates more thoroughly in §5.

Figure 2 shows the number of invalid and valid certiﬁ-
cates found in the University of Michigan and Rapid7
datasets. The number of invalid certiﬁcates is increas-
ing in both of the datasets, which aligns with our obser-
vation of the increasing popularity of HTTPS-enabled
end-user devices (§2). Looking at each scan, we found
that the fraction of invalid certiﬁcates varied between
59.6% and 73.7%, with an average of 65.0%. The cause
of the disparity between the average fraction of invalid
certiﬁcates per scan (65.0%) and the fraction across all
scans (87.9%) will become clear in the following section
when we investigate the certiﬁcates’ lifetimes.

5. COMPARISON TO VALID CERTS

We begin our analysis by comparing the 70M invalid
certiﬁcates to the 9.7M valid certiﬁcates, with the un-

7We identiﬁed self-signed certiﬁcates as those where openssl
returned error code 19 (self-signed) or where we manually veriﬁed
the certiﬁcate’s signature with its own public key. The second
step is necessary as openssl is known to only generate error 19 if
the certiﬁcate is self-signed and the subject and issuer match.

 0 0.2 0.4 0.6 0.8 11.0.0.0/864.0.0.0/8128.0.0.0/8192.0.0.0/8Fraction Hosts UniqueNetworkU. MichiganRapid7 0 1x106 2x106 3x106 4x106 5x106 6x106 7x10601/01/1209/01/1205/01/1301/01/1409/01/1405/01/15Univ. Michigan InvalidUniv. Michigan ValidRapid7 InvalidRapid7 Valid# of CertificatesScan Date530Figure 3: Cumulative distribution of the validity periods
for both valid and invalid certiﬁcates. The validity periods
of invalid certiﬁcates diﬀer signiﬁcantly, with 5.38% of them
having a negative validity period, and others lasting decades.

Figure 4: Cumulative distribution of the lifetimes of both
valid and invalid certiﬁcates. The lifetime of invalid certiﬁ-
cates is far shorter than its validity period: 60% of invalid
certiﬁcates’ lifetimes are a single day.

derlying goal of understanding why so much of the PKI
consists of invalid certiﬁcates. We start by evaluating
how invalid certiﬁcates diﬀer from their valid counter-
parts across several diﬀerent properties, including key
lengths, lifetimes, and geographic distribution.
5.1 Certiﬁcate Longevity

One possible explanation for why there are so many
more invalid certiﬁcates than valid ones across our
years-long dataset is that some hosts replace invalid cer-
tiﬁcates more frequently. We investigate this by exam-
ining two characteristics of certiﬁcates: their validity
periods and their lifetimes.

First, we examine the certiﬁcates’ validity period, or
the time between the certiﬁcates’ Not Before and Not
After [20] dates (the ﬁrst and last dates, respectively,
during which the certiﬁcate should be considered valid).
Figure 3 shows the cumulative distribution of all valid
and invalid certiﬁcates’ validity periods. The distri-
butions are starkly diﬀerent. Valid certiﬁcates typi-
cally have narrow validity periods, with a median of
1.1 years and a 90th percentile of 3.1 years. Conversely,
invalid certiﬁcates have an exceedingly large range, with
a median of 20 years, a 90th percentile of 25 years,
and some with Not After dates that end in the year
3000 or beyond, resulting in validity periods greater
than 1M days. Moreover, we observe that 5.38% of
invalid certiﬁcates have Not After dates prior to Not
Before dates, which results in negative validity period
(not shown in the graph, but note the Invalid line starts
at y = 0.0538). The diﬀerences between these distribu-
tions indicate that the manner in which valid and invalid
certiﬁcates are created also diﬀers signiﬁcantly.

Second, we examine the certiﬁcates’ lifetime, or the
(inclusive) time between the ﬁrst scan and the last scan
where we saw the certiﬁcate. For example, if we only
saw the certiﬁcate on a single day, we calculate the life-
time to be one day; if we saw the certiﬁcate on two scans
a week apart, we calculate the lifetime to be 8 days.8
Figure 4 shows the cumulative distribution of all valid

8Our calculation of a certiﬁcate’s lifetime is a lower bound on

its true lifetime, due to the periodic nature of our scan data.

and invalid certiﬁcates’ lifetimes. Here, too, we see dras-
tically diﬀerent distributions: the median lifetime for
valid certiﬁcates is 274 days, while the median lifetime
for invalid certiﬁcates is one day! This means that the
majority of invalid certiﬁcates were observed in only a
single scan, implying that they are ephemeral (i.e., the
device that served these certiﬁcates likely reissues its
certiﬁcate on a regular basis). An alternative explana-
tion is that users are manually updating the certiﬁcates
in their devices at least once a week, on average, but we
believe this to be unlikely.

To provide additional evidence that these ephemeral
certiﬁcates are likely reissued, we compare each
ephemeral certiﬁcate’s Not Before date to the day we
observed the certiﬁcate. We anticipate that a Not Be-
fore date typically has the same day as when its certiﬁ-
cate was created; assuming this, if most of the Not Be-
fore dates are close to the scan dates, it suggests that
the certiﬁcates were generated right before our scan.
The cumulative distribution of this diﬀerence is shown
in Figure 5. Interestingly, we notice a bi-modal distri-
bution: 70% of ephemeral certiﬁcates show a diﬀerence
of less than four days, while 20% show a diﬀerence over

Figure 5: Cumulative distribution of the diﬀerence be-
tween ephemeral certiﬁcates’ ﬁrst advertised and Not Be-
fore dates for all invalid certiﬁcates. Note that y-axis starts
at 32.9%: For 30% of the certiﬁcates, these were the same
date; for 2.9%, the Not Before date was after the ﬁrst ad-
vertised date (negative values not shown in the plot). The
long tail reaches to 42,091 days.

 0 0.2 0.4 0.6 0.8 1100101102103104105106107CDFValidity Period (Days)InvalidValid 0 0.2 0.4 0.6 0.8 1 0 200 400 600 800 1000 1200CDFLifetime (Days)InvalidValid 0 0.2 0.4 0.6 0.8 1100101102103104105CDF First Advertised Date - Not Before Date (Days)531Top Issuers of Valid Certiﬁcates

Go Daddy Secure Certification Authority
RapidSSL CA
PositiveSSL CA 2
Go Daddy Secure Certificate Authority - G2
GeoTrust DV SSL CA

Top Issuers of Invalid Certiﬁcates

www.lancom-systems.de
192.168.1.1
(Empty string)
remotewd.com
VMware

Num.

1,869,701
969,879
511,894
436,055
435,477

Num.

4,691,873
2,438,776
925,579
881,406
748,937

Table 1: The top ﬁve issuers of valid and invalid certiﬁ-
cates. Our results for valid certiﬁcates align with prior
work [14]; our results from invalid certiﬁcates suggest that
end-user devices are prevalent.

In fact, we found that one particular public key is
shared by 4,586,469 certiﬁcates (6.5% of all invalid cer-
tiﬁcates in our dataset)! We manually inspected these
certiﬁcates and found that they are all issued by Lan-
com Systems, a German company manufacturing home
routers and wireless access points. This observation in-
dicates that a large number of Lancom devices use the
same key pair making them potentially vulnerable to
impersonation or snooping if an attacker is able to ex-
tract the private key from one of these devices10.

These results provide further evidence that invalid
certiﬁcates represent a fundamentally diﬀerent point in
the certiﬁcate landscape, and are not simply valid cer-
tiﬁcates that have “gone bad.” This raises the question:
who issues the invalid certiﬁcates in the ﬁrst place?
5.3 Issuer Diversity

We evaluate who issues invalid certiﬁcates by inves-
tigating two properties. First, we consider the diversity
of the keys used to sign the invalid certiﬁcates. Prior
studies have identiﬁed the relatively low diversity in the
set of issuers for valid certiﬁcates [14, 25]. Our results
conﬁrm this, showing that just ﬁve signing keys (out of
1,477 observed valid keys) is enough to span half of all
valid certiﬁcates.

When we consider the invalid certiﬁcates, the results
are quite diﬀerent. Recall that over 88.0% of invalid
certiﬁcates are self-signed, immediately making it ap-
pear as if they have signiﬁcant diversity. However, even
if we focus on the non-self-signed certiﬁcates that list
their Authority Key ID, we ﬁnd that invalid certiﬁ-
cates appear to have greater parent key diversity than
valid certiﬁcates: the top ﬁve keys only cover 37% of
the certiﬁcates. Moreover, we observe a total of 1.7M
unique parent keys (as opposed to only 1,477 unique
parent keys for valid certiﬁcates).

10Additionally, we found that these devices do not support
Perfect Forward Secrecy (PFS) [27], meaning that their historic
traﬃc is also vulnerable to decryption.

Figure 6: Fraction of public keys (x) needed to cover a
given fraction of valid and invalid certiﬁcates (y). There is
a signiﬁcant diﬀerence in the two distributions, with invalid
certiﬁcates showing signiﬁcantly higher rates of sharing keys.

1,000 days. This indicates that ephemeral certiﬁcates
are largely from devices that reissue their certiﬁcates on
a regular basis.
In §6, we present techniques that allow us to “link”
these reissued certiﬁcates together, enabling us to track
a given device’s reissued certiﬁcates. In the remainder
of this section, we seek to understand the root cause
and origins of invalid certiﬁcates.
5.2 Key Diversity

In principle, each unique SSL certiﬁcate should carry
the Public Key from a unique key pair, as the certiﬁ-
cate binds a subject (e.g., a domain name) to a Pub-
lic Key. If Public Keys are shared across certiﬁcates
owned by diﬀerent domains, either party could imper-
sonate the other.

Figure 6 shows the relationship between the fraction
of certiﬁcates and the fraction of public keys they span.
In an ideal case—wherein each certiﬁcate has a unique
public key—this would result in a linear relationship
with y = x. However, given that a certiﬁcate can have
at most one public key, it must be the case that y ≥ x in
this plot; the larger this inequality, the more certiﬁcates
there are that share the same public key.

Figure 6 shows that neither valid or invalid certiﬁ-
cates exhibit a perfect y = x line. This result is some-
what expected: Zhang et al. [53] found that nearly half
of all reissues of valid certiﬁcates in the Alexa top-1M
are done with the same public key.9

However, the invalid certiﬁcates exhibit signiﬁcantly
less diversity of public keys. To our surprise, we observe
that over 47% of invalid certiﬁcates share their Public
Key with another certiﬁcate. As a point of compari-
son, Heninger et al. [24] found that over 60% of hosts
scanned in 2012 were observed to share keys with an-
other host; the discrepancy between their results and
ours is likely to due to looking at hosts (as they do)
versus certiﬁcates (as we do).

9This is an acceptable security practice as long as the private
key has not been compromised. However, in the case of Heart-
bleed (which potentially exposed private keys), Zhang et al. [53]
found that 4.1% of reissues were still done with the same key.

 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1y=xFraction of CertificatesFraction of Public KeysInvalidValid532Figure 7: Cumulative distribution of the average number
of IP addresses advertising each certiﬁcate across all scans.
Valid and invalid certiﬁcates exhibit signiﬁcantly diﬀerent
distributions. Note that the y-axis starts at 0.75; the long
tail for invalid certiﬁcates extends to over 3.6M IP addresses.

Figure 8: Cumulative distribution of the number of au-
tonomous systems from which valid and invalid certiﬁcates
are served. Although invalid certiﬁcates far outnumber valid
ones, they originate from fewer ASes. 18% of all invalid cer-
tiﬁcates originate from a single AS.

Second, we examine the most frequent Common Names
of the certiﬁcates used to sign valid and invalid certiﬁ-
cates in Table 1. The most common issuers of valid
certiﬁcates are well-known CAs, such as GoDaddy and
RapidSSL (similar to ﬁndings in prior studies [14]).
The invalid certiﬁcates’ issuers are far less standard.
We see several device manufacturers,
including Lan-
com Systems, and Western Digital. Additionally, a
large fraction of invalid certiﬁcates are issued by mal-
formed Common Names, including private IP addresses
(e.g., 3,353,464 invalid certiﬁcates were issued with a
common name from 192.168.0.0/16) or empty strings.
Ultimately, these results indicate a bimodal distribu-
tion of the source of invalid certiﬁcates: many originate
from a small set of issuers while the majority are self-
signed. In other words, invalid certiﬁcates are largely
issued by the very hosts who serve them. Next, we turn
our attention to investigating these hosts directly.
5.4 Host Diversity

We expect that invalid certiﬁcates do not represent
globally replicated websites. To evaluate this hypothe-
sis, we consider the diversity of hosts who serve invalid
versus valid certiﬁcates. We measure the average num-
ber of unique IP addresses that advertise the certiﬁcate
during each scan.

IP address diversity. Figure 7 shows the cumula-
tive distribution of the average number of IP addresses
advertising each certiﬁcate per scan, for all invalid and
valid certiﬁcates. We observe that the majority of both
valid and invalid certiﬁcates are advertised by just a sin-
gle host (note that the y axis starts at 0.75). However,
we observe that invalid certiﬁcates are, overall, adver-
tised by far fewer hosts. The 99th percentile of invalid
certiﬁcates are served by 2.0 hosts, while the same 99th
percentile of valid certiﬁcates are served by 11.3 hosts.
In fact, we observe valid CA certiﬁcates that are served
by over 3.6M IP addresses!

These results show that, across our entire dataset,
there is a (nearly) one-to-many mapping between IP

addresses and invalid certiﬁcates. It may thus be feasi-
ble to track end-user devices based on their invalid SSL
certiﬁcate. We explore this application in §7.

AS diversity. One might expect that because invalid
certiﬁcates far outnumber valid certiﬁcates, they come
from a much larger set of IP addresses, and thus per-
haps a more diverse set of ASes. On the other hand,
the results from Figure 7 show that a single valid cer-
tiﬁcate can be served from many distinct IP addresses,
and thus valid certiﬁcates may come from a larger set
of ASes. To resolve this, we show in Figure 8 the diver-
sity of ASes for both valid and invalid certiﬁcates, by
mapping the IP addresses advertising certiﬁcates into
ASes using CAIDA’s historic RouteViews dataset [9]
Both show a surprising number of certiﬁcates originat-
ing from a small number of ASes; 10% of all valid certiﬁ-
cates and 18% of all invalid certiﬁcates originate from a
single AS. Beyond this small number of popular ASes,
the invalid certiﬁcates exhibit signiﬁcantly less diversity
in their origins than valid ones; a set of 165 ASes ac-
counts for 70% of all invalid certiﬁcates, while it takes
a set of 500 ASes to account for the 70% of valid cer-
tiﬁcates.

To explore which ASes the certiﬁcates come from,
we classiﬁed the ASes using CAIDA’s AS classiﬁcations
dataset [10]. Table 2 shows the resulting distribution;
we can immediately observe that valid certiﬁcates come

AS Type

% of Valid % of Invalid

Transit/Access
Content
Enterprise
Unknown

46.6%
42.9%
7.8%
2.6%

94.1%
4.7%
1.5%
1.7%

Table 2: Breakdown of AS types where certiﬁcates are
advertised, based on CAIDA’s classiﬁcation [10]. Most in-
valid certiﬁcates come from transit/access networks, while
most valid certiﬁcates are advertised from transit/access and
content networks. Content networks are the most likely to
advertise a valid certiﬁcate instead of an invalid one.

 0.75 0.8 0.85 0.9 0.95 1100101102Cumulative Fractionof CertificatesAvg. Number of IP Addresses Hosting a CertificateInvalidValid 0 0.2 0.4 0.6 0.8 1100101102103104105Cumulative Fractionof CertificatesNumber of ASes Hosting a CertificateInvalidValid533Top ASes Hosting Valid Certiﬁcates

#26496 GoDaddy.com, LLC (USA)
#46606 Uniﬁed Layer (USA)
#14618 Amazon, Inc. (USA)
#36351
#16509 Amazon, Inc. (USA)

SoftLayer Technologies (USA)

Top ASes Hosting Invalid Certiﬁcates

#3320 Deutsche Telekom AG (DEU)
#7922 Comcast Cable Comm., Inc. (USA)
#3209 Vodafone GmbH (DEU)
#6805 Telefonica Germany GmbH (DEU)
#4766 Korea Telecom (KOR)

Num.

836,521
224,806
171,689
168,285
151,048

Num.

12,115,594
2,889,282
2,525,880
1,808,687
1,795,298

Table 3: The top ﬁve ASes (with AS number and country)
from which valid and invalid certiﬁcates are hosted.

from both Content networks (e.g., large websites) and
Transit/Access networks (e.g., ISPs, and major ISPs
who are hosted primarily on ASes other than their own),
while invalid certiﬁcates almost exclusively come from
the latter.

To underscore this diﬀerence, Table 3 shows the ASes
from which valid and invalid certiﬁcates are most fre-
quently hosted. The top ASes for valid certiﬁcates are
all in the United States, and constitute a combination of
popular hosting services. Conversely, invalid certiﬁcates
are more geographically dispersed, with many hosted in
Germany. Moreover, the hosting ASes of invalid certiﬁ-
cates correspond largely with end-user home ISPs.

Device diversity. Finally, we investigate the types
of the actual devices hosting the invalid certiﬁcates.
We did this manually by looking up model numbers
included in certiﬁcates and by simply loading the web
pages from the IP addresses hosting invalid certiﬁcates
and inspecting them. Because this was a manual pro-
cess, we restricted this investigation to the certiﬁcates
corresponding to the top 50 issuers.

Table 4 shows the breakdown of invalid certiﬁcates
by device type. From this subset of the most common
issuers, we see that the greatest contributor of invalid
certiﬁcates is home routers and cable modems. In gen-
eral, invalid certiﬁcates tend to be served by Internet
devices, such as routers, VPNs, ﬁrewalls, and remote
storage devices. There is also a relatively wide range of
other devices, such as IPTVs and IP phones. Based on
these results, we anticipate that, as these devices be-
come increasingly popular—and particularly with the
growing trend towards an Internet of Things—the num-
ber of invalid certiﬁcates will continue to grow.
5.5 Summary

We began this section with the goal of better under-
standing why so much of the SSL ecosystem consists
of invalid certiﬁcates. We found that the large portion
of invalid certiﬁcates is caused by devices that reissue
their certiﬁcates on a regular basis, thereby inﬂating the

Pct. Device Type

45.3% Home router/cable modem
32.0% Unknown
6.04% VPN
5.70% Remote storage
4.27% Remote administration
1.92% Firewall
1.78% IP camera
2.62% Other (IPTV, IP phone, Alternate CA, Printer)

Table 4: Device types based on manual analysis of the top
50 issuing CAs. Invalid certiﬁcates tend to be served from
end-user and enterprise devices.

number of invalid certiﬁcates overall (valid certiﬁcates
are typically used for a year or more, whereas many in-
valid certiﬁcates have lifespans of days). We also found
signiﬁcant diﬀerences between valid and invalid certiﬁ-
cates, including that invalid certiﬁcates are more likely
to share keys, be advertised by fewer hosts, and be ad-
vertised from ASes that provide end-user Internet con-
nectivity. In the next section, we take a closer look at
the invalid certiﬁcates to see if we can “link” together
those that originate from the same device.

6. LINKING CERTIFICATES

The results from our comparative study of valid and
invalid certiﬁcates indicate that a relatively small num-
ber of end-user devices regularly reissue new invalid cer-
tiﬁcates. In this section, we develop techniques to “link
together” distinct invalid certiﬁcates as having origi-
nated from the same device.
6.1 Challenges

In the context of valid certiﬁcates, the process of ob-
taining a new version of an existing certiﬁcate is referred
to as reissuing the certiﬁcate. Tracking valid certiﬁcates
reissues is relatively straightforward, as one can gener-
ally match on Common Names; we ﬁnd that it is consid-
erably more diﬃcult with invalid certiﬁcates.

There are two key challenges to linking together in-
valid certiﬁcates. First, a single certiﬁcate can be shared
across many diﬀerent devices—this is also relatively
common with valid certiﬁcates, largely due to services
replicated across multiple physical machines or loca-
tions. We discuss in §6.2 how we distinguish legitimate
duplicates from inconsistencies in the scanning method-
ology. The second challenge is that even for certiﬁcates
that are only ever advertised from a single device at
any one time, surprisingly, there is often no one clear
certiﬁcate ﬁeld that makes it obvious whether two dif-
ferent invalid certiﬁcates were generated by the same
device. Moreover, across the entire dataset, many cer-
tiﬁcate values are shared across many distinct devices,
even those we expected to be unique (such as the Com-
mon Name). In §6.3, we present heuristics to choose and
link together certiﬁcate features and we evaluate in §6.4.

5346.2 Scan Duplicates

Before we attempt to link two distinct certiﬁcates
across certiﬁcate scans, we ﬁrst seek to map a given
certiﬁcate to a device within a single scan. At ﬁrst
glance, it would seem trivially straightforward to treat
the IP address from which a certiﬁcate is advertised as
a unique identiﬁer for the device hosting the certiﬁcate.
However, there is a complicating factor: the scans are
not instantaneous, as it takes up to 10 hours [15] to scan
and collect all certiﬁcates in the entire IPv4 space. Ad-
ditionally, ZMap’s implementation scans IP addresses in
a random order [15] to prevent a sudden surge in traﬃc
to diﬀerent networks. As a result, if a device changes
its IP address during the scan, it is possible that it may
end up being scanned twice from diﬀerent IP addresses
(or more, if it changes more than once and the scan
contacts IP addresses in the right order). Thus, if we
are not careful, certiﬁcates that are unique to a single
device may be incorrectly classiﬁed as shared.

To address this issue, we leverage the fact that most
known dynamic IP assignment policies lease IP ad-
dresses to users on the order of days [32]. Thus, the
case of a device changing its IP address multiple times
during a scan—and the scan discovering these three or
more IP addresses in order—should be rare. We there-
fore set our threshold for certiﬁcate uniqueness to two:
if we observe a certiﬁcate advertised by no more than
two IP addresses during each scan11, we declare the cer-
tiﬁcate to be unique; if we ever observe the certiﬁcate
advertised by more than two IP addresses, we declare
the certiﬁcate to be non-unique.

Thus, for the 1.6% of invalid certiﬁcates that are ad-
vertised from more than two IP addresses (shown in
more detail in Figure 7), we cannot be sure that this
certiﬁcate is not shared across multiple devices. We
exclude these; for the remainder of this section, we con-
sider the remaining 69,481,047 invalid certiﬁcates.
6.3 Linking Certiﬁcates Across Scans

After accounting for scan duplicates, we obtain from
each scan a one-time snapshot of a device-to-certiﬁcate
mapping. We next seek to use the certiﬁcates to “link”
devices from one scan to another. We would ideally like
to link using both features of the certiﬁcate (e.g., the
Common Name) and features that can be observed from
the network connection used to collect the certiﬁcate
(e.g., the initial TCP window size). Unfortunately, the
certiﬁcate scan data contains only the certiﬁcates them-
selves; thus, in the remainder of this section, we focus
on using only features from certiﬁcates and leave other
features to future work.

For valid certiﬁcates, tracking a device across scans is
mostly straightforward. Valid certiﬁcates tend to have

11The only exception to this policy is if we see the certiﬁ-
cate advertised by exactly two IP address in every scan; since IP
addresses are scanned in random order each time, this strongly
suggests that there are two devices with the certiﬁcate. In this
case, we declare the certiﬁcate to be non-unique.

% Non-unique

Feature

67.7% Not Before
67.5% Common Name
61.4% Not After
47.0% Public Key
19.6% Subject Alternate Name List
4.2% Issuer Name & Serial No. (IN + SN)

Table 5: Features from invalid certiﬁcates and the per-
centage of them that are not unique across all scans in our
dataset.

long lifetimes (§5.1), and they generally have unique
Common Names: a certiﬁcate for example.com in one
scan is likely to appear in the subsequent scan, as well.
However, invalid certiﬁcates are often short-lived (§5.1)
and have non-unique Common Names, with 192.168.1.1
being one of the most common (§5.4).
Our insight is driven by our ﬁndings from §5: because
many invalid certiﬁcates are self-signed, we anticipate
that the combination of features of invalid certiﬁcates
will uniquely deﬁne a device (or at least a particular
device vendor). To this end, we examine diﬀerent ﬁelds
within each SSL certiﬁcate to determine whether they
provide clues for linking.
6.3.1 Linkable Features
To determine that two given certiﬁcates correspond
to the same device, we seek features of the certiﬁcates
that remain the same between two scans, but do not
appear in other certiﬁcates (i.e., they uniquely identify
a single device). Table 5 lists the certiﬁcate features we
considered, as well as the percentage of invalid certiﬁ-
cates that have a non-unique value for each feature. For
linking two certiﬁcates, non-uniqueness is a necessary
condition—if two certiﬁcates share no common values,
we cannot link them as coming from the same device.
However, non-uniqueness is not a suﬃcient condition;
for instance, 2,438,776 certiﬁcates share the common
name of 192.168.1.1 (see Table 1), but clearly these
do not map to a single device. Similarly, as shown in
§5.2, many certiﬁcates share the same public keys.

In addition to the features listed in Table 5, we
also considered certiﬁcate extensions that help clients
access the “parent” certiﬁcate and ensure the valid-
ity of the given certiﬁcate: Certificate Revocation
List (CRL) endpoints, Authority Information Ac-
cess (AIA) locations, Online Certificate Status
Protocol (OCSP) responders, and Object IDs (OIDs).
Although these are present in 95% of valid certiﬁcates,
we ﬁnd that they are rarely used in invalid certiﬁcates:
99.2% of invalid certiﬁcates have no CRL, 99.3% have no
AIA location, 99.9% have no OCSP responder, and 99.9%
have no OID. As a result, they link only a small fraction
of certiﬁcates, and they link very few uniquely.

5356.3.2 Linking Methodology
To successfully link certiﬁcates despite the challenges
that the diﬀerent ﬁelds present, we devise a methodol-
ogy to eliminate many false positives by leveraging the
lifetime of each certiﬁcate (where the lifetime is deﬁned
as the time between the ﬁrst scan and the last scan
where the certiﬁcate was observed). Our methodology
is based on the observation that if a device reissued its
certiﬁcate, then the lifetime of the old certiﬁcate must
end and the lifetime of a new certiﬁcate must begin.

Thus, our methodology proceeds as follows. We ﬁrst
group certiﬁcates by shared ﬁeld values: for each ﬁeld
type and each value of that ﬁeld, we collect all certiﬁ-
cates that have that value (i.e., all certiﬁcates with a
Common Name of “WD2GO 293822”, or all certiﬁcates
with a certain public key). Then, we consider this set
of certiﬁcates to be linked (from the same device) so
long as the lifetimes of any pair of these certiﬁcates do
not overlap by more than a single scan.

If any pair of the certiﬁcates’ lifetimes do overlap,
then we do not allow any of these certiﬁcates to be
linked using this ﬁeld (of course, subsets of this group
may be linked using other ﬁelds). The reason we allow
the overlap of certiﬁcates on a single scan is because
devices may change IP addresses (and reissue their cer-
tiﬁcate) during a single scan.

To show the intuition behind this methodology, we
present a few examples in Figure 9. Each box in this
ﬁgure represents a certiﬁcate we observed from a given
IP address on a given scan. Across multiple scans, we
can group certiﬁcates by the public keys they share;
each color in the ﬁgure represents a diﬀerent group of
certiﬁcates, each of which shares a given public key.
For the certiﬁcates sharing PK1, we observe no overlap,
that is, PK1 is only ever advertised from at most one IP
address on any given scan (note that we did not observe
it in the third scan). Therefore, by our methodology,
the PK1 certiﬁcates are linkable across multiple scans.
Likewise, although we see PK2 advertised from several
diﬀerent IP addresses, certiﬁcates 3 and 4 only overlap
on a single scan; thus these certiﬁcates are also linkable.
However, for PK3, we see two scans with overlapping
yet distinct certiﬁcates, and we therefore conclude that
these certiﬁcates are, with high probability, served from
diﬀerent devices. Therefore, the certiﬁcates with PK3
in this example are not linkable.
This methodology eliminates most of the issues with
the certiﬁcate ﬁelds identiﬁed in §6.3.1. In particular,
for ﬁelds that are shared by diﬀerent devices (e.g., the
Lancom public key), our technique marks them as non-
linkable, as the certiﬁcates have signiﬁcant overlap.
6.4 Evaluation

We now evaluate our proposed linking methodology.
Below, we ﬁrst describe our approach to evaluating our
linking procedure before presenting the results.

Figure 9: Timeline of example certiﬁcate lifetimes for three
groups of certiﬁcates. Each box represents a certiﬁcate with
a given Public Key (PK) seen in a given scan. Our method-
ology links the certiﬁcates with public keys PK1 and PK2
across their respective scans, but it marks certiﬁcates with
PK3 as not linkable, as they overlap on more than one scan.

6.4.1 Approach
When trying to evaluate how well our certiﬁcate link-
ing methodology works, we face a signiﬁcant challenge:
we do not have ground truth on whether diﬀerent certiﬁ-
cates are actually from the same device. Thus, we use
the information we do have available to us to serve as
a rough version of ground truth: the IP address where
we saw the certiﬁcate advertised.

Speciﬁcally, to evaluate whether two linked certiﬁ-
cates are from the same device, we ask whether they
were advertised from the same IP address (we refer to
this as IP-level consistency). If they were, we have some
conﬁdence that they are actually from the same device
(recall that we only link groups of certiﬁcates that share
a common ﬁeld and do not have overlapping lifetimes).
Thus, the most likely explanation for a set of certiﬁcates
that have non-overlapping lifetimes, share a common
ﬁeld that no other certiﬁcates have, and are advertised
from the same IP address is that they are from the same
device.

However, it is well-known that many ISPs implement
dynamic IP address assignment policies, meaning de-
vices’ IP addresses may change over time [39]. As a re-
sult, if a device were to change its IP address, it should
be considered a valid linking, but our rule may incor-
rectly mark it as a false positive. To counteract this
eﬀect, we repeat the same analysis, examining whether
the certiﬁcates were advertised by IP addresses in the
same /24 network or whether the certiﬁcates were ad-
vertised by IP addresses in the same AS, referred to
as /24-level consistency and AS-level consistency. Of
course, looking beyond exact IP address matches may
introduce false positives—and assuming that address re-
assignment policies stay within the same /24 may intro-
duce false negatives—but we can get an idea of how the
linking procedure performs overall. For example, if we
observe cases where the linking procedure has low IP-
level consistency but high AS-level consistency, we can

Scan 1Scan 2Scan 3Scan 4IP addr 1IP addr 2IP addr 3IP addr 4IP addr 5IP addr 6Cert 7Cert 8Cert 1Cert 2Cert 2Cert 3Cert 4Cert 4Cert 5???Cert 6Cert 6Cert 7PK1PK2PK3Cert 4Cert 3536Total linked
Uniq. linked
IP-consistency
/24-consistency
AS-consistency

Public Key
23,276,298
11,798,203
41.9%
46.1%
98.0%

Not Before
16,301,321
5,296,175
53.5%
54.3%
63.0%

Common Name
8,576,231
1,794,118
51.1%
53.3%
96.6%

Not After
6,235,419
1,197,317
51.2%
52.9%
58.2%

IN + SN
4,193,744
955,764
48.2%
49.6%
89.3%

SAN
2,484,652
123,740
52.2%
55.0%
97.5%

CRL
389,264
4,912
85.8%
87.2%
95.2%

OCSP
3,352
185

OID
AIA
593
377,310
3,192
121
85.7% 52.2% 83.9%
87.1% 55.0% 86.6%
95.1% 97.5% 92.6%

Table 6: The linking performance of diﬀerent SSL certiﬁcate ﬁelds (IN + SN is Issuer Name & Serial No.). The ﬁrst two
rows show the total number of certiﬁcates linked by each ﬁeld, and the total number of certiﬁcates linked only by that ﬁeld.
The bottom three lines show the IP-level, /24-level, and AS-level consistency.

infer that this may be a case where the AS has a dy-
namic IP address assignment policy.

IP addresses as Common Names. 33,145,677 (46.9%)
of certiﬁcates’ Common Names appear to be an IPv4 ad-
dress. As our objective is to link certiﬁcates regardless
of the IP address of the hosts, we intentionally disregard
the certiﬁcates whose Common Name appears to be an IP
address when trying to link using Common Names for the
fairness of our evaluation.

Example. Consider the group of certiﬁcates in Fig-
ure 9 that all share the public key PK2. Recall that
our methodology would link these certiﬁcates, as they
do not overlap with one another on multiple scans. We
observe these certiﬁcates across three distinct IP ad-
dresses; suppose that IP addresses “2” and “3” reside in
the same /24, and that all three of them are owned by
the same AS. The most commonly appearing IP address
(IP address 2) is seen on two of the four scans; thus the
IP-level consistency is 0.5. The most commonly appear-
ing /24 shows up three of the four times, and thus the
/24-level consistency is 0.75. Finally, since they all re-
side in the same AS, the AS-level consistency would be
1.0. This example shows that, generally, our IP-level
consistency is the most conservative, and we would ex-
pect it to be low in ASes that implement dynamic IP
address assignment policies.

6.4.2 Results
Table 6 presents our evaluation results when linking
on each certiﬁcate ﬁeld. The ﬁrst two rows of the table
present the number of certiﬁcates linked by that ﬁeld,
and the number of certiﬁcates linked only by this ﬁeld.
The bottom three rows present the IP-level consistency,
/24-level consistency, and AS-level consistency that re-
sults when we use each ﬁeld to link.
Below, we take a closer look at the performance of
each of the ﬁelds; in §6.4.3, we more closely examine
the characteristics of the linked groups.

Public Key. We observe that Public Key can link
the most certiﬁcates among all ﬁelds, and does so with
98% AS-level consistency, but only 41.9% IP-level con-
sistency. To take a closer look at this discrepancy, we
manually examined the certiﬁcates for which IP-level
consistency is less than the average. We ﬁnd that the
certiﬁcates with one particular SAN—[fritz.fonwlan.

box]12—represent 12,078,402 (51.9%) of the public-key-
linked certiﬁcates, but the consistency of linking of this
group is 27% at the IP-level and 99% at the AS-level.
Thus, these devices account for much of the low IP-level
consistency of linking on public key; if we remove them,
we ﬁnd that the consistency jumps to 69.4% at the IP
address level. We found 82.6% of these devices to be
deployed in the German ISPs Deustche Telekom, Voda-
fone, and Telefonica Germany. These ASes are known
to change end users’ IP addresses frequently [35,39], ex-
plaining why we see such low IP-level consistency. Thus,
there are a large number of devices that regenerate their
certiﬁcates, but keep the same, unique Public Key over
time; this enables us to link these certiﬁcates together
and track the devices.

Linking on Public Key represents a case where a few
ASes give speciﬁc devices to users and implement a dy-
namic IP address assignment policy. Thus, our method-
ology is correct in linking these certiﬁcates together (i.e.,
the AS-level consistency is the correct one to consider).

Not Before and Not After. These ﬁelds are both
able to link large numbers of certiﬁcates—16M and 6M
certiﬁcates respectively—but their consistency has poor
performance in both IP- and AS-level. We tried to in-
vestigate the reason behind the poor performance by
manually investigating the group of certiﬁcates linked
together, but we are unable to observe any speciﬁc pat-
terns. However, we found that the sizes of the linked
groups is almost always two or three certiﬁcates; we
conjecture that Not Before and Not After incorrectly
link certiﬁcates that happen to share the same value
but are not actually related. This is also bolstered by
the fact that the size of the set of potential values (i.e.,
recent timestamps) for Not Before and Not After is
dramatically smaller than the size of the set of potential
values for Common Name and Public Key. As a result,
we exclude Not Before and Not After from consider-
ation.

Common Name. We observe that Common Name per-
forms similarly to Public Key, with 96.6% AS-level
consistency, but only 51.1% IP-level consistency. We
observe that 5,561,069 (21.0%) of the linked certiﬁ-
cates have URL-formatted Common Names. To investi-
gate which domains are used for the Common Name, we
Interestingly,
grouped them by second-level domain.

12These devices are FRITZ!Box devices mentioned in §6.3.1.

537895,775 (16%) of these certiﬁcates (the largest por-
tion) share the common second-level domain myfritz.
net, which is the dynamic DNS feature provided by
FRITZ!Box. Similarly, we observe that 445,585 (8%) of
these certiﬁcates contain “dyndns” or “selfhost” in the
Common Name, which also indicates that the device uses
dynamic DNS.

Issuer Name and Serial Number.
Similar to
Public Key, these ﬁelds exhibit 89.3% AS-level con-
sistency, but only 48.2% IP-level consistency. To
investigate this phenomenon, we manually examined
the linked certiﬁcates.
Interestingly, we ﬁnd 965,366
(23.1%) of certiﬁcates are advertised from “PlayBook”
devices, a tablet computer developed by BlackBerry.
These certiﬁcates share the same format for Issuer
Name: “PlayBook:
[MAC-ADDRESS]”. We conjecture
that these devices are connected through Blackberry’s
mobile network, which frequently re-assigns their IP ad-
dress.
If we disregard the PlayBook devices, the IP-
level consistency jumps to 71.9%.

Subject Alternate Names. We observe that SANs
can link 2.4M certiﬁcates in total, but only about 123K
certiﬁcates uniquely. Also, similar to Public Key, SANs
show high consistency at the AS-level, but low consis-
tency at the IP-level. Closely investigating these, we
ﬁnd that 1,658,575 (66.8%) of the linked certiﬁcates
are from FRITZ!Box devices (the same devices that we
found with Public Keys), explaining why SAN links few
devices uniquely. As expected, the IP-level consistency
among these is 24.3%, while the IP-level consistency for
the non-FRITZ!Box devices is 85.0%. Thus, the behav-
ior of linking on SANs is similar to that of Public Key.

CRL, AIA, OCSP, and OID. We found common
characteristics among CRLs, AIA, OCSP, and OID. But,
because they are rarely used, they link few certiﬁcates.

6.4.3 Linked Groups
Based on the results above, we view the ﬁelds Not
Before, Not After, and Issuer Name and Serial
Number as having insuﬃcient consistency to be used to
link (i.e., less than 90% consistency in AS-level); we do,
however, consider all other ﬁelds for linking. Specif-
ically, we consider each ﬁeld in Table 6 (other than
Not Before, Not After, and Issuer Name and Serial
Number) in decreasing order of AS-level consistency. We
iteratively link all certiﬁcates each ﬁeld i, remove the
linked certiﬁcates from consideration, and continue with
ﬁeld i + 1.

Ultimately, we are able to link 27,373,584 certiﬁcates
(39.4% of all invalid certiﬁcates) into 2,980,746 groups.
Figure 10 shows the cumulative distribution of the sizes
of these groups, both in aggregate and depending on
the ﬁeld that they were linked on. We ﬁnd that public
key can group the largest number of certiﬁcates: 62%
of linked groups are composed of more than 2 certiﬁ-
cates, and there exist groups that link up to 413 certiﬁ-

Figure 10: Cumulative distribution of the number of cer-
tiﬁcates grouped by the major ﬁelds. The x-axis starts at 2
and the long tail extends to 413 certiﬁcates.

cates. In contrast, for certiﬁcates linked via CRLs, 90%
of groups are only two certiﬁcates. Interestingly, in our
linking process, even though we link the certiﬁcates via
the SAN ﬁeld after Common Names, the average number
of certiﬁcates in SAN groups (5.10) is larger than that of
Common Name (2.60), which suggests that each ﬁeld has
diﬀerent potential for linking certiﬁcates.

6.4.4 Comparison with Original Set
As a ﬁnal evaluation, we examine how our method-
ology changes the set of devices that we are able to
track. To this end, we combine the linked invalid cer-
tiﬁcates (27M certiﬁcates in 2.9M groups) and unlinked
invalid certiﬁcates (42M) together and examine how the
lifetime of certiﬁcates changes after they are linked. We
observe that the portion of unlinked certiﬁcates that ap-
pear in only a single scan drops from 61% to 50.7% and
mean lifetime increases from 95.4 days to 132.3 days.
This indicates that our methodology has linked together
many of the ephemeral certiﬁcates, and has given us a
better understanding of the behavior of the device that
generated them.

7. TRACKING END-USER DEVICES

The linking methodology we developed in §6 permits
us to associate the reissued certiﬁcates from a given de-
vice. Moreover, recall from §5.4 (and in particular Fig-
ure 7) that over 94% of invalid certiﬁcates are hosted
by a single IP address on any given scan. This indicates
that, once we determine the set of certiﬁcates that origi-
nated from a given device, we can track end-user devices
as they move through the IP address space, purely by
observing the (invalid) SSL certiﬁcates they serve on
port 443.

In this section, we explore two applications of end-
user device tracking: monitoring device movement
(across ASes and geographically), and inferring IP ad-
dress reassignment policies. Neither of these studies are
complete, and both leave open many interesting ques-
tions for future work; however, they show that, by ap-
plying our linking methodology, invalid certiﬁcates can
lend considerable insight into the Internet at breadth.

 0 0.2 0.4 0.6 0.8 12101102103CDFNumber of Certificates Grouped TogetherCRLsCommon NameSANPublic KeyAll5387.1 Background

Longitudinal measurements of the Internet are cru-
cial for understanding past trends as well as making fu-
ture predictions. For example, researchers may wish to
study how the end-user devices attached to the Internet
are changing, as users upgrade devices or change ISPs.
Unfortunately, IP addresses—the most straightforward
form of identiﬁcation—cannot be used to uniquely iden-
tify devices over long timescales for several reasons:
ISPs often use dynamic IP address assignments [51]
or carrier-grade network address translators (NAT) [6],
and users and devices can move between ISPs.

In long timescales, researchers have given users mon-
itoring software [46] or dedicated hardware [40], en-
abling long-term measurements regardless of IP address
changes. These approaches, however, are also diﬃcult
to scale, as it is necessary to recruit users to partici-
pate. Thus, being able to track Internet-connected de-
vices over long timescales, both at large-scale and high
ﬁdelity, remains a challenge. Most related work relies
either application-level or network ﬁngerprints. For the
former, there is work [5, 36, 41, 54] that aims to track
users via their web browser conﬁgurations, such as cook-
ies [4, 16], User-Agent, plugins, JavaScript [33] etc. In
fact, recent work [54] proposes generating stable device
IDs using inaudible sounds. For the latter, Greenwald et
al. [22] have presented a method to understand the po-
tential for, and to prevent, network device ﬁngerprint-
ing. Often, network device ﬁngerprinting can reveal the
type of device (or software), but is unable to identify
individual devices uniquely.

The techniques we present in this section diﬀer funda-
mentally from prior approaches, as they do not require
users to deploy hardware [40,47], install additional soft-
ware, or interact with a server [1,2]. Instead, we use la-
tent features within the certiﬁcates that users’ devices
already publicly host as evidence that two diﬀerent cer-
tiﬁcates measured days or weeks apart may correspond
to the same physical device.
7.2 Trackable Devices

For the analysis below, we deﬁne a trackable device
as one we observe for longer than a year. Before ap-
plying our linking methodology, we can only track the
5,585,965 devices that advertise the same distinct cer-
tiﬁcate on every scan. After applying our methodology
from §6, we ﬁnd a total of 6,750,744 trackable devices,
representing an increase of 17.2%. This highlights that
our linking methodology is able to signiﬁcantly increase
the number of devices that can be tracked over time.
Moreover, it shows how we are able to gain a far wider
view into devices than would be possible with explicit
user participation or hardware deployment.
7.3 Tracking Device Movement

Using our set of tracked devices, we observe 718,495
devices that change ASes at least once (among the

6,750,744 total tracked devices), as well as a total of
1,328,223 AS transitions. We can observe that most of
these devices (69.7%) change their AS only once, while
others changed their AS more than 100 times (and are
likely mobile devices like the Playbook).

There are two common reasons why a device may
move from one AS to another. First, the device’s ISP
could have transferred its IP addresses to another AS.
To detect this, we look for instances wherein at least
50 devices switch from one AS to another between
scans; this happens 1,159 times in our dataset, covering
343,687 devices movements between 500 ASes. In some
instances, this is due to the ISP simply transferring its
IP addresses between ASes the ISP owns. For instance,
Verizon (AS19262) transferred a large portion of its IP
address space to MCI Communications (AS701), ac-
quired by Verizon, twice (once with 14,453 devices and
the other with 10,880). We see similar such movements
with AT&T in September, 2013 (12,739 IP addresses).
Second, a device could move from one AS to another
because the user chose to switch ISPs or to physically
move to a diﬀerent geographic location. We observe
45,450 devices move across countries.13 For example,
we observe 9,719 devices moved out of the U.S. and
7,868 devices moved into the U.S.
These ﬁndings show that much can be inferred from
applying our linking methodology (§6) to invalid certiﬁ-
cates longitudinally. Considering the growing number
of Internet of Things devices using port 443, we believe
increasingly many devices will use invalid certiﬁcates for
their secure communications and our approaches can be
directly applicable. There are also many interesting av-
enues of future work, but each comes with potential eth-
ical concerns; for instance, it may be possible to track
mobile devices with these techniques, which risks track-
ing personal movements over time.
7.4 Inferring IP Reassignment Policies

Being able to track individual devices and their as-
signed IP addresses naturally allows us to observe how
a given ISP reassigns IP addresses to its customers.
To investigate reassignment policies, we group IP ad-
dresses by AS and exclude any AS that has fewer than
10 tracked devices in our dataset; this leaves 4,467 ASes.
Although we cannot distinguish with certainty slow-
changing from static IP addresses, we classify an ad-
dress as statically assigned if it is mapped to one device
across our entire dataset and we have observed it for
at least one year. Figure 11 shows the distribution of
ASes’ static IP address assignment policies.

Surprisingly many ASes assign static IP address per-
vasively. We observe from Figure 11 that 2,517 ASes
(56.3%) assign static IP addresses to 90% of their de-

13We

rely

on CAIDA’s

historical AS-to-organization
dataset [11] to determine the country in which each AS is
located. It is worth noting that the dataset has a resolution of
3–4 months; we choose the entry that is closest to each of our
scans.

539largely because our technique applies to devices that do
not appear in standard device-tracking datasets, such as
RIPE Atlas [43] and SamKnows [47]. We believe that
the approach that we have taken in this paper (using
IP-level, /24-level, and AS-level consistency as a proxy
for accuracy) in fact forms a lower bound of the true
accuracy, as nearly half of all IP address changes result
in a diﬀerent /16 [39], but a more direct validation is
in order. Despite these shortcomings, this paper pro-
vides strong evidence that invalid certiﬁcates, though
long overlooked, can provide valuable insights into the
certiﬁcate ecosystem, IP address changes, and end-user
devices in general. We believe that many areas of future
work can beneﬁt from incorporating them, and to this
end, we make our data and code publicly available at
https://securepki.org
Acknowledgments
We thank the anonymous reviewers and our shepherd,
kc claﬀy, for their helpful comments. This research was
supported by NSF grants CNS-1409249, CNS-1421444,
CNS-1563320, and CNS-1564143, and by the NSA as
part of a Science of Security lablet.
9. REFERENCES
[1] Cisco IP Device Tracking. 2015. http://www.cisco.
com/c/en/us/td/docs/switches/lan/Denali_16-1/
ConfigExamples_Technotes/Config_Examples/
Device_Tracking/ip_device_tracking.pdf.

[2] SolarWinds User Device Tracker. 2015.

http://cdn.swcdn.net/creative/v12.7/pdf/
datasheets/SW_UDT_datasheet.pdf.

[3] D. Akhawe and A. P. Felt. Alice in Warningland: A

Large-scale Field Study of Browser Security Warning
Eﬀectiveness. USENIX Security, 2013.

[4] G. Acar, C. Eubank, S. Englehardt, M. Juarez, A.
Narayanan, and C. Diaz. The Web Never Forgets:
Persistent Tracking Mechanisms in the Wild. CCS,
2014.

[5] G. Acar, M. Juarez, N. Nikiforakis, C. Diaz, S.

G¨urses, F. Piessens, and B. Preneel. FPDetective:
Dusting the Web for Fingerprinters. CCS, 2013.

[6] S. Alcock, R. Nelson, and D. Miles. Investigating the

impact of service provider NAT on residential
broadband users. INFOCOM, 2010.

[7] A. Bates, J. Pletcher, T. Nichols, B. Hollembaek, and

K. R.B. Butler. Forced Perspectives: Evaluating an
SSL Trust Enhancement at Scale. IMC, 2014.

[8] D. Cooper, S. Santesson, S. Farrell, S. Boeyen, R.
Housley, and W. Polk. Internet X.509 Public Key
Infrastructure Certiﬁcate and Certiﬁcate Revocation
List (CRL) Proﬁle. RFC 5280, IETF, 2008.
http://www.ietf.org/rfc/rfc5280.txt.

[9] CAIDA Routeviews Preﬁx to AS Mappings Dataset.

http://www.caida.org/data/routing/
routeviews-prefix2as.xml.

[10] CAIDA AS Classiﬁcations Dataset.

http://www.caida.org/data/as-classification/.

[11] CAIDA AS Organizations Dataset.

http://www.caida.org/data/as-organizations/.

[12] Convergence. http://convergence.io.

Figure 11: The fraction of devices with statically assigned
IP addresses, as a distribution over ASes. ASes tend to have
long-lived IP address assignments.

vices. For example, three of Comcast Cable Commu-
nications’ ASes do not reassign IP addresses to 90%
(25,178) of the devices we are able to track, likewise
with AT&T Internet Services (9,058 devices, or 88.9%,
across 14 of their ASes).

Conversely, relatively few other ASes exhibit highly
dynamic IP address reassignment policies.
In partic-
ular, we found 15 ASes who assign a new IP address
to at least 75% of their hosts between every scan. For
example, 182,536 (76.3%) of the devices in Deutsche
Telekom had their IP address changed between every
scan. Similarly, the 29,385 (99.6%) devices in Telefonica
Venezolana from Venezuela, 820 (97.0%) devices Tim
Celular from Brazil, and 206 (95.3%) devices in BSES
TeleCom Limited from India did so as well.

This application demonstrates the beneﬁts of being
able to track devices across a wide range of populated
ASes, made possible, surprisingly, by the widespread
deployment of invalid certiﬁcates.
8. CONCLUSION

In this paper, we presented the ﬁrst in-depth study of
the invalid certiﬁcates in the web’s PKI. Although typi-
cally ignored by measurement studies and browsers (and
end users who proceed anyway), we have demonstrated
that invalid certiﬁcates merit study, as they constitute
the vast majority (65.0% in daily average, and 87.9% in
total measurement period) of all certiﬁcates in the web’s
PKI over the past four years. Our investigation into the
origins of invalid certiﬁcates led us to observe signiﬁcant
diﬀerences with valid ones, and to ultimately conclude
that invalid certiﬁcates originate largely from end-user
devices that regularly regenerate new, self-signed certiﬁ-
cates. Surprisingly, a large number of invalid certiﬁcates
stem from a rather small set of device manufacturers
and ISPs. Moreover, we presented techniques that use
the latent features of invalid certiﬁcates to track devices
over long periods of time, permitting a broad, longitu-
dinal study of IP address reassignment policies and user
mobility without any explicit user interaction.

Future work can strengthen the results in this pa-
per. Primarily, we lack a ground truth against which
to validate our techniques for tracking end-user devices,

 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1Cumulative Frac. of ASesFraction of AS’s IP Addresses that Are Statically Assigned540[13] Z. Durumeric, J. Kasten, D. Adrian, J. A. Halderman,

M. Bailey, F. Li, N. Weaver, J. Amann, J. Beekman,
M. Payer, and V. Paxson. The Matter of Heartbleed.
IMC, 2014.

[14] Z. Durumeric, J. Kasten, M. Bailey, and J. A.
Halderman. Analysis of the HTTPS Certiﬁcate
Ecosystem. IMC, 2013.

[15] Z. Durumeric, E. Wustrow, and J. A. Halderman.

ZMap: Fast Internet-Wide Scanning and its Security
Applications. USENIX Security, 2013.

[16] S. Englehardt, D. Reisman, C. Eubank, P.

Zimmerman, J. Mayer, A. Narayanan, and E. W.
Felten. Cookies That Give You Away: The
Surveillance Implications of Web Tracking. WWW,
2015.

[17] EFF SSL Observatory.

https://www.eff.org/observatory.

[18] S. Fahl, M. Harbach, T. Muders, L. Baumg¨artner, B.
Freisleben, and M. Smith. Why Eve and Mallory Love
Android: An Analysis of Android SSL (in)Security.
CCS, 2012.

[19] S. Fahl, M. Harbach, H. Perl, M. Koetter, and M.

Smith. Rethinking SSL Development in an Appiﬁed
World. CCS, 2013.

[20] D. W. S. Ford and D. Solo. Internet X.509 Public Key

Infrastructure Certiﬁcate and Certiﬁcate Revocation
List (CRL) Proﬁle. IETF RFC 3280, IEFT, 2013.
[21] M. Georgiev, S. Iyengar, S. Jana, R. Anubhai, D.

Boneh, and V. Shmatikov. The Most Dangerous Code
in the World: Validating SSL Certiﬁcates in
Non-browser Software. CCS, 2012.

[33] K. Mowery, D. Bogenreif, S. Yilek, and H. Shacham.

Fingerprinting Information in
JavaScriptImplementations. W2SP, 2011.

[34] S. Matsumoto, P. Szalachowski, and A. Perrig.

Deployment Challenges in Log-based PKI
Enhancements. EuroSec, 2015.

[35] G. C. M. Moura, C. Ga˜n´an, Q. Lone, P. Poursaied, H.
Asghari, and M. van Eeten. How Dynamic is the ISPs
Address Space? Towards Internet-Wide DHCP Churn
Estimation. Networking, 2015.

[36] N. Nikiforakis, A. Kapravelos, W. Joosen, C. Kruegel,

F. Piessens, and G. Vigna. Cookieless Monster:
Exploring the Ecosystem of Web-Based Device
Fingerprinting. IEEE S&P, 2013.

[37] OS X Yosemite: List of available trusted root

certiﬁcates.
https://support.apple.com/en-us/HT202858.
[38] H. Perl, S. Fahl, and M. Smith. You Won’t Be

Needing These Any More: On Removing Unused
Certiﬁcates from Trust Stores. FC, 2014.

[39] R. Padmanabhan, A. Dhamdhere, E. Aben, k. claﬀy,

and N. Spring. Why Dynamic Addresses Change.
IMC, 2016.

[40] Project BISmark. http://projectbismark.net.
[41] F. Roesner, T. Kohno, and D. Wetherall. Detecting
and Defending Against Third-Party Tracking on the
Web. NSDI, 2012.

[42] M. D. Ryan. Enhanced Certiﬁcate Transparency and

End-to-End Encrypted Mail. NDSS, 2014.

[43] RIPE Atlas. https://atlas.ripe.net/about/.
[44] Rapid7 SSL Certiﬁcate Scans.

[22] L. G. Greenwald and T. J. Thomas. Understanding

https://scans.io/study/sonar.ssl.

and preventing network device ﬁngerprinting. Bell
Labs Technical Journal, 12(3), 2007.

[23] L.-S. Huang, A. Rice, E. Ellingsen, and C. Jackson.

Analyzing Forged SSL Certiﬁcates in the Wild. IEEE
S&P, 2014.

[24] N. Heninger, Z. Durumeric, E. Wustrow, and J. A.

Halderman. Mining your Ps and Qs: Detection of
widespread weak keys in network devices. USENIX
Security, 2012.

[25] R. Holz, L. Braun, N. Kammenhuber, and G. Carle.

The SSL Landscape – A Thorough Analysis of the
X.509 PKI Using Active and Passive Measurements.
IMC, 2011.

[26] H.D. Moore. Personal Communication.
[27] D. C. D. Harkins. The Internet Key Exchange (IKE).

IETF RFC 2409, IEFT, 1998.

[28] T. H.-J. Kim, L.-S. Huang, A. Perring, C. Jackson,

and V. Gligor. Accountable Key Infrastructure (AKI):
A Proposal for a Public-key Validation Infrastructure.
WWW, 2013.

[29] O. Levillain, A. ´Ebalard, B. Morin, and H. Debar.
One year of SSL Internet measurement. ACSAC,
IEEE Computer Society, 2012.

[30] Y. Liu, W. Tome, L. Zhang, D. Choﬀnes, D. Levin,

B. M. Maggs, A. Mislove, A. Schulman, and C.
Wilson. An End-to-End Measurement of Certiﬁcate
Revocation in the Web’s PKI. IMC, 2015.
[31] Let’s Encrypt. https://letsencrypt.org.
[32] G. Maier, A. Feldmann, V. Paxson, and M. Allman.

On Dominant Characteristics of Residential
Broadband Internet Traﬃc. IMC, 2009.

[45] P. Szalachowski, S. Matsumoto, and A. Perrig.
PoliCert: Secure and Flexible TLS Certiﬁcate
Management. CCS, 2014.

[46] M. A. S´anchez, J. S. Otto, Z. S. Bischof, D. R.

Choﬀnes, F. E. Bustamante, B. Krishnamurthy, and
W. Willinger. Dasu: Pushing Experiments to the
Internet’s Edge. NSDI, 2013.

[47] SamKnows. https://www.samknows.com/.
[48] The DNS-Based Authentication of Named Entities
(DANE) Transport Layer Security (TLS) Protocol:
TLSA. RFC 6698, IETF, 2012.
https://tools.ietf.org/html/rfc6698.

[49] University of Michigan HTTPS Ecosystem Scans.

https://scans.io/study/umich-https.

[50] N. Vallina-Rodriguez, J. Amann, C. Kreibich, N.

Weaver, and V. Paxson. A Tangled Mass: The
Android Root Certiﬁcate Stores. CoNEXT, 2014.

[51] Y. Xie, F. Yu, K. Achan, E. Gillum, M. Goldszmidt,

and T. Wobber. How Dynamic are IP Addresses?
SIGCOMM, 2007.

[52] S. Yilek, E. Rescorla, H. Shacham, B. Enright, and S.
Savage. When Private Keys Are Public: Results from
the 2008 Debian OpenSSL Vulnerability. IMC, 2009.

[53] L. Zhang, D. Choﬀnes, T. Dumitra¸s, D. Levin, A.

Mislove, A. Schulman, and C. Wilson. Analysis of SSL
certiﬁcate reissues and revocations in the wake of
Heartbleed. IMC, 2014.

[54] Z. Zhou, W. Diao, X. Liu, and K. Zhang. Acoustic

Fingerprinting Revisited: Generate Stable Device ID
Stealthily with Inaudible Sound. CCS, 2014.

541