Differentially Private Sequential Data Publication

via Variable-Length N-Grams

Rui Chen

∗

Gergely Acs

Claude Castelluccia

Concordia University

Montreal, Canada

ru_che@encs.concordia.ca

INRIA
France

gergely.acs@inria.fr

INRIA
France

claude.castelluccia@inria.fr

ABSTRACT
Sequential data is being increasingly used in a variety of
applications. Publishing sequential data is of vital impor-
tance to the advancement of these applications. However,
as shown by the re-identiﬁcation attacks on the AOL and
Netﬂix datasets, releasing sequential data may pose consid-
erable threats to individual privacy. Recent research has
indicated the failure of existing sanitization techniques to
provide claimed privacy guarantees. It is therefore urgent
to respond to this failure by developing new schemes with
provable privacy guarantees. Diﬀerential privacy is one of
the only models that can be used to provide such guarantees.
Due to the inherent sequentiality and high-dimensionality,
it is challenging to apply diﬀerential privacy to sequential
data. In this paper, we address this challenge by employ-
ing a variable-length n-gram model, which extracts the es-
sential information of a sequential database in terms of a
set of variable-length n-grams. Our approach makes use of
a carefully designed exploration tree structure and a set of
novel techniques based on the Markov assumption in order to
lower the magnitude of added noise. The published n-grams
are useful for many purposes. Furthermore, we develop a
solution for generating a synthetic database, which enables
a wider spectrum of data analysis tasks. Extensive exper-
iments on real-life datasets demonstrate that our approach
substantially outperforms the state-of-the-art techniques.

Categories and Subject Descriptors
H.2.7 [Database Administration]:
and protection]; H.2.8 [Database Applications]:
mining]

[Security,

integrity,
[Data

General Terms
Algorithms, Performance, Security

∗This work was done when the ﬁrst author was on an in-
ternship at INRIA.

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

Keywords
Diﬀerential privacy, sequential data, n-gram model, Markov
assumption

1.

INTRODUCTION

Sequential data (see a formal deﬁnition in Section 3.1),
such as DNA sequences, web browsing histories and mobil-
ity traces, is being increasingly used in a variety of real-life
applications, spanning from genome and web usage analy-
sis to location-based recommendation systems. Publishing
sequential data is important, since they enable researchers
to analyze and understand interesting patterns. For exam-
ple, mobility traces have become widely collected in recent
years and have opened the possibility to improve our under-
standing of large-scale social networks by investigating how
people exchange information, interact and develop social re-
lationships. With billions of handsets in use worldwide, the
amount of sequential data has been gigantic. When aggre-
gated, it can help understand complex processes (e.g., the
spread of viruses), build better transportation systems, and
prevent traﬃc congestion [20]. While the beneﬁts provided
by sequential data are indisputable, it, unfortunately, poses
considerable threats to individual privacy [19]. In fact, se-
quential data might be used by a malicious adversary to dis-
cover potential sensitive information about a record owner,
such as his habits, religion or relationships. Because privacy
is so important to people, companies and researchers are re-
luctant to publish datasets by fear of being held responsible
for potential privacy breaches. As a result, only very few
of them are actually released and available. This limits our
ability to analyze such data to derive information that could
beneﬁt the general public.

Several sequential data sanitization algorithms have been
presented recently [19], [3]. However, their privacy proper-
ties are still dubious, since they rely on privacy models that
are either ad-hoc or considered weak. It is therefore urgent
to respond to the failure of existing sanitization techniques
by developing new schemes with provable privacy guaran-
tees. Diﬀerential privacy [9] is one of the only models that
can be used to provide such guarantees. The main idea of
diﬀerential privacy is to add noise to a dataset so that an
adversary cannot decide whether a particular record (e.g., a
sequence in our case) is included in the dataset or not. Due
to the inherent sequentiality and high-dimensionality of se-
quential data, it is challenging to apply diﬀerential privacy
to sequential data. In particular, naively adding noise to the
occurrence count of each distinct sequence in the dataset
negatively impacts both privacy and utility. First, unless

638we always release the noisy counts of all possible sequences
(whether in or not in the dataset), which is computationally
infeasible in practice, adding a new record will most likely
entail the inclusion of a new sequence that has not been
present in the dataset. This clearly breaks ε-diﬀerential pri-
vacy and requires to relax the privacy model to the weaker
(ε, δ)-diﬀerential privacy [8]. Second, since most sequences
are unique, the added noise will most likely be much larger
than the actual occurrence counts, which reduces data util-
ity considerably.

In this paper, we demonstrate that there is no need to
release the noisy counts of all possible sequences in order
to retain sequentiality information of a sequential dataset.
Instead, we leverage on the well-established n-gram model,
which has been heavily used in natural language process-
ing [14]. With this model, it is often suﬃcient to publish
the most common n-grams (contiguous subsequences of size
n, where n is typically smaller than 5) for accurately “recon-
structing” the original dataset. This fact positively impacts
both privacy and utility. First, the universe of all grams with
a small n value is relatively small (note that our approach
does not even require to explore the entire universe of all n-
grams), and thus we can employ the stronger ε-diﬀerential
privacy model. Second, the counts of shorter grams are often
large enough to resist noise. Finally, the inherent Markov as-
sumption in the n-gram model allows to reduce the injected
noise and therefore further improves utility.

Contributions. The major contributions of this paper are
three-fold:

• For the ﬁrst time, we introduce the n-gram model as an
eﬀective means of achieving diﬀerential privacy in the
context of sequential data. To better suit diﬀerential
privacy, we propose the use of a novel variable-length
n-gram model, which balances the trade-oﬀ between
information of the underlying database retained and
the magnitude of Laplace noise added. The variable-
length n-gram model intrinsically ﬁts diﬀerential pri-
vacy in the sense that it retains the essential infor-
mation of a sequential dataset in terms of a set of
high-quality n-grams whose counts are large enough
to resist Laplace noise.

• We develop a series of techniques to guarantee good
utility under the variable-length n-gram model, includ-
ing an adaptive privacy budget allocation scheme, a
formal choice of a threshold value, and the enforcement
of consistency constraints. These techniques make use
of the inherent Markov assumption in an n-gram model.
In addition, we develop an eﬃcient method to generate
a synthetic dataset from released n-grams, enabling a
wider spectrum of data analysis tasks.

• We conduct an extensive experimental study on the
variable-length n-gram model over real-life datasets,
which provides important insights for future work. In
particular, we demonstrate that our solution substan-
tially outperforms the state-of-the-art techniques [16],
[4] in terms of count query and frequent sequential pat-
tern mining.

The rest of the paper is organized as follows. We provide a
literature review in Section 2. Section 3 presents the prelim-
inaries of our solution. Section 4 discusses our sanitization

solution in detail. Section 5 gives the formal privacy guar-
antee of our solution. Comprehensive experimental results
are reported in Section 6. Finally, we conclude the paper in
Section 7.

2. RELATED WORK

Sequential data could be considered as a special type of
trajectory data. Due to the ubiquitousness of trajectory (se-
quential) data, some recent works [1], [21], [24], [12], [5], [18]
have been done on privacy-preserving trajectory data pub-
lishing. Abul et al. [1] propose the (k, δ)-anonymity model
based on the inherent imprecision of sampling and position-
ing systems, where δ represents the possible location impre-
cision. They propose to modify trajectories by space trans-
lation so that k diﬀerent trajectories co-exist in a cylinder
of the radius δ. Terrovitis and Mamoulis [21] model an
adversary’s background knowledge as a set of projections
of sequences in a sequential database and propose a data
suppression technique to limit the conﬁdence of inferring
the presence of a location. Yarovoy et al. [24] propose to
k-anonymize a moving object database (MOD) by consid-
ering timestamps as the quasi-identiﬁers. Adversaries are
assumed to launch privacy attacks based on attack graphs.
Monreale et al. [18] present an approach based on spatial
generalization in order to achieve k-anonymity. They de-
velop a generalization scheme that depends on the underly-
ing trajectory dataset rather than a ﬁxed grid hierarchy.

Hu et al. [12] present the problem of k-anonymizing a tra-
jectory database with respect to a sensitive event database
with the goal of ensuring that every event is shared by at
least k users. They propose a new generalization mecha-
nism known as local enlargement, which achieves better util-
ity. Chen et al. [5] consider the emerging trajectory data
publishing scenario, in which users’ sensitive attributes are
published with trajectory data, and consequently propose
the (K, C)L-privacy model that thwarts both identity link-
ages on trajectory data and attribute linkages via trajectory
data. They develop a generic solution for various data utility
metrics by use of local suppression. All these approaches [1],
[21], [24], [12], [5], [18] are built based on partition-based pri-
vacy models, and therefore are not able to provide suﬃcient
privacy protection for sequential data. Compared with the
above works, the major contribution of our paper is the use
of diﬀerential privacy, which provides signiﬁcantly stronger
privacy guarantees.

With the recent emergence of diﬀerential privacy, there
has been extensive research on applying it to non-interactive
privacy-preserving data publishing. Blum et al. [2] demon-
strate that it is possible to release synthetic private databases
that are useful for all queries over a discretized domain from
a concept class with polynomial Vapnik-Chervonenkis di-
mension. However, their mechanism is not eﬃcient, taking
runtime complexity of superpoly(|C|, |I|), where |C| is the
size of a concept class and |I| the size of the universe. Dwork
et al. [10] propose a recursive algorithm for generating a syn-
thetic database with runtime complexity of poly(|C|, |I|).
This improvement, however, is still insuﬃcient to handle
real-life sequential datasets due to the exponential size of
|C|. Xiao et al. [23] propose a wavelet-transformation based
approach for relational data to lower the magnitude of noise,
rather than adding independent Laplace noise. Two recent
papers [17], [6] point out that data-dependent approaches
are more eﬃcient and more eﬀective for generating a dif-

639Table 1: Dataset
Rec. # Sequence
1
2
3
4
5
6
7
8

I2 → I3 → I1
I2 → I3
I3 → I2
I2 → I3 → I1
I3 → I2 → I1
I2 → I3 → I1 → I2 → I3
I3 → I2
I3 → I1 → I2 → I3

Table 2: 1-grams
Gram # Pr
I1
I2
I3

0.21
0.38
0.41

5
9
10

Table 3: 2-grams

Gram # Pr Gram # Pr
0
I1 → I1
2
I1 → I2
I1 → I3
0
I1 → & 3

1
I2 → I1
0
I2 → I2
I2 → I3
6
I2 → & 2

0
0.4
0
0.6

0.11
0
0.67
0.22

Gram # Pr
4
0.4
I3 → I1
0.3
3
I3 → I2
0
I3 → I3
0
I3 → & 3
0.3

ferentially private release. Mohammed et al. [17] propose
a generalization-based sanitization algorithm for relational
data with the goal of classiﬁcation analysis. Chen et al. [6]
propose a probabilistic top-down partitioning algorithm for
set-valued data. Both approaches [17], [6] make use of tax-
onomy trees to adaptively narrow down the output domain.
However, these approaches cannot be directly applied to se-
quential data due to its inherent sequentiality.

To our best knowledge, the paper [4] is the only work that
applies diﬀerential privacy to sequential data release. They
make use of the preﬁx tree structure to group sequences
with the identical preﬁx into the same branch. However,
with the growth of the preﬁx tree, the number of sequences
falling into a branch decreases quickly, resulting in poor util-
ity. In addition, though not dedicated to sequential data,
McSherry and Mahajan [16] develop a method for ﬁnding
frequent (sub)strings. This method also makes use of a pre-
ﬁx structure. In contrast, we make use of the variable-length
n-gram model, which achieves signiﬁcantly improved utility.

3. PRELIMINARIES

3.1 Sequential Database

Let I = {I1, I2, · · · , I|I|} be the universe of items, where
|I| is the size of the universe. The semantic meaning of an
item could be diﬀerent from application to application. For
example, an item could be a station in a transportation sys-
tem, a word in a natural language processing application, or
a nucleobase in a DNA sequence. Each record in a sequen-
tial database is a sequence of (time-)ordered items drawn
from the universe. For instance, a sequence can represent
the movement history of a record owner (i.e., his trajectory),
where each item corresponds to a location visited, or a user’s
password, where each item corresponds to a character.

Formally, a sequence S of length |S| is an ordered list of
items S = L1 → L2 → · · · → L|S|, where ∀1 ≤ i ≤ |S|, Li ∈
I. An item may occur multiple times in S, and may occur
consecutively in S. Therefore, S = I1 → I2 → I2 is a valid
sequence. A sequential database D of size |D| is composed
of a multiset of sequences D = {S1, S2, · · · , S|D|}. Table 1
presents a sample sequential database with I = {I1, I2, I3}.

3.2 N-Gram Model

model based on an (n − 1)-order Markov model.
It can
compactly model large-scale sequential data and provide
scalable trade-oﬀ between storage and accuracy. N -gram
models have been proven to be very robust in modeling
sequential data and have been widely used in probability,
communication theory, computational linguistics (e.g., sta-
tistical natural language processing), computational biology
(e.g., biological sequence analysis), and data compression.

N -gram models estimate the probability of the next item
for a given sequence by making use of the Markov indepen-
dence assumption (of order n − 1) that the occurrence of
each item in a sequence depends only on the previous n − 1
items (instead of all previous items), where n is typically a
small value (e.g., 3-5). Let the probability that a sequence
L1 → L2 → . . . → Li, where Lj ∈ I (∀1 ≤ j ≤ i) and i ≥ n,
is followed by Li+1 ∈ I be denoted by P (Li+1|L1 → L2 →
. . . → Li). Then, under the n-gram model, P (Li+1|L1 →
L2 → . . . → Li) :≈ P (Li+1|Li−n+2 → Li−n+3 → . . . → Li).
N -gram models provide a trade-oﬀ between storage and
accuracy: a larger n value retains more information of the
dataset, but it requires more storage and time to process.
For example, Tables 2 and 3 show the set of all unigrams
and 2-grams, respectively, along with their counts and prob-
abilities for the sample dataset in Table 1, where & is a
special symbol representing the termination of a sequence.
Consider the calculation of the (approximate) number of
occurrences of I3 → I1 → I2 → I3, whose true number is
2. Using 2-grams, one possible approximation is #(I3 →
I1) · P (I2|I1) · P (I3|I2) = 4 · 0.4 · 0.67 = 1.07. In contrast, us-
ing 3-grams, a better approximation could be #(I3 → I1 →
I2) · P (I3|I1 → I2) = 2 · 1.0 = 2.0. However, this better
scheme requires to process all 3-grams at the cost of storage
and time.

3.3 Differential Privacy

Dwork proves that absolute privacy protection is impossi-
ble in the presence of background knowledge [7], resulting in
the notion of diﬀerential privacy based on indistinguishabil-
ity. Diﬀerential privacy [9] requires that the outcome of any
computation be insensitive to the change of a single record.
It follows that any information that can be learned from the
database with a record can also be learned from the one
without this record. Consequently, for a record owner, it
means that any privacy breach will not be a result of par-
ticipating in the database.

Definition 3.1

(Differential privacy). A privacy
mechanism A gives ε-diﬀerential privacy if for any database
D1 and D2 diﬀering on at most one record, and for any
possible output O ∈ Range(A),

P r[A(D1) = O] ≤ eε × P r[A(D2) = O]

(1)

where the probability is taken over the randomness of A.

A fundamental concept for achieving diﬀerential privacy
is the global sensitivity of a function [9] that maps an un-
derlying database to (vectors of) reals.

Definition 3.2

(Global Sensitivity). For any func-

tion f : D → Rd, the sensitivity of f is

∆f = max
D1,D2

||f (D1) − f (D2)||1

(2)

An n-gram model is a type of probabilistic prediction

for all D1, D2 diﬀering in at most one record.

640Laplace Mechanism. A standard mechanism to achieve
diﬀerential privacy is to add properly calibrated Laplace
noise to the true output of a function, which is known as
Laplace mechanism [9]. It takes as inputs a database D, a
function f , and the privacy parameter ε. The noise is gener-
ated according to a Laplace distribution with the probability
2λ e−|x|/λ, where λ is deter-
density function (pdf) p(x|λ) = 1
mined by both ∆f and the desired privacy parameter ε. Let
L(λ) denote a Laplace random variable with a probability
density function deﬁned as above.

Theorem 3.1. For any function f : D → Rd, the mech-

anism

Laplace(D, f, ε) = f (D) + [L1(λ), L2(λ), . . . , Ld(λ)]

(3)

gives ε-diﬀerential privacy if λ = ∆f /ε and Li(λ) are i.i.d
Laplace random variables.

4. SANITIZATION ALGORITHM

4.1 Overview

The main idea of our scheme is simple: we add prop-
erly calibrated Laplace noise to the counts of high-quality
grams and release them. Our goal is two-fold: (1) to release
grams whose real counts are large enough to increase util-
ity1, and (2) to maximize the sizes of released grams (i.e.,
the n value) to preserve as much sequentiality information
as possible. There is a fundamental trade-oﬀ between the
utility of noisy n-grams and their sizes: shorter grams enjoy
smaller relative error due to Laplace noise but carry less se-
quentiality information; longer grams contain more sequen-
tiality information but have smaller counts (and thus larger
relative error). In this paper, we address this trade-oﬀ by
releasing variable-length n-grams with counts larger than a
threshold 2 and of sizes less than a maximal size nmax
3. For
most practical datasets, setting nmax to a small value (e.g.,
3-5) has been suﬃcient to capture most of the sequentiality
information. Since short grams are typically of large real
counts, this property, which is also experimentally justiﬁed
in Appendix A, explains why the n-gram model is so pow-
erful and why it provides an excellent basis for diﬀerentially
private sequential data publishing.

To identify the set of high-quality (i.e., having low rela-
tive error) n-grams with possibly varying n values (1 ≤ n ≤
nmax ) from an input sequential dataset, we propose a well-
designed tree structure, called exploration tree.
It groups
grams with the same preﬁx into the same branch so that all
possible n-grams with size 1 ≤ n ≤ nmax can be explored
eﬃciently. The exploration starts with unigrams and then
proceeds to longer grams until nmax is reached. Intuitively,
if the noisy count of a gram g is small (i.e., close to the
standard deviation of the added noise), its real count also
tends to be small and thus the relative error is large. Since
all grams having the preﬁx g (i.e., all nodes in the subtree
rooted at g) have smaller real counts than g’s real count,

1The added noise is calibrated to the global sensitivity and is
independent of the count values. Thus, larger counts provide
better utility in terms of relative error.
2This threshold is set to limit the magnitude of noise in
released data.
3Beyond nmax , the utility gain of longer grams is usually
smaller than the utility loss due to noise.

Algorithm 1 Sequential Database Sanitization
Input: Raw sequential database D
Input: Privacy budget ε
Input: Maximal sequence length ℓmax
Input: Maximal n-gram size nmax
Output: Private sequential database eD

1: Truncate each S ∈ D by keeping the ﬁrst ℓmax items;
2: Create an exploration tree T with a virtual root;
3: i = 0;
4: while i < nmax do
5:

for each non-leaf node vij ∈ levelSet(i, T )
and lb(vij ) 6= & do
Calculate εvij ;
//see Section 4.3.2
Uc ← all possible children of vij with labels I ∪ {&};
//Compute the noisy count of each uk ∈ Uc
Q = {|g(u1)|, |g(u2)|, · · · , |g(u|I|+1)|};
eQ = Laplace(D, Q, εvij );
for each node uk ∈ Uc do

//∆Q = ℓmax

6:
7:
8:
9:

Add uk to T ;
if c(uk) < θ then

10:
11:
12:
13:
14:
15:
16: Enforce consistency on T ;
17: Generate eD from T ;
18: return eD;

i++;

Mark uk as leaf;

//see Section 4.3.3

//see Section 4.3.4
//see Section 4.3.5

they can be omitted from further computation. This obser-
vation makes our approach signiﬁcantly faster than naively
processing every single gram regardless of its size. It also
explains why we do not adopt the approach that generates
all possible n-grams and then prunes the tree.

4.2 Terminology

We ﬁrst give some notations used in our solution. The ex-
ploration tree is denoted by T . Each node v ∈ T is labeled
by an item I ∈ I ∪ {&}, where & is a special symbol rep-
resenting the termination of a sequence. The function lb(v)
returns v’s item label. Each node v is associated with an
n-gram deﬁned by the sequence of items from the root of T
to v, denoted by g(v). We slightly abuse the term count to
mean the number of occurrences of g(v) in the input dataset,
which is denoted by |g(v)|. Note that an n-gram may oc-
cur multiple times in a sequence. For example, the count of
I2 → I3 in the sample dataset in Table 1 is 6, instead of 5.
Each node v also keeps a noisy version of |g(v)|, denoted by
c(v). In addition, each node v conveys a conditional proba-
bility, denoted by P (v), which predicts the probability of the
transition from v’s parent to v. P (v) can be obtained by nor-
malizing the noisy counts of v’s siblings and v. For example,
in Figure 1, P (v5) = P (I1|I2 → I3) = 4/(4+0+1+2) = 4/7.
The set of all nodes in level i of T is denoted by levelSet(i, T )
and these nodes represent all i-grams in the dataset. The
level number of node v in T is denoted by level(v, T ). The
root of T is in level zero.
In the sequel, the probability
P (Li+1|Lj → Lj+1 → . . . → Li) is shortly denoted by
P (Li+1|Lj

i ).

4.3 Detailed Descriptions

4.3.1 Private Sequential Database Release

Algorithm 1 provides an overview of our approach.

It
takes as inputs a sequential database D, the total privacy
budget ε, the maximal sequence length ℓmax and the max-
imal n-gram size nmax , and returns a sanitized sequential

641v1

I1 4 ε/5 

Label
Root

Noisy Count

Privacy Budget

-

-

I2 10 ε/5 

v2

v3

v4

I3 9 ε/5 

I1 0 4ε/5  I2 4 4ε/5  I3 0 4ε/5  & 0 4ε/5 

I1 1 2ε/5  I2 0 2ε/5  I3 7 2ε/5  & 2 2ε/5 

I1 4 2ε/5  I2 2 2ε/5  I3 1 2ε/5  & 2 2ε/5 

v5

I1 4 2ε/5  I2 0 2ε/5  I3 1 2ε/5  & 2 2ε/5 

I1 1 2ε/5  I2 2 2ε/5  I3 0 2ε/5  & 1 2ε/5 

v6

v7

v8

v9

v10

v11

v12

I2 2

-

v13

Figure 1: The exploration tree of the sample data

database eD satisfying ε-diﬀerential privacy. ℓmax is a pa-

rameter speciﬁed by the data holder to limit the inﬂuence
of a single sequence in computation. The algorithm con-
siders only the ﬁrst ℓmax items in each input sequence. A
larger ℓmax allows more information to be retained from D,
but requires more noise to be injected in later computation;
a smaller ℓmax does the opposite. We discuss and report
the eﬀect of diﬀerent ℓmax values in Section 6, and provide
insights for a data holder to select a good ℓmax value in
practice. nmax bounds the height of the exploration tree T
and thus the maximal size of released grams. The choice
of nmax aﬀects the privacy parameter assigned to each level
of T , and, therefore, is also related to the magnitude of
noise. In practice, nmax could be set to 5, which is the max-
imal n value popularly used in the literature. Similarly, we
present more details on the selection of a reasonable nmax in
Section 6. We emphasize that this does not mean that all
released grams have a size of nmax but rather their sizes can
vary between 1 and nmax .

In Algorithm 1, we ﬁrst preprocess D by keeping only the
ﬁrst ℓmax items of each sequence in order to bound the inﬂu-
ence of a single sequence by ℓmax (Line 1). The construction
of T starts by creating an empty tree with a virtual root
(Line 2). In Lines 4-15, the algorithm iteratively constructs
each level of T . For level i of T , we decide whether to ex-
pand a node vij ∈ levelSet(i, T ) by comparing its noisy count
c(vij) with a threshold θ. If c(vij) ≥ θ, we expand vij by ex-
plicitly considering every possible item in I ∪ {&} as a child
of vij in order to satisfy diﬀerential privacy. By deﬁnition,
nodes labeled by & cannot be expanded because it means
the termination of a sequence. The entire exploration pro-
cess ends when either the depth of the tree reaches nmax or
no node can be further expanded (since their noisy counts
do not pass θ or their privacy budgets have run out). Exam-
ple 4.1 illustrates the construction of a possible exploration
tree on the sample dataset in Table 1.

Example 4.1. Given nmax = 5, ℓmax = 5 and θ = 3,
the construction of a possible exploration tree over the sam-
ple dataset in Table 1 is illustrated in Figure 1 (ignore the
privacy budget information and node v13 for now).

In the following, we detail the key components of Algo-
rithm 1: how to compute the privacy budget εij for each
node in T (Section 4.3.2), how to compute the threshold
θ for each node (Section 4.3.3), how to make T consistent
(Section 4.3.4), and how to generate a synthetic version of

the input database D from T (Section 4.3.5). Finally, in
Section 5, we prove the privacy guarantee of our scheme.

4.3.2 Adaptive Privacy Budget Allocation

nmax

Given the maximal gram size nmax , a simple privacy bud-
get allocation scheme is to expect the height of T to be nmax
and uniformly assign ε
to each level of T to calculate the
noisy counts of the nodes in each level. However, in reality,
many (or even all) root-to-leaf paths have a length much
shorter than nmax for the reason of their counts not being
able to pass θ. Hence assigning privacy parameters solely
based on nmax is clearly not optimal. For example, in Ex-
ample 4.1, since the height of the exploration tree is 3 and
nmax = 5, at least 2ε
5 privacy budget would be wasted in all
paths.

To address this drawback, we propose an adaptive privacy
budget allocation scheme that allows private operations to
make better use of the total privacy budget ε. Intuitively,
a desirable privacy budget allocation scheme should take
into consideration the length of a root-to-leaf path:
for a
shorter path, each node in the path should receive more
privacy budget; for a longer path, each node should use less
privacy budget. Hence we adaptively estimate the length of
a path based on known noisy counts and then distribute the
remaining privacy budget as per the estimated length.

At the beginning of the construction of T , in the absence
of information from the underlying dataset, we can only as-
sume that each root-to-leaf path is of the same length nmax
so that our algorithm would not exceptionally halt due to
is used to
running out of privacy budget. Therefore,
calculate the noisy counts of nodes in level 1. Once we obtain
some information from the underlying dataset (e.g., nodes’
noisy counts), we can make more accurate predictions on
the length of a path.

nmax

ε

For a node v in level i ≥ 2 with noisy count c(v), we
predict the height hv of the subtree rooted at v, denoted by
Tv, as follows. Let Pmax be the estimation of the probability
of transiting from v to the mode of its children (i.e., v’s child
with the largest noisy count). Assume that the probability
4. Under this
of the mode at each level of Tv is also Pmax
assumption, we can estimate the largest noisy count of the
nodes in level hv of Tv by c(v) · (Pmax )hv . Recall the fact
that Tv will not be further expanded if none of the nodes in
level hv can pass the threshold θ. We get c(v)·(Pmax )hv = θ,

4A more precise estimation could be obtained by applying
the Markov assumption to each level of Tv at the cost of
eﬃciency.

642that is, hv = logPmax
by nmax − i, we have

θ
c(v) . Since the height of Tv is bounded

4.3.3 Computing Threshold θ

A node in T is not further expanded if its noisy count is
less than the threshold θ. The main source of error in T
comes from the nodes that are of a true count of zero but of
a noisy count greater than θ (referred to as false nodes). For
this reason, we design a threshold to limit the total number
of false nodes in T with the goal of lowering the magnitude
of noise in T .

For each expansion, a false node v will generate, on av-
erage, |I|Pθ false children, where Pθ is the probability of
Laplace noise passing θ. This is because a descendant of v
must have a true count of zero. With the expansion of T ,
the number of false nodes accumulates exponentially with
the factor of |I|Pθ, resulting in excessive noise. To limit
the exponential growth of false nodes, we require |I|Pθ ≤ 1,
that is, Pθ ≤ 1
|I| . Since, under Laplace mechanism, given
the threshold θ and the privacy parameter ε′,

Pθ =Z ∞

θ

ε′

2ℓmax

exp(cid:18)−

xε′

ℓmax(cid:19) dx =

1
2

exp(cid:18)−

ε′θ

ℓmax(cid:19) ,

we get the threshold θ =
. We show in Section 6
that this threshold is eﬀective in eliminating false nodes
while having limited inﬂuence on nodes with large counts.

ε′

2

ℓmax ·ln |I|

4.3.4 Enforcing Consistency Constraints

The generated exploration tree T may contain some in-
consistencies for the reason that: (1) the sum of children’s
noisy counts is very unlikely to equal their parent’s noisy
count, and (2) there are some leaf nodes whose noisy counts
are missing (since their counts cannot pass the threshold θ).
In this section, we propose a method to resolve such inconsis-
tencies with the goal of improving data utility. In Appendix
A, we experimentally show that this method helps achieve
better performance.

The general idea is to approximate the missing counts by
making use of the Markov assumption and then normalize
children’s counts based on their parent’s count. More specif-
ically, our method works as follows. If none of the children
of a node v in T exceed the threshold θ, it is strong evi-
dence that v should not be further expanded, and therefore
all children of v (leaf nodes in T ) are assigned noisy counts
0. If all children pass θ, we ﬁrst calculate the conditional
probability of each child based on the sum of all children’s
noisy counts, and then obtain a consistent approximation by
multiplying this probability with their parent’s noisy count.
If some children (but not all) of v pass θ, we approximate the
noisy counts of the other children by the Markov assump-
tion. Let vc and C(vc) denote a child of v whose noisy count
cannot pass θ (called a missing node) and its Markov parent
in T , respectively. Let V denote the set of v’s children. We
partition V into V + and V −, where V + contains all nodes
passing the threshold, whereas V − contains the rest.

1. Deﬁne the following ratio for each vi ∈ V −:

rvi =

P (C(vi))

Pvj ∈V + P (C(vj))

For each vj ∈ V +, let A(vj) denote the noisy count
resulted by the Laplace mechanism in Line 10 of Al-
gorithm 1.

hv = min(logPmax

θ

c(v)

, nmax − i).

Next we discuss how to calculate Pmax for v. Let the i-
gram associated with v be L1 → L2 → · · · → Li (∀1 ≤ j ≤ i,
Lj ∈ I ∪{&}). Then we need to estimate the probability dis-
tribution of v’s children from the noisy counts known by far.
We resort to the Markov assumption for this task. Recall
that the order i−1 Markov assumption states P (Li+1|L1
i ) :≈
P (Li+1|L2
i ) may not be known in T (be-
cause we expand a node only when it passes the threshold
θ), we consider a chain of Markov assumptions (of diﬀerent
orders)

i ). Since P (Li+1|L2

P (Li+1|L1

i ) :≈ P (Li+1|L2

i ) :≈ P (Li+1|L3

i ) :≈ · · · :≈ P (Li+1)

to ﬁnd the best estimation of P (Li+1|L1
i ), which is the con-
ditional probability with the longest condition (i.e., the left-
most conditional probability in the chain) that is known in
T . Since T contains all unigrams, there is always an esti-
mation of P (Li+1|L1
i ). Pmax is then
deﬁned to be

i ), denoted by eP (Li+1|L1
Li+1∈I∪{&} eP (Li+1|L1

max

i ).

i ) and eP (Li+1|L1

If P (Li+1|L1
i ) are represented by nodes v
and v′ in T , respectively, then v′ is the Markov parent of
v in T , and any pair of corresponding nodes in the above
chain are Markov neighbors. For example, in Figure 1, v4 is
the Markov parent of v5; v5 and v1 are Markov neighbors.

Once Pmax is calculated, we can calculate the privacy pa-
rameter εv that is used for calculating the noisy counts of
v’s children as follow:

εv =

min(logPmax

¯ε
θ
c(v) , nmax − i)

,

where ¯ε is the remaining privacy budget (i.e., the total pri-
vacy budget ε minus the sum of privacy parameters con-
sumed by v and v’s ancestors). It can be observed that this
scheme ensures that the privacy budget used in a root-to-leaf
path is always ≤ ε.

10

Example 4.2. Continue from Example 4.1. For all nodes
in level 1, ε
5 is used to calculate their noisy counts. For
the expansion of the node labeled by v1 in Figure 1, we
4+10+9 = 0.43 and hv1 = 1. Therefore, the
have Pmax =
noisy counts of v1’s children are calculated with privacy pa-
rameter ε − ε
5 = 4ε
5 . For the expansion of node v2, we
4+10+9 = 0.43 and hv2 = 2. Hence its chil-
get Pmax =
dren’s noisy counts are calculated with privacy parameter
ε− ε
5 . For the expansion of node v3, we have Pmax = 4
2 = 2ε
5
9
5 is used to compute the noisy counts

10

and hv3 = 1. Thus, 2ε
of v3’s children.

The sensitivities of Q (Line 9) in diﬀerent levels are dif-
ferent. For Q in level i, a single record of length ≤ ℓmax
can change Q by at most ℓmax − i + 1. However, under the
adaptive privacy budget allocation scheme, we have to use
the largest sensitivity among all levels, that is ℓmax , in all
Laplace mechanisms; otherwise, ε-diﬀerential privacy may
be violated.

6432. If level(C(vc), T ) ≥ 2, ∀vi ∈ V −,

A(vi) = rvi · Xvj ∈V +

A(vj)

3. Otherwise,

(a) IfPvj ∈V + A(vj) ≤ c(v), ∀vi ∈ V −,

A(vi) =

c(v) −Pvj ∈V + A(vj)

|V −|

(b) Otherwise, ∀vi ∈ V −, A(vi) = 0

4. Renormalize: ∀vi ∈ V , c(vi) = c(v) ·

A(vi)

Pvj ∈V A(vj )

If vc can ﬁnd a high-quality Markov parent in T (i.e., one
representing an n-gram with n ≥ 2 5), we estimate its counts
from its high-quality siblings based on the ratio deﬁned in
Step 1. The idea behind this deﬁnition is that the ratio of
any node insigniﬁcantly changes between Markov neighbors,
and hence, it can be well approximated from the Markov
parents. Otherwise, we approximate the noisy counts by
assuming a uniform distribution, that is, equally distribute
the count left among the missing nodes (Step 3). In Step 4,
these estimated counts are normalized by the parent’s count
in order to obtain consistent approximations.

Example 4.3. Continue from Example 4.1. Suppose that
A(v9) = 2.1, A(v10) = 4, A(v11) does not pass θ, and
A(v12) = 1.9. Since rv11 = 0/(4 + 0 + 0) = 0, A(v11) :≈
(1.9 + 4 + 2.1) · 0 = 0. Finally, renormalizing the result,
we obtain c(v9) = 4 · 2.1/(2.1 + 4 + 1.9 + 0) ≈ 1, c(v10) =
4 · 4/(2.1 + 4 + 1.9 + 0) = 2, c(v11) = 0, c(v12) = 4 · 1.9/(2.1 +
4 + 1.9 + 0) ≈ 1.

4.3.5

Synthetic Sequential Database Construction

The released n-grams are useful for many data analysis
tasks. However, it is often necessary to generate a synthetic
database for diﬀerent types of queries and tasks.
In this
section, we propose an eﬃcient solution to construct a syn-
thetic sequential database from the exploration tree T (Line
17). The general idea is to iteratively generate longer grams
(up to size ℓmax ) based on the Markov assumption and make
use of the theorem below for synthetic sequential database
construction.

Theorem 4.1. Given the set of n-grams with size 1 ≤
n ≤ ℓmax , the (truncated) input database (with maximal se-
quence length ℓmax ) can be uniquely reconstructed.

Proof. (Sketch) Since ℓmax -grams can only be supported
by sequences of length ℓmax , all sequences of length ℓmax can
be uniquely reconstructed by ℓmax -grams. Once all ℓmax
sequences have been identiﬁed, we can update the n-gram
counts by decreasing the numbers of occurrences of the n-
grams in ℓmax sequences. The resulting set of n-grams (1 ≤
n ≤ ℓmax − 1) can then be considered as if they were gener-
ated from an input database with maximal sequence length
ℓmax − 1. Therefore, sequences of length ℓmax − 1 can be
uniquely reconstructed as well. Following this iterative pro-
cess, all sequences can be uniquely identiﬁed. This proof
explains the way we generate the synthetic database based
on noisy n-grams.
5A unigram conveys an unconditional probability and there-
fore cannot provide a very accurate estimation.

Intuitively, longer grams can be generated by “joining”
shorter grams. Formally, we deﬁne a join operation over
two n-grams. Let g1 = L11 → L12 → · · · → L1n and g2 =
L21 → L22 → · · · → L2n. Then g1 can join with g2 if
∀2 ≤ i ≤ n, L1i = L2(i−1), denoted by g1 ✶ g2, and g1 ✶
g2 = L11 → L12 → · · · → L1n → L2n. Note that the join
operation is not symmetric:
it is possible that g1 can join
with g2, but not vice versa.

Let the height of T be h. We iteratively extend T by
generating n-grams with h < n ≤ ℓmax , starting from level
h of T . We extend T level by level, where level n + 1,
representing all (n + 1)-grams, can be generated by joining
all possible n-grams in level n. Let g1 and g2 be two n-grams
that can be joined. Then we can estimate the count of the
joined (n + 1)-gram as follows:

|g1 ✶ g2| = c(g1) × P (L2n|g1)

= c(g1) × P (L2n|L11 → L12 → · · · → L1n)
≈ c(g1) × P (L2n|L12 → L13 → · · · → L1n)
= c(g1) × P (L2n|L21 → L22 · · · → L2(n−1))

≈ c(g1) ×

c(L21
2n)

c(L21

2(n−1))

Note that all counts in the above equation are noisy ones
for the reason of privacy (see more details in Section 5).
Since c(L21
2(n−1)) must have been known in the
extended T , |g1 ✶ g2| can be computed. We keep extending
T until: 1) ℓmax has been reached, or; 2) no grams in a level
can be joined.

2n) and c(L21

c(I3→I1) = 4 × 2

Example 4.4. Continue from Example 4.1. I2 → I3 →
I1 and I3 → I1 → I2 can be joined to generate I2 → I3 →
I1 → I2. Its count can be estimated by c(I2 → I3 → I1) ×
c(I3→I1→I2)
4 = 2. This 4-gram is represented as a
new node in T , as illustrated by v13 in Figure 1. Similarly,
I2 → I3 → I1 can join with I3 → I1 → I1, resulting in
I2 → I3 → I1 → I1. Since these two 4-grams cannot be
joined, the extension of T ends at level 4.

After extending T , we can generate the synthetic database
in the following way. Let the height of the extended T be
he. We start from level he. For each v ∈ levelSet(he, T ),
we publish c(v) copies of g(v), and update the counts of all
nodes supported by g(v) (i.e., all nodes representing a gram
that can be generated from g(v)). An n-gram supports at
i=1 i = n(n+1)
nodes and therefore requires at most
updates. With a hash map structure, each update

n(n+1)

2

most Pn

2

can be done in constant time.

Example 4.5. Continue from Example 4.4. For node v13
in level 4 of T , we publish 2 copies of I2 → I3 → I1 → I2
and update the counts of all nodes supported by g(v13), that
is, the nodes representing I1, I2, I3, I2 → I3, I3 → I1,
I1 → I2, I2 → I3 → I1 and I3 → I1 → I2.

5. PRIVACY ANALYSIS

We give the privacy guarantee of our approach below.

Theorem 5.1. Algorithm 1 satisﬁes ε-diﬀerential privacy.

Proof. (Sketch) Due to the correlation of the counts in
the same level of T (i.e., a single sequence can aﬀect mul-
tiple counts in a level), the sequential composition and par-

644allel composition properties [15] must be applied with cau-
tion. Hence, we prove the theorem by the deﬁnition of ε-
diﬀerential privacy. Consider two neighboring databases D
and D′. We ﬁrst consider Lines 1 − 15 of Algorithm 1, that
is, the construction of T . Let this part be denoted by A.
Then we need to prove P r[A(D)=T ]
In essence, T
is built on the noisy answers to a set of count queries (via
Laplace mechanism). Let each root-to-leaf path be indexed
by j. We denote a node in level i and path j by vij, its pri-
vacy parameter by εij, and its count in D and D′ by Q(D)ij
and Q(D′)ij, respectively. Then we have

P r[A(D′)=T ] ≤ eε.

P r[A(D) = T ]
P r[A(D′) = T ]

=

nmaxYi=1

|L|i

Yj=1

exp(−εij

exp(−εij

|c(vij )−Q(D)ij )|

)
|c(vij )−Q(D′)ij )|

ℓmax

ℓmax

(4)

)

We ﬁrst claim that a single record can only aﬀect at most
ℓmax root-to-leaf paths. This is due to two facts: (1) all an-
cestors of a node that is inﬂuenced by the additional record

must also be inﬂuenced; (2)Pj |Q(D)ij − Q(D′)ij| ≤ ℓmax .

Therefore, Equation 4 could be rewritten as

P r[A(D) = T ]
P r[A(D′) = T ]

|c(vij )−Q(D)ij )|

)
|c(vij )−Q(D′)ij )|

ℓmax

)

ℓmax

j=1 εij|Q(D)ij − Q(D′)ij|

=

exp(−εij

exp(−εij

ℓmaxYj=1

nmaxYi=1
≤ exp Pnmax
i=1 Pℓmax
≤ exp  1
ℓmaxXj=1
nmaxXi=1
≤ exp  1

ℓmax

ℓmax

≤ eε

ℓmax

εij!

ε!

ℓmaxXj=1

SincePi εij = ε, we have

P r[A(D) = T ]
P r[A(D′) = T ]

Note that εij is calculated based on noisy counts. Hence,
the construction of T satisﬁes ε-diﬀerential privacy. In ad-
dition to the construction of T , we enforce consistency con-
straints on T and generate the synthetic sequential database
in Lines 16 and 17. Since these two steps are conducted on
noisy data and do not require access to the original database,
they satisfy 0-diﬀerential privacy. Therefore, our solution as
a whole gives ε-diﬀerential privacy.

6. PERFORMANCE ANALYSIS

6.1 Error Analysis

The error of the sanitized data comes from three major
sources: ﬁrst, using n-grams with 1 ≤ n ≤ h to estimate
longer n-grams with h < n ≤ ℓmax (recall that h is the
height of the unextended tree, see Section 4.3.5); second, the
truncation conducted to limit the eﬀect of a single sequence;
third, the noise added to the n-grams with 1 ≤ n ≤ h to sat-
isfy diﬀerential privacy. We call the ﬁrst two types of error
approximation error and the last type of error Laplace er-
ror. Given a speciﬁc ε value, the total error of our approach
is determined by ℓmax and nmax . Intuitively, a smaller ℓmax
value incurs larger approximation error, but meanwhile it in-
troduces less Laplace error because of a smaller sensitivity.
Analogously, a smaller nmax value causes larger approxima-
tion error, but results in more accurate counts. Therefore

Table 4: Experimental dataset characteristics.

Datasets
MSNBC

STM

|D|

989,818
1,210,096

|I| max|S|
17
14,795
342

121

avg|S|

5.7
6.7

our goal is to identify good values for ℓmax and nmax that
minimize the sum of approximation error and Laplace error.
Due to the space limit, we experimentally study the eﬀect
of varying ℓmax and nmax values on the performance of our
solution and provide our insights in Appendix A. In gen-
eral, our solution is designed to perform stably well under
a relatively wide range of ℓmax and nmax values. In the rest
of this section, we only report the major results of our solu-
tion in terms of count query and frequent sequential pattern
mining.

6.2 Experimental Evaluation

!

We experimentally evaluate the performance of our solu-
tion (referred to as N-gram) in terms of two data analysis
tasks, namely count query and frequent sequential pattern
mining. As a reference point, for count query, we compare
the utility of our solution with the approach proposed in [4],
which relies on a preﬁx tree structure (referred to as Preﬁx );
for frequent sequential pattern mining, we compare our ap-
proach with both Preﬁx and the method designed in [16] for
ﬁnding frequent (sub)strings (referred to as FFS ). Two real-
life sequential datasets are used in our experiments. MSNBC
describes sequences of URL categories browsed by users in
time order on msnbc.com.
It is publicly available at the
UCI machine learning repository6. STM records sequences
of stations visited by passengers in time order in the Mon-
treal transportation system. It is provided by the Soci´et´e de
transport de Montr´eal 7. The detailed characteristics of the
datasets are summarized in Table 4, where |D| is the number
of records (sequences) in D, |I| is the universe size, max |S|
is the maximum length of sequences in D, and avg|S| is the
average length of sequences.

6.2.1 Count Query

To evaluate the performance of our approach for count
queries, we follow the evaluation scheme that has been widely
used in previous works [23], [22], [6]. The utility of a count
query Q is measured by the relative error of its answer on

the sanitized sequential database Q(eD) with respect to the

true answer on the original database Q(D), which is formal-
ized as follows:

error (Q(eD)) =

|Q(eD) − Q(D)|

max{Q(D), s}

,

where s is a sanity bound that mitigates the eﬀect of the
queries with extremely small selectivities [23], [22]. Follow-
ing the convention, s is set to 0.1% of |D|, the same setting
as [23], [22], [6]. In particular, the answer to Q is deﬁned
to be the number of occurrences of Q in a database. For
example, given Q = I2 → I3, its answer over the dataset
in Table 1 is 6. This type of count queries plays an im-
portant role in many applications, for example, calculating
riderships in a transportation system.

In the ﬁrst set of experiments, we examine the average
relative errors of count queries under diﬀerent query sizes
6http://archive.ics.uci.edu/ml/
7http://www.stm.info

645r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

N-gram

Prefix

N-gram-Uniform

Baseline

4

8

12

16

20

Query Size

(a) ε = 0.1

N-gram

Prefix

N-gram-Uniform

Baseline

0.5 

0.4 

0.3 

0.2 

0.1 

0.0 

0.5 

0.4 

0.3 

0.2 

0.1 

0.0 

r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

N-gram

Prefix

N-gram-Uniform

Baseline

4

8

12

16

20

Query Size

(a) ε = 0.1

N-gram

Prefix

N-gram-Uniform

Baseline

0.5 

0.4 

0.3 

0.2 

0.1 

0.0 

0.5 

0.4 

0.3 

0.2 

0.1 

0.0 

4

8

12

16

20

4

8

12

16

20

Query Size

(b) ε = 1.0

Query Size

(b) ε = 1.0

Figure 2: Average relative error vs. ε on MSNBC

Figure 3: Average relative error vs. ε on STM

(i.e., the number of items in a query) and diﬀerent privacy
budgets. We divide all queries into ﬁve subsets with dif-
ferent maximal query sizes (4, 8, 12, 16 and 20). For each
subset, we generate 10,000 random queries of sizes that are
uniformly distributed at random between 1 and its maximal
size. Each item in a query is uniformly selected at random
from the item universe.

Figures 2 and 3 report the average relative errors of dif-
ferent schemes under diﬀerent query sizes over two typical
ε values 8 while ﬁxing ℓmax = 20 and nmax = 5. It can be
observed that the average relative errors of N-gram are con-
sistently lower than those of Preﬁx under all settings. The
improvements are substantial, ranging from 32% to 63%.
The relative errors of N-gram are relatively small even un-
der a strong privacy requirement (i.e., ε = 0.1).

To demonstrate the eﬀectiveness of the n-gram model, we
apply the synthetic database generation technique described
in Section 4.3.5 on non-noisy 5-grams of both MSNBC and
STM, and issue count queries on the two synthetic databases
(referred to as Baseline). The average relative errors of
Baseline give the approximation error due to the employ-
ment of the n-gram model, while the diﬀerences between
Baseline and N-gram ascribe to Laplace error. As one can
observe, the approximation errors are relatively small on
both datasets, demonstrating that the n-gram model is ef-
fective in capturing the essential sequentiality information
of a database. For Laplace error, we stress that the n-gram
model provides a general and ﬂexible framework that can
accommodate other more advanced noise injection mecha-
nisms, such as the matrix mechanism [13] and the MWEM
mechanism [11]. Hence it may require less noise added than
Laplace mechanism, resulting in smaller Laplace error.
It
may even allow a larger nmax value to be used and therefore
further reduce approximation error. Thus, we deem that
the variable-length n-gram model bears great promise for
diﬀerentially private sequential data release.

To prove the beneﬁt of our adaptive privacy budget alloca-

8According to [16], ε = 0.1 and ε = 1.0 correspond to high
and medium privacy guarantees, respectively.

tion scheme, we report the average relative errors of a vari-
ant of N-gram (referred to as N-gram-Uniform), in which
the adaptive allocation scheme is replaced by the uniform
allocation scheme described in Section 4.3.2. The improve-
ment is less obvious on M SN BC because many paths are
actually of length nmax, whereas the improvement on ST M
is noticeable, especially when ε = 0.1.

Due to the truncation operation conducted in Algorithm 1,
any count query with a size greater than ℓmax receives an an-
swer 0 on the sanitized dataset. However, we point out that
in reality it is not a problem because the true answer of
such a query is typically very small (if not 0). For many
real-life analyses (e.g., ridership analysis), the diﬀerence be-
tween such a small value and 0 is negligible. In addition, this
limitation also exists in Preﬁx and is inherent in any dif-
ferentially private mechanism because Laplace mechanism
cannot generate reliable answers on extremely small values.

6.2.2 Frequent Sequential Pattern Mining

The second data analysis task we consider is frequent se-
quential pattern mining, a more speciﬁc data mining task.
Given a positive integer number K, we are interested in the
top K most frequent sequential patterns (i.e., most frequent
subsequences) in the dataset. This data analysis task helps,
for example, a transportation agency better understand pas-
sengers’ transit patterns and consequently optimize its net-
work geometry.

We compare the performance of N-gram with Preﬁx and
FFS. All size-1 frequent patterns are excluded from the re-
sults since they are of less interest and trivial in frequent se-
quential pattern mining. We would like to clarify that FFS
actually has two assumptions: 1) all frequent patterns are of
the same length; 2) the lengths of frequent patterns are iden-
tical to the lengths of input sequences. Since generally these
two assumptions cannot be satisﬁed in a frequent sequen-
tial pattern mining task, it is not fair to directly compare
FFS with N-gram and Preﬁx. However, there are very few
approaches that support frequent sequential pattern mining
under diﬀerential privacy. Hence we still report the perfor-

646Table 5: True positive ratio vs. K value on M SN BC

(a) ε = 0.1

40

20

K value
100
N-gram 100% 90% 93% 96% 94%
85% 78% 80% 84% 86%
Preﬁx
FFS
70% 63% 57% 58% 55%

60

80

(b) ε = 1.0

40

20

K value
100
N-gram 100% 93% 97% 99% 97%
90% 82.5% 85% 90% 89%
Preﬁx
FFS
70%
63% 57% 58% 55%

80

60

Table 6: True positive ratio vs. K value on ST M

(a) ε = 0.1

40

20

100
K value
N-gram 95% 93% 93% 94% 91%
65% 68% 75% 83% 82%
Preﬁx
FFS
35% 33% 35% 36% 43%

60

80

(b) ε = 1.0

40

60

20

K value
100
N-gram 100% 100% 98% 100% 98%
70% 68% 80% 86% 85%
Preﬁx
FFS
35% 33% 35% 36% 43%

80

mance of FFS and provide insights on the key factor that
guarantees high utility on frequent sequential pattern min-
ing. For both FFS and Preﬁx, we have tested various param-
eter settings and report the best results we have obtained.
To give an intuitive impression on the performance of
these three approaches, we ﬁrst report their true positive
ratios under diﬀerent K and ε values in Tables 5 and 6.
Given K, we generate the top K most frequent sequential
patterns on both the original dataset D and the sanitized

dataset eD, which are denoted by FK (D) and FK (eD), re-

spectively. The true positive ratio is then deﬁned to be the
percentage of frequent patterns that are correctly identiﬁed,
. The results indicate that N-gram
that is,
can reliably identify the most frequent patterns in a given
database with strong privacy guarantee.

|FK (D)∩FK ( eD)|

K

To measure the utility of sanitized data more precisely, we
adopt the metric proposed in [6], which further takes into
consideration the accuracy of the supports of patterns in

FK (eD) 9. The utility loss on the sanitized dataset is deﬁned
to be the diﬀerence between FK (D) and FK (eD), that is,
|sup(Fi, FK (D)) − sup(Fi, FK (eD))|

PFi∈FK (D)

sup(Fi, FK (D))
K

,

If Fi /∈

port of every frequent pattern); if the metric equals 1, it

where sup(Fi, FK (D)) and sup(Fi, FK (eD)) denote the sup-
ports of Fi in FK (D) and FK (eD), respectively.
FK (eD), sup(Fi, FK (eD)) = 0. Therefore, if the metric equals
0, it means that FK (D) is identical to FK (eD) (even the sup-
implies that FK (D) and FK (eD) are totally diﬀerent.

In Figures 4 and 5, where ℓmax = 20 and nmax = 5, we
can observe that our proposal signiﬁcantly outperforms the
9The support of a pattern is the number of its occurrences
in a database.

N-gram
Prefix
FFS

20

40

60

80

100

K Value
(a) ε = 0.1

N-gram
Prefix
FFS

s
s
o
L
 
y
t
i
l
i
t

U

1.0 

0.8 

0.6 

0.4 

0.2 

0.0 

s
s
o
L
 
y
t
i
l
i
t

U

1.0 

0.8 

0.6 

0.4 

0.2 

0.0 

20

40

60

80

100

K Value
(b) ε = 1.0

Figure 4: Utility loss vs. K on MSNBC

other two approaches. In addition, for the frequent patterns
that are correctly identiﬁed, the relative errors of their sup-
ports are typically very small even when ε = 0.1. The main
reason is that N-gram extracts the essential information of
a database in terms of a set of n-grams, which are actually
the most frequent patterns in the database. This fact al-
lows N-gram to perform well even under a small ε value. In
contrast, in Preﬁx, the noise added to a frequent pattern’s
count accumulates quickly in proportion to the number of
longer sequences that contain this frequent pattern. The
major limitation of FFS is its preﬁx data structure, which
generates frequent patterns based on very short preﬁxes.

7. CONCLUSION

In this paper, we proposed a novel approach to diﬀeren-
tially private sequential data publication based on a variable-
length n-gram model. This model extracts the essential
information of a sequential database in terms of a set of
variable-length n-grams whose counts are relatively large
and therefore subject to lower Laplace error. We devel-
oped a set of key techniques that are vital to the success
of the n-gram model. Furthermore, we designed a synthetic
sequential database construction method, which allows pub-
lished n-grams to be used for a wider range of data analysis
tasks. Extensive experiments on real-life datasets proved
that our solution substantially outperforms state-of-the-art
techniques [16], [4] in terms of count query and frequent
sequential pattern mining.

8. ACKNOWLEDGMENTS

This work was supported in part by a grant from the EIT
ICT Labs to INRIA. The authors would like to thank the
anonymous reviewers for their constructive comments.

9. REFERENCES
[1] O. Abul, F. Bonchi, and M. Nanni. Never walk alone:

Uncertainty for anonymity in moving objects
databases. In ICDE, pages 376–385, 2008.

647N-gram
Prefix
FFS

r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

MSNBC

STM

0.20

0.15

0.10

0.05

0.00

20

40

60

80

100

K Value
(a) ε = 0.1

16

18

20
lmax

22

24

Figure 6: Average relative error vs. ℓmax (ε = 1.0)

s
s
o
L
 
y
t
i
l
i
t

U

1.0 

0.8 

0.6 

0.4 

0.2 

0.0 

s
s
o
L
 
y
t
i
l
i
t

U

1.0 

0.8 

0.6 

0.4 

0.2 

0.0 

N-gram
Prefix
FFS

20

40

60

80

100

K Value
(b) ε = 1.0

Figure 5: Utility loss vs. K on STM

[2] A. Blum, K. Ligett, and A. Roth. A learning theory

approach to non-interactive database privacy. In
STOC, pages 609–618, 2008.

[3] F. Bonchi, L. V. Lakshmanan, and H. W. Wang.

Trajectory anonymity in publishing personal mobility
data. SIGKDD Explorations Newsletter, 13(1):30–42,
2011.

[4] R. Chen, B. C. M. Fung, and B. C. Desai.

Diﬀerentially private trajectory data publication.
CoRR, abs/1112.2020, 2011.

[5] R. Chen, B. C. M. Fung, N. Mohammed, and B. C.
Desai. Privacy-preserving trajectory data publishing
by local suppression. Information Sciences, in press.

[6] R. Chen, N. Mohammed, B. C. M. Fung, B. C. Desai,

and L. Xiong. Publishing set-valued data via
diﬀerential privacy. PVLDB, 4(11):1087–1098, 2011.

[7] C. Dwork. Diﬀerential privacy. In ICALP, pages 1–12,

2006.

[8] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov,

and M. Naor. Our data, ourselves: privacy via
distributed noise generation. In EUROCRYPT, pages
486–503, 2006.

[9] C. Dwork, F. McSherry, K. Nissim, and A. Smith.

Calibrating noise to sensitivity in private data
analysis. In TCC, pages 265–284, 2006.

[10] C. Dwork, M. Naor, O. Reingold, G. N. Rothblum,
and S. Vadhan. On the complexity of diﬀerentially
private data release: eﬃcient algorithms and hardness
results. In STOC, pages 381–390, 2009.

[11] M. Hardt, K. Ligett, and F. McSherry. A simple and

practical algorithm for diﬀerentially private data
release. CoRR, abs/1012.4763, 2012.

[12] H. Hu, J. Xu, S. T. On, J. Du, and J. K.-Y. Ng.

Privacy-aware location data publishing. ACM
Transactions on Database Systems, 35(3):17, 2010.

[13] C. Li, M. Hay, V. Rastogi, G. Miklau, and

A. McGregor. Optimizing linear counting queries

under diﬀerential privacy. In PODS, pages 123–134,
2010.

[14] C. Manning and H. Schutze. Foundations of Statistical

Natural Language Processing. MIT Press, 1999.

[15] F. McSherry. Privacy integrated queries: an extensible

platform for privacy-preserving data analysis. In
SIGMOD, pages 19–30, 2009.

[16] F. McSherry and R. Mahajan. Diﬀerentially private

network trace analysis. In SIGCOMM, pages 123–134,
2010.

[17] N. Mohammed, R. Chen, B. C. M. Fung, and P. S.

Yu. Diﬀerentially private data release for data mining.
In SIGKDD, pages 493–501, 2011.

[18] A. Monreale, G. Andrienko, N. Andrienko,

F. Giannotti, D. Pedreschi, S. Rinzivillo, and
S. Wrobel. Movement data anonymity through
generalization. Transactions on Data Privacy,
3(2):91–121, 2010.

[19] P. Ohm. Broken promises of privacy: Responding to
the surprising failure of anonymization. UCLA Law
Review, 2010.

[20] B. Sheridan. A trillion points of data. Newsweek,

March 2009.

[21] M. Terrovitis and N. Mamoulis. Privacy preservation

in the publication of trajectories. In MDM, pages
65–72, 2008.

[22] X. Xiao, G. Bender, M. Hay, and J. Gehrke. iReduct:

Diﬀerential privacy with reduced relative errors. In
SIGMOD, pages 229–240, 2011.

[23] X. Xiao, G. Wang, and J. Gehrke. Diﬀerential privacy
via wavelet transforms. In ICDE, pages 225–236, 2010.

[24] R. Yarovoy, F. Bonchi, L. V. S. Lakshmanan, and

W. H. Wang. Anonymizing moving objects: How to
hide a MOB in a crowd? In EDBT, pages 72–83, 2009.

APPENDIX

A. ADDITIONAL EXPERIMENTS

In this section, we present the performance of N-gram un-
der diﬀerent ℓmax and nmax values and discuss several hints
for selecting reasonable ℓmax and nmax values. In addition,
we demonstrate the utility improvement due to the approx-
imation technique proposed in Section 4.3.4.

A.1 Count Query

We examine the impact of diﬀerent parameters (i.e., ℓmax
and nmax ) of the n-gram model on average relative error
of count queries. In Figure 6, we study how relative error
changes under diﬀerent ℓmax values with ε = 1.0, nmax = 5
and query size equal to 8.
In theory, a larger ℓmax value

648r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

MSNBC

STM

0.20

0.15

0.10

0.05

0.00

s
s
o
L
 
y
t
i
l
i
t

U

1.0 

0.8 

0.6 

0.4 

0.2 

0.0 

MSNBC

STM

3

4

5
nmax

6

7

16

18

20
lmax

22

24

Figure 7: Average relative error vs. nmax (ε = 1.0)

Figure 9: Utility loss vs. ℓmax (ε = 1.0)

MSNBC

STM
MSNBC-No_Approx

STM-No_Approx

s
s
o
L
 
y
t
i
l
i
t

U

1.0 

0.8 

0.6 

0.4 

0.2 

0.0 

MSNBC

STM

4

8

12

16

20

Query Size

(a) ε = 0.1

3

4

5

nmax

6

7

Figure 10: Utility loss vs. nmax (ε = 1.0)

0.5 

0.4 

0.3 

0.2 

0.1 

0.0 

0.5 

0.4 

0.3 

0.2 

0.1 

0.0 

r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

r
o
r
r

 

E
e
v
i
t

l

 

a
e
R
e
g
a
r
e
v
A

MSNBC
STM

MSNBC-No_Approx

STM-No_Approx

4

8

12

16

20

Query Size

(b) ε = 1.0

Figure 8: Eﬀect of node count approximation.

allows more information of the underlying database to be
retained at the cost of higher sensitivity (and hence larger
Laplace noise). Therefore, the selection of ℓmax needs to
take into consideration the trade-oﬀ between approximation
error and Laplace error. However, in reality, a reasonable
ℓmax value could be chosen more easily because the aver-
age sequence length of many real-life datasets is relatively
small. Consequently, Laplace error is the major concern in
this case. This is conﬁrmed by Figure 6. Since most se-
quences in M SN BC and ST M are of a small length, when
ℓmax is suﬃciently large (i.e., 16), increasing ℓmax does not
signiﬁcantly lower approximation error, but simply increases
Laplace noise. Moreover, we can observe that our approach
performs relatively stable under varying ℓmax values. This
can be explained by the large counts of short grams, which
are more resistant to Laplace noise.

Figure 7 examines the performance of N-gram with re-
spect to varying nmax values, where ε = 1.0, ℓmax = 20 and
query size is 8. Similar to the selection of ℓmax , the selection
of nmax also involves the trade-oﬀ between approximation er-
ror and Laplace error. A larger nmax reduces approximation
error while increasing Laplace error. To obtain a reasonable
trade-oﬀ, we develop the adaptive privacy budget allocation
scheme and the formal choice of the threshold value, which
automatically select the best gram sizes on the ﬂy. Even
a data holder speciﬁes an unreasonably large nmax , our ap-

proach will end up with shorter grams. Therefore, it can be
observed that the performance of our solution is insensitive
to varying nmax values. From our experimental results, we
believe that, in most cases, nmax = 5 is a good choice. In
addition, we point out that a good nmax value is related to
|D| and |I|, a larger |D| or a smaller |I| suggests a larger
nmax value.

One key technique that we develop to improve accuracy
of count queries is to enforce consistency constraints by ap-
proximating the counts of the nodes that cannot pass the
threshold (Section 4.3.4). In the next set of experiments, we
demonstrate that this technique indeed improves the accu-
racy of count queries compared to the case where we naively
set the noisy counts of all nodes that cannot pass the thresh-
old to 0.
In Figure 8, we set ℓmax = 20 and nmax = 5.
MSNBC No-Approx and STM No-Approx give the relative
errors of N-gram without the approximation technique. As
we can observe, this technique improves the relative error
for all query sizes under diﬀerent ε values, up to 47%.

A.2 Frequent Sequential Pattern Mining

In the last set of experiments, we study the impact of ℓmax
and nmax on frequent sequential pattern mining. Figure 9
reports the utility loss of N-gram under diﬀerent ℓmax values
with ε = 1.0 and nmax = 5. The aforementioned trade-oﬀ
in the selection of ℓmax still applies to frequent sequential
pattern mining. This time, we can clearly observe such a
trade-oﬀ in Figure 9: when ℓmax is small, the approximate
error is the main source of error; when ℓmax becomes larger,
the total error is dominated by Laplace error. Nevertheless,
N-gram can provide good utility for a wide range of ℓmax
values. This property makes it easier for a data holder to
select a good ℓmax value.

Similar trade-oﬀ due to nmax can be observed in Figure 10,
where ℓmax is ﬁxed to 20. There exists a nmax value that
minimizes the sum of approximation error and Laplace error.
Due to the series of techniques we propose, the utility lost
under diﬀerent nmax values is comparable.

649