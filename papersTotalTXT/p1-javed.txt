Measurement and Analysis of Trafﬁc Exchange Services

Mobin Javed
U.C. Berkeley

mobin@cs.berkeley.edu

Cormac Herley
Microsoft Research

cormac@microsoft.com

Marcus Peinado
Microsoft Research

marcuspe@microsoft.com

Vern Paxson

U.C. Berkeley, International
Computer Science Institute
vern@cs.berkeley.edu

Abstract
Trafﬁc exchange services enable members to bring trafﬁc to their
websites from a diverse pool of IP addresses, in return for visiting
sites of other members. We examine the world of trafﬁc exchanges
to characterize their makeup, usage, and monetization. We ﬁnd
that the ecosystem includes a range of services, from manual ex-
changes where participants must solve CAPTCHAs between suc-
cessive page views, to exchanges that provide tools that automati-
cally surf without requiring any user action. By “milking” a sam-
ple of these exchanges, we analyze month-long datasets to examine
the nature of URLs that members submit to them. We ﬁnd a wide
prevalence of URLs for services that pay users in return for views to
their content, and at least 30% of the requested impressions are for
pages that clearly participate in a class of impression fraud called
referrer spooﬁng. We also analyze the size and composition of
a sample of these exchange networks by making purchases, ﬁnd-
ing that the exchanges delivered visits from roughly 200K unique
IP addresses, and that in some exchange networks, the majority of
visits came from cloud hosting services.

Categories and Subject Descriptors
C.2.0 [General]: Security and protection

General Terms
Measurement; Advertising fraud

Keywords
Trafﬁc exchanges; Impression fraud; Click fraud

1.

INTRODUCTION

An eco-system has arisen to provide free trafﬁc from a diverse
pool of IP addresses using the principle of exchange: members visit
each other’s websites, in return receiving visits to their own web-
sites. Exchanges of signiﬁcant size can potentially enable members
to effectively “launder” clicks to their sites, making them appear of
a much richer nature than in reality.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
IMC’15, October 28–30, 2015, Tokyo, Japan.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3848-6/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2815675.2815708.

Understanding the signiﬁcance and likely evolution of such ex-
changes requires identifying the motives of the participants. One
obvious motive—though not the only one, it turns out—concerns
forms of advertising fraud.
Internet advertisers generally desire
“organic” visitors, i.e., truly engaged users. Unscrupulous pub-
lishers of Internet content, however, can seek to receive cheap in-
organic trafﬁc in order to fraudulently earn from purported impres-
sions and clicks received on the advertisements they display. Ad-
vertisers can identify simple forms of bogus trafﬁc by observing
impressions or clicks disproportionately due to the same IP ad-
dresses over a short period of time. Fraudsters in turn will seek
ways to spread out the apparent pool of users visiting their pages to
thwart such detection.

Indeed, over the past decade different schemes for generating
fraudulent trafﬁc from a diverse pool have arisen. By their sheer
size, botnets are well suited to generate trafﬁc from disparate
sources, as evidenced by impression and click-fraud botnets such as
ZeroAccess, Fiesta, and 7cy [31, 33]. Another approach, pay-per-
view networks, embeds websites as pop-unders in other websites,
seemingly delivering the visitors of one website to another [34].

A third approach, one that our study examines in detail, is the use
of trafﬁc exchanges to pool clicks, allowing participants to bring
disparate trafﬁc to their sites on-the-cheap. In such exchange net-
works, participants performing N clicks for the exchange, all com-
ing from the participant’s IP address, in return reap credits to re-
ceive a different N visits (or somewhat fewer, depending on the
exchange’s structure) delivered to URLs of their choosing. Since
the exchange has many members, the trafﬁc arriving at each mem-
ber’s target site appears quite dispersed.

More broadly, we examine the world of trafﬁc exchanges, ﬁnd-
ing a wide variety of offerings, and usage paradigms beyond just
ad fraud. The offerings range from manual exchanges, where par-
ticipants must solve CAPTCHAs between successive clicks, to ex-
changes that provide tools that automatically surf without requiring
any user action, and allow customization of time-on-page, User-
Agent, and Referer ﬁelds. Some exchanges are free, while others
charge for certain levels of service. We study several prominent
exchanges in each category, casting light on this little-studied phe-
nomenon and the monetization it supports.

By lurking as a non-active exchange participant, we observe both
the origin (which IP addresses) and the destination (what websites)
of trafﬁc in circulation. This allows us to estimate the size of ex-
changes and understand the strategies pursued by those using them.
We ﬁnd that some exchanges deliver trafﬁc from tens of thousands
of IP addresses. A large fraction of the trafﬁc that ﬂows through
the autosurf exchanges is generated by bots running in cloud host-
ing services, and terminates on websites that generate a multitude
of impression requests to ad networks. Such referrer spooﬁng ad

1fraud makes up one of the major categories we observed [35, 25].
In contrast, members of the manual exchanges appear to indeed
reﬂect the sought-after demographic of the ads displayed there.

Two factors distinguish our work from previous studies on traf-
ﬁc generation. First, while there have been studies of services that
deliver bulk trafﬁc for money, ours is the ﬁrst large-scale examina-
tion of exchange networks primarily designed for free exchange of
trafﬁc amongst participants, though they also offer trafﬁc for pur-
chase. Second, the targets of trafﬁc exchanges potentially differ
in character from those for paid sites; since participants barter for
their trafﬁc with reciprocal trafﬁc, they may pursue different mon-
etization strategies from those who pay for trafﬁc.

The rest of this paper proceeds as follows: § 2 covers related
work and § 3 provides basic background on the different categories
of exchanges. § 4 describes the characteristics of the exchanges we
study. § 5 describes our measurements of popular target websites
in the exchanges. In § 6 we measure the size of the exchanges in
terms of unique participants and provide estimates of the impres-
sions these exchanges serve per day. In § 7 we discuss our ﬁnd-
ings and provide rough estimates of the volume of money ﬂowing
through the exchanges.

2. RELATED WORK

Trafﬁc generation and advertising fraud have received consider-
able study. Work on advertising fraud lies in three categories: (i)
impression fraud and markets for buying trafﬁc, (ii) characteriza-
tion studies on click fraud, and (iii) detection of fraudulent clicks.
Zhang et al. study the quality of trafﬁc delivered by trafﬁc
providers who promise bulk visitors for a monthly cost, and com-
pare that to the trafﬁc obtained from traditional keyword auctions
and sponsored banner ads in search results [37]. They purchase
trafﬁc from these providers, and based on characterization of mouse
activity, sub-page views, and timing of visits on their websites,
ﬁnd that these providers mostly deliver inorganic/automated traf-
ﬁc; only one of the providers delivered seemingly organic trafﬁc
via a paid-to-view scheme for recruiting visitors.

The work of Springborn et al. on impression fraud appears most
relevant to our paper [34]. The authors bought views from multi-
ple trafﬁc sources and studied how the trafﬁc is delivered to their
honeypot websites by investigating the referer ﬁeld. They identify
various pay-per-view (PPV) networks, in which participating web-
sites load multiple other websites as pop-unders, i.e., in windows
hidden behind the active browser window. This way, whenever a
legitimate user arrives at the participating website, they unknow-
ingly also visit the websites loaded as pop-unders. By mining the
publicly available Common Crawl Dataset [7], the authors identify
≈ 11K unique domains that embed PPV tags, similar to standard
ad tags, from the ten networks they study. By looking at the trafﬁc
statistics of these websites at MuStat [19], they estimate that these
networks deliver on the order of 150M impressions per day to web-
sites, which in turn load up ≈ 500M ad impressions per day. Based
on this analysis, the authors suggest simple countermeasures, to
the effect of checking the referer against a blacklist of PPV net-
works/publishers that participate in these networks, and checking
the viewport dimensions to make sure that the ad is indeed dis-
played in a visible area in a browser. Pay-per-view networks differ
from trafﬁc exchange networks in how they generate trafﬁc and
their business model. While trafﬁc exchange networks often of-
fer free trafﬁc using the principle of exchange, pay-per-view net-
works generate trafﬁc using participating websites, to whom they
pay cheap CPM (cost per thousand impressions) rates, and then sell
the generated trafﬁc at a proﬁt.

We are unaware of any work on view-fraud botnets in the aca-
demic literature. However, at least two botnets intended for view
fraud have received blogging attention: (i) The Chameleon bot-
net estimated to consist of ≈ 120K machines targeted a set of 200
websites, and repeatedly cleared cookies on the victim’s browser
to appear as a new user on every visit to the website [9]; (ii) The
TDSS botnet, which leveraged the ClickIce Ad Exchange to deliver
bot trafﬁc to various publishers, who in turn defrauded display ad-
vertisers [8]. This botnet utilized the pay-per-click model of the
ClickIce Exchange to request text ads that contained a clickable
publisher link. TDSS bots have the following capabilities: (i) de-
liver trafﬁc to publishers by visiting the clickable link; some pub-
lishers optimize their webpages for this bot trafﬁc—if a real user
visits, they are shown pages with content, but if the bot requests the
same page, a page with only ads is displayed, (ii) use the browser
cookies of the infected user to make the ad networks on the pub-
lisher’s website believe that the ad-slot is for a high-value user, and
(iii) spoof mouse, scroll, and click events on the target webpages.
Recent years have seen characterization studies of click fraud
bots. Miller et al. studied the Fiesta and 7cy clickbot families to
understand the click fraud techniques they employ [31]. For Fiesta,
they observe that, similar to TDSS, the pay-per-click model is used
to deliver trafﬁc to publishers rather than directly to the advertis-
ers in order to serve as an intermediary layer; the publishers act in
an advertiser role on obscure ad exchanges in order to capture the
trafﬁc generated from the bots. For 7cy, they ﬁnd trafﬁc directly
delivered to the publishers, with the bots mimicking human brows-
ing behavior closely and acting upon C&C instructions to click on
ads. Pearce et al. examine the activities of the ZeroAccess bot-
net, and estimate that it plausibly induced losses of $100K per day
until Microsoft’s takedown operation in late 2013 [33]. Finally,
Stone-Gross et al. document the fraudulent activities in online ad
exchanges, as observed from the perspective of a participating ad
network [35].

Detection of fraudulent trafﬁc has received less attention in the
literature, primarily due to the lack of access to data from adver-
tising networks. Haddadi proposed a technique to ﬁght click fraud
using “bluff” ads—ads having content that a normal human user is
highly unlikely to click, but click-bots would click since they do not
base clicking on comprehensibility of the content [27]. Based on
this idea, Dave et al. developed a technique to estimate the fraction
of click spam from the perspective of an advertiser, independently
from the estimates of the ad network [24]. They signed up as an ad-
vertiser on ten different networks and collected click data for their
ads (26M impressions over a period of 50 days). Analyzing this
data, they identiﬁed click spam delivered using malware, parked
domains, and arbitrage.

Lewis and Rao point out the difﬁculty of measuring the Re-
turn on Investment for advertising campaigns; the noisiness of the
efﬁcacy signals available to advertisers makes fraud hard to de-
tect [29].

Click fraud is but one web-based fraud phenomenon that has
surged in recent years. Careful measurements have played a large
part in furthering our understanding of different types of fraud and
abuse. Kanich et al., for example, study the returns from several
large spam campaigns [28]. Grier et al. characterize the spam
found on Twitter [26]. Christin details activity found on a large
underground market for illicit goods [23]. McCoy et al. study the
afﬁliate programs that are commonly used in selling medications
online [30]. These measurement studies reveal phenomena that are
more complex than they ﬁrst appear and inform efforts to combat
the fraud.

23. BACKGROUND

We surveyed the landscape of trafﬁc exchanges by performing
online web searches. We compiled a list of 50 such exchanges, and
manually investigated them to understand the features they offer.
In our analysis, we observed two categories of trafﬁc exchanges:
(i) generic, and (ii) social media promotion, where generic refers
to an exchange which offers trafﬁc exchange service for any web-
site, whereas social media promotion refers to an exchange de-
signed speciﬁcally for increasing views, likes, comments, and/or
subscribers/friends/followers on social platforms such as Twitter,
Facebook and YouTube. The latter category often requires mem-
bers to use their social network accounts for participation in the
exchange.

In this paper, we focus on generic exchanges as the destinations
to which the participants direct free trafﬁc. Determining their rea-
sons for doing so presents interesting puzzles.

We further classify the generic exchanges into the following cat-

egories based on the quality of trafﬁc they offer:

(i) Manual: Manual surf exchanges require an exchange mem-
ber to solve a CAPTCHA for each website view. This check allows
the exchange to claim that it offers human surfers for website views.
(ii) Basic Autosurf: Basic autosurf exchanges provide the mem-
bers a surf link that they can open in a browser for autosurf.
Javascript on this page automatically fetches the next site to be
viewed periodically and opens it inside an iframe within the surf
page.

(iii) Advanced Autosurf: Advanced autosurf exchanges provide
the members a tool/plugin, that they can download and run on their
machines.
In addition to automatically fetching and loading the
next page to be viewed, this tool can generate webpage view re-
quests with custom Referer and User-Agent.

We look at a sample of nine exchanges in this paper, which we
chose according to their popularity in Google search results, the
Internet marketing underground forum Black Hat World [5], and
various trafﬁc exchange ranking lists. We picked two manual ex-
changes: EasyHits4U [10] and HitSafari [15]; two basic autosurf
exchanges: 247AutoHits [2] and 10Khits [1]; and four advanced
autosurf exchanges: HitLeap [14], eBesucher [11], Jingling [16],
Otohits [20]. We also look at one of the social media promotion
exchanges, EnhanceViews Autowatcher [12], for the purpose of
comparing view trafﬁc characteristics.

4. EXCHANGE CHARACTERISTICS

In this section we provide an overview of the characteristics of
the exchanges, such as account pricing and the conﬁguration op-
tions that each exchange provides for the trafﬁc it delivers. Table 1
summarizes the characteristics of the exchanges we studied. We
discuss these in detail below.
4.1 Earning and using trafﬁc exchange cred-

its

All exchanges, with the exception of Jingling, require a user to
sign up for an account on their website. The sign-up process is sim-
ple, requiring only a valid email address. Some of the exchanges
offer premium memberships, which cost extra, but provide a better
exchange ratio (of sent to received views), monthly bonus points,
or enhanced functionality (see Table 1). The exchanges provide a
link or tool to the registered members, which they can view/run on
their machine(s) to earn exchange credits. The autosurf link/tool
communicates with the exchange Command & Control server pe-
riodically to get the list of URLs to view, whereas the manual ex-
changes require the user to solve a CAPTCHA for each URL fetch

from the server. The following are some of the features that differ-
entiate exchanges and membership levels.

• Account-to-Machine Ratio: The manual surf exchanges en-
force that one account be used only from one IP address at a
time. On the other hand, all the autosurf exchanges we stud-
ied allow an account to be used from multiple IP addresses
simultaneously.

• Exchange Ratio: For free accounts, most exchanges offer
an exchange ratio of less than 1 (often in the range 0.5–0.7).
This means that free members do not receive the same num-
ber of visits to their own websites as the number of web-
sites they view. Instead, the exchange takes a cut, thereby
enabling it to sell views directly for money. One autosurf
exchange offers a ratio greater than 1 for premium levels of
membership. The high premium membership cost at this ex-
change presumably allows the exchange to generate the extra
clicks for premium members using its own infrastructure if
the order cannot be fulﬁlled using the exchange members.

• Credits/Cash-Out: All the exchanges we investigated of-
fer trafﬁc exchange credits as a reward for surﬁng/running
their autosurf tool. Only EasyHits4U and eBesucher of-
fer a conversion of the credits to cash pay-out (via Paypal).
EasyHits4U pays $0.30 per 1,000 website views, and has a
minimum cash-out of $3. eBesucher pays $0.02 per 1,000
views, and has a minimum cash-out of ≈$3 as well. To the
best of our knowledge, cashing out on eBesucher involves
an identity check, requiring a scanned copy of a valid photo
identity document. This means that anyone who wishes to
remain anonymous must ﬁnd an indirect path to monetize
their credits. We did not try to cash-out from EasyHits4U,
since that would have required signiﬁcant effort (solving 10K
CAPTCHAs).

4.2 Controls offered for views

The exchanges offer a range of capabilities to make the trafﬁc
resemble that of an organic user population. Some of these are of-
fered only to premium members, which comes at a monthly mem-
bership price of 3–7AC, depending on the exchange and the service
level (see Table 1).

• Website Slots: Website slots are the number of URLs that
a member can have simultaneously active for viewing in the
exchange (the URLs can be pages of the same website or
different websites). The number of slots vary with member-
ship level on most exchanges, with a free account offering
between 3–15 slots depending on the exchange, and paid ac-
counts offering a higher number of slots—unlimited in some
cases. Some exchanges offer the same number of slots re-
gardless of membership level. For example, Jingling offers
400 slots, and Otohits and EnhanceViews Autowatcher offer
unlimited slots for all tiers.
An exchange user who wishes to direct trafﬁc at a small num-
ber of URLs might manage with few slots; however, a user
who wishes to generate views to a large number of URLs (for
example, different videos on a YouTube channel) might need
more than what the free tiers offer.

• Views Timing: This refers to how long a website will be
viewed for, which can affect whether the view is credited
for view count and payment purposes on the target website.
Manual and basic autosurf exchanges offer fairly short views

3Exchange

Requires
Account?

HitSafari

EasyHits4U

10Khits

247AutoHits

HitLeap

eBesucher

Jingling

Otohits
EnhanceViews

Yes

Yes

Yes

Yes

Yes

Yes

No

Yes
Yes

Earning Credits

Machines
Per Account

Cash
Payout

1

1

UL

UL

UL

UL

UL

UL
UL

No

Yes

No

No

No

Yes

No

No
No

Account
Level

I
II
III
I
II
III

I
II
III
I
II
II

I
II
III
I
II
III
I
II
-
-

Cost

Free
$5

$9.99
Free
$7.95
$19.95

Free
$10
$29
Free
$6.99
$9.99

Website
Slots
Manual

Exchange

Ratio

10
30
40
15
UL
UL

Basic Autosurf

3
10
45
5
10
100

0.5
1.0
1.0
1.0
1.0
1.0

0.5
1.2
2.0
0.7
0.8
1.0

Advanced Autosurf

Free
3AC
7AC
Free
2.90AC
5.90AC
Free
6.34AC
Free
Free

3
5
15
15
50
150
400
400
UL
UL

0.7
0.8
1.0
1.0
1.0
1.0
1.0
1.0

Variable ∓

1.0

Delivering Trafﬁc

Geo

Targeting

Anonymous

Referer

-
-
-




-
-
-
-
-
-

-
-
-



†
†
-
-

-
-
-
-
-
-

-
-
-
-
-
-













-‡

Custom

Randomize
View Time

Pageview

Time

-
-
-
-
-
-

-
-
-
-
-
-













-‡

No

No

No

No

Yes

No

Yes

Yes
No

6s

10–40s

10s

30s

10–60s

15s–10m

20s–40s
20s–2m
10s–10m
30s–2m

Table 1: The different trafﬁc exchanges offer different levels of service. For example, the Basic service at eBesucher is free, allows geo-
targeting, but will not allow anonymous or custom referer-ﬁelds, while the premium service costs 2.90AC per month and allows custom and
anonymous referers. † indicates that the exchange offers geo-targeting at the granularity of China vs. Non-China. ‡ indicates the exchange
does not offer setting a referer value, and we lack visibility to comment on the default value. ∓ indicates the exchange ratio decreases with
the number of website “slots” used (see below). UL indicates Unlimited. ‘–’ indicates that the exchange does not offer the feature at any
membership level.

(6–20s) for all service levels, and do not offer randomizing
the length of the views. Among the advanced autosurf ex-
changes, Jingling offers the shortest views (view-length of
20–40s) for a free account, but offers longer views at an ad-
ditional cost. HitLeap offers a maximum of 60s view time,
and provides the option of randomizing the time for each
view. eBesucher, Otohits and EnhanceViews Autowatcher
offer longer views (2m–10m), but all views are of the same
length. Longer views cost more on all exchanges.

• User-Agent: This option is only offered by advanced auto-
surf exchanges. Both Otohits and Jingling offer conﬁguring a
custom User-Agent. Others do not speciﬁcally offer this op-
tion. However, based on the trafﬁc we bought (which we dis-
cuss later in Section 6), we observe HitLeap and eBesucher,
by default, use a variety of User-Agents, whereas Jingling, by
default, provides only various versions of Internet Explorer.
We lack visibility for EnhanceViews Autowatcher; we did
not buy any trafﬁc from this exchange because directing au-
tosurf trafﬁc to YouTube potentially raises ethical concerns.
• Anonymous/Custom Referer: This option is also only of-
fered by advanced autosurf exchanges; the manual and basic
autosurf exchanges send the link of the exchange itself as
referer. All advanced autosurf exchanges except Enhance-
Views Autowatcher offer sending a custom referer for the
view requests at an additional cost (see Table 1 for details).
HitLeap and eBesucher also charge for hiding the default
referer which indicates the views come from the trafﬁc ex-
change. Jingling by default does not send a referer. Ob-
viously a user-agent or referer ﬁeld that indicates the click

comes from a trafﬁc exchange would allow a website to eas-
ily ﬁlter the autosurf trafﬁc.

• Geo-Targeting: Geo-targeting refers to advertising the page
for viewing to exchange members residing in a speciﬁc loca-
tion. eBesucher and EasyHits4U offer geo-targeting at the
country-level as well as at a coarser granularity of conti-
nents. Jingling offers geo-targeting at a coarse granularity
of China and Non-China, and city-level granularity within
China. Others do not offer any geo-targeting.
4.3 Buying views from the exchange

The exchanges also sell trafﬁc views directly, i.e., one can get
trafﬁc by paying, instead of by earning exchange credits via surf-
ing/running their autosurf tool. The price per 100K views with
a view-length of 15s ranges between $2–60 for the generic au-
tosurf exchanges. Views on manual and social media promo-
tion exchanges cost more; 100K views cost $450 on EasyHits4U,
and $1,000 on HitSafari. Similarly, the cost for 100K 15s-long
YouTube views on EnhanceViews Autowatcher is $375. (The ex-
changes sell views in bulk, with discounts for packages with higher
views).

5. POPULAR TARGETS IN THE EX-

CHANGES

In order to develop insight into the popular domains in these ex-
changes, we captured a snapshot of the websites in circulation in
the exchanges. We did so by milking: retrieving the instructions
from the exchanges on the URLs to view, but not performing the
action. In this section, we discuss our milking infrastructure, the

4Exchange

EasyHits4U
HitSafari
247AutoHits
10Khits
HitLeap
Jingling
eBesucher
Otohits
EnhanceViews
Autowatcher

Time Milkers
Span
3 d
3 d
30 d
30 d
30 d
30 d
30 d
30 d

-
-
25
25
50
25
25
50

Requested Page Impressions
Unique
Unique
Total
URLs Domains
125
210
121
152
141
210
3,632
2,195
0.7 M
3,436
7,209
0.2 M
28,734
5.5 M
98,243
104 M 337,829
61,727
1,431
7,323
0.6 M
5.2 M
2,708
1,409

7 d

5

8.5 K

2,772

1

Table 2: Dataset obtained by milking the autosurf trafﬁc exchanges,
i.e., collecting the lists of URLs to be clicked but not sending
clicks. We collected the data for manual exchanges manually, solv-
ing CAPTCHAs.

datasets we collected, and analysis on the popular categories of
monetization observed in these exchanges.
5.1 Dataset

In all the autosurf exchanges we study, the communication with
the exchange is unencrypted, enabling us to easily write our own
milker bots that replicate this communication and receive instruc-
tions from the exchange. The instructions contain the URL(s) to
be viewed, visit-length, and the referer to use in the view request
(if offered by the exchange). We ran these milker bots from 25–50
different IP addresses per exchange via a proxy.

Using the above infrastructure, we collected month-long datasets
for all autosurf exchanges, except for EnhanceViews Autowatcher.
Since the latter only offers visits to a pre-deﬁned list of social
networks/user-content websites, we do not carry out the domains
analysis for this exchange.
Instead, we collected a week-long
dataset for EnhanceViews Autowatcher’s YouTube Watcher tool to
compare the characteristics of video URLs in this exchange with
those in the other generic exchanges we study. For the manual ex-
changes, which require a CAPTCHA to be solved between consec-
utive page views, we collected smaller datasets by manually surﬁng
on the exchanges.

Table 2 describes the datasets we collected. For the manual
exchanges, EasyHits4U and HitSafari, we solved 70 CAPTCHAs
each. Each click resulted in the display of the main target page, as
well as one display and one text ad. We also manually clicked on
the display and text ads (see below), resulting in a total of 210 web
page visits on each of the two exchanges. For autosurf exchanges,
our milker bots recorded between 8.5K–104M page impression re-
quests per exchange. The average rate of requests and the median
view length varies across the exchanges, resulting in a difference in
the scale of datasets.

We processed the raw URLs dataset to expand any URLs in the
following set of popular URL shortening services: {bit.ly, goo.gl,
ow.ly, t.co}.1 We further processed the URLs to extract the “reg-
istered domains”, according to the public sufﬁx list maintained by
Mozilla [18]. The numbers listed in Table 2 are for the processed
dataset. It contains 2.7–337K unique URLs, and 1.4–61K unique

1We compiled this list based on their high frequency in our dataset,
and unshortened the URLs belonging to them because the short-
ened versions hide the intended destination. We also observed
URLs shortened using paid shortening services in our dataset, but
did not unshorten them since they present an interesting monetiza-
tion avenue, as we sketch later in § 5.3.1.

Category
Web trafﬁc
Afﬁliates and marketing
Other products and services

EasyHits4U HitSafari
30%
48%
22%

38%
35%
27%

Table 3: Distribution of website and ad categories we observed on
EasyHits4U and HitSafari.

domains per exchange. For the rest of the analysis, we work at the
granularity of registered domains.

Ethical Considerations: We were cautious to not participate
in view/click fraud when collecting our datasets. For the manual
exchanges, we collected small-scale datasets by hand. We observed
no indication of ad fraud.
In addition, since during the process
we ourselves viewed the websites circulating in the exchanges—
as expected by the exchange and a website owner/advertiser—we
view our actions as not contributing to view fraud.

For autosurf exchanges, we only collected the associated URLs,
and did not view them in an automated fashion. Our milker bots
emulated the timing patterns of requests from the autosurf tools—
except for Jingling, for which we could request URLs at a rate ﬁve
times greater than what a Jingling bot would do. (For other ex-
changes, requesting at a higher rate did not return any new URLs).
We did so after determining, as best as we could from inspect-
ing Jingling’s website, that doing so did not violate any terms-of-
service.

We note that none of our actions underlied intent to fraudulently
earn credits, as prohibited by some of the exchanges in their terms-
of-service, though such crediting did occasionally occur as a by-
product of milking. The exchanges varied in their detection of
milking: HitLeap imposed a penalty on our account after about an
hour of milking. They continued to provide us with URLs to view,
but we did not earn any credits for those URLs (as in fact, we were
not viewing them). eBesucher temporarily blocked our accounts.
Milking Jingling did not require accounts, hence we did not earn
any credits. Others showed no indications of detection.
5.2 Analysis: Manual Exchanges

For manual exchanges, our datasets are small enough that cate-
gorizing them manually was viable. Table 3 summarizes the results.
The ﬁrst category, web trafﬁc, comprises trafﬁc-related websites.
This included other manual exchanges as well as sellers of web
trafﬁc and offers of cash for manual clicks (paid-to-promote sites).
The second category, afﬁliates and marketing, comprises web-
sites that target persons attempting to earn money by selling over
the Internet. Many ads offered commissions to afﬁliates for sale of
various products and services. Some websites offered tools and in-
frastructure for afﬁliates such as email advertising. Others offered
classes and manuals on how to become a successful Internet mar-
keter. For example, one site offered a system for earning $10,000
per month as a Clickbank afﬁliate for a fee of $37 per month [6].

The large majority of the websites in these two categories ap-
peared to be directly targeted at users of manual trafﬁc exchanges,
offering the prospect of cash in exchange for small fees or various
types of simple online tasks. Websites of this type made up about
three quarters of the total on both exchanges.

The third category, other products and services, contains ads for
products and services outside the afﬁliate marketing and web trafﬁc
ecosystem itself. These ranged from web hosting services to legit-
imate niche products, such as self-published children’s ebooks or
special chocolate bars, to miracle weight loss programs and supple-
ments, to formulas for large proﬁts in currency and options trading,

5Exchange

247AutoHits

10Khits

Jingling

HitLeap

eBesucher

Otohits

Top domains by views
twistrix.com (10%)
hitlink.com (6 %)
paragonmailer.com (4%)
paragontrafﬁc.com (4%)
vitality.ws (4%)
kpopselca.com (10%)
reportershub.com (2%)
ebay.co.uk (2%)
hitleap.com (2%)
apkmodder.com (1%)
adf.ly (6%)
saringan.net (5%)
wonosobo.in (4%)
trifter.com (2%)
gameolosophy.com (2%)
youtube.com (8%)
ziddu.com (4%)
ads-host-media.com (2%)
ijgbiorjg.com (2%)
4554fdd56f4.com (2%)
mustbuysneakers.com (13%)
planetfem.com (10%)
admg.info (6%)
genevaforever.com (6%)
feltdizzy.com (4%)
health-spiritual.net (13%)
healthspiritual.net (13%)
zenbux.co (10%)
planete-carpe.com (4%)
menintown.net (4%)

Top domains by URLs
trck.me (1%)
trafﬁcadbar.com (1%)
wordpress.com (1%)
weebly.com (1%)
adf.ly (1%)
apkmodder.com (3%)
ziddu.com (2%)
youtube.com (2%)
ebay.co.uk (2%)
seoad.in (1%)
adf.ly (10%)
taobao.com (10%)
baidu.com (8%)
ziddu.com (5%)
user.qzone.qq.com (3%)
ziddu.com (20%)
youtube.com (11%)
adfoc.us (1%)
adf.ly (1%)
sh.st (1%)
admg.info (3%)
dhush.com (3%)
trends-beauty.de (3%)
softskills24.eu (2%)
job-market24.com (2%)
nomeimporta.es (1%)
herreiroimoveis.com.br (1%)
tripleclicks.com (1%)
weebly.com (1%)
my-style.in (1%)

Table 4: Popular domains of the milked URLs in the autosurf trafﬁc
exchanges. Bold domains represent direct monetization avenues:
the service offers pay-per-view for user content/sharing links. Italic
domains are trafﬁc exchanges; members promote exchanges in or-
der to earn activity points, as top 25 active members get a share in
the monthly cash pot (worth ≈ $10). Domains colored light-green
are backed by a blogging service triond that pays users for views
to their blog posts. Domains colored red do not have any real con-
tent and participate in ad placement fraud via referer spooﬁng on
the AppNexus ad exchange.

to a manual on how to fuel cars with water. This category makes
up about one quarter of the URLs on each exchange.

The target web sites were mostly free of external ads. We did not

observe any indication of ad fraud.
5.3 Analysis: Autosurf Exchanges

For autosurf exchanges, we focus our analysis on the popular
domains by views and URLs, since our datasets for this category
are extensive. A domain can receive a high number of views from
the exchange under three scenarios: (i) popular Internet service do-
mains having a large user base (for example, YouTube), (ii) do-
mains belonging to exchange participants, who are able to earn a
large number of exchange credits using a number of machines, and
in return direct huge volume of trafﬁc to their own domains, or (iii)
someone buying bulk views to a domain from the exchange. We
can identify the ﬁrst of these, but it is hard to differentiate between
the latter two, and we treat these as equally interesting as potential
targets for monetization/SEO/Alexa rank increase.

We characterize the top ﬁve domains by views and URL counts
for each exchange in Table 4. We observe four categories of popu-
lar domains: (i) direct monetization avenues, (ii) ad fraud domains,
(iii) legitimate looking domains, and (iv) trafﬁc exchanges.

5.3.1 Direct Monetization Avenues
This category comprises domains that pay users for views to con-
tent they upload, such as YouTube. YouTube inserts video adver-

tisements when playing user videos, and pays the user in proportion
to the legitimate views their videos receive. In recent years, another
category of services has emerged that does not require users to pro-
vide their own content in order to earn. Rather, users can get paid
for linking and sharing existing content on the Internet. For exam-
ple, URL shortening services such as adf.ly pay users for visits
to their shortened URLs. A visitor to a URL shortened using such
a service is ﬁrst shown an advertisement, and then redirected to the
URL that was shortened. Hence, money enters the eco-system from
advertisers and ﬂows to the users of the URL shortening services.
We next discuss examples of both these monetization avenues as
observed in the exchanges we studied.

The URL shortening services adf.ly, adfoc.us, and
sh.st are among the top ﬁve domains in HitLeap, Jingling and
247AutoHits. Manually inspecting several requested adf.ly
URLs reveals that 90% of the time the intermediate link solicits
downloading a video player. It is possible that in addition to le-
gitimate advertising, some of the malicious advertisers attempt to
install malware on user machines. Our observation of malicious
advertisements is consistent with the ﬁndings of Nikiforakis et al.,
who investigated malicious aspects of paid URL shortening ser-
vices [32].

Another domain in this category popular on HitLeap, Jingling,
and 10Khits is ziddu.com, a content distribution platform that
pays for ﬁle downloads and sharing news links hosted on its plat-
form [22]. Users with their own content can upload their ﬁles and
earn for downloads of those ﬁles. An alternative (and lower ef-
fort) way to earn is to share existing content on Ziddu and direct
views to it. Manually analyzing some of the ziddu.com URLs
in our dataset, we observed that they contain news content lifted
from other news websites under the title “Sponsored news”, and
generate impression requests to multiple ad networks. Further in-
specting Ziddu’s website, we found that it also offers desktop and
mobile apps to “turn idle cycles into money”. The app displays
advertisements (rather than websites) automatically, indicating that
Ziddu apparently defrauds advertisers. In a manual investigation,
we found the majority of the advertisements to be malicious, re-
questing to upgrade a media player or download a software. Ziddu
does not list pay rates on its website.

We observe another model for the domains trifter.com and
gameolosophy.com, popular in Jingling. These are niche sites
dedicated to travel and online games respectively. The content
hosted on these websites is not generated by the website owners.
Instead, these websites are backed by triond.com, a blogging
service, which automatically shares the content submitted by its
bloggers to the most relevant site out of the pool of sites it sup-
ports. Triond then pays the blogger for views to their content.

YouTube receives the highest percentage of view requests (8%)
in HitLeap, and has the second-highest percentage of URLs in this
exchange. Note that YouTube video watch URLs2 play videos au-
tomatically upon opening the link in a browser or an autosurf tool.
Hence, directing exchange trafﬁc to YouTube videos results in the
videos being auto-watched. We investigated whether sending ex-
change trafﬁc from HitLeap to YouTube videos results in increas-
ing video view counts, and consequently provides a monetization
avenue. We extracted the list of YouTube videos from our dataset
(≈ 10K unique videos) and queried the YouTube API to get their
view counts. Per Figure 1, approximately 24% of the videos in
circulation on the HitLeap exchange were no longer available on
YouTube at the time of querying; they were either taken down by
YouTube or the user themselves. 25% had a view count frozen at

2These URLs have the form: http://www.youtube.com/watch?v=VIDEOID.

6Exchange
HitLeap
Jingling
eBesucher
Otohits
247AutoHits
10Khits

URLs
2,606 (2.7%)
2,571 (0.8%)
230 (3.1%)
50 (1.9%)
27 (0.7%)
28 (0.4%)

Impressions
1,231,027 (23%)
10,426,448 (11%)
59,410 (9%)
336,634 (6%)
5,398 (1%)
494 (0.2%)

Table 5: Percentage of milked URLs and corresponding impres-
sions served by sites exhibiting referrer-spooﬁng ad placement
fraud in various exchanges.

Media exchange in their study of fraudulent activities in online ad
exchanges. The convoluted online advertising ecosystem fosters
this kind of fraud. In particular, the exchange/advertisers take the
referrer in the URL parameters at face value. Although the impres-
sion requests to an ad exchange contain an id value that determines
which party gets credited when an ad is displayed on the site in the
referrer ﬁeld, the need for reaching broad audiences in online ad-
vertising complicates its use for fraud detection. Since impressions
can be bought through an intermediary (rather than directly from
publishers) to enable wider reach, an ad exchange cannot employ
an exclusive website-owner-speciﬁc id to be credited on impres-
sion requests for the particular website [25].

Given that we observed referrer spooﬁng fraud as one of the ma-
jor categories in multiple exchanges, we ﬁngerprinted this behavior
in order to classify the number of URLs in our dataset that partici-
pate in this fraud. We crawled the entire datasets using a distributed
infrastructure, recording all the web requests that each URL gen-
erates.4 We then identiﬁed the URLs that generate requests to
adnxs.com with spoofed referrers. We identiﬁed spoofed refer-
rers as those that are for a domain other than on which the ad is ac-
tually displayed. Table 5 summarizes our ﬁndings. We ﬁnd ≈ 2.5K
URLs in HitLeap and Jingling that participate in this ad fraud, re-
spectively accounting for 23% and 11% of the total impression re-
quests we milked for these exchanges. Other exchanges have fewer
URLs, accounting for 1–9% of their impression requests.

The

most

in

5.3.3 Legitimate looking domains
We ﬁnd some of the other websites harder to judge. While essen-
tially all of them bear advertisements, some of these appear to be
niche websites targeted at topics such as cars, sneakers, workout,
and news speciﬁc to a particular location.
domain

eBesucher,
mustbuysneakers.com, is a legitimate-looking niche website,
with an ‘Advertising: Starboyant Media’ tag in the website footer.
Investigating the Starboyant Media website, we found that it offers
advertising on three other niche websites: onlyhiphop.com,
workouteveryday.com, and stylishceleb.com. We
ﬁnd all of these in our eBesucher dataset, accounting for 22% of
the total impression requests we milked on eBesucher.

popular

We ﬁnd ourselves unable to judge whether these and other
legitimate-looking domains are websites with considerable legiti-
mate trafﬁc to which a fraudster also directs trafﬁc, or they have
been crafted to make judgment difﬁcult and have little trafﬁc be-
yond that automatically generated.

5.3.4 Trafﬁc Exchanges
Surprisingly, most of the top domains in the basic autosurf ex-
change 247AutoHits are other trafﬁc exchanges. On closer inspec-

4We opened each website in a browser instance until the browser
indicated that the page had ﬁnished loading.

Figure 1: Distribution of view counts of the YouTube video URLs
obtained by milking trafﬁc exchanges. We obtained the view counts
of the videos by querying the YouTube API provided by Google.
The size of the discontinuity at 301 views indicates the fraction of
videos stuck at that view count. Note that about 25% of HitLeap
but only 10% of EnhanceViews Autowatcher videos are stuck there.
The discontinuity at 301 views suggests that YouTube’s fraud de-
tection prevents many videos from advancing beyond this point,
even if they receive many more clicks.

301 (indicating that YouTube had identiﬁed something suspicious
with the views [13]). However, ≈ 42% of the videos on HitLeap
had view counts above 301, with a maximum of 18 million views.
Recall from Table 1 that HitLeap views are short-lived (60s at
maximum), which possibly could be a factor in the detection of
its fraudulent trafﬁc. For comparison, we look at the view counts
of YouTube videos in the EnhanceViews Autowatcher exchange,
which plays the full video for each view. We observe in Figure 1
that EnhanceViews Autowatcher does better than HitLeap, with a
frozen view count for only 10% of the videos.

We also queried the YouTube API to get the channel ID and the
categories of the videos in our HitLeap dataset. The 10K videos
were associated with ≈ 2,500 channels—8% of the videos came
from a single channel. The videos in this dominant channel be-
longed to the categories Gaming, Shows, and Film/Animation, with
none of the videos stuck at a view count of 301. Inspecting this
channel, we found that the latest video gathered 25K views in one
day, though we lack visibility into what fraction of these were
fraudulently generated. Generally, we ﬁnd that 26% of the videos
in our dataset belong to the Gaming category and 23% in the cat-
egory People and Blogs, with the former mainly screen-captures
of people playing video games, and the latter primarily comprising
tutorials.

5.3.2 Ad Placement Fraud
We also observed websites that show clear evidence of impres-
sion/click fraud. For example, ads-host-media.com, ijgbiorjg.com,
and 4554fdd56f4.com in HitLeap do not display any content
to a visiting user.3 But these sites generate dozens of ad re-
quests with varying referrers to the AppNexus ad exchange [4].
The URL requests are of the format: ib.adnxs.com/tt?ttjb=
1&bdc=1&bdh=CQLrezBk2vGyQNA7G5993lyZhww.&id=3445029&size=
300x250&referrer=carpreserve.com, with varying referrers sent
on each request.

Others have documented this referrer spooﬁng fraud [35, 25].
Stone-Gross et al. observed it in the context of the Yahoo Right-

3We conﬁrmed that we had not been cloaked against by visiting
these domains in the autosurf tool in addition to the browser; we
conﬁgured a proxy to allow the autosurf tool to visit these domains
for a short amount of time.

1100100000.00.40.8Number of Youtube viewsECDFllHitLeapEnhanceViews7tion, we ﬁnd that these are splash pages provided to the users by
an exchange itself for circulation in other exchanges. The four ex-
changes that appear in the top domains—twistrix.com, hitlink.com,
paragonmailer.com, and paragontrafﬁc.com—were not included in
our study. Looking through their websites, we ﬁnd that these ex-
changes offer a share in a cash pot (worth ≈ $10) at the end of
every month to the top 25 active users. Submitting the member-
speciﬁc exchange promotion link on other exchanges is one of the
ways in which members can earn activity points towards a share in
the cash pot.

6. TRAFFIC QUALITY & SIZE OF EX-

CHANGE NETWORKS

In this section we study the quality of trafﬁc that the exchange
networks deliver, and measure the scale and characteristics of the
IP address population that participates in these exchanges. We base
our observations on buying bulk views from the exchanges for ﬁve
consecutive days and recording the characteristics of the visitors.

Infrastructure: We set up eight websites, one per exchange,
on Amazon EC2, conﬁgured to auto-scale in order to handle large
peaks of trafﬁc. The websites themselves were fairly simplis-
tic, and identical in content, appearing to be a photo blog. We
employed Javascript instrumentation on the websites to detect (i)
mouse movement, and (ii) whether at the time of visit the visitor
was logged into any of Google, Twitter, or Facebook.5 While not
perfect, this instrumentation gives us a sense of organic (real) users
participating in these exchanges. Where possible, we requested
views for a view-length of 30s or greater, in order to allow enough
time for the instrumentation Javascript to execute. We also set
cookies to study the behavior of returning visitors.

We signed up for two premium accounts on each exchange, and
purchased views from the exchanges alternating between the ac-
counts every other day. Premium accounts gave us access to more
website slots on the exchanges, enabling us to submit multiple
pages of our websites in order to get bulk trafﬁc. Making purchases
from two accounts arguably enables us to collect independent sam-
ples of the IP addresses in an exchange.

Purchases: Table 6 lists the breakdown of trafﬁc we bought
from each exchange. For each exchange, we started with a pilot
measurement of 100K visitors per day for autosurf and 10K visi-
tors per day for manual exchanges,6 and scaled down the number of
visitors in subsequent purchases, requesting at least twice as many
visitors as the number of unique IP addresses observed in the pilot
measurement.

Purchase Order Completion: For each purchase, we requested
visitors distributed across multiple pages of our corresponding
website (at a maximum rate of 250 visitors per hour per page),7
so that the expected completion time for the purchase order was
one day. The exchanges varied in the completion of purchase or-
der. HitSafari, 247AutoHits, and 10Khits on average fulﬁlled only
50/63/68% of the order, and charged us only for what they were
able to fulﬁll. Our measurements indicate that these three are the
smallest of the eight exchanges we measured (on the order of a
thousand IP addresses), explaining the inability to fulﬁll larger or-

5We used the methodology described at http://www.tomanthony.co.uk/
blog/detect-visitor-social-networks/.
6We made smaller purchases from manual exchanges due to higher
cost of manual trafﬁc.
7The exchanges set upper bounds on the number of visits per URL
per hour, e.g., 500 for HitLeap and 1,000 for eBesucher. We re-
quested a limit lower than the upper bound based on a pilot run that
found the upper bound did not get delivered in a timely fashion.

Exchange

/ IP Addresses

eBesucher
(33,749)

Jingling
(110,641)

HitLeap
(72,135)
Otohits
(3,931)

Popular ASNs

Google, US (15%)
Hetzner Online AG, DE (5%)
Scana, UA (5%)
CHINANET-BACKBONE No.31, CN (26%)
Amazon, US (12%)
China169 Backbone, CN (10%)
Google, US (7%)
HINET, TW (7%)
Amazon, US (35%)
Google, US (19%)
OVH SAS, FR (10%)
Amazon, US (26%)
Google, US (24%)

Table 7: ASNs having at least 5% representation in the exchanges.
We highlight major cloud hosting providers in bold. A signiﬁcant
percentage of the IP addresses in the advanced autosurf exchanges
comes from Google and Amazon.

ders within a day. Others claimed to fulﬁll the complete orders, but
had some losses—the instrumentation reported by the exchange did
not match that recorded by our web server logs. Speciﬁcally, Jin-
gling fulﬁlled only 61% of the order on average; others had a loss
in the range 2–12%.
6.1 Quality of delivered views

The views were delivered from a variety of User-Agents by de-
fault, on the order of several hundred for most of the exchanges.
Most notably, Jingling delivered trafﬁc from ≈ 33K different
user-agents (dominated by different versions of Internet Explorer).
Since we did not request a custom Referer, the Referer we
received was the link of the trafﬁc exchange for all the exchanges
except Jingling, for which it was not present.

The page components (stylesheet, Javascript) hosted on the same
domain were fetched for 92–100% of IP addresses of the differ-
ent exchanges. An image embedded from a different domain was
fetched for 86–100% of IP addresses for all exchanges except Jin-
gling, for which only 1% of the IP addresses fetched the image.

We found that Javascript was executed for 83–97% of the IP ad-
dresses on six of the exchanges. On Jingling, the number is much
lower (37%)—this could be due to high load on the machines that
run Jingling, because it initiates multiple threads and views multi-
ple websites in parallel. For 10Khits, the Javascript instrumentation
ﬁred for only 20% of the IP addresses. Further, upon investigation,
our web logs indicated that for the IP addresses where it did ﬁre,
the POST request paths were malformed, hence no data was logged
in our database for the mouse movement and social-network login
instrumentation. This is presumably because at the time of our data
collection, the 10Khits website indicated it was in a transitional
phase, soon to launch their own autosurf tool. Perhaps the hits to
our websites were delivered by a buggy version of the tool.
6.2 Characterization of View Sources/IP ad-

dresses

Over the ﬁve days, we received visits to our websites from
≈ 204K unique IP addresses across the eight exchanges, corre-
sponding to ≈ 93K unique /24 network preﬁxes. 77–95% of the
/24 preﬁxes have only one IP address, suggesting that a signiﬁcant
fraction of these IP addresses belong to individual machines (or
NATs), with little IP aliasing.
6.2.1 Manual Exchanges
We recorded 1K IP addresses on HitSafari from 73 countries, and
6K on EasyHits4U from 128 countries. Of these, 40% on HitSafari

8Exchange Size & Characteristics Of IP Addresses (Measured over ﬁve days)

Javascript
Executed

Social

Mouse
Network Movement

Exchange

HitSafari
EasyHits4U

10Khits

247AutoHits

Otohits

eBesucher
HitLeap
Jingling

Purchase Order (Per Day)

Views

Cost

Duration

CPM

Avg.
Order
Fulﬁlled

IP

Addresses

User
Agents

2.5K
10K
10K
10K
50K
100K
100K
100K

$25
$75
$10
$7
$3
$17
$44
$41

6s
30s
30s
30s
30s
30s
30s
40s

$10
$7.5
$1
$0.7
$0.06
$0.17
$0.44
$0.41

50%
98%
68%
63%
98%
88%
97%
61%

1,018
6,191
1,578
1,420
3,931
33,749
72,135
110,641

179
699
260
219
336
1,752
871
33,222

Page Component Fetches
Other
Domain
86%
96%
95%
85%
97%
95%
100%
1%

Same
Domain
92%
99%
99%
95%
100%
96%
100%
99%

84%
96%
20%
83%
97%
95%
97%
37%

Logins
40%
65%
–
43%
13%
12%
–
0.1%

10%
21%
–
6%
4%
3%
0.1%
–

Table 6: Our purchases from various exchanges to study the quality of trafﬁc. We purchased trafﬁc in varying quantities, and recorded the
HTTP requests, page rendering, and organic-visitor instrumentation over ﬁve days.

and 65% on EasyHits4U had an account logged into a social net-
work, indicating that a signiﬁcant fraction of views came from real
users (or compromised machines). Our instrumentation recorded
mouse movements for 10% and 21% of IP addresses on HitSafari
and EasyHits4U respectively. The low percentage is presumably
because the users do the bare minimum required to get paid.

Finding these organic visitor indicators, we next investigate
whether this trafﬁc comes from real users in low-wage countries
who click intentionally in the hope of earning money. We looked at
the top ASNs, and ﬁnd that the trafﬁc mostly comes from residen-
tial networks, with no single dominant contributor. Surprisingly,
geo-location (using the MaxMind database) indicates that 52% of
the IP addresses in EasyHits4U come from Europe, with Asia the
second major contributor (25%). The IP addresses from Europe
are dominated by Russia, Romania, and Ukraine with each hav-
ing 5–6% representation. IP addresses from Asia are dominated
by India and Indonesia. In HitSafari, North America has a 40%
contribution, followed by Europe (31%), and Asia (22%). We ﬁnd
that the country distribution in HitSafari differs from that in Easy-
Hits4U, with UK and Germany having the top representation (but
only 4–5% each) in Europe, and China and Singapore dominating
IP addresses from Asia.

In light of this geographic diversity and the signiﬁcant contribu-
tions from North America and Western Europe, click farms in low-
wage countries do not appear to be the principal source of clicks on
manual exchanges.

6.2.2 Autosurf Exchanges
Our measurements ﬁnd that

the basic autosurf exchanges,
247AutoHits and 10Khits, are small in size, on the order of 1.5K IP
addresses each. However, in the advanced autosurf category Oto-
hits has ≈ 4K IP addresses, while the other three are an order of
magnitude larger.

Geolocation: We received hits from 80–147 different countries
across the various autosurf exchanges. The spread over countries
for the smaller networks differed from that of the larger ones:
eBesucher is highly concentrated (80%) in Europe, with Russia,
Ukraine and Germany predominant. Jingling has the highest rep-
resentation in Asia (70%), with China contributing 56% of the IP
addresses. The second major contributor in both eBesucher and Jin-
gling is North America, with 15% and 28% representation respec-
tively. HitLeap’s network is predominantly based in North America
(63%), with 60% of IP addresses from the US. 20% of HitLeap’s
IP address space is based in Europe, with Italy and Germany the
top contributors (but only 4–5% IP addresses each). Similar to
HitLeap, Otohits has representation in North America (47%) and
Europe (26%), with the US predominant (45%), and Taiwan, Viet-
nam and Germany each at 5%.

For the smaller networks, 247AutoHits and 10Khits, Asia and
Europe have 74% representation. The country distribution is dis-
persed, with Vietnam, Indonesia, India, Germany, and the UK as
the popular countries (4–8% representation).

Organic Visitors: The trafﬁc recorded from 247AutoHits had
the highest percentage of visitors from machines where a user was
logged in to a social network (43%), but only 6% indicated a mouse
movement. For the advanced autosurf exchanges, it is possible that
the user uses a browser different than that used by the autosurf tool.
Hence we treat the estimates we discuss below as a lower bound.
We ﬁnd that on average ≈ 12% of the visitors from eBesucher, and
≈ 13% on Otohits, were from machines where a user was logged in
to a social network.8 In contrast, the number is much lower for Jin-
gling; only 0.1% of the visitors appear organic. We recorded mouse
movement for only 1–4% of IP addresses on these exchanges.

We could not carry out this analysis for HitLeap and 10Khits,
because (i) HitLeap’s autosurf tool uses a built-in browser rather
than a browser on the user’s machine, and thus none of the visitors
appeared to have logged in, when in fact they might have been, and
(ii) as described in Section 6.1, the 10Khits surf tool had malformed
URL request paths, due to which we did not log any data in our
database.

Popular ASNs: We next take a look at the popular enti-
ties/organizations to which the IP addresses of exchange networks
belong. We obtain the ASNs of the IP addresses via Team Cymru’s
IP-to-ASN mappings database [36]. Table 7 lists the popular ASNs
(those having at least a 5% representation), and the corresponding
percentage of IP addresses observed for each exchange. We ﬁnd
that a striking percentage of the IP addresses in the HitLeap and Jin-
gling exchanges belong to Amazon, totaling ≈ 38K IP addresses.
Similarly, a signiﬁcant portion of IP addresses in the autosurf ex-
changes comes from Google’s cloud, totaling ≈ 27K IP addresses.
We also observe other smaller cloud providers and Internet host-
ing/data centers in the top ﬁve ASNs. For example, the second-
highest contribution in eBesucher’s network comes from Hetzner
Online (5%), an Internet hosting provider and data center operator
based in Germany. Similarly, HitLeap addresses also appear from
other smaller cloud providers such as Limestone Networks [17] and
OVH [21].

6.2.3 Overlap across exchanges
We ﬁnd very little overlap across the IP address space of the man-
ual and autosurf exchanges. However, within these categories, we
observe signiﬁcant overlaps. 17% of HitSafari’s IP address space

8Conceivably, there is a small chance that there is a fraudster run-
ning social media promotion tools in parallel; we do not have a
method for verifying whether the user on a machine is genuine.

9Exchange
HitSafari
EasyHits4U
10Khits
247AutoHits
Otohits
eBesucher
HitLeap
Jingling

% Overlap with
other exchanges

Top overlap contributors
(≥ 5% contribution)

17% EasyHits4U
9% –
43% HitLeap, 247AutoHits, eBesucher
43% HitLeap, 10Khits, eBesucher
74% HitLeap, Jingling
8% HitLeap
31% Jingling
18% HitLeap

Table 8: Overlap of IP address space across various exchanges.

overlaps with that of EasyHits4U. 43–74% of the address space of
smaller autosurf networks is also seen in other exchanges. For the
larger networks, 31% of HitLeap’s space overlaps with that of Jin-
gling.
6.3 Impressions Per Day Estimates

In this section we develop a handle on the number of impressions
these exchanges serve per day. We base our estimates on the daily
number of IP addresses recorded in our logs. However, we note
that two factors can lead to overestimating/underestimating these
numbers: (i) IP address aliasing (the same machine switching IP
addresses), and (ii) multiple machines behind NATs.

We analyzed cookie data recorded in our web logs to potentially
adjust for these two factors. For multiple visits from the same IP
address, we ﬁnd that 85–95% of IP addresses in manual exchanges,
80–85% in basic autosurf, and 20–45% in advanced autosurf re-
turned the same cookie set on the ﬁrst visit. Others request and
return multiple cookies. Investigating this further, we ﬁnd that a
high fraction of the IP addresses in advanced autosurf exchanges
clear cookies after every visit.

Due to the limitation of the cookie data, we report our population
estimates at the granularity of IP addresses. We use these popula-
tion sizes to estimate the total number of impressions the exchanges
serve per day. To this end, we compute the average number of im-
pression requests that our milker bots received on average per day,9
and multiply it by the population size of the exchange. Table 9 lists
the impressions per day estimates. On the lower end, we estimate
that 10Khits serves 173K impressions per day, and on the higher
end Jingling serves on the order of 789 M impressions per day.

7. DISCUSSION

In the previous sections we measured a number of facets of trafﬁc
exchanges. In this section, we attempt to draw plausible inferences
based on what we observed.
7.1 Selection pressure

We ﬁnd evidence of trafﬁc fraud responding to selection pres-
sure. The very existence of exchanges, a tool to disperse the orig-
inating IP addresses of trafﬁc, indicates that advertisers actively
look for fraud; clearly, clicking endlessly from a single IP address
seldom achieves the desired result. The differences between the
free and premium versions of the advanced autosurf tools (shown
in Table 1) largely reﬂect the ability to target certain geographic
locations, and to set custom User-Agent and Referer ﬁelds. There
would be little reason for exchange participants to pay for this func-
tionality if it did not bring meaningful advantage. It seems likely

9Since we milked Jingling at a higher rate, we use the number ob-
tained from running the original bot through the Fiddler proxy, con-
ﬁgured to only allow communication with the exchange.

Exchange

IP addresses

HitSafari
EasyHits4U
10Khits
247AutoHits
Otohits
eBesucher
HitLeap
Jingling

329
1,786
483
507
2,178
18,164
41,711
40,227

(σ=94)
(σ=414)
(σ=109)
(σ=376)
(σ=378)
(σ=707)
(σ=507)
(σ=5,200)

Impressions
per bot
–
–
359
1,420
3,654
1,066
3,607
19,630

Estimated total
impressions
–
–
173 K
719 K
7.9 M
19 M
150 M
789 M

Table 9: Impression estimates per day. σ represents standard devi-
ation across ﬁve days of measurements.

that these ﬁelds are used by sites to detect fraudulent trafﬁc, and
the ability to vary them will increase proﬁts. The large fraction of
YouTube videos stuck at 301 credited views in Figure 1 strongly
suggests a fraud-detection barrier that blocks a large fraction of the
YouTube-bound trafﬁc from two autosurf networks.
7.2 Manual vs. Autosurf exchanges

A common property of the exchanges is that they facilitate dis-
persion of trafﬁc; indeed the need for dispersion is likely the factor
that has led to their popularity. Beyond this common point, we
found little similarity between the manual and autosurf exchanges.
Table 4 shows that the most popular destinations for trafﬁc from
the autosurf exchanges have ad-bearing properties, and ad-fraud of
some kind dominates their trafﬁc. By contrast, Table 3 shows that
trafﬁc from the manual exchanges is predominantly directed at sites
that advertise afﬁliate programs, other manual trafﬁc exchanges, or
pages advertising goods sold by the participants themselves.
In
other words, pages visited in the manual exchanges appear directed
at luring humans (the exchange participants) to upgrade, join other
exchanges or afﬁliate programs, or purchase products that do not
have mainstream appeal. Our inspection of manual exchange traf-
ﬁc turned up numerous examples of what appear to be implausi-
ble propositions and get-rich-quick schemes. For example, one
site asks $9.99 for a pamphlet explaining how to “run your car on
water.” A number of destinations of the manual exchange trafﬁc
appear to be Ponzi or multi-level marketing schemes. For exam-
ple, at http://imarketingfasttrack.com/ new entrants invest $25 and recruit
four newcomers who do similarly; while participants are promised
an easy $1,700, there is no mention of any product beyond par-
ticipant recruitment. Another, http://www.theleadmagnet.com/, is a viral
email lead-generation tool that offers commissions if members get
others to purchase the tool.
7.3 Monetization

Monetization clearly poses a signiﬁcant problem even if one can
generate volumes of well-dispersed trafﬁc. The direct cash-out pay-
ments offered by the exchanges are low: $0.30 per thousand man-
ual clicks for EasyHits4U, and $0.02 per thousand automated clicks
at eBesucher (though getting paid requires a photo ID, as noted in
Section 4.1). Note that, based on Table 9, this amounts to 2 cents
per machine per day, or $7.30 per machine per year.

For fraudsters, exploiting sites such as YouTube, which offer to
pay for trafﬁc delivered, represents an appealing approach. This
has the beneﬁt of low start-up costs: the fraudster simply sets up a
channel with some content to which they direct the trafﬁc, avoiding
costs associated with registering a domain and hosting. Moreover,
the content does not have to be of a quality sufﬁcient to attract
actual human viewers. If the fraud is discovered and the channel
blocked, one can simply start over by setting up a new channel.

10Figure 1 suggests that services such as YouTube successfully de-
tect a good percentage of inorganic trafﬁc, making it hard to lin-
early translate automatically generated views to money. Perhaps
participants direct trafﬁc to YouTube primarily for increasing view
counts to gain popularity, rather than monetization.
7.4 Lack of sophistication

Some of our data supports the view that many trafﬁc exchange
participants lack technical sophistication and struggle to monetize
their efforts, particularly on the manual exchanges. At ﬁrst sight,
the manual exchanges operate as web trafﬁc brokers, offering free
trafﬁc/advertising in exchange for clicks. The exchange extracts
money from participants via the exchange ratio (i.e., exchanging
clicks at less than a 1–1 ratio so that the excess can be sold) or
monthly fee. But this explanation does not seem satisfactory. A
participant who seeks trafﬁc for their product receives clicks only
from others similarly motivated to sell their products. Since the
average quality of clicks received is the same as those delivered, the
average participant should lose in expectation once the exchange’s
cut is removed, unless outside money enters the exchange.
It is
also hard to believe that cash-out rates of $0.30 per 1,000 clicks
(about $0.05 per hour of clicking) could be a long-term incentive
for participants.

The emphasis on afﬁliate programs and related tools and services
among the exchange ads points to a different explanation. These
ads appear targeted at an unsophisticated user group lured by the
prospect of easy money and a career in “Internet marketing”. This
description may well be representative of a large fraction of the
actual manual exchange users. In this case, the sites advertising
on the exchanges might be receiving quality trafﬁc for their offers
with acceptable conversion rates, even if they buy trafﬁc from the
exchange rather than clicking.
7.5 Revenue estimates

Table 6 gives the prices at which we bought clicks from various
exchanges. The cost per thousand (CPM) ranges from $0.06 at Oto-
hits to $10 at HitSafari. Obviously, the clicks are not all of the same
quality, and some may suit far better than others for a particular pur-
pose. For comparison, we compute the cost of generating clicks if
one rented the cheapest instance of a virtual machine from a cloud
hosting service. A micro-instance from Amazon AWS costs $0.013
per hour [3]; setting such a machine to click twice per minute would
cost $0.013 × 1000/(2 × 60) ≈ $ 0.11 per thousand. Of course
these clicks would offer no IP address dispersion. However, these
clicks can be dispersed by using the free service of one of the auto-
surf exchanges. Thus, we calculate that dispersed clicks can be pro-
duced at about $0.11 per thousand. If one needed the customization
that the premium services offer, then at 2.9AC≈ $3.5 per month the
cost becomes $ (0.013×24×30+3.5)×1000/(30×24×60×2) ≈
$ 0.15 per thousand (i.e., renting the instance for a month at the
hourly rate plus the cost of premium exchange membership). Note
that this is signiﬁcantly lower than several of the auto exchanges
charge; e.g., HitLeap charges $0.44 and Jingling $0.41 per thou-
sand. The fact that dispersed customized clicks can be produced
at signiﬁcantly lower cost than the exchanges charge suggests an
inefﬁcient market. It could be that the exchanges price optimisti-
cally and sell very little at the advertised rates, or it could be that
there are unsophisticated buyers for whom the task of setting up an
AWS instance represents a barrier. Note that the manual exchanges
ask more than 10× more per click. A possible explanation is that
proposed in Sections 7.2 and 7.4: it is the participants themselves
rather than an ad network who are the targets, and sending Ponzi
and get-rich-quick schemes at this population is more proﬁtable on

a per-click basis than sending inorganic trafﬁc to YouTube. Our
measurements (and the requirement to perform a CAPTCHA be-
tween clicks) suggest that a large fraction of trafﬁc on the manual
exchanges is in fact organic.

It is hard to pin down deﬁnitive stable numbers for how much
one can expect to earn from inorganic trafﬁc. Some URL short-
ening sites post their current payout rates: adf.ly pays $3.96,
adfoc.us pays $5.50, and sh.st pays $4.03 per thousand.
YouTube does not post payout rates, and discussion forums seem to
indicate it is a complex function of channel subscribers and number
of “likes” that a video receives; between $0.50 and $4 per thousand
appears to be a commonly mentioned range. (The need for “likes”
and subscribers to help monetize views suggests a market for those
commodities also).

If clicks can be produced at $0.15 per thousand (or bought at
the rates shown in Table 6) and sold for $4 or so per thousand to
URL shortening services, the opportunity is very proﬁtable. At the
two clicks per minute rate this would produce $ (4.03 − −0.15) ×
30 × 24 × 60 × 2/1000 ≈ $ 335.2 proﬁt per machine per month.
It seems very likely however that URL shortening services detect
(and refuse to credit) a large volume of inorganic trafﬁc (e.g., in
its TOU adf.ly forbids publishers from “advertising their adf.ly
URL links directly on any form of trafﬁc exchange/PTC website”,
and other services use similar wording). Equally, even the lower
of YouTube payout rates would appear proﬁtable if detection has
negligible effect. Ethical considerations prevent us from sending
automated trafﬁc to any of these services to probe their detection
rates.
It is thus difﬁcult to estimate the true return on inorganic
trafﬁc. We note, however, that even if only 5% of the inorganic
trafﬁc is credited (≈ $17 per machine per month), the ability to
scale up by adding more machines would still allow healthy returns.
Table 9 gives our estimate of the number of impressions per day
from each of the autosurf exchanges. Again, we caution that the
fraction of exchange trafﬁc that is detected (and thus not credited)
is unknown. Nonetheless it is interesting to get rough ideas of the
economic damage inorganic trafﬁc might be causing. HitLeap, at
150M impressions per day, would cost $66K per day to advertisers
if all exchange participants managed to monetize at $0.44 per thou-
sand impressions (i.e., the rate the exchange charges for clicks as
shown in Table 6). Similarly, the ﬁgures for eBesucher and Jingling
would be $3,230 and $323K respectively. These can be considered
somewhat loose upper bounds.

8. CONCLUSION

We examined several manual and automated trafﬁc exchange ser-
vices, which enable dispersion of trafﬁc origins. We found that
these exchanges range across three orders of magnitude in diver-
sity of IP addresses and impressions served per day, and appear
to differ signiﬁcantly in the monetization strategies of participants.
Our results shed light on a previously poorly understood part of the
trafﬁc and ad-fraud ecosystem.

Acknowledgments
Our thanks to Ben Edelman, Paul England, Mariusz Jakubowski,
and Gloria Mainar-Ruiz for discussions on various aspects of this
work.

This work was supported by the U.S. Army Research Ofﬁce un-
der MURI grant W911NF-09-1-0553, and by the National Science
Foundation under grant CNS-1237265. Any opinions, ﬁndings,
and conclusions or recommendations expressed in this material are
those of the authors and do not necessarily reﬂect the views of the
sponsors.

119. REFERENCES
[1] 10khits. http://www.10khits.com. Online. Mar, 2015.
[2] 247autohits. http://www.247autohits.com. Online. Mar, 2015.
[3] Amazon ec2 pricing. http://aws.amazon.com/ec2/pricing/. Online.

Mar, 2015.

[4] Appnexus. http://www.appnexus.com. Online. Mar, 2015.
[5] Black hat world. http://www.blackhatworld.com. Online. Mar,

2015.

[6] Clickbank. http://www.clickbank.com. Online. Mar, 2015.
[7] Common crawl. http://commoncrawl.org/the-data/. Online. Mar,

2015.

[8] Cyber criminals defraud display advertisers with tdss.

http://goo.gl/e1dcsj. Mar, 2015.

[9] Discovered: Botnet costing display advertisers over six

million dollars per month.
http://www.spider.io/blog/2013/03/chameleon-botnet/. Online. Mar,
2015.

[10] Easyhits4u. http://www.easyhits4u.com. Online. Mar, 2015.
[11] Ebesucher. http://www.ebesucher.com. Online. Mar, 2015.
[12] Enhanceviews autowatcher. http://www.enhanceviews.com. Online.

Mar, 2015.

[13] Frozen view count - youtube.

https://support.google.com/youtube/troubleshooter/2991876?hl=en-GB/.
Online. Mar, 2015.

[14] Hitleap. https://hitleap.com. Online. Mar, 2015.
[15] Hitsafari. http://www.hitsafari.com. Online. Mar, 2015.
[16] Jingling. http://service.spiritsoft.cn. Online. Mar, 2015.
[17] Limestone networks. https://www.limestonenetworks.com. Online.

Mar, 2015.

[18] Mozilla public sufﬁx list. http://wiki.mozilla.org/Public_Sufﬁx_List.

Online. Mar, 2015.

[19] Mustat. http://www.mustat.com. Online. Mar, 2015.
[20] Otohits. http://www.otohits.net. Online. Mar, 2015.
[21] Ovh - webhosting, cloud and dedicated servers.

https://www.ovh.com/. Online. Mar, 2015.

[22] Ziddu. http://www.ziddu.com. Online. Mar, 2015.
[23] N. Christin. Traveling the silk road: A measurement analysis
of a large anonymous online marketplace. In Proceedings of
the 22nd international conference on World Wide Web, pages
213–224. International World Wide Web Conferences
Steering Committee, 2013.

[24] V. Dave, S. Guha, and Y. Zhang. Measuring and

ﬁngerprinting click-spam in ad networks. In Proceedings of
the Special Interest Group on Data Communication
(SIGCOMM), August 2012.

[25] B. G. Edelman. Accountable? the problems and solutions of
online ad optimization. In IEEE Security & Privacy 12, no. 6
(November–December 2014): 102–107.

[26] C. Grier, K. Thomas, V. Paxson, and M. Zhang. @spam: The
underground on 140 characters or less. In Proceedings of the

17th ACM conference on Computer and communications
security, pages 27–37. ACM, 2010.

[27] H. Haddadi. Fighting online click-fraud using bluff ads.

SIGCOMM Comput. Commun. Rev., 40(2):21–25, Apr. 2010.

[28] C. Kanich, C. Kreibich, K. Levchenko, B. Enright, G. M.

Voelker, V. Paxson, and S. Savage. Spamalytics: An
empirical analysis of spam marketing conversion. In
Proceedings of the 15th ACM conference on Computer and
communications security, pages 3–14. ACM, 2008.

[29] R. A. Lewis and J. M. Rao. On the near impossibility of
measuring the returns to advertising. Unpublished paper,
Google, Inc. and Microsoft Research.
http://justinmrao.com/lewis_rao_nearimpossibility.pdf,
2013.

[30] D. McCoy, A. Pitsillidis, G. Jordan, N. Weaver, C. Kreibich,

B. Krebs, G. M. Voelker, S. Savage, and K. Levchenko.
Pharmaleaks: Understanding the business of online
pharmaceutical afﬁliate programs. In Proceedings of the 21st
USENIX conference on Security symposium. USENIX
Association, 2012.

[31] B. Miller, P. Pearce, C. Grier, C. Kreibich, and V. Paxson.

What’s clicking what? techniques and innovations of today’s
clickbots. In Proceedings of the 8th International Conference
on Detection of Intrusions and Malware, and Vulnerability
Assessment, DIMVA, pages 164–183. Springer-Verlag, 2011.

[32] N. Nikiforakis, F. Maggi, G. Stringhini, M. Z. Raﬁque,

W. Joosen, C. Kruegel, F. Piessens, G. Vigna, and S. Zanero.
Stranger danger: Exploring the ecosystem of ad-based url
shortening services. In Proceedings of the 23rd international
conference on World wide web, pages 51–62. International
World Wide Web Conferences Steering Committee, 2014.

[33] P. Pearce, V. Dave, C. Grier, K. Levchenko, S. Guha,
D. McCoy, V. Paxson, S. Savage, and G. M. Voelker.
Characterizing large-scale click fraud in zeroaccess. In
Proceedings of the 21st ACM Conference on Computer and
Communications Security (CCS). ACM – Association for
Computing Machinery, November 2014.

[34] K. Springborn and P. Barford. Impression fraud in on-line

advertising via pay-per-view networks. In Proceedings of the
22nd USENIX Security Symposium, pages 211–226,
Washington, D.C., 2013. USENIX.

[35] B. Stone-Gross, R. Stevens, A. Zarras, R. Kemmerer,
C. Kruegel, and G. Vigna. Understanding fraudulent
activities in online ad exchanges. In Proceedings of the
eleventh ACM SIGCOMM Conference on Internet
Measurement Conference, pages 279–294, New York, NY,
USA, 2011. ACM.

[36] TeamCymru. IP to ASN Mapping. http://tinyurl.com/5dtp78.

Online. Mar, 2015.

[37] Q. Zhang, T. Ristenpart, S. Savage, and G. M. Voelker. Got

trafﬁc?: An evaluation of click trafﬁc providers. In
Proceedings of the Joint WICOW/AIRWeb Workshop on Web
Quality, pages 19–26, New York, NY, USA, 2011. ACM.

12