2013 IEEE Symposium on Security and Privacy

The Crossﬁre Attack

Min Suk Kang

ECE Department and CyLab
Carnegie Mellon University
Email: minsukkang@cmu.edu

Soo Bum Lee

CyLab

Carnegie Mellon University
Email: soobum@cmu.edu

Virgil D. Gligor

ECE Department and CyLab
Carnegie Mellon University

Email: gligor@cmu.edu

Abstract—We present the Crossﬁre attack – a powerful
attack that degrades and often cuts off network connections to a
variety of selected server targets (e.g., servers of an enterprise,
a city, a state, or a small country) by ﬂooding only a few
network links. In Crossﬁre, a small set of bots directs low-
intensity ﬂows to a large number of publicly accessible servers.
The concentration of these ﬂows on the small set of carefully
chosen links ﬂoods these links and effectively disconnects
selected target servers from the Internet. The sources of the
Crossﬁre attack are undetectable by any targeted servers, since
they no longer receive any messages, and by network routers,
since they receive only low-intensity, individual ﬂows that are
indistinguishable from legitimate ﬂows. The attack persistence
can be extended virtually indeﬁnitely by changing the set of
bots, publicly accessible servers, and target links while main-
taining the same disconnection targets. We demonstrate the
attack feasibility using Internet experiments, show its effects
on a variety of chosen targets (e.g., servers of universities, US
states, East and West Coasts of the US), and explore several
countermeasures.

I. INTRODUCTION

Botnet-driven distributed denial-of-service (DDoS) at-
tacks which ﬂood selected Internet servers have been known
for some time [1, 2, 3, 4]. In contrast, link-ﬂooding attacks
that effectively disconnect chosen Internet servers have been
uncommon, possibly because of the complexity of selective
server targeting. Instead, most of these attacks cause route
instabilities [5] and Internet connectivity disruption [6, 7]
rather than selective end-server disconnection (reviewed in
Section VII). Nevertheless, when the aim of an attack is
to cut off critical infrastructure (e.g., energy distribution,
time-critical ﬁnance, command and control services) from
the Internet, link ﬂooding can be extremely effective; e.g.,
current peak rates of a single botnet-driven attack can easily
exceed 100 Gbps [8], making it possible to ﬂood the vast
majority of Internet links.

Link ﬂooding by botnets cannot be easily countered by
any of the current Internet defense methods for three reasons.
First, bots can use valid IP addresses, and thus defenses
based on detecting or preventing use of spoofed IP addresses
become irrelevant; e.g., defenses based on ingress ﬁlter-
ing [9], capability systems [10, 11], or accountable protocol
designs [12, 13]. Second, and more insidiously, botnets can
ﬂood links without using unwanted trafﬁc; e.g., they can
send packets to each other in a way that targets groups of

1081-6011/13 $26.00 © 2013 IEEE
DOI 10.1109/SP.2013.19

127

routers [7]. Third, a botnet can launch an attack with low-
intensity trafﬁc ﬂows that cross a targeted link at roughly the
same time and ﬂood it; e.g., a botnet controller could com-
pute a large set of IP addresses whose advertised routes cross
the same link (i.e., decoy IPs), and then direct its bots to
send low-intensity trafﬁc towards those addresses. This type
of attack, which we call the Crossﬁre attack1 and describe in
this paper, is undetectable by any server located at a decoy
IP address, and its effects are invisible to an ISP until (too)
late2. Furthermore, current
trafﬁc engineering techniques
are unable to counter these attacks. The latency of ofﬂine
trafﬁc engineering is impractically high (e.g., hours and
days [15, 16]) whereas online trafﬁc engineering techniques
cannot offer strong stability guarantees [17], particularly
when multiple ISPs need to coordinate their responses to
counter an attack, and hence cannot be deployed in the
Internet backbone. Worse yet, even if online techniques
could be deployed, an adversary attack could change the
set of target links in real time thereby circumventing online
trafﬁc engineering defenses; viz., discussion in Section IV.
In this paper, we present the Crossﬁre attack. This attack
can effectively cut off the Internet connections of a targeted
enterprise (e.g., a university campus, a military base, a set
of energy distribution stations); it can also disable up to
53% of the total number of Internet connections of some
US states, and up to about 33% of all the connections of
the West Coast of the US. The attack has the hallmarks of
Internet terrorism3: it is low cost using legitimate-looking
means (e.g., low-intensity, protocol conforming trafﬁc); its
locus cannot be anticipated and it cannot be detected until
substantial, persistent damage is done; and most importantly,
it is indirect: the immediate target of the attack (i.e., selected
Internet links) is not necessarily the intended victim (i.e., an
end-point enterprise, state, region, or small country). The
low cost of the attack (viz., Section IV), would also enable

1This attack should not be confused with that of Chou et al. [14], which
also uses the term “crossﬁre” for a different purpose; i.e., to illustrate
unintentionally dropped legitimate ﬂows.

2Of course, an adversary could easily change the set of bots used in the
attack; e.g., typical networks of 1M bots would allow one hundred disjoint,
and a very large number of different sets of 10K bots.

3Although common agreement on a general deﬁnition of terrorism does
not exist, the means of attack suggested here are common to most terrorist
attacks in real life.

a perpetrator to blackmail the victim.

The main contributions of this paper can be summarized

as follows:

1) We introduce the Crossﬁre attack in the Internet and
show how it can isolate a target area by ﬂooding care-
fully chosen links. In particular, we show that it requires
relatively small botnets (e.g.,
ten thousand bots) and is
largely independent of the bot distribution. It has no effective
countermeasure at either target routers or end-point servers,
and as a result, it can degrade and even cut off connections
to selected Internet areas ranging from a single organization
to several US states, for a long time.

2) We show the feasibility of the Crossﬁre attack with
data obtained from large-scale experiments. In particular,
our analysis of Internet trafﬁc to targets shows that very
few carefully chosen links are responsible for delivering the
vast majority of all trafﬁc to a speciﬁc area, a fact which
makes this attack fairly easy to launch. Trafﬁc concentration
in a small set of links located a few (e.g., three to four)
hops away from a targeted area is intuitively attributable to
the shortest path routing by the Internet IGP/BGP protocols,
and easily discoverable by common tools such as traceroute.
We show that the attack trafﬁc on these links follows a
power-law distribution that depends on the targeted servers
and cannot be anticipated by generic Internet-connectivity
metrics; e.g., metrics based on router connectivity [18, 19]
or betweenness centrality [20].

3) We show that the Crossﬁre attack is persistent in the
sense that it cannot be stopped either by individual ISPs or
by end-point servers, which are effectively disconnected by
ﬂooded links at least three hops away, for a long time. Attack
persistence is caused by three independent factors. First, the
selected attack routes become stable after the removal of
all load balancing dynamics (which is consistent with prior
observations [21]). Second, the attack trafﬁc is shaped such
that (i) only a data plane of a link is ﬂooded while the
control plane remains unaffected, and hence dynamic re-
routing can be initiated only after data-plane ﬂood detection,
which gives an adversary ample time to select alternate sets
of links for the same target area; and (ii) early congestion
of links located upstream from a targeted link is avoided by
a priori estimation of the bandwidth available on the route
to that link. Third, the availability of multiple, disjoint sets
of target links distributed across multiple ISPs implies that
no single ISP can unilaterally detect and handle this attack.
4) We argue that collaborative on-line, rather than ofﬂine,
trafﬁc engineering techniques would become necessary to
reduce the persistence of such attacks. In the absence of
such measures, the Crossﬁre attack must be handled by
application protocol layers; e.g., overlays that detect effec-
tive host disconnection from the Internet and re-route trafﬁc
via different host routes [22, 23]. Botnet market disruption
and international prosecution of attack perpetrators may
complement technical countermeasures against these attacks.

Figure 1: The Elements of the Crossﬁre Attack



II. THE CROSSFIRE ATTACK

In this section, we present the steps of the Crossﬁre attack.
The adversary’s goal is to prevent legitimate trafﬁc from
ﬂowing into a speciﬁc geographic region of the Internet,
and the capability she needs to accomplish that goal is to
ﬂood a few network links in and around that region. We
begin by deﬁning the two most common terms used in this
paper: the target area and target link. Then, we describe how
an adversary designs an attack using the bots she controls.
Fig. 1 illustrates the concept of the Crossﬁre attack.

Target Area: A target area is a geographic region of the
Internet against which an adversary launches an attack;4 viz.,
the area enclosed by the circle in Fig. 1. A typical target
area includes the servers of an organization, a city, a state,
a region, and even a country, of the adversary’s choice.

Target Link: A target link is an element of a set of network
links the adversary needs to ﬂood so that the target area is
cut off from the rest of the Internet. These carefully chosen
network links are the actual target of the ﬂooding attack
whereas the target area is the real, intended target.

To launch a Crossﬁre attack against a target area, an
adversary selects a set of public servers within the target
area and a set of decoy servers surrounding the target area.
These servers can be easily found since they are chosen
from publicly accessible servers (viz., Section V-B). The set
of public servers is used to construct an attack topology
centered at the target area, and the set of decoy servers is
used to create attack ﬂows. Then, the adversary constructs
a “link map”, namely the map of layer-3 links from her bot

4The attack may have side effects and affect other non-targeted areas.
However, these side effects do not increase attack’s detectability. They can
be a desired feature whenever the adversary’s goal is to cut off most of the
trafﬁc at and around a target area, rather than to surgically isolate a small
number of speciﬁc servers.

128

addresses to those of the public servers. (The differences
between a link map and a typical router-topology map are
discussed below.) Once the link map is created, the adversary
uses it to select the best target links whose ﬂooding will
effectively cut off the target area from the Internet. Next,
the adversary coordinates the bot-decoy (server) ﬂows to
ﬂood the target links, which would eventually block most
of the ﬂows destined to the target area. This can be easily
done since target links are shared by ﬂows to the decoy
servers and target area. Finally, the adversary selects multiple
disjoint sets of target links for the same target area and ﬂoods
them one set at a time, in succession, to avoid triggering bot-
server route changes. The three main steps needed to launch
the Crossﬁre attack consist of the link map construction,
attack setup, and bot coordination, as shown in Fig. 2. Note
that, to extend the duration of the attack, the last step,
namely the bot coordination step, is executed repeatedly by
dynamically changing the sets of target links, which we will
explain in detail in Section II-D. We describe each of the
adversary’s steps below.

A. Link Map Construction

To ﬂood links leading to a target area, an adversary needs
to construct a link map of the Internet surrounding that area.

1) Traceroute from Bots to Servers:
To construct the link map, the adversary instructs her bots
to run traceroute and ﬁnd all the router-level routes to the
public servers in the target area and the decoy servers. The
result of a traceroute is a sequence of IP addresses that are
assigned to the interfaces of the routers on the route, where
a link is identiﬁed by the IP address of the adjacent router’s
interface. Thus, the sequence of IP addresses represents the
sequence of layer-3 links5 that the attack trafﬁc would travel.
A link map for the Crossﬁre attack is different from a typ-
ical router-topology map [18] that attempts to build a router-
level connectivity to analyze topological characteristics (e.g.,
node degree). This attack only needs the list of layer-3 links
and their relationships to compute a set of target links on
the bot-to-target area routes, while each link’s membership
to a speciﬁc router is irrelevant. Note that the link map
construction does not require IP alias resolution [24]; i.e.,
determining the set of IP interfaces owned by the same router
is unnecessary. As a consequence, an adversary can use the
ordinary traceroute for the link map construction regardless
of how inaccurate its IP alias resolution may be [25].

A bot runs multiple traceroutes to the same server in order
to determine the stability and multiplicity (or diversity) of a
route, both of which are used for selecting effective target
links (discussed in Section V-D in detail). The traceroute

5Although a single layer-3 link consists of several lower layer connec-
tions that are invisible to the adversary, the ﬂooding on the layer-3 link
is still effective whenever the adversary’s maximum bandwidth assumption
(e.g., 40 Gbps in our experiments) is correct along the layer-3 link.

$GYHUVDU\

%RWV

7UDFH'DWD

traceroute
ᬅᬅᬅᬅ

ᬆᬆᬆᬆ

traceroute

,QWHUQHW

3XEOLF
VHUYHUV

$

'HFR\VHUYHUV

7DUJHW$UHD

/LQN0DS&RQVWUXFWLRQ
ᬅᬅᬅᬅ 7UDFHURXWH%RWVĺ6HUYHUV
ᬆᬆᬆᬆ /LQN3HUVLVWHQFH

$GYHUVDU\

%RWV

/LQNPDS

ᬅᬅᬅᬅ
)ORZGHQVLW\

,QWHUQHW

ᬆᬆᬆᬆ
7DUJHW/LQNV

3XEOLF
VHUYHUV

'HFR\VHUYHUV

7DUJHW$UHD

%

$WWDFN6HWXS
ᬅᬅᬅᬅ )ORZ'HQVLW\&RPSXWDWLRQ
ᬆᬆᬆᬆ 7DUJHW/LQN6HOHFWLRQ

$GYHUVDU\

ᬅᬅᬅᬅ

&RPPDQGV

%RWV

$WWDFN )ORZV

ᬆᬆᬆᬆ

3XEOLF
VHUYHUV

'HFR\VHUYHUV

7DUJHW$UHD

,QWHUQHW

&

%RW&RRUGLQDWLRQ
ᬅᬅᬅᬅ $WWDFN)ORZ$VVLJQPHQW
ᬆᬆᬆᬆ 7DUJHW/LQN)ORRGLQJ


Figure 2: The steps of the Crossﬁre attack.

results are collected by the adversary and used to construct
the link map.

2) Link-Persistence:
The link map obtained in the previous step cannot be
directly used to ﬁnd target links since some of the routes
obtained may be unstable. Unstable routes would complicate
the attack since the adversary may end up chasing a moving
target. Route instability is primarily caused by ISPs’ load
balancing processes (i.e., forwarding trafﬁc through multiple
routes), which are supported by most commercial routers
[26]. A consequence of load balancing is that, for the
same bot-to-server pair, some links do not always appear
on the trace of the route produced by multiple invocations

129

of traceroute (viz., the arrowed links of step A-② in Fig.
2). These links are said to be transient, whereas those that
always appear on a route are said to be persistent. The
adversary identiﬁes transient links and removes them from
the set of potential target links. Our Internet experiment
shows that 72% of layer-3 links measured by traceroute are
persistent6.

B. Attack Setup

The adversary uses the obtained link map to discover the
set of target links whose ﬂooding cuts off the largest number
of routes to the target area. Clearly, the larger the proportion
of cut routes out of all possible routes to the target area,
the stronger the attack. The attack-setup step consists of the
following two sub-steps.

1) Flow-Density Computation:
The adversary analyzes the link map for a target area
and computes ‘target-speciﬁc attack-ﬂow density’, or simply
ﬂow density henceforth, for each network link in the link
map. The ﬂow density of a persistent link is deﬁned as
the number of ﬂows between bots and target-area servers
that can be created through that link. Hence, ﬂow density
is a target-area-speciﬁc metric and can vary widely from
one target area to another (viz., Section III-A). It is a very
different metric from those used for Internet connectivity,
such as the “betweenness centrality” [20] and the degree
of routers [18, 19] (viz., Section III-A), and should not be
confused with them.

A high ﬂow density for a link indicates that the link
delivers both a large number of attack and legitimate (or non-
attack) to a speciﬁc target area, and thus the link becomes a
good attack target. We found that the ﬂow density follows
a power-law distribution in a link map (viz., Section III-A),
and this enables an adversary to easily discover a set of high
ﬂow density links that delivers most trafﬁc to a target area.7
Furthermore,
the computed ﬂow density remains largely
unchanged for at least several hours due to the well-known,
long-term stability of Internet routes [27, 21]. Hence, ﬂow
density can be used as a stable and reliable metric by the
adversary in selecting target links.

2) Target-Link Selection:
In this step, the adversary ﬁnds multiple disjoint sets of
target links to be ﬂooded. The adversary selects at least two
disjoint sets of target links and uses them one at a time, in
succession, to achieve attack persistence (viz., Section II-D).
The goal of this step is to maximize the amount of disrupted

6The link map obtained may not include backup links since these links
typically do not show up in traceroutes. The existence of such links is
largely immaterial to the effectiveness of Crossﬁre. If attack trafﬁc spills
over onto backup links and its intensity dampens appreciably, the adversary
could easily switch to a new set of target links for the same server area, as
shown in Section II-D.

7The power-law of ﬂow density should not be confused with connectivity
properties derived from traceroute, such as those for the degree of router
level topology [19].

trafﬁc ﬂowing into the target area by optimal selection of
target links using the link map and ﬂow density.

To quantify how much of the trafﬁc to a target area can be
cut off by a chosen target-link set, the adversary computes
the degradation ratio for that target area. The degradation
ratio is the fraction of the number of bot-target area routes
cut by the attack over the number of all possible bot-target
area routes. We say that a route is cut by an attack if the
route contains a target link that is ﬂooded by the attack.

To select the target links that maximize the degradation
ratio to a target area, the adversary must solve the general-
ized maximum coverage problem, which is a well-known
NP-hard problem. Instead of ﬁnding an exact solution,
the adversary uses an efﬁcient heuristic, namely a greedy
algorithm [28], presented in Section IV-D. The execution
time of our heuristic is very small, namely less than a minute
in all experiments (viz., Section IV-D). This enables the
adversary to adapt to dynamic route changes, if necessary.
The output of this algorithm shows that ﬂooding a few target
links can block a majority of the connections to a target
area. For example, ﬂooding ten target links causes a 89%
degradation ratio for a small target area; ﬂooding ﬁfteen
target links can block 33% of connections ﬂowing to the
West Coast of the US (viz., Section V-D).

C. Bot Coordination

Once target links are selected at step B-② (Fig. 2), the
adversary coordinates individual bots to ﬂood the target
links. To create ﬂooding ﬂows for a given set of target links,
the adversary assigns to each bot (1) the list of decoy servers
and (2) the send-rates for packets destined to individual
decoy servers. The send-rates are assigned in such a way that
individual attack ﬂows have low intensity (or low bandwidth)
while their aggregate bandwidth is high enough to ﬂood all
target links. This step consists of two sub-steps.

1) Attack-Flow Assignment:

The goal of the attack-ﬂow assignment is to make
the aggregate trafﬁc rate at each target link slightly higher
than the link bandwidth so that all the legitimate ﬂows
are severely degraded in those links. Two assignment con-
straints must be satisﬁed. The ﬁrst is that the adversary
must keep each per-ﬂow rate low enough so that none of
the network protection mechanisms in routers or intrusion
detection systems (IDS) at or near a server can identify the
ﬂow as malicious. The second is that the aggregate attack
trafﬁc necessary to ﬂood all the targeted links is relatively
evenly assigned to multiple bots and decoy servers. The
ﬁrst constraint ensures indistinguishability of attack ﬂows
whereas the second addresses undetectability both at servers
in the target area and at decoy servers; viz., Section VI
for details. The adversary ﬁrst sets the maximum target
bandwidth for each target link and exhausts it with attack
ﬂows. Then, she assigns individual ﬂows for each target link.

130

The rate of an attack ﬂow at a target link is lower-bounded
by the ﬂow density. The average per-ﬂow rate for the target
link should be higher than the target bandwidth divided
by the maximum number of available attack ﬂows on the
link, which is proportional to its ﬂow density. Moreover,
the assignment of the per-ﬂow rate must take into account
the maximum ﬂow rate a decoy server can handle without
triggering trafﬁc alarms. For example, if a decoy server is
a public web server, one web click per second on average
(a HTTP GET packet per second (cid:2) 4 Kbps) would not be
classiﬁed as abnormal trafﬁc at the server. Therefore, the
adversary can easily assign a large enough number of attack
ﬂows with low per-ﬂow rates. The adversary also has to
assign per-bot and per-decoy server rates that are evenly
distributed. For enhanced undetectability of attack trafﬁc at
the bots and the decoy servers, the adversary must account
for all previously assigned trafﬁc rates at the bots and decoy
servers whenever assigning new attack ﬂows. The adversary
conservatively sets the target bandwidth to 40 Gbps, which
is the most widely used link bandwidth currently deployed
(OC-768) for high bandwidth backbones.

Despite an adversary’s careful attack ﬂow assignment,
non-target links located upstream of the target links could
still become congested, which we call early congestion, if
they have limited bandwidth and/or the bot density in a
certain area is too high. The adversary can avoid potential
early congestion using a priori link bandwidth estimation,
which we discuss in detail in Section IV-C.

2) Target-Link Flooding:
The adversary directs her bots to start generating the
attack ﬂows. Each bot is responsible for multiple attack
ﬂows, each of which is assigned a distinct decoy server with
the corresponding required send-rate. Bots slowly increase
the send-rates of their attack ﬂows up to their assigned send-
rates, which makes the attack ﬂows indistinguishable from
the trafﬁc patterns of typical ”ﬂash crowds” [29]. Bots can
adjust the intensity of their ﬂow trafﬁc dynamically, based
on the state of each target link; i.e., if the actual bandwidth
of a target link is less than the assigned attack bandwidth
(set in Section II-C1), the bots stop increasing the rates of
attack ﬂows as soon as the target link is ﬂooded.

D. Rolling attacks

The adversary can dynamically change the set of target
links (among the multiple sets found previously) and extend
the duration of the Crossﬁre attack virtually indeﬁnitely.
Continuous link ﬂooding of the same set of target links
would lead to bot-server route changes since it would
inevitably activate the router’s failure detection mechanism.
Hence, changing the set of target links assures attack per-
sistence and enables the attack to remain a pure data-plane
attack. The adversary can also dynamically change the set of
bots to further enhance the undetectability of the Crossﬁre
attack. These dynamic attack execution techniques are called

131

rolling attacks in Section IV-B where they are described in
more detail.

III. TECHNICAL UNDERPINNINGS

In this section, we discuss the two characteristics of the
current Internet which enable the Crossﬁre attack, namely
(1) the power law of ﬂow-density distribution, which is
target-area speciﬁc, and (2) the independence of the geo-
graphical distribution of bots from target links and attack
targets, which gives an adversary has a wide choice of bots
in different locations on the globe.

A. Characteristics of Flow-Density Distribution

Before analyzing the distribution of ﬂow density, we
must distinguish between the attack-speciﬁc ﬂow density and
connectivity-speciﬁc metrics, such as the betweenness cen-
trality [20] and the degree of routers [18], which characterize
an Internet topology. Recall that the ﬂow density of a link
represents the number of source-to-destination (i.e., bot-to-
server in the target area in the Crossﬁre attack) pairs whose
trafﬁc crosses the link persistently. In contrast, betweenness
centrality, which is the number of shortest routes among
all vertices that pass through an edge in a graph, does not
reﬂect actual trafﬁc ﬂows and their dynamics. Similarly, the
connectivity degree of a router, which represents the router’s
layer-3 direct connections to neighbor routers, namely the
topological connectivity of the router, does not capture any
dynamics of trafﬁc ﬂows. Thus, neither of these metrics
could be used to evaluate the feasibility of the Crossﬁre
attack.

Our analysis on the ﬂow-density distribution is two-fold;
ﬁrst, we show that it is easy to ﬁnd target links that have
extremely high ﬂow density for a selected target area; and
second, we show that ﬂow density of a link is not a constant
but varies depending on a selected target area (i.e., ﬂow
density is a target-area speciﬁc metric).

1) Universal power-law property of ﬂow-density distribu-
tion: A power-law distribution exhibits a heavy-tail charac-
teristic, which indicates that extreme events are far more
likely to occur than they would in a Gaussian distribution.
More formally, a quantity x obeys a power-law if it follows
a probability distribution

p(x) ∝ x−α for x > x0,

(1)

where α is a constant parameter of the distribution known as
the scaling parameter [30]. The power-law property appears
in the tail of the distribution (i.e., x > x0)8. If a power-law

their datasets follow a power-law distribution [18, 31];

8Some past research relied on simple data-ﬁtting methods to conclude
that
if a
histogram of empirical datasets is well ﬁtted to a straight line on log-log
scale, a power-law behavior would be ascribed to the datasets. However,
recent studies [32, 25] show that these data-ﬁtting methods are insufﬁcient
to conclude the power-law compliance of empirical data. According to
Clauset et al. [30], the majority of purported power-law datasets fail to
pass the rigorous statistical hypothesis test on their power-law distribution.

i.e.,

100

10−1

10−2

10−3

 

)
x
≥
X

 

(
r
P

10−4

  x
 = 1138
0
  α = 3.15
  p−value = 0.68

(a) East Coast

100

10−1

10−2

10−3

 

)
x
≥
X

 

(
r
P

10−4

0

  x
 = 690
  α = 3.45
  p−value = 0.96

(b) New York

10−1 100 101 102 103 104

10−1 100

x

102

103

104

101

x

Figure 3: Flow-density distributions for various target areas:
(a) East Coast and (b) New York. The complementary
cumulative distribution functions (CCDFs) (i.e., Pr(X ≥ x))
of ﬂow density (x) for both areas are plotted on log-log scale.

distribution holds for ﬂow density, that would imply that an
adversary could easily ﬁnd links whose ﬂow density is many
orders of magnitude higher than average. These links would
become good targets for attack for a particular target area.
We use the rigorous statistical test proposed by Clauset
et al. [30]9 to show that a power-law holds for ﬂow-density
distributions. We ﬁrst estimate the parameters (i.e., x0 and
α) of power-law distribution on our ﬂow-density datasets and
test the power-law hypothesis with the estimated parameters.
Fig. 3 shows the ﬂow-density distributions of two different
target areas: (a) East Coast and (b) New York. The com-
plementary cumulative distribution function (CCDF) (i.e.,
Pr(X ≥ x), where x is ﬂow density) of the ﬂow-density
datasets is plotted on a log-log scale. As the graphs show,
both distributions are well ﬁtted to the diagonal lines at the
tail. More precisely, we apply the power-law hypothesis test
proposed by Clauset et al. [30] to the measured ﬂow-density
dataset and obtain the p-value, which indicates the degree
of plausibility of a hypothesis, for each test. The p-values
for the two target areas (i.e., 0.68 and 0.96) are much higher
than the signiﬁcance level, which is often set to 0.05. Hence,
the plausibility of the null hypothesis (i.e., the ﬂow-density
distribution follows a power law) is accepted [33].

2) Target-area dependency of ﬂow density: Unlike
connectivity-related metrics, which are dependent only on
physical network connectivity but
independent of attack
targets, ﬂow density is an attack-speciﬁc metric; i.e., a target
link that has high ﬂow density for a target area may have a
very different density for other areas.

Table I illustrates the top 20 links ordered by ﬂows den-
sities for three target areas of different sizes: the East Coast,
Massachusetts, and Univ2. Naturally, one would expect that
the links’ ﬂow densities would follow the obvious link-
map inclusion relations, namely the link map of Univ2 ⊂
link map of Massachusetts ⊂ link map of the East Coast.
However, Table I shows that the top 20 links for these related
target areas are very different: not only these links do not
follow the link-map inclusion, but also whenever some are

9The statistical tools, proposed by Clauset et al. [30], are available at

http://tuvalu.santafe.edu/∼aaronc/powerlaws/.

132

Target area

East Coast

Massachusetts

Univ2

Indices of top 20 ﬂow-density links
01, 02, 03, 04, 05, 06, 07, 08, 09, 10,
11, 12, 13, 14, 15, 16, 17, 18, 19, 20
19, 21, 13, 22, 23, 24, 25, 26, 27, 28,
29, 30, 31, 32, 33, 34, 35, 36, 37, 38
39, 40, 30, 41, 42, 23, 43, 44, 45, 46,
47, 48, 49, 50, 51, 52, 53, 54, 55, 56

Table I: Top 20 ﬂow-density links for three different target
areas: the East Coast of the US, Massachusetts, and Univ2.
Each link IP address is mapped to a link index. Bold indices
denote the links shared by different areas.

shared between areas they have different density ranks. For
example, link 19 has the highest ﬂow-density rank when
the state of Massachusetts is targeted, and yet it only ranks
next to the last for the East Coast. Furthermore, link 19
does not even appear in the top 20 link densities of Univ2.
This clearly shows that ﬂow density is a target-area speciﬁc
metric, which reveals a link’s usefulness in an attack that
targets a speciﬁc area.

B. Geographical Distribution of Bots

Although the selected target links are highly dependent
on the target area of the attack, they are nearly independent
of the choice of bot distributions; i.e., even if an adversary
uses different sets of bots that have different geographic
distributions to ﬂood a target area,
the effectiveness of
the Crossﬁre attack would remain nearly unchanged. To
show this, we performed the following experiment. First,
we partitioned the set of bots into several subsets based on
bots’ geolocation (viz., subsets denoted by Sj, j = 1, ..., 8
in Table II). Then, we selected different subsets to form
six different bot distributions (viz., distributions denoted by
Distri, i = 1, ..., 6 in Table II), and simulated a separate
Crossﬁre attack for each distribution against three different
target areas;
i.e., East Coast, Pennsylvania, and Univ1.
Finally, we analyzed how the different distributions affect
the degradation ratios.

The geographical distributions of 620 PlanetLab nodes
and 452 LG servers are as follows: 42% were located in
Europe, 39% in North America, 13% in Asia, and 6% in
the rest of the world (viz., Figure 5). Since the distributions
of PlanetLab nodes and LG servers in North America and
Europe cover wider areas than those in the rest of the world,
we (1) assigned three disjoint subsets to each; i.e., S1, S2,
and S3 to North America and S4, S5, and S6 to Europe;
and (2) constructed the bot distributions such that Distr1,
Distr2, and Distr3 cover a similar number of bots in
North America and Asia, and Distr4, Distr5, and Distr6
a similar number of bots in Europe and Asia.

Fig. 4 shows the degradation ratios for the six different bot
distributions shown in Table II and three different-size target
areas chosen; i.e., East Coast, Pennsylvania, and Univ1. For
each target area, we deﬁned a baseline degradation ratio
(denoted by “Baseline” in Fig. 4) as the degradation ratio

North America
S1
S3
(cid:2)
(cid:2)

S2
(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

Europe

S4
(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

S5
(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

S6
(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

Asia
S7
(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

Others

S8
(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

(cid:2)

Baseline
Distr1
Distr2
Distr3
Distr4
Disrt5
Distr6

Table II: Different geographic distributions of bots (Distri)
created using different subsets of PlanetLab nodes and LG
servers (Sj).

1

0.8

0.6

0.4

0.2

 

o
i
t
a
R
n
o
i
t
a
d
a
r
g
e
D

0

 
0

10

Univ1

Pennsylvania

East Coast

20

30

Number of target links

 

Baseline
     Distr1
     Distr2
     Distr3
     Distr4
     Distr5
     Distr6

40

50

Figure 4: Degradation ratios for different geographic distri-
butions of PlanetLab nodes and LG servers.

given by an attack launched by all bots available. The six
degradation ratios are computed using the same total number
of routes as that used in the baseline ratio. Thus, if the
degradation ratio of a certain distribution is close to the
baseline, that distribution of bots is as damaging to the target
area as the baseline (i.e., as all available bots). As shown in
Fig. 4, the choice of the six different distributions does not
diminish the effectiveness of the attack in a measurable way.
That is, the effectiveness of an attack is nearly independent
of the geographical distribution of bots. This is particularly
noticeable in the case of the small and medium target area
where the degradation ratios are almost indistinguishable
from the baseline.

IV. ATTACK PERSISTENCE AND COST

A. Data-Plane-Only Attack: Indeﬁnite Duration

In this subsection, we discuss how the Crossﬁre at-
tack maintains its effectiveness, namely a high connection
degradation ratio for selected target areas caused by link
ﬂooding (data plane only), by avoiding any route change
(by the control plane) in the Internet. Clearly, the goal of
the adversary is to avoid control plane reaction since that
would cause routes to change dynamically in response to
any unexpected network-state variations (e.g., due to link
failures or high trafﬁc load akin to link ﬂooding).

The Crossﬁre attack takes advantage of the fact that the
current Internet’s dynamic response to link ﬂooding is too
slow for an adaptive adversary. That is, if the adversary
periodically changes the set of predetermined target links
in less than 3 minutes, she can maintain a very high
connection degradation ratio without inducing any Internet

133

route changes. Thus, the attack duration can be extended
virtually indeﬁnitely. The technique of changing the set of
target links, namely the rolling attack, is discussed in detail
in Section IV-B. The following two subsections illustrate
how slowly the current Internet would react to the Crossﬁre
attack.

1) Link failure detection: Link-failure detection refers
to a function of a routing protocol that enables a router
to assess the physical connectivity of its network link to
its neighbor router [34]. A router which misses several
consecutive control packets (e.g., hello packets for OSPF
or keepalive messages for BGP) in a speciﬁc time interval
(default 40 seconds for OSPF or default 180 seconds for
BGP) will conclude that the link failed and broadcast the
link failure to other routers. The consequence of the link
failure is two-fold. First, if an intra-AS link fails, the failure
notiﬁcation is sent to all the routers within the same AS,
which leads to internal topology changes. In contrast, if a
link between two neighbor ASs (i.e., an inter-AS link) fails,
the failure, in the worst case, could propagate to all the BGP
speaking routers in the Internet and cause a global topology
change. These topology changes would redirect the attack
trafﬁc to alternate routes and invalidate the ﬂow densities
computed for the on-going Crossﬁre attack.

To measure Internet reaction to link failures, Shaikh et al.
[34] inject trafﬁc that consumes 100% of the capacity of a
link and measure the time for the router to detect the link
failure. This experiment shows that it takes 217 seconds for
a IGP router (that runs OSPF or IS-IS) and 1,076 seconds for
a BGP router to diagnose congestion as a failure10. Note that
failure detection takes much longer than its default waiting
time interval for the control packets, namely 40 seconds
for OSPF and 180 seconds for BGP. This is because some
control packets that are queued at the congested interface
at a router can successfully reach a neighbor router even
in severe link congestion. Clearly, the congestion diagnostic
times are too long to enable rapid reaction to the Crossﬁre
attack where the adversary can change the set of target links
for an area in much less than 3 minutes; viz., the rolling
attacks of the next subsection.

2) Trafﬁc engineering: Most commonly, ISPs use ofﬂine
trafﬁc engineering techniques, whereby network parameters
are periodically re-optimized based on the estimated trafﬁc
matrix among the ingress/egress points of their networks
[16]. The network parameters can be the link weights of IGP
protocols (e.g., OSPF or IS-IS) in pure IP networks [37] or
bandwidths of LSP (label switched path) tunnels in MPLS
networks [38, 39]. Ofﬂine trafﬁc engineering produces new

10We assume that the OSPF and BGP protocols do not use shorter
intervals for fast failure detection [35], but use default timers (HelloInterval
& RouteDeadInterval for OSPF and KeepaliveTimer & HoldTimer for
BGP). Since most optical ﬁber connections (e.g., SONET or SDH) provide
failure reports in less than 50 ms, additional system conﬁguration for faster
link failure detection at layer-3 is obviously unnecessary [36].

routes on a time scale ranging from tens of minutes to
hours and days [15], though more commonly in days and
weeks [38, 39, 16]. Even though it is not frequently used by
ISPs due to its potential instability problem, online trafﬁc
engineering occurs on a smaller time scale, namely from
minutes to hours [16, 17]. Given that the adversary can
repeatedly relaunch the Crossﬁre attack for new routes,
neither current ofﬂine nor online trafﬁc engineering can offer
effective countermeasures.

B. Proactive Attack Techniques: the Rolling Attack

A Crossﬁre attack is said to be rolling if the adversary
changes the attack parameters (e.g., bots, decoy servers, and
target links) dynamically while maintaining the same target
area. A rolling attack can be employed by an adversary to
further increase indistinguishability of attack trafﬁc from
legitimate trafﬁc and undetectability of all target links by
target area. Based on the types of attack parameters that can
be dynamically changed, rolling attacks can be categorized
into two types: one that changes bots and decoy servers
while maintaining the same target links, and the other that
changes target links while maintaining the same target area.
The main advantage of the ﬁrst type of attack is that
it further increases the indistinguishability of the Crossﬁre
ﬂows from legitimate ﬂows while maintaining the same
attack effects. Since the source and the destination IP
addresses seen at
links change over
time, the ISPs cannot easily identify the source and the
destination IP addresses that contribute to the attack. A
potential disadvantage is that this attack requires more bots
and decoy servers than the minimum necessary to ﬂood
the target links. However, the current cost of bots suggests
that this disadvantage is insigniﬁcant (viz., discussion of bot
costs below).

the selected target

The second type of rolling attack uses multiple sets of
disjoint target links for the same target area. To ﬁnd the
multiple disjoint sets, the adversary executes the target-link
selection algorithm (viz., Section II-B2) successively; i.e.,
the n-th best set of the target links is selected after removing
the previously selected links. The use of multiple disjoint
sets of the target links enhances attack undetectability by
ISPs since ISPs could not anticipate the adversary’s choice
of targets with certainty. More importantly, this type of
rolling attack enables Crossﬁre to remain a pure data plane
attack, as discussed in the previous subsection. A potential
disadvantage is that this type of rolling attack may degrade
the effectiveness of the Crossﬁre attack since the degradation
ratio caused by attacking a non-best
target set can be
lower than that of attacking the best set. However,
the
degradation ratios of different sets of target links shown
in Table III indicate that this degradation is minimal. In
order to maximize attack effects while being undetected, the
adversary can alternate the target sets; she would use the best
set for the most of attacks and switch to the non-best sets

Target area

Best set

Univ1

Pennsylvania
East Coast

89%
42%
21%

Target link set
2nd best set

3rd best set

77%
30%
16%

63%
24%
14%

Table III: Degradation ratios for different disjoint target link
sets. Each set has 10 target links.

only for a short time interval. For example, if the adversary
repeatedly schedules 3 minutes for the attack on the best
set and next 30 seconds for the second-best set, she can
maintain the attack towards a target area indeﬁnitely while
limiting the reduction of the degradation ratio less than 4%.

C. Avoidance of Early Congestion

Crossﬁre avoids early congestion, namely the event
whereby a non-target link, or more, located upstream of
the target links becomes congested. We argue that early
congestion does not affect attack feasibility, but instead is a
matter of attack provisioning, which is a very distinct and
easily handled issue by an adversary.

Bots can easily detect early congestion by regularly per-
forming traceroutes to the target area since if it happens, they
would not receive most of replies (i.e., ICMP time exceeded
messages) from the congested router and the subsequent
routers on the route. When early congestion is reported
by the bots, the adversary can re-assign some attack ﬂows
to over-provisioned bots, to avoid the early congestion. In
other words, the adversary adaptively assigns attack ﬂows to
geographically distributed bots, so that a sufﬁcient number
of attack packets reach the target links and ﬂood them. Note
that additional attack routes to target links can always be
found before the attack and used only if necessary.

In addition to the dynamic assignment of attack ﬂows,
the adversary can instruct bots to estimate the available
bandwidth towards the target links using a priori bandwidth
estimation tools (e.g., Pathneck [40]) and predict early
congestion before assigning attack ﬂows. In this way, the
adversary can provision the bots so that early congestion
would not happen.

D. Execution Time of Target Selection Algorithm

The greedy algorithm of selecting a set of T target links

runs as follows:
Let R, L and T be the set of all bot-to-target area routes,
the set of candidate links for the target area, and the set of
target links, respectively. Let li be a link on a route.
(1) Add all distinct links (l(cid:2)
(2) Take out the highest ﬂow density link, lmax

is) of R to L.

, from L and

i

(3) Recompute the ﬂow density for all li’s in L.
(4) Repeat (2) and (3) until T target links are selected, i.e.,

add it to T .

until |T | = T .

The above algorithm ﬁnds the T best target links that
disconnect the target area in terms of the degradation ratio,

134

Target area

Univ1

Pennsylvania
East Coast

T = 10

T = 20

T = 30

T = 40

T = 50

0.94
3.10
13.44

1.87
5.46
24.93

2.79
7.38
35.13

3.72
8.99
43.96

4.65
10.38
52.05

Table IV: Execution time (in seconds) to select T target links
for different target sizes.

i

in T iterations of steps (2) - (3). Step (3) re-evaluates ﬂow
densities after removing all routes of R that include lmax
and as a consequence, the step ensures that the adversary
selects the target link that maximally disconnects the target
area at each iteration. Table IV shows the execution times
taken by our experiments. As expected, the execution time is
proportional to the number of target links (T ) for all target
areas, and grows signiﬁcantly for a large target area (e.g., 52
seconds in selecting 50 target links for the East Coast of the
US), since more unique links can be found in large target
areas. However, the number of unique links is bounded by
a limited number of routes. This number is limited because
bot-decoy pairs in the same source and destination subnets
produce a single unique route. Hence, the execution time of
the algorithm is short enough (e.g., at most a couple minutes)
for an adversary to adapt to all potential route changes even
for a large target area, in practice.

E. The Cost of the Crossﬁre Attack

To launch a Crossﬁre attack, an adversary needs bots. To
get them, she can either infect user machines and install
her own bots or buy the bots from Pay-Per Install (PPI)
botnet markets [41]. For cost estimation, we assume that
the adversary buys the bots from the markets. Our cost
estimates are based on a recent analysis of PPI botnet
markets [41]. A possible option would be to rent cloud
services for bot operation from many, say one hundred,
providers around the world. Given the low computation and
communication requirements of Crossﬁre bots and the high-
bandwidth connectivity of data centers to the Internet, the
bots’ behavior during an attack would not trigger providers’
alarms.

PPI botnet markets have region-speciﬁc pricing plans.
Generally, bots in the US or the UK are most expensive
and cost $100-$180 per thousand bots. Bots in continental
Europe cost $20-$60 whereas bots in the rest of the world
cost less than $10 per thousand bots. The mix of bots used
in our experiments (presented in Section III-B) has 49%
of bots in the US or UK, 37% in continental Europe, and
14% in the rest of the world. If we assume the size of
a bot cluster (β) is 500, the total cost of the Crossﬁre
attack is roughly $46K. Our experiments also show (viz.,
Section V-D) that the minimum number of required bots
that can ﬂood 10 target links can be as low as 107,200 bots,
and hence the attack cost can be as low as $9K. This implies
that a single organization or even an individual can launch a
massive Crossﬁre attack. If the attack is state- or corporate-

sponsored, many more bots can be purchased and a much
larger number of links can be targeted. In this case, the
Crossﬁre attack could easily disconnect almost 100% of the
Internet connections to a large target area.

V. EXPERIMENT SETUP AND RESULTS

In this section, we demonstrate the feasibility of the
Crossﬁre attack and its effects on various target areas using
real Internet data. In particular, we show how one sets up the
bots, decoy servers, and target area for a Crossﬁre attack.

A. Bots

Instead of using real bots to perform our experiments,
which would raise ethical [42, 43] and/or legal concerns
[44], we use PlanetLab nodes [45] and Looking Glass (LG)
servers as attack sources. PlanetLab is a global research
testbed that supports more than one thousand nodes at
549 sites. An LG server is a publicly available router that
provides a Web-interface for running a set of commands,
including traceroute [46]. They have been used as vantage
points for discovering Internet topology [47, 48, 49].

The PlanetLab and LG server networks provide a faithful
approximation of a globally distributed bot network. As seen
in Fig. 5, the 620 PlanetLab nodes and 452 LG servers are
located 309 cities in 56 countries. In Section III-B, we will
show that different bot distributions created using PlanetLab
nodes and LG servers, result in practically the same attack
effectiveness. Hence, the Crossﬁre attack using real bots
(e.g., leased from botnet markets) would experience similar
attack effects as in our experiments. A single PlanetLab
node or LG server represents several hundred bots, given
(1) the high degree of clustering observed in real-bot distri-
butions [50, 51], and (2) the fact that bot-originated trafﬁc
from the same AS domain would converge at a router and
then follow the same route, due to the BGP’s single best
route selection policy. Hence, the routes we trace from the
PlanetLab nodes or LG servers to the public servers in the
target area, allows us to build the actual Internet link map
of the target area. We call the group of bots represented by
the same PlanetLab node or LG server a bot cluster, and
experiment with cluster sizes of 100, 200, and 500 bots.

B. Decoy servers

Decoy servers, which are the destinations for attack trafﬁc,
can be any public server whose physical location is nearby
a target area. Among various possible ways an adversary
could select decoy servers, one way is to ﬁnd servers of
public institutions (e.g., universities and colleges) physically
located surrounding the target area. For example, the servers
of a university or college are typically located on their

135

Target area

Univ1
Univ2

New York

Pennsylvania
Massachusetts

Virginia

East Coast (US)
West Coast (US)

Number of
public servers
in target area
1,000
1,000
86,000
82,000
54,000
34,000
351,000
201,000

Number of
decoy servers

350,000
350,000
265,000
269,000
297,000
317,000
351,000
201,000



Figure 5: A map of geographic locations of the 620 Planet-
Lab nodes (red pins) and 452 LG servers (blue pins) used
in our experiments.

Table V: The extrapolated numbers of public servers in target
areas and decoy servers used for attacking each target area
in our experiments

campus11.

We found 552 institutions (i.e., universities and colleges)
on both the East Coast (10 states) and West Coast (7 states)
of the US, which can provide large numbers of decoy
servers. The list of institutions in a speciﬁc US state is easily
found on the Web12. An adversary can ﬁnd a minimum of
1,000 public servers within an institution. For example, we
found 2,737 and 7,411 public web servers within Univ1 in
Pennsylvania and Univ2 in Massachusetts, respectively, via
port-scanning. Had we used real bots, port scanning duties
would be distributed to each bot and would be performed
over a period of time, to avoid triggering IDSs or ﬁrewall
alarms at those institutions. Similarly, an adversary could
use 351,000 public servers located in 351 institutions on the
East Coast of the US, and 201,000 public servers in 201
institutions on the West Coast.

C. Target area

A target area is the geographic location where an ad-
versary wants to block Internet trafﬁc. To establish that
the Crossﬁre attack works for various target-area sizes,
we used three different conﬁgurations: small, medium, and
large. For the small area size, we set a single organization
as the target area. Speciﬁcally, we set Univ1 and Univ2
as examples of small-sized target areas. As examples of
medium-sized areas, we picked four US states, namely New
York, Pennsylvania, Massachusetts, and Virginia. Finally,
we picked ten states on the East Coast and seven on the
West Coast as two examples for large target areas. Note that
the large target areas’ sizes could conceivably represent a
medium-size country. For a small or medium target area,
we chose decoy servers outside the target area for the
undetectability of attack ﬂows. However, for a large target
area, we chose decoy servers inside the target area since

11The adversary might use a public search engine, such as SHODAN
(http://www.shodanhq.com), to gather a large number of publicly accessible
IPs at a geographical location. However, use of SHODAN would require
cross-validation of the IP addresses in a geolocation due to possible search
inaccuracies. Cross-validation would be a fairly simple matter of comparing
results of multiple IP geolocation services for a certain target area

12http://www.4icu.org/

the wide array of decoy servers within the area would not
diminish the Crossﬁre’s undetectability.

Table V illustrates the extrapolated numbers of public
servers in the target areas and decoy servers used for
attacking those areas. Note that the extrapolation is based
on that an adversary can ﬁnd 1,000 public servers within an
institution.

D. Results

We performed Internet-scale experiments to verify the
feasibility and the impact of the Crossﬁre attack based on
the steps described in Section II. For each attack target area
illustrated in Table V, we construct a link map (Step 1,
viz., Section II-A) and select the target links (Step 2, viz.,
Section II-B), using the PlanetLab nodes and LG servers, and
public servers in the target area. Bot-coordination (Step 3,
viz., Section II-C) is performed via simulations, for obvious
ethical and legal reasons. However, the simulations use the
real link map and data obtained from the ﬁrst two attack
steps illustrated in Fig. 2. In this section, we summarize the
results of our experiments.

Link map. We gather traceroute data from all the Planet-
Lab nodes and LG servers (i.e., sources) to all the institutions
in the target areas (i.e., destinations) and construct
the
link maps centered on the target areas of the East and
West Coasts of the US. For each source-destination pair,
we run a traceroute six times to diagnose link persistence.
Since multiple traceroute packets (i.e., ICMP packets) to
the same destination are independently load-balanced at a
load-balancing router [26], running six traceroutes is enough
to determine whether a link on the route is persistent or
transient. We classify a link as persistent if the link appears
in all six traceroute results. The false positive probability,
namely the probability that we falsely determine a transient
link as persistent, is at most 0.016 ((cid:2) 2−6). This is the
case because the highest false positive probability is reported
when a router, which has two load-balancing links to the next
hop router, happens to select the same link in forwarding
six traceroute packets originated from the same source. If

136

Target area

Univ1
Univ2

New York

Pennsylvania
Massachusetts

Virginia

East Coast (US)
West Coast (US)

Percentage of persistent links
79.99 %
70.37 %
69.70 %
75.68 %
74.11 %
70.32 %
71.78 %
72.37 %

Table VI: Percentage of persistent links per target area

the router has more load-balancing links, the false positive
probability becomes lower.

We summarize the percentages of persistent links found
by traceroutes in Table VI. Regardless of the size of a target
area, the majority of the discovered links are persistent and
hence can be used for the Crossﬁre attack. This result shows
that even though trafﬁc load-balancing through multiple
links is widely implemented by ISPs in the current Internet,
a large portion of Internet links are persistent. This enables
the adversary to easily ﬁnd (persistent) target links. In the
following subsection, we discuss how the adversary ﬁnds the
target links whose congestion would effectively disconnect
a target area.

Link Coverage. Although one could not demonstrate that
all links leading to a target area can be found by traceroute,
one could show that all critical links can be found for a
target area. To show this we selected different uniformly-
distributed subsets of the 1,072 bots used (i.e., PlanetLab
nodes and LG servers); e.g., subsets of 10%, 20%,..., 90%
of all bots. We computed their degradation ratios for three
target areas and plotted those against the baseline degra-
dation ratio produced by all 1,072 bots. Figure 6 shows
that, for each target area, beyond a certain bot-subset size,
the differences in deviations from the baseline degradation
ratios taper off, indicating that additional critical links which
would increase degradation ratios can no longer be found;
i.e., that size is approximately 10% of all bots for Univ1,
20% for Pennsylvania, and 50% for the East Coast. In similar
experiments, if we vary server-subset sizes beyond a certain
target-area related threshold, additional critical links that
would increase the degradation ratios could not be found
any longer. These two experiments suggest that the critical
links we ﬁnd adequately cover the ﬂows toward a target area.
Flow density. To compute ﬂow densities of all persistent
links of the link map, we count the number bot-to-target area
routes on those links. As expected, the distribution of ﬂow
densities is highly non-uniform, namely it follows a power-
law distribution; i.e., a few links have unusually high ﬂow
densities while most of the other links have much lower ﬂow
densities (viz., Section III-A). The power-law distribution
of ﬂow densities makes the Crossﬁre attack very effective
indeed. That is, ﬂooding only a few high ﬂow-density links
would effectively disconnect a large number bot-target area









!

!






 







 








"!

"!






 










 




  



  



































  






 







 




Figure 6: Deviations from baseline degradation ratios for
different bot subsets.

1

0.8

0.6

0.4

0.2

 

o
i
t
a
R
n
o
i
t
a
d
a
r
g
e
D

0

 
0

10

20

30

Number of target links

 

Univ1
Univ2
New York
Pennsylvania
Massachusetts
Virginia
East Coast (US)
West Coast (US)

40

50

Figure 7: Degradation ratios for various target areas for
different numbers of target links.

routes.

After computing the ﬂow densities of all persistent links,
we select a set of target links using the greedy algorithm
speciﬁed in Section IV-D. Recall that we do not select links
that are located close to a target area (more precisely, links
whose distance from the target area is less than or equal
to three hops) to avoid attack detection by any servers in
the target area. For example, the average hop distance from
the selected target links to Univ1 and Univ2 are 3.67 and
4.33, respectively13. Note that even though we eliminate
links that are less than three hops away from the target area,
we can effectively ﬁnd target links with sufﬁciently large
ﬂow densities as discussed in the following subsection.

Degradation ratio. Fig. 7 shows the degradation ratios
for various target areas with different numbers of target
links. As shown in this ﬁgure, the increase in the degradation

13For medium and large areas, the hop distance can be measured relative

to the peripheral servers.

137

)
s
p
b
M

(
 
e
t
a
R
−
d
n
e
S
 
e
g
a
r
e
v
A

3

2

1

0

 

 

Per−Bot (β=100)
Per−Bot (β=200)
Per−Bot (β=500)
Per−DecoyServer

Small area

Medium area

(Univ1)                (Pennsylvania)       (East Coast of USA)

Large area

Figure 8: Per-bot, per-decoy server average send-rates for
different bot cluster sizes (β).

ratio achieved by ﬂooding additional target links diminishes
as we ﬂood more links; e.g., ﬂooding the ﬁrst ﬁve target
links for attacking Univ1 results in an 83% degradation ratio
whereas ﬂooding ﬁve additional target links increases the
degradation ratio by only 6%. This trend clearly shows that
the power-law distribution of the ﬂow density enables the
adversary to achieve a high degradation ratio by ﬂooding
only a few target links. In general, the smaller the target
area, the higher degradation ratio, because smaller target
areas have relatively few links that deliver most of the trafﬁc
to them. For example, when ﬂooding 15 target links, the
degradation ratio of a large area (i.e., West Coast of US) is
as high as 32.85%, that of a medium area (i.e., Virginia) is
as high as 53.05%, and that of a small area (i.e., Univ1) is
as high as 90.52%. This result may be misinterpreted and
conclude that the Crossﬁre attack would damage only small
target areas. In reality, when the attack effects are measured
in terms of the total number of effectively disconnected end-
users (or hosts) in a target area, the attack appears to be
far more lethal to a large target area than a small one. For
example, a Crossﬁre attack against West Coast using 15
target links effectively disconnects only 32.85% of trafﬁc,
yet the number of affected servers is huge.

Attack bots and ﬂows. To ﬂood the selected target
links, we assign attack ﬂows to bots by providing the list
of decoy server IPs and corresponding ﬂow rates. In our
experiments, we set a 4 Kbps per-ﬂow rate, which can be
achieved by sending one HTTP GET message per second,
for the indistinguishability of the Crossﬁre attack. While
maintaining the low per-ﬂow rate, we assign the attack
ﬂows evenly to the multiple bots and decoy servers. We
conservatively assume that the bandwidth of target links is
40 Gbps, which ensures the presence of at least 107 (i.e.,
40 Gbps/4 Kbps ) attack ﬂows through each target link.

Fig. 8 shows the per-bot and per-decoy server average
send-rates for three target areas of different sizes when
ﬂooding ten selected target links. Notice that for the large
bot cluster size (β), we achieve lower per-bot send-rate
since the attack ﬂows can be more evenly distributed. An
important observation is that for any target area, the per-
bot average send-rate can be much lower than 1 Mbps

138

when the bot cluster size (β) equals 500 (i.e., 536,000 bots
in total). This shows that the adversary can aggregate a
sufﬁciently large number (i.e., 107) of low-rate (i.e., 4 Kbps)
attack ﬂows at each selected target link and thus successfully
exceed the bandwidth (i.e., 40 Gbps) of the target link while
maintaining low per-bot and per-decoy server average send-
rates. If the adversary uses more bots and decoy servers in
practice, these average rates would become even lower.

VI. ATTACK CHARACTERISTICS

The Crossﬁre attack has four distinct characteristics which
distinguish it from ordinary DDoS attacks, namely unde-
tectability, attack-ﬂow indistinguishability, ﬂexibility in the
choice of targets, and persistence in terms of attack duration.
Undetectability at the Target Area. The Crossﬁre at-
tack uses all legitimate ﬂows to ﬂood target links. Each
bot creates ordinary connections (e.g., HTTP) with a set
of decoy servers following the adversary’s (i.e., the bot-
master’s) assignments, and hence individual connections do
not trigger an attack alarm at the servers. Since a target area
is not directly attacked and the decoy servers near the target
area do not see any suspicious trafﬁc, the servers in the
target area would be unable to detect the attack. Even decoy
servers would be unable to detect the attack since the well-
coordinated ﬂows to the decoy servers would cause only a
few Mbps bandwidth increase to each server. Furthermore,
the adversary can easily select target links among the links
in the target set that are several hops (i.e., at least 3 hops in
our experiments) away from the target area since links with
high ﬂow density are usually located in the core backbone
networks. This makes it difﬁcult even for the target links to
identify an attack.

Indistinguishability of Flows in Routers. In the Cross-
ﬁre attack, a large number of low-rate attack ﬂows pass
through a target link. Hence, a router connected to the target
link cannot distinguish the attack ﬂows from legitimate ones.
In other words, since all the attack ﬂows carry different
source IP addresses and destination IP addresses, the high
bandwidth aggregation mechanisms (e.g., Pushback [52],
PSP [14]) become ineffective even if they are employed at
all routers along the attack routes. Inspecting the payload
of each packet would not help either because the attack
ﬂows carry the same payload as that of legitimate ﬂows.
Moreover, ﬂooding target links with different sets of bots
(e.g., the rolling attack, viz., Section IV-B) would further
enhance this inherent indistinguishability of attack ﬂows in
routers.

Persistence. The Crossﬁre attack is able to disconnect a
target area persistently by controlling the bot trafﬁc so as not
to trigger any control plane changes (e.g., route changes).
This is achieved by using stable routes in rolling attacks,
which change an active set of target
links dynamically
(viz., Section IV-B). In essence, a rolling attack makes the
Crossﬁre attack a pure data plane attack, thereby leaving

the control plane of the Internet unchanged. This extends
the attack duration virtually indeﬁnitely. The details of the
attack persistence are presented in Section IV-A.

Flexibility. The Crossﬁre attack can be launched against
any target area (regardless of its size) since an adversary
can usually ﬁnd a large number of public servers inside that
target area and decoy servers near it; e.g., the adversary can
select any of the many publicly accessible servers without
needing permission from that server. This offers a great deal
of ﬂexibility in the adversary’s choice of a target area, which
is one of the most important characteristics that distinguish
the Crossﬁre attack from other link-ﬂooding attacks (viz.,
Related Work in Section VII). Our adversary’s choice is
enhanced by its low-rate ﬂows used by the bots since the
resulting attack ﬂows would not trigger individual alarms in
any potential target area.

VII. RELATED WORK

A. Control Plane DDoS Attacks

DDoS attacks against a network link, even if launched
with low-rate trafﬁc, can disrupt a routing protocol (e.g.
BGP) and ultimately trigger instability in the Internet. This
class of attacks, which we call Control Plane DDoS attack,
ﬁrst proposed by Zhang et al. [53], exploits the fact that
the control plane and data plane use the same physical
medium. This fate-sharing allows an unprivileged adversary
to convince a BGP speaking router that its BGP session
has failed. Schuchard et al. in [5] extended this attack to
multiple BGP sessions, which were selected based on the
betweenness centrality measures of the network topology.
They showed that their CXPST attack can generate enough
BGP updates to cripple the Internet’s control plane.

In contrast, the Crossﬁre attack is pure data plane attack,
which maintains the effects of the attack persistently by
suppressing any control plane reaction.

B. Attacks against Links

The recent Coremelt attack [7] demonstrates how a set of
bots can send packets to each other and ﬂood a set of AS
backbone routers. The key characteristic of Coremelt is that
it creates only wanted trafﬁc and thus it eludes all defense
mechanisms that ﬁlter unwanted trafﬁc. Furthermore, this
trafﬁc is not subject to the congestion-control mechanisms
of TCP and can thus exceed typical TCP trafﬁc bounds.
This unique advantage cannot be exploited in Crossﬁre,
since the ends of its attack ﬂows are not bots. Thus,
Crossﬁre uses protocol messages that are unencumbered by
congestion control; e.g., HTTP GET requests. In contrast
with Coremelt, Crossﬁre creates very low intensity trafﬁc
(e.g., 4 Kbps ﬂows) to decoy servers, which can be any
public IP addresses. Furthermore, it can ﬂood any of the
selected target links regardless of the distribution of bots,
and its server-disconnection effects at a target area are easily
predictable. Crossﬁre is more persistent than Coremelt, since

139

Design Goal

Crossﬁre

Coremelt

High

Y

Flexibility of targeting server areas
Bot-distribution independence
Persistence
· Data vs. control plane distinction
· Robustness against route changes
Distribution of target links across multiple ISPs
Indistinguishability at routers
Undetectability at target area servers
Reliance on wanted ﬂows only
(* only if bot-to-bot ﬂow intensity does not exceed router bounds.

Y
Y
Y
N

Higher

N/G
N

Lower

N/G
Y*
N/G
Y

N/G = “Not a design Goal”)

Table VII: Crossﬁre vs. Coremelt [7] Differences

it does not trigger control-plane reaction (e.g., BGP route
changes [5]) and it can easily evade route-change counter-
measures produced by online trafﬁc engineering. Finally,
unlike Coremelt, which targets the backbone routers of
an AS, Crossﬁre aims to select routers and links that are
distributed across ASs of different ISPs, such that no single
ISP could counter the attack. In short, the Crossﬁre attack is
different from Coremelt as it shares neither all the goals nor
the attack techniques of Coremelt. Table VII summarizes the
key differences between Crossﬁre and Coremelt.

C. Large-Scale Connectivity Attacks

The technical underpinnings of the Crossﬁre attack are
also related to research on the robustness of Internet con-
nectivity to attacks that disable routers or links [54, 55, 56].
Albert et al. [54] illustrate that if an adversary disables 4%
of the highly connected routers, the entire Internet would
break up into small isolated pieces. However, later work by
Magoni [55] and Wang et al. [56] concludes that all such
attacks would be infeasible because of the huge number of
routers or links that need to be disconnected.

The main distinction between the Crossﬁre attack and this
line of work is that our notion of (dis)connectivity captures
the practical realities of the Internet; we say that a node A
is (effectively) disconnected from a node B whenever the
persistent route from A to B is severely congested (viz.,
Section II-A2).

The Crossﬁre attack also has a clearly different goal from
the routing attack proposed by Bellovin and Gansner that
cuts multiple network links to attract a certain trafﬁc to
compromised routers for eavesdropping purposes [6].It is
also different from the DoS source-detection technique pro-
posed by Burch and Cheswick [57] whereby a victim server
attempts to ﬂood various routers and measure decreases in
attack trafﬁc – a telltale sign identifying attack sources on
the router’s path.

D. Brute-Force DDoS Attacks

The goals of the Crossﬁre attack are fundamentally dif-
ferent from those of conventional brute-force DDoS attacks
[1, 2, 29, 58] in at
it has a
ﬂexible choice of targets in a much more scalable range

three respects. First,

least

than those of DDoS attacks (e.g., from servers of a single
enterprise, to those of a state or country). Second, its attack
sources (i.e., bot hosts) are undetectable by any targeted
servers, since they do not receive attack messages, and
by network routers, since they receive only low-intensity,
individual ﬂows that are indistinguishable from legitimate
ﬂows. Third, its persistence against the same set of targets
can be extended virtually indeﬁnitely by changing attack
parameters. The Crossﬁre advantage of the ﬂexible choice
of targets in a geographic area is shared by the geo-targeted
DDoS attacks in cellular networks proposed by Traynor et al.
[59]. However, these attacks are less relevant for the Internet.

VIII. CONCLUSION

The proliferation of bot networks seems unavoidable, for
at least as many reasons as that of malware, the primary
reason being successful large-scale social engineering scams
against unsuspecting users world-wide. End-server bots
ﬂooding the Internet router fabric to effectively disconnect
other end-server systems is the penultimate insult to the end-
to-end argument in network design, the ultimate being, of
course, the loss of end-to-end trust caused by malware in
end-servers [60].

The question of whether it is possible to counter an attack
such as Crossﬁre arises naturally given the current Internet
architecture and ISP operations. Preliminary analysis sug-
gests that combinations of multiple countermeasures against
such attacks may, in fact, become necessary. As argued
in Section IV, no single ISP can counter such an attack
whenever the ﬂooded links reside in different ISP domains,
regardless of the quality of trafﬁc engineering techniques
employed by individual ISPs. Whether ISP coordination be-
comes practical despite of competitive concerns, remains to
be seen. Another possibility would be to support application
layer overlays that would route around ﬂooded links by
selecting different server routes in response to link-ﬂooding
alerts. Yet another possibility would be to deter massive
attacks by both preemptive and retaliatory disruption of bot
markets with certainty. This would require analysis of bot
markets along the lines of described by Caballero et al. [41].
Finally, international agreements regarding prosecution of
telecommunication-infrastructure attacks may also become
necessary [61].

ACKNOWLEDGEMENTS

We are grateful to Hsu-Chun Hsiao, Yongdae Kim, Adrian
Perrig, Vyas Sekar, and the symposium reviewers for their
insightful comments and suggestions. This research was
supported in part by CyLab at Carnegie Mellon under
contract W911NF-09-1-0273 from the US Army Research
Ofﬁce, and by the National Science Foundation (NSF) under
grants CNS1040801. The views and conclusions contained
in this document are solely those of the authors and should
not be interpreted as representing the ofﬁcial policies, either
expressed or implied, of any sponsoring institution, the U.S.
government or any other entity.

140

REFERENCES

[1] V. D. Gligor, “Guaranteeing access in spite of distributed
service-ﬂooding attacks,” in Security Protocols Workshop,
2003, pp. 80–96.

[2] J. Mirkovic and P. Reiher, “A taxonomy of DDoS attack and
DDoS defense mechanisms,” SIGCOMM Comput. Commun.
Rev., vol. 34, no. 2, pp. 39–53, Apr. 2004.

[3] F. C. Freiling, T. Holz, and G. Wicherski, “Botnet tracking:
exploring a root-cause methodology to prevent distributed
denial-of-service attacks,” in Proceedings of ESORICS’05.
Berlin, Heidelberg: Springer-Verlag, 2005, pp. 319–335.

[4] D. Dagon, G. Gu, C. Lee, and W. Lee, “A taxonomy of botnet
structures,” in Computer Security Applications Conference.
ACSAC 2007. Twenty-Third Annual, dec. 2007, pp. 325 –339.
[5] M. Schuchard, A. Mohaisen, D. Foo Kune, N. Hopper,
Y. Kim, and E. Y. Vasserman, “Losing control of the in-
ternet: using the data plane to attack the control plane,” in
Proceedings of NDSS 2011. ACM, 2010, pp. 726–728.

[6] S. M. Bellovin and E. R. Gansner, “Using link cuts to attack
internet routing,” Tech. Rep., ATT Research, 2004, Work in
Progress 2003 USENIX.

[7] A. Studer and A. Perrig, “The Coremelt attack,” in Proceed-
ings of ESORICS’09. Berlin, Heidelberg: Springer-Verlag,
2009, pp. 37–52.

[8] J. Nazario, “DDoS attack trends through 2009-2011,” NANOG

54, Feb. 2012.

[9] P. Ferguson, “Network Ingress Filtering: Defeating Denial of
Service Attacks which employ IP Source Address Spooﬁng,”
RFC 2827, 2000.

[10] A. Yaar, A. Perrig, and D. Song, “SIFF: A Stateless Internet
Flow Filter to Mitigate DDoS Flooding Attacks,” in Proceed-
ings of the IEEE Security and Privacy Symposium, 2004.

[11] Xiaowei Yang and David Wetherall and Thomas Anderson,
“A DoS-limiting network architecture,” in SIGCOMM ’05,
2005.

[12] R. Moskowitz and P. Nikander, “Host Identity Protocol (HIP)

Architecture,” RFC 4423, 2006.

[13] D. G. Andersen, H. Balakrishnan, N. Feamster, T. Koponen,
D. Moon, and S. Shenker, “Accountable Internet Protocol
(AIP),” in ACM SIGCOMM, 2008.

[14] J. C.-Y. Chou, B. Lin, S. Sen, and O. Spatscheck, “Proactive
Surge Protection: a defense mechanism for bandwidth-based
attacks,” IEEE/ACM Transactions on Networking (TON),
vol. 17, no. 6, pp. 1711–1723, 2009.

[15] A. Feldmann, A. Greenberg, C. Lund, N. Reingold, J. Rex-
ford, and F. True, “Deriving trafﬁc demands for operational IP
networks: methodology and experience,” in ACM SIGCOMM
Computer Communication Review, vol. 30, no. 4. ACM,
2000, pp. 257–270.

[16] N. Wang, K. Ho, G. Pavlou, and M. Howarth, “An overview
of routing optimization for Internet trafﬁc engineering,” Com-
munications Surveys Tutorials, IEEE, vol. 10, no. 1, pp. 36
–56, quarter 2008.

[17] K. Levanti, “Routing management in network operations,”

Ph.D. dissertation, Carnegie Mellon University, 2012.

[18] M. Faloutsos, P. Faloutsos, and C. Faloutsos, “On power-
law relationships of the internet topology,” in Proceedings
of SIGCOMM ’99. ACM, 1999, pp. 251–262.

[19] A. Lakhina, J. W. Byers, M. Crovella, and P. Xie, “Sampling
biases in IP topology measurements,” in Proceedings of
INFOCOM, vol. 1.

IEEE, 2003, pp. 332–341.

[20] M. E. Newman, “A measure of betweenness centrality based
on random walks,” Social networks, vol. 27, no. 1, pp. 39–54,
2005.

[21] I. Cunha, R. Teixeira, and C. Diot, “Measuring and charac-
terizing end-to-end route dynamics in the presence of load
balancing,” in Proceedings of PAM’11. Berlin, Heidelberg:
Springer-Verlag, 2011, pp. 235–244.

[22] Y. Amir and C. Danilov, “Reliable communication in overlay
networks,” IEEE/IFIP International Conference on Depend-
able Systems and Networks (DSN 2012), vol. 0, p. 511, 2003.
[23] A. D. Keromytis, V. Misra, and D. Rubenstein, “SOS: secure
overlay services,” in Proceedings of SIGCOMM ’02. New
York, NY, USA: ACM, 2002, pp. 61–72.

[24] J. Sherry, E. Katz-Bassett, M. Pimenova, H. V. Madhyastha,
T. Anderson, and A. Krishnamurthy, “Resolving IP aliases
with prespeciﬁed timestamps,” in Proceedings of IMC ’10.
New York, NY, USA: ACM, 2010, pp. 172–178.

[25] W. Willinger, D. Alderson, and J. C. Doyle, “Mathematics
and the Internet: A source of enormous confusion and great
potential,” American Mathematical Society, 2009.

[26] B. Augustin, T. Friedman, and R. Teixeira, “Measuring load-
balanced paths in the internet,” in Proceedings of IMC ’07.
New York, NY, USA: ACM, 2007, pp. 149–160.

[27] V. Paxson, “End-to-end routing behavior in the internet,” in
Proceedings on SIGCOMM ’96. New York, NY, USA: ACM,
1996, pp. 25–38.

[28] R. Cohen and L. Katzir, “The generalized maximum coverage
problem,” Information Processing Letters, vol. 108, no. 1, pp.
15 – 22, 2008.

[29] J. Jung, B. Krishnamurthy, and M. Rabinovich, “Flash crowds
and denial of service attacks: characterization and implica-
tions for CDNs and web sites,” in Proceedings of WWW ’02.
New York, NY, USA: ACM, 2002, pp. 293–304.

[30] A. Clauset, C. R. Shalizi, and M. E. J. Newman, “Power-Law
Distributions in Empirical Data,” SIAM Review, vol. 51, no. 4,
pp. 661–703, 2009.

[31] O. Narayan and I. Saniee, “Scaling of load in communications

networks,” Phys. Rev. E, vol. 82, p. 036102, Sep 2010.

[32] M. P. H. Stumpf and M. A. Porter, “Critical truths about
power laws,” Science, vol. 335, no. 6069, pp. 665–666, 2012.
[33] S. Ross, Introduction to Probability and Statistics for En-
gineers and Scientists, ser. Wiley series in probability and
mathematical statistics. Academic Press/Elsevier, 2009.

[34] A. Shaikh, A. Varma, L. Kalampoukas, and R. Dube, “Rout-
ing stability in congested networks: Experimentation and
analysis,” in Proc. of ACM SIGCOMM, 2000, pp. 163–174.
[35] P. Francois, C. Filsﬁls, J. Evans, and O. Bonaventure,
“Achieving sub-second IGP convergence in large IP net-
works,” SIGCOMM CCR, vol. 35, no. 3, pp. 35–44, Jul. 2005.
[36] G. Iannaccone, C.-N. Chuah, S. Bhattacharyya, and C. Diot,
“Feasibility of ip restoration in a tier 1 backbone,” Network,
IEEE, vol. 18, no. 2, pp. 13 – 19, mar-apr 2004.

[37] B. Fortz, J. Rexford, and M. Thorup, “Trafﬁc engineering with
traditional IP routing protocols,” Communications Magazine,
IEEE, vol. 40, no. 10, pp. 118 – 124, oct 2002.

[38] B. Davie and A. Farrel, MPLS: Next Steps, ser. Morgan
Kaufmann Series in Networking. Elsevier/Morgan Kaufmann
Publishers, 2008.

[39] T. Nadeau, MPLS Network Management: MIBs, Tools, and
Techniques, ser. Morgan Kaufmann Series in Networking.
Elsevier Science, 2002.

[40] N. Hu, L. E. Li, Z. M. Mao, P. Steenkiste, and J. Wang,
“Locating internet bottlenecks: algorithms, measurements,
and implications,” in Proceedings of SIGCOMM ’04. New
York, NY, USA: ACM, 2004, pp. 41–54.

[41] J. Caballero, C. Grier, C. Kreibich, and V. Paxson, “Mea-
suring Pay-per-Install: The Commoditization of Malware

141

Distribution,” in Proceedings of the 20th USENIX Security
Symposium, Aug. 2011.

[42] IEEE Policies.

IEEE, February 2012, ch. 7.8 IEEE Code of

Ethics.

[43] “ACM Code of ethics and professional conduct,” Commun.

ACM, vol. 35, no. 5, pp. 94–99, May 1992.

National
potential

[44] FBI
lion
http://www.fbi.gov/news/pressrel/press-releases/
over-1-million-potential-victims-of-botnet-cyber-crime,
June 13, 2007.

Press
victims

Ofﬁce,
of

botnet

“Over

cyber

one

mil-
crime,”

[45] PlanetLab., “http://www.planet-lab.org/.”
[46] Traceroute.org, “Public route server and looking glass site

list,” http://www.traceroute.org/.

[47] L. Subramanian, S. Agarwal, J. Rexford, and R. Katz,
“Characterizing the internet hierarchy from multiple vantage
points,” in Proceedings of INFOCOM 2002, vol. 2, 2002, pp.
618 – 627 vol.2.

[48] F. Wang and L. Gao, “On inferring and characterizing Internet
routing policies,” in Proceedings of IMC ’03. New York, NY,
USA: ACM, 2003, pp. 15–26.

[49] B. Augustin, B. Krishnamurthy, and W. Willinger, “IXPs:
mapped?” in Proceedings of IMC ’09. New York, NY, USA:
ACM, 2009, pp. 336–349.

[50] D. Dagon, C. Zou, and W. Lee, “Modeling botnet propagation
using time zones,” in In Proceedings of the 13 th Network and
Distributed System Security Symposium NDSS, 2006.

[51] S. Staniford, V. Paxson, and N. Weaver, “How to own the
Internet
the 11th
USENIX Security Symposium. Berkeley, CA, USA: USENIX
Association, 2002, pp. 149–167.

in your spare time,” in Proceedings of

[52] R. Mahajan, S. M. Bellovin, S. Floyd, J. Ioannidis, V. Paxson,
and S. Shenker, “Controlling high bandwidth aggregates in the
network,” SIGCOMM Comput. Commun. Rev., vol. 32, no. 3,
pp. 62–73, Jul. 2002.

[53] Y. Zhang, Z. M. Mao, and J. Wang, “Low-rate TCP-targeted
DoS attack disrupts internet routing,” in Proc. 14th Annual
Network & Distributed System Security Symposium, 2007.

[54] R. Albert, H. Jeong, and A.-L. Barabasi, “Error and attack
tolerance of complex networks,” NATURE, vol. 406, p. 378,
2000.

[55] D. Magoni, “Tearing down the Internet,” Selected Areas in
Communications, IEEE Journal on, vol. 21, no. 6, pp. 949 –
960, aug. 2003.

[56] Y. Wang, S. Xiao, G. Xiao, X. Fu, and T. H. Cheng,
“Robustness of complex communication networks under link
attacks,” in Proceedings of ICAIT ’08. New York, NY, USA:
ACM, 2008, pp. 61:1–61:7.

[57] H. Burch and B. Cheswick, “Tracing anonymous packets to
their approximate source,” in Proceedings of the 2000 Usenix
LISA Conference, 2000, pp. 319–327.

[58] D. Moore, G. Voelker, and S. Savage, “Inferring Internet
Denial-of-Service Activity,” in Proceedings of the 10th Usenix
Security Symposium, 2001, pp. 9–22.

[59] P. Traynor, W. Enck, P. Mcdaniel, and T. La Porta, “Exploiting
open functionality in SMS-capable cellular networks,” Jour-
nal of Computer Security, vol. 16, no. 6, pp. 713–742, 2008.
[60] D. D. Clark and M. S. Blumenthal, “The end-to-end argu-
ment and application design: The role of trust,” in Federal
Communications Law Journal, vol. 63, 2011, pp. 357–390.

[61] International Telecommunication Union, “http://www.itu.int.”

