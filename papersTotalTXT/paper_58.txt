VeriStream – A Framework for Veriﬁable Data

Streaming

Dominique Sch¨oder and Mark Simkin

Saarland University
Saarbr¨ucken, Germany

Abstract In a Veriﬁable Data Streaming (VDS) protocol a compu-
tationally weak client outsources his storage to an untrusted storage
provider. Later, the client can eﬃciently append and update data ele-
ments in the already outsourced and authenticated data set. Other users
can stream arbitrary subsets of the authenticated data and verify their
integrity on-the-ﬂy, using the data owner’s public veriﬁcation key. In this
work, we present VeriStream, a fully-ﬂedged open source framework for
veriﬁable data streaming with integration into Dropbox. At its core, our
framework is based upon a novel construction of an authenticated data
structure, which is the ﬁrst one that allows veriﬁable data streams of
unbounded length and at the same time outperforms the best known
constructions in terms of bandwidth and computational overhead. We
provide a detailed performance evaluation, showing that VeriStream only
incurs a small bandwidth overhead, while providing various security guar-
antees, such as freshness, integrity, authenticity, and public veriﬁability,
at the same time.

1

Introduction

Cloud storage providers like Dropbox, Amazon Cloud Drive, and Google Drive
are on the rise and constantly gain popularity. Users are able to outsource their
storage into the “cloud” of some dedicated provider and access or share their
data with others later on. The advantages of cloud storage are manifold. Among
many, users are no longer bound to speciﬁc devices or locations when accessing
their data and users can share or collaborate on their data with others easily.
Many of these providers allow their users to retrieve, i.e. stream, smaller subsets
of the initially outsourced data set. In the case of multimedia content, prominent
examples are YouTube and SoundCloud. They allow users to upload their audio
and video ﬁles and share them with others. A diﬀerent user can stream the
whole uploaded ﬁle or just smaller parts of it. This streaming scenario is not
solely limited to multimedia content. Another interesting example can be found
in the stock market. Here, stock brokers base their purchasing decisions on the
latest published stock quotes. These stock quotes are published by trusted stock
managers and distributed through web services like Yahoo Finance or quote.com
Brokers use these services to stream the latest published stock quotes and buy
or sell stocks accordingly.

state
[22]
Dynamic O(log M) O(1)
δ-bounded O(log M) O(1)

Proof Client’s Upload Update Streaming Unbounded Security
size
time/space time/space time/space
O(log N) O(log N) O(log N) O(log N) O(log N)
O(log M) O(log M) O(log M)
O(log M) O(log M) O(log M)

proof
Standard





ROM

Standard

Table 1. Comparison of existing and proposed CAT constructions. N is the upper
bound of elements that can be authenticated, whereas M is the number of already
authenticated elements. Security proof indicates whether the construction’s proof of
security is given in the standard model or whether it requires the random oracle model.

All these scenarios have in common that the users have to trust the storage
provider that streams the content back to the requesting user. Currently, there
are little or no mechanisms in place to protect and ensure the integrity of such
dynamic streamed content. A ﬁrst step towards solving this problem was done
in [22], where the problem of Veriﬁable Data Streaming (VDS) was deﬁned on
a theoretical level. The authors provided a ﬁrst solution based on generalized
Merkle-Trees, so called Chameleon Authentication Trees (CATs), that allow a
data owner, having a secret signing and a public veriﬁcation key, to upload his
content in a unidirectional fashion. That is, the owner can upload and append
data to the existing data set by sending one message per chunk to the server,
without needing to update his public veriﬁcation key after each transmitted data
chunk. In addition, the CAT allows the data owner to eﬃciently update arbitrary
subsets of the authenticated outsourced data set, without the need to re-upload
or re-authenticate any of the elements that are not updated. After an update,
the veriﬁcation key is updated to invalidate the stale data elements, however all
other data elements remain authenticated under the new veriﬁcation key.

1.1 Our Contribution
On the practical side, we present VeriStream, the ﬁrst fully-ﬂedged framework
for providing streaming applications with security guarantees, such as stream
authenticity, integrity, correct ordering of the streamed elements, public veriﬁ-
ability, and eﬃcient updates simultaneously. The VeriStream standalone client
can be used upload, update, and stream content from personal web servers. In
addition, VeriStream allows its users to use their Dropbox account as the un-
derlying storage layer. Apart from up- and downloading arbitrary ﬁles in an
authenticated fashion, our framework also supports video and audio streaming
with on-the-ﬂy veriﬁcation. In Section 5 we provide a detailed performance eval-
uation of VeriStream and compare its performance to the construction from [22].
On the theoretical side we improve upon the state-of-the-art for veriﬁable
data streaming [22]. Their construction is upper bounded during the initializa-
tion by some parameter N, meaning that it can authenticate up to N elements.
Their construction incurs a computational and bandwidth overhead of O(log N)
for each outsourced, updated, or streamed element. The size of their client’s state
is O(log N). In particular this means, either N is chosen large, e.g. polynomial,
to be able to authenticate a quasi unbounded amount of elements, which incurs

a prohibitively large overhead, or N is chosen small, which in turn means that
the resulting construction can only authenticate a limited number of elements.
We propose two novel constructions. The ﬁrst one, the fully-dynamic CAT,
is the ﬁrst scheme that can authenticate an unbounded number of elements and
is secure in the random oracle model. The second one, the δ-bounded CAT,
has an upper bound on the number of elements it can authenticate, and we
prove its security in the standard model. Both of our constructions only incur
a computational and bandwidth overhead of O(log M) for each outsourced, up-
dated, or streamed element, where M is the number of authenticated elements
so far. Note that in general the number of outsourced elements M is signiﬁcantly
smaller than the upper bound N. The size of our client’s state is O(1). For a
concise comparison of the existing and our proposed constructions see Table 1.

1.2 System Overview
In this section we outline the high-
level workﬂow and usage of VeriStream
based on the classic task of outsourc-
ing and sharing data. An overview is
given in Figure 1. The major entities
are the data owner, other clients that
may read data uploaded by the data
owner, and the untrusted server stor-
ing the data. To allow an easy in-
tegration of our framework into al-
ready deployed systems, we designed
VeriStream to coexist with the ex-
isting system. This means that our
framework does not directly alter or
modify any of the transmitted data,
but only appends and strips its own
additional data to and from the trans-
mitted data chunks. All involved enti-
ties use VDS handlers to authenticate
or verify transmitted data. When the data owner wants to upload some data to
the server, he initializes his local VDS handler with his secret key. Rather than
transmitting all data chunks directly to the server, they are passed through the
VDS handler, which authenticates them on-the-ﬂy by appending a proof of cor-
rectness to the data chunk. The retrieving server uses his VDS handler to strip
the proof from each data chunk. The data itself is stored in a database and the
proofs are stored in a CAT. It should be noted, that uploading data to the server
does not require the owner to update his veriﬁcation key after each chunk, which
would put an unrealistic burden on the public directory or PKI that handles the
keys.

Figure 1.
VeriStream.

A client can request data chunks by transmitting their indices. The server
fetches the data chunks from the database and computes the corresponding

High-level

overview

of

proofs of correctness using his VDS handler, which has access to the CAT. The
data and the appended proofs are sent to the client, who can verify the correct-
ness and authenticity of each received data chunk separately on-the-ﬂy, using
the VDS handler and the data owner’s public veriﬁcation key.

When the data owner wants to update some data chunk in the database,
he ﬁrst receives the element the same way other clients do. After verifying the
authenticity of the retrieved chunk, he uses his VDS handler in combination
with the retrieved data chunk, its proof of correctness, and the new data chunk
to compute a new proof of correctness for the new chunk. The new data chunk
with the appended proof is then sent to the server. The owner updates his public
veriﬁcation key at the PKI or the public directory. This is necessary to invalidate
the now stale chunk and protect other users from retrieving old data from the
server. However, even though the owner only requested and modiﬁed the updated
chunk, all other outsourced data chunks remain valid under the new veriﬁcation
key.

1.3 Related Work
Veriﬁable data streaming (VDS) protocols have been introduced by Schr¨oder
and Schr¨oder [22]. The authors formalized the problem on a theoretical level
and gave a ﬁrst construction for a bounded number of elements. Their short-
comings in comparison to our constructions are already discussed in Section 1.1.
A related line of research investigates veriﬁable databases (VDBs). VDBs have
been extensively investigated in the context of accumulators [16,5,6] and authen-
ticated data structures [15,14,19,26]. These approaches, however, often rely on
non-constant assumptions, such as the q-Strong Diﬃe-Hellman assumption, as
observed in [4]. More recent works, such as [4] or [8], only support a polynomial
number of values instead of exponentially many, and the scheme of [4] is not
publicly veriﬁable. Furthermore, the VDB schemes require the data owner to
update his veriﬁcation key after each newly uploaded element. In contrast, in a
VDS protocol, data can be added non-interactively and without updating the
veriﬁcation key by sending a single message to the server. VDS can be seen as a
generalization of VDBs.

Another line of research deals with (dynamic) proofs of retrievability (PoR).
Here, the client uploads his data to some untrusted server. A PoR protocol al-
lows the user to eﬃciently verify, whether all of his data is still stored on the
server [24,10,23,7]. A weaker form of PoR are so called proofs of data posses-
sion [9]. They only ensure that the server stores most of the data. In these
scenarios the protocols only ensure that all or most of the data is stored, but
they do not provide any security guarantees w.r.t. the authenticity of streamed
content.

Recently, the notion of streaming authenticated data structures was intro-
duced by Papamanthou, Shi, Tamassia and Yi [18], where a computationally
weak client and a server observe a stream of data independently. Afterwards the
client can perform range queries and verify the results from the server against a
veriﬁcation value it computed while observing the stream. However both notions

diﬀer in the following aspects: The veriﬁcation token of their scheme changes af-
ter each streamed/uploaded element, while ours does not. In their scheme, no
secret key is involved, which means that a client can only verify responses if he
has either seen the seen stream, or if he obtained the veriﬁcation token from a
trusted party. Furthermore, since the key changes after each new element, all
elements that are transmitted after receiving the veriﬁcation token cannot be
veriﬁed. Our proofs are logarithmic in the size of the uploaded dataset, while
theirs are logarithmic in the size of the universe from which the elements are
drawn. Finally, we provide comprehensive benchmark results, while their work
only provides a asymptotical run time analysis.

Another successful line of research consider “pure” streaming protocols be-
tween a sender and possibly multiple clients, such as TESLA and their variants
such e.g., [21,20]. In contrast to our setting, the TESLA protocols assume that
the sender and the receiver are loosely synchronized and these protocols do not
oﬀer public veriﬁability. The signature based solution of [21] is also diﬀerent,
because the protocol does not support eﬃcient updates, which is a necessary
property for our applications, such as e.g., veriﬁable cloud storage.
Na¨ıve Approaches: There are a few seemingly simple solutions to the de-
scribed problem, which do not work. In this paragraph we would like to discuss
the shortcomings of some of them. The ﬁrst idea might be to use a simple Merkle
Tree. In a Merkle tree the data is stored in the leaves and the value of each inter-
nal node is deﬁned as the hash of the concatenation of its children’s values. The
veriﬁcation key is the value of the root node and a proof of correctness for some
data chunk consists of all nodes that are required to compute the root node’s
value starting from the leaf, where the data chunk is stored. This solution would
recompute the tree after each uploaded element. This means, that whenever we
upload some new data chunk, the veriﬁcation key is updated, which puts an
infeasible burden on the public directory or PKI that stores the public keys. A
diﬀerent approach would be to use signature chains, i.e. for all two adjacent data
chunks we compute one signature. Here, the problem is that eﬃcient updates
are not possible. When updating a data chunk, we need to invalidate its old
version, but here the veriﬁcation key is just the signature’s public key and does
not depend on the uploaded data itself. The data owner would need to update
the signature’s public key and recompute all signature in the chain, which is
clearly infeasible. The same argument also holds for forward-secure signature
schemes [13], where the secret key is updated from time to time. Since the pub-
lic key remains the same, freshness cannot be ensured, i.e. a user is not able to
distinguish the fresh data chunk from a stale version thereof.

2 Chameleon Authentication Trees

Our formal deﬁnition of CATs diﬀers slightly from [22], since we directly model
updates as a property of the CATs. This allows us to build VDS protocols in a
black-box way from CATs, while [22] needed to make speciﬁc nonblack-box as-

sumptions about the proof that might not hold in general. The second diﬀerence
is that we do not put an upper bound on the number of leaves. Thus, the only
input of catGen is the security parameter. The formal deﬁnition of VDS itself is
deferred to Appendix A.

Deﬁnition 1. A chameleon authentication tree is a tuple of eﬃcient algorithms
ΠCAT = (catGen, catAdd, catUpdate, catVerify), which are deﬁned as follows:

catGen(1λ): The key generation algorithm takes the security parameter λ and
outputs a key pair (vp, sp). For simplicity we always assume that vp is con-
tained in sp.
catAdd(sp, ‘): The insertion algorithm takes a secret key sp, and a datum ‘ from
some data space L. It outputs a new secret key sp0, a position i at which ‘
was inserted and a proof πi, which is a publicly verifable proof showing that
‘ is indeed stored at position i.
catUpdate(sp, i, ‘): The update algorithm takes the secret key sp, a position i at
which we want to perform the update, and the new datum ‘ ∈ L as input. It
replaces the current datum at i with ‘ and outputs a new key pair (vp0, sp0)
as well as a proof πi for the new datum.

catVerify(vp, i, ‘, πi): The veriﬁcation algorithm takes the public key vp, a posi-
tion i, a datum ‘ and a proof πi as input and outputs 1 iﬀ ‘ is stored at
position i. It outputs 0 otherwise.

Security of CATs: Our security deﬁnition deviates from the one given in [22],
by taking update queries of the adversary into account. We present a single
deﬁnition that covers both, structure-preservation and one-wayness. Intuitively,
we say that a CAT is secure if no eﬃcient adversary can modify the tree by
changing the sequence of the data stored in it, substituting any datum, or by
adding further data to it. In particular, the deﬁnition also prevents the adversary
from returning stale to clients. The game is deﬁned as follows:
Setup: The challenger generates a key-pair (sp, vp) ← catGen(1λ) and hands vp
over to the adversary A.
Uploading: Proceeding adaptively, the attacker A uploads a datum ‘ ∈ L to
the challenger. The challenger adds ‘ to the database, computes (sp0, i, ˆπ) ←
catAdd(sp, ‘), and returns (i, ˆπ) to A. Alternatively, the adversary may up-
date any element in the outsourced database by sending an index i, a datum
‘0 to the challenger. The challenger then runs the update algorithm with
A updating ‘i to ‘0. At the end of the update protocol the challenger re-
i and the updated public-key vp0 to A. Denote by
turns the updated proof π0
Q := {(‘1, 1, ˆπ1), . . . , (‘q(λ), q(λ), ˆπq(λ))} the ordered sequence of the latest
versions of all uploaded elements and let vp∗ be the corresponding public
key.
Output: Eventually, A outputs (‘∗, i∗, ˆπ∗). The attacker A is said to win the

game if one of the following two conditions is true:
a) If 1 ≤ i∗ ≤ q(λ) and (‘∗, i∗, ˆπ∗) 6∈ Q and catVerify(vp∗, i∗, ‘∗, ˆπ∗) = 1.

b) If i∗ > q(λ) and catVerify(vp∗, i∗, ‘∗, ˆπ∗) = 1.

We deﬁne AdvsecA to be the probability that the adversary A wins in the above
game.

Deﬁnition 2. A chameleon authentication tree ΠCAT = (catGen, catAdd, catUpdate,
catVerify) is secure if for any q ∈ N, and for any eﬃcient algorithm A, the prob-
ability AdvsecA evaluates to 1 is negligible (as a function of λ).

3 Constructing Fully Dynamic CATs

We now present our fully dynamic CAT construction, which is the ﬁrst con-
struction that is able to authenticate an unbounded number of data elements
and improves upon the state-of-the-art in terms of computational and band-
width overhead. In the following we ﬁrst recall the deﬁnition of chameleon hash
functions and then present our construction.

3.1 Chameleon Hash Functions

A chameleon hash function is a randomized hash function that is collision-
resistant but provides a trapdoor to eﬃciently compute collisions. It is deﬁned
through the tuple CH = (chGen, ch, col) [12], where the key generation algorithm
chGen(1λ) returns a key pair (csk, cpk). We set ch(·) := ch(cpk,·) for the remain-
der of this paper. The function ch(x; r) produces a hash value h ∈ {0, 1}out for
a message m ∈ {0, 1}in and a randomness r ∈ {0, 1}λ. The function is collision-
resistant meaning that given cpk it is computationally diﬃcult to compute a
tuple (m, r), (m0, r0) such that (m, r) 6= (m0, r0) and ch(m, r) = ch(m0, r0). How-
ever, using the trapdoor csk and the collision-ﬁnding algorithm col(csk, x, r, x0)
we can break the collision-resistance property and ﬁnd a value r0 such that both,
(x, r) and (x0, r0) map to the same hash value.

We call CH invertible if it is surjective and there exists an eﬃcient algorithm
scol(csk, x, y) that outputs an r for any input x and y such that y = ch(x; r).
This property has previously been deﬁned by Shamir and Tauman [25].

Chameleon hash functions can be instantiated from the discrete-logarithm
assumption [12,2], the factoring assumption [25], the RSA assumption [2,11], or
in a generic way from certain Σ-protocols [3].

3.2 Intuition

The main idea of our construction is to build a binary tree, which stores the
data elements in its leaves and grows dynamically from bottom up. Whenever
the tree of a certain depth d is full, the data owner can increase the tree’s depth

by one using his secret trapdoor. The resulting tree is of depth d + 1 and can
therefore store another 2d elements. The previous full tree becomes the left child
under the new root and the right child serves as a place holder for an empty
subtree, which can be used to store new data.

This new approach of dynamically increasing the depth of the tree means
that we cannot simply store the root node’s value in the public key, since it
changes whenever the depth is extended. Instead, our idea is to deﬁne the new
root through a deterministic function that is applied to a ﬁxed value in the public
key and depends on the current depth of the tree. More precisely, let ρ be the
value in the public key pk and assume that the depth of the tree is d. Then, the
root node is deﬁned as H d(ρ), where H is a collision-resistant hash function and
by H d(ρ) we denote the d-fold application of H to ρ.

Our binary tree is structured as follows: Each node value is computed as the
output of a function of the concatenated values of its children. For nodes which
are left children themselves we use a collision-resistant hash function. For right
children we use a chameleon hash function. The only exception to this rule are
all nodes, that have been a root at some point, i.e., all nodes at the very left of
each level. We insert the data elements into the trees starting from the leftmost
leaf moving to the right. Whenever we insert some data element into a leaf we
have to ensure that, roughly speaking, the root node’s value computed from that
leaf remains the same as before the insertion. Therefore, we search for a node
computed by a chameleon hash function on the path from the inserted leaf to
the root and compute an appropriate collision using our secret trapdoor.

In the following, we exemplify basic idea of our construction with a small
example, where we will refer to a node v at height h and index i by vh,i. Please
note, even though we will be including two leaves at the same time, this should
not be seen as a restriction or a problem. It is done for the sake of clarity and
the construction can be easily extended to insert one leaf at a time, as it is done
in our framework.
Setup: We compute (cpk, csk) ← chGen(1λ) using the key generation algorithm
of the chameleon hash function. The setup algorithm stores the trapdoor csk
of the chameleon hash function in the private key sk; the corresponding public
veriﬁcation key pk contains cpk and a randomly chosen value ρ. At the beginning
of the streaming protocol, the tree is empty.
Appending the elements ‘1, ‘2: In the ﬁrst step, we append the elements ‘1
and ‘2 to the tree. Since the tree is empty, i.e. it has depth 0, it is necessary
to increase its depth by one. In order to add ‘1 and ‘2 to the tree without
changing the root, the data owner uses his secret trapdoor to compute r1,0 ←
scol(csk, ‘1k‘2, H1(ρ)). Hence ch(‘1k‘2; r1,0) = H(ρ). Recall that scol outputs
some randomness r when given (y, x) and the secret key csk such that y =
ch(x; r). At this stage the entire tree consists only of two leaves and one root
node as depicted in Figure 2 (level 1). To verify that the leaves (‘1, ‘2) are in the
tree, the veriﬁcation algorithm checks whether H1(ρ) = ch(‘1k‘2; r1,0) holds.

Figure 2. The fully dynamic CAT. Green nodes are computed using the chameleon
and black nodes using the collision-resistant hash functions. The tree stores 2i elements
at level i.

Appending the elements ‘3, ‘4: Next, we add ‘3 and ‘4 to the tree. Since the
current tree is full, we need to extend its height to obtain new free leaf positions.
Therefore, we pick a random x1,1 and r1,1 and we compute the dummy node
v1,1 ← ch(x1,1; r1,1). The randomly chosen pre-images are stored by the client
in his secret local state. To ensure the integrity of the tree, we need to ﬁnd a
randomness r2,0 for the new root v2,0 such that ch(H1(ρ)kv1,1; r2,0) = H2(ρ).
Again, this is achieved by exploiting the inversion property of the chameleon
hash function to compute r2,0 ← scol(csk, H1(ρ)kv1,1, H2(ρ)). We can now add
our leaves ‘3 and ‘4 to the tree by appending them to the lowest free right child,
1,1 ← col(csk, x1,1, r1,1, ‘3k‘4). The resulting
which is v1,1. Thus, we compute r0
proof for ‘3, ‘4 would therefore contain (v1,0, r2,0, r1,1). The corresponding tree
is shown in Figure 2 (level 2).
Appending the elements ‘5, ‘6 and ‘7, ‘8: Since the tree is full again, we
need to increase its depth the same way we did before. Afterwards, we search
for the lowest right child, which does not have any children yet. In this case
the node is v2,1 that has been computed by ch(x2,1; r2,1). The dummy values
(x2,1, r2,1) can be retrieved from the local client state. In order to append ‘5
and ‘6, we generate an empty subtree below v2,1. This subtree consists of a
dummy node v1,3 and the leaves ‘5 and ‘6. After appending ‘5 and ‘6 below
2,1 ← col(csk, x2,1, r2,1, v1,2kv1,3). The proof for these elements
v1,2, we compute r0
contains (r0
2,1, v1,3, v2,0). Next, ‘7 and ‘8 can authenticated by appending them
to v1,3 and computing a collision in the same fashion as in the previous steps.
Verification: The veriﬁcation algorithm works analogously to the one of a
Merkle tree. One might get the impression that the size of the proofs grows
with the number of leaves for all leaves. This, however, is not the case. For
instance, the node v1,0 veriﬁes the leaves ‘1 and ‘2 even if 250 elements are
stored in the tree. The veriﬁcation algorithm still simply checks whether H(ρ) =
ch(‘0k‘1; r1,0).

level 1level 2level 4H(ρ)H(H(ρ))H(H(H(ρ)))v1,0v1,1v2,0v2,1v3,0v1,2v1,3v1,4v1,5v1,6v1,7v2,2v2,3v3,1v4,0l1l2l3l4l5l6l7l8l9l10l11l12l13l14l15l16Updating the Tree: Whenever we wish to update the i-th element in the
database to some element ‘0
i, we simply replace the element, recompute the
values on the path from ‘0
i to the corresponding root node, pick a fresh value ρ0,
and update all sub-roots w.r.t. ρ0. Updating the sub-roots means that the client
has to compute logarithmically many collisions.
Constant State: In the intuitive description of our construction, the client’s
state is logarithmic in the depth of the tree, since all created dummy nodes
y ← ch(x; r) are stored by the client. To reduce the client’s state to O(1) we
use a pseudorandom function PRF to compute the dummy elements on the ﬂy.
That is, for each dummy node vh,i, the clients computes the pair (xh,i, rh,i) ←
PRF(k, hki), rather than choosing it randomly. This allows us to recompute the
dummy nodes we need on-the-ﬂy without storing them.

The secret seed of the PRF is stored as part of the secret key. Therefore, the
ﬁnal secret key in our construction consists of the trapdoor csk of the chameleon
hash function, the seed k of the PRF, and a counter c that keeps track of the
next free leaf index. In practice and in our framework, one can instantiate the
PRF using a symmetric encryption scheme, such as AES.

3.3 Formal Construction

We now provide a detailed description of all algorithms, that have been sketched
in the previous section. We avoid using the PRF in this description for the sake
of clarity, but the modiﬁcation is absolutely straightforward as described above.

Construction 1 Let H : {0, 1}∗ 7→ {0, 1}len be a hash function and CH =
(chGen, ch, col, scol) an invertible chameleon hash function that maps strings
of length {0, 1}∗ to {0, 1}len. The fully-dynamic chameleon authentication tree
ΠCAT = (catGen, catAdd, catUpdate, catVerify) consists of the following eﬃcient
algorithms:
catGen(1λ): The setup algorithm generates a key-pair of the chameleon hash
(cpk, csk) ← chGen(1λ), it picks a uniformly random value ρ ← {0, 1}λ, and
denote by st the private state. This state stores the next free leaf index c, a set
of pre-images of unused dummy nodes and the last computed proof. Initially we
set c ← 0, while the set of pre-images and the last computed proof are both
empty. It returns the public veriﬁcation key vp = (cpk, ρ) and the private key
sp = (csk, st, vp).
catAdd(sp, ‘): Parse sp as (csk, st, vp) and check whether the current tree is full,
i.e., whether c is a power of two:
The counter c is a power of two: In this case the current tree is full, we
need to increase its current depth by one to obtain a tree of depth d, which
has free leaves again. To do so, we store the old root node H d−1(ρ) as the left
child of the new root node H d(ρ) and we create a dummy node vd−1,1 for the

right child as follows: First, we pick the values xd−1,1 and rd−1,1 uniformly at
random and we compute the dummy node vd−1,1 ← ch(xd−1,1; rd−1,1). Second,
we exploit the inversion property of the chameleon hash function in order to
compute rd,0 ← scol(csk, H d−1(ρ)kvd−1,1, H d(ρ)). Next, we add (xd−1,1, rd−1,1)
to the set of pre-images and vd−1,1 to the proof in st and proceed as in the case
where c is not a power of two.
The counter c is not a power of two: Since the tree is not full, we search
for the lowest right child vi,j, which has no children, in the proof that was stored
in st during the last run of catAdd. Then, we generate a skeleton subtree below
vi,j the following way. First, we descend from vi,j along the left edge until we
reach height 1. Then we create one adjacent dummy node at each height, i.e.,
we create dummy nodes at vi−k,2k·j+1 for k = 1 . . . i − 1. The pre-image of each
created dummy node is added to st. Now, we append the given leaf ‘ as the left
most child to the newly generated subtree at height 0. Given the leaf and the
dummy nodes, the value of vi,j can now be determined recursively by computing
vi,j ← vi−1,2·jkvi−1,2·j+1. We re-establish the tree’s integrity by computing a ran-
i,j ← col(csk, xi,j, ri,j, vi,j). We create a proof π for ‘, which contains
domness r0
all newly created dummy nodes, r0
i,j, the node adjacent to vi,j and all nodes from
the old proof, which were above vi,j. Finally, we increase the next free leaf index
c in the client state by one, replace the proof in st with the newly generated one,
and return it.
catVerify(vp, i, ‘, π): Parse vp as (cpk, ρ). In order to verify, whether π authen-
ticates ‘ we compute, starting from the bottom, each node as the hash or the
chameleon hash of the concatenation of its two children until we compute a node
with index 0. All nodes and randomnesses that are needed are taken from the
given π. In case the node we want to compute has a odd index, we use the
chameleon hash function. Otherwise we use the hash function. Let vd,0 be the
node at which we terminated. We return 1 iﬀ vd,0 = H d(ρ), and 0 otherwise.
catUpdate(sp, i, ‘0): Parse sp as (csk, st, vp) and vp as (cpk, ρ). Request ‘i, with
its proof of correctness πi. Request ‘0 with its proof of correctness π0. Com-
pute catVerify(vp, i, ‘i, πi) and catVerify(vp, 0, ‘0, π0) and abort if one of them
outputs 0. Let π = πi ∪ π0 denote the total set of nodes and randomnesses ob-
tained by the client at this point. Replace ‘i with ‘0 and recompute all values
that are on the path from ‘0 to the root recessively. Pick a new ρ0 ← {0, 1}λ
and replace ρ with ρ0 in vp. This means that at each height h we now have
to ensure again that H h(ρ0) = ch(vh−1,0kvh−1,1). Therefore, we compute r0
h,0 ←
scol(csk, vh−1,0kvh−1,1, H h(ρ0)) at each height h and add all newly computed r0
h,0
to π and return π.

Theorem 1. If CH is an invertible one-way collision-resistant chameleon hash
function and H is a collision-resistant hash function modeled as a random oracle,
then Construction 1 is a secure unbounded veriﬁable data streaming protocol.

Due to space constraints the security proof is deferred to Section B.

4

Implementation

VeriStream is written in Java and it contains all protocols described in this paper
as well as a separate library for chameleon hash functions, which contains imple-
mentations of the Krawczyk-Rabin [12], the Ateniese and de Medeiros chameleon
hash [2], and its elliptic curve equivalent. For the elliptic curve operations we
used the Bouncy Castle Cryptographic API (Release 1.49) [1]. In addition we
provide a generic interface for transforming Σ-protocols, that fulﬁl certain prop-
erties into chameleon hash functions [3]. Using this interface we instantiated a
chameleon hash function from the Fiat-Shamir protocol [3]. Many chameleon
hash functions only take input from certain message spaces, e.g., Krawczyk-
Rabin expects messages from Z∗
q. We provide a simple wrapper that transforms
them into functions that take arbitrary large inputs, by ﬁrst hashing the input
with a common collision-resistant hash function, like SHA-256, before passing
it to the chameleon hash function. The remaining algorithms of the chameleon
hash functions are adapted accordingly by the wrapper.

We developed a platform independent standalone client that uses VeriStream
(see Figure 3). It allows its users to manage, upload, download, or share ﬁles of
an arbitrary format in an authenticated fashion. Users can choose whether they
want to upload their data to a private web storage or whether they want to
use their Dropbox account as the underlying storage layer. The client is able to
stream audio and video content with on-the-ﬂy-veriﬁcation, even if Dropbox is
the underlying storage layer.

For developers, VeriStream oﬀers a simple to use interface by the means of
so called VDS handlers. This handler is parameterized by the VDS protocol
type and chameleon hash function that shall be deployed. It oﬀers methods for
creating, verifying, updating, and obtaining proofs from CATs. Since network
bandwidth is an important issue, we transform the proofs into compact byte
sequences representations before sending them over the network, rather than
relying on bloated formats like JSON. We implemented a server, based on a
common thread-pool architecture, that receives from and streams data to clients,
where both parties deploy a VDS handler to secure the transmitted content.

Eﬃciency Optimizations. For performance and bandwidth reasons, our frame-
work diﬀers from the theoretical description in several points that we discuss in
the following.
Short Proofs: When uploading data to the server it is not necessary to always
send the whole proof. Instead, it is suﬃcient to only send all nodes that are below
the chameleon hash node that was extended. One can think of this optimization
as transmitting only the delta between the previous proof(s) and the current
one.
Parallelizing the CAT: Recall that the insertion algorithm always generates
a certain amount of chameleon dummy nodes by picking random pre-images and

Figure 3. Screenshot of the VeriStream standalone client.

storing them in the client state. Later on, when we insert elements below one
such dummy node, we use the pre-images from the state to compute a collision in
that dummy accordingly. Now, instead of picking these pre-images completely at
random, we provide the possibility to pick them using a pseudorandom function,
which takes the dummy nodes position as input. This way, we reduce the client
state to constant size, since we do not need to store the pre-images anymore.
Furthermore, being able to compute the values of dummy nodes independent of
the actual existing tree allows us to obtain concurrent versions of all protocols.
The position of an element in the data stream while uploading uniquely deﬁnes
its position in the CAT. Having the element, and using the pseudorandom func-
tion to obtain the dummy value to which that element will be appended, we can
compute the short proof independent of the remaining tree. We believe that it
is not straightforward to see that the parallelization of the CAT indeed works,
because almost half of the nodes are computed using a collision-resistant hash
functions and these nodes cannot be pre-computed without knowing the pre-
images. However, a closer look at our construction shows that all these values
belong to the left part of the tree and these elements have all been pre-computed
before.
Continuous Requests: Depending on the concrete scenario, a single or multi-
ple elements in succession can be requested. In the case, where multiple adjacent
elements are requested, we exploit the following observation: Given the proof πi
for some leaf i and the proof πi+1 for its successor i + 1, all nodes in πi+1, that
are above the node which was extended when inserting the leaf i + 1 are also
contained in πi. Hence when a set of adjacent elements is requested, we send the
full proof for the ﬁrst and short proofs for the remaining elements.

5 Evaluation

In this section, we provide a comprehensive eﬃciency analysis of VeriStream.
In this analysis, the chunk size is an important variable, because we compute
one proof for each chunk and we therefore test our implementation with diﬀer-

Figure 4. Average time for authenticating one data chunk. On the left all computations
were performed on cyclic groups. On the right on elliptic curves.

ent chunk sized to obtain detailed insights into the protocols performance. In
addition, we conduct several diﬀerent benchmarks highlighting all possible op-
erations for all discussed protocols. Our experimental analysis was conducted on
a Intel Core i3-2120 CPU with 8 GB of RAM running Ubuntu 12.04 with Java
1.6.0.
Evaluation of our Framework: We analyzed the performances of all proto-
cols by uploading and streaming 2GB of data with diﬀerent chunk sizes, such as
32kB, 64kB, . . ., 1024kB. Smaller chunk sizes result in more chunks and therefore
bigger CATs. In addition, we were interested in the performance impact of utiliz-
ing a pseudorandom function for computing the dummy nodes and therefore we
conducted experiments with the fully dynamic CAT that used a pseudorandom
function. As the underlying chameleon hash function we used the scheme due
to Ateniese and de Medeiros. For a performance comparison of chameleon hash
functions see Section D. As the underlying group we used both elliptic curves and
regular cyclic groups with a security parameter of 112 bits. The CAT from [22]
was initialized with a depth of 30, which results in a tree that can authenticate
230 data chunks. In the following we will refer to their construction in the ﬁgures
as static. To obtain meaningful and detailed performance results, we computed
the averages of the following measurements:
– Time for hashing a chunk and authenticating it.
– Time for obtaining and verifying a proof from the CAT.
– Bandwidth overhead produced by a proof retrieved from the CAT.
Evaluation Results: When authenticating and uploading data chunks to the
server, the data owner only sends short proofs to the server as described in Sec-
tion 4. A comparison of the computational overhead incurred by this authentica-
tion step in the diﬀerent constructions is depicted in Figure 4. One can see that
our constructions outperform the construction from [22]. In particular, this is
interesting, since our fully dynamic CAT also provides a better functionality, i.e.
it allows uploading and streaming an unbounded amount of data. One somewhat
surprising result is, that combining our construction with a pseudorandom func-
tion not only reduces the size of the client’s state, but also signiﬁcantly increases
its performance. In practice, the computation of the client’s state after each up-
loaded chunk is far more expensive than the evaluation of the pseudorandom
function. All protocols perform better by more than a factor of two, when using
the elliptic curve chameleon hash function.

InsertionStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)3255.55692755.74875353.32982320.3985123213.80990413.72059213.81835210.2690886455.70614255.78441653.43542520.212166413.91404813.8430413.89865610.3782412856.06662856.0377653.71332620.2210712814.25140814.10656614.29339510.67396425656.701156.54224454.27227420.9248625614.92729114.70519714.87135211.36738451258.06886757.7498755.50998322.28264251216.32411815.9948816.20148512.77957102460.8464760.35670558.12282625.399181102418.84442118.82599819.02814715.383316Insertion OverheadStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF320.11648890.116547490.1165143550.11651052320.571442960.57182460.57157340.5715733640.116470310.116566310.116523850.1165224640.57140430.57211840.57165090.571653371280.116459930.116665650.116542760.116545771280.571299430.57262010.5717570.57176262560.116422810.1168027450.116588580.1165852560.57113190.573586170.571989360.571992045120.116356890.11699770.116684080.1166172555120.570860450.575331570.572425250.572427610240.116267650.117430920.1167523040.1168101310240.57020320.57835110.573044540.5730742RetrievalStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF3292.25345660.8953664.7342558.6286432201.28745164.63712155.65833153.627756461.24822243.16601643.41177741.6464364152.17377132.27968126.34976126.0459512841.31880633.1440133.29614632.385303128123.85311113.92153109.065155108.97983625630.09280627.0193327.31221227.454172256106.451996101.4568697.46364697.2219751225.60035924.10291924.21505424.52841851296.04198592.6574588.68970588.8062102422.83930421.94728922.06090222.12129102487.0245784.6765681.1141381.10491Retrieval OverheadStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)324.88516763.12066723.2687023.2684555320.860961440.57961320.61381650.6138812644.8109882.91230323.06035923.060797640.84126940.54233260.57647820.57740471284.7371262.7044152.85276562.85266541280.825831530.50467520.539245840.539410952564.6628062.49615722.64425472.64425042560.808384060.46702560.502069350.50126795124.58830452.28817182.43615372.43605955120.79102310.430028920.464025620.4644495510244.5146452.0800272.2284562.228640310240.773619230.392381280.427046570.42661718Tim in ms05101520Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Overhead in kB012345Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB00.10.20.30.40.50.60.70.80.9Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms010203040506070Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB0.5660.5680.570.5720.5740.5760.5780.58Chunk size in kB32641282565121024StaticBoundedDynamicDynamic PRFOverhead in kB0.1150.1160.1170.1170.118Chunk size in kB32641282565121024Static (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms055110165220Chunk size in kB32641282565121024StaticDynamicDynamic PRFTime in ms0255075100Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)InsertionStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)3255.55692755.74875353.32982320.3985123213.80990413.72059213.81835210.2690886455.70614255.78441653.43542520.212166413.91404813.8430413.89865610.3782412856.06662856.0377653.71332620.2210712814.25140814.10656614.29339510.67396425656.701156.54224454.27227420.9248625614.92729114.70519714.87135211.36738451258.06886757.7498755.50998322.28264251216.32411815.9948816.20148512.77957102460.8464760.35670558.12282625.399181102418.84442118.82599819.02814715.383316Insertion OverheadStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF320.11648890.116547490.1165143550.11651052320.571442960.57182460.57157340.5715733640.116470310.116566310.116523850.1165224640.57140430.57211840.57165090.571653371280.116459930.116665650.116542760.116545771280.571299430.57262010.5717570.57176262560.116422810.1168027450.116588580.1165852560.57113190.573586170.571989360.571992045120.116356890.11699770.116684080.1166172555120.570860450.575331570.572425250.572427610240.116267650.117430920.1167523040.1168101310240.57020320.57835110.573044540.5730742RetrievalStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF3292.25345660.8953664.7342558.6286432201.28745164.63712155.65833153.627756461.24822243.16601643.41177741.6464364152.17377132.27968126.34976126.0459512841.31880633.1440133.29614632.385303128123.85311113.92153109.065155108.97983625630.09280627.0193327.31221227.454172256106.451996101.4568697.46364697.2219751225.60035924.10291924.21505424.52841851296.04198592.6574588.68970588.8062102422.83930421.94728922.06090222.12129102487.0245784.6765681.1141381.10491Retrieval OverheadStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)324.88516763.12066723.2687023.2684555320.860961440.57961320.61381650.6138812644.8109882.91230323.06035923.060797640.84126940.54233260.57647820.57740471284.7371262.7044152.85276562.85266541280.825831530.50467520.539245840.539410952564.6628062.49615722.64425472.64425042560.808384060.46702560.502069350.50126795124.58830452.28817182.43615372.43605955120.79102310.430028920.464025620.4644495510244.5146452.0800272.2284562.228640310240.773619230.392381280.427046570.42661718Tim in ms05101520Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Overhead in kB012345Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB00.10.20.30.40.50.60.70.80.9Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms010203040506070Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB0.5660.5680.570.5720.5740.5760.5780.58Chunk size in kB32641282565121024StaticBoundedDynamicDynamic PRFOverhead in kB0.1150.1160.1170.1170.118Chunk size in kB32641282565121024Static (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms055110165220Chunk size in kB32641282565121024StaticDynamicDynamic PRFTime in ms0255075100Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Figure 5. The two plots at the top depict the average full proof computation and veri-
ﬁcation time per data chunk. The two plots at the bottom show the average bandwidth
overhead for one data chunk.

In the next step we analyzed the computational and bandwidth overhead
of the retrieval operation. We measured the time it took to compute the proof
from the CAT upon a client request for a certain element and verify the returned
proof. More precisely we created a CAT that contained proofs for a 2GB large
data set and requested all chunks from it, such that each proof in the CAT had
to be computed once. For each received proof the veriﬁcation algorithm was ex-
ecuted once. We stress that we did not use the eﬃcent method for retrieving
sequential parts of the uploaded data, but purposely requested each chunk on
its own with its full proof. The results of this experiment can be seen in Fig-
ure 5. At the top one can see the average time it took to obtain a proof from
the CAT and verify it. At the bottom one can see the average size of such a
retrieved proof. The protocol from [22] performs worst w.r.t. to computational
and bandwidth overhead, what conﬁrms our expectation, since, in contrast to
the dynamically growing trees, all elements in their construction verify against
the very top level root value. This requires, on average, much more bandwidth
and more computational power. Our two constructions perform roughly equally
well as expected. Using the elliptic curve variant of the Ateniese and de Medeiros
chameleon hash results in a improvement of roughly factor 5 with regards to the
size of the proofs and a speed up of about factor 3.

Acknowledgements

Dominique Schr¨oder and Mark Simkin were supported by the German Federal
Ministry of Education and Research (BMBF) through funding for the Center for
IT-Security, Privacy, and Accountability (CISPA; see www.cispa-security.org).
Dominique Schr¨oder is also supported by an Intel Early Career Faculty Honor
Program Award.

InsertionStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)3255.55692755.74875353.32982320.3985123213.80990413.72059213.81835210.2690886455.70614255.78441653.43542520.212166413.91404813.8430413.89865610.3782412856.06662856.0377653.71332620.2210712814.25140814.10656614.29339510.67396425656.701156.54224454.27227420.9248625614.92729114.70519714.87135211.36738451258.06886757.7498755.50998322.28264251216.32411815.9948816.20148512.77957102460.8464760.35670558.12282625.399181102418.84442118.82599819.02814715.383316Insertion OverheadStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF320.11648890.116547490.1165143550.11651052320.571442960.57182460.57157340.5715733640.116470310.116566310.116523850.1165224640.57140430.57211840.57165090.571653371280.116459930.116665650.116542760.116545771280.571299430.57262010.5717570.57176262560.116422810.1168027450.116588580.1165852560.57113190.573586170.571989360.571992045120.116356890.11699770.116684080.1166172555120.570860450.575331570.572425250.572427610240.116267650.117430920.1167523040.1168101310240.57020320.57835110.573044540.5730742RetrievalStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF3292.25345660.8953664.7342558.6286432201.28745164.63712155.65833153.627756461.24822243.16601643.41177741.6464364152.17377132.27968126.34976126.0459512841.31880633.1440133.29614632.385303128123.85311113.92153109.065155108.97983625630.09280627.0193327.31221227.454172256106.451996101.4568697.46364697.2219751225.60035924.10291924.21505424.52841851296.04198592.6574588.68970588.8062102422.83930421.94728922.06090222.12129102487.0245784.6765681.1141381.10491Retrieval OverheadStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)324.88516763.12066723.2687023.2684555320.860961440.57961320.61381650.6138812644.8109882.91230323.06035923.060797640.84126940.54233260.57647820.57740471284.7371262.7044152.85276562.85266541280.825831530.50467520.539245840.539410952564.6628062.49615722.64425472.64425042560.808384060.46702560.502069350.50126795124.58830452.28817182.43615372.43605955120.79102310.430028920.464025620.4644495510244.5146452.0800272.2284562.228640310240.773619230.392381280.427046570.42661718Tim in ms05101520Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Overhead in kB012345Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB00.10.20.30.40.50.60.70.80.9Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms010203040506070Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB0.5660.5680.570.5720.5740.5760.5780.58Chunk size in kB32641282565121024StaticBoundedDynamicDynamic PRFOverhead in kB0.1150.1160.1170.1170.118Chunk size in kB32641282565121024Static (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms055110165220Chunk size in kB32641282565121024StaticDynamicDynamic PRFTime in ms0255075100Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)InsertionStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)3255.55692755.74875353.32982320.3985123213.80990413.72059213.81835210.2690886455.70614255.78441653.43542520.212166413.91404813.8430413.89865610.3782412856.06662856.0377653.71332620.2210712814.25140814.10656614.29339510.67396425656.701156.54224454.27227420.9248625614.92729114.70519714.87135211.36738451258.06886757.7498755.50998322.28264251216.32411815.9948816.20148512.77957102460.8464760.35670558.12282625.399181102418.84442118.82599819.02814715.383316Insertion OverheadStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF320.11648890.116547490.1165143550.11651052320.571442960.57182460.57157340.5715733640.116470310.116566310.116523850.1165224640.57140430.57211840.57165090.571653371280.116459930.116665650.116542760.116545771280.571299430.57262010.5717570.57176262560.116422810.1168027450.116588580.1165852560.57113190.573586170.571989360.571992045120.116356890.11699770.116684080.1166172555120.570860450.575331570.572425250.572427610240.116267650.117430920.1167523040.1168101310240.57020320.57835110.573044540.5730742RetrievalStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF3292.25345660.8953664.7342558.6286432201.28745164.63712155.65833153.627756461.24822243.16601643.41177741.6464364152.17377132.27968126.34976126.0459512841.31880633.1440133.29614632.385303128123.85311113.92153109.065155108.97983625630.09280627.0193327.31221227.454172256106.451996101.4568697.46364697.2219751225.60035924.10291924.21505424.52841851296.04198592.6574588.68970588.8062102422.83930421.94728922.06090222.12129102487.0245784.6765681.1141381.10491Retrieval OverheadStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)324.88516763.12066723.2687023.2684555320.860961440.57961320.61381650.6138812644.8109882.91230323.06035923.060797640.84126940.54233260.57647820.57740471284.7371262.7044152.85276562.85266541280.825831530.50467520.539245840.539410952564.6628062.49615722.64425472.64425042560.808384060.46702560.502069350.50126795124.58830452.28817182.43615372.43605955120.79102310.430028920.464025620.4644495510244.5146452.0800272.2284562.228640310240.773619230.392381280.427046570.42661718Tim in ms05101520Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Overhead in kB012345Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB00.10.20.30.40.50.60.70.80.9Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms010203040506070Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB0.5660.5680.570.5720.5740.5760.5780.58Chunk size in kB32641282565121024StaticBoundedDynamicDynamic PRFOverhead in kB0.1150.1160.1170.1170.118Chunk size in kB32641282565121024Static (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms055110165220Chunk size in kB32641282565121024StaticDynamicDynamic PRFTime in ms0255075100Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)InsertionStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)3255.55692755.74875353.32982320.3985123213.80990413.72059213.81835210.2690886455.70614255.78441653.43542520.212166413.91404813.8430413.89865610.3782412856.06662856.0377653.71332620.2210712814.25140814.10656614.29339510.67396425656.701156.54224454.27227420.9248625614.92729114.70519714.87135211.36738451258.06886757.7498755.50998322.28264251216.32411815.9948816.20148512.77957102460.8464760.35670558.12282625.399181102418.84442118.82599819.02814715.383316Insertion OverheadStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF320.11648890.116547490.1165143550.11651052320.571442960.57182460.57157340.5715733640.116470310.116566310.116523850.1165224640.57140430.57211840.57165090.571653371280.116459930.116665650.116542760.116545771280.571299430.57262010.5717570.57176262560.116422810.1168027450.116588580.1165852560.57113190.573586170.571989360.571992045120.116356890.11699770.116684080.1166172555120.570860450.575331570.572425250.572427610240.116267650.117430920.1167523040.1168101310240.57020320.57835110.573044540.5730742RetrievalStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF3292.25345660.8953664.7342558.6286432201.28745164.63712155.65833153.627756461.24822243.16601643.41177741.6464364152.17377132.27968126.34976126.0459512841.31880633.1440133.29614632.385303128123.85311113.92153109.065155108.97983625630.09280627.0193327.31221227.454172256106.451996101.4568697.46364697.2219751225.60035924.10291924.21505424.52841851296.04198592.6574588.68970588.8062102422.83930421.94728922.06090222.12129102487.0245784.6765681.1141381.10491Retrieval OverheadStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)324.88516763.12066723.2687023.2684555320.860961440.57961320.61381650.6138812644.8109882.91230323.06035923.060797640.84126940.54233260.57647820.57740471284.7371262.7044152.85276562.85266541280.825831530.50467520.539245840.539410952564.6628062.49615722.64425472.64425042560.808384060.46702560.502069350.50126795124.58830452.28817182.43615372.43605955120.79102310.430028920.464025620.4644495510244.5146452.0800272.2284562.228640310240.773619230.392381280.427046570.42661718Tim in ms05101520Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Overhead in kB012345Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB00.10.20.30.40.50.60.70.80.9Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms010203040506070Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB0.5660.5680.570.5720.5740.5760.5780.58Chunk size in kB32641282565121024StaticBoundedDynamicDynamic PRFOverhead in kB0.1150.1160.1170.1170.118Chunk size in kB32641282565121024Static (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms055110165220Chunk size in kB32641282565121024StaticDynamicDynamic PRFTime in ms0255075100Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)InsertionStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)3255.55692755.74875353.32982320.3985123213.80990413.72059213.81835210.2690886455.70614255.78441653.43542520.212166413.91404813.8430413.89865610.3782412856.06662856.0377653.71332620.2210712814.25140814.10656614.29339510.67396425656.701156.54224454.27227420.9248625614.92729114.70519714.87135211.36738451258.06886757.7498755.50998322.28264251216.32411815.9948816.20148512.77957102460.8464760.35670558.12282625.399181102418.84442118.82599819.02814715.383316Insertion OverheadStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF320.11648890.116547490.1165143550.11651052320.571442960.57182460.57157340.5715733640.116470310.116566310.116523850.1165224640.57140430.57211840.57165090.571653371280.116459930.116665650.116542760.116545771280.571299430.57262010.5717570.57176262560.116422810.1168027450.116588580.1165852560.57113190.573586170.571989360.571992045120.116356890.11699770.116684080.1166172555120.570860450.575331570.572425250.572427610240.116267650.117430920.1167523040.1168101310240.57020320.57835110.573044540.5730742RetrievalStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)StaticBoundedDynamicDynamic PRF3292.25345660.8953664.7342558.6286432201.28745164.63712155.65833153.627756461.24822243.16601643.41177741.6464364152.17377132.27968126.34976126.0459512841.31880633.1440133.29614632.385303128123.85311113.92153109.065155108.97983625630.09280627.0193327.31221227.454172256106.451996101.4568697.46364697.2219751225.60035924.10291924.21505424.52841851296.04198592.6574588.68970588.8062102422.83930421.94728922.06090222.12129102487.0245784.6765681.1141381.10491Retrieval OverheadStaticBoundedDynamicDynamic PRFStatic (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)324.88516763.12066723.2687023.2684555320.860961440.57961320.61381650.6138812644.8109882.91230323.06035923.060797640.84126940.54233260.57647820.57740471284.7371262.7044152.85276562.85266541280.825831530.50467520.539245840.539410952564.6628062.49615722.64425472.64425042560.808384060.46702560.502069350.50126795124.58830452.28817182.43615372.43605955120.79102310.430028920.464025620.4644495510244.5146452.0800272.2284562.228640310240.773619230.392381280.427046570.42661718Tim in ms05101520Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Overhead in kB012345Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB00.10.20.30.40.50.60.70.80.9Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms010203040506070Chunk size in kB32641282565121024StaticDynamicDynamic PRFOverhead in kB0.5660.5680.570.5720.5740.5760.5780.58Chunk size in kB32641282565121024StaticBoundedDynamicDynamic PRFOverhead in kB0.1150.1160.1170.1170.118Chunk size in kB32641282565121024Static (ECC)Bounded (ECC)Dynamic (ECC)Dynamic PRF (ECC)Time in ms055110165220Chunk size in kB32641282565121024StaticDynamicDynamic PRFTime in ms0255075100Chunk size in kB32641282565121024Static (ECC)Dynamic (ECC)Dynamic PRF (ECC)References
1. Bouncy Castle Crypto APIs. 4
2. Giuseppe Ateniese and Breno de Medeiros. On the key exposure problem in
chameleon hashes.
In Carlo Blundo and Stelvio Cimato, editors, SCN 04: 4th
International Conference on Security in Communication Networks, volume 3352
of Lecture Notes in Computer Science, pages 165–179, Amalﬁ, Italy, September 8–
10, 2004. Springer, Berlin, Germany. 3.1, 4, C

3. Mihir Bellare and Todor Ristov. Hash functions from sigma protocols and im-
provements to VSH.
In Josef Pieprzyk, editor, Advances in Cryptology – ASI-
ACRYPT 2008, volume 5350 of Lecture Notes in Computer Science, pages 125–
142, Melbourne, Australia, December 7–11, 2008. Springer, Berlin, Germany. 3.1,
4, C

4. Siavosh Benabbas, Rosario Gennaro, and Yevgeniy Vahlis. Veriﬁable delegation of
computation over large datasets. In Phillip Rogaway, editor, Advances in Cryptol-
ogy – CRYPTO 2011, volume 6841 of Lecture Notes in Computer Science, pages
111–131, Santa Barbara, CA, USA, August 14–18, 2011. Springer, Berlin, Germany.
1.3

10. D´ecio Luiz Gazzoni Filho and Paulo S´ergio Licciardi Messeder Barreto. Demon-
strating data possession and uncheatable data transfer. Cryptology ePrint Archive,
Report 2006/150, 2006. http://eprint.iacr.org/. 1.3

11. Susan Hohenberger and Brent Waters. Realizing hash-and-sign signatures under
standard assumptions. In Antoine Joux, editor, Advances in Cryptology – EURO-
CRYPT 2009, volume 5479 of Lecture Notes in Computer Science, pages 333–350,
Cologne, Germany, April 26–30, 2009. Springer, Berlin, Germany. 3.1, B, B

5. Jan Camenisch, Markulf Kohlweiss, and Claudio Soriente. An accumulator based
on bilinear maps and eﬃcient revocation for anonymous credentials. In Stanislaw
Jarecki and Gene Tsudik, editors, PKC 2009: 12th International Conference on
Theory and Practice of Public Key Cryptography, volume 5443 of Lecture Notes in
Computer Science, pages 481–500, Irvine, CA, USA, March 18–20, 2009. Springer,
Berlin, Germany. 1.3

6. Jan Camenisch and Anna Lysyanskaya. Dynamic accumulators and application
to eﬃcient revocation of anonymous credentials. In Moti Yung, editor, Advances
in Cryptology – CRYPTO 2002, volume 2442 of Lecture Notes in Computer Sci-
ence, pages 61–76, Santa Barbara, CA, USA, August 18–22, 2002. Springer, Berlin,
Germany. 1.3

7. David Cash, Alptekin K¨up¸c¨u, and Daniel Wichs. Dynamic proofs of retrievability
via oblivious ram.
In Advances in Cryptology - EUROCRYPT 2013, 32nd An-
nual International Conference on the Theory and Applications of Cryptographic
Techniques, Athens, Greece, May 26-30, 2013. Proceedings, volume 7881 of Lecture
Notes in Computer Science, pages 279–295. Springer, 2013. 1.3

8. Dario Catalano and Dario Fiore. Vector commitments and their applications. In
Kaoru Kurosawa and Goichiro Hanaoka, editors, PKC 2013: 16th International
Workshop on Theory and Practice in Public Key Cryptography, volume 7778 of
Lecture Notes in Computer Science, pages 55–72, Nara, Japan, February 26 –
March 1, 2013. Springer, Berlin, Germany. 1.3

9. C. Christopher Erway, Alptekin K¨up¸c¨u, Charalampos Papamanthou, and Roberto
Tamassia. Dynamic provable data possession. In Ehab Al-Shaer, Somesh Jha, and
Angelos D. Keromytis, editors, ACM CCS 09: 16th Conference on Computer and
Communications Security, pages 213–222, Chicago, Illinois, USA, November 9–13,
2009. ACM Press. 1.3

12. Hugo Krawczyk and Tal Rabin. Chameleon signatures.

In ISOC Network and
Distributed System Security Symposium – NDSS 2000, San Diego, California, USA,
February 2–4, 2000. The Internet Society. 3.1, 4

13. Tal Malkin, Daniele Micciancio, and Sara K. Miner. Eﬃcient generic forward-secure
signatures with an unbounded number of time periods. In Lars R. Knudsen, editor,
Advances in Cryptology – EUROCRYPT 2002, volume 2332 of Lecture Notes in
Computer Science, pages 400–417, Amsterdam, The Netherlands, April 28 – May 2,
2002. Springer, Berlin, Germany. 1.3

14. Chip Martel, Glen Nuckolls, Prem Devanbu, Michael Gertz, April Kwong, and
Stuart G. Stubblebine. A general model for authenticated data structures. Algo-
rithmica, 39:2004, 2001. 1.3

15. Moni Naor and Kobbi Nissim. Certiﬁcate revocation and certiﬁcate update. IEEE

Journal on Selected Areas in Communications, 18(4):561–570, 2000. 1.3
16. Lan Nguyen. Accumulators from bilinear pairings and applications.

In Alfred
Menezes, editor, Topics in Cryptology – CT-RSA 2005, volume 3376 of Lecture
Notes in Computer Science, pages 275–292, San Francisco, CA, USA, February 14–
18, 2005. Springer, Berlin, Germany. 1.3

17. National Institute of Standards and Technology. Recommendation for key man-
agement. Special Publication 800-57 Part 1 Rev. 3, NIST, 2012. http://www.
keylength.com/. D

18. Charalampos Papamanthou, Elaine Shi, Roberto Tamassia, and Ke Yi. Streaming
authenticated data structures. In Advances in Cryptology - EUROCRYPT 2013,
32nd Annual International Conference on the Theory and Applications of Crypto-
graphic Techniques, Athens, Greece, May 26-30, 2013. Proceedings, volume 7881
of Lecture Notes in Computer Science, pages 353–370. Springer, 2013. 1.3

19. Charalampos Papamanthou and Roberto Tamassia. Time and space eﬃcient al-
gorithms for two-party authenticated data structures. In Proceedings of the 9th
international conference on Information and communications security, ICICS’07,
pages 1–15, Berlin, Heidelberg, 2007. Springer-Verlag. 1.3

20. Adrian Perrig, Ran Canetti, Dawn Xiaodong Song, and J. Doug Tygar. Eﬃcient
and secure source authentication for multicast. In ISOC Network and Distributed
System Security Symposium – NDSS 2001, pages 35–46, San Diego, California,
USA, February 7–9, 2001. The Internet Society. 1.3

21. Adrian Perrig, Ran Canetti, J. Doug Tygar, and Dawn Xiaodong Song. Eﬃcient
authentication and signing of multicast streams over lossy channels. In 2000 IEEE
Symposium on Security and Privacy, pages 56–73, Oakland, California, USA, May
2000. IEEE Computer Society Press. 1.3

22. Dominique Schr¨oder and Heike Schr¨oder. Veriﬁable data streaming. In Ting Yu,
George Danezis, and Virgil D. Gligor, editors, ACM CCS 12: 19th Conference
on Computer and Communications Security, pages 953–964, Raleigh, NC, USA,
October 16–18, 2012. ACM Press. 1.1, 1, 1.1, 1.3, 2, 2, 5, 5, A, A, B, C

23. Thomas Schwarz and Ethan L. Miller. Store, forget, and check: Using algebraic
signatures to check remotely administered storage. Proceedings of the IEEE Int’l
Conference on Distributed Computing Systems (ICDCS ’06), July 2006. 1.3

24. Hovav Shacham and Brent Waters. Compact proofs of retrievability.

In Josef
Pieprzyk, editor, Advances in Cryptology – ASIACRYPT 2008, volume 5350 of
Lecture Notes in Computer Science, pages 90–107, Melbourne, Australia, Decem-
ber 7–11, 2008. Springer, Berlin, Germany. 1.3

25. Adi Shamir and Yael Tauman. Improved online/oﬄine signature schemes. In Joe
Kilian, editor, Advances in Cryptology – CRYPTO 2001, volume 2139 of Lecture

Notes in Computer Science, pages 355–367, Santa Barbara, CA, USA, August 19–
23, 2001. Springer, Berlin, Germany. 3.1

26. Roberto Tamassia and Nikos Triandopoulos. Certiﬁcation and authentication of

data structures. In AMW, 2010. 1.3

A Veriﬁable Data Streaming

In the following we shortly recall the formal deﬁnitions of VDS protocols and
CATs. Our deﬁnition of VDS is taken almost verbatim from [22]:
Deﬁnition 3. A veriﬁable data streaming protocol VDS = (Setup, Append, Query,
Verify, Update) is a protocol between two eﬃcient algorithms: a client C and a
server S. The server can store an exponential number N of elements in its
database DB and the client keeps some small state, which shall not be larger
than O(log N). The scheme consists of the following eﬃcient algorithms:
Setup(1λ): The setup algorithm outputs a veriﬁcation key pk and a secret key
sk, where pk is given to the server S and sk to the client C. W.l.o.g., sk
always contains pk.
Append(sk, s): This algorithm appends the value s to the database DB held by
the server. The client sends a single message to the server who stores the
element in DB. Adding elements to the database may change the private key
to sk0, but it does not change the veriﬁcation key pk.
Query(pk, DB, i): The interactive query protocol is deﬁned as hS(pk, DB),C(i)i
and is executed between the server S(pk, DB) and client C(i). At the end of
the protocol, the client either outputs the ith entry s[i] of DB together with
a proof πs[i], or ⊥.
ment in the database DB, otherwise it returns ⊥.
takes place between the server S(pk, DB) and the client C(sk, i, s0) who wishes
to update the ith entry of the database DB to s0. At the end of the protocol
the server sets s[i] ← s0 and pk is updated to pk0.

Verify(pk, i, s, πs[i]): The veriﬁcation algorithm outputs s[i] if s[i] is the ith ele-
Update(pk, DB, sk, i, s0): The interactive update protocol, denoted by hS(pk, DB),C(sk, i, s0)i,

Security of VDS: Loosely speaking, an adversary A against a VDS protocol
tries to tamper with the uploaded data set by either adding an element to it,
changing the order of two elements, or deleting an element from the authenti-
cated data set. Since our modiﬁed security deﬁnition of CATs given in Section 2
directly implies the security deﬁnition for VDS from [22], we omit a formal se-
curity deﬁnition of VDS here.

B Security Proof for the Fully Dynamic CAT

Before proving the security of our construction, we describe the main proof idea.
Recall that our goal is to rule out any adversary that can creates a valid proof

for an element that was not at a certain position in the stream. Intuitively, it
seems obvious that there must be either a collision in the hash function or in the
chameleon hash function. The problem, however, occurs in the reduction to the
chameleon hash function. The reasons are twofold: First, in the reduction against
the collision-resistance of the chameleon hash function does not have access to
the trapdoor, thus, computing a colliding randomness while the adversary adds
elements to the tree is not possible. The second issue stems from the fact, that
once the attacker receives the public key, it learns the initial seed ρ. Thus,
programming the random oracle to map to the output of the chameleon hash does
also not work because the attacker can simply compute the n-fold application
of H to ρ before sending a single element to the server.

To handle these issue, we split the proof in three parts. First, we ﬁrst prove
a weaker result in which the adversary has to commit to all values in the stream
before seeing the public key of the CAT. Moreover, the attacker cannot perform
any update query. The attacker then receives the public key, the corresponding
proofs of correctness, and its task is to output a false statement.The main obser-
vation is that programming the random oracle is now indeed possible, because
the adversary obtains the public key after outputting all elements.

Afterwards, we allow the adversary to choose the elements in the stream
adaptively, but we still do not allow to perform any update queries. The main
idea here is to achieve adaptivity by storing chameleon hash values in the leaves.
Thus, whenever the attacker asks to add an element, we use the trapdoor of the
chameleon hash to ﬁnd a colluding randomness. This technique is well known
and has previously been used in, e.g., [11,22].

In the last step of the proof we allow the attacker to perform updates. The
main issue in simulating update queries is again that we have to ﬁnd logarith-
mically many collisions, without having access to the trapdoor of the chameleon
hash. The key idea to overcome this technical challenge is to exploit the pro-
grammability of the random oracle again. In contrast to the ﬁrst step of the proof,
this is indeed possible because we pick a fresh value ρ0 that will be stored in the
public key. Thus, for a tree of depth D, we check that all values H(ρ0), . . . , H d(ρ0)
have not been queried by the adversary. If this is the case then, we can program
these values accordingly, by setting H(ρ0) := ch(‘1,k‘2; r0), ... for a freshly cho-
sen randomness r0. Observe that ch(‘1,k‘2; r0) is uniformly distributed, because
r0 is chosen at random. Thus, the distribution generated during the simulation
is identical to the one in our construction. Furthermore, with all but negligible
probability ch(‘1,k‘2; r0) maps to a fresh value. Otherwise, we could easily build
a reduction against the collision-resistance of ch.

Proposition 1. If CH is an invertible one-way collision-resistant chameleon
hash function and H a collision-resistant hash function modeled as a random
oracle, then Construction 1 is a secure fully dynamic chameleon authentication
tree (according to Deﬁnition 2).

In the ﬁrst step of the proof we only consider non-adaptive adversaries that
output all elements that should be added to the CAT before seeing the public-key.
In addition, this class of adversaries cannot update any element. We distinguish
between two diﬀerent cases. Either, the attacker manages to change some element
in the stream, or the adversary appended an element to it. We prove both cases
with the following two claims.

Claim. If A is a non-adaptive adversary that outputs (‘∗, i∗, π∗) such that 1 ≤
i∗ ≤ q(λ), then Prob[catVerify(pk, i∗, ‘∗, π∗) = 1] ≈ 0.

Proof. Let (λ) := Prob[catVerify(pk, i∗, ‘∗, π∗) = 1] and assume towards con-
tradiction that  6≈ 0. Then, there exists an eﬃcient non-adaptive adversary A
that outputs q elements ‘1, . . . , ‘q before obtaining the public key pk together
with the corresponding proofs πi that contain the authentication paths ˆπi. After-
wards, it outputs a tuple (‘∗, i∗, π∗), where π∗ is the authentication path in the
tree such that 1 ≤ i∗ ≤ q(λ) and catVerify(pk, i∗, ‘∗, π∗) = 1 holds with probabil-
ity (λ). In what follows, we show how to either build an attacker Bh that ﬁnds a
collision in the hash function, or an algorithm Bch against the collision-resistance
of the chameleon hash function. Within the proof we use the following notions.
Setup of the Tree: The setup procedure for both algorithms Bh and Bch is
the same: The algorithm BS (where BS ∈ {Bh,Bch} depending on the case)
runs a black-box simulation of A, in order to obtain the q leaves ‘1, . . . , ‘q.
Denote by t the depth of the resulting tree, i.e., 2t ≥ q and by R the list of
random oracle query/answer pairs that is initially empty. The algorithm BS
computes the tree from the bottom up as follows. First, it sets u1,1 ← ‘0k‘1, it
picks a fresh randomness r1,1 and a random value ρ ← {0, 1}2len, and computes
ρ1 ← ch(x1,1; r1,1). Afterwards, B‘ programs the mapping of the random oracle
as H(ρ) := ρ1, it stores (ρ, ρ1) in R, and sets pk := ρ.

In order to add the leaves ‘3, ‘4 to the tree, BS sets u1,1 ← H(‘1k‘2)
and u1,2 ← ch(‘3k‘4; r1,2) for a random value r1,2. BS computes the root by
picking r2,1 uniformly at random and by programming the random oracle as
H(ρ1) = H(H(ρ)) := ch(u1,1ku1,2; r1,2). BS adds the pair (ρ1, ρ2) in R, where
ρ2 = ch(u1,1ku1,2; r1,2).

i=1) to A.

BS repeats these steps until all elements are stored in the tree. Following
these steps, it is easy to see that all elements verify as valid leaves in the tree.
BS then returns (pk,{(‘i, i, πi)}q
Answering Random Oracle Queries: BS answers all random oracle queries
x from A as follows. If there exists an element (x,·) in R, then BS returns the ﬁrst
one. (If there is more than one element (x,·) in R, then BS aborts. Otherwise,
if such a pairs does not exist, then BS samples a value y ∈ {0, 1}len uniformly
at random. If there exists an element (·, y) ∈ R, then BS repeats keeps sampling
until it ﬁnds a fresh value y. BS stores (x, y) in R and returns y to A.

Computing a Collision: We show how to build an attacker BH against the
collision-resistant of H using an attacker AH. The reduction against the collision-
resistance of ch works analogously and is omitted.

0, . . . , v0

0, . . . , v0

0, . . . , v0

0 , . . . , v0∗

i∗) be the sub-path and let mPathi∗ = (i, s, (v0

D−2,bi/2D−2c), R∗) and 1 ≤ i∗ ≤ q. Let mPath∗ = (v0∗

Eventually, AH stops outputting a pair (‘∗, i∗, π∗) 6∈ Q with π∗ = ˆπ∗ =
((v∗
1,bi/2c, . . . , v∗
D−1)
denote the path from the leaf ‘∗ to the root. If AH succeeds, then the nodes
ˆπ∗ authenticates the leaf ‘∗, but AH has not received the tuple (‘∗, i∗, ˆπ∗),
i.e., (‘∗, i∗, ˆπ∗) 6∈ Q where Q = ((‘1, 1, ˆπ1), . . . , (‘q(λ), q, ˆπq)). Now consider the
leaf ‘i∗ together with the corresponding authentication path ˆπ = ((v1,bi/2c, . . . ,
vD−2,bi/2D−2c), R) and with its path mPath = (v0
D−1)) to the root. Let
ˆπi∗ := (v0
i∗)), re-
spectively. Then, we distinguish two cases:
Case 1: Suppose that mPath 6= mPathMsgFake. Since both paths have the
same root ρ, there must exist an index 0 ≤ i < D − 1 with mPathi+1 =
mPathMsgFakei+1 and mPathi 6= mPathMsgFakei. Now, a collision is found since
mPathi+1 = H(ˆπi||mPathi)
Case 2: Suppose that mPath = mPathMsgFake. If ‘i 6= ‘∗, then a collision is
found. On the other hand, if ‘i = ‘∗, then ˆπi and ˆπ∗ are distinct. Suppose that
ˆπi 6= myPathFakei for an index i < D − 1. Since mPathi+1 = H(ˆπi||mPathi)
and because mPathMsgFakei+1 = H(myPathFakei||mPathMsgFakei) a collision is
found.

For the analysis, it is easy to see that B terminates (in particular when an-
swering the random oracle queries). Furthermore, the probability that B aborts
when answering the random oracle queries is negligible. Thus, we assume in the
following that B does not abort. Then, it follows easily from the reduction that
BH performs a perfect simulation from AH’s point of view, and that both algo-
rithms are eﬃcient. Thus, BH ﬁnds a collision whenever AH succeeds. Denote by
H the corresponding probability. Assuming that H is non-negligible, however,
contradicts the assumption that the hash function is collision-resistant.

The algorithm Bch that ﬁnds a collision in the chameleon hash function ch
works analogously to BH. We denote by Ach the underlying adversary and by
ch its success probability. The algorithm B then simply guesses if it has access
to AH or Ach. Thus, we calculate the overall success probability 0(λ) of B as

0(λ) := Prob[B succ] = 1

2(H(λ) + ch(λ)),

where X succ denotes the event that the algorithm X wins its security game.

Claim. If A is a non-adaptive adversary that outputs (‘∗, i∗, π∗) such that i∗ >
q(λ), then Prob[catVerify(pk, i∗, ‘∗, π∗) = 1] ≈ 0.

The main observation to prove this theorem is that any authentication path for
a leaf ‘∗ with index i∗ for q + 1 ≤ i∗ ≤ 2D must contain a right-handed node on

a subtree where no leaf has been added yet. Recall that every right-handed node
is computed by chameleon hash function using a randomly chosen value. Thus,
if the attacker manages to compute a valid authentication path, then it must
must invert the chameleon hash on this value. It might be the case, however,
that we ﬁnd a diﬀerent pre-image. But then we can build a reduction against
the collision resistance.

Proof. We prove this theorem by contradiction assuming that A is an eﬃcent
adversary that returns a tuple (‘∗, i∗, ˆπ∗) such that q + 1 ≤ i∗ ≤ 2D. Then,
we construct an attacker B against the one-wayness of ch (resp. against the
collision-resistance).
Setup: The input of B is an image y∗ ← ch(x; r) and the public key cpk of
the chameleon hash function. It runs A in a black-box way obtaining q leaves
‘1, . . . , ‘q. Let D be the depth of the resulting tree such that 2D ≥ q and denote
by t the unused dummy nodes (i.e., these are right nodes that do not have any
children and that would be computed by a dummy value). B sets up the tree
by picking t − 1 dummy nodes yi ← {0, 1}len and guessing a random index
j = 1, . . . , t. Then, B computes the tree from the bottom to the top using where
the ﬁrst q leaves are ‘1, . . . , ‘q. To do so, it programs the random oracle as
described in the proof of Proposition 1 and it uses the nodes y1, . . . , y∗, . . . , yt−1
as dummy nodes. Furthermore, B computes the authentication paths ˆπi for the
leaves ‘i (for i = 1, . . . , q). The attacker B then sets pk ← (cpk, ρ) and runs a
black-box simulation of A on input (pk,{(‘i, i, ˆπi)}q
Answering the Random Oracle Queries: Our reduction answers the ran-
dom oracle queries by lazy sampling as described in the proof of Proposition 1.
Inverting CH: Eventually, the attacker A terminates, outputting a pair (‘∗, i∗, ˆπ∗)
D−2,bi/2D−2c), R∗) and q + 1 ≤ i∗ ≤ 2D. Let mPath∗ =
with ˆπ∗ = ((v∗
D−1) denote the path from the leaf ‘∗ to the root. If there exists an
(v0∗
0 , . . . , v0∗
j = y∗, then B computes the authentication path ˆπ∗ up to y∗.
index j such that v0
Then, the algorithm B outputs the resulting pre-image x∗ = ˆπ∗ together with
the corresponding randomness r∗. Otherwise, it aborts.

1,bi/2c, . . . , v∗

i=1).

1,bi/2c, . . . , v∗

For the analysis ﬁrst note that B performs a perfect simulation from A’s point
of view (applying the same arguments as in the previous proof). Now, assume
that A succeeds with non-negligible probability. Then, it returns a valid pair
D−2,bi/2D−2c), R∗) such that q+1 ≤ i∗ ≤ 2D.
(‘∗, i∗, ˆπ∗) with ˆπ∗ = ((v∗
Since the authentication path veriﬁes, it follows from our construction that one
node in ˆπ∗ is a right-handed node on the authentication path of ‘q. Since it is a
right node, it follows that this node is the output of a chameleon hash function.
Now, assume that B has guessed this node correctly. Then, it follows from our
construction that B computes a pre-image (x∗, r∗) of y∗. We have to show that
(x∗, r∗) = (x, r). This, however, follows from the collision-resistance of ch. If we
assume towards contradiction that (x∗, r∗) 6= (x, r), then we can easily build an
adversary that ﬁnds a collision in ch.

Assume further that A succeeds with non-negligible probability O(λ). Then,
it is easy to see that B wins with probability δO(λ) := O(λ)/t. This, however,
either contradicts the one-wayness or the collision-resistance of ch.

The next step of the proof to achieve full security, is to apply the general trans-
formation that turns any weakly secure CAT into a fully secure one. The basic
idea is to store chameleon hash values (using a diﬀerent trapdoor) in the leaves,
such that the reduction can adjust these values for each query. Let Π0
CAT be
the CAT that is identical to the scheme deﬁned in Construction 1, with the
diﬀerence being that the leaves store the values of a chameleon hash with an
independently chosen key.

Proposition 2. If ΠCAT is a weakly secure chameleon authentication tree and
CH is a collision-resistant chameleon hash function, then Π0
CAT as deﬁned above
is a secure chameleon authentication tree that does not support updates.

The proof is almost the same as the one for signature schemes (see [11]) and

is omitted.

Proposition 3. The chameleon authentication tree as deﬁned in Construction 1
is secure against adaptive updates.

The main idea of the proof of this proposition is as follows. Whenever, A
asks to update an element in the tree, then we pick a fresh value ρ0 such that
the mapping H(ρ0), . . . , H t(ρ0) are unknown. If this is the case, then we program
the mapping of the hash function accordingly. Otherwise, if one of the mappings
are known, then the reduction aborts.

C δ-bounded CATs

The fully dynamic CAT is more eﬃcient than previous constructions [22] and
allows the data owner to upload an unbounded amount of data. However, the
proof is only given in the random oracle model and the construction requires
the additional inversion property of chameleon hash functions. Although two
of the three chameleon hash functions we consider, namely the Fiat-Shamir [3]
and the Ateniese and de Medeiros [2] construction have this property, it is still
desirable to ﬁnd a solution based on weaker assumptions, which can be proven in
the standard model. Therefore we propose the δ-bounded CAT, which is upper
bounded by the depth δ, but is provably secure in the standard model and has
roughly the same computational and bandwidth overhead as the fully dynamic
construction.

C.1

Intuition

Let us reconsider our ﬁrst construction. There, we exploited the inversion prop-
erty of our chameleon hash function to ﬁnd randomnesses that mapped to certain
root values. To provide a proof in the standard model we have to refrain from
using this property. Instead, we pre-compute δ dummy root values ρh,0 where
h = 1 . . . δ, publish them in the public key pk, and keep their pre-images secret
in our state st. An authentication path with depth i is then veriﬁed against ρi,0.
Since we keep all pre-images in our state, we can use col rather than scol to ﬁnd
collisions.
Note, again we can make use of a pseudorandom function to make the client’s
state constant.

C.2 Construction

We now provide the formal description of all algorithms of the δ-bounded CAT
construction.
Construction 2 Let H : {0, 1}∗ 7→ {0, 1}len be a hash function and CH =
(chGen, ch, col) a chameleon hash function. The δ-bounded chameleon authenti-
cation tree ΠCAT = (catGen, catAdd, catUpdate, catVerify) is deﬁned as follows:
catGen(1λ, δ): The algorithm computes (cpk, csk) ← chGen(1λ) and sets c ← 0.
For i = 1, . . . , δ it generates dummy nodes ρi,0 and stores their pre-images
in st. It returns the private key sp = (csk, st, vp) and the public key vp =
(cpk, (ρ1,0, . . . , ρδ,0))
catAdd(sp, s): Parse sp as (csk, st, vp) and check whether the current tree is full,
i.e., whether c is a power of two:
The counter c is a power of two: In this case the tree is full again. We
need to extend its height by one to create a tree which has free leaves. Let d be its
depth before increasing it by one. If d = δ we abort, since the tree has reached its
maximum capacity. Otherwise, we compute a dummy node vd−1,1, and store its
pre-images in st. Next, we need to compute r0
d,0) =
ρd. We use the stored pre-image (xd,0, rd,0) of ρd,0 from st and compute rd,0 ←
col(csk, xd,0, rd,0, ρd−1,0kvd−1,1). Now we add vd−1,1, r0
d,0 to π in st and proceed
as in the case where c is not a power of two.
The counter c is not a power of two: In this case the tree is not full. The
algorithms behaviour here is identical to the one in the fully dynamic version as
deﬁned in Constrution 1.
catVerify(vp, i, ‘, π): Parse vp as (cpk, (ρ1,0, . . . , ρδ,0)). In order to verify, whether
π authenticates ‘ we compute, starting from the bottom, each node as the hash
or the chameleon hash of its two children until we compute a node with index 0.
If the a nodes index is odd, we compute it using the chameleon hash function,
and we use the hash function otherwise. All required nodes and randomnesses

d,0 such that ch(ρd−1,0kvd−1,1, r0

are taken from π. Let vd,0 be the node at which we terminated. Return 1 iﬀ
vd,0 = ρd,0, and 0 otherwise.
catUpdate(sp, i, ‘0): Parse sp as (csk, st, vp). Request ‘i, with its proof of cor-
rectness πi, and compute catVerify(vp, i, ‘i, πi); abort if it outputs 0. Otherwise,
replace ‘ with ‘0 and recompute the new value of the corresponding root vd,0.
Update the root node’s value at that height in the public key vp0 accordingly.
Recompute all root node values above vd,0 update the vp0 accordingly.

Regarding security, we obtain the following theorem.
Theorem 2. Suppose that CH is a one-way collision-resistant chameleon hash
function and H is a collision-resistant hash function, then Construction 2 is a
secure δ-bounded chameleon authentication tree.

The proofs is similar to the previous one, with the diﬀerence that we do not need
to program the random oracle anymore, and can easily be deduced.

D Evaluation of Chameleon Hash Functions

We discuss the performance of chameleon hash functions on their own, since they
represent the most expensive building block in our protocols. In particular, we
examine the hashing and collision ﬁnding performances of the Fiat-Shamir, the
Ateniese and de Medeiros, its elliptic curve equivalent, and the Krawczyk-Rabin
chameleon hash.

To evaluate their performances, we used each of them to compute 2000 hashes
for randomly generated 160 bit long messages and then computed the average
time it took. We used a security parameter of 2048 and chose all sizes in the
underlying primitives according to the NIST Recommendations 2012 [17]. For
the elliptic curve variation of the Ateniese and de Medeiros hash we used the
P-224 curve.

The collision ﬁnding performances were measured by running the experiment
above with the diﬀerence that we additionally computed a collision for another
randomly generated message after each hash operation. The average times for
computing one hash, or one hash and one collision respectively are depicted in
Table 2.

One can see that when only performing the hash operation, the Fiat-Shamir
construction is the fastest one. Unfortunately its performance for computing
collisions is very poor, which renders it infeasible for applications that require
high throughput. Quiet interestingly Ateniese and de Medeiros is slower than its
elliptic curve pendant. Further tests with a smaller security parameter like 1024
showed that the elliptic curve variant is slower at ﬁrst, but scales much better,
when the security parameter increases. As expected from the mathematical de-
scription of the Krawczyk-Rabin chameleon hash, it performs very well and its

Fiat-Shamir Krawczyk-Rabin Ateniese and de Medeiros Ateniese and de Medeiros (EC)

Hash
Hash and Coll.

6.501

2143.046

10.213
10.2305

26.617
54.1225

7.637
13.134

Table 2. Chameleon hash function benchmarks in milliseconds.

collision ﬁnding algorithm is extremely eﬃcient. However, it is not invertible and
therefore it cannot be used in the dynamic constructions.

