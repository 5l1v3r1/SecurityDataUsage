Tackling Bufferbloat in 3G/4G Networks

Haiqing Jiang1, Yaogong Wang1, Kyunghan Lee2, and Injong Rhee1

North Carolina State University, USA 1 Ulsan National Institute of Science and Technology, Korea 2

{hjiang5, ywang15, rhee}@ncsu.edu

khlee@unist.ac.kr

ABSTRACT
The problem of overbuﬀering in the current Internet (termed
as buﬀerbloat) has drawn the attention of the research com-
munity in recent years. Cellular networks keep large buﬀers
at base stations to smooth out the bursty data traﬃc over
the time-varying channels and are hence apt to buﬀerbloat.
However, despite their growing importance due to the boom
of smart phones, we still lack a comprehensive study of
buﬀerbloat in cellular networks and its impact on TCP per-
formance. In this paper, we conducted extensive measure-
ment of the 3G/4G networks of the four major U.S. carriers
and the largest carrier in Korea. We revealed the severity
of buﬀerbloat in current cellular networks and discovered
some ad-hoc tricks adopted by smart phone vendors to mit-
igate its impact. Our experiments show that, due to their
static nature, these ad-hoc solutions may result in perfor-
mance degradation under various scenarios. Hence, a dy-
namic scheme which requires only receiver-side modiﬁcation
and can be easily deployed via over-the-air (OTA) updates
is proposed. According to our extensive real-world tests, our
proposal may reduce the latency experienced by TCP ﬂows
by 25% ∼ 49% and increase TCP throughput by up to 51%
in certain scenarios.

Categories and Subject Descriptors
C.2.2 [Computer-Communication Networks]: Network
Protocols

General Terms
Design, Measurement, Performance

Keywords
Buﬀerbloat, Cellular Networks, TCP, Receive Window

1.

INTRODUCTION

Buﬀerbloat, as termed by Gettys [10], is a phenomenon
where oversized buﬀers in the network result in extremely

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
IMC’12, November 14–16, 2012, Boston, Massachusetts, USA.
Copyright 2012 ACM 978-1-4503-1705-4/12/11 ...$15.00.

Conventional Networks
e.g., WiFi, Wired Networks

Server

Cellular Networks

e.g., 3G, 4G

Client

Figure 1: Buﬀerbloat has been widely observed in
the current Internet but is especially severe in cel-
lular networks, resulting in up to several seconds of
round trip delay.

long delay and other performance degradation. It has been
observed in diﬀerent parts of the Internet, ranging from
ADSL to cable modem users [5, 17, 26]. Cellular networks
are another place where buﬀers are heavily provisioned to
accommodate the dynamic cellular link (Figure 1). How-
ever, other than some ad-hoc observations [24], buﬀerbloat
in cellular networks has not been studied systematically.

In this paper, we carried out extensive measurements over
the 3G/4G networks of all four major U.S. carriers (AT&T,
Sprint, T-Mobile, Verizon) as well as the largest cellular car-
rier in Korea (SK Telecom). Our experiments span more
than two months and consume over 200GB of 3G/4G data.
According to our measurements, TCP has a number of per-
formance issues in buﬀerbloated cellular networks, includ-
ing extremely long delays and sub-optimal throughput. The
reasons behind such performance degradation are two-fold.
First, most of the widely deployed TCP implementations
use loss-based congestion control where the sender will not
slow down its sending rate until it sees packet loss. Sec-
ond, most cellular networks are overbuﬀered to accommo-
date traﬃc burstiness and channel variability [20]. The ex-
ceptionally large buﬀer along with link layer retransmission
conceals packet losses from TCP senders. The combination
of these two facts leads to the following phenomenon: the
TCP sender continues to increase its sending rate even if it
has already exceeded the bottleneck link capacity since all
of the overshot packets are absorbed by the buﬀers. This
results in up to several seconds of round trip delay. This
extremely long delay did not cause critical user experience
problems today simply because 1) base stations typically
has separate buﬀer space for each user [20] and 2) users
do not multitask on smart phones very often at this point.
This means only a single TCP ﬂow is using the buﬀer space.
If it is a short-lived ﬂow like Web browsing, queues will
not build up since the traﬃc is small. If it is a long-lived

329ﬂow like downloading a ﬁle, long queues will build up but
users hardly notice them since it is the throughput that mat-
ters rather than the delay. However, as the smart phones
become more and more powerful (e.g., several recently re-
leased smart phones are equipped with quad-core processors
and 2GB of memory), users are expected to perform multi-
tasking more often. If a user is playing an online game and
at the same time downloading a song in the background,
severe problem will appear since the time-sensitive gaming
traﬃc will experience huge queuing delays caused by the
background download. Hence, we believe that buﬀerbloat
in 3G/4G networks is an important problem that must be
addressed in the near future.

This problem is not completely unnoticed by today’s smart
phone vendors. Our investigation into the open source An-
droid platform reveals that a small untold trick has been
applied to mitigate the issue: the maximum TCP receive
buﬀer size parameter (tcp rmem max ) has been set to a rel-
atively small value although the physical buﬀer size is much
larger. Since the advertised receive window (rwnd) cannot
exceed the receive buﬀer size and the sender cannot send
more than what is allowed by the advertised receive win-
dow, the limit on tcp rmem max eﬀectively prevents TCP
congestion window (cwnd) from excessive growth and con-
trols the RTT (round trip time) of the ﬂow within a reason-
able range. However, since the limit is statically conﬁgured,
it is sub-optimal in many scenarios, especially considering
the dynamic nature of the wireless mobile environment. In
high speed long distance networks (e.g., downloading from
an oversea server over 4G LTE (Long Term Evolution) net-
work), the static value could be too small to saturate the
link and results in throughput degradation. On the other
hand, in small bandwidth-delay product (BDP) networks,
the static value may be too large and the ﬂow may experi-
ence excessively long RTT.

There are many possible ways to tackle this problem, rang-
ing from modifying TCP congestion control algorithm at the
sender to adopting Active Queue Management (AQM) at
the base station. However, all of them incur considerable
deployment cost. In this paper, we propose dynamic receive
window adjustment (DRWA), a light-weight, receiver-based
solution that is cheap to deploy. Since DRWA requires mod-
iﬁcations only on the receiver side and is fully compatible
with existing TCP protocol, carriers or device manufactur-
ers can simply issue an over-the-air (OTA) update to smart
phones so that they can immediately enjoy better perfor-
mance even when interacting with existing servers.

DRWA is similar in spirit to delay-based congestion con-
trol algorithms but runs on the receiver side.
It modiﬁes
the existing receive window adjustment algorithm of TCP
to indirectly control the sending rate. Roughly speaking,
DRWA increases the advertised window when the current
RTT is close to the minimum RTT we have observed so far
and decreases it when RTT becomes larger due to queuing
delay. With proper parameter tuning, DRWA could keep
the queue size at the bottleneck link small yet non-empty
so that throughput and delay experienced by the TCP ﬂow
are both optimized. Our extensive experiments show that
DRWA reduces the RTT by 25% ∼ 49% while achieving
similar throughput in ordinary scenarios. In large BDP net-
works, DRWA can achieve up to 51% throughput improve-
ment over existing implementations.

In summary, the contributions of this paper include:

Clients in Seoul, Korea

Server in Seoul, Korea

Server in Raleigh, NC, US

Internet

Server in Princeton, NJ, US

(a) Experiment testbed

Samsung
Droid Charge
(Verizon)

HTC 
EVO Shift
(Sprint)

LG G2x
(T-Mobile)

iPhone 4
(AT&T)

Samsung 
Galaxy S2
(AT&T and
SK Telecom)

(b) Experiment phones

Figure 2: Our measurement framework spans across
the globe with servers and clients deployed in vari-
ous places in U.S. and Korea using the cellular net-
works of ﬁve diﬀerent carriers.

• We conducted extensive measurements in a range of
cellular networks (EVDO, HSPA+, LTE) across vari-
ous carriers and characterized the buﬀerbloat problem
in these networks.

• We anatomized the TCP implementation in state-of-
the-art smart phones and revealed the limitation of
their ad-hoc solution to the buﬀerbloat problem.

• We proposed a simple and immediately deployable so-
lution that is experimentally proven to be safe and
eﬀective.

The rest of the paper is organized as follow. Section 2 in-
troduces our measurement setup and highlights the severity
of buﬀerbloat in today’s 3G/4G networks. Section 3 then
investigates the impact of buﬀerbloat on TCP performance
and points out the pitfalls of high speed TCP variants in
cellular networks. The abnormal behavior of TCP in smart
phones is revealed in Section 4 and its root cause is located.
We then propose our solution DRWA in Section 5 and eval-
uate its performance in Section 6. Finally, alternative so-
lutions and related work are discussed in Section 7 and we
conclude our work in Section 8.

2. OBSERVATION OF BUFFERBLOAT IN

CELLULAR NETWORKS

Buﬀerbloat is a phenomenon prevalent in the current In-
ternet where excessive buﬀers within the network lead to
exceptionally large end-to-end latency and jitter as well as
throughput degradation. With the recent boom of smart
phones and tablets, cellular networks become a more and
more important part of the Internet. However, despite the

3301000

)

B
K

(
 
t
h
g

i
l

F
 
n
i
 
s
t
e
k
c
a
P

800

600

400

200

 

0
0

AT&T HSPA+

Sprint EVDO T−Mobile HSPA+ Verizon EVDO Campus WiFi

 

500

1000

1500

For each ACK

2000

2500

3000

Figure 3: We observed exceptionally fat pipes across
the cellular networks of ﬁve diﬀerent carriers. We
tried three diﬀerent client/server locations under
both good and weak signal case. This shows the
prevalence of buﬀerbloat in cellular networks. The
ﬁgure above is a representative example.

abundant measurement studies of the cellular Internet [4,
18, 20, 23, 14], the speciﬁc problem of buﬀerbloat in cellular
networks has not been studied systematically. To obtain a
comprehensive understanding of this problem and its impact
on TCP performance, we have set up the following measure-
ment framework which is used throughout the paper.

2.1 Measurement Setup

Figure 2(a) gives an overview of our testbed. We have
servers and clients deployed in various places in U.S. and
Korea so that a number of scenarios with diﬀerent BDPs
can be tested. All of our servers run Ubuntu 10.04 (with
2.6.35.13 kernel) and use its default TCP congestion control
algorithm CUBIC [11] unless otherwise noted. We use sev-
eral diﬀerent phone models on the client side, each working
with the 3G/4G network of s speciﬁc carrier (Figure 2(b)).
The signal strength during our tests ranges from -75dBm to
-105dBm so that it covers both good signal condition and
weak signal condition. We develop some simple applications
on the client side to download data from the server with
diﬀerent traﬃc patterns (short-lived, long-lived, etc.). The
most commonly used traﬃc pattern is long-lived TCP ﬂow
where the client downloads a very large ﬁle from the server
for 3 minutes (the ﬁle is large enough so that the down-
load never ﬁnishes within 3 minutes). Most experiments
have been repeated numerous times for a whole day with a
one-minute interval between each run. That results in more
than 300 samples for each experiment based on which we
calculate the average and the conﬁdence interval.

For the rest of the paper, we only consider the perfor-
mance of the downlink (from base station to mobile station)
since it is the most common case. We leave the measure-
ment of uplink performance as our future work. Since we
are going to present a large number of measurement results
under various conditions in this paper, we provide a table
that summaries the setup of each experiment for the reader’s
convenience. Please refer to Table 1 in Appendix A.

2.2 Bufferbloat in Cellular Networks

The potential problem of overbuﬀering in cellular net-
works was pointed out by Ludwig et al. [21] as early as 1999
when researchers were focusing on GPRS networks. How-
ever, overbuﬀering still prevails in today’s 3G/4G networks.
To estimate the buﬀer space in current cellular networks,

)
s
m

(
 
p
o
H
 
h
c
a
E

 
f
o
 
T
T
R

2500

2000

1500

1000

500

0

 

 

Without background traffic
With background traffic

1

3

5

7
9
Hop Count

11

13

15

Figure 4: We veriﬁed that the queue is built up at
the very ﬁrst IP hop (from the mobile client).

we set up the following experiment: we launch a long-lived
TCP ﬂow from our server to a Linux laptop (Ubuntu 10.04
with 2.6.35.13 kernel) over the 3G networks of four major
U.S. carriers. By default, Ubuntu sets both the maximum
TCP receive buﬀer size and the maximum TCP send buﬀer
size to a large value (greater than 3MB). Hence, the ﬂow
will never be limited by the buﬀer size of the end points.
Due to the closed nature of cellular networks, we are unable
to know the exact queue size within the network. Instead,
we measure the size of packets in ﬂight on the sender side
to estimate the buﬀer space within the network. Figure 3
shows our measurement results. We observed exceptionally
fat pipes in all four major U.S. cellular carriers. Take Sprint
EVDO network for instance. The peak downlink rate for
EVDO is 3.1 Mbps and the observed minimum RTT (which
approximates the round-trip propagation delay) is around
150ms. Therefore, the BDP of the network is around 58KB.
But as the ﬁgure shows, Sprint is able to bear more than
800KB of packets in ﬂight!

As a comparison, we ran a similar experiment of a long-
lived TCP ﬂow between a client in Raleigh, U.S. and a server
in Seoul, Korea over the campus WiFi network. Due to the
long distance of the link and the ample bandwidth of WiFi,
the corresponding pipe size is expected to be large. However,
according to Figure 3, the size of in-ﬂight packets even in
such a large BDP network is still much smaller than the ones
we observed in cellular networks.

We extend the measurement to other scenarios in the ﬁeld
to verify that the observation is universal in current cellular
networks. For example, we have clients and servers in vari-
ous locations over various cellular networks in various signal
conditions (Table 1). All the scenarios prove the existence
of extremely fat pipes similar to Figure 3.

To further conﬁrm that the buﬀerbloat is within the cellu-
lar segment rather than the backbone Internet, we designed
the following experiment to locate where the long queue is
built up. We use Traceroute on the client side to measure the
RTT of each hop along the path to the server and compare
the results with or without a background long-lived TCP
ﬂow. If the queue is built up at hop x, the queuing delay
should increase signiﬁcantly at that hop when background
traﬃc is in place. Hence, we should see that the RTTs before
hop x do not diﬀer much no matter the background traﬃc is
present or not. But the RTTs after hop x should have a no-
table gap between the case with background traﬃc and the
case without. The results shown in Figure 4 demonstrate
that the queue is built up at the very ﬁrst hop. Note that
there could be a number of components between the mo-

331Verizon LTE
Verizon EVDO
AT&T HSPA+

800

700

600

500

400

300

200

100

)
s
m

(
 
g
n
P

i

 
f
o
 
T
T
R

 

)

B
K

i

i

 

(
 
e
z
S
w
o
d
n
W
 
n
o
i
t
s
e
g
n
o
C

0

 

1

3
Interval between Consecutive Pings (s)

11

5

7

9

13

15

Figure 5: RRC state transition only aﬀects short-
lived TCP ﬂows with considerable idle periods in
between (> 7s) but does not aﬀect long-lived ﬂows.

bile client and the ﬁrst IP hop (e.g., RNC, SGSN, GGSN,
etc.). It may not be only the wireless link between the mo-
bile station and the base station. Without administrative
access, we are unable to diagnose the details within the car-
rier’s network but according to [20] large per-user buﬀer are
deployed at the base station to absorb channel ﬂuctuation.
Another concern is that the extremely long delays we ob-
served in cellular networks are due to Radio Resource Con-
trol (RRC) state transitions [1] rather than buﬀerbloat. We
set up the following experiment to demonstrate that these
two problems are orthogonal. We repeatedly ping our server
from the mobile station with diﬀerent intervals between con-
secutive pings. The experiment has been carried out for a
whole day and the average RTT of the ping is calculated.
According to the RRC state transition diagram, if the in-
terval between consecutive pings is long enough, we should
observe a substantially higher RTT due to the state promo-
tion delay. By varying this interval in each run, we could ob-
tain the threshold that would trigger RRC state transition.
As shown in Figure 5, when the interval between consecutive
pings is beyond 7 seconds (speciﬁc threshold depends on the
network type and the carrier), there is a sudden increase in
RTT which demonstrates the state promotion delay. How-
ever, when the interval is below 7 seconds, RRC state tran-
sition does not seem to aﬀect the performance. Hence, we
conclude that RRC state transition may only aﬀect short-
lived TCP ﬂows with considerable idle periods in between
(e.g., Web browsing), but does not aﬀect long-lived TCP
ﬂows we were testing since their packet intervals are typi-
cally at millisecond scale. When the interval between pack-
ets is short, the cellular device should remain in CELL DCH
state and state promotion delays would not contribute to the
extremely long delays we observed.

3. TCP PERFORMANCE OVER BUFFER-

BLOATED CELLULAR NETWORKS

Given the exceptionally large buﬀer size in cellular net-
works as observed in Section 2, in this section we investigate
its impact on TCP’s behavior and performance. We carried
out similar experiments to Figure 3 but observed the con-
gestion window size and RTT of the long-lived TCP ﬂow
instead of packets in ﬂight. As Figure 6 shows, TCP con-
gestion window keeps probing even if its size is far beyond
the BDP of the underlying network. With so much over-
shooting, the extremely long RTT (up to 10 seconds!) as
shown in Figure 6(b) is not surprising.

1400

1200

1000

800

600

400

200

 

0
0

4
10

AT&T HSPA+ Sprint EVDO T−Mobile HSPA+ Verizon EVDO

 

10

20

30

Time (s)

40

50

60

(a) Congestion Window Size

AT&T HSPA+ Sprint EVDO T−Mobile HSPA+ Verizon EVDO

 

)
s
m

(
 
T
T
R

3
10

 

0

10

20

30

Time (s)

40

50

60

(b) Round Trip Time

Figure 6: TCP congestion window grows way be-
yond the BDP of the underlying network due to
buﬀerbloat. Such excessive overshooting leads to
extremely long RTT.

In the previous experiment, the server used CUBIC as its
TCP congestion control algorithm. However, we are also
interested in the behaviors of other TCP congestion con-
trol algorithms under buﬀerbloat. According to [32], a large
portion of the Web servers in the current Internet use high
speed TCP variants such as BIC [30], CUBIC [11], CTCP
[27], HSTCP [7] and H-TCP [19]. How these high speed
TCP variants would perform in buﬀerbloated cellular net-
works as compared to less aggressive TCP variants like TCP
NewReno [8] and TCP Vegas [2] is of great interest.

Figure 7 shows the cwnd and RTT of TCP NewReno, Ve-
gas, CUBIC, BIC, HTCP and HSTCP under AT&T HSPA+
network. We left CTCP out of the picture simply because we
are unable to know its internal behavior due to the closed na-
ture of Windows. As the ﬁgure shows, all the loss-based high
speed TCP variants (CUBIC, BIC, HTCP, HSTCP) over-
shoot more often than NewReno. These high speed variants
were originally designed for eﬃcient probing of the available
bandwidth in large BDP networks. But in buﬀerbloated cel-
lular networks, they only make the problem worse by con-
stant overshooting. Hence, the buﬀerbloat problem adds a
new dimension in the design of an eﬃcient TCP congestion
control algorithm.

In contrast, TCP Vegas is resistive to buﬀerbloat as it uses
a delay-based congestion control algorithm that backs oﬀ as
soon as RTT starts to increase. This behavior prevents cwnd
from excessive growth and keeps the RTT at a low level.
However, delay-based TCP congestion control has its own
problems and is far from a perfect solution to buﬀerbloat.
We will further discuss this aspect in Section 7.

332)
s
t
n
e
m
g
e
S

i

i

 

(
 
e
z
S
w
o
d
n
W
 
n
o
i
t
s
e
g
n
o
C

600

500

400

300

200

100

 
 

0
0

NewReno
Vegas

 
 

CUBIC
BIC
HTCP
HSTCP

1500

1000

500

)
s
m

(
 
T
T
R

NewReno
Vegas

 
 

CUBIC
BIC
HTCP
HSTCP

2000

4000

6000

For each ACK

8000

10000

12000

 
 

0
0

2000

4000

6000

For each ACK

8000

10000

12000

(a) Congestion Window Size

(b) Round Trip Time

Figure 7: All the loss-based high speed TCP variants (CUBIC, BIC, HTCP, HSTCP) suﬀer from the
buﬀerbloat problem more severely than NewReno. But TCP Vegas, a delay-based TCP variant, is resis-
tive to buﬀerbloat.

4. CURRENT TRICK BY SMART PHONE

4.1 Understanding the Abnormal Flat TCP

VENDORS AND ITS LIMITATION

The previous experiments used a Linux laptop with mobile
broadband USB modem as the client. We have not looked
at other platforms yet, especially the exponentially growing
smart phones. In the following experiment, we explore the
behavior of diﬀerent TCP implementations in various desk-
top (Windows 7, Mac OS 10.7, Ubuntu 10.04) and mobile
operating systems (iOS 5, Android 2.3, Windows Phone 7)
over cellular networks.

 
 

)

B
K

(
 

i

 

e
z
S
w
o
d
n
W
n
o

 

i

i
t
s
e
g
n
o
C

700

600

500

400

300

200

100

 
 

0
0

Windows 7
Mac OS 10.7
iOS 5

Android 2.3
Ubuntu 10.04
Windows Phone 7

10

20

30

Time (s)

40

50

60

Figure 8: The behavior of TCP in various platforms
over AT&T HSPA+ network exhibits two patterns:
“ﬂat TCP” and “fat TCP”.

Figure 8 depicts the evolution of TCP congestion win-
dow when clients of various platforms launch a long-lived
TCP ﬂow over AT&T HSPA+ network. To our surprise,
two types of cwnd patterns are observed: “ﬂat TCP” and
“fat TCP”. Flat TCP, such as observed in Android phones,
is the phenomenon where the TCP congestion window grows
to a constant value and stays there until the session ends.
On the other hand, fat TCP, such as observed in Windows
Phone 7, is the phenomenon that packet loss events do not
occur until the congestion window grows to a large value far
beyond the BDP. Fat TCP can easily be explained by the
buﬀerbloat in cellular networks and the loss-based conges-
tion control algorithm. But the abnormal ﬂat TCP behavior
caught our attention and revealed an untold story of TCP
over cellular networks.

How could the TCP congestion window stay at a constant
value? The static cwnd ﬁrst indicates that no packet loss
is observed by the TCP sender (otherwise the congestion
window should have decreased multiplicatively at any loss
event). This is due to the large buﬀers in cellular networks
and its link layer retransmission mechanism as discussed ear-
lier. Measurement results from [14] also conﬁrm that cellular
networks typically experience close-to-zero packet loss rate.
If packet losses are perfectly concealed, the congestion
window may not drop but it will persistently grow as fat
TCP does. However,
it unexpectedly stops at a certain
value and this value is diﬀerent for each cellular network
or client platform. Our inspection into the TCP implemen-
tation in Android phones (since it is open-source) reveals
that the value is determined by the tcp rmem max param-
eter that speciﬁes the maximum receive window advertised
by the Android phone. This gives the answer to ﬂat TCP be-
havior: the receive window advertised by the receiver crops
the congestion windows in the sender. By inspecting var-
ious Android phone models, we found that tcp rmem max
has diverse values for diﬀerent types of networks (refer to
Table 2 in Appendix B for some sample settings). Generally
speaking, larger values are assigned to faster communica-
tion standards (e.g., LTE). But all the values are statically
conﬁgured.

To understand the impact of such static settings, we com-
pared the TCP performance under various tcp rmem max
values in AT&T HSPA+ network and Verizon LTE network
in Figure 9. Obviously, a larger tcp rmem max allows the
congestion window to grow to a larger size and hence leads to
higher throughput. But this throughput improvement will
ﬂatten out once the link is saturated. Further increase of
tcp rmem max brings nothing but longer queuing delay and
hence longer RTT. For instance, when downloading from
a nearby server, the RTT is relatively small. In such small
BDP networks, the default values for both HSPA+ and LTE
are large enough to achieve full bandwidth utilization as
shown in Figure 9(a). But they trigger excessive packets
in ﬂight and result in unnecessarily long RTT as shown in
Figure 9(b). This demonstrates the limitation of static pa-
rameter setting: it mandates one speciﬁc trade-oﬀ point in
the system which may be sub-optimal for other applications.
Two realistic scenarios are discussed in the next subsection.

333)
s
p
b
M

(
 
t
u
p
h
g
u
o
r
h
T

20

15

10

5

0

 

AT&T HSPA+ (default: 262144)
Verizon LTE (default: 484848)

 

65536

110208

262144

484848

524288

655360

tcp_rmem_max (Bytes)

)
s
m

(
 
T
T
R

1400

1200

1000

800

600

400

200

0

 

AT&T HSPA+ (default: 262144)
Verizon LTE (default: 484848) 

 

65536

110208

262144

484848

524288

655360

tcp_rmem_max (Bytes)

(a) Throughput

(b) Round Trip Time

Figure 9: Throughput and RTT performance of a long-lived TCP ﬂow in a small BDP network under diﬀerent
tcp rmem max settings. For this speciﬁc environment, 110208 may work better than the default 262144 in
AT&T HSPA+ network. Similarly, 262144 may work better than the default 484848 in Verizon LTE network.
However, the optimal value depends on the BDP of the underlying network and is hard to be conﬁgured
statically in advance.

4.2 Impact on User Experience
Web Browsing with Background Downloading: The
high-end smart phones released in 2012 typically have quad-
core processors and more than 1GB of RAM. Due to their
signiﬁcantly improved capability, the phones are expected to
multitask more often. For instance, people will enjoy Web
browsing or online gaming while downloading ﬁles such as
books, music, movies or applications in the background. In
such cases, we found that the current TCP implementation
incurs long delays for the interactive ﬂow (Web browsing or
online gaming) since the buﬀer is ﬁlled with packets belong-
ing to the background long-lived TCP ﬂow.

)
x
 
≤
 
X
P

(

1

0.8

0.6

0.4

0.2

 

0
0

 

With background downloading (avg=2.65s)
Without background downloading (avg=1.02s)

5

Web Object Fetching Time (s)

10

15

Figure 10: The average Web object fetching time
is 2.6 times longer when background downloading is
present.

Figure 10 demonstrates that the Web object fetching time
is severely degraded when a background download is un-
der way. In this experiment, we used a simpliﬁed method
to emulate Web traﬃc. The mobile client generates Web
requests according to a Poisson process. The size of the
content brought by each request is randomly picked among
8KB, 16KB, 32KB and 64KB. Since these Web objects are
small, their fetching time mainly depends on RTT rather
than throughput. When a background long-lived ﬂow causes
long queues to be built up, the average Web object fetching
time becomes 2.6 times longer.
Throughput in Large BDP Networks: The sites that
smart phone users visit are diverse. Some contents are well
maintained and CDNs (content delivery networks) are as-

sisting them to get “closer” to their customers via replica-
tion.
In such cases, the throughput performance can be
satisfactory since the BDP of the network is small (Fig-
ure 9). However, there are still many sites with long latency
due to their remote locations. In such cases, the static set-
ting of tcp rmem max (which is tuned for moderate latency
case) fails to ﬁll the long fat pipe and results in sub-optimal
throughput. Figure 11 shows that when a mobile client in
Raleigh, U.S. downloads contents from a server in Seoul, Ko-
rea over AT&T HSPA+ network and Verizon LTE network,
the default setting is far from optimal in terms of through-
put performance. A larger tcp rmem max can achieve much
higher throughput although setting it too large may cause
packet loss and throughput degradation.

In summary, ﬂat TCP has performance issues in both
throughput and delay. In small BDP networks, the static
setting of tcp rmem max may be too large and cause un-
necessarily long end-to-end latency. On the other hand, it
may be too small in large BDP networks and suﬀer from
signiﬁcant throughput degradation.

5. OUR SOLUTION

In light of the limitation of a static tcp rmem max setting,
we propose a dynamic receive window adjustment algorithm
to adapt to various scenarios automatically. But before dis-
cussing our proposal, let us ﬁrst look at how TCP receive
windows are controlled in the current implementations.

5.1 Receive Window Adjustment in Current

TCP Implementations

As we know, the TCP receive window was originally de-
signed to prevent a fast sender from overwhelming a slow
receiver with limited buﬀer space. It reﬂects the available
buﬀer size on the receiver side so that the sender will not
send more packets than the receiver can accommodate. This
is called TCP ﬂow control, which is diﬀerent from TCP con-
gestion control whose goal is to prevent overload in the net-
work rather than at the receiver. Flow control and conges-
tion control together govern the transmission rate of a TCP
sender and the sending window size is the minimum of the
advertised receive window and the congestion window.

With the advancement in storage technology, memories
are becoming increasingly cheaper. Currently, it is common

33410

AT&T HSPA+ (default: 262144)
Verizon LTE (default: 484848)

 

 

1000

AT&T HSPA+ (default: 262144)
Verizon LTE (default: 484848) 

)
s
p
b
M

(
 
t
u
p
h
g
u
o
r
h
T

8

6

4

2

0

 

65536

262144

484848

655360

917504 1179648 1310720

tcp_rmem_max (Bytes)

)
s
m

(
 
T
T
R

800

600

400

200

0

 

65536

262144

484848

655360

tcp_rmem_max (Bytes)

917504 1179648 1310720

(a) Throughput

(b) Round Trip Time

Figure 11: Throughput and RTT performance of a long-lived TCP ﬂow in a large BDP network under diﬀerent
tcp rmem max settings. The default setting results in sub-optimal throughput performance since it fails to
saturate the long fat pipe. 655360 for AT&T and 917504 for Verizon provide much higher throughput.

to ﬁnd computers (or even smart phones) equipped with gi-
gabytes of RAM. Hence, buﬀer space on the receiver side
is hardly the bottleneck in the current Internet. To im-
prove TCP throughput, a receive buﬀer auto-tuning tech-
nique called Dynamic Right-Sizing (DRS [6]) was proposed.
In DRS, instead of determining the receive window based
by the available buﬀer space, the receive buﬀer size is dy-
namically adjusted in order to suit the connection’s demand.
Speciﬁcally, in each RTT, the receiver estimates the sender’s
congestion window and then advertises a receive window
which is twice the size of the estimated congestion window.
The fundamental goal of DRS is to allocate enough buﬀer
(as long as we can aﬀord it) so that the throughput of the
TCP connection is never limited by the receive window size
but only constrained by network congestion. Meanwhile,
DRS tries to avoid allocating more buﬀers than necessary.

Linux adopted a receive buﬀer auto-tuning scheme simi-
lar to DRS since kernel 2.4.27. Since Android is based on
Linux, it inherits the same receive window adjustment al-
gorithm. Other major operating systems also implemented
customized TCP buﬀer auto-tuning (Windows since Vista,
Mac OS since 10.5, FreeBSD since 7.0). This implies a sig-
niﬁcant role change for the TCP receive window. Although
the functionality of ﬂow control is still preserved, most of
the time the receive window as well as the receive buﬀer size
is undergoing dynamic adjustments. However, this dynamic
adjustment is unidirectional: DRS increases the receive win-
dow size only when it might potentially limit the congestion
window growth but never decreases it.

5.2 Dynamic Receive Window Adjustment

As discussed earlier, setting a static limit on the receive
window size is inadequate to adapt to the diverse network
scenarios in the mobile environment. We need to adjust
the receive window dynamically. DRS is already doing this,
but its adjustment is unidirectional. It does not solve the
buﬀerbloat problem. In fact, it makes it worse by incessantly
increasing the receive window size as the congestion window
size grows. What we need is a bidirectional adjustment al-
gorithm to rein TCP in the buﬀerbloated cellular networks.
At the same time it needs to ensure full utilization of the
available bandwidth. Hence, we build our DRWA proposal
on top of DRS and Algorithm 1 gives the details.

DRWA uses the same technique as DRS to measure RTT
on the receiver side when the TCP timestamp option [15] is

Algorithm 1 DRWA
1: Initialization:
2: tcp rmem max ← a large value;
3: RT Tmin ← ∞;
4: cwndest ← data rcvd in the ﬁrst RT Test;
5: rwnd ← 0;
6:
7: RTT and minimum RTT estimation:
8: RT Test ← the time between when a byte is ﬁrst acknowl-
edged and the receipt of data that is at least one window
beyond the sequence number that was acknowledged;

9:
10: if TCP timestamp option is available then
11: RT Test ← averaging the RTT samples obtained from

the timestamps within the last RTT;

12: end if
13:
14: if RT Test < RT Tmin then
15: RT Tmin ← RT Test;
16: end if
17:
18: DRWA:
19: if data is copied to user space then
20:
21:
22:
23:
24:
25:
26:
27: end if

if elapsed time < RT Test then

RT Tmin
RT Test

return;

end if

cwndest ← α ∗ cwndest + (1 − α) ∗ data rcvd;
rwnd ← λ ∗
Advertise rwnd as the receive window size;

∗ cwndest;

not available (Line 8). However, if the timestamp option is
available, DRWA uses it to obtain a more accurate estima-
tion of the RTT (Line 10–12). TCP timestamp can provide
multiple RTT samples within an RTT whereas the tradi-
tional DRS way provides only one sample per RTT. With
the assistance of timestamps, DRWA is able to achieve ro-
bust RTT measurement on the receiver side. We also sur-
veyed that both Windows Server and Linux support TCP
timestamp option as long as the client requests it in the
initial SYN segment. DRWA records the minimum RTT
ever seen in this connection and uses it to approximate the

335300

)

B
K

(
 

250

 

Without DRWA
With DRWA

9000

8000

7000

6000

5000

4000

3000

2000

1000

)
s
m

(
 
T
T
R

 

Without DRWA
With DRWA

3.5

3

2.5

2

1.5

1

0.5

)
s
p
b
M

(
 
t

u
p
h
g
u
o
r
h
T

 

Without DRWA
With DRWA

i

 

e
z
S
w
o
d
n
W
n
o

 

i

i
t
s
e
g
n
o
C

200

150

100

50

 

0
0

10

20

30

40

Time (s)

50

60

70

80

 

0
0

10

20

30

40

Time (s)

50

60

70

80

 

0
0

10

20

30

40

Time (s)

50

60

70

80

(a) Receive Window Size

(b) Round Trip Time

(c) Throughput

Figure 12: When the smart phone is moved from a good signal area to a weak signal area and then moved
back, DRWA nicely tracks the variation of the channel conditions and dynamically adjusts the receive window
size, leading to a constantly low RTT but no throughput loss.

round-trip propagation delay when no queue is built up in
the intermediate routers (Line 14–16).

After knowing the RTT, DRWA counts the amount of
data received within each RTT and smooths the estimated
congestion window by a moving average with a low-pass ﬁl-
ter (Line 24). α is set to 7/8 in our current implementation.
This smoothed value is used to determine the receive window
we advertise. In contrast to DRS who always sets rwnd to
∗ cwndest where λ is
2 ∗ cwndest, DRWA sets it to λ ∗
a tunable parameter larger than 1 (Line 25). When RT Test
is close to RT Tmin, implying the network is not congested,
rwnd will increase quickly to give the sender enough space
to probe the available bandwidth. As RT Test increases, we
gradually slow down the increment rate of rwnd to stop TCP
from overshooting. Thus, DRWA makes bidirectional ad-
justment of the advertised window and controls the RT Test
to stay around λ ∗ RT Tmin. More detailed discussion on the
impact of λ will be given in Section 5.4.

RT Tmin
RT Test

This algorithm is simple yet eﬀective. Its ideas stem from
delay-based congestion control algorithms but work better
than they do for two reasons. First, since DRWA only guides
the TCP congestion window by advertising an adaptive re-
ceive window, the bandwidth probing responsibility still lies
with the TCP congestion control algorithm at the sender.
Therefore, typical throughput degradation seen in delay-
based TCP will not appear. Second, due to some unique
characteristics of cellular networks, delay-based control can
work more eﬀectively: in wired networks, a router may han-
dle hundreds of TCP ﬂows at the same time and they may
share the same output buﬀer. That makes RTT measure-
ment noisy and delay-based congestion control unreliable.
However, in cellular networks, a base station typically has
separate buﬀer space for each user [20] and a mobile user is
unlikely to have many simultaneous TCP connections. This
makes RTT measurement a more reliable signal for network
congestion.

However, DRWA may indeed suﬀer from one same prob-
lem as delay-based congestion control:
inaccurate RT Tmin
estimation. For instance, when a user move from a location
with small RT Tmin to a location with large RT Tmin, the
ﬂow may still memorize the previous smaller RT Tmin and
incorrectly adjust the receive window, leading to potential
throughput loss. However, we believe that the session time
is typically shorter than the time scale of movement. Hence,
this problem will not occur often in practice. Further, we
may supplement our algorithm with an accelerometer mon-
itoring module so that we can reset RT Tmin in case of fast
movement. We leave this as our future work.

)
x
 
≤
 
X
P

(

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

 

0
5

 

Without DRWA
(avg=11.58)
With DRWA
(avg=11.61)

10

Throughput (Mbps)

15

)
x
 
≤
 
X
P

(

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

 

0
30

 

Without DRWA(avg=36.64)
With DRWA(avg=37.65)

40

50

RTT (ms)

60

70

Figure 13: DRWA has negligible impact in networks
that are not buﬀerbloated (e.g., WiFi).

5.3 The Adaptive Nature of DRWA

DRWA allows a TCP receiver to dynamically report a
proper receive window size to its sender in every RTT rather
than advertising a static limit. Due to its adaptive nature,
DRWA is able to track the variation of the channel condi-
tions. Figure 12 shows the evolution of the receive window
and the corresponding RTT/throughput performance when
we move an Android phone from a good signal area to a weak
signal area (from 0 second to 40 second) and then return to
the good signal area (from 40 second to 80 second). As
shown in Figure 12(a), the receive window size dynamically
adjusted by DRWA well tracks the signal strength change
incurred by movement. This leads to a steadily low RTT
while the default static setting results in an ever increasing
RTT as the signal strength decreases and the RTT blows
up in the area of the weakest signal strength (Figure 12(b)).
With regard to throughput performance, DRWA does not
cause any throughput loss and the curve naturally follows
the change in signal strength.

In networks that are not buﬀerbloated, DRWA has neg-
ligible impact on TCP behavior. That is because, when
the buﬀer size is set to the BDP of the network (the rule
of thumb for router buﬀer sizing), packet loss will happen
before DRWA starts to rein the receive window. Figure 13
veriﬁes that TCP performs similarly with or without DRWA
in WiFi networks. Hence, we can safely deploy DRWA in
smart phones even if they may connect to non-buﬀerbloated
networks.

5.4 The Impact of λ

λ is a key parameter in DRWA. It tunes the operation
region of the algorithm and reﬂects the trade-oﬀ between

336)
s
p
b
M

(
 
t

u
p
h
g
u
o
r
h
T

1.2

1

0.8

0.6

0.4

0.2

0

 

λ = 2
λ = 3
λ = 4

 

Verizon EVDO Sprint EVDO

6

5

4

3

2

1

0

AT&T HSPA+SKTel. HSPA+

(a) Throughput

λ = 2
λ = 3
λ = 4

600

500

400

300

200

100

)
s
m

(
 
T
T
R

0

 

Verizon EVDO Sprint EVDO

 

600

500

400

300

200

100

0

AT&T HSPA+SKTel. HSPA+

11

10

9

8

7

6

5

4

3

2

1

0

300

250

200

150

100

50

0

 

 

1

0.8

0.6

0.4

0.2

)
x
 
≤
 
X
P

(

Verizon LTE

 

0
0

2

Without DRWA (avg=3.56s)
With DRWA (avg=2.16s)

4

Web Object Fetching Time (s)

6

8

10

12

(a) Web Object Fetching Time

1

0.8

0.6

0.4

0.2

)
x
 
≤
 
X
P

(

Verizon LTE

 

0
0

200

400

600

Without DRWA (avg=523.39ms)
With DRWA (avg=305.06ms)
1000
1600

1200

1400

800
RTT (ms)

(b) Round Trip Time

(b) Round Trip Time

Figure 14: The impact of λ on the performance of
TCP: λ = 3 seems to give a good balance between
throughput and RTT.

Figure 15: DRWA improves the Web object fetching
time with background downloading by 39%.

throughput and delay. Note that when RT Test/RT Tmin
equals to λ, the advertised receive window will be equal to
its previous value, leading to a steady state. Therefore, λ
reﬂects the target RTT of DRWA. If we set λ to 1, that
means we want RTT to be exactly RT Tmin and no queue is
allowed to be built up. This ideal case works only if 1) the
traﬃc has constant bit rate, 2) the available bandwidth of
the wireless channel is also constant and 3) the constant bit
rate equals to the constant bandwidth. In practice, Internet
traﬃc is bursty and the channel condition varies over time.
Both necessitate the existence of some buﬀers to absorb the
temporarily excessive traﬃc and drain the queue later on
when the load becomes lighter or the channel condition be-
comes better. λ determines how aggressive we want to be in
keeping the link busy and how much delay penalty we can
tolerate. The larger λ is, the more aggressive the algorithm
is. It will guarantee the throughput of TCP to be maximized
but at the same time introduce extra delays. Figure 14 gives
the performance comparison of diﬀerent values of λ in terms
of throughput and RTT1. This test combines multiple sce-
narios ranging from small to large BDP networks, good to
weak signal, etc. Each has been repeated 400 times over
the span of 24 hours in order to ﬁnd the optimal parameter
setting. As the ﬁgure shows, λ = 3 has some throughput
advantage over λ = 2 under certain scenarios. Further in-
creasing it to 4 does not seems to improve throughput but
only incurs extra delay. Hence, we set λ to 3 in our current
implementation. A potential future work is to make this
parameter adaptive.

1We plot diﬀerent types of cellular networks separately since
they have drastically diﬀerent peak rates. Putting LTE
and EVDO together will make the throughput diﬀerences
in EVDO networks indiscernible.

5.5 Improvement in User Experience

Section 4.2 lists two scenarios where the static setting of
tcp rmem max may have a negative impact on user experi-
ence. In this subsection, we demonstrate that, by applying
DRWA, we can dramatically improve user experience in such
scenarios. More comprehensive experiment results are pro-
vided in Section 6.

Figure 15 shows Web object fetching performance with a
long-lived TCP ﬂow in the background. Since DRWA re-
duces the length of the queue built up in the cellular net-
works, it brings 42% reduction in RTT on average, which
translates into 39% speed-up in Web object fetching. Note
that the absolute numbers in this test are not directly com-
parable with those in Figure 10 since these two experiments
were carried out at diﬀerent time.

Figure 16 shows the scenario where a mobile client in
Raleigh, U.S. launches a long-lived TCP download from a
server in Seoul, Korea over both AT&T HSPA+ network and
Verizon LTE network. Since the RTT is very long in this
scenario, the BDP of the underlying network is fairly large
(especially the LTE case since its peak rate is very high).
The static setting of tcp rmem max is too small to ﬁll the
long fat pipe and results in throughput degradation. With
DRWA, we are able to fully utilize the available bandwidth
and achieve 23% ∼ 30% improvement in throughput.

6. MORE EXPERIMENT RESULTS

We implemented DRWA in Android phones by patching
their kernels. It turned out to be fairly simple to implement
DRWA in the Linux/Android kernel. It only takes around
100 lines of code. We downloaded the original kernel source
codes of diﬀerent Android models from their manufacturers’
website, patched the kernels with DRWA and recompiled

337)
s
p
b
M

(
 
t

u
p
h
g
u
o
r
h
T

4.5

4

3.5

3

2.5

2

1.5

1

0.5

0

 

265ms

347ms

451ms

570ms

Propagation Delay

 

Without DRWA
With DRWA

677ms

)
s
p
b
M

(
 
t

u
p
h
g
u
o
r
h
T

1.4

1.2

1

0.8

0.6

0.4

0.2

0

 

326ms

433ms

 

Without DRWA
With DRWA

798ms

550ms

653ms

Propagation Delay

(a) Improvement in AT&T HSPA+:

-1%,

(b) Improvement in Verizon EVDO: -3%, -

0.1%, 6%, 26% and 41%

0.3%, 4%, 29% and 51%

)
s
p
b
M

(
 
t

u
p
h
g
u
o
r
h
T

1.2

1

0.8

0.6

0.4

0.2

0

 

312ms

448ms

536ms

625ms

Propagation Delay

 

Without DRWA
With DRWA

754ms

)
s
p
b
M

(
 
t

u
p
h
g
u
o
r
h
T

20

15

10

5

0

 

131ms

219ms

 

Without DRWA
With DRWA

533ms

351ms

439ms

Propagation Delay

(c) Improvement in Sprint EVDO: 4%, 5%,

37%, 45% and 51%

(d) Improvement in Verizon LTE: -1%, 39%,

37%, 26% and 31%

Figure 17: Throughput improvement brought by DRWA over various cellular networks: the larger the
propagation delay is, the more throughput improvement DRWA brings. Such long propagation delays are
common in cellular networks since all traﬃc must detour through the gateway [31].

 

Without DRWA
HSPA+ (avg=3.36)
With DRWA
HSPA+ (avg=4.14)
Without DRWA
LTE (avg=7.84)
With DRWA
LTE (avg=10.22)

1

0.8

0.6

0.4

0.2

)
x
 
≤
 
X
P

(

 

0
0

2

4

8
Throughput (Mbps)

6

10

12

Figure 16: DRWA improves the throughput by 23%
in AT&T HSPA+ network and 30% in Verizon LTE
network when the BDP of the underlying network
is large.

them. Finally, the phones were ﬂashed with our customized
kernel images.

6.1 Throughput Improvement

Figure 17 shows the throughput improvement brought by
DRWA over networks of various BDPs. We emulate dif-
ferent BDPs by applying netem [12] on the server side to
vary the end-to-end propagation delay. Note that the prop-
agation delays we have emulated are relatively large (from
131ms to 798ms). That is because RTTs in cellular networks
are indeed larger than conventional networks. Even if the
client and server are close to each other geographically, the
propagation delay between them could still be hundreds of
milliseconds. The reason is that all the cellular data have to

go through a few IP gateways [31] deployed across the coun-
try by the carriers. Due to this detour, the natural RTTs in
cellular networks are relatively large.

According to the ﬁgure, DRWA signiﬁcantly improves the
TCP throughput in various cellular networks as the propa-
gation delay increases. The scenario over the Sprint EVDO
network with the propagation delay of 754ms shows the
largest improvement (as high as 51%).
In LTE networks,
the phones with DRWA show throughput improvement up
to 39% under the latency of 219ms. The reason behind the
improvement is obvious. When the latency increases, the
static setting of tcp rmem max fails to saturate the pipe,
resulting in throughput degradation. In contrast, networks
with small latencies do not show such degradation since the
static value is large enough to ﬁll the pipe. According to our
experiences, RTTs between 400 ms and 700 ms are easily ob-
servable in cellular networks, especially when using services
from oversea servers. In LTE networks, TCP throughput is
even more sensitive to tcp rmem max setting. The BDP can
be dramatically increased by a slight RTT increase. There-
fore, the static conﬁguration easily becomes sub-optimal.
However, DRWA is able to keep pace with the varying BDP.

6.2 RTT Reduction

In networks with small BDP, the static tcp rmem max
setting is suﬃcient to fully utilize the bandwidth of the net-
work. However, it has a side eﬀect of long RTT. DRWA
manages to keep the RTT around λ times of RT Tmin, which
is substantially smaller than the current implementations in
networks with small BDP. Figure 18 shows that the reduc-
tion in RTT brought by DRWA does not come at the cost
of the throughput. We see a remarkable reduction of RTT

338)
x
 
≤
 
X
P

(

1

0.8

0.6

0.4

0.2

 

0
0

Without DRWA AT&T HSPA+ (avg=3.83)
With DRWA AT&T HSPA+ (avg=3.79)
Without DRWA Verizon LTE (avg=15.78)
With DRWA Verizon LTE (avg=15.43)

 

1

0.8

0.6

0.4

0.2

)
x
 
≤
 
X
P

(

5

10

Throughput (Mbps)

15

20

 

0
0

200

 

Without DRWA AT&T HSPA+ (avg=435.37)
With DRWA AT&T HSPA+ (avg=222.14)
Without DRWA Verizon LTE (avg=150.78)
With DRWA Verizon LTE (avg=97.39)

400

600

RTT (ms)

800

1000

(a) Throughput in HSPA+ and LTE net-

(b) RTT in HSPA+ and LTE networks

works

1

0.8

0.6

0.4

0.2

)
x
 
≤
 
X
P

(

 

0
0

0.5

 

Without DRWA Verizon EVDO (avg=0.91)
With DRWA Verizon EVDO (avg=0.92)
Without DRWA Sprint EVDO (avg=0.87)
With DRWA Sprint EVDO (avg=0.85)
1

1.5

2

Throughput (Mbps)

)
x
 
≤
 
X
P

(

1

0.8

0.6

0.4

0.2

0

 

200

400

600

 

Without DRWA Verizon EVDO (avg=701.67)
With DRWA Verizon EVDO (avg=360.94)
Without DRWA Sprint EVDO (avg=526.38)
With DRWA Sprint EVDO (avg=399.59)
1400

1000

1200

800

RTT (ms)

(c) Throughput in EVDO networks

(d) RTT in EVDO networks

Figure 18: RTT reduction in small BDP networks: DRWA provides signiﬁcant RTT reduction without
throughput loss across various cellular networks. The RTT reduction ratios are 49%, 35%, 49% and 24% for
AT&T HSPA+, Verizon LTE, Verizon EVDO and Sprint EVDO networks respectively.

up to 49% while the throughput is guaranteed at a similar
level (4% diﬀerence at maximum).

Another important observation from this experiment is
the much larger RTT variation under static tcp rmem max
setting than that with DRWA. As Figures 18(b) and 18(d)
show, the RTT values without DRWA are distributed over a
much wider range than that with DRWA. The reason is that
DRWA intentionally enforces the RTT to remain around the
target value of λ ∗ RT Tmin. This property of DRWA will
potentially beneﬁt jitter-sensitive applications such as live
video and/or voice communication.

7. DISCUSSION

7.1 Alternative Solutions

There are many other possible solutions to the buﬀerbloat
problem. One obvious solution is to reduce the buﬀer size
in cellular networks so that TCP can function the same way
as it does in conventional networks. However, there are two
potential problems with this simple approach. First, the
large buﬀers in cellular networks are not introduced without
a reason. As explained earlier, they help absorb the busty
data traﬃc over the time-varying and lossy wireless link,
achieving a very low packet loss rate (most lost packets are
recovered at link layer). By removing these extra buﬀer
space, TCP may experience a much higher packet loss rate
and hence much lower throughput. Second, modiﬁcation
of the deployed network infrastructure (such as the buﬀer
space on the base stations) implies considerable cost.

An alternative to this solution is to employ certain AQM
schemes like RED [9]. By randomly dropping certain packets
before the buﬀer is full, we can notify TCP senders in ad-

vance and avoid long RTT. However, despite being studied
extensively in the literature, few AQM schemes are actually
deployed over the Internet due to the complexity of their pa-
rameter tuning, the extra packet losses introduced by them
and the limited performance gains provided by them. More
recently, Nichols et al. proposed CoDel [22], a parameter-
less AQM that aims at handling buﬀerbloat. Although it
exhibits several advantages over traditional AQM schemes,
they suﬀers from the same problem in terms of deployment
cost: you need to modify all the intermediate routers in the
Internet which is much harder than updating the end points.
Another possible solution to this problem is to modify the
TCP congestion control algorithm at the sender. As shown
in Figure 7, delay-based congestion control algorithms (e.g.,
TCP Vegas, FAST TCP [28]) are resistive to the buﬀerbloat
problem. Since they back oﬀ when RTT starts to increase
rather than waiting until packet loss happens, they may
serve the buﬀerbloated cellular networks better than loss-
based congestion control algorithms. To verify this, we com-
pared the performance of Vegas against CUBIC with and
without DRWA in Figure 19. As the ﬁgure shows, although
Vegas has a much lower RTT than CUBIC, it suﬀers from
signiﬁcant throughput degradation at the same time. In con-
trast, DRWA is able to maintain similar throughput while
reducing the RTT by a considerable amount. Moreover,
delay-based congestion control protocols have a number of
other issues. For example, as a sender-based solution, it re-
quires modifying all the servers in the world as compared
to the cheap OTA updates of the mobile clients. Further,
since not all receivers are on cellular networks, delay-based
ﬂows will compete with other loss-based ﬂows in other parts
of the network where buﬀerbloat is less severe. In such sit-

3391

0.8

0.6

0.4

0.2

)
x
 
≤
 
X
P

(

 

0
0

1

 

)
x
 
≤
 
X
P

(

1

0.8

0.6

0.4

0.2

 

0
0

 

CUBIC without DRWA (avg=493)
TCP Vegas (avg=132)
CUBIC with DRWA (avg=310)

500

RTT (ms)

1000

1500

CUBIC without DRWA (avg=4.38)
TCP Vegas (avg=1.35)
CUBIC with DRWA (avg=4.33)
5

3

4

2
Throughput (Mbps)

(a) Throughput

(b) Round Trip Time

Figure 19: Comparison between DRWA and TCP Vegas as the solution to buﬀerbloat: although delay-based
congestion control keeps RTT low, it suﬀers from throughput degradation. In contrast, DRWA maintains
similar throughput to CUBIC while reducing the RTT by a considerable amount.

uations, it is well-known that loss-based ﬂows unfairly grab
more bandwidth from delay-based ﬂows [3].

Traﬃc shaping is another technique proposed to address
the buﬀerbloat problem [26]. By smoothing out the bulk
data ﬂow with a traﬃc shaper on the sender side, we would
have a shorter queue at the router. However, the problem
with this approach is how to determine the shaping param-
eters beforehand. With wired networks like ADSL or ca-
ble modem, it may be straightforward. But in highly vari-
able cellular networks, it would be extremely diﬃcult to ﬁnd
the right parameters. We tried out this method in AT&T
HSPA+ network and the results are shown in Figure 20.
In this experiment, we again use netem on the server to
shape the sending rate to diﬀerent values (via token bucket)
and measure the resulting throughput and RTT. Accord-
ing to this ﬁgure, lower shaped sending rate leads to lower
RTT but also sub-optimal throughput. In this speciﬁc test,
4Mbps seems to be a good balancing point. However, such
static setting of the shaping parameters could suﬀer from
the same problem as the static setting of tcp rmem max.

In light of the problems with the above-mentioned solu-
tions, we handled the problem on the receiver side by chang-
ing the static setting of tcp rmem max. That is because
receiver (mobile device) side modiﬁcation has minimum de-
ployment cost. Vendors may simply issue an OTA update to
the protocol stack of the mobile devices so that they can en-
joy a better TCP performance without aﬀecting other wired
users. Further, since the receiver has the most knowledge of
the last-hop wireless link, it could make more informed deci-
sions than the sender. For instance, the receiver may choose
to turn oﬀ DRWA if it is connected to a network that is not
severely buﬀerbloated (e.g., WiFi). Hence, a receiver-centric
solution is the preferred approach to transport protocol de-
sign for mobile hosts [13].

7.2 Related Work

Adjusting the receive window to solve TCP performance
issues is not uncommon in the literature. Spring et al. lever-
aged it to prioritize TCP ﬂows of diﬀerent types to improve
response time while maintaining high throughput [25]. Key
et al. used similar ideas to create a low priority background
transfer service [16]. ICTCP [29] instead used receive win-
dow adjustment to solve the incast collapse problem for TCP
in data center networks.

There are a number of measurement studies on TCP per-
[4] evaluated

formance over cellular networks. Chan et al.

5000

4000

3000

2000

1000

)
s
p
b
K

(
 
t
u
p
h
g
u
o
r
h
T

)
s
m

(
 
T
T
R

0

500

400

300

200

100

0

8Mbps

6Mbps

4Mbsp

2Mbps

800Kbps

600Kbps

Shaped Sending Rate

Figure 20: TCP performance in AT&T HSPA+ net-
work when the sending rate is shaped to diﬀerent
values. In time-varying cellular networks, it is hard
to determine the shaping parameters beforehand.

the impact of link layer retransmission and opportunistic
schedulers on TCP performance and proposed a network-
based solution called Ack Regulator to mitigate the eﬀect
of rate and delay variability. Lee [18] investigated long-
lived TCP performance over CDMA 1x EVDO networks.
The same type of network is also studied in [20] where
the performance of four popular TCP variants were com-
pared. Prokkola et al. [23] measured TCP and UDP perfor-
mance in HSPA networks and compared it with WCDMA
and HSDPA-only networks. Huang et al.
[14] did a com-
prehensive performance evaluation of various smart phones
over diﬀerent types of cellular networks operated by diﬀer-
ent carriers. They also provide a set of recommendations
that may improve smart phone users experiences.

8. CONCLUSION

In this paper, we thoroughly investigated TCP’s behav-
ior and performance over buﬀerbloated cellular networks.
We revealed that the excessive buﬀers available in the ex-
isting cellular networks void the loss-based congestion con-
trol algorithms and the ad-hoc solution that sets a static
tcp rmem max is sub-optimal. A dynamic receive window
adjustment algorithm was proposed. This solution requires
modiﬁcations only on the receiver side and is backward-
compatible as well as incrementally deployable. Experiment
results show that our scheme reduces RTT by 24% ∼ 49%
while preserving similar throughput in general cases or im-
proves the throughput by up to 51% in large BDP networks.

340The buﬀerbloat problem is not speciﬁc to cellular networks
although it might be most prominent in this environment. A
more fundamental solution to this problem may be needed.
Our work provides a good starting point and is an immedi-
ately deployable solution for smart phone users.

9. ACKNOWLEDGMENTS

Thanks to the anonymous reviewers and our shepherd
Costin Raiciu for their comments. This research is sup-
ported in part by Samsung Electronics, Mobile Communi-
cation Division.

10. REFERENCES

[1] N. Balasubramanian, A. Balasubramanian, and

A. Venkataramani. Energy Consumption in Mobile
Phones: a Measurement Study and Implications for
Network Applications. In IMC’09, 2009.

[2] L. S. Brakmo, S. W. O’Malley, and L. L. Peterson.

TCP Vegas: New Techniques for Congestion Detection
and Avoidance. In ACM SIGCOMM, 1994.

[3] L. Budzisz, R. Stanojevic, A. Schlote, R. Shorten, and

F. Baker. On the Fair Coexistence of Loss- and
Delay-based TCP. In IWQoS, 2009.

[4] M. C. Chan and R. Ramjee. TCP/IP Performance

over 3G Wireless Links with Rate and Delay
Variation. In ACM MobiCom, 2002.

[5] M. Dischinger, A. Haeberlen, K. P. Gummadi, and

S. Saroiu. Characterizing Residential Broadband
Networks. In IMC’07, 2007.

[6] W.-c. Feng, M. Fisk, M. K. Gardner, and E. Weigle.
Dynamic Right-Sizing: An Automated, Lightweight,
and Scalable Technique for Enhancing Grid
Performance. In PfHSN, 2002.

[7] S. Floyd. HighSpeed TCP for Large Congestion

Windows. IETF RFC 3649, December 2003.

[8] S. Floyd and T. Henderson. The NewReno

Modiﬁcation to TCP’s Fast Recovery Algorithm.
IETF RFC 2582, April 1999.

[9] S. Floyd and V. Jacobson. Random Early Detection

Gateways for Congestion Avoidance. IEEE/ACM
Transactions on Networking, 1:397–413, August 1993.

[10] J. Gettys. Buﬀerbloat: Dark Buﬀers in the Internet.
IEEE Internet Computing, 15(3):96, May-June 2011.

[11] S. Ha, I. Rhee, and L. Xu. CUBIC: a New

TCP-friendly High-speed TCP Variant. ACM SIGOPS
Operating Systems Review, 42:64–74, July 2008.

[12] S. Hemminger. Netem - emulating real networks in the

lab. In Proceedings of the Linux Conference, 2005.

[13] H.-Y. Hsieh, K.-H. Kim, Y. Zhu, and R. Sivakumar. A

Receiver-centric Transport Protocol for Mobile Hosts
with Heterogeneous Wireless Interfaces. In ACM
MobiCom, 2003.

[14] J. Huang, Q. Xu, B. Tiwana, Z. M. Mao, M. Zhang,
and P. Bahl. Anatomizing Application Performance
Diﬀerences on Smartphones. In ACM MobiSys, 2010.

[15] V. Jacobson, R. Braden, and D. Borman. TCP

Extensions for High Performance. IETF RFC 1323,
May 1992.

[16] P. Key, L. Massouli´e, and B. Wang. Emulating

Low-priority Transport at the Application Layer: a

Background Transfer Service. In ACM SIGMETRICS,
2004.

[17] C. Kreibich, N. Weaver, B. Nechaev, and V. Paxson.
Netalyzr: Illuminating the Edge Network. In IMC’10,
2010.

[18] Y. Lee. Measured TCP Performance in CDMA 1x

EV-DO Networks. In PAM, 2006.

[19] D. Leith and R. Shorten. H-TCP: TCP for High-speed

and Long-distance Networks. In PFLDnet, 2004.

[20] X. Liu, A. Sridharan, S. Machiraju, M. Seshadri, and

H. Zang. Experiences in a 3G Network: Interplay
between the Wireless Channel and Applications. In
ACM MobiCom, 2008.

[21] R. Ludwig, B. Rathonyi, A. Konrad, K. Oden, and

A. Joseph. Multi-layer Tracing of TCP over a Reliable
Wireless Link. In ACM SIGMETRICS, 1999.

[22] K. Nichols and V. Jacobson. Controlling Queue Delay.

ACM Queue, 10(5):20:20–20:34, May 2012.

[23] J. Prokkola, P. H. J. Per¨al¨a, M. Hanski, and E. Piri.

3G/HSPA Performance in Live Networks from the
End User Perspective. In IEEE ICC, 2009.

[24] D. P. Reed. What’s Wrong with This Picture? The

end2end-interest mailing list, September 2009.

[25] N. Spring, M. Chesire, M. Berryman,

V. Sahasranaman, T. Anderson, and B. Bershad.
Receiver Based Management of Low Bandwidth
Access Links. In IEEE INFOCOM, 2000.

[26] S. Sundaresan, W. de Donato, N. Feamster,

R. Teixeira, S. Crawford, and A. Pescap`e. Broadband
Internet Performance: a View from the Gateway. In
ACM SIGCOMM, 2011.

[27] K. Tan, J. Song, Q. Zhang, and M. Sridharan.

Compound TCP: A Scalable and TCP-Friendly
Congestion Control for High-speed Networks. In
PFLDnet, 2006.

[28] D. X. Wei, C. Jin, S. H. Low, and S. Hegde. FAST

TCP: Motivation, Architecture, Algorithms,
Performance. IEEE/ACM Transactions on
Networking, 14:1246–1259, December 2006.

[29] H. Wu, Z. Feng, C. Guo, and Y. Zhang. ICTCP:

Incast Congestion Control for TCP in Data Center
Networks. In ACM CoNEXT, 2010.

[30] L. Xu, K. Harfoush, and I. Rhee. Binary Increase
Congestion Control (BIC) for Fast Long-distance
Networks. In IEEE INFOCOM, 2004.

[31] Q. Xu, J. Huang, Z. Wang, F. Qian, A. Gerber, and

Z. M. Mao. Cellular Data Network Infrastructure
Characterization and Implication on Mobile Content
Placement. In ACM SIGMETRICS, 2011.

[32] P. Yang, W. Luo, L. Xu, J. Deogun, and Y. Lu. TCP

Congestion Avoidance Algorithm Identiﬁcation. In
IEEE ICDCS, 2011.

APPENDIX

A. LIST OF EXPERIMENT SETUP

See Table 1.

B. SAMPLE TCP RMEM MAX SETTINGS

See Table 2.

341Figure

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

Location

Signal

Strength

Raleigh
Chicago

Seoul

Good
Weak

Client

Model

Traﬃc
Pattern

Location

Congestion

Control

Server

Network

Linux Laptop

Long-lived TCP

Princeton

CUBIC

Seoul

Raleigh

Raleigh

Good

Galaxy S2

Raleigh

Good

Galaxy S2

Droid Charge

Traceroute

Long-lived TCP

Raleigh

CUBIC

AT&T

HSPA+

Ping

Raleigh

-

Carrier

AT&T
Sprint

T-Mobile
Verizon

SK Telecom

Network

Type

HSPA+
EVDO

LTE
WiFi

AT&T
Verizon

AT&T
Sprint

T-Mobile
Verizon

HSPA+
EVDO

LTE

HSPA+
EVDO

AT&T

HSPA+

Raleigh

Good

Linux Laptop

Long-lived TCP

Raleigh

CUBIC

Raleigh

Good

Linux Laptop

Long-lived TCP

Raleigh

NewReno

Vegas
CUBIC

BIC

HTCP
HSTCP

Raleigh

Good

Raleigh

Good

Linux Laptop

Mac OS 10.7 Laptop

Windows 7 Laptop

Galaxy S2
iPhone 4

Windows Phone 7

Galaxy S2

Droid Charge

Long-lived TCP

Raleigh

CUBIC

AT&T

HSPA+

Long-lived TCP

Raleigh

CUBIC

AT&T
Verizon

HSPA+

LTE

Raleigh

Good

Galaxy S2

Short-lived TCP
Long-lived TCP

Raleigh

CUBIC

AT&T

HSPA+

Raleigh

Raleigh

Raleigh

Raleigh

Seoul

Good

Good
Weak
Good

Good
Weak

Galaxy S2

Droid Charge

Long-lived TCP

Seoul

CUBIC

AT&T
Verizon

HSPA+

LTE

Galaxy S2

Long-lived TCP

Raleigh

CUBIC

AT&T

HSPA+

Galaxy S2

Long-lived TCP

Princeton

CUBIC

Galaxy S2

Droid Charge

EVO Shift

Long-lived TCP

Raleigh

CUBIC

-

AT&T
Verizon
Sprint

SK Telecom

WiFi

HSPA+

LTE

EVDO

Raleigh

Good

Galaxy S2

Short-lived TCP
Long-lived TCP

Raleigh

CUBIC

AT&T

HSPA+

Raleigh

Good

Raleigh

Good

Raleigh

Good

Raleigh

Raleigh

Good

Good

Galaxy S2

Droid Charge

Galaxy S2

Droid Charge

EVO Shift
Galaxy S2

Droid Charge

EVO Shift

Long-lived TCP

Seoul

CUBIC

Long-lived TCP

Raleigh

CUBIC

Long-lived TCP

Raleigh

CUBIC

Galaxy S2

Long-lived TCP

Raleigh

Galaxy S2

Long-lived TCP

Raleigh

CUBIC
Vegas
CUBIC

Table 1: The setup of each experiment

AT&T
Verizon
AT&T
Verizon
Sprint
AT&T
Verizon
Sprint

AT&T

AT&T

HSPA+

LTE

HSPA+

LTE

EVDO
HSPA+

LTE

EVDO

HSPA+

HSPA+

Samsung Galaxy S2 (AT&T) HTC EVO Shift (Sprint)

Samsung Droid Charge (Verizon)

LG G2x (T-Mobile)

WiFi
UMTS
EDGE
GPRS
HSPA+
WiMAX

LTE

Default

110208
110208
35040
11680
262144

-
-

110208

110208
393216
393216
393216

-

524288

-

110208

393216
196608
35040
11680

-
-

484848
484848

393216
110208
35040
11680
262144

-
-

110208

Table 2: Maximum TCP receive buﬀer size (tcp rmem max ) in bytes on some sample Android phones for
various carriers. Note that these values may vary on customized ROMs and can be looked up by looking for
“setprop net.tcp.buﬀersize.*” in the init.rc ﬁle of the Android phone. Also note that diﬀerent values are set
for diﬀerent carriers even if the network types are the same. We guess that these values are experimentally
determined based on each carrier’s network conditions and conﬁgurations.

342