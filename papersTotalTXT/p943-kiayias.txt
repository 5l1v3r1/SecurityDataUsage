How to Keep a Secret:

Leakage Deterring Public-key Cryptosystems

Aggelos Kiayias

National and Kapodistrian University of Athens
Dept. of Informatics and Telecommunications

aggelos@di.uoa.gr

National and Kapodistrian University of Athens

Qiang Tang

& University of Connecticut
qiang@cse.uconn.edu

ABSTRACT
How is it possible to prevent the sharing of cryptographic
functions? This question appears to be fundamentally hard
to address since in this setting the owner of the key is the
adversary: she wishes to share a program or device that (po-
tentially only partly) implements her main cryptographic
functionality. Given that she possesses the cryptographic
key, it is impossible for her to be prevented from writing
code or building a device that uses that key. She may
though be deterred from doing so. We introduce leakage-
deterring public-key cryptosystems to address this problem.
Such primitives have the feature of enabling the embedding
of owner-speciﬁc private data into the owner’s public-key so
that given access to any (even partially functional) imple-
mentation of the primitive, the recovery of the data can be
facilitated. We formalize the notion of leakage-deterring in
the context of encryption, signature, and identiﬁcation and
we provide eﬃcient generic constructions that facilitate the
recoverability of the hidden data while retaining privacy as
long as no sharing takes place.

Categories and Subject Descriptors
K.6 [Management of Computing and Information Sys-
tems]: Security and Protection; E.3 [Data Encryption]:
Public key Cryptosystems

Keywords
Public-key Cryptography, Self-enforcement, Key Manage-
ment, Leakage-deterring

1.

INTRODUCTION

Consider any organization that maintains a PKI support-
ing various cryptographic functions including public-key en-
cryption, signatures and identiﬁcation. How is it possible to

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516691 .

prevent individuals from sharing their cryptographic func-
tions? Certiﬁed PKI members, out of convenience or even
malice, can delegate their private keys to each other (or
even to outsiders), thus violating accountability and organi-
zational policy. Even worse, delegation can be partial: for
instance, a public-key encryption user can share (or, in fact,
even sell) an implementation that only decrypts messages
of a certain form (e.g., only e-mails from a speciﬁc source).
Seemingly, very little can be done to prevent this as the ad-
versary in this case is the owner of the cryptographic key:
inevitably practice has shown that no matter how much one
protects a cryptographic implementation, a determined at-
tacker can always reverse engineer it.

The above scenario puts forth the central problem our
work aims to solve: how is it possible to prevent the sharing
of cryptographic functions? The main challenge here is that
the owner of the key is adversarial: she wishes to share a pro-
gram or hardware device that (potentially only partly) im-
plements her main cryptographic functionality. Given that
she possesses the cryptographic key (either in software or
hardware), it is impossible for her to be prevented from del-
egating it. However, as we highlight, there can be ways
for her to be deterred from doing so. A straightforward de-
terrence mechanism would be to identify and penalize the
sharing behavior. However, the enforcement of a penalty
mechanism is contingent to detecting the act of sharing —
something that limits the eﬀectiveness of penalties: a cau-
tious adversary can keep itself “below the radar” and thus
remain penalty-free. To address this we put forth and ex-
plore a more proactive approach.

A cryptographic scheme will be called leakage-deterring if
the release of any implementation of the cryptographic func-
tion (e.g, decryption, signing), leads to the recovery of some
private information (that the owner prefers to keep hidden)
by anyone that possesses the implementation. Leakage de-
terrence is thus achieved in the sense that sharing the cryp-
tographic function in any form incurs the penalty of reveal-
ing the private information (while non-sharing maintains its
privacy).

Note that a leakage-deterring primitive should retain its
original functionality (e.g., encryption, signing, identiﬁca-
tion) but it will also oﬀer two additional operations: ﬁrst,
it is possible to embed private data into the public-key of
the primitive in a way that they are (at least) semantically
secure. The embedding operation is facilitated through an
interaction with an authority that vouches for the integrity
of the private data and is akin to a PKI certiﬁcation of the
owner’s public-key. In this fashion, the primitive’s public-

943key becomes “enhanced” and is a carrier of private infor-
mation itself (i.e., a ciphertext) — otherwise the intended
functionality of the primitive should remain unchanged. The
second operation that is oﬀered by a leakage-deterring prim-
itive comes into play when the owner of the secret key pro-
duces an implementation of the main operation in the form
of a “box” and shares it with other entities (in software or
hardware). Given such a box, any entity that receives it can
utilize a public recovering algorithm that will interact with
the box and produce the private data that are embedded
into the owner’s enhanced public-key.

In a nutshell, designing a leakage-deterring scheme re-
quires the transformation of the public-key of the primitive
into a (one-time) ciphertext that can be decrypted by any
working implementation of the cryptographic functionality.
The main challenge comes precisely from this latter require-
ment: any working implementation of the cryptographic
functionality should be usable as a decryption key that un-
locks the private data embedded into the public-key, even if
the adversarial implementor takes into account the recover-
ability algorithm and the enhanced public-key that carries
the private data when implementing the functionality.

To appreciate the complexity of the problem, consider a
naive attempt to produce a leakage-deterring public-key en-
cryption (PKE): the authority certiﬁes as the enhanced pub-
lic key the pair (pk, ψ) where ψ = Enc(pk, s) and s is the
private data related to the owner. Recoverability can be at-
tempted by feeding ψ into a decryption box. It is apparent
that this construction can be defeated by an adversarial im-
plementation of decryption that given input c, it decrypts
it only in the case c (cid:54)= ψ (or even Dec(c) (cid:54)= s). The con-
structions we seek should facilitate recoverability even if the
adversarial box implementor releases implementations that
work for arbitrary input distributions of her choice.

The applications of leakage-deterring cryptographic prim-
itives are in any context where the intentional leakage of a
cryptographic functionality should be deterred or restricted
in some fashion or in a context where the leakage of an im-
plementation should enable the computation of a value that
is otherwise hidden.
In the most simple scenario, the en-
hanced public-key contains some piece of information that
the owner prefers to keep secret (e.g., her credit-card num-
ber or similar piece of private information as suggested by
Dwork, Lotspiech and Naor [9] that introduced the concept
of self-enforcement – in a related but diﬀerent context – see
below). It follows that the system setup “self-enforces” the
owner to keep the cryptographic functionality to herself. De-
pending on the deployment environment, diﬀerent types of
secret-information can be used. We describe more applica-
tion scenarios of leakage deterring cryptographic primitives
in section 5.
Our Contributions. We introduce, formalize and imple-
ment leakage-deterring cryptographic primitives for public-
key encryption, digital signatures, and identiﬁcation schemes.
The main technical contributions we provide are three dif-
ferent techniques for constructing leakage-deterring crypto-
graphic primitives. Our techniques enable the secure em-
bedding of private information into the public key of the
primitive in a way that is recoverable given any (even par-
tially) working implementation. Our ﬁrst method, applies
to encryption that is partially homomorphic; given a box
that works only for some adversarially chosen distributions
we show how to exploit the homomorphic property to appro-

priately manipulate a target ciphertext and make it decrypt-
able by the adversarial decryption box. Our second method,
which can rely on any encryption scheme, hides the key that
unlocks the private information into an exponentially large
key space that is encoded in the public-keys. By using ap-
propriate redundancy in the public key space we enable the
tracing of the vector of keys that identify the private infor-
mation, out of any (even partially working) implementation.
Achieving recoverability while maintaining small ciphertext
size in this setting requires an involved recoverability algo-
rithm which is one of the highlights of our contributions.
Finally, our third method applies to signature and identiﬁ-
cation schemes. It uses the fact that working implementa-
tions of suitably chosen such primitives can be used to build
“knowledge extractors.” These are algorithms that reveal in-
formation about the secret-key of the underlying primitives
which we use to hide the private information.

Our ﬁrst construction for public-key encryption requires a
standard homomorphic property and achieves constant size
ciphertexts while oﬀering recoverability for any (non-trivial)
adversarial distribution. The second construction is generic
and the size of ciphertexts is a parameter that increases
as the min-entropy of the allowed adversarial distributions
becomes smaller. We analyze our constructions in the IND-
CPA setting and then present a generic transformation to
obtain IND-CCA2 security.1
It is evident that there is a
trade-oﬀ between privacy and recoverability. For encryp-
tion schemes, we aim at maximizing the recoverability while
privacy can only be achieved if no decryption query is al-
lowed. For the case of signatures, we present a construc-
tion that maintains the privacy of the embedded informa-
tion even if the adversary has arbitrary access to the signing
functionality (which is most desirable since digital signatures
are typically publicly available). We still manage to enable
recoverability by exploiting the random oracle model and
non-black-box access to the implementation. Security prop-
erties of our identiﬁcation schemes are shown in the standard
model. To attain privacy in the standard model we utilize
strong extractors for random variables with high conditional
unpredictability.
Related work. The most relevant work to ours is [9] that
introduced self-enforcement as a way of avoiding illegal con-
tent redistribution in a multi-user setting. Self-enforcement
was argued in that paper by ensuring (under certain as-
sumptions) that an owner has only two options when im-
plementing a decoder: either using her private key (that
includes private personal information), or encoding a de-
rived key that is of size proportional to the data to be de-
crypted. In our terminology, this means that the schemes
of [9] exhibit a leakage-deterrence/program-length tradeoﬀ
and hence are not leakage-deterring per se. Furthermore,
recoverability in [9] is only “white-box” as opposed to the

1It may come as a surprise that recoverability and IND-
CCA2 can actually coexist. Attaining IND-CCA2 intu-
itively means that a decryption oracle basically leaks no use-
ful information about manipulated ciphertexts. Thus, the
recovering algorithm can seemingly do nothing useful with
access to a decryption implementation beyond decrypting
valid ciphertexts, which if related to the enhanced public-
key can be rejected. Still, the paradox can be resolved, if
one observes that the decryption oracle should be useless
only with respect to breaking the security of regular cipher-
texts and not the security of the data that are somehow
embedded into the enhanced public-key.

944black-box nature that our constructions achieve. In another
related line of work [5, 27, 4, 21] it was discussed how to
deter a user from transferring her credentials (or the secret
key directly) to others in the context of identiﬁcation sys-
tems. The techniques from these works – by nature – were
restricted to only identiﬁcation schemes and digital signa-
tures. The primitive of circular encryption introduced in
[4] might look promising at ﬁrst sight to achieve leakage-
deterrence in the public-key encryption setting as well, how-
ever, no recovery algorithm which works for all partial im-
plementations is immediately apparent. Indeed, recall that
the technically most challenging aspect of leakage-deterring
cryptosystems is in the design of black-box recoverability
and for this, techniques other than circular encryption are
needed.
Interestingly, our embedding techniques eventu-
ally obviate the need for circular encryption altogether as
they can hide the owner private data in an information-
theoretic sense and hence the secret-key can be safely em-
bedded into the public-key without jeopardizing the security
of the scheme. Furthermore, for the case of identiﬁcation
and signature schemes, the idea of taking advantage of the
knowledge extractor for preventing the transfer of identiﬁca-
tion tokens has been utilized before [5, 27, 4, 21] (in the sense
that sharing a token implies sharing the key). In our con-
struction we go beyond this, by showing that the secret key
can be of suﬃcient (pseudo)entropy so that it can hide ar-
bitrary information (and not merely itself). In fact we show
that no additional intractability assumptions are necessary
for achieving leakage-deterring signature and identiﬁcation
schemes. Other forms of leakage deterring techniques were
considered in various settings, e.g., limited delegation [13],
data collection [14], e-payments [31] or designated veriﬁer
signatures in [26, 32] in the form of non-delegatability (which
is a weaker notion than our leakage-deterring concept).

Another related notion, introduced in [28], dealt with the
problem copyrighting a public-key decryption function: a
single public-key decryption functionality should be imple-
mented in many distinct ways so that if an implementation
is derived from some of them, then it is possible to dis-
cover the index of at least one of the implementations that
was used. This notion was further investigated in [23] and
was related to traitor tracing schemes [6]. In the context of
public-key encryption, the objective of copyrighting a func-
tion or of a traitor tracing scheme is orthogonal to ours.
While in both cases we deal with adversarial implementa-
tions of cryptographic functionalities (hence the similarities
in terminology), the adversarial goal is diﬀerent: in the case
of traitor tracing, the adversary has many diﬀerent imple-
mentations of the same functionality and tries to produce a
new one that is hard to trace back to the ones she is given.
In an attack against a leakage-deterring scheme on the other
hand the adversary possesses an implementation of a cryp-
tographic functionality and tries to modify it in a way that
it cannot be used to extract some information that is hidden
in the primitive’s public-key. Combining the two function-
alities in one is an interesting question and we leave it as
open problem (a step towards this general direction but in
a much weaker model than ours was suggested in the work
of [24] but the leakage-deterring aspect (in our terminology)
was found to be insecure in [22]).

Accountable authority identity based encryption (AIBE) [15,

16, 25, 30] considers the problem of judging whether an im-
plementation of decryption belongs to the owner or the PKG

(in the context of IBE). In this setting, both the owner and
the PKG may be the potential adversary who try to impli-
cate the other. Hence, some property similar to our recover-
ability is needed. In any case, the single bit decisional output
required by AIBE is much weaker than our recoverability re-
quirement in leakage-deterring public-key encryption (even
in the IBE setting) where by interacting with a decryption
box, one should recover the whole private data embedded in
the enhanced public-key.

Finally we should point out that the notion of leakage de-
terrence is diﬀerent from the notion of leakage-resilience (see
e.g., [20, 10]). Our notion aims at constructing schemes with
the property that intensional leakage of the cryptographic
functionality implies the revelation of some private owner
information (hence they are “leakage-deterring”), while the
leakage-resilience notion aims at ensuring that the uninten-
tional leakage (as in the case of side channel attacks) pro-
vides no useful information to an adversary.

2. DEFINITIONS AND SECURITY MODEL
2.1 Leakage-deterring Cryptosystems

A leakage-deterring cryptographic primitive includes two
additional algorithms on top of the regular algorithms the
primitive normally possess: EnKey(·), which embeds some
(private) owner related information into the public key, and
Rec(·) which recovers the private information from the pub-
lic key by interacting with any non-trivial implementation
(or “box”) which can be executed by anyone. While the con-
cept of a leakage-deterring cryptographic primitive can be
deﬁned in abstract terms for a wide class of primitives we
ﬁnd it more instructive to present it for three main cryp-
tographic primitives individually; we focus on encryption;
deﬁnitions of leakage-deterring signatures and identiﬁcation
are similar and we defer them for the full version. With these
examples at hand, it is relatively straightforward to derive
leakage-deterring deﬁnitions for other cryptographic primi-
tives following the same general structure (see also remarks
below).
Leakage-deterring Public Key Encryption:

• KeyGen(1λ): On input security parameter λ, this al-

gorithm returns a key pair (pk, sk).

• EnKey(O, A): This is a protocol between two parties
O (owner) and A (authority), with inputs (pk, sk, s)
and (pk, s) respectively that has the objective to em-
bed the private owner’s data s into his public-key; the
protocol terminates with the owner O obtaining an en-
hanced key pair (epk, esk) while A obtains simply the
enhanced epk.

• Enc(epk, m): On input a message m and the user’s
enhanced public key epk, this algorithm returns a ci-
phertext c.

• Dec(esk, c): On input a ciphertext c and enhanced

secret key esk, this algorithm returns m or ⊥ (fail).
• RecB,D(epk, δ):2 Using access to a decryption box B
and a plaintext distribution D (which is supposedly the
2Having access to D is necessary; to see that, consider the
following simple example: the box processes the input only
if the message encrypted is of the form sc||m for some secret
string sc; otherwise it outputs ⊥.
It follows that without

945one that B is suited for and is correct with probability
δ), as well as input the enhanced public key epk for a
certain user, this algorithm outputs s or ⊥ (fail).

Remarks. One can think of EnKey as an extension of
a public-key certiﬁcation operation by an authority. The
owner may still utilize (pk, sk) for the primitive’s operation
(as in a PKI one may still use an uncertiﬁed key) but epk is
the key designated for public use.

The deﬁnitions for other primitives are similar and we
present them in the full version. They share the same basic
structure in terms of the syntax of the recovering algorithm
but there is some variability across primitives with respect
to when this algorithm is supposed to operate. We tackle
this question in the following section. Furthermore, we note
that in the Rec algorithm, one may distinguish several ways
that the algorithm may have access to the main functional-
ity box (which is assumed to be resettable, i.e., it does not
maintain state from one query to the next). Speciﬁcally, be-
yond black-box access we will also consider a certain type of
non-black-box access.
2.2 Correctness and Security Modeling

In this section we introduce the main security require-
ments for leakage-deterring cryptographic primitives.
In
general any leakage-deterring primitive should oﬀer privacy
for the owner (as long as no implementation of the primitive
is leaked) and recoverability, i.e., that the recovering algo-
rithm will be able to produce the private data of the owner
as long as it has access to a non-trivial implementation of
the cryptographic primitive. Finally, it is important that the
introduction of the additional functionality does not disturb
the standard cryptographic properties of the primitive. We
examine these properties below.
Privacy (of Owner’s Data): For an honest owner who does
not leak any non-trivial box, the privacy of its data bound in
the enhanced public key should be protected. To deﬁne the
property formally we introduce the following game between
a challenger and an adversary A.

• The challenger runs KeyGen(·) and sends to the ad-

versary A the public key pk.

• The adversary A chooses two private strings s0, s1 and

sends them to the challenger.

• The challenger chooses b and simulates EnKey(·) on

sb and pk, sk; it sends epk to the adversary.

• A returns his guess b(cid:48) about b.
If there is no eﬃcient adversary A that can correctly
guess b with non-negligible advantage, i.e., for all PPT A,
2| ≤  where  is a negligible function, we
| Pr[b(cid:48) = b] − 1
say the leakage-deterring cryptographic scheme achieves pri-
vacy (in the sense of indistinguishability). Furthermore, in
the above game, we may allow the adversary to observe the
cryptographic functionality on a certain input distribution.
If the above deﬁnition holds even in the case that the adver-
sary has access to an oracle O(esk,·) (that is dependent on
the enhanced secret-key of the owner, e.g., decryption ora-
cle or signing oracle w.r.t. some plaintext distribution D)
we will say that the scheme achieves privacy with respect
knowledge of D, the box is useless. This counterexample
applies to the other leakage-deterring primitives.

to the secret-key oracle O(esk,·). Note that for privacy we
consider both owner and authority honest. It is possible to
extend the model to the case of a dishonest authority but
this goes beyond our current scope.

Recoverability (of Owner’s Data): If a dishonest owner re-
leases a functional box B, anyone having access to B should
be able to recover the owner’s private data from the en-
hanced public key epk. Formally, consider the following
game between a challenger and an adversary A:

• The adversary A on input 1λ generates a key pair
(sk, pk) and submits it together with the owner pri-
vate data s to the challenger.

• The challenger acting as the authority runs EnKey
with the adversary (playing the role of the owner) to
produce the enhanced key pair (epk, esk).

• A outputs an implementation B and a distribution D.
• The challenger outputs the value s(cid:48) = RecB,D(epk, δ).

For a given δ, we will say that the leakage-deterring cryp-
tographic primitive satisﬁes black-box recoverability with re-
spect to the class of input distributions D, if for any eﬃcient
adversary A the following event in the game above happens
with negligible probability.

(B is δ-correct w.r.t. D) ∧ (D ∈ D) ∧ (s

(cid:48) (cid:54)= s)

The predicate “B is δ-correct w.r.t. D” takes a diﬀerent form
depending on the cryptographic primitive and is intended
to capture the fact that the box produced by the adversary
should have some minimum utility parameterized by δ.
Consider the case of a PKE scheme (KeyGen, Enc, Dec).
The predicate for δ-correctness w.r.t. D in this case is as fol-
lows: Pr[B(Enc(epk, m)) = m] ≥ δ, s.t. m ← D where the
random variables epk,D, B are deﬁned as in the game. It is
worth noting that the largest class of distributions D we can
hope recoverability to work for is one that includes those dis-
tributions whose predicting probability3 is by a non-negligible
amount smaller than δ; otherwise, one can implement a de-
cryption box by always returning the most probable sample
from D. In a similar vein, we deﬁne correctness for digital
signatures and identiﬁcation in the full version.

We will also consider a form of the above deﬁnition where
a non-black-box technique is used for recovering the owner’s
private data. In this case we can think of the Rec algorithm
as a family of algorithms parameterized by the box algorithm
B (as opposed to being a single algorithm with black-box
access to B).

We next compare privacy and recoverability and observe a
natural trade-oﬀ between the two properties. Privacy w.r.t.
a secret-key oracle O(esk,·) for a distribution D (i.e., when
adversarial access to the cryptographic primitive is allowed
for input distribution D) can not be achieved if the leakage-
deterring cryptographic primitive satisﬁes black-box recov-
erability w.r.t. D, in case D ∈ D. This easily follows from
the fact that the privacy adversary can simulate the Rec
algorithm with the help of the secret key oracle.
Correctness Properties. Leakage-deterring cryptographic pri-
mitives should satisfy correctness in the usual sense (albeit
correctness should be expressed with respect to the enhanced
3Denoted by p(D) is equal to 2−H∞(D), where H∞(D) =
− log maxx Pr[x ∈ D] is the min-entropy of D.

946public and secret-keys). The extension of the deﬁnitions is
straightforward and we defer them for the full version.
Security Properties. We next consider how the individual
security properties for leakage-deterring primitives should
be amended. In general, the original security property (e.g.,
IND-CPA or unforgeability) should be retained with respect
to the enhanced public and secret-keys even in the presence
of a corrupted authority running the EnKey protocol.
IND-CPA/CCA Security (leakage-deterring public-key en-
cryption with dishonest authority): Consider the following
game between the adversary and the challenger:

• The challenger runs KeyGen(·) to get (pk, sk) and

returns pk to the adversary A.

• The adversary A selects s and playing the role of the
authority runs EnKey(·) with the challenger on input
pk, s.

• The adversary A chooses two messages m0, m1, and

sends them to the challenger.

• The challenger randomly picks a bit b ∈ {0, 1}, and

gives A the encryption of mb under epk.

• Finally, A returns a guess b(cid:48) about b.

Suppose there is no eﬃcient adversary A that can output
a correct guess about b with non-negligible advantage, i.e,
|P r[b(cid:48) = b] − 1
In
this case, we say that the leakage-deterring encryption is
IND-CPA-secure (with dishonest authority).

2| ≤ , where  is a negligible function.

If we allow the adversary to ask decryption queries at
anytime before outputting the guess (it can be both be-
fore and after receiving the challenge ciphertext, with the
only restriction being that the challenge ciphertext cannot
be queried), then we refer to this as IND-CCA2 security.

We can also consider the security deﬁnition with an hon-
est authority, in which case both KeyGen, EnKey are ex-
ecuted by the challenger. The deﬁnitions of unforgeability
for the case of digital signatures and impersonation resis-
tance for identiﬁcation schemes are in the same vein and are
deferred for the full version.

3. LEAKAGE-DETERRING PUBLIC KEY EN-

CRYPTION

In this section, we present constructions of leakage-deterring

public key encryption schemes. We start with a construc-
tion from any additive homomorphic encryption to demon-
strate our ﬁrst technique for implementing recoverability,
then, we show a generic construction of IND-CPA secure
leakage-deterring PKE from any IND-CPA secure encryp-
tion along with an improvement that achieves constant size
ciphertexts.
In section 3.3, we provide a general way to
achieve IND-CCA2 security for all leakage-deterring encryp-
tion schemes.
3.1

IND-CPA-secure Leakage-deterring PKE
from Homomorphic Encryption

Recall the trivial solution presented in the introduction
(encrypting the owner’s private data with its public-key).
It does not work because an adversarial decryption box is
able to test whether the queries fed by the recovering algo-
rithm match the ciphertext stored in epk. A seeming ﬁx is

to query via rerandomizing the ciphertext contained in the
enhanced public key. However, given that the private data
are known to the attacker, the adversarial box can check for
them and still refuse to cooperate. So in some sense to go
around the problem one has to re-randomize the plaintext as
well! (so that after re-randomization, the plaintexts should
be distributed according to D but in a way that is still some-
how useful for decrypting the private data). We provide a
solution along these lines in this section.
Informally, an encryption algorithm E(·) has a homomor-
phic property if E(m1 + m2) = E(m1) · E(m2) for some op-
erations (+,·) over plaintexts and ciphertexts respectively.
For instance, we can submit a ciphertext c∗ · E(r) to the
decryption box B, and retrieve the message in c∗ from the
answer by subtracting r. This method would be eﬀective
for our purpose only if B satisﬁes correctness w.r.t. to ran-
dom distributions over the whole message space. However
we would like a solution that works even for adversarially
chosen distributions that are unknown at the time of the
generation of epk. The recovering technique we introduce
below achieves this goal.

First assume that we have an underlying encryption E :
(KeyGen, Enc, Dec) that is an IND-CPA secure PKE with
a homomorphic property. Speciﬁcally, we assume that for
any message m and any a, b from the message space, Enc(m)a·
Enc(b) is identically distributed to Enc(am + b). We call
the following construction Scheme-I.

• KeyGen(1λ): Run the KeyGen algorithm of E, re-

turn (pk, sk).

• EnKey(O, A): This is a protocol between O and A
with input (pk, sk, s) and (pk, s) respectively. A ran-
domly chooses n = |s| messages ωi, i = 1, . . . , n accord-
ing to the uniform distribution over {0, 1}. Then A
1 . . . s(cid:48)
calculates s(cid:48)
n.
The protocol terminates with O obtaining the enhanced
key pair (epk, esk) where epk = (pk,{ci}, s(cid:48)), and esk =
sk, while A gets only the enhanced public key epk.

i = ωi ⊕ si, {ci = E(pk, ωi)}, s(cid:48) = s(cid:48)

• Enc(epk, m): This algorithm runs the encryption al-

gorithm Enc, returning c = Enc(pk, m).

• Dec(esk, c): This algorithm runs the decryption algo-

rithm Dec, returning m = Dec(sk, c).

• RecB,D(epk, δ): With access to a decryption box B
and a distribution D, over which B works with δ-
correctness, the objective of this algorithm is to trans-
form the ciphertexts c1, . . . , cn found in the epk to ci-
phertexts that look inconspicuous from the point of
view of the box B. For each ciphertext ci the algo-
rithm will operate as follows. First it will calculate
a suﬃciently long sequence of pairs (x, y) (the exact
length N of the sequence depends on the parameters
of B and D and will be determined in our security
analysis). For each pair, the algorithm ﬁrst indepen-
dently samples two plaintexts m0, m1 according to D.
Then it calculates x, y by solving the following linear
system:

(cid:26) 0 · x + y = m0

1 · x + y = m1

Let (xl, yl)l=1,...,N be the pairs produced by running
the above procedure N times and m0,l, m1,l be the

947pair of plaintexts used as constant terms of the lin-
ear system for the l-th sample. Having calculated
· E(pk, yl)
those, the algorithm computes c(cid:48)
for l = 1, . . . , N , and feeds B with those ciphertexts
(observe that their corresponding plaintexts follow the
distribution D). Let a1, . . . , aN , be the answers of the
box B where al = ⊥ if the box does not provide an an-
swer for the l-th ciphertext. Now consider the modiﬁed
answer sequence deﬁned as follows:

i,l = cxl

i

(cid:26) (al − yl)/xl

⊥

∗
l =

a

al ∈ {m0,l, m1,l)} ∧ xl (cid:54)= 0
otherwise

1, . . . , a∗

l ∈ {0, 1,⊥}. If the majority symbol among
Note that a∗
the non-⊥ symbols of (cid:104)a∗
N(cid:105) is deﬁned, the re-
covering algorithm calculates it as vi and proposes it
as the decryption of ci (otherwise the algorithm fails).
This procedure is repeated for all ciphertexts c1, . . . , cn
thus forming v = v1 . . . vn. Finally, the recovering al-
gorithm proposes as the private data of the owner the
string s(cid:48) ⊕ v where s(cid:48) is parsed from the epk.

Security Analysis: We will analyze correctness and three
security properties, i.e, security, privacy, recoverability. First
observe that correctness is trivial, according to the correct-
ness of the underlying encryption scheme E while IND-CPA
security is also relatively obvious since the extra informa-
tion exposed due to our extension are some independent
values (ω1 . . . ωn, s). Now regarding the privacy property,
we can see that the EnKey algorithm in Scheme-I is a
KEM/DEM mechanism [7], using a KEM which encrypts
each bit of the key with a secure encryption. Given {ci},
the adversary is not able to predict the bit ωi with a suﬃ-
cient bias, thus every ωi is random conditioned on the ad-
versary’s view. This proves privacy (assuming no secret-key
oracle O(esk,·) is given). Regarding recoverability we can
prove it w.r.t. essentially any distribution D. The Rec al-
gorithm produces a sequence of ciphertexts with plaintexts
following D whose correct decryption reveals the bits ωi by
a majority argument. As long as the correctness of the box
B is non-negligibly larger than the predicting probability of
D (which is a necessary characteristic of “box usefulness”)
the recovering algorithm will produce the ωi values with
overwhelming certainty since it can do a perfect simulation
of ciphertexts with D distributed plaintexts. The complete
proofs of all those facts can be found in the full version
(available by the authors). Among others, there we estab-
lish that N = O(α−2 log6 λ) is suﬃcient where α represents
the gap between the prediction probability of D and δ.
3.2 Generic IND-CPA Leakage-deterring PKE

with Honest Authority

In this section, we show that leakage-deterring PKE can
be based on any secure PKE (even without a homomorphic
property). We will only consider IND-CPA security with
honest authority in this section and we will show how to go
beyond this and achieve security against dishonest authori-
ties (and actually IND-CCA2) in the next section.
Linear-Size Construction. To make the exposition more
accessible we present ﬁrst a less eﬃcient construction (with
linear size ciphertexts in the length of hidden information);
then we show our main generic construction which is con-
stant size. Consider a semantically secure public key encryp-
tion E. The main idea of the construction is as follows. For

each bit of private data there is a pair of public keys, and
the owner has only one of the secret keys. The ambiguity
of which secret key the owner has oﬀers the opportunity for
the recovering algorithm to work. We call this construction
Scheme-II, details are as follows:

• KeyGen(1λ): This algorithm generates n = |s| key

pairs (pk1, sk1), . . . , (pkn, skn).

i

1, pk1

n, pk1

1), . . . , (pk0

• EnKey(O, A): (O, A) inputs (pk1, . . . , pkn, s, sk1, . . . ,
skn), and (pk1, . . . , pkn, s) respectively, where s ∈ {0, 1}n.
A randomly generates r ∈ {0, 1}n which we call indi-
cating string, and n new random public keys pk(cid:48)
1, . . . , pk(cid:48)
n.
The enhanced public key epk is n pairs of public keys
n), together with s(cid:48) = r ⊕ s,
(pk0
= pk(cid:48)
where for i = 1, . . . , n, pkri
i,
and the enhanced secret key is esk = (sk, r), where
sk = (sk1, . . . , skn).

i = pki, pk1−ri

domly, and computes mn = m−(cid:80)n−1

dicating string r, and returns m =(cid:80)n

• Enc(epk, m):This algorithm picks m1, . . . , mn−1 ran-
i=1 mi (wlog we as-
sume that additive secret-sharing works over the plain-
text space). It outputs the ciphertext c = [(c0
1), . . . ,
(c0
i , mi).
• Dec(esk, c): To decrypt ciphertext c, this algorithm
chooses from c the ciphertexts corresponding to the in-
i=1 Dec(ski, cri
i ).
• RecB,D(epk, δ): With access to a decryption box B
and a plaintext distribution D for which the box sup-
posedly works with δ-correctness, the algorithm recov-
ers each bit si of s by repeating the following procedure
N times (the exact value of N will be speciﬁed in the
analysis):
It ﬁrst samples m, m(cid:48) independently, according to D,
randomly chooses m1, . . . , mi−1, mi+1, . . . , mn, and com-
putes m0

i = m(cid:48) −(cid:80)

i = m −(cid:80)

1, c1
i = Enc(pk1

i = Enc(pk0

n)], where c0

i , mi), c1

n, c1

i ).

1, c1

n, c1

i ), c1

i , m1

1), . . . , (c0

j(cid:54)=i mj, and m1

i = Enc(pk1

j , c1
i , m0

j(cid:54)=i mj.
n)], where for
j encrypts the same message mj while

Then it feeds B with [(c0
all j (cid:54)= i, c0
i = Enc(pk0
c0
The algorithm records a 0, if the response from the box
is m, 1 if the response is m(cid:48), and ⊥ in any other case
including the case m = m(cid:48). For each i, the algorithm
will propose ri to be the majority of the recorded non-
⊥ values (the algorithm fails if majority is not well-
deﬁned).
The above procedure is repeated for all i ∈ {1, . . . , n}
to form a string r, and ﬁnally, the algorithm outputs
s = s(cid:48) ⊕ r, where s(cid:48) is parsed from epk.

Security Analysis. We now analyze the security proper-
ties of Scheme-II. Let us call an encryption using a single
pair of keys as a “unit building block”. It is not hard to see
that IND-CPA security of the unit building block implies the
IND-CPA of scheme-II (assuming authority is honest and
taking into account the security of additive secret-sharing).
Regarding privacy, observe that s is perfectly hidden within
epk as a one-time pad ciphertext. Finally, regarding recov-
erability w.r.t any distribution D, the recovering algorithm
can attempt to query diﬀerent encrypted messages in any
single unit location. Due to the secret-sharing, any box
(even partly successful) has to include a key for each co-
ordinate. Due to these facts, the recovering algorithm can

948detect which secret key does the owner possess at each loca-
tion something that leads to the calculation of the indicating
string and hence the recovery of the private data. A detailed
analysis can be found in the full version (available by the au-
thors) where we show that a value for N as in scheme-I is
suﬃcient.
Main Generic Construction. In the previous construc-
tion, the sender splits the message into n pieces. This makes
the ciphertext size (number of ciphertext units) linear in the
length of the owner’s private data. We now improve the
generic construction to achieve a ciphertext size O(log 1
δ ) by
using an error correcting code to create the indicating string,
where δ is a speciﬁed minimum decryption probability re-
quired by adversarial implementations and is a parameter
of the construction. We call this construction Scheme-III.

• KeyGen(1λ): Same as in Scheme II.
• EnKey(O, A): (O, A) have inputs (pk1, . . . , pkm, s, sk),
and (pk1, . . . , pkm, s) respectively where s ∈ {0, 1}n;
the parameter m is selected based on n according to
an ECC (e.g., the one of [17]) that corrects up to m
errors. A randomly generates ˜r ∈ {0, 1}n, computes
5
the indicating string r = ECC(˜r). Also, A selects m
random public keys pk(cid:48)
m. The protocol termi-
nates with O obtaining (epk, esk) and A obtaining epk,
m, pk1
where epk is (pk0
m), together with
s(cid:48) = ˜r ⊕ s, and for i = 1, . . . , m, pkri
i = pki, pk1−ri
=
pk(cid:48)

1, . . . , pk(cid:48)

i, and esk = (sk, r).

1), . . . , (pk0

1, pk1

i

• Enc(epk, m): To encrypt a message m, the algorithm
ﬁrst chooses a random subset S ⊆ {1, . . . , m} with size
t = 5 ln 4
δ ; we denote the i-th element of S by Si. Then
it randomly picks m1, . . . , mt−1, and computes mt =
t , c1

m−(cid:80)t−1

i=1 mi. The ciphertext c = [S, (c0
1, c1
Si , mi) for b ∈ {0, 1}.
i = Enc(pkb

1), . . . , (c0

where cb

• Dec(esk, c): To decrypt ciphertext c, this algorithm
chooses from c the ciphertexts corresponding to the
indicating string r projected on S, and returns m =

t )],

(cid:80)t

i=1 Dec(skSi , c

rSi
i

).

• RecB,D(epk, δ): With access to a decryption box B
and a plaintext distribution D, the algorithm recovers
each bit si of s by repeating the following procedure
N times (the exact number will be speciﬁed in the
analysis):
It ﬁrst randomly selects a subset S ⊆ {1, . . . , m} with
size t.
If i ∈ S, and i is the k-th element of S, the algorithm
randomly chooses m, m(cid:48) independently according to D
as well as random values m1, . . . , mk−1, mk+1, . . . , mt.
Then, it computes m0
k =
t )]
where, for all j (cid:54)= k, the pair c0
j encrypts the same
message mj using pk0
k =
Enc(pkb
If i (cid:54)∈ S, the algorithm proceeds by performing a reg-
ular encryption of a plaintext from D.
If i ∈ S and the response of the decryption box is
m, the algorithm records 0; if i ∈ S and the response
is m(cid:48), this algorithm records a 1; Otherwise (in any
other case including i (cid:54)∈ S or m = m(cid:48)), it records ⊥.

k = m −(cid:80)

j(cid:54)=k mj, and m1
t , c1

j(cid:54)=i mj. It feeds B with [S, (c0

i , pk1
k) for b ∈ {0, 1}.

m(cid:48) −(cid:80)

i respectively, while cb

1), . . . , (c0

i , mb

j , c1

1, c1

For each i the majority of the non-⊥ recorded values is
proposed as the value of ri. If no majority is deﬁned,
a random bit is produced as ri.
The above procedure is repeated for all i ∈ {1, . . . , m},
and a string r is formed. The decoding algorithm of
ECC is now executed on r to obtain ˜r. The algorithm
terminates by returning s = s(cid:48) ⊕ ˜r, where s(cid:48) is parsed
from epk.

Security Analysis: The IND-CPA and privacy properties
are essentially the same as in scheme II. We only discuss
recoverability which is signiﬁcantly more complex. The in-
tuition is that because of the error correcting code, the Rec
algorithm would work as long as a linear fraction of bits of r
can be recovered. As we will prove in the appendix, suppose
that q is the number of positions among the m for which our
recoverability procedure fails. We will show that the proba-
bility of correct decryption will become roughly smaller than
e−tq/m = δ5q/m. From this we derive that any decryption
box operating with probability at least δ (as postulated) can
make our algorithm fail in at most m/5 of the m secret keys
which is suﬃcient for correct decoding. The full analysis is
presented in the appendix B.
3.3 Generic CCA2 Secure Construction with

Dishonest Authority

In this section, we introduce a simple general method to
construct an IND-CCA2 secure leakage-deterring encryp-
tion with dishonest authority from a leakage-deterring PKE
which is IND-CPA secure with honest authority, and an
IND-CCA2 secure standard PKE. The main idea is to com-
pose these two encryptions to form a nested encryption with
the outer layer encryption being the IND-CCA2 secure one.
Recoverability could be maintained because the Rec algo-
rithm can run the Rec algorithm of the inner leakage-deterring
encryption to collect queries, and encrypt them using the
outer layer public key to form its own recovering queries.
Construction: Suppose E1 is an IND-CPA secure leakage-
deterring PKE (with an honest authority), and E2 is an
IND-CCA2 secure PKE. We call the following construction
Scheme-IV.

• KeyGen(1λ): This algorithm executes the KeyGen
algorithm of both E1, E2, and returns {(pki, ski)}i=1,2.
• EnKey(O, A): This is a protocol between O, A with
inputs (pki, ski, s) and (pki, s) respectively; it proceeds
by executing the EnKey protocol of E1 to get (epk1, esk1)
ﬁrst, and this protocol terminates with O obtaining en-
hanced key pair (epk, esk), and A obtaining epk only,
where (epk, esk) = ((epk1, pk2), (esk1, sk2)).

• Enc(epk, m): To encrypt a message m, this algorithm
runs the encryption algorithms of both of E1, E2, and
returns the ciphertext as c = Enc(pk2, Enc(epk1, m))
• Dec(esk, c): To decrypt a ciphertext c, this algorithm
runs the decryption algorithms of both E1, E2 and re-
turns m = Dec(esk1, Dec(sk2, c)).

• RecB,D(epk, δ): With access to a decryption box B
and a plaintext distribution D, this algorithm calls the
Rec algorithm R1 of E1. For each query c of R1, this
algorithm feeds B with Enc(pk2, c). It then passes the
responses of the box to R1 and returns whatever R1
returns.

949Security Analysis: Correctness is obvious, and Privacy
and Recoverability are not inﬂuenced by the extra outer layer
encryption. To see IND-CCA2 security with dishonest au-
thority, ﬁrst, even if the authority has part of the secret key
for the inner layer enhanced public key epk1, any message
will be protected using the outer layer encryption E2; fur-
ther, CCA security also easily follows from the CCA security
of E2: the simulator can answer decryption oracle queries
by asking the E2 challenger to decrypt the outer layer, and
decrypt the inner ciphertext locally using esk1. Details can
be found in the full version.

We remark that the generic method above can be also
applied to the identity based setting; in that case, we can use
the one-time signature paradigm to achieve CCA2 security.
We omit further details.

4. LEAKAGE-DETERRING SIGNATURE &

IDENTIFICATION

In this section, we design leakage-deterring signatures and
identiﬁcation schemes. The main idea is that we treat any
functional box as an unforgeability or impersonation ad-
versary, and then take advantage of “witness extractabil-
ity” used in the security arguments of the underlying prim-
itive to extract the secret-key which will unlock the private
data; in this case we have non-black-box recoverability. We
stress that our constructions do not employ any additional
intractability assumptions than the underlying primitives.
4.1 Leakage-deterring Signature In the Ran-

dom Oracle Model

We construct a leakage-deterring signature scheme based
on a class of Σ-protocol-based signature schemes as in [29].
The security proofs of these signatures rely on the fact that
if the adversary can forge one signature, then he could also
forge another correlated signature for the same message with
the same random tape but a diﬀerent random oracle. Using
these two forgeries that are correlated, one can extract the
secret key of the owner.

Our construction of leakage-deterring signature is based
on two independent digital signatures instances Sig0 and
Sig1 that are unforgeable under adaptively chosen message
attacks. Further, Sig1 is required to be unforgeable in the
random oracle(RO) model following [29]; speciﬁcally, the sig-
nature has the form of (m, σ1, h, σ2) as in [29], and satisﬁes
h = H(m, σ1), and σ2 only depends on m, σ1, h, where H is
a RO. We call the following construction Scheme-V.

• KeyGen(1λ): This algorithm executes the KeyGen
algorithm of Sig0, and returns the key pair (pk0, sk0).
• EnKey(O, A): This protocol is executed between O, A
with inputs (pk0, sk0, s), and (pk0, s) respectively. A
runs KeyGen algorithm of Sig1 to generate a key
pair (pk1, sk1). The protocol terminates with O ob-
taining (epk, esk), and A obtaining epk, where epk =
(pk0, pk1, H(sk1) ⊕ s), and esk = (sk0, sk1).

• Sign(esk, m): On input a message m, this algorithm
returns the signature σ = (σ0, σ1), where it holds σ0 =
1, h1, σ2
Sign0(sk0, m), and σ1 = Sign1(sk1, m) = (σ1
1).
• Verify(epk, m, σ): On input a message-signature pair
(m, σ) and enhanced public key epk = (pk, pk(cid:48)), this

algorithm returns 1 if both of the two signatures are
valid, 0 otherwise.

1, h1, σ2

• RecD(epk, B, δ): The recovering algorithm follows the
security proof argument of [29]: Whenever the box B
asks a random oracle query (suppose total number of
such queries is bounded by q), the algorithm selects a
uniform response from the range of the random oracle
and feeds it to the box; it also maintains a table of
all these queries. The recovering algorithm samples a
message m according to D and simulates the box B
on m. When the box outputs a valid signature σ0, σ1,
where σ1 = (σ1
1), algorithm checks the table
and identiﬁes the index i of the ﬁrst query from B on
(m, σ1
1). Then, it rewinds B to the state prior to the
i-th query, and continues the simulation picking new
random query responses.
The above procedure is repeated until the box outputs
another valid signature (σ(cid:48)
0, σ(cid:48)
1) on the same message
m, where σ(cid:48)
1, σ(cid:48)
2), and also the index i that
1) was queried is the same for both σ1 and σ(cid:48)
(m, σ1
1.
Refer to the appendix for a more formal explanation
of knowledge extraction.
Now the algorithm can extract the second secret key
sk1 from (m, σ1
2) using the Σ pro-
tocol properties of the scheme that deﬁne Sig1. The
recovery of s follows immediately.

1), (m, σ1

1, h, σ(cid:48)

1 = (σ1

1, h(cid:48)

1, h1, σ2

Security Analysis: We now analyze the three properties.
It is easy to see that unforgeability against adaptively chosen
message attacks can be derived from the property of Sig0
as any forgery will imply also a forgery of Sig0. Note that
signing queries are easy to simulate because the simulator
has the secret key for Sig1, and can ask signing queries to
the challenger for Sig0. Privacy w.r.t. a secret-key oracle
for any distribution can be achieved because any successful
privacy attacker will have to eventually query sk1 to the ran-
dom oracle hence violating the unforgeability of Sig1. Note
that recoverability cannot violate privacy w.r.t. an arbitrary
secret key oracle, since it is achieved now via a non-black-
box technique. It uses the fact that rewinding the signing
box and controlling the random coins in an execution, one
can always ﬁnd a pair of signatures that reveal the secret
key, something that yields the private data. Details of the
analysis are in the full version.
4.2 Leakage-deterring Identiﬁcation

We will construct a leakage-deterring identiﬁcation scheme
by using a similar approach as in the signature case. How-
ever here we will show our construction secure in the stan-
dard model, and thus we need a novel method to embed the
owner private data into the enhanced public key. In fact we
will need no additional assumption beyond the one employed
for the underlying scheme.

Our construction of a leakage-deterring identiﬁcation scheme

is based on the class of identiﬁcation schemes which are
derived from zero-knowledge proofs of knowledge protocols
that can be parallely composed. We utilize the fact that
given access to the code of any box that implements the
identiﬁcation functionality, one can rewind the box and im-
plement the knowledge extractor assured to exist due to the
soundness property of the zero-knowledge proof. We call the
following construction Scheme-VI and is based on a param-
eter t that we specify below.

950• KeyGen(1λ): This algorithm executes the KeyGen
algorithm of the underlying identiﬁcation scheme, and
returns the key pair (pk, sk).

• EnKey(O, A): This is a protocol executed between
O, A with inputs (pk, sk, s), and (pk, s) respectively. A
runs KeyGen algorithm to generate t new key pairs
(pk1, sk1), . . . , (pkt, skt), and further, A calculates s(cid:48) =
r ⊕ s, where r = Ext(sk1|| . . .||skt, ρ) and Ext is a
strong randomness extractor (see below for implemen-
tation remarks) while ρ is the random seed. The proto-
col terminates with O obtaining (epk, esk), and A ob-
taining epk, where epk = (pk, pk1, . . . , pkt, s(cid:48), ρ), and
esk = (sk, sk1, . . . , skt).

• Identify(P, V ): This protocol is executed between P, V
with inputs (epk, esk), and epk respectively. The pro-
tocol is the parallel composition of the t + 1 underlying
identiﬁcation schemes. The protocol terminates with
V outputting 1 if he accepts the proof of knowledge of
all secret keys, and 0 otherwise.

• Rec(epk, B): The algorithm given B, runs the knowl-
edge extractor algorithm for the parallel composition
of the t schemes until all the secret keys of {sk1, . . . , skt}
are recovered. Then it applies the randomness extrac-
tor on ρ and returns s = s(cid:48) ⊕ Ext(sk1|| . . .||skt, ρ)

Security Analysis: We now analyze the security proper-
ties. Recoverability is essentially the same as the recover-
ability of Scheme-V. Impersonation resistance is also similar
to the unforgeability property of Scheme-IV; this property
mainly relies on the fact that nothing related to the original
secret key of the owner sk is added to the epk, therefore the
security of identiﬁcation using the original (pk, sk) can be
reduced to the impersonation resistance of Scheme-V. Re-
garding privacy, according to impersonation resistance, af-
ter seeing a polynomial number of transcripts of interaction
between P, V , there is still unpredicatability on the secret
key, (otherwise, one can impersonate by eavesdropping) then
applying the strong extractor one can get pure randomness
out of the secret-keys, and thus the owner data is hidden
computationally. Details are given in the full version.
Remark1: The strong randomness extractor Ext should work
on any source with suﬃcient conditional unpredictability
along the lines of [19]. For instance, we can use the extractor
derived from the Goldreich-Levin hard-core predicate [12].
Intuitively, one can think of the view (protocol transcripts
adaptively queried) of the adversary as the output of a one
way function on input {ski}. Using this, [12] implies an ex-
tractor of log λ bits per instance and thus t should be as long
as |s|/ log λ.
Remark2: If one is willing to allow additional intractabil-
ity assumptions, a more compact construction for leakage-
deterring signature (in the RO model) and leakage-deterring
identiﬁcation is also possible4. The construction would uti-
lize two key pairs (pk0, sk0), (pk1, sk1) and the secret infor-
mation will be embedded as E(pk1, s), thus only sk1 will be
used by the recoverability algorithm. Observe now that pri-
vacy will rely on the security of the encryption scheme (and
thus may require assumptions going beyond the underlying
identiﬁcation scheme). Furthermore reusing the same key
for signing and decrypting may not always be secure and

4We thank an anonymous reviewer for pointing this out.

Scheme Ciphertext/Signature Size Enc/Sign Time

I
III
V

1

O(log 1
δ )

2

1
O(log 1
δ )
2

Table 1: Eﬃciency of main leakage-deterring (LD)
schemes, the size and time denote the ratio of the
LD-scheme to the underlying primitive.

some specialized systems would need to be employed, for
instance cf. [18].

5. LEAKAGE-DETERRING CRYPTOSYSTEMS

IN PRACTICE

In this section we ﬁrst summarize the eﬃciency of our
main constructions of leakage-deterring public key primi-
tives in Table 5. Then we explore in more detail practi-
cal scenarios where leakage-deterring cryptosystems can be
used to provide novel solutions to security problems related
to sharing and transferring cryptographic functions.

Let us start with a more detailed motivating scenario:
consider a user that maintains all her e-mail encrypted on
a mailserver. The user is approached by someone wishing
to buy all e-mails sent by the e-mail address x@y in the
past, present and future. Using a regular encryption, the
user may release to the attacker an implementation of her
decryption function that works only if the plaintext is an
e-mail sent by x@y (and rejects all other input). If the user
does not care about the secrecy of the e-mails from x@y, she
has no strong reason to be deterred from releasing the im-
plementation (all her other messages can still be relatively
safe assuming the implementation is suﬃciently obfuscated
or delivered in hardware). Using our encryption however,
she is deterred:
if she releases the above implementation
(even in the form of a hardware token) an adverse action is
guaranteed to take place (via the recoverability algorithm):
her private information will be revealed. Obviously, a de-
termined secret-key owner can always decrypt and release
the plaintexts corresponding to those e-mails individually.
But this has to be done one by one, at a potentially high
cost. In this scenario, leakage-deterring public-key encryp-
tion ensures there is no way to optimize this operation:
if
one wants to provide access to his decryption he has to do it
on a “per-case” basis. Within a PKI this enforces secret-key
owners to practice more responsible secret-key management.
to secret key oracles (that would
be the CCA ﬂavor of our privacy property) and recover-
ability can not be achieved simultaneously in the general
case: the two properties are mutually exclusive. Thus, one
needs to choose a proper trade-oﬀ if he wants to implement
leakage-deterring public key schemes. Regarding PKE, our
objective in this work is to maximize the scope of recov-
erability:
it should work for all (even partially functional)
implementations; this makes our primitive most useful from
a self-enforcement perspective and necessitates the restric-
tions we have made in terms of the privacy property. If the
user wishes the private information to remain hidden, she
should provide no access to her secret-key. In the case of
signature/identiﬁcation schemes the situation is more tricky
since by nature of the functionality, the user is expected to
release signatures/identiﬁcation transcripts publicly (which

Recall privacy w.r.t.

951in some cases they may even be adaptively selected). Thus,
we must compromise and weaken our recoverability property
in some way. We resolved this by adopting a non-black-box
recoverability algorithm. As expected, if the implementation
becomes “obfuscated” then recoverability would be infeasi-
ble. We believe the trade-oﬀs we utilized are natural for
the primitives studied, but of course diﬀerent tradeoﬀs can
be possible between privacy and recoverability, and we leave
them as future work.

Depending on diﬀerent application scenarios, we can em-
bed various types of private owner information to deter the
leakage of a cryptographic functionality:
Self-enforcement. In the context of self-enforcement the
owner of the cryptographic functionality has embedded into
her enhanced public-key some private information that she
normally prefers to keep secret. This can be e.g., her credit-
card number or similar piece of private information as sug-
gested by Dwork, Lotspiech and Naor [9] that introduced
self-enforcement (in a diﬀerent context - see related work
in the introduction). In this way, when using our leakage-
deterring primitives, if the owner releases any implementa-
tion of the cryptographic functionality, any recipient of the
implementation will become privy to the hidden informa-
tion. This property “self-enforces” the owner to keep the
functionality to herself and solves the problem of how to
deter the sharing of software or hardware devices that im-
plement cryptographic functionalities.
All-or-nothing sharing of cryptographic functions.
In this scenario, the owner is obliged to embed the secret
key of the cryptographic primitive itself into the enhanced
public-key (in practice this can be done e.g., by a trusted key
generator algorithm which will be running the embedding al-
gorithm that is executed by the authority in our model). Us-
ing our techniques this means that any working implementa-
tion of the cryptographic functionality would leak the whole
secret-key. In this sense, the cryptographic functionality be-
comes “unobfuscatable”, any program that partially imple-
ments it, say for some types of inputs, can be transformed to
a program that implements it perfectly. Leakage-deterring
primitives used in this way suggest a type of all-or-nothing
property for cryptographic keys: owners of a cryptographic
functionality cannot partially share it, they either have to
keep it to themselves or share it fully. In practice, one can
expect that this is also a type of self-enforcing mechanism:
either all information about the cryptographic key will be
leaked or none.
Anonymity revocation from implementations. In this
setting, the owner of the cryptographic functionality oper-
ates it under a pseudonym (i.e., the enhanced public-key is
certiﬁed but without openly identifying the owner). How-
ever, the embedded information is ensured by the author-
ity to be either the owner’s real identity or an identity cre-
dential that the owner prefers to hide. In this setting, us-
ing our methodology, if any working implementation of the
functionality is conﬁscated, it will be possible to use the
recovering algorithm to reveal the hidden identity creden-
tial. This in turn, ensures some level of accountability: the
owner remains pseudonymous as long as he does not share
the cryptographic functionality but can be identiﬁed in case
any (even partially working) implementation is leaked.

6. CONCLUSIONS AND OPEN PROBLEMS
We introduced the notion of leakage-deterring cryptosys-

tems. Our schemes have the property that whenever an
owner releases an (even partially) “functional” box for oth-
ers to use instead of herself, anyone who has access to the
box can recover some private information that is embedded
into the public-key of the owner. We deﬁned the security
properties of these primitives and we provided several con-
structions for public key encryption, signatures, and identi-
ﬁcation.

Since this is the ﬁrst step in the formal investigation of
such primitives, several interesting open questions remain.
A natural question is how to combine the notion with traitor
tracing and other multi-user oriented cryptosystems. An-
other direction is with respect to CCA2 security: our con-
struction can potentially be optimized for eﬃciency and
avoid the nesting of two encryptions. A third direction is to
see to what extent it is feasible to construct leakage-deterring
signatures and identiﬁcation with black-box recoverability in
the standard model or more generally explore the tradeoﬀ
between recoverability and privacy. Last but not least, it
would be desirable to see how the trust to the authority can
be reduced (and e.g., obviate the need for the authority to
know the secret information).

Acknowledgements.
This work was supported by European Research Council
Project CODAMODA. The ﬁrst author was also partially
supported by Marie Curie project RECUP.

7. REFERENCES
[1] M. Bellare and O. Goldreich. On deﬁning proofs of

knowledge. In CRYPTO, pages 390–420, 1992.

[2] M. Bellare and G. Neven. Multi-signatures in the

plain public-key model and a general forking lemma.
In ACM CCS, pages 390–399, 2006.

[3] M. Bellare and P. Rogaway. Random oracles are

practical: A paradigm for designing eﬃcient protocols.
In ACM CCS, pages 62–73, 1993.

[4] J. Camenisch and A. Lysyanskaya. An eﬃcient system

for non-transferable anonymous credentials with
optional anonymity revocation. In EUROCRYPT,
pages 93–118, 2001.

[5] R. Canetti, M. Charikar, S. R. Sridhar Rajagopalan,

A. Sahai, and A. Tomkins. Non-transferrable
anonymous credentials. US Patent 7,222,362., 2008.
[6] B. Chor, A. Fiat, and M. Naor. Tracing traitors. In

CRYPTO, pages 257–270, 1994.

[7] R. Cramer and V. Shoup. Design and analysis of

practical public-key encryption schemes secure against
adaptive chosen ciphertext attack. SIAM J. Comput.,
33(1):167–226, 2004.

[8] I. Damgard. On σ- protocols. In

http://www.daimi.au.dk/ ivan/Sigma.pdf, 2010.

[9] C. Dwork, J. B. Lotspiech, and M. Naor. Digital

signets: Self-enforcing protection of digital information
(preliminary version). In STOC, pages 489–498, 1996.

[10] S. Dziembowski and K. Pietrzak. Leakage-resilient

cryptography. In FOCS, pages 293–302, 2008.
[11] A. Fiat and A. Shamir. How to prove yourself:

Practical solutions to identiﬁcation and signature
problems. In CRYPTO, pages 186–194, 1986.

[12] O. Goldreich and L. A. Levin. A hard-core predicate

for all one-way functions. In STOC, pages 25–32, 1989.

952[13] O. Goldreich, B. Pﬁtzmann, and R. L. Rivest.

Self-delegation with controlled propagation-or-what if
you lose your laptop. In CRYPTO, pages 153–168,
1998.

[14] P. Golle, F. McSherry, and I. Mironov. Data collection

with self-enforcing privacy. In ACM CCS, pages
69–78, 2006.

[15] V. Goyal. Reducing trust in the pkg in identity based

cryptosystems. In CRYPTO, pages 430–447, 2007.

[16] V. Goyal, S. Lu, A. Sahai, and B. Waters. Black-box

accountable authority identity-based encryption. In
ACM CCS, pages 427–436, 2008.

identity-based signatures from standard signatures. In
Public Key Cryptography, pages 121–140, 2008.

APPENDIX
Due to the page limit, we only put some preliminaries and
the most involved security analysis for scheme-III here, while
all other related contents (omitted deﬁnitions, security proofs,
and identity based constructions) are in the full version.

A. PRELIMINARIES

We recall some known primitives and results which we

[17] V. Guruswami and P. Indyk. Expander-based

utilized in our constructions or security analysis.

constructions of eﬃciently decodable codes. In FOCS,
pages 658–667, 2001.

[18] S. Haber and B. Pinkas. Securely combining public-key

cryptosystems. In ACM CCS, pages 215–224, 2001.

[19] C.-Y. Hsiao, C.-J. Lu, and L. Reyzin. Conditional

computational entropy, or toward separating
pseudoentropy from compressibility. In EUROCRYPT,
pages 169–186, 2007.

[20] Y. Ishai, A. Sahai, and D. Wagner. Private circuits:

Securing hardware against probing attacks. In
CRYPTO, pages 463–481, 2003.

[21] M. Jakobsson, A. Juels, and P. Q. Nguyen. Proprietary

certiﬁcates. In CT-RSA, pages 164–181, 2002.

[22] A. Kiayias and M. Yung. Breaking and repairing
asymmetric public-key traitor tracing. In Digital
Rights Management Workshop, pages 32–50, 2002.

[23] A. Kiayias and M. Yung. Traitor tracing with constant

transmission rate. In EUROCRYPT, pages 450–465,
2002.

[24] H. Komaki, Y. Watanabe, G. Hanaoka, and H. Imai.

Eﬃcient asymmetric self-enforcement scheme with
public traceability. In Public Key Cryptography, pages
225–239, 2001.

[25] B. Libert and D. Vergnaud. Towards black-box

accountable authority ibe with short ciphertexts and
private keys. In Public Key Cryptography, pages
235–255, 2009.

[26] H. Lipmaa, G. Wang, and F. Bao. Designated veriﬁer
signature schemes: Attacks, new security notions and
a new construction. In ICALP, pages 459–471, 2005.
[27] A. Lysyanskaya, R. L. Rivest, A. Sahai, and S. Wolf.

Pseudonym systems. In International Workshop on
Selected Areas in Cryptography, SAC ’99, pages
184–199, 2000.

[28] D. Naccache, A. Shamir, and J. P. Stern. How to

copyright a function? In Public Key Cryptography,
pages 188–196, 1999.

[29] D. Pointcheval and J. Stern. Security arguments for

digital signatures and blind signatures. J. Cryptology,
13(3):361–396, 2000.

[30] A. Sahai and H. Seyalioglu. Fully secure

accountable-authority identity-based encryption. In
Public Key Cryptography, pages 296–316, 2011.

[31] T. Sander and A. Ta-Shma. Auditable, anonymous

electronic cash extended abstract. In CRYPTO, pages
555–572, 1999.

[32] S. F. Shahandashti and R. Safavi-Naini. Construction

of universal designated-veriﬁer signatures and

Proof of Knowledge: [1] A proof of knowledge protocol
is one that a prover convinces the veriﬁer he knows a wit-
ness to a publicly known polynomial-time predicate. This is
a protocol between two parties P, V where P proves a state-
ment x ∈ L for a language L’s instance x with its witness w
from a witness set denoted by W (x). The protocol has two
properties:

• Completeness: Honest prover always convinces the ver-

iﬁer: Pr[V (P (x, w)) = 1 ∧ w ∈ W (x)] = 1.

• Soundness: There exist an eﬃcient “knowledge extrac-
tor” who interacts with prover, and outputs the wit-
ness with probability close to the success probability
that P convinces V . Formally, Pr[ExtP (x) ∈ W (x)] ≥
Pr[V (P (x)) = 1] − , where  is negligible.

Σ-Protocol: [8] One frequently used type of proof of
knowledge protocol is the class of Σ-protocol, which have
a three move structure (a, e, z), starting with the prover
sending a ‘commit’ message a, then the veriﬁer sending a
‘challenge’ message e, and ﬁnally the prover answering with
a ‘response’ message z. Using the Fiat-Shamir transforma-
tion [11], one can construct a signature scheme based on such
protocol in the random oracle model [3]. Security of such
signature schemes is comprehensively studied in [29], and it
mainly relies on the existence of a knowledge extractor algo-
rithm (which is implied by the soundness of the protocol).

General Forking Lemma: [2] The general forking lemma
states that that if an adversary, on inputs drawn from some
distribution, produces an output, then the adversary will
produce another correlated output with diﬀerent inputs from
same distribution and same random tape. Rigorously, let
A be a probabilistic algorithm, with inputs (x, r1, . . . , rq; ρ)
that outputs a pair (J, σ), where ρ refers to the random tape
of A (that is, the random coins A will make). Suppose fur-
ther that x is sampled from some distribution X, and R is a
set of size |R| and ri is sampled uniformly from R. Let acc
be the probability for J ≥ 1. We can then deﬁne a “forking
algorithm” as follows,

• on input x: pick a random tape ρ for A.
• r1, . . . , rq
r← R, (J, σ) ← A(x, r1, . . . , rq; ρ)
• If J = 0, return (0, , ).
• r(cid:48)
• (J(cid:48), σ(cid:48)) ← A(x, r1, . . . , rJ−1, r(cid:48)
• If J(cid:48) = J and rJ (cid:54)= r(cid:48)

J , . . . , r(cid:48)

J , . . . , r(cid:48)

r← R

q; ρ)

q

J then return (1, σ, σ(cid:48)), otherwise,

return (0, ε, ε).

Let frk be the probability that A outputs (b, σ, σ(cid:48)), and b =
1, then frk ≥ acc( acc

q − 1|R| ).

953B. ANALYSIS FOR SCHEME-III

Theorem 1. Scheme-III parameterized by any δ > 0,
achieves IND-CPA (with honest authority), privacy (with-
out secret-key oracle), and black-box recoverability w.r.t. the
δ −c},
class of distributions Dδ = {D | H∞(D) ≥ log |s|+log 1
where c is a constant (depending on the ECC) and |s| the
length of the private information.

Proof. The most involved part of the proof is related
to recoverability, so we mainly analyze this property. It is
not diﬃcult to see that the way we sample m0, m1 in the
Rec algorithm, every query is an encryption of a message
independently sampled from D (the only exception is that
D almost always outputs only one message but in this case,
any box becomes “trivial”). Thus, the recovering query is
identically distributed as normal decryption queries and B
would have δ-correctness for a random recovering query!

The main challenge in the proof of the theorem is the fact
that the box B might behave diﬀerently depending on i and
thus force us to err in a number of locations i. We will
prove that we can bound this number and hence our error-
correction layer will be suﬃcient for recovering the hidden
information in the epk. Let δi = Pr[B decrypts correctly |
i ∈ S]. We divide the indices i ∈ {1, . . . , m} in two sets, Bad
and Good, we deﬁne i ∈ Good if and only if δi ≥ κ + α0 =
δ0, where κ = p(D) = 2−H∞(D) denoting the predicting
probability and α0 = (δ − κ)/m2 . We will later estimate
the number of repetition for each i, denoted by N , such that,
if i ∈ Good the recoverability will return the proper bit in
the i-th coordinate with overwhelming probability. In order
to upper bound the size of Bad consider the following. Let
D be the event of correct decryption. We have that,
Pr[D] = Pr[D | S ∩ Bad = ∅] · Pr[S ∩ Bad = ∅]
+ Pr[D | S ∩ Bad (cid:54)= ∅] · Pr[S ∩ Bad (cid:54)= ∅],

k

Regarding Pr[S ∩ Bad = ∅] observe that if k = |Bad|, this
i=0(1 −
probability is bounded by p(k, t) = C t
m−i ) ≤ (1 − k
m )t. From inequality ex ≥ 1 + x, we can get
p(k, t) ≤ e−kt/m. Regarding Pr[D | S ∩ Bad (cid:54)= ∅] note that
i∈Bad δi ≤ m(κ + α0) (This bound follows
i=1 Pr[F|Ai],
directly from the fact that Pr[F| ∪n
for any event F, Ai). We now derive the following,

it is bounded by(cid:80)

i=1 Ai] ≤(cid:80)n

m−k/C t

m =(cid:81)t−1

δ ≤ Pr[D] ≤ e

−tk/m + m(κ + α0),
from which we obtain the upper bound k ≤ m
t · ln(δ− m(κ +
α0))−1. Now observe that due to the condition for the min-
entropy, we derive a bound on κ ≤ 2cδ/|s| = c(cid:48)δ/|s|, for
some constant c(cid:48). From the choice of α0, we can prove
that δ − m(κ + α0) ≥ δ/4 as long as c is selected ap-
propriately (taking into account the error-correcting rate
which is constant). We plug this condition and the fact
that t = 5 ln(4δ−1) into the above bound for k, we conclude
that k ≤ m ln(4δ−1)/5 ln(4δ−1) = m/5.
Now we analyze the number of repetitions needed for an
i ∈ Good(in terms of an asymptotic function of the security
parameter λ) to guarantee we are almost certain that s will
be returned in the Rec algorithm.
First, an experiment is useful only if m0 (cid:54)= m1, otherwise,
we will always record a ⊥ for this query. The probability
of having one useful experiment after sampling N0 pairs of
(m0, m1) will be 1−Col(D)N0 , where Col(D) is the collusion
probability of distribution D which denotes the probability

of sampling a same element from two independent trials.
Observe that Col(D) < 1 − γ, for some non-negligible γ,
if D is not trivial which has probability almost 1 over one
element. If we repeat N0 = 2 log2 λ times sampling, we will
get a useful experiment with probability almost 1.

Second, randomly selecting S will not always contain i
to be a “useful query” for recovering i. But sampling S ran-
domly instead of always containing some i aims at producing
the recovering queries indistinguishable from normal cipher-
text. Suppose now the target of the recovering algorithm
is the i-th bit, in one selection, the probability Pr[i ∈ S] is
C t−1
m−1/C t
m = t/m. From the lower tail of Chernoﬀ bound,
the probability of selecting N1 times without hitting i once is
2m −1). After randomly sample 4m/t times,
smaller than e−(
one will be sure that one of the subsets will contain i, and
one useful query is created.

N1t

p

2κ+α0

δ0+p ≤ p+η

Further, In one useful query which contains the target
location i, only two answers (m0, m1) would be considered
possibly correct, all other answers could be simply ignored
(denoted by ⊥). The probability of getting at least one
correct answer after repeating N2 times useful experiments
is 1 − (1 − (κ + α0))N2 , if N2 = O(log2 λ), this probability
is almost 1(with negligibly small diﬀerence).
Next, in one useful query, the probability of returning an
incorrect but non-⊥ answer is at most κ, since this hap-
pens only when the box returns mb while the correct an-
swer is m1−b, for b = 0, 1 (recall these two messages are
independently sampled from D). Now we focus on non-⊥
answers only, the probability of an incorrect answer appear-
ing among the non-⊥ answers is at most q = κ
(This
can be argued as follows: suppose κ = p + η,where p is
the probability of returning an incorrect but non-⊥ answer
in one query and η ≥ 0; then, the probability of obtain-
ing an incorrect (but non-⊥) answer among all non-⊥ an-
δ0+p+η = q). Suppose X is the
swers is at most
random variable that denotes the number of appearances
of incorrect (but non-⊥) answers after collecting N3 non-
⊥ answers, and µ denotes the expectation of X which is
no bigger than N3q. The probability that correct answers
do not constitute the majority is Pr[X ≥ N3
2 ]. Using the
upper tail of the Chernoﬀ bound:Pr[X > (1 + β)µ)] ≤
−β2µ
, we can verify that this probability is bounded by
e
exp(−N3α2
0/(24p(D)2 + 6p(D)α0)). So if we collect more
log2 λ) non-⊥ symbols, the majority will
−2
than N3 = O(α
0
be occupied by the correct answers with probability almost
1, and hence we can recover the bit.
Combining these procedures, in total, if the recovering
procedure repeats N0 × N1 × N2 × N3 = O(α
−2
0 m log6 λ) =
O(α−2λ5 log6 λ) times (given that the length of the code-
word m = O(λ), and α = δ − p(D)), one can recover ri cor-
rectly with overwhelming probability as long as i ∈ Good.
Since the number of errors in recovering r is bounded by k,
5 ≥ k,
and the ECC is able to correct up to m
thus ˜r will be recovered correctly with overwhelming prob-
ability and hence also s. (note that if we can reset the box
across experiments the ciphertexts for which i (cid:54)∈ S can be
just omitted, saving a factor of N1).

5 errors, and m

3

Remark: In this construction, the ciphertext size is parame-
terized by the correctness δ which is inﬂuenced by the min-
entropy of the distribution the box works on. Essentially,
if the min-entropy is getting smaller, then ciphertext size
increases.

954