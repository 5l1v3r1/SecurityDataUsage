PyCRA: Physical Challenge-Response Authentication

For Active Sensors Under Spooﬁng Attacks

Yasser Shoukry, Paul Martin, Yair Yona, Suhas Diggavi, and Mani Srivastava

Electrical Engineering Department, University of California at Los Angeles, USA

{yshoukry, pdmartin, yairyo99, suhasdiggavi,mbs}@ucla.edu

ABSTRACT
Embedded sensing systems are pervasively used in life- and security-
critical systems such as those found in airplanes, automobiles, and
healthcare. Traditional security mechanisms for these sensors focus
on data encryption and other post-processing techniques, but the
sensors themselves often remain vulnerable to attacks in the phys-
ical/analog domain. If an adversary manipulates a physical/analog
signal prior to digitization, no amount of digital security mecha-
nisms after the fact can help. Fortunately, nature imposes funda-
mental constraints on how these analog signals can behave. This
work presents PyCRA, a physical challenge-response authentica-
tion scheme designed to protect active sensing systems against phys-
ical attacks occurring in the analog domain. PyCRA provides se-
cure active sensing by continually challenging the surrounding en-
vironment via random but deliberate physical probes. By analyz-
ing the responses to these probes, the system is able to ensure that
the underlying physics involved are not violated, providing an au-
thentication mechanism that not only detects malicious attacks but
provides resilience against them. We demonstrate the effectiveness
of PyCRA in detecting and mitigating attacks through several case
studies using two sensing systems: (1) magnetic sensors like those
found on gear and wheel speed sensors in robotics and automo-
tive, and (2) commercial Radio Frequency Identiﬁcation (RFID)
tags used in many security-critical applications. In doing so, we
evaluate both the robustness and the limitations of the PyCRA se-
curity scheme, concluding by outlining practical considerations as
well as further applications for the proposed authentication mecha-
nism.

Categories and Subject Descriptors
C.2.0 [COMPUTER-COMMUNICATION NETWORKS]: Gen-
eral: Security and protection

General Terms
Security

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813679.

Keywords
Embedded Security; Active sensors; Challenge-response authenti-
cation; Spooﬁng attacks; Physical attacks

1.

INTRODUCTION

Recent decades have witnessed a proliferation in embedded sen-
sors for observing a variety of physical phenomena. Increased use
of these sensors in security- and life-critical applications has been
accompanied by a corresponding increase in attacks targeting sens-
ing software, hardware, and even physical, analog signals them-
selves. While considerable research has explored sensor security
from a system-level perspective—network redundancy, sensor fu-
sion, and the like—sensors themselves remain largely vulnerable to
attacks targeting analog signals prior to digitization. This vulnera-
bility can lead to catastrophic failures when a malicious third party
attempts to spoof the sensor [19, 14, 3, 33].

Several system-level sensor security schemes have been proposed
in the context of power grids. For example, Dorﬂer et al. have ex-
plored distributed cyber-physical attack detection in the context of
power networks [6, 30]. Similar ideas for providing system-level
security in smart grids can be found in [16, 18, 4, 22, 35]. Security
schemes in this vein include, among others, state-space and control-
theoretic approaches for detecting anomalous system behavior [7,
30]. One idea common to these efforts is that an inherent security
mechanism and robustness can be found in the physics governing
the dynamics of the system as a whole. For example, a mismatch
between the rate of change in a vehicle’s location as reported by
GPS and by the odometer sensor may indicate that one of these
two sensors is either faulty or under attack.

A complementary security mechanism can be found in the un-
derlying physics governing the sensor itself. If a sensor observes
an analog signal that appears to violate the physics governing the
sensing dynamics, the signal itself may be under attack, necessi-
tating security mechanisms at the analog signal level. To reduce
sensor-level vulnerabilities, engineers often place sensors in secure
or remote physical locations to preclude direct physical contact
with the sensing hardware. Additionally, the phenomenon being
sensed is often difﬁcult to access, whether prohibitively far away
or surrounded by protective material. In such scenarios, adversaries
have access only to the analog signal prior to it reaching the sensor,
and their attack must be carried out without direct access to any
hardware in the entire sensing path, from source to sink. Even with
these countermeasures in place, an adversary can still attack sen-
sors by manipulating the physical signals before their transduction
and subsequent digitization [19, 33]. Robust countermeasures for
such attacks must necessarily be carried out at the physical level
as well—once these signals have been sampled and digitized, no
amount of post-processing can repair the compromised sensor data.

1004Broadly speaking, sensors can be divided into two categories:
passive (those that sense pre-existing physical signals) and active
(those that perform some action to evoke and measure a physical
response from some measurable entity). Examples of passive sen-
sors include temperature, humidity, and ambient light, while active
sensors include ultrasound, laser scanners, and radar. Passive sen-
sors are largely naïve listening devices–they blindly relay informa-
tion to higher levels of software without regard for the integrity of
that information. Digital ﬁltering and other post-processing tech-
niques can be used to remove noise from passive sensors, but they
remain unable to combat attacks at the physical layer in any mean-
ingful way. On the other hand, active sensors introduce the possi-
bility for more advanced security measures. PyCRA is, at its core, a
method of ensuring the trustworthiness of information obtained by
active sensors by comparing their responses to a series of physical
queries or challenges. The driving concept behind PyCRA is that,
by periodically stimulating the environment with a known signal
and measuring the response, we can ensure that the signal measured
by the sensor is in accordance with the underlying sensing physics.
This periodic stimulation and subsequent behavioral analysis—the
physical challenge-response authentication, creating a secure active
sensing platform—is the main contribution of this work.

We demonstrate the effectiveness of PyCRA for three exemplary
cases: physical attack detection for magnetic encoders, physical at-
tack resilience for magnetic encoders, and passive eavesdropping
detection for RFID readers. Magnetic encoders are used in a wide
array of commercial and industrial applications and are representa-
tive of a large class of inductive active sensors. We demonstrate not
only how active spooﬁng attacks can be detected for these inductive
sensors but also how the effects of these attacks can be mitigated.
Eavesdropping detection on RFID readers serves to illustrate an
extension of PyCRA to enable detection of passive attacks. Our re-
sults from more than 90 experiments demonstrate that PyCRA can
accurately detect attacks in a variety of settings. We believe that
the methods demonstrated in this work can be applied to a broad
array of active sensors beyond those studied directly in this work,
including ultrasound, optical sensors, active radar, and more.
1.1 Contributions of PyCRA

In summary, the contributions described in this paper are three-

fold:

• We present a generalizable physical challenge-response au-

thentication scheme for active sensing subsystems.

• We introduce algorithms for detecting the presence of and
providing resilience against physical attacks when using phys-
ical challenge-response authentication.

• We demonstrate the effectiveness of PyCRA, our implemen-
tation of physical challenge-response authentication, against
several different attack types and for over 90 experiments
with three exemplary applications: (1) detection of active at-
tacks on magnetic encoders, (2) resilience against active at-
tacks on magnetic encoders, and (3) detecting passive eaves-
dropping attacks on RFID readers.

The rest of this paper is organized as follows. Section 2 outlines
the attacker model. Section 3 describes the basic operation of the
PyCRA authentication scheme for detecting active attacks. Section
4 outlines theoretical limitations of attackers on physical signals.
Section 5, 6, and 7 are devoted to the results of three case studies:
attack detection for magnetic encoders, attack detection for passive
eavesdropping on RFID readers, and attack resilience for magnetic

Figure 1: A typical active sensor architecture. The actuator gener-
ates an analog signal (energy) which is reﬂected by the measured
entity back to the sensor. The received analog signal is captured and
processed by the analog front-end. The signal is then converted to
a digital format which is processed once more (by the digital back-
end) before being sent to higher level software layers.

encoders. Finally, we offer a discussion and concluding thoughts
in Sections 8.1, 8.2 and 9.

2. ATTACKER MODEL

Before describing mechanisms by which we can detect and pre-
vent sensor attacks at the physical layer, we must differentiate be-
tween two broad categories of sensors—namely passive and active
sensors—and deﬁne what we mean by a physical attack.
2.1 Passive vs. Active Sensors

Sensors can be broadly classiﬁed as either passive or active based
on the source of energy being sensed. Passive sensors measure am-
bient energy. For example, temperature sensors like those found in
thermostats are considered passive, because they measure heat en-
ergy in the ambient environment. By contrast, active sensors probe
some physical entity with self-generated energy as shown in Fig-
ure 1. This energy is partially reﬂected back to the sensor where it
is measured and used to infer properties about some physical phe-
nomenon. Examples of active sensors include ultrasonic range ﬁnd-
ers (used in robotics), optical and magnetic encoders (used in au-
tomotive vehicles, industrial plants, & chemical reﬁneries), radar,
and even radio-frequency identiﬁcation (RFID) systems. In RFID,
a reader is used to generate electromagnetic waves which are then
used by wireless tags to transfer back their unique identiﬁer to the
reader.

In this paper, we focus on providing security for active sensors.
In particular, we leverage an active sensor’s ability to emit energy
in order to 1) provide detection of active attackers trying to spoof
the sensor, 2) mitigate the effects of active spooﬁng attacks and 3)
detect passive eavesdropping attacks attempting to listen to the in-
formation received by the sensor. In the following subsections, we
deﬁne what we mean by physical attacks on active sensors and out-
line the assumed properties and limitations of a potential adversary.
2.2 Deﬁning Physical Attacks

In this paper, a physical attack refers to a malicious alteration
of a physical, analog signal (e.g., magnetic waves, acoustic waves,
visible waves) prior to transduction and digitization by a sensor, as
shown in Figure 1.
2.3 Adversarial Goals

The adversary considered in this work has a number of goals
related to misinforming and misleading sensors. These goals are
summarized below.

G1 Concealment: An attacker does not want the presence of his

or her attack to be known.

If a sensor attack can be easily detected, preventative countermea-
sures like hardware redundancy and resilience at the system-level
can often be used to mitigate the damage done by the attack [7, 30].

Active SensorActuatorAnalog Front-End(sensing & (cid:31)ltering)Digitization(ADC)DigitalBack-EndSoftware LayersMeasured Entityphysical attackProbeResponse1005Figure 2: Examples of physical delays seen in typical sensing and
actuation hardware, including optical sensors (left) and electromag-
netic coupled (e.g., RFID) sensors (right). In each case, the mea-
sured analog signal (blue solid) lags behind the ideal, “logical” sig-
nal (red dashed), causing delays.

G2 Signal Injection: An attacker will attempt to trick the sen-
sor into thinking that a malicious, injected signal is the true
physical signal.

The primary goal of an attack is to replace the true physical sig-
nal that a sensor aims to sense with a malicious signal. In other
words, an adversary will attempt to “inject” a signal into the phys-
ical medium that the sensor is measuring in order to jam or spoof
the sensor.

G3 Signal Masking: An attacker will attempt to prevent the sen-

sor from being able to detect the true physical signal.

If the sensor is still capable of reliably discerning the correct sig-
nal from the malicious, injected signal, then the attack may not be
successful. Thus, the adversary aims not only to inject a signal but
also to mask the true signal, whether by overpowering, modifying,
or negating (canceling) it.
2.4 Assumptions about the Adversary

The physical attacks against sensors considered in this work op-

erate under four main assumptions:

A1 Non-invasiveness: Attacks are of a non-invasive nature—that
is, the attacker is not allowed direct access to the sensor
hardware. Additionally, the adversary does not have ac-
cess to the sensor ﬁrmware or software, whether directly or
through wired or wireless networking.

In most life- and safety-critical applications, engineers are careful
to ensure that sensors are not physically exposed and vulnerable to
direct tampering. For example:

• Sensors are often installed inside the body of a physically
secured infrastructure (e.g., sensors inside the body of an au-
tomotive system, moving UAV drones, etc.).

• For sensors which are physically accessible, existing tech-
niques in the literature demonstrate ways to implement tamper-
proof packaging to protect sensors from direct, physical mod-
iﬁcations [31, 17, 1].

• Numerous sensor systems have methods for detecting when
wires connecting their various sensors have been tampered
with. For example, automotive systems are equipped with
sensor failure detection systems which can detect whether
all sensor subsystems are correctly connected and alert the
driver if any of them fails [8].

Because of this, any attack must be carried out from a distance,
without direct access to any sensor hardware. In short, an adversary
is assumed to have access only to the physical/analog medium used
by the sensor—magnetic waves, optics, acoustics, etc.

Additionally, it is important to distinguish these sensors from
sensor nodes (which appear in the literature of sensor networks);
the attacks and countermeasures in this work target sensors them-
selves. Sensors are simple subsystems designed to perform only

one simple task; sensing the physical world. Because of this, many
sensors do not support remote ﬁrmware updates and do not typi-
cally receive commands from a remote operator, making such at-
tack vectors uncommon as many sensors do not have such capabil-
ities.

A2 Trusted Measured Entity We assume that the physical entity
to be measured by the sensor is trusted and incapable of be-
ing compromised.

Similar to the sensor hardware itself, the entity that the sensor aims
to measure is typically difﬁcult to access or alter directly while
maintaining Goals G1–G3. For example, in RFID systems the tag
itself is often encased in tamper-proof packaging [31, 17]; for ul-
trasonic ranging and active radar, maliciously altering the measured
entity (often the entire surrounding environment) is impractical in
time & effort and undoubtedly violates Goal G1; for airplane en-
gine speed sensors, the engines cannot easily be modiﬁed or re-
placed; for heart monitors, the heart cannot (we hope) be modiﬁed
[19], and so forth.

A3 Physical Delays (τattack): Adversaries require physical hard-
ware with inherent physical delays. This delay, though vari-
able in duration, is fundamental to all physical actuation and
sensing hardware.

These same analog/physical signals cannot be manipulated or even
observed (i.e. sniffed) without physical hardware. That is, to tam-
per with magnetic waves, an attacker needs hardware that is able to
generate magnetic waves, optical signals need physical hardware
that generates optical signals, and so on. Furthermore, this hard-
ware has to obey fundamental physics imposed by nature; the un-
derlying physics dictate that the response of any physical element
is governed by a dynamical model (mathematically modeled using
differential/difference equations) [9, ch. 2], [2, chs. 8–9]. This
dynamical model describes the output response for each physical
element in response to their inputs, e.g., the time for a voltage to
drop from a certain value to zero and so on. Although from a sys-
tem point of view, we often assume that analog signals like those in
Figure 2 take on logical values of 0 and 1, the underlying physics
is always different from this “system” point of view. For example,
Figure 2 shows how hardware that generates clock waveforms and
optical pulse signals behaves quite differently from the desired, log-
ical signals used to control them. In general, no physical signal can
arbitrarily jump from one state to another without suffering from
delays imposed by physics [9, ch. 2].

Furthermore, these physical delays are lower bounded by a non-
zero, fundamental limit. For example, the time response of an elec-
tromagnetic sensor/actuator is a multiple of physical constants like
magnetic permeability [2, chs. 8–9] or permitivity and electric con-
stants for capacitive sensors [9, ch. 4]. In general, the time response
of any sensor or actuator can never be below certain fundamental
thresholds controlled by physical constants. We refer to this physi-
cal delay as τattack for the remainder of this paper.

A4 Computational Delays: PyCRA is designed and analyzed with
a focus on physical delays. We make no assumption regard-
ing the computational power of a potential adversary.

We assume that an adversary has knowledge of the underlying se-
curity mechanism, attempting to conceal an attack by reacting to
each physical challenge or probe from the PyCRA-secured active
sensor. In practice, such an adversary would suffer from compu-
tational delays in addition to the physical delays addressed above.
These delays would make it even more difﬁcult for an adversary to
respond to these challenges in a timely manner. PyCRA is designed

00.20.40.60.811.21.41.61.82·10−70246Time[s]Voltage[volt]Physical/Analogsignal“Logical”representation00.20.40.60.81·10−40510Time[s]Voltage[volt]Physical/Analogsignal“Logical”representation1006(a)

Figure 3: An illustration of three physical attack types: (a) a passive eavesdropping attack, (b) a simple spooﬁng attack where a malicious
actuator blindly injects a disruptive signal, and (c) an advanced spooﬁng attack where an adversary uses a sensor to measure the original
signal and an actuator to actively cancel the original signal and inject a malicious one.

(b)

(c)

to leverage only the physical delays addressed above, but additional
computational delays would make it even easier to detect the pres-
ence of an attack.
2.5 Physical Attack Types for Sensors

Attacks can be classiﬁed as either passive (eavesdropping) or ac-
tive (spooﬁng). While we consider only physical/analog attacks in
accordance with assumptions A1–A4, the passivity of an attack is
decided by whether or not the attacker is manipulating (or spoof-
ing) the physical signal or merely listening to it. Active attacks
themselves can be classiﬁed once more into simple spooﬁng or ad-
vanced spooﬁng attacks. In short, physical sensor attacks in accor-
dance with assumptions A1–A4 can be broadly divided into three
categories (Types):

T1 Eavesdropping Attacks: In an eavesdropping attack, an ad-
versary uses a malicious sensor in order to listen to the active
sensor’s “communication” with the measured entity (Figure
3a).

T2 Simple Spooﬁng Attacks: In a simple spooﬁng attack, an ad-
versary uses a malicious actuator to blindly inject a mali-
cious signal in order to alter the signal observed by the sen-
sor. These attacks are simple in that the malicious signal is
not a function of the original, true signal (Figure 3b).

T3 Advanced Spooﬁng Attacks In an advanced spooﬁng attack,
an adversary uses a sensor in order to gain full knowledge
of the original signal and then uses a malicious actuator to
inject a malicious signal accordingly. This enables an at-
tacker to suppress the original signal or otherwise alter it in
addition to injecting a malicious signal (Figure 3c).

We argue that these attack types span all possible modes of attacks
that abide by Assumptions A1–A4 with those goals outlined in G1–
G3. For example, jamming or Denial of service (DoS) attacks falls
in category T2 where the attacker’s actuator is used to blindly gen-
erate high amplitude, wide bandwidth signals to interfere with the
physical signal before it reaches the sensors; replay attacks fall in
either category T2 or T3 based on whether the attacker is blindly
replaying a physical signal or destructing the original physical sig-
nal before inserting the replay signal; spooﬁng attacks like those
demonstrated in [19] fall in category T2; and attacks described in
[33] fall within both T2 and T3.

At ﬁrst glance, attacks of type T1 may not seem important espe-
cially if the sensor under attack measures a physical signal that is
publicly accessible (e.g., room temperature, car speed, etc.).
In
such cases, an adversary can measure the same physical signal
without the need to “listen” to the interaction between the active
sensor and the environment. However, this may not always be the

case. For example, an attacker might measure magnetic waves dur-
ing an exchange between an RFID reader and an RFID tag, learning
potentially sensitive information about the tag. These attacks are
passive, meaning that the attacker does not inject any energy into
the system. Sections 5 describes methods for detecting attack types
T2 and T3, leaving attack type T1 for later discussion in Section 6.

3. PYCRA AUTHENTICATION SCHEME

The core concept behind PyCRA is that of physical challenge-
response authentication. In traditional challenge-response authen-
tication schemes, one party requires another party to prove their
trustworthiness by correctly answering a question or challenge. This
challenge-response pair could be a simple password query, a ran-
dom challenge to a known hash function, or other similar mecha-
nisms. In the proposed physical challenge-response authentication,
the challenge comes in the form of a physical stimulus placed on the
environment by an active sensor. Unlike traditional schemes, the
proposed physical challenge operates in the analog domain and is
designed so that an adversary cannot issue the correct response be-
cause of immutable physical constraints rather than computational
or combinatorial challenges.

We begin by modeling the problem of detecting physical sensor
attacks as an authentication problem. To draw this analogy, let us
consider the communication system shown in Figure 4a. This ﬁg-
ure shows two ‘parties’: (1) an active sensor composed of actuation
and sensing subsystems and (2) the measured entity which responds
to signals emitted by the actuator contained within the active sen-
sor. The ﬁrst party—the active sensor—is responsible for initiating
the “communication” by generating some physical signal such as a
magnetic, acoustic, or optical wave. The second party—the mea-
sured entity—responds to this “communication” by modulating this
signal and reﬂecting it back to the sensing subsystem of the active
sensor. With this analogy in mind, the problem of detecting physi-
cal attacks can be posed as that of ensuring that the “message” seen
by the sensor has originated from a trusted party (the true entity
to be measured). This is akin to identity authentication in the the
literature of computer security but applied to the analog domain.
3.1 Simple PyCRA Attack Detector

Using the communication analogy shown in Figure 4a and re-
calling that we are interested only in active sensors as described in
Section 2.1, we notice that the measured entity, as a participating
party in this communication, is strictly passive, i.e. it cannot initi-
ate communication; it responds only when the sensor generates an
appropriate physical signal.

PyCRA exploits this “passivity” in order to facilitate the detec-
tion of attacks. Without PyCRA, an active sensor’s actuator would
probe the measured entity in a normal fashion using a determin-

ActuatorMeasured EntityActive SensorproberesponseSensorSensorMaliciousActuatorMeasured EntityActive SensorproberesponseSensorActuatorMaliciousActuatorMeasured EntityActive SensorproberesponseSensorSensorMaliciousActuatorMaliciousShield1007A (t)

t

u(t)

y(t)

B(t)

t

u(t)

y(t)

B(t)

t

u(t)

y(t)

a(t)

a(t)

a(t)

t

t

t

t

t

t

(a)

Figure 4: An illustration of the PyCRA architecture and attack detection scheme: (a) During normal operation, the active sensor generates a
signal A (t). This signal passes through environmental dynamics and is reﬂected back to the sensor as y(t); (b) Using the proposed PyCRA
scheme, the sensor generates a modulated signal B(t). If there is no attack present, the reﬂected signal diminishes if the active sensor’s
actuator is driven to zero; (c) Using the proposed PyCRA scheme while the sensor is under attack (by signal a(t)), a malicious signal is
detected during the period when the actuator is disabled.

(b)

(c)

istic signal denoted by A (t). We embed in this signal a physical
challenge through pseudo-random binary modulation of the form:

B(t) = u(t)A (t), u(t) ∈ {0,1}

(1)
where u(t) is the binary modulation term and B(t) is the modulated
output of the actuator. The output of the active sensor is denoted by
y(t) as shown in Figure 4. In the absence of an attacker and from the
passivity of the measured entity, setting u(t) = 0 (and consequently
B(t) = 0) at time tchallenge will cause y(t) to go to zero.

Potential attackers must actively emit a signal a(t) to overpower
or mask y(t) (Goals G2–G3). A naïve attacker might continue to
emit this signal even when B(t) = 0 as shown in Figure 4c. In this
case, the attack can be easily detected, since any nonzero y(t) while
u(t) = 0 can be attributed to the existence of an attacker.

More advanced attackers might attempt to conceal their attacks
when they sense the absence of B(t) as in Goal G1. Due to As-
sumption A3, an attacker could drive a(t) to zero only after a delay
of τattack, where τattack ≥ τphysical limit > 0 is the unavoidable phys-
ical delay inherent in the attacker’s hardware. Therefore, the mech-
anism described above can still detect the presence of an attack
within this unavoidable time delay. Furthermore, an attacker can-
not learn and compensate for this inherent delay preemptively due
to the randomness of the modulation term u(t). Again, any nonzero
y(t) sensed while u(t) = 0 can be attributed to the existence of an
attacker. The simple PyCRA attack detector can be summarized as
follows:
[Step 1] Select a random time, tchallenge
[Step 2] Issue a physical challenge by setting u(tchallenge) = 0
[Step 3] If y(tchallenge) > 0, declare an attack
Note that the previous process needs to happen within small amount
of time (e.g., in the order of milliseconds) such that it does not af-
fect the normal operation of the system.
3.2 The Confusion Phase

Every physical signal is subject to random perturbations known
as noise. A fundamental characteristic of this noise is the signal to
noise ratio (SNR). This SNR determines the ability of any sensor to
distinguish between changes in a signal of interest and the random
noise. As with the physical delay, this SNR is fundamental, and
it is never equal to zero. As a result, if a signal is within the noise
ﬂoor (less than the noise amplitude), it is fundamentally impossible
to detect any change in the physical signal [36].

As with the physical time delay τattack, we use this fundamental
limit in order to enhance PyCRA and introduce additional security.
To do so, we modify the physical challenge by introducing an in-
termediate step—between the active phase (e.g., u(t) = 1) and the
silent phase (e.g., u(t) = 0)—called the confusion phase. In this

phase, the active sensor uses its actuator to generate a signal u(t)
that is small enough to barely exceed the noise level. Next, we wait
in this confusion phase for a random time tcon f usion before entering
the silent time. This process is summarized in Figure 5.

Recall that one of the attacker’s goals is to remain stealthy (Goal
G1). If the attacker is unable to instantaneously detect the changes
in the physical challenge, he or she will reveal themselves. Due
to the existence of noise, no attacker—whether using software or
hardware to counter the physical challenges issued by PyCRA—
can instantaneously detect the change in the physical challenge.
That is, there always exists a non-zero probability of the attacker
missing the changes in the physical challenge. In Section 4, we
detail a theoretical result that explains the relationship between the
amplitude of the physical challenge within the confusion phase and
the probability that the attacker will fail to detect changes in the
physical challenge.
3.3 Effect of Physical Delays at the Sensor

As with the attacker, the actuator used by the active sensor it-
self suffers from physical delays. This means that when PyCRA
issues a physical challenge, the actuator output does not transition
immediately. Apparently, if the physical delay in the active sensor
is greater than τattack, then an adversary can conceal his signal. To
counter this, PyCRA constructs a mathematical model for the sen-
sor that is used—in real time—to predict and eliminate the effects
of the active sensor’s physics. By calculating the residual between
the expected output and the measured output, PyCRA can still de-
tect the existence of an attack even if the sensor’s dynamics are
slower than those of the attacker.
3.4

χ2 PyCRA Attack Detector

If we obtain an accurate model of the sensor’s actuator dynam-
ics, then we can remove its effects from the measured response,
ensuring that any residual energy measured while u(t) = 0 belongs
to an external source such as an attacker.
3.4.1 Obtaining the Sensor Model
To compensate for the actuator dynamics, we ﬁrst need to ac-
quire an accurate model that captures the underlying physics of the
active sensor. Below we model the active sensor using the generic
nonlinear state update of the form:

y(t) = h(x(t)) + v(t)

x(t + 1) = f (x(t),u(t)) + w(t)

(2)
(3)
where x(t) ∈ Rn is the active sensor state at time t ∈ N0 (e.g., the
electrical current and voltages inside the sensor at time t), u(t) ∈ R
is the modulation input to the sensor, the function f : Rn × R → Rn

ActuatorActive SensorSensorMeasured EntityActuatorActive SensorSensorMeasured EntityActuatorActive SensorSensorMeasured Entity1008Figure 5: Sensor actuator output (top) with confusion and silence
phases and the corresponding raw signal (bottom) with an attack.

is a model describing how the physical quantities of the sensor
evolve over time, and the function h : Rn → R models the sensor
measurement physics. Such models can be either derived from ﬁrst
principles [9, 2, 10] or through experimental studies [23, 20]. Ad-
ditionally, these models are used to design the sensors themselves
and are typically known to the sensor manufacturers. Finally, since
no mathematical model can capture the true system behavior ex-
actly, the term w(t) ∈ Rn represents the mismatch between the true
sensor and the mathematical model while v(t) models the noise in
the sensor measurements.
3.4.2
χ2 Detector
We use the dynamical model of the sensor (Equations (2) and (3))
in designing a χ2 detector to detect the existence of an attacker. χ2
detectors appear in the literature of automatic control, where they
are used in designing fault tolerant systems [26, 28, 25, 38]. The
χ2 detector works as follows:
[Step 1] Select random times, tchallenge and tcon f usion.
[Step 2] Issue a physical challenge by entering the confusion phase
at time tchallenge and then enter the silent phase at time tchallenge +
tcon f usion.
[Step 3] Residual Calculation: Here we use Equations (2) and (3)
to calculate an estimate for the current sensor state ˆx(t) and the pre-
dicted output ˆy(t) = h( ˆx(t)). This operation is initiated at tchallenge +
tcon f usion when u(t) transitions to 0—the actuator “silence time”—
and terminates once u(t) transitions back to one, signaling the end
of actuator “silence.”

The model represented by Equations (2) and (3) describes the
output of the sensor when the attack is equal to zero. Therefore,
the residual1 between the measured output and the predicted out-
put, z(t) = y(t)− ˆy(t), corresponds to both the attack signal as well
as the environmental dynamics during the time interval before u(t)
drops to 0. For each segment of length T where u(t) = 0, we cal-
culate the norm of the residual z(t) as:

g(t) =

1
T

t

∑

τ=t−T +1

z2(τ)

(4)

[Step 4] Detection Alarm: Once calculated, we compare the χ2
residual g(t) against a pre-computed alarm threshold α. This alarm
threshold is chosen based on the noise v(t). Whenever the condition
g(t) > α is satisﬁed, the sensor declares that an attacker has been
detected.

4. THEORETICAL GUARANTEES

As discussed before, PyCRA is based on the concept that physics
impose fundamental and immutable constraints on how quickly an
attacker can detect changes in the physical-challenge and how fast
1The name of the Chi-squared (χ2) detector follows from the fact
that, in the case of no attack, the residual z(t) is a Gaussian ran-
dom variable, and hence its square g(t) is a χ2 distributed random
variable.

he can react to these challenges. In this section, we show a theo-
retical result that allows PyCRA to increase the probability of an
attacker failing to detect the changes in the physical-challenge by
correctly designing the confusing phase (discussed in Section 3.2)
and hence increase the probability of detecting the attack.

THEOREM 1. Consider an attacker attempting to detect changes
in a physical challenge signal with mis-detection probability α. For
any strategy the attacker chooses, and because of the SNR exists at
any sensor, the probability of the attacker having a constant detec-
tion delay τ > 0 is bounded away from zero, i.e., with high proba-
bility the attacker will detect a change and turn off his signal only
after time T after the beginning of the confusion period. In addi-
tion, decreasing the amplitude of the signal emitted by the active
sensor during the confusion period by a factor of β > 1 increases
the delay τ by a factor of β 2.

PROOF SKETCH. We base the proof on the results reported in
[36] on change point detection which measure fundamental limits
on checking changes in noisy signal. In the change point detection
setting, the false alarm probability is analogous to the event where
the attacker switches off his signal before the beginning of the silent
period. Delay in [36] is deﬁned as the time that elapses from the
change point until the change is detected. When α (cid:28) 1, the false
alarm probability induces a probability which is proportional to α
for the event that change is detected within a time interval shorter
than T (a constant independent of α).

Decreasing the amplitude of the signal actuated by the active sen-
sor during the confusion period by a factor of β leads to a decrease
in SNR by a factor of β 2. Based on this relation, the attacker has to
increase the delay by a factor of β 2 in order to maintain false alarm
probability α.

5. CASE STUDY (1): DETECTING ACTIVE
SPOOFING ATTACKS FOR MAGNETIC
ENCODERS

Magnetic encoders are active sensors used in a wide array of
industrial, robotics, aerospace, and automotive applications. The
goal of an encoder is to measure the angular velocity or position of
a gear or wheel in order to provide feedback to a motor controller.
The operation of these systems depends heavily on the accuracy
and timeliness of the individual encoders. This section describes
the basic operation of magnetic encoders in particular and the types
of attacks that can be mounted against them as well as how PyCRA
can be used to provide security for them.
5.1 Magnetic Encoders

Magnetic encoders rely on magnetic variations to measure the
angular velocity of a gear or wheel and are often designed to handle
dust, mud, rain, and extreme temperatures without failing. The goal
of each encoder is to provide a signal whose frequency corresponds
to the speed of a gear. These signals are conditioned and passed to
a motor controller unit which detects if any corrective actions need
to be taken.

Typical magnetic encoders operate by generating a magnetic ﬁeld
in the presence of a rotating ferromagnetic tone ring or tone wheel.
This ring has a number of teeth on its edge so that the reﬂected mag-
netic wave as observed by the encoder varies over time as a (noisy)
sinusoidal wave. By measuring the frequency of this reﬂected sig-
nal over time, each sensor and consequently the motor controller is
able to infer the angular velocity of any given gear, wheel, or motor
as illustrated in Figure 6.

Attacks on magnetic encoders have been studied in [33] in the
context of Anti-lock Braking Systems in automotive vehicles. Both

1009Figure 6: Flow diagram for a typical magnetic encoder: The signal
begins as a reﬂected magnetic wave from a gear. This signal is
captured by a pick-up coil or Hall Effect sensor, conditioned into a
clean square wave, and ﬁnally translated into an angular velocity.

simple spooﬁng [T2] and advanced spooﬁng [T3] attacks are shown
to inﬂuence the vehicle stability. In this case study, we show how
PyCRA can detect the existence of such attacks.
5.2 The PyCRA-secured Magnetic Encoder

Physically, the proposed secure magnetic encoder sensor con-
sists of two main parts: (i) the front-end containing the actuator
and pickup coils responsible for both probing the rotating tone ring
and measuring the response, and (ii) the processing backend. Fig-
ure 7 shows the front-end of the sensor used in our evaluation. The
actuator coil depicted is much larger than would be required in a
commercial product, because it consists of a magnetic core and a
hand-wound high-gauge wire. The following is an overview of the
main blocks of the sensor.
5.2.1 Actuator Coil
The main component required for the secure sensor is the actu-
ator coil. In this work, we use an insulated copper wire wrapped
around a ferromagnetic core and driven using a power ampliﬁer.
5.2.2 Pickup and Filtering
The pickup (measurement) coil is wrapped around the same fer-
romagnetic core used for the actuator coil. In order to reduce the
effect of noise from other EMI sources within the vehicle body,
the output of the pickup coil is connected to a differential ampliﬁer
with high common-mode rejection. The output of this differential
ampliﬁer is connected to the digital processing backend.

Another security concern of the magnetic encoder is the wires
connecting the coils to the digital backend. These wires pose a po-
tential vulnerability, as an attacker can cut them and connect his at-
tack module directly. However, such attacks are already accounted
for in many systems as addressed in Assumption A1.
5.2.3 Processing Elements
The secure sensor requires enough processing power to perform
the necessary computations in real-time. The DSP calculations take
place on a high power ARM Cortex (M4 STM32F407) processor,
which has ample ﬂoating point support. We do not consider any
power consumption issues in our design.
5.3 Obtaining the Sensor Model

The dynamics of the sensor (including the actuator, high gain
current ampliﬁer, sensors, and the signal conditioning circuit) are
identiﬁed using standard system identiﬁcation methods [23]. That
is, we applied four different pseudo random binary sequences (PRBS)
to the system, collected the output, and then applied subspace sys-
tem identiﬁcation techniques in order to build models of increasing
complexity [23]. Finally we used both whiteness tests and correla-
tion tests to assess the quality of the obtained model [20]. In order
to validate the model, we generated a random sequence similar to
those used in the real implementation of the sensor. We fed the
same input to both the sensor and the model and recorded the error.

Figure 7: PyCRA encoder actuator coil, sensor, and gear setup.

Experiments show that the model is reasonably accurate with an
error in the range of 5 milli-Volts.
5.4 Testbed

In order to test the PyCRA-secured magnetic encoder, we con-
structed a testbed consisting of the proposed secure sensor attached
to a Mazda Rx7 tone ring. The tone ring is attached to a DC mo-
tor which simulates a rotating wheel. An additional coil is added
to simulate the effect of an attacker. The attacker coil is also con-
trolled by a high gain ampliﬁer controlled through a real-time xPC
Target system connected to MATLAB.

A Mazda RX7 magnetic encoder sensor is also attached to the
same tone ring in order to provide ground truth. The output of this
sensor is connected to a MAX9926U evaluation kit which includes
an interface capable of converting the raw sinusoidal wave into the
encoded square wave as shown in Figure 6. The output of the pro-
posed secure sensor as well as the output of the MAX9926U is
monitored by the same real-time xPC Target for comparison.
5.5 Calibration against natural variations

Sensor modeling is usually done in a controlled environment.
However, once the sensor is placed in a testbed, multiple natural
variations, mechanical asymmetries, and other environmental fac-
tors degrade the accuracy of such models. To account for these
variations, we use a simple learning mechanism to estimate the
noise level in the measurements and the deviation between the ex-
pected outputs (as per the model) and the actual outputs. Once
these parameters are learned, we can set the alarm threshold ac-
cordingly. Results can be further improved by considering online
identiﬁcation-and-calibration of the sensor model.
5.6 Attack Detection for Magnetic Encoders
We begin with a simple spooﬁng attack [T2] in which an attacker
injects a sinusoidal wave of varying frequency. Spooﬁng attacks of
this nature attempt to overpower the true frequency of the system
and force the sensor to track the false frequency (mirroring the sim-
plistic spooﬁng attack in [13]). In this experiment the original tone
ring frequency is ﬁxed at 71 Hz, and the frequency of the attacking
coil increases linearly from 60 Hz to just over 400 Hz.

As per our attacker model in Section 2, we assume that the at-
tacker attempts to conceal his or her presence (Adversarial goal
[G1]). This means that the adversary will be able to detect when
the actuator coil is turned off and will, after some time τattack, tem-
porarily halt the attack.

The stealthiness of the attacker necessitates that the PyCRA de-
tection scheme have high accuracy even when the attacker is quick

GearEncoderMotorControllerActuatorCoilPickupCoilGear1010(a)

(b)

Figure 8: Results from 30 experiments showing (a) the accuracy
of attack detection for a simple spooﬁng attack with sampling rate
Fs = 10 kHz and a range of τattack, and (b) attack detection accuracy
as a function of τattack for several sampling rates, Fs.

to react. We evaluated the PyCRA detection scheme across a range
of τattack values, χ2 detection thresholds (α), and sampling fre-
quencies (Fs). Note that in order to simulate an attacker with 0
ms physical delays (which is physically impossible), we gave the
attacker access to the random signal generated by PyCRA so that
the attacker can start shutting down his actuators before PyCRA
generates the physical challenge.

In total, we conducted over 30 experiments on our experimental
testbed to validate the robustness of the proposed security scheme.
The resulting accuracy with Fs = 10 kHz is depicted by the ROC2
curves in Figure 8a for a range of α. From this ﬁgure it is clear that
between τattack = 500 and 700 µs is all that is necessary for PyCRA
to accurately distinguish attacked signals from normal signals, if
α is chosen appropriately. With α set to a predetermined value,
we can vary Fs as shown in Figure 8b3. These results show that
increasing Fs from 10 kHz to 30 kHz reduces required time for
detection to between τattack = 100 and 200 µs.

Repeating these experiments for the advanced spooﬁng attack
[T3] yields similar results. In fact, there is no fundamental differ-
ence between the two in terms of attack detection; this is governed
by the dynamics of the attacker’s actuator rather than the nature of
the attack itself.

It is important to evaluate this detection accuracy (which is our
security guarantee) in terms of the physical delay property τattack of
the attacker model. In practice, the state-of-the-art in low-dimension,
high Q-factor hardware that provide enough power to carry out a
spooﬁng attack will have τ (cid:29) 200µs4. From Figure 8b it is appar-
ent that PyCRA has good performance for this range of practical
physical delays.

Moreover, the results we have shown thus far use a relatively low
sampling frequency (high end micro controllers can operate in the
range of 200 kHz). As illustrated by Figure 8b, higher sampling
2A Receiver Operating Characteristic (ROC) is a visual aid for
evaluating the accuracy of binary classiﬁers in terms of both true
and false positive rates.
3The F1 score is a statistical measure of a binary classiﬁer that mea-
sures the classiﬁer accuracy in terms of precision and recall.
4These values were obtained by surveying a range of state-of-the-
art, commercially available components.

(a)

(b)

Figure 9: The schematic used in the RFID eavesdropping case
study (a) and corresponding hardware setup (b). The setup con-
tains two low frequency antennas (one for the RFID reader and one
for the eavesdropper) along with a Proxmark3 board running the
PyCRA detection algorithm. The analog signal is also captured by
a digital oscilloscope for visualization

rates result in reduced attack detection times. However, using low
sampling frequencies in our case study serves to illustrate the efﬁ-
ciency of the proposed detection mechanism.

6. CASE STUDY (2): DETECTION OF PAS-

SIVE EAVESDROPPING ON RFID

In this section, we discuss detection of passive eavesdropping
attacks on active sensors. In this scenario, an adversary listens or
records the same physical signals captured by the sensor. Indeed
this type of attack satisﬁes assumptions A1–A3 described in Sec-
tion 3 and hence it will be useful to extend PyCRA to such cases.
6.1 Passive Eavesdropping on RFID

In this section, we use radio-frequency identiﬁcation (RFID) as
an example where successful passive attacks can have severe con-
sequences. RFID systems are commonly used to control access
to physical places and to track the location of certain objects. An
RFID system consists of two parts: a reader and a tag. The RFID
reader continuously sends a magnetic signal that probes for exist-
ing tags in the near proximity. Once a tag enters the proximity of
the reader, the tag starts to send its “unique” identiﬁer to the reader
by modulating the magnetic probe signal.

RFID tags can be classiﬁed as either passive or active based on
the source of their energy. While passive tags rely on the energy
transmitted by an RFID reader in order to power their electron-
ics, active tags have their own power supplies. As a result, active
tags can be equipped with computational platforms that run crypto-
graphic and security protocols to mitigate cloning attacks [5]. On
the other hand, passive tags do not enjoy these luxuries and there-
fore are more prone to cloning attacks.

Cloning of passive RFID tags can take place in one of two forms.
In the ﬁrst, the attacker uses a mobile RFID reader and attempts to
place it near the RFID tag. The tag innocently responds to the com-
munication issued by the adversarial reader and sends its unique
identiﬁer. The other form of attack carried out against RFID sys-
tems is to eavesdrop on the communication between the tag and
a legitimate reader. RFID protective shields and blockers [27, 15]
are commonly used as countermeasure to the ﬁrst form of cloning
attacks discussed above. Unfortunately, these shields are of no use

00.20.40.60.8100.20.40.60.81False Positive RateTrue Positive Rate  0.7 ms0.5 ms0.2 ms0 ms00.10.20.30.40.50.60.70.80.910.20.40.60.81Attacker Physical Delay,  τattack (ms)Detection F1 Score  Fs = 30 kHzFs = 20 kHzFs = 10 kHzRFID ReaderSni(cid:31)erProxmark3OscilloscopeTag1011(a)

(b)

(c)

Figure 10: Results of applying PyCRA to detect the existence of an eavesdropper in the proximity of an RFID reader. (a) Results of using
standard 125KHz signal for detection. (b) Results of using PyCRA when only an RFID tag is present in the proximity of the PyCRA-enabled
reader, and (c) Results of using PyCRA in detecting eavesdropping when both an RFID tag and an eavesdropper antenna are present in the
proximity of the PyCRA-enabled reader. Top ﬁgure shows the response to the physical challenges when no eavesdropper is placed in the
proximity of the RFID reader. The middle ﬁgure shows the response to the physical challenges when (a) an eavesdropper antenna (b) passive
tag only (c) passive tag + eavesdropper antenna are placed in the proximity of the reader. Finally, the bottom ﬁgure shows the value of the
residuals calculated by PyCRA along with the alarm threshold.

against the second type of attacks, because the user is obliged to re-
move the protective shield before using the tag with the legitimate
RFID reader, at which time an adversary can successfully eaves-
drop.

To carry out an eavesdropping attack, a snifﬁng device must be
placed in close proximity to the RFID reader so that it can measure
the electromagnetic waves transmitted by the reader and reﬂected
by the tag. In the following results, we show how PyCRA is able to
detect the existence of such an attack, allowing the reader to disable
communication with the tag before revealing private information.
6.2 Using PyCRA to Detect Eavesdroppers

Recall from the physics of electromagnetic waves that antennas
placed within close proximity will always affect each other’s elec-
trical signals to some degree. This is a fundamental law in physics
known as magnetic coupling [2] and is used in the design of RFID.
Note that, similar to the physical delays, the magnetic coupling as-
sumption is a fundamental limitation that the attacker cannot over-
come. Hence, we can use the PyCRA detection algorithm outlined
in Section 3 by computing the residual between the model (which
assumes magnetic coupling only with the RFID tag) and the sensor
output which suffers from magnetic coupling with the eavesdrop-
ping antenna. This is shown in the experimental results in the next
subsection.
6.3 Hardware Setup and Real-time Results

Figure 9 shows the hardware setup used to carry out this case-
study. In this setup, two identical low frequency RFID antennas are
used. The ﬁrst RFID antenna is used as the legitimate RFID reader
while the second is used to eavesdrop. We built a PyCRA-enabled
RFID reader on top of the open source RFID Proxmark3 board,
adding random modulation to the probing signal and constructing
the appropriate models as outlined in Section 3.

Figure 10a (top) shows the received electromagnetic wave of an
RFID reader operating in the classical operational mode. In this
mode, the RFID reader generates the standard 125KHz sinusoidal

wave that is used to communicate with the RFID tag. Figure 10a
(middle) shows the resulting electromagnetic wave when an eaves-
dropper uses an identical antenna to listen. In this case it is hard
to distinguish between the two waves and hence hard to detect the
existence of an eavesdropper. This is better illustrated by the resid-
ual between the two waves as shown by the residual in Figure 10a
(bottom).

On the other hand, Figures 10b and 10c show the result of the
same case study when PyCRA is used with and without an eaves-
dropper present, respectively. In this mode, the PyCRA algorithm
occasionally halts the normal operation of the RFID reader and
switches to detection mode. In this mode, PyCRA selects random-
ized periods of time to issue the physical challenges by switching
the RFID antenna from on to off and from off to on.

In order to select an appropriate alarm threshold, we ﬁrst study
the effect of the magnetic coupling between the reader and the tag
in the absence of an eavesdropper. This is shown in Figure 10b
where the alarm threshold is chosen such that no alarm is triggered
when the effect of the magnetic coupling—the residual between the
“no tag” response (top) and the response with a tag (middle)—is
within the acceptable range. This acceptable residual range allows
for coupling induced by the tag only. Any increase on top of this al-
lowable threshold is then attributed to the existence of an excessive
magnetic coupling due to an eavesdropper.

Figure 10c (middle) shows the response to the same set of phys-
ical challenges when the attacker places an eavesdropping antenna
in the proximity of the RFID reader while the tag is also present.
Thanks to the physical challenge produced by PyCRA, the mag-
netic coupling produced by the eavesdropper antenna is now easily
detected. This can be shown in Figure 10c (bottom) which shows
the residuals between the expected output and the measured signal
exceeding the alarm threshold.

We recorded over 1 hour of RFID measurements with varying
distances of the malicious eavesdropping antenna. Of those exper-
iments where the attacker was close enough to observe the RFID
communication, PyCRA successfully detected the existence of an

00.20.40.60.81·10−40510Time[s]Voltage[volt]00.20.40.60.81·10−40510Time[s]Voltage[volt]00.20.40.60.81·10−40246AlarmthresholdTime[s]Voltage[volt]Normalresponse(noattack)ResponseunderattackResidual=|output-expected|00.20.40.60.81·10−40510Time[s]Voltage[volt]00.20.40.60.81·10−40510Time[s]Voltage[volt]00.20.40.60.81·10−40246AlarmthresholdTime[s]Voltage[volt]Normalresponse(noattack)ResponseunderattackResidual=|output-expected|00.20.40.60.81·10−40510Time[s]Voltage[volt]00.20.40.60.81·10−40510Time[s]Voltage[volt]00.20.40.60.81·10−40246AlarmthresholdTime[s]Voltage[volt]Normalresponse(noattack)ResponseunderattackResidual=|output-expected|1012attacker with 100% accuracy. Intuitively, if the attacker success-
fully measures the RFID signal, he has consequently removed enough
energy from the channel to trigger an alarm.

7. CASE STUDY (3): EXTENDING PYCRA

FOR ATTACK RESILIENCE

In some scenarios it is possible to extend the PyCRA authentica-
tion system to provide attack resilience as well. Here the goal is to
design a sensor whose estimate of a physical phenomenon remains
robust in the face of a range of physical attacks. One way to mit-
igate the effects of an attack is by characterizing the attack signal
during the confusion phase, when the attacking signal remains de-
tectable for τattack. This characterization depends on the properties
of the sensor and signals in question, but it is in general made eas-
ier if the attack signal is sparse in some domain. One such attack
resilience scheme for magnetic encoders is described below.

The signal reﬂected by a magnetic encoder’s tone ring is a si-
nusoidal wave dominated by a single frequency component. If we
consider the frequency domain representation of the measured sig-
nal over a window, we expect to see the energy concentrated at
one frequency corresponding to that of the tone ring. However, in
the existence of an attacker and using Fourier analysis, we can rea-
sonably expect to observe energy concentrated at multiple frequen-
cies. The sensor must be able to distinguish between the correct
frequency and those of the attacker. If the attack signal itself is rea-
sonably sparse in some domain—e.g., the Fourier domain in this
example—we may obtain an accurate model of that signal over a
short time period, aided by the confusion period and delay τattack.
For example, we can use our earlier χ2 estimator as an attack indi-
cator for any given frequency component using the recursive Dis-
crete Fourier Transform (DFT) with the following form:
Yk(t + 1) = e( j2πk/N)Yk(t) + e(− j2πk(N−1)/N)y(t)

− e( j2πk/N)y(t − N)

(5)
where Yk(t) ∈ CN is the kth component of the N-point DFT of the
sensor output y(t) at time t ∈ N0. The χ2 detector uses the sensor
(in the case of no attack) denoted(cid:98)Yk(t). We deﬁne the χ2 residual
model along with (5) to predict the natural response of the tone gear
in the frequency domain as Zk(t) = |Yk(t)|−|(cid:98)Yk(t)|, allowing us to

deﬁne thresholds to again indicate when an attack is detected and,
now, the nature of that attack in terms of its its frequency compo-
nents.

We implemented the scheme described above and again tested
against a number of spooﬁng attacks in more than 90 experiments.
Figure 11a illustrates the result of these experiments for a swept
frequency attack, where the malicious (red) signal is accurately de-
tected and therefore easily subtracted from the measured signal,
providing a more robust estimate of the signal of interest. Figure
11b shows the accuracy of this prediction in terms of true and false
positive rates as a function of τattack. Here we demonstrate accu-
rate attack characterization and mitigation even for τattack delays
as low as 5 ms. In addition, the PyCRA-secured magnetic encoder
remains robust even in the face of an active cancellation spooﬁng
attack, where the attacker attempts to use destructive interference
to destroy the signal of interest. Again, during the confusion pe-
riod we can actively characterize the attack signal and subtract its
effects.

8. DISCUSSION

We have shown that PyCRA is able to detect and possibly mit-
igate different attacks on physical signals. In this section, we pro-

(a)

(b)

Figure 11: A visual tour of the PyCRA resilience scheme against
the swept frequency attack (a) and attack prediction accuracies with
a range of τattack values.

vide some distilled discussion thrusts by comparing PyCRA to the
existing literature, revisiting the connection between physics and
security guarantees and the effect of using PyCRA on the overall
system performance.

8.1 Comparison With Literature

We can classify previous work on secure sensing based on the
redundancy needed to provide security. For example the work de-
scribed in [7, 30, 35] provides security through network and sen-
sor redundancy. Additional research has explored fusing redun-
dant measurements to provide secure localization [32, 21] and se-
cure time synchronization [24]. The work presented in this paper
falls within a second category in which no redundancy is needed
to provide security. Indeed, providing security using single mea-
surements is complementary to the security guarantees provided
by redundancy based techniques. We can further classify this cate-
gory into two subcategories depending on the dependency of cryp-
tographic constructs. As described in previous sections, crypto-
graphic constructs fail to counteract active attacks taking place in
the analog domain—a gap for which PyCRA has been designed and
implemented. While PyCRA is novel in bringing security against
active attacks on sensory data in the analog domain, there exist
similar ideas in the literature for other types of active attacks. For
example, the work reported in [34] also exploits physical proper-
ties in order to provide secure localization mechanism for wireless
sensor networks without relying on redundancy.

Numerous results in the literature have described and implemented
counter-measures for passive attacks (e.g, eavesdropping), espe-
cially in the RFID literature. For example, in the work reported
in [37, 29] the eavesdropper reveals itself through power leakage
(e.g., oscillators), provided such power measurements can be ob-
tained. In contrast, PyCRA does not assume the existence of power
consumption side-channels. Rather, the experiments shown in Fig-
ure 10 demonstrate an environment with only a passive eavesdrop-

0200400600Raw SignalFrequencies (Hz)Estimated AttackedFrequencies (Hz)6004002000051015202530050100150Time (sec)Reported SensorSpeed (km/h)  Unsecure EstimateSecure PyCRA EstimateTrue SpeedAttackerfrequencyOriginalfrequency00.20.40.60.810.50.60.70.80.911.1False Positive RateTrue Positive Rate  15 ms10 ms5 ms1013ping antenna and no such power leakage. Another example is the
work reported in [11] which considers an active relay attack where
the attacker actively sends information. The detection scheme is
based on detecting the action of sending. As discussed above, our
system works for completely passive attacks. However, PyCRA is
not designed to protect against a passive eavesdropper that mea-
sures backscattered waves as discussed in [12] (compared to mag-
netic coupling eavesdropping). Typically RFID range is small and
we make the case that PyCRA creates security for short-range op-
eration. Indeed, some of the ideas in literature can serve to comple-
ment the contributions in PyCRA.
8.2 Physics, Randomness, & Security

The underlying ideas behind PyCRA utilize accurate mathemati-
cal models that capture the physics and dynamics of active sensors.
With these models in hand, PyCRA is able to isolate the response of
the attacker from the response of the environment when challenged
by the proposed secure sensor. The success of the system presented
in this paper lends credence to the notion of physical challenge-
response authentication as a whole. Section 1 made brief mention
of several additional sensing modalities where PyCRA can provide
improved security. In fact, adaptation of the methods described in
this work to these sensors is not difﬁcult—one need only revisit the
physical models involved in order to derive a method of probing the
physical environment and measuring the environmental response.
The results presented in the previous sections demonstrate the
key strengths of PyCRA—namely that it uses fundamental proper-
ties of physics (physical delays and noise) along with mathemat-
ical models to provided the following security aids (i) timely and
accurate detection of external, potentially malicious sources of sig-
nal interference, (ii) resilience via accurate estimation of malicious
spectra, and (iii) accurate detection of passive eavesdropping at-
tacks. The success of these security mechanisms are bolstered by
physical limitations such as delays (τattack) and change point detec-
tion, for which we have derived theoretical guarantees.

Another major factor in the security provided by PyCRA is the
amount of randomness used in generating the physical challenges.
The relationship between randomness and security guarantees is
a classical relationship that appears in most cryptographic security
protocols. However, a fundamental difference in this scheme is that
PyCRA relies only on private randomness compared to shared ran-
domness in classical cryptographic authentication schemes. This is
a consequence of the “passivity” property of the measured entity
exploited by PyCRA. This in turn eliminates the classical prob-
lem of random data distribution (e.g., key distribution) and thus
increases the security provided by the proposed system.
8.3 Overcoming Negative Effects of PyCRA

A PyCRA-secured sensor will occasionally cease measurement
of the physical phenomena it is measuring. This can negatively
affect the overall sensor performance. However, measuring any
physical phenomenon requires a sampling rate dictated by its band-
width—e.g., magnetic encoders require 50Hz sampling-rate—while
electronics can operate much faster (e.g., 10kHz in our experi-
ments), and we exploit this by performing authentication using
oversampling, thereby performing multiple authentications within
a single physics-dictated sampling-period. Once the sensor is au-
thenticated, we can select any of the authenticated measurements
collected within the sampling-period and provide this as the ‘se-
cure’ sensor measurement without affecting performance.
If the
sensor detects an attack, then attack-resilient estimation/computa-
tion (shown in Section 7) needs to be carried out. Again, these
computations operate at a higher sampling rate. Higher sampling

rate comes at the cost of increased power consumption, but this is
perhaps a reasonable price to pay for security.

9. CONCLUSION

We have presented PyCRA, a physical challenge-response au-
thentication method for active sensors. The driving concept be-
hind PyCRA is that, through random physical stimulation and sub-
sequent behavior analyses, we are able to determine whether or
not a sensor is under attack and, in some cases, remain resilient
to attacks. This work further describes ways in which the Py-
CRA scheme can be applied to (1) passive eavesdropping attacks,
(2) simple spooﬁng attacks, and (3) more advanced spooﬁng at-
tacks. We have demonstrated the effectiveness of PyCRA for more
than 90 experiments on physical hardware focusing on three case
studies: magnetic encoder attack detection, magnetic encoder at-
tack resilience, and RFID eavesdropping detection. Our results
from these case studies indicate that physical challenge-response
authentication can accurately and reliably detect and mitigate ma-
licious attacks at the analog sensor level. Finally, we believe the
results discussed in this work lend credence to the notion of physi-
cal challenge-response systems in general, advocating its adoption
for active sensors in general where secure operation is a critical
component. More broadly, PyCRA offers security to a wide array
of systems (not just sensors) where inputs are mapped to outputs
by well-understood models.

Acknowledgments
This material is based upon work supported by the NSF under
award CNS-1136174. The U.S. Government is authorized to re-
produce and distribute reprints for Governmental purposes notwith-
standing any copyright notation thereon. The views and conclu-
sions contained herein are those of the authors and should not be
interpreted as necessarily representing the ofﬁcial policies or en-
dorsements, either expressed or implied, of NSF or the U.S. Gov-
ernment.

10. REFERENCES
[1] R. Anderson and M. Kuhn. Tamper resistance: A cautionary
note. In Proceedings of the 2Nd Conference on Proceedings
of the Second USENIX Workshop on Electronic Commerce -
Volume 2, WOEC’96, pages 1–11, Berkeley, CA, USA,
1996. USENIX Association.

[2] J. Brauer. Magnetic Actuators and Sensors. Wiley, 2006.
[3] A. A. Cárdenas, S. Amin, and S. Sastry. Research challenges
for the security of control systems. In Proceedings of the 3rd
conference on Hot topics in security, HOTSEC’08, pages
6:1–6:6, Berkeley, CA, USA, 2008. USENIX Association.

[4] G. Dán and H. Sandberg. Stealth attacks and protection

schemes for state estimators in power systems. In Smart Grid
Communications (SmartGridComm), 2010 First IEEE
International Conference on, pages 214–219, 2010.

[5] T. Dimitriou. A lightweight rﬁd protocol to protect against
traceability and cloning attacks. In Security and Privacy for
Emerging Areas in Communications Networks, 2005.
SecureComm 2005. First International Conference on, pages
59–66, Sept 2005.

[6] F. Dorﬂer, F. Pasqualetti, and F. Bullo. Distributed detection

of cyber-physical attacks in power networks: A waveform
relaxation approach. In allerton, pages 1486–1491, Allerton,
IL, USA, Sept. 2011.

1014[7] H. Fawzi, P. Tabuada, and S. Diggavi. Secure estimation and
control for cyber-physical systems under adversarial attacks.
IEEE Transactions on Automatic Control, 59(6):1454–1467,
June 2014.

[8] Ford Motor Company. Fault detection and isolation in

automotive wiring harness including dedicated test line,
Nov. 23 1993. US Patent 5,264,796.

[9] J. Fraden. Handbook of Modern Sensors: Physics, Designs,

and Applications (Handbook of Modern Sensors).
SpringerVerlag, 2003.

Pearson Education, 1998.

[10] C. Grimes, E. Dickey, and M. Pishko. Encyclopedia of

Sensors. American Scientiﬁc Publishers, 2006.

[11] S.-B. Hamida, P.-H. Thevenon, J.-B. Pierrot, O. Savry, and

C. Castelluccia. Detecting relay attacks in rﬁd systems using
physical layer characteristics. In Wireless and Mobile
Networking Conference (WMNC), 2013 6th Joint IFIP,
pages 1–8, April 2013.

[12] G. P. Hancke. Practical eavesdropping and skimming attacks

on high-frequency rﬁd tokens. J. Comput. Secur.,
19(2):259–288, Apr. 2011.

[13] T. Humphreys, B. Ledvina, and M. Psiaki. Assessing the
spooﬁng threat: Development of a portable gps civilian
spoofer. In Technical Report. Cornel University, 2008.

[14] V. M. Igure, S. A. Laughter, and R. D. Williams. Security

issues in SCADA networks. Computers and Security,
25(7):498 – 506, 2006.

[15] A. Juels. Rﬁd security and privacy: a research survey.
Selected Areas in Communications, IEEE Journal on,
24(2):381–394, Feb 2006.

[16] T. Kim and H. Poor. Strategic protection against data

injection attacks on power grids. Smart Grid, IEEE
Transactions on, 2(2):326–333, 2011.

[17] O. Kömmerling and M. G. Kuhn. Design principles for

tamper-resistant smartcard processors. In Proceedings of the
USENIX Workshop on Smartcard Technology on USENIX
Workshop on Smartcard Technology, WOST’99, pages 2–2,
Berkeley, CA, USA, 1999. USENIX Association.

[18] O. Kosut, L. Jia, R. Thomas, and L. Tong. Malicious data

attacks on the smart grid. Smart Grid, IEEE Transactions on,
2(4):645–658, 2011.

[19] D. Kune, J. Backes, S. Clark, D. Kramer, M. Reynolds,

K. Fu, Y. Kim, and W. Xu. Ghost talk: Mitigating emi signal
injection attacks against analog sensors. In Security and
Privacy (SP), 2013 IEEE Symposium on, pages 145–159,
May 2013.

[20] I. D. Landaue, R. Lozano, M. M’Saad, and A. Karimi.

Adaptive Control: Algorithms, Analysis and Applications.
Communications and Control Engineering. Springer, June
2011.

[21] D. Liu, P. Ning, and W. Du. Attack-resistant location

estimation in sensor networks. In Information Processing in
Sensor Networks, 2005. IPSN 2005. Fourth International
Symposium on, pages 99–106, April 2005.

[22] Y. Liu, P. Ning, and M. K. Reiter. False data injection attacks

against state estimation in electric power grids. In
Proceedings of the 16th ACM conference on Computer and
communications security, CCS ’09, pages 21–32, New York,
NY, USA, 2009. ACM.

[23] L. Ljung. System Identiﬁcation: Theory for the User.

[24] M. Manzo, T. Roosta, and S. Sastry. Time synchronization
attacks in sensor networks. In Proceedings of the 3rd ACM
Workshop on Security of Ad Hoc and Sensor Networks,
SASN ’05, pages 107–116, New York, NY, USA, 2005.
ACM.

[25] R. Mehra and J. Peschon. An innovations approach to fault

detection and diagnosis in dynamic systems. Automatica,
7(5):637 – 640, 1971.

[26] F. Miao, M. Pajic, and G. J. Pappas. Stochastic game
approach for replay attack detection. In Decision and
Control (CDC), 2013 IEEE 52nd Annual Conference on,
pages 1854–1859, Dec 2013.

[27] A. Mitrokotsa, M. Rieback, and A. Tanenbaum. Classifying

rﬁd attacks and defenses. Information Systems Frontiers,
12(5):491–505, 2010.

[28] Y. Mo and B. Sinopoli. Secure control against replay attacks.
In Communication, Control, and Computing, 2009. Allerton
2009. 47th Annual Allerton Conference on, pages 911–918,
Sept 2009.

[29] A. Mukherjee and A. Swindlehurst. Detecting passive

eavesdroppers in the mimo wiretap channel. In Acoustics,
Speech and Signal Processing (ICASSP), 2012 IEEE
International Conference on, pages 2809–2812, March 2012.

[30] F. Pasqualetti, F. Dorﬂer, and F. Bullo. Attack detection and
identiﬁcation in cyber-physical systems. Automatic Control,
IEEE Transactions on, 58(11):2715–2729, Nov 2013.
[31] S. Ravi, A. Raghunathan, and S. Chakradhar. Tamper

resistance mechanisms for secure embedded systems. In
VLSI Design, 2004. Proceedings. 17th International
Conference on, pages 605–611, 2004.

[32] N. Sastry, U. Shankar, and D. Wagner. Secure veriﬁcation of
location claims. In Proceedings of the 2Nd ACM Workshop
on Wireless Security, WiSe ’03, pages 1–10, New York, NY,
USA, 2003. ACM.

[33] Y. Shoukry, P. D. Martin, P. Tabuada, and M. B. Srivastava.
Non-invasive spooﬁng attacks for anti-lock braking systems.
In Workshop on Cryptographic Hardware and Embedded
Systems 2013, G. Bertoni and J.-S. Coron (Eds.): CHES
2013, LNCS 8086, pages 55–72. International Association
for Cryptologic Research, 2013.

[34] D. Singelee and B. Preneel. Location veriﬁcation using

secure distance bounding protocols. In Mobile Adhoc and
Sensor Systems Conference, 2005. IEEE International
Conference on, pages 7 pp.–840, Nov 2005.

[35] K. Sou, H. Sandberg, and K. Johansson. On the exact

solution to a smart grid cyber-security analysis problem.
Smart Grid, IEEE Transactions on, 4(2):856–865, 2013.

[36] A. G. Tartakovsky and V. V. Veeravalli. General asymptotic

bayesian theory of quickest change detection. Theory
Probab. Appl., 49(3):458 –497, 2005.

[37] B. Wild and K. Ramchandran. Detecting primary receivers

for cognitive radio applications. In New Frontiers in
Dynamic Spectrum Access Networks, 2005. DySPAN 2005.
2005 First IEEE International Symposium on, pages
124–130, Nov 2005.

[38] A. S. Willsky. A survey of design methods for failure

detection in dynamic systems. Automatica, 12(6):601 – 611,
1976.

1015