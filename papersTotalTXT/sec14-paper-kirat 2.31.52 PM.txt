BareCloud: Bare-metal Analysis-based  

Evasive Malware Detection

Dhilung Kirat, Giovanni Vigna, and Christopher Kruegel,  

University of California, Santa Barbara

https://www.usenix.org/conference/usenixsecurity14/technical-sessions/presentation/kirat

This paper is included in the Proceedings of the 23rd USENIX Security Symposium.August 20–22, 2014 • San Diego, CAISBN 978-1-931971-15-7Open access to the Proceedings of  the 23rd USENIX Security Symposium is sponsored by USENIXBareCloud: Bare-metal Analysis-based Evasive Malware Detection

University of California, Santa Barbara

University of California, Santa Barbara

Giovanni Vigna

vigna@cs.ucsb.edu

Dhilung Kirat

dhilung@cs.ucsb.edu

Christopher Kruegel

University of California, Santa Barbara

chris@cs.ucsb.edu

Abstract

1

Introduction

The volume and the sophistication of malware are con-
tinuously increasing and evolving. Automated dynamic
malware analysis is a widely-adopted approach for de-
tecting malicious software. However, many recent mal-
ware samples try to evade detection by identifying the
presence of the analysis environment itself, and refrain-
ing from performing malicious actions. Because of the
sophistication of the techniques used by the malware au-
thors, so far the analysis and detection of evasive mal-
ware has been largely a manual process. One approach to
automatic detection of these evasive malware samples is
to execute the same sample in multiple analysis environ-
ments, and then compare its behaviors, in the assumption
that a deviation in the behavior is evidence of an attempt
to evade one or more analysis systems. For this reason, it
is important to provide a reference system (often called
bare-metal) in which the malware is analyzed without the
use of any detectable component.

In this paper, we present BareCloud, an automated
evasive malware detection system based on bare-metal
dynamic malware analysis. Our bare-metal analysis sys-
tem does not introduce any in-guest monitoring compo-
nent into the malware execution platform. This makes
our approach more transparent and robust against sophis-
ticated evasion techniques. We compare the malware be-
havior observed in the bare-metal system with other pop-
ular malware analysis systems. We introduce a novel ap-
proach of hierarchical similarity-based malware behavior
comparison to analyze the behavior of a sample in the
various analysis systems. Our experiments show that our
approach produces better evasion detection results com-
pared to previous methods. BareCloud was able to au-
tomatically detect 5,835 evasive malware out of 110,005
recent samples.

The malware threat landscape is continuously evolving.
Early detection of these threats is a top priority for en-
terprises, governments, and end users. The widely-
deployed signature-based and static-analysis-based de-
tection approaches can be easily evaded by techniques
commonly seen in the wild, such as obfuscation, poly-
morphism, and encryption. Therefore, dynamic mal-
ware analysis tools have recently become more pop-
ular to automate the analysis and detection of these
threats [1, 14, 35]. These systems execute the suspi-
cious sample in a controlled environment and observe
its behavior to detect malicious intent. While this dy-
namic analysis approach is more effective against com-
mon static analysis evasion techniques, it faces a differ-
ent set of challenges. More speciﬁcally, a malware sam-
ple, when executed, can detect the analysis environment
and refuse to perform any malicious activity, for example
by simply terminating or stalling the execution.

Malware authors have developed several ways to de-
tect the presence of malware analysis systems. The
most common approach is based on the ﬁngerprinting of
the runtime environment of the analysis system. This
includes checking for speciﬁc artifacts, such as some
speciﬁc registry keys, background processes, function
hooks, or IP addresses that are speciﬁc to a known anal-
ysis tool. These artifacts must be known to the mal-
ware authors in advance to develop the corresponding
ﬁngerprinting techniques. Another approach leverages
the fact that most of the analysis systems use emulated
or virtualized environments as their malware execution
platform. Such execution platforms can be detected by
checking the platform-speciﬁc characteristics that are
different with respect to a baseline environment (i.e., an
unmodiﬁed operating system installed on real hardware,
often referred to as a “bare-metal” installation). Such
characteristics can be the timing properties of the execu-
tion, or a small variation in the CPU execution seman-

USENIX Association  

23rd USENIX Security Symposium  287

1

tics [31, 32].

Public-facing malware analysis systems are particu-
larly vulnerable to the ﬁrst approach to ﬁngerprinting.
This is because an attacker can submit malware samples
speciﬁcally designed to extract the malware analysis en-
vironment artifacts to be then used in ﬁngerprinting the
analysis system. Private malware analysis systems are
less prone to this type of ﬁngerprinting. However, be-
cause of the internal sharing of malware samples among
these private and public analysis systems, private sys-
tems may also be vulnerable to such ﬁngerprinting [37].
One way to prevent the ﬁngerprinting of the analy-
sis environment is to construct a malware analysis sys-
tem indistinguishable from a real host. Such systems
are also known as transparent analysis systems. One of
the ﬁrst transparent analysis systems, called Cobra [34],
tries to achieve this by developing a stealthy analysis
environment using binary translation. However,
this
approach can only prevent known ﬁngerprinting tech-
niques. Ether [14] is a more robust transparent analysis
system that leverages hardware virtualization to maintain
the CPU execution semantics of a hardware CPU. How-
ever, the system introduces signiﬁcant performance over-
head when performing ﬁne-grained monitoring, which is
required to produce a comprehensive malware behavioral
proﬁle. With such performance overhead, it is funda-
mentally infeasible to make it transparent, especially if
the malware execution has access to an external timing
source [20].

Instead of preventing the ﬁngerprinting of the analysis
system, some of the recent works have focused on detect-
ing a deviation of the malware behavior in different anal-
ysis environments [9, 13, 23, 24, 28]. The approach is to
execute a malware sample in different analysis environ-
ments and compare their behavioral proﬁles to ﬁnd a de-
viation. A behavioral proﬁle is a higher-level abstraction
of the activities performed by a malware sample when
executed. The assumption is that the presence of such
deviations is evidence of an attempt to ﬁngerprint and
evade one or more analysis systems. This is a generic and
robust approach because it can detect evasion regardless
of the knowledge of the techniques used by the malware
sample in order to ﬁngerprint and evade the analysis sys-
tem. This approach assumes that the malware shows its
malicious behavior in one of the analysis systems, also
known as the reference system. However, all previous
approaches have used emulated or virtualized environ-
ments for observing the deviation in the malware behav-
ior, and such environments are known to be detectable. If
all of the analysis systems are evaded by a malware sam-
ple, no signiﬁcant deviation may be present in the execu-
tion traces. Moreover, some of the analysis systems use
in-guest modules for behavior extraction, which further
compromises the transparency of the analysis system.

A malware analysis system that is indistinguishable
from a real host is a system that uses an unmodiﬁed op-
erating system installation that runs on actual hardware
(i.e., a bare-metal system). However, this approach faces
several fundamental challenges. One of the important
challenges is to efﬁciently restore the analysis system af-
ter every analysis run. Recently, a bare-metal-based mal-
ware analysis system, called BareBox [25], proposed an
efﬁcient system-restore technique. In this technique, the
physical memory of the host is partitioned and only one
partition is used for the analysis environment, while an-
other partition is used for a snapshot of the system to be
restored. Whenever needed, an external operating sys-
tem located outside the physical memory of the analy-
sis environment performs the restoration of the physical-
memory snapshot, without the need for a reboot. How-
ever, a sophisticated malware can forcefully probe the
physical memory and detect the presence of the Bare-
Box system. Another bare-metal based malware analy-
sis framework is Nvmtrace [5]. This system leverages
IPMI (Intelligent Platform Management Interface) tech-
nology to automate the power cycle of the bare-metal
analysis system. However, a complete reboot of the sys-
tem is required after every analysis run. Another chal-
lenge to the bare-metal based malware analysis system
is the extraction of the behavioral proﬁle. To this end,
no process-level behavior, such as process creation, ter-
mination, and hooking activities, can be extracted from
a bare-metal analysis system without introducing some
form of an in-guest analysis component. However, the
presence of such components inside the system violates
the transparency requirement and makes the system de-
tectable. Because of this limitation, the observable mal-
ware behavior on a pure bare-metal system is limited to
the disk-level and network-level activities. When only
the disk-level and network-level behaviors are available,
it may not be possible to perform an in-depth behavioral
analysis, but these types of activity can be effectively
used for detecting evasive behavior.

In this paper, we present BareCloud, a system for au-
tomatically detecting evasive malware. BareCloud de-
tects evasive malware by executing them on a bare-metal
system and comparing their behavior when executed on
other emulation and virtualization-based analysis sys-
tems. Our bare-metal system has no in-guest monitor-
ing component. This approach provides a robust trans-
parent environment for our reference system where both
user-mode and kernel-mode malware can be analyzed.
BareCloud transparently extracts the behavioral proﬁle
of the malware from its disk-level and network-level ac-
tivity. The disk-level activity is extracted by comparing
the system’s state after each malware execution with the
initial clean state. Using the understanding of the operat-
ing system of the analysis host, BareCloud also extracts

288  23rd USENIX Security Symposium 

USENIX Association

2

operating-system-level changes, such as changes to spe-
ciﬁc registry keys and system ﬁles. Network-level activi-
ties are captured on the wire as a stream of network pack-
ets. This approach extracts malware behavior only from
the persistent changes to the system. In principle, a mal-
ware sample could perform its activities without causing
any persistent change, or could revert any changes after
the activities are carried out. However, to perform any
substantially malicious activity, a malware has to depend
on some persistent change to the system, or it has to in-
teract with external services, such as a C&C server. Both
types of activities are transparently observable in our sys-
tem.

When comparing the behavior of a malware sample
on multiple platforms, previous works have considered
the behavioral proﬁles purely as sets or bags of ele-
ments drawn from a ﬂat domain, and computed their
similarity using traditional set-intersection-based meth-
ods [8, 13, 28]. Set-intersection-based measures may not
accurately capture similarity when data is sparse or when
there are known relationships between elements within
the sets [19]. For example, if two behavioral proﬁles un-
der comparison contain a large number of similar ﬁle ac-
tivities, but only one proﬁle exhibits some network activ-
ities, set-intersection-based similarity measures, such as
Jaccard similarity, produce a high similarity score, and
fail to properly capture the lack of similarity among net-
work activities. One may compute the similarity of the
ﬁle activities and the network activities separately. How-
ever, similar problems exist; for example, two proﬁles
may contain large number of similar DNS activities, but
only one proﬁle contains an HTTP request.
It is im-
portant to identify such small-yet-important differences
while comparing behavioral proﬁles for detecting eva-
sions.

When manually comparing behavioral proﬁles, we
start from generic questions such as “Do both proﬁles
contain network and ﬁle activities?” If they do, we move
on to other questions such as “Do these activities corre-
spond to the same network or ﬁle objects?” This way
of reasoning indicates that the behavioral proﬁles have
an inherent similarity hierarchy based on the level of ab-
straction of the activities. Therefore, our similarity mea-
sure is based on the notion of the similarity hierarchy.
Such hierarchy-base similarity can compute similarity at
different levels of abstraction and identify activities that
share similar characteristics even if they are not exactly
the same. We show that this approach performs better
than the set-intersection-based measure while comparing
behavioral proﬁles for detecting evasive malware.

We compare the malware behavioral proﬁle extracted
from the bare-metal system with three major malware
analysis platforms that are based on emulation and differ-
ent types of virtualization, and we detect evasive behav-

ior by detecting the deviation in the behavioral proﬁle.
Note that, beside evasion, there can be other factors that
may cause a deviation in the behavioral proﬁle. Section 4
describes how we mitigate those factors.

Our work makes the following contributions:
• We present BareCloud, a system for automatically
detecting evasive malware. Our system performs
malware analysis on a transparent bare-metal sys-
tem with no in-guest monitoring component and on
emulation-based and virtualization-based analysis
systems.

• We introduce a novel evasion detection approach
that leverages hierarchical similarity-based behav-
ioral proﬁle comparison. We show that this ap-
proach produces better results compared to the pre-
vious set-intersection-based approaches.

• We evaluate our system on a large dataset of re-
cent real-world malware samples. BareCloud was
able to detect 5,835 evasive malware instances out
of 110,005 samples.

2 System Overview
The goal of our system is to automatically detect eva-
sive malware by performing automated analysis of a
large number of samples on a bare-metal reference sys-
tem and other dynamic analysis systems. The goal is
to identify deviations in the dynamic behavior of a sam-
ple when executed on different analysis environments.
BareCloud achieve this by a multi-step process as de-
picted in Figure 1. The large volume of input samples
is ﬁrst pre-screened using the Anubis malware analy-
sis framework [1]. The purpose of the pre-screening
process is to select more interesting samples that are
likely to have environment-sensitive behavior. These
pre-screened samples are then executed on the cluster
of bare-metal analysis hosts and on three other malware
analysis systems, namely, Ether [14], Anubis [1], and
Cuckoo Sandbox [2]. Each analysis system consists of
multiple analysis hosts. The execution of the same sam-
ple in different systems is synchronized by the Scheduler
component. Analysis hosts (workers) can independently
join, perform analysis, and leave the BareCloud sys-
tem. BareCloud extracts behavioral proﬁles from each
of these analysis run, and, in the next step, it processes
these proﬁles to detect evasive behavior.

3 Monitoring Environments
In this section, we describe the four malware analysis
environments we use for monitoring the behavior of mal-
ware samples.

USENIX Association  

23rd USENIX Security Symposium  289

3

Incoming
samples

Pre-filter

Scheduler

Synchronized

Execution

Bare-metal

Profiles

Ether

Profiles

Anubis

Profiles

Virtualbox

Profiles

Behavior Comparison

Behavior Deviation Score

Figure 1: Overview of the system

3.1 Virtualization
We use Cuckoo Sandbox, which is based on Virtual-
Box [7], to provide a virtualization-based malware anal-
ysis platform. This is also known as a Type 2 hypervi-
sor, that is, the virtualization host is a software applica-
tion that runs on top of an operating system. Cuckoo
Sandbox [2] supports the automation of the analysis pro-
cess, and also includes function-hooking-based in-guest
monitoring components. These components monitor
execution-related events inside the analysis host. Several
analysis and reporting plugins are available for speciﬁc
needs. In this work, we use the analysis reporting plugin
that includes Windows API call traces and network traf-
ﬁc. We use this trace to build the behavioral proﬁle of a
malware sample in the virtualized environment.

3.2 Emulation
We use the Anubis platform [1] to analyze malware in
an emulated environment. Anubis is a whole-system
emulation-based malware analysis platform. The emu-
lator is based on Qemu [12]. No monitoring compo-
nent is present inside the analysis environment other than
some commonly used GUI automation tools. The emula-
tor performs execution monitoring by observing the exe-
cution of pre-computed memory addresses. These mem-
ory addresses corresponds to important system API func-
tions. Anubis is able to extract additional information
about the API execution by inserting its own instructions
to the emulator’s instruction execution chain. Anubis im-
plements a host of techniques, such as Product ID ran-
domization, to prevent straightforward detection of the
analysis system.

3.3 Hypervisor
We use Ether [14] to analyze malware in a hypervisor-
based analysis environment. Ether is a Xen-based trans-
parent malware analysis framework that utilizes Intel’s

VT hardware virtualization extensions [3]. The use of
the hypervisor makes it possible to execute most of the
malware instructions as native CPU instructions on the
real hardware without any modiﬁcations. Thus, it does
not suffer from inaccurate or incomplete system emu-
lation issues that might affect emulation-based analysis
systems. Ether can monitor a wide range of dynamic
malware behaviors, such as system calls, memory writes,
and ﬁne-grained instructions execution. However, moni-
toring of memory writes and instruction-level trace intro-
duces a substantial overhead and is only suitable for man-
ual analysis. In this work, we only use Ether’s coarse-
grained system call trace collection capability.
In ad-
dition, we also record all network communications dur-
ing the malware execution. We combine the information
from the system call trace and the network trafﬁc to gen-
erate the behavioral proﬁle.

3.4 Bare-metal
Our bare-metal malware analysis system is a cluster of
hardware-based modular worker units. The workers’
disks are based on a remote storage disk. This allows
BareCloud to leverage copy-on-write techniques to per-
form disk restoration more efﬁciently when compared to
a complete local disk overwrite. The bare-metal system
also has a software-based remote control mechanism to
automate the malware execution process on the workers.
This mechanism is based on the IPMI remote adminis-
tration features (e.g., IPMI allows to control the power
cycle of the analysis worker units). We use the iSCSI
protocol (Internet Small Computer System Interface) to
attach remote disks to worker units. We used Logical
Volume Manager (LVM)-based copy-on-write snapshots
to host the remote disk used by the analysis system run-
ning on the worker units. After the completion of each
malware analysis, the corresponding volume snapshot is
recreated from a clean volume.

One of the critical components of a malware analy-

290  23rd USENIX Security Symposium 

USENIX Association

4

sis system is the malware initiator, which is the compo-
nent that starts the execution of the malware. Usually,
this component is implemented as some form of in-guest
agent that waits for a malware sample through a network
service. If the analysis system reboots after each analy-
sis run, another approach can be to install a start-up en-
try in the system conﬁguration that executes an applica-
tion from a speciﬁc path. A malware sample can then
be updated at this speciﬁc path for each analysis run by
directly modifying the disk-image when the analysis sys-
tem is ofﬂine. However, precise control over the malware
execution duration is difﬁcult when using this approach,
as the overall execution time includes the system reboot
time, which can vary among multiple reboots..

For a bare-metal analysis system, making its malware
initiator component transparent is very important. This
is because the malware can simply check for the presence
of this component to ﬁngerprint the environment. To this
end, our system uses the network-based approach. The
malware initiator removes itself and all of its artifacts af-
ter initiating the malware. This network-based approach
also makes the malware execution duration more accu-
rate, as it does not account for the reboot time.

3.5 User Environment
Apart from stock operating system,
the environment
installed inside the malware analysis systems includes
some data and components that are usually present on
a real host, such as saved credentials for common social
networks, browser history, user document ﬁles, and other
customizations. With this setup, we can observe addi-
tional malware behavior that we could not have observed
using a bare user environment.

4 Behavior Comparison

In this section, we discuss malware behavioral deviation,
behavioral proﬁle extraction, and formalize behavioral
proﬁle comparison.

4.1 Behavior deviation
There are many factors that may cause a malware sam-
ple to show deviations in the dynamic behavior associ-
ated with different analysis environments. Hereinafter,
we discuss each of these factors in detail.

• Evasive behavior of the malware sample:

Deviation in the behavior may be the result of a suc-
cessful ﬁngerprinting of the analysis environment.
This deviation is observable due to the change in the

activities performed by the malware after the detec-
tion. This is the type of deviation we are interested
in.

• Intrinsic non-determinism:

A malware may have intrinsic non-determinism em-
bedded in the code. That is, malware behavior
might depend on some random value that it reads at
the time of execution. For example, a malware sam-
ple may create a ﬁle with a random name. Random-
ization in the behavior can also result from the use
of certain system services and APIs. For example,
a successful call to URLDownloadToFile creates a
random temporary folder to download the web con-
tent.

• Internal environment:

Difference in the software environment of the dif-
ferent analysis systems may trigger different dy-
namic behaviors of the malware sample. For exam-
ple, some malware may depend on a .NET frame-
work installed in the analysis system, or may de-
pend on the availability of a speciﬁc version of a
system DLL. If one of the malware analysis envi-
ronments does not contain such software compo-
nents, the resulting malware behavior may be dif-
ferent.

• External environment:

Another critical factor that may cause a deviation
in the malware behavior is the external environment
with which a malware sample can interact. In the
context of malware execution, this external envi-
ronment largely comprises of different network ser-
vices, such as DNS and C&C servers. The non-
deterministic nature of such network services may
introduce deviations in the dynamic behavior of a
malware sample. One simple way to minimize this
factor is to completely disable access to external
network environments. However, the network activ-
ity of a malware sample is one of the most important
aspects to characterize the behavior of the sample.
Hence, a successful behavior comparison of a mal-
ware sample requires the inclusion of its network
activities.

Since our goal

is to identify behavior deviations
caused by the evasive technique employed by the mal-
ware sample, we need to minimize the effect of the three
other factors that may cause a behavior deviation.

One approach to identifying intrinsic non-determinism
is to execute the same sample in the same environment
multiple times. By comparing the execution traces from

USENIX Association  

23rd USENIX Security Symposium  291

5

these different execution runs, non-deterministic behav-
ior can be identiﬁed. Previous work [28] used this ap-
proach to ﬁlter out randomized behavior. However, this
approach is resource- and time-expensive. Moreover, not
all malware exhibit such randomized behavior.

In this work, we propose a more efﬁcient hierarchical
similarity-based approach to behavior comparison, de-
scribed in Section 4.4. This approach is able to min-
imize the effect of intrinsic randomization without re-
quiring multiple execution runs of the same sample in
the same analysis environment. In order to address devi-
ation caused by different internal environments, we must
provide identical software environments to all analysis
systems. Therefore, we prepared identical base software
environments for all of our analysis systems.

Precisely controlling the behavior deviation intro-
duced by the external environment is difﬁcult. This is
because these factors are not under our direct control.
However, failure to minimize the impact of these factors
may result erroneous behavior deviations. This consider-
ation is important because most malware communicates
with the external environment to carry out its malicious
activities. To minimize the effect of the external environ-
ment, we implemented the following strategies.

• Synchronized execution: We execute the same mal-
ware sample in all analysis environments at the
same time. The scheduler component facilitates the
synchronization among different analysis hosts. By
doing this, we minimize the behavior deviation that
may be introduced by the variation of the external
factors over time. For example, a malware may try
to connect to a fast-ﬂux network. The availability
and the returned response of the C&C server and
the DNS server may vary over time.
If the mal-
ware is executed in different environments at differ-
ent times, such variations in external environment
may result in a spurious behavior deviation. Syn-
chronized execution mitigates such differences.

• Identical local network: Malware can interact with
the local network by different network-related ac-
tivities, such as probing available local network ser-
vices and accessing ﬁle shares. We expose all analy-
sis systems to identical simulated local network en-
vironments.

• Network service ﬁlters: One approach to minimize
the non-determinism introduced by different net-
work services is to actively intercept network com-
munications and maintain identical responses to
identical queries among all instances of a malware
running in different analysis environments. This re-
quires an application-level understanding of the net-
work services. To this end, we intercept all DNS

and SMTP communications and respond with con-
sistent replies in all analysis system. For example,
the system responds with identical IP information to
identical DNS queries coming from different analy-
sis environments. With this setup, we are also able
to sinkhole non-existent domain and SMTP com-
munications to the local simulated network. This
helps us observe more network behavior of a mal-
ware sample, which otherwise may not be observ-
able.

4.2 Behavioral proﬁle
After the execution of a malware sample in different
analysis environments, we need to extract its behavioral
proﬁle for comparison. Usually, the behavioral proﬁle is
extracted from some form of dynamic execution trace,
such as a system-call trace. Bayer et al. have intro-
duced a comprehensive method of extracting behavioral
proﬁle from an augmented system-call trace. The ad-
ditional information provides taint tracking of input and
output parameters of system calls that provides depen-
dency information between different system calls [10].
This approach has been used to cluster a large number
of malware, and to compare malware behaviors [10, 28].
Similar approaches can be used in three of our analy-
sis environments, where system-call traces are available.
However, this system-call based approach is not directly
applicable to our bare-metal malware analysis system, as
we do not have access to the system-call trace.

Transient and resultant behavioral proﬁle

A transient behavioral proﬁle is a proﬁle that represents
all of the operations performed by a malware sample dur-
ing its execution. The system-call-based behavioral pro-
ﬁle discussed previously is a type of transient behavioral
proﬁle. This represents a more comprehensive view of
how a malware performs its malicious activities. The
resultant behavioral proﬁle consists of the cumulative
changes made by the malware from the beginning to the
end of its execution. This includes those operations that
make persistent changes to the system. Multiple simi-
lar operations to the same object are combined and rep-
resented as one operation to reﬂect the resulting effect
of the operations. This represents a more summarized
view of what a malware does to the system. A mal-
ware can obfuscate its transient behavior to evade tran-
sient behavior-base similarity detection. However, simi-
lar malicious activities produce similar resulting behav-
ioral proﬁles, even if the transient behavior is obfuscated
or randomized. This makes the comparison of malware
behavior based on the resultant behavioral proﬁle more
robust.

292  23rd USENIX Security Symposium 

USENIX Association

6

The transparency requirement of our bare-metal analy-
sis system limits us to the extraction of only the resulting
behavioral proﬁle. That is, the transient behaviors of pro-
cess activities and ﬁlesystem activities are not available.
However, we can extract the resulting ﬁlesystem behav-
ior by comparing the disk contents from before and after
the malware execution. Extraction of network behavior
is straightforward using an external trafﬁc capture com-
ponent.

With these constraints in hand, we model our behav-
ioral proﬁle based on the model introduced by Bayer et
al. [10], such that only the objects and the operations are
used. That is, we take into consideration the object upon
which a malware performs an operation that causes a per-
sistent change to the object. Formally, a behavioral pro-
ﬁle Π is deﬁned as a 3-tuple.

Π = (O,R,P)
Where, O is the set of all objects, R is the set of all op-
erations that causes persistent changes, and P ⊆ (O× R)
is a relation assigning one or more operations to each ob-
ject. Unlike in the model proposed in [10], where the
objects and the operations are conceptualized as OS Ob-
jects and OS operations, we generalize the objects and
operations to any environment entity with which a mal-
ware can interact. More details on objects and operations
are provided hereinafter.

Objects

An object represents an entity, such as a ﬁle or a network
endpoint, upon which a malware can perform some op-
eration.

It is a tuple of type and name formally deﬁned as fol-

lows.
O = (ob j type,ob j name)
ob j type ::= f ile|registry|syscon f|mbr|network
The ﬁle type represents ﬁlesystem-speciﬁc ﬁle objects
of the disk, the registry type represents registry keys,
the sysconf type represents OS-speciﬁc system conﬁg-
urations, such as the boot conﬁguration, mbr represents
OS-independent Master Boot Record, and the network
type represents network entities, such as a DNS server.

Operations

An operation generalizes the actions performed by a mal-
ware sample upon the above-described objects. An oper-
ation is formally deﬁned as:
R ::= (op name,op attribute)

That is, an operation has a name and a correspond-
ing attribute to provide additional information. As men-
tioned previously, only those operations that cause a per-
sistent change to the system are included. For example,

in case of a ﬁle type object, only the creation, deletion,
and modiﬁcation operations are included in the proﬁle.

4.3 Behavior extraction

Our bare-metal system can only access the raw disk con-
tents. We extract the ﬁlesystem behavior by comparing
the ﬁlesystem state before and after the execution of a
malware sample. A detailed understanding of the ﬁlesys-
tem internal structures is required to extract such infor-
mation. We leverage the functionalities provided by the
SleuthKit framework [6] for extracting the ﬁle meta-data
information from the raw disk image. By doing this, we
are able to extract all ﬁle names in the disk, including
some recently deleted ﬁles, along with their correspond-
ing meta-data, such as size and modiﬁcation date. We
ﬁrst build two sets representing the ﬁle object meta-data:
the clean set and the dirty set, corresponding to the disk
content before and after a malware execution. Extract-
ing the deletion and creation operations of a ﬁle object
are simple set operations. That is, any ﬁle not present in
the dirty set is considered as deleted, and any ﬁle only
present in the dirty set is considered as created. If a ﬁle
is present in both sets with different meta-data, it is con-
sidered as modiﬁed. However, if a malware writes to
a disk-sector (other than MBR) that is invisible to the
ﬁlesystem, or modiﬁes an existing ﬁle without chang-
ing the size and ﬁle-date meta-data, the current approach
will not detect such changes. The straightforward way
of comparing all ﬁle contents between two disk states
can be very inefﬁcient. This limitation can be mitigated
by ﬁrst detecting such changes in the disk sectors from
copy-on-write data or iSCSI communication, and map-
ping the dirty sectors to ﬁles. Similar approach has been
previously proposed [29]. To this end, we leave this im-
provement as a future work.

Registry behavior is extracted using a similar ap-
proach. We extract the meta-data of all the registry keys
from the raw registry hive (registry database ﬁle) us-
ing the registryfs ﬁlesystem extension of the SleuthKit
framework. Again, we build two sets representing the
registry meta-data corresponding to the registry hive con-
tent before and after the malware execution. We perform
set operations similar to the case of the ﬁlesystem to ex-
tract malware operations on the registry objects.

To extract the behavior of type sysconf, we process the
ﬁlesystem and registry behavior to identify critical mod-
iﬁcations to the system conﬁguration. Some examples of
the system conﬁguration locations are listed in Table 1.
For the three other analysis systems, we process

system-call traces to extract behavior information.

USENIX Association  

23rd USENIX Security Symposium  293

7

Table 1: Examples of the conﬁguration locations

obj type
sysconf
sysconf
sysconf
sysconf
sysconf
sysconf
sysconf

obj name
startup
startup
startup
boot
autoexec
sysini
winini

System path
HKLM/Software/Microsoft/Windows/CurrentVersion/Run
HKCU/Software/Microsoft/Windows/CurrentVersion/Run
HKLM/System/CurrentControlSet/Services
%SYSTEMROOT%/BOOT.INI
%SYSTEMROOT%/AUTOEXEC.BAT
%SYSTEMROOT%/WINDOWS/SYSTEM.INI
%SYSTEMROOT%/WINDOWS/WIN.INI

Behavior normalization

Behavioral proﬁle extracted from the difference of the
initial and ﬁnal disk states contains both malware behav-
ior as well as the background operating system behav-
ior. We need to ﬁlter out the features of the behavioral
proﬁle that do not correspond to the malware execution.
One way to ﬁlter such features is to use the ﬁle modiﬁ-
cation timestamp of the ﬁle objects. That is, by selecting
only those ﬁles that are created and modiﬁed during the
time when the malware is executed, one can ﬁlter out un-
related ﬁle modiﬁcations that occur before and after the
malware execution. However, some unrelated ﬁlesystem
changes caused by the base operating system might still
be present in the ﬁltered proﬁle. Moreover, many mal-
ware samples actively modify the system time, or tamper
with the ﬁle meta-data to revert the ﬁle’s modiﬁcation
time. Although the simple ﬁle time-stamp-based ﬁlter is
efﬁcient, this approach will fail in such situations.

Another approach to ﬁlter the background behavior is
to ﬁrst learn the behavioral proﬁle of the base operating
system and then ﬁlter this behavior from the proﬁle gen-
erated by a malware execution. By doing this, we can
overcome many of the shortcomings of the timestamp-
based approach. This approach may exclude some mal-
ware operations that match the operation performed by
the base operations. However, it is difﬁcult to perform
malicious actions using only operations that are also per-
formed by the base operating system. Also, such oper-
ations are less important in deﬁning the malicious be-
havior of the malware. We use this approach to ﬁlter our
proﬁles. To extract the background behavior of the analy-
sis system, we wrote a “void” program that does nothing
other than stall inﬁnitely. For each analysis environment,
we extract the behavioral proﬁle of the “void” program
from all of its analysis hosts and combine them to build
a generalized background proﬁle. We use this proﬁle to
ﬁlter the behavioral proﬁle of a malware execution.

\\?\C:\Documents and Settings

Some objects used to describe the proﬁle may
be referenced using multiple names.
For ex-
ample,
and
C:/DOCUME∼1/ correspond to the same ﬁle object.
We convert such identiﬁable object names to the same
format. Different usernames may also result in different
physical names for semantically similar ﬁle locations.
For example, the locations C:/DOCUME∼1/USERA and
C:/DOCUME∼1/USERB are semantically similar loca-

tions, which is the user’s home directory. Some system
APIs that create temporary ﬁles also generate different
ﬁle paths, which are semantically similar. Many such
temporary path names have known root locations and
can be identiﬁed by their naming structure. We replace
such occurrences in the object names with corresponding
generic tokens.

4.4 Behavior comparison
Previous works have compared the persistent change-
based behavioral proﬁle using set-intersection-based
methods over the feature set [13, 28]. However, when
comparing behavioral proﬁles that only considers persis-
tent changes, one can expect a sparse feature set. Fur-
thermore, features within the proﬁle are highly related
and can be categorized in groups and subgroups. How-
ever, when the features are sparse or when there are
known relationships between features within the set, set-
intersection-based measures may not accurately capture
the similarity [19].

Unlike previous works, we use a hierarchical similar-
ity measure to overcome this problem. The hierarchy is
associated with the different abstraction levels present in
the behavioral proﬁle. This approach makes our simi-
larity measure less sensitive to randomization introduced
by non-determinism in malware code. This is because
the randomization is usually introduced only in one level
of the hierarchy while keeping other levels of the hierar-
chy identical. For example, a malware may randomize
the ﬁlename (ob j name) it creates, but perform the same
create operation (op name) on a ﬁle object (ob j type)
with the same operation attribute (op attribute).

4.5 Hierarchical similarity
The notion of the hierarchical similarity is often used in
text similarity, in mining association rules, and in vari-
ous computer vision tasks for ﬁnding similar shapes [16,
17, 21]. We use a similar notion of hierarchical simi-
larity to compare behavioral proﬁles. The similarity hi-
erarchy of the behavioral proﬁle is represented in Fig-
ure 2. As one can see, knowledge of the semantics
and of the relationship between the objects is encoded
in the representation. The leaves of the tree are the ac-
tual feature elements of the behavioral proﬁle. The ﬁrst
level of similarity hierarchy is ob j type. An ob j type
may have one or multiple ob j name, and each such
ob j name can be associated with one or more op name
corresponding to various operations. Each such opera-
tion has one leaf node corresponding to the associated
attribute of the operation. The leaf nodes are the fea-
ture elements whose attributes are represented by its
parent nodes. For example, in the Figure 2, the ele-

294  23rd USENIX Security Symposium 

USENIX Association

8

  Object Type

obj_type1

obj_type2

root

  Object Name

obj_name1

obj_name2

obj_name3

  Operation Name

op_name1

op_name2

op_name1

op_name3

  Operation Attribute

op_attrb1

op_attrb2

op_attrb1

op_attrb1

  Feature Elements

p1

p2

p3

p4

Figure 2: Behavior similarity hierarchy

ment p1 is a feature element having the feature attributes
(ob j type1,ob j name1,op name1,op attrb1).

We compute the similarity in a two-step process. First
we identify the matching nodes in the hierarchies of two
behavioral proﬁles. We do this iteratively, starting from
the ﬁrst level (ob j type). For each of these matching
nodes, we identify the matching nodes among their child
nodes, i.e., the next level of hierarchy. We compute the
similarity measure at each hierarchy level. Finally, we
aggregate level similarity measures to compute the over-
all similarity.

The model
Let H be a rooted tree representing the similarity hierar-
chy, where all nodes have associated labels. For exam-
ple, Figure 2 is an instance of H. Let LH be all labels
in H, and L(H,d) be the set of labels of the nodes of
H at depth d. Let δ be the height of the tree such that
L(H,δ ) is the set of all labels of the leaves of H. The set
of labels L(H,δ ) represents the feature elements p such
that p ∈ P, where P represents the behavioral proﬁle. In
the example Figure 2, the leaf nodes p1, p2, p3, and p4
represents the feature elements of the behavioral proﬁle.
L(H,δ ) and P are equivalent, one represented as leaves
of the tree structure, another represented as a tuple of the
feature attributes. With this, any P can be mapped into
H. There is a hierarchy in L(H,δ ), and hence in P, su-
perimposed by H.

Let P1 and P2 be two behavioral proﬁles of a malware
sample m from analysis systems a1 and a2. Let these
behavioral proﬁles be mapped into hierarchies H1 and
H2, instances of the hierarchical model H. Let PL(H,l)
be the label of the parent node of a node with label l,
where l ∈ LH, the set of all labels in H. Here, we want
to ﬁnd nodes with matching labels at each depth d whose

parent nodes also have matching labels. We recursively
deﬁne match and candidate for each level d as:

matchH1,H2(d) =L (H1,d)∩ L(H2,d) |

∀l ∈ matchH1,H2(d),PL(H1,l) =PL (H2,l) and

PL(H1,l) ∈ matchH1,H2(d − 1)

candidateH1,H2(d) =L (H1,d)∪ L(H2,d) |

∀l ∈ candidateH1,H2(d),

PL(H1,l)∪ PL(H2,l) ∈ matchH1,H2(d − 1)

where,

matchH1,H2(0) =root .

(1)

(2)

(3)

We deﬁne levelsimH1,H2(d), the similarity of H1 and
H2 at level d, as the Jaccard similarity coefﬁcient. That
is,

levelsimH1,H2(d) = |matchH1,H2(d)|
|candidateH1,H2(d)|

.

(4)

We deﬁne the overall hierarchical similarity between
behavioral proﬁles P1 and P2 as the arithmetic average of
similarity at each level:

Sim(P1,P2) =

1
δ

δ−1
∑
d=1

levelsimH1,H2(d).

(5)

This deﬁnition is consistent, since the right side of this
equation always lies between 0 and 1. Hence, the be-
havior distance between P1 and P2 can simply be deﬁned
as:

USENIX Association  

23rd USENIX Security Symposium  295

9

Dist(P1,P2) =1 − Sim(P1,P2).

(6)

This is possible because Sim(P1,P2) is derived from

the Jaccard similarity coefﬁcients.

Finally, we deﬁne the behavior deviation score of
a malware sample D among different analysis system
a1...an with respect to the behavioral proﬁle Pr extracted
from the reference system ar as the quadratic mean of the
behavior distances as follows.

Deviation(D) =(cid:31) 1

n

n

∑

i=1

Dist(Pr,Pi)2,

(7)

where n is the number of analysis systems, and Pi is
the behavioral proﬁle extracted from the analysis system
ai. This deviation score D is in interval [0,1], where the
value of 0 means no deviation and the value of 1 means
maximum deviation. We deﬁne a deviation threshold t.
If the deviation score D exceeds this value, we consider
the sample as evasive.

5 Evaluation

We evaluated our approach using Windows XP SP2 as
the operating system for all analysis systems, as the
weaker security measures of this operating system allow
us to observe more malware behavior.

We conducted two experiments, which are detailed in

the following sections.

5.1 Experiment I
In this experiment, we evaluated our hierarchical
similarity-based behavior comparison approach.

Dataset
We ﬁrst built the ground truth dataset of evasive mal-
ware and non-evasive malware samples. We received
234 recent and possibly evasive malware samples from
a security company. We manually analyzed them and
conﬁrmed 111 samples from 29 families to be evasive
(i.e., they ﬁngerprint and evade at least one of the con-
sidered analysis environments ). To build the dataset of
non-evasive samples, we manually analyzed recent sam-
ples submitted to Anubis. By doing this, we selected 119
samples from 49 families that did not exhibit evasive be-
havior in any of the analysis environments.

We extracted the behavioral proﬁles of these samples
from all analysis environments and computed the hierar-
chical similarity-based deviation score D with respect to
the bare-metal analysis environment. We also computed

n
o
i
s
i
c
e
r
P

0
1

.

9
0

.

8
0

.

7

.

0

6
0

.

5
0

.

4
0

.

Hierarchical similarity
Jaccard similarity

0.0

0.2

0.4

0.6

0.8

1.0

Recall

Figure 3: Precision-Recall analysis of the hierarchical
similarity-based and the Jaccard similarity-based behav-
ior comparison.

the Jaccard distance-based deviation score as proposed
in [28]. That is, the behavioral proﬁle distance is com-
puted as the Jaccard distance:

P1 ∩ P2
P1 ∪ P2

.

JD = max

J(P1,P2) =1 −
The Jaccard distance-based deviation score JD is com-
puted as the maximum of the distances among different
analysis systems as:
1<i<n{ max

1< j<n,i(cid:27)= j{J(Pi,Pj)}}.

Since we do not extract multiple behavioral proﬁles
of same malware sample from the same analysis envi-
ronment, we did not compute the intra-sandbox distance
as proposed in [28]. Instead, we wanted to compare the
two different similarity approaches when the available
behavioral proﬁles are limited to one proﬁle per analysis
environment.

We performed a precision-recall analysis by varying
the threshold t for these deviation scores. If the devia-
tion score is greater than t, the sample is considered eva-
sive. The result is presented in Figure 3. We can clearly
see that the hierarchical similarity-based deviation score
gives better results. It is able to produce higher preci-
sion results while maintaining a high recall rate. While
the highest precision the regular Jaccard distance-based
similarity could produce is limited to 88.54%. This is be-
cause some non evasive samples have the same Jaccard
distance-based deviation score as other evasive samples
having highest deviation score. Hence, no matter how
we vary the threshold t, precision does not increase.

Figure 4 shows the precision-recall characteristics of

296  23rd USENIX Security Symposium 

USENIX Association

10

events) and network activity in the Anubis analysis
environment. We include this group to see if sim-
ilar behavior can be observed in all other analysis
environments.

• Samples with high network activity: These are the
samples that show minimal system activity but high
network activity (more than 10 packets) in the Anu-
bis analysis environment.

• Samples with high system activity: These are the
samples that show no network activity but high sys-
tem activity in the Anubis analysis environment.

We selected 110,005 samples from the above groups
observed during a four months period, starting from July
2013. We extracted behavioral proﬁles of these samples
from all four analysis environments and computed the
deviation scores. We used the behavior deviation thresh-
old of t = 0.84 that was selected in the previous experi-
ment. With this threshold, we were able to detected 5,835
samples as evasive. That is, these evasive samples evade
one or more analysis environments. Since we do not have
the ground truth for this dataset, we cannot provide the
true precision of this detection.

We also categorized these evasive samples into
environment-speciﬁc evasions by using the number of
events observed within the various analysis environ-
ments. That is, if no activity that results in persistent
change is observed in an analysis environment ax while
the same sample shows persistent change activities in at
least one of the other analysis environments [a1, ...,an],
we considered that as an evasion of the analysis envi-
ronment ax. The results are presented in Table 2. We
found that 2,530 samples showed no activity that resulted
in persistent change in all three common malware anal-
ysis environments, while such persistent change activ-
ities were observed in the bare-metal analysis environ-
ment. We see that many samples were able to evade the
Ether environment, which is considered as a transpar-
ent environment. Manual analysis of those samples re-
vealed that many samples were able to ﬁngerprint Ether
by leveraging the dependency of the Xen-hypervisor on
Qemu-based device models to emulate required virtual
devices, such as hard disks. Since Ether is based on
Xen-hypervisor, it also requires the Qemu-based device
models to run the unmodiﬁed guest, which acts as the
transparent analysis host. Therefore, if a malware sam-
ple inside Ether tries to ﬁngerprint its devices, it might
identify Ether as a Qemu-based analysis system. In ad-
dition, system call tracing in Ether introduces additional
overhead to the system, and, in some of the cases, regu-
lar timing-based attacks were successful in detecting the
presence of the analysis system.

Figure 4: Precision-recall analysis of the behavior devi-
ation threshold value t. Threshold value t = 0.84 gives
the highest recall rate with 100% detection precision.

the hierarchical similarity-based deviation score with re-
spect to different values for deviation threshold t. We
can see that with the threshold value t = 0.70, more than
half of the evasive samples can be detected with above
98% precision. While with threshold t = 0.84, we get
100% precision with the recall rate of 40.20%.
In the
next large-scale experiment, we used this threshold value
t = 0.84 to have a high conﬁdence on the detection re-
sults.

5.2 Experiment II
In this experiment, we applied our behavior comparison
approach to the incoming malware feed received by Anu-
bis. We ﬁrst ﬁltered the incoming samples based on the
size and the type of the behavioral proﬁle extracted in the
Anubis analysis environment. This is required to select
interesting samples from the large volume of the incom-
ing malware without introducing any strong bias. This
pre-selection process randomly selects samples from the
following four groups.

• Samples with minimal activity: These are the sam-
ples that show minimal to no activity in the Anubis
analysis environment (less than 1000 events). This
group may contain evasive malware that success-
fully evade Anubis analysis environment.

• Samples with high system and network activity:
These are the samples that show a substantial
amount of system-related activity (more than 1000

USENIX Association  

23rd USENIX Security Symposium  297

11

0.00.20.40.60.81.0Threshold (t)Precision0.000.200.400.600.801.00PrecisionRecallt=0.84Table 2: Evasion detection on different environments

Environment Detection count
Anubis
Ether
VirtualBox
All
Total

4,947
4,562
3,576
2,530
5,835

Percentage
84.78
78.18
61.28
43.35

6 Limitations

In this section, we discuss the limitations of our ap-
proach.

One of the limitations inherent to all dynamic analysis
systems is the inability of handling stalling code in a gen-
eral way. A malware sample can wait for some time (e.g.,
tens of minutes) before performing any malicious activ-
ity. Kolbitsch et al. have proposed a technique to detect
and mitigate malware stalling code [26]. However, the
mitigation technique is only possible where ﬁne-grained
analysis is possible. The technique is not applicable in
our bare-metal system. A more sophisticated stalling at-
tack may encrypt the malicious payload with some weak
encryption key, which the malware will brute-force dur-
ing the execution. It is difﬁcult to expedite such process
to reveal the malicious activities within a limited execu-
tion time. To this end, BareCloud will not be able to
observe activity in malware with stalling code.

Malware may employ heuristic checks for anomalies
in the internal or external environments that are speciﬁc
to malware analysis systems. For example, it can wait for
real user activities, or try to resolve known non-existent
domain using a public DNS server. If there is no user
activity in the system or if every non-existent domain is
resolved, it is likely that the system is an analysis en-
vironment. One of the mitigation techniques can be to
remove external anomalies by not actively intercepting
and modifying the network communication. User activi-
ties can be injected into the system by using automation
techniques. However, transparently performing such au-
tomation in a bare-metal system is challenging. To this
end, such heuristic checks will be able to detect our bare-
metal analysis system.

Although, our similarity measure is less sensitive to
randomization introduced by the non-deterministic code
of a malware sample, high levels of randomization in the
persistent changes will result in an erroneous detection of
evasion. Other mitigation techniques, such as the multi-
ple execution of the malware on the same analysis sys-
tem, can be performed to mitigate this problem at the
expense of more computational resources.

Both known and unknown ﬁngerprinting techniques
focused on detecting virtualized or emulated platforms

will fail to detect BareCloud, because we are executing
malware on a bare-metal hardware. However, there is
the possibility that our system can be ﬁngerprinted by
examining unique software/hardware environment fea-
tures, such as the MAC address of the network device
or the presence of the iSCSI driver. In the case of emu-
lated/virtualized environments, it is trivial to randomize
such information for each malware analysis run. Since
our system uses real hardware, introducing this random-
ization while preserving the transparency is difﬁcult. The
iSCSI driver detection can be mitigated by using more
expensive hardware iSCSI initiator instead of a software
iSCSI initiator. A hardware iSCSI initiator is a host bus
adapter (HBA) that appears to the OS as a hardware stor-
age device. To this end, our system runs as a private mal-
ware analysis framework and all outside network com-
munications are blocked. A limited access to the Internet
is provided through proxy. As long as the unique envi-
ronment variables are not leaked to the malware authors,
the system can be kept undetectable. However, a dedi-
cated attacker may detect any dynamic analysis system
that allows external network communications like ours
by using active reconnaissance-based attacks [37]. Mal-
ware writers can upload decoy samples to public mal-
ware analysis systems so that it is eventually picked up
by private analysis systems, such as ours. Such sam-
ples can leak unique environment artifacts of these anal-
ysis systems using “phoning home” technique and can be
used for active reconnaissance.

7 Related works

7.1 Dynamic analysis
Researchers have developed many dynamic analysis
tools to analyze malware. These tools mostly focus
on extracting system call or Windows API call traces.
Many of these analysis systems are based on sandbox-
ing techniques [1, 4, 14, 35]. A sandbox is an instru-
mented execution environment that executes the malware
sample in a contained way. Some of these sandboxes
leverage in-guest techniques to trace Windows API calls,
such as CWSandbox [35] and Norman Sandbox [4].
Other sandbox systems are implemented using emula-
tion or virtualization technologies. VMScope [22], TT-
Analyze [11], and Panorama [36] are some of the exam-
ples of emulation-based malware analysis systems. All
of them are based on Qemu [12] and implement whole-
system emulation. Other tools, such as Ether [14] and
HyperDBG [15] are based on hardware-supported vir-
tualization technology. While most system deal with
user-land malware samples, some of the analysis sys-
tems are speciﬁcally targeted to analyze kernel-mode
malware [27, 30].

298  23rd USENIX Security Symposium 

USENIX Association

12

7.2 Transparent analysis
Many transparent malware analysis systems have been
proposed to defeat evasive malware. Cobra [34] was
the ﬁrst analysis system speciﬁcally focused on defeat-
ing anti-debugging techniques. However, Cobra runs its
tool at the same privilege level as the malware. In prin-
ciple, this approach makes it impossible to provide abso-
lute transparency.

Many of the malware analysis tools based on the out-
of-VM approach are designed to provide better trans-
parency [1, 14, 22], as the analysis system is completely
external to the execution environment. However, de-
tection techniques have been developed to detect these
analysis systems as well. There are several techniques
to detect VMWare [9, 18, 33], as well as Bochs and
Qemu [9, 18, 31]. Pek et al. [32] have shown that hard-
ware virtualization-based Ether [14] can be detected us-
ing local timing attacks.

The most effective way to provide transparency is to
run on real hardware, with an environment that has not
been extended with analysis artifacts. BareBox [25] and
Nvmtracer [5] both provide bare-metal environments for
malware analysis.

7.3 Evasion detection
Chen et al. proposed a detailed taxonomy of evasion
techniques used by malware against dynamic analysis
system [13]. Lau et al. have employed a dynamic-static
tracing technique to detect VM detection techniques.
Kang et al. [24] proposed a scalable trace-matching al-
gorithm to locate the point of execution diversion be-
tween two executions. The system is able to dynamically
modify the execution of the whole-system emulator to
defeat anti-emulation checks. Balzarotti et al. [9] pro-
posed a system for detecting dynamic behavior deviation
of malware by comparing behaviors between an instru-
mented environment and a reference host. The compar-
ison method is based on the deterministic program exe-
cution replay. That is, the malware under analysis is ﬁrst
executed in a reference host while recording the interac-
tion of the malware with the operating system. Later,
the execution is replayed deterministically in a differ-
ent analysis environment by providing system call return
value recorded in the ﬁrst run, in the assumption that any
deviation in the execution is evidence of some kind of en-
vironment ﬁngerprinting. Disarm [28] compares behav-
ioral proﬁles of four emulation-based analysis environ-
ments. The behavior comparison requires each sample
to be analyzed multiple times in each analysis environ-
ment. The main difference between Disarm and our work
is that our analysis systems are based on four fundamen-
tally different analysis platforms, including the transpar-

ent bare-metal environment with no monitoring compo-
nent present in the hardware. Moreover, we propose an
improved behavior comparison technique that captures
the inherent similarity hierarchy of the behavior features,
and do not require the resource-expensive execution of
same sample multiple times in the same analysis envi-
ronment.

7.4 Hierarchical Similarity
Hierarchies are used to encode domain knowledge about
different levels of abstraction in the type of events ob-
served. They have been used in different ﬁeld of similar-
ity detection, such as ﬁnding text similarity [16], detect-
ing association rules using hierarchies of concepts [21],
and ﬁnding similarity among deformable shapes [17].
Ganesan et al. [19] proposed a similarity measure that in-
corporates hierarchical domain structure. However, the
similarity computation is focused on the element-level
similarity rather than the proﬁle-level similarity. It uses
a modiﬁed version of cosine-similarity measure.

8 Conclusions

Dynamic analysis is an effective approach for analyzing
and detecting malware that uses advanced packing and
obfuscation techniques. However, evasive malware can
ﬁngerprint such analysis systems, and, as a result, stop
the execution of any malicious activities. Most of the
ﬁngerprinting techniques exploit the fact that dynamic
analysis systems are based on virtualized or emulated
environments, which can be detected by several known
methods. The ultimate way to thwart such detection is to
analyze malware in a bare-metal environment.

In this work, we presented BareCloud, a system for
automatically detecting evasive malware by using hier-
archical similarity-based behavioral proﬁle comparison.
The proﬁles are collected by running a malware sam-
ple in bare-metal, virtualized, emulated, and hypervisor-
based analysis environments.

Future work will focus on improving the transparency
of the bare-metal analysis component and on developing
an iSCSI module that can extract high-level, intermediate
ﬁle system operation, providing a richer ﬁlesystem-level
event trace.

9 Acknowledgments

This work is supported by the Ofﬁce of Naval Re-
search (ONR) under grant N00014-09-1-1042 and the
Army Research Ofﬁce (ARO) under grant W911NF-09-
1-0553.

USENIX Association  

23rd USENIX Security Symposium  299

13

References

[1] Anubis. http://anubis.iseclab.org.

[2] Cuckoo Sandbox. http://www.cuckoosandbox.org.

[3] Intel Virtualization Technology. http://intel.com/

technology/virtualization.

[4] Norman Sandbox. http://www.norman.com/.

[5] Nvmtrace. http://code.google.com/p/nvmtrace.

[6] SleuthKit. http://www.sleuthkit.org.

[7] VirtualBox. http://www.virtualbox.org.

[8] BAILEY, M., OBERHEIDE, J., ANDERSEN, J.,
MAO, Z. M., JAHANIAN, F., AND NAZARIO, J.
Automated Classiﬁcation and Analysis of Internet
Malware. In Symposium on Recent Advances in In-
trusion Detection (RAID) (2007).

[9] BALZAROTTI, D., COVA, M., KARLBERGER, C.,
KIRDA, E., KRUEGEL, C., AND VIGNA, G. Ef-
ﬁcient Detection of Split Personalities in Malware.
In Symposium on Network and Distributed System
Security (NDSS) (February 2010).

[10] BAYER, U., COMPARETTI, P. M., HLAUSCHEK,
C., KRUEGEL, C., AND KIRDA, E. Scalable,
Behavior-Based Malware Clustering.
In Sympo-
sium on Network and Distributed System Security
(NDSS) (2009).

[11] BAYER, U., KRUEGEL, C., AND KIRDA, E. TT-
Analyze : A Tool for Analyzing Malware. Eu-
ropean Institute for Computer Antivirus Research
(EICAR) (2006).

[12] BELLARD, F. QEMU, a Fast and Portable Dynamic
In USENIX Annual Technical Confer-

Translator.
ence, FREENIX Track (2005).

[13] CHEN, X., ANDERSEN, J., MAO, Z. M., BAILEY,
M., AND NAZARIO, J. Towards an Understanding
of Anti-virtualization and Anti-debugging Behav-
ior in Modern Malware.
In IEEE Conference on
Dependable Systems and Networks With FTCS and
DCC (2008), IEEE.

[14] DINABURG, A., ROYAL, P., SHARIF, M., AND
Ether: Malware Analysis via Hard-
LEE, W.
ware Virtualization Extensions.
In ACM Confer-
ence on Computer and Communications Security
(CCS) (2008).

[15] FATTORI, A., PALEARI, R., MARTIGNONI, L.,
AND MONGA, M.
Dynamic and Transpar-
ent Analysis of Commodity Production Systems.
In IEEE/ACM International Conference on Auto-
mated Software Engineering (ASE) (2010), ACM.

[16] FELDMAN, R., AND DAGAN, I. Knowledge Dis-
covery in Textual Databases (KDT). In Conference
on Knowledge Discovery and Data Mining (KDD)
(1995).

[17] FELZENSZWALB, P. F., AND SCHWARTZ, J. D.
Hierarchical Matching of Deformable Shapes.
In
IEEE Conference on Computer Vision and Pattern
Recognition (CVPR) (2007), IEEE.

[18] FERRIE, P. Attacks on more virtual machine emu-

lators. Symantec Technology Exchange (2007).

[19] GANESAN, P., GARCIA-MOLINA, H., AND
WIDOM, J. Exploiting Hierarchical Domain Struc-
ture to Compute Similarity. ACM Transactions on
Information Systems (TOIS) (2003).

[20] GARFINKEL, T., ADAMS, K., WARFIELD, A.,
AND FRANKLIN, J. Compatibility Is Not Trans-
parency: VMM Detection Myths and Realities. In
USENIX Workshop on Hot Topics in Operating Sys-
tems (HotOS) (2007).

[21] HAN, J., AND FU, Y. Discovery of Multiple-level
Association Rules from Large Databases. In Con-
ference on Very Large Data Bases (VLDB) (1995).

[22] JIANG, X., AND WANG, X. Out-of-the-Box Mon-
itoring of VM-Based High-Interaction Honeypots.
In Symposium on Recent Advances in Intrusion De-
tection (RAID) (2007).

[23] JOHNSON, N. M., CABALLERO, J., CHEN, K. Z.,
MCCAMANT, S., POOSANKAM, P., REYNAUD,
D., AND SONG, D. Differential Slicing:
Iden-
tifying Causal Execution Differences for Security
Applications. In IEEE Symposium on Security and
Privacy (2011).

[24] KANG, M., YIN, H., AND HANNA, S. Emulating
Emulation-resistant Malware. ACM Workshop on
Virtual machine security (2009).

[25] KIRAT, D., VIGNA, G., AND KRUEGEL, C. Bare-
Box : Efﬁcient Malware Analysis on Bare-Metal.
In Annual Computer Security Applications Confer-
ence (ACSAC) (2011).

[26] KOLBITSCH, C., KIRDA, E., AND KRUEGEL, C.
The Power of Procrastination: Detection and Mit-
igation of Execution-Stalling Malicious Code.
In

300  23rd USENIX Security Symposium 

USENIX Association

14

[37] YOSHIOKA, K., HOSOBUCHI, Y., ORII, T., AND
MATSUMOTO, T. Your Sandbox is Blinded: Im-
pact of Decoy Injection to Public Malware Anal-
ysis Systems. Journal of Information Processing
(2011).

ACM Conference on Computer and Communica-
tions Security (CCS) (2011).

[27] LANZI, A., SHARIF, M., AND LEE, W. K-Tracer:
A System for Extracting Kernel Malware Behavior.
In Symposium on Network and Distributed System
Security (NDSS) (2009).

[28] LINDORFER, M., KOLBITSCH, C., AND COM-
PARETTI, P. M. Detecting Environment-Sensitive
Malware. In Symposium on Recent Advances in In-
trusion Detection (RAID) (2011).

[29] MANKIN, J., AND KAELI, D. Dione: A Flexi-
ble Disk Monitoring and Analysis Framework. Re-
search in Attacks, Intrusions, and Defenses (2012).

[30] NEUGSCHWANDTNER, M., PLATZER, C., COM-
PARETTI, P. M., AND BAYER, U. dAnubis Dy-
namic Device Driver Analysis Based on Virtual
Machine Introspection. Detection of Intrusions and
Malware, and Vulnerability Assessment (DIMVA)
(2010).

[31] PALEARI, R., MARTIGNONI, L., ROGLIA, G. F.,
AND BRUSCHI, D. A ﬁstful of red-pills: How to
automatically generate procedures to detect CPU
emulators.
In USENIX Workshop on Offensive
Technologies (WOOT) (2009).

[32] P ´EK, G., BENCS ´ATH, B., AND BUTTY ´AN, L.
nEther:
In-guest Detection of Out-of-the-guest
Malware Analyzers. In European Workshop on Sys-
tem Security (EUROSEC) (2011), ACM.

[33] RUTKOWSKA, J.

Red Pill or how to detect
VMM using (almost) one CPU instruction. http:
//invisiblethings.org/papers/redpill.html, 2004.

[34] VASUDEVAN, A., AND YERRABALLI, R. Co-
bra: Fine-grained Malware Analysis using Stealth
Localized-executions. In IEEE Symposium on Se-
curity and Privacy (2006).

[35] WILLEMS, C., HOLZ, T., AND FREILING, F. To-
ward Automated Dynamic Malware Analysis Us-
ing CWSandbox. IEEE Security and Privacy 5, 2
(Mar. 2007).

[36] YIN, H., SONG, D., EGELE, M., KRUEGEL, C.,
AND KIRDA, E. Panorama : Capturing System-
wide Information Flow for Malware Detection and
Analysis.
In ACM Conference on Computer and
Communications Security (CCS) (2007).

USENIX Association  

23rd USENIX Security Symposium  301

15

