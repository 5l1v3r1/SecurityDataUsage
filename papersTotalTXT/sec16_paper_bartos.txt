Optimized Invariant Representation of Network 
Traffic for Detecting Unseen Malware Variants

Karel Bartos and Michal Sofka, Cisco Systems, Inc.; Vojtech Franc,  

Czech Technical University in Prague

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/bartos

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Optimized Invariant Representation of Network Trafﬁc for Detecting

Unseen Malware Variants

Karel Bartos

Cisco Systems, Inc.

Czech Technical University in Prague,

Faculty of Electrical Engineering

Michal Sofka

Cisco Systems, Inc.

Czech Technical University in Prague,

Faculty of Electrical Engineering

Vojtech Franc

Czech Technical University in Prague,

Faculty of Electrical Engineering

Abstract
New and unseen polymorphic malware, zero-day attacks,
or other types of advanced persistent threats are usually
not detected by signature-based security devices, ﬁre-
walls, or anti-viruses. This represents a challenge to
the network security industry as the amount and vari-
ability of incidents has been increasing. Consequently,
this complicates the design of learning-based detection
systems relying on features extracted from network data.
The problem is caused by different joint distribution of
observation (features) and labels in the training and test-
ing data sets. This paper proposes a classiﬁcation sys-
tem designed to detect both known as well as previously-
unseen security threats. The classiﬁers use statistical
feature representation computed from the network traf-
ﬁc and learn to recognize malicious behavior. The rep-
resentation is designed and optimized to be invariant to
the most common changes of malware behaviors. This
is achieved in part by a feature histogram constructed
for each group of HTTP ﬂows (proxy log records) of a
user visiting a particular hostname and in part by a fea-
ture self-similarity matrix computed for each group. The
parameters of the representation (histogram bins) are op-
timized and learned based on the training samples along
with the classiﬁers. The proposed classiﬁcation system
was deployed on large corporate networks, where it de-
tected 2,090 new and unseen variants of malware sam-
ples with 90% precision (9 of 10 alerts were malicious),
which is a considerable improvement when compared to
the current ﬂow-based approaches or existing signature-
based web security devices.

1

Introduction

Current network security devices classify large amounts
of the malicious network trafﬁc and report the results
in many individually-identiﬁed incidents, some of which
are false alerts. On the other hand, a lot of malicious traf-

ﬁc remains undetected due to the increasing variability
of malware attacks. As a result, security analysts might
miss severe complex attacks because the incidents are not
correctly prioritized or reported.

The network trafﬁc can be classiﬁed at different lev-
els of detail. Approaches based on packet inspection
and signature matching [15] rely on a database of known
malware samples. These techniques are able to achieve
results with high precision (low number of false alerts),
but their detection ability is limited only to the known
samples and patterns included in the database (limited
recall). Moreover, due to the continuous improvements
of network bandwidth, analyzing individual packets is
becoming intractable on high-speed network links.
It
is more efﬁcient to classify network trafﬁc based on
ﬂows representing groups of packets (e.g. NetFlow [1]
or proxy logs [26]). While this approach has typically
lower precision, it uses statistical modeling and behav-
ioral analysis [8] to ﬁnd new and previously unseen ma-
licious threats (higher recall).

Statistical features calculated from ﬂows can be used
for unsupervised anomaly detection, or in supervised
classiﬁcation to train data-driven classiﬁers of malicious
trafﬁc. While the former approach is typically used to
detect new threats, it suffers from lower precision which
limits its practical usefulness due to large amount of false
alerts. Data-driven classiﬁers trained on known mali-
cious samples achieve better efﬁcacy results, but the re-
sults are directly dependent on the samples used in the
training. Once a malware changes the behavior, the sys-
tem needs to be retrained. With continuously rising num-
ber of malware variants, this becomes a major bottleneck
in modern malware detection systems. Therefore, the ro-
bustness and invariance of features extracted from raw
data plays the key role when classifying new malware.

The problem of changing malware behavior can be
formalized by recognizing that a joint distribution of the
malware samples (or features) differs for already known
training (source) and yet unseen testing (target) data.

USENIX Association  

25th USENIX Security Symposium  807

This can happen as a result of target evolving after the
initial classiﬁer or detector has been trained. In super-
vised learning, this problem is solved by domain adapta-
tion. Under the assumption that the source and target
distributions do not change arbitrarily, the goal of the
domain adaptation is to leverage the knowledge in the
source domain and transfer it to the target domain. In
this work, we focus on the case where the conditional
distribution of the observation given labels is different,
also called a conditional shift.

The domain adaptation (or knowledge transfer) can
be achieved by adapting the detector using importance
weighting such that training instances from the source
distribution match the target distribution [37]. Another
approach is to transform the training instances to the do-
main of the testing data or to create a new data represen-
tation with the same joint distribution of observation and
labels [4]. The challenging part is to design a meaning-
ful transformation that transfers the knowledge from the
source domain and improves the robustness of the detec-
tor on the target domain.

In this paper, we present a new optimized invari-
ant representation of network trafﬁc data that enables
domain adaptation under conditional shift. The rep-
resentation is computed for bags of samples, each of
which consists of features computed from network traf-
ﬁc logs. The bags are constructed for each user and con-
tain all network communication with a particular host-
name/domain. The representation is designed to be in-
variant under shifting and scaling of the feature values
and under permutation and size changes of the bags. This
is achieved by combining bag histograms with an invari-
ant self similarity matrix for each bag. All parameters of
the representation are learned automatically for the train-
ing data using the proposed optimization approach.

The proposed invariant representation is applied to de-
tect malicious HTTP trafﬁc. We will show that the clas-
siﬁer trained on malware samples from one category can
successfully detect new samples from a different cate-
gory. This way, the knowledge of the malware behavior
is correctly transferred to the new domain. Compared
to the baseline ﬂow-based representation or widely-used
security device, the proposed approach shows consider-
able improvements and correctly classiﬁes new types of
network threats that were not part of the training data.

This paper has the following major contributions:

• Classifying new malware categories – we propose
a supervised method that is able to detect new types
of malware categories from a limited amount of
training samples. Unlike classifying each category
separately, which limits the robustness, we propose
an invariant training from malware samples of mul-
tiple categories.

• Bag representation of samples – Instead of classi-
fying ﬂows individually, we propose to group ﬂows
into bags, where each bag contains ﬂows that are re-
lated to each other (e.g. having the same user and
target domain). Even though the concept of group-
ing ﬂows together has been already introduced in
the previously published work (e.g. in [32]), these
approaches rely on a sequence of ﬂow-based fea-
tures rather than on more complex representation.
• Features describing the dynamics of the samples
– To enforce the invariant properties of the represen-
tation, we propose to use a novel approach, where
the features are derived from the self-similarity of
ﬂows within a bag. These features describe the dy-
namics of each bag and have many invariant proper-
ties that are useful when ﬁnding new malware vari-
ants and categories.

• Learning the representation from the training
data – To optimize the parameters of the representa-
tion, we propose a novel method that combines the
process of learning the representation with the pro-
cess of learning the classiﬁer. The resulting repre-
sentation ensures easier separation of malicious and
legitimate communication and at the same time con-
trols the complexity of the classiﬁer.

• Large scale evaluation – We evaluated the pro-
posed representation on real network trafﬁc of mul-
tiple companies. Unlike most of the previously pub-
lished work, we performed the evaluation on highly
imbalanced datasets as they appear in practice (con-
sidering the number of malicious samples), with
most of the trafﬁc being legitimate, to show the po-
tential of the approach in practice. This makes the
classiﬁcation problem much harder. We provided a
comparison with state-of-the-art approaches and a
widely-used signature-based web security device to
show the advantages of the proposed approach.

2 Related Work

Network perimeter can be secured by a large variety
of network security devices and mechanisms, such as
host-based or network-based Intrusion Detection Sys-
tems (IDS) [36]. We brieﬂy review both systems, focus-
ing our discussion on network-based IDS, which are the
most relevant to the presented work.

Host-based IDS systems analyze malicious code and
processes and system calls related to OS information.
Traditional and widely-used anti-virus software or spy-
ware scanners can be easily evaded by simple transfor-
mations of malware code. To address this weakness,
methods of static analysis [30], [38] were proposed.

808  25th USENIX Security Symposium 

USENIX Association

2

Static analysis, relying on semantic signatures, concen-
trates on pure investigation of code snippets without ac-
tually executing them. These methods are more resilient
to changes in malware codes, however they can be easily
evaded by obfuscation techniques. Methods of dynamic
analysis [29], [34], [42] were proposed to deal with the
weaknesses of static analysis, focusing on obtaining re-
liable information on execution of malicious programs.
The downside of the dynamic analysis is the necessity
to run the codes in a restricted environment which may
inﬂuence malware behavior or difﬁculty of the analysis
and tracing the problem back to the exact code location.
Recently, a combination of static and dynamic analysis
was used to analyze malicious browser extensions [20].
Network-based IDS systems are typically deployed on
the key points of the network infrastructure and moni-
tor incoming and outgoing network trafﬁc by using static
signature matching [15] or dynamic anomaly detection
methods [8]. Signature-based IDS systems evaluate each
network connection according to the predeﬁned malware
signatures regardless of the context. They are capable of
detecting well-known attacks, but with limited amount of
detected novel intrusions. On the other hand, anomaly-
based IDS systems are designed to detect wide range of
network anomalies including yet undiscovered attacks,
but at the expense of higher false alarm rates [8].

Network-based approaches are designed to detect ma-
licious communication by processing network packets
or logs. An overview of the existing state-of-the-art
approaches is shown in Table 1. The focus has been
on the trafﬁc classiﬁcation from packet traces [5], [28],
[39], [41], as this source provides detailed information
about the underlying network communication. Due to
the still increasing demands for larger bandwidth, an-
alyzing individual packets is becoming intractable on
high-speed network links. Moreover, some environments
with highly conﬁdential data transfers such as banks or
government organizations do not allow deployment of
packet inspection devices due to the legal or privacy rea-
sons. The alternative approach is the classiﬁcation based
on network trafﬁc logs, e.g. NetFlow [1], DNS records,
or proxy logs. The logs are extracted at the transport
layer and contain information only from packet headers.
Methods introduced in [12] and [23] apply features
extracted from NetFlow data to classify network traf-
ﬁc into general classes, such as P2P, IMAP, FTP, POP3,
DNS, IRC, etc. A comparison and evaluation of these ap-
proaches can be found in a comprehensive survey [24].
A combination of host-based statistics with SNORT rules
to detect botnets was introduced in [16]. The authors
showed that it is possible to detect malicious trafﬁc using
statistical features computed from NetFlow data, which
motivated further research in this ﬁeld. An alternative
approach for classiﬁcation of botnets from NetFlow fea-

tures was proposed in [6]. The authors of [33] have used
normalized NetFlow features to cluster ﬂow-based sam-
ples of network trafﬁc into four predeﬁned categories.
As opposed to our approach, the normalization was per-
formed to be able to compare individual features with
each other. In our approach, we extended this idea and
use normalization to be able to compare various malware
categories. While all these approaches represent rele-
vant state-of-the-art, network threats evolve so rapidly
that these methods are becoming less effective due to the
choice of features and the way they are used.

One of the largest changes in the network security
landscape is the fact that HTTP(S) trafﬁc is being used
not only for web browsing, but also for other types of
services and applications (TOR, multimedia streaming,
remote desktop) including lots of malicious attacks. Ac-
cording to recent analysis [18], majority of malware sam-
ples communicate via HTTP. This change has drawn
more attention to classifying malware from web traf-
ﬁc.
In [25], the authors proposed an anomaly detec-
tion system composed of several techniques to detect at-
tacks against web servers. They divide URIs into groups,
where each group contains URIs with the same resource
path. URIs without a query string or with return code
outside of interval [200, 300] are considered as irrele-
vant. The system showed the ability to detect unseen
malware samples and the recall will be compared with
our proposed approach in Section 8.
In [40], the au-
thors introduced a method for predicting compromised
websites using features extracted from page content and
Alexa Web Information Service.

Having sufﬁcient amount of labeled malware samples
at disposal, numerous approaches proposed supervised
learning methods to achieve better efﬁcacy. Clasifying
DGA malware from DNS records based on connections
to non-existent domains (NXDomains) was proposed in
[2]. Even though several other data sources were used
to detect malware (such as malware executions [3] or
JavaScript analysis [22]), the most relevant work to our
approach uses proxy logs [9], [17], [27], [44], [32].

In all these methods, proxy log features are extracted
from real legitimate and malicious samples to train a
data-driven classiﬁer, which is used to ﬁnd new mali-
cious samples from the testing set. There are ﬁve core
differences between these approaches and our approach:
(1) we do not classify individual ﬂows (in our case proxy
log records), but sets of related ﬂows called bags, (2)
we propose a novel representation based on features de-
scribing the dynamics of each bag, (3) the features are
computed from the bags and are invariant against various
changes an attacker could implement to evade detection,
(4) parameters of the proposed representation are learned
automatically from the input data to maximize the detec-
tion performance, (5) the proposed classiﬁcation system

USENIX Association  

25th USENIX Security Symposium  809

3

Approach

Type Method

Features

Wang [41]
Kruegel [25]
Gu [16]
Bilge [6]
Antonakakis [2]
Bailey [3]
Kapravelos [22]
Choi [9]
Zhao [44]
Huang [17]
Ma [27]
Invernizzi [18]
Soska [40]
Nelms [32]
Our approach

U
U
U
S
S
S
S
S
S
S
S
U
S
S
S

anomaly detection
anomaly detection
clustering
random forest
multiple
hierarch. clustering
similarity of trees
SVM + RAkEL
active learning
SVM
multiple
graph clustering
random forests
heuristics
learned repr.+SVM learned bag dynamics

packet payload
URL query parameters
host statistics+SNORT
ﬂow size, time
NXDomains
state changes
abstract syntax tree
URL lexical, host, dns
URL lexical + host
URL lexical
URL lexical + host
proxy log ﬁelds
content of web pages
web paths

Target class

worms, exploits
web malware
botnet
botnets
dga malware
malware
web malware
malicious ﬂows
malicious ﬂows
phishing
malicious ﬂows
mw downloads
infected websites
mw downloads
malicious ﬂows

Type
packets
proxy logs
NetFlow
NefFlow
DNS data
executions
JavaScript
proxy logs
proxy logs
proxy logs
proxy logs
proxy logs
web pages
proxy logs
proxy logs

Testing Data

Year
2003
2003
2007
2011
2011
2007
2012
2009
2009
2011
2011
2012
2014
2014
2015

All samples
531,117
1,212,197
100,000k
78,000,000
360,700
4,591
20,918,798
72,000
1,000,000
12,193
2,000,000
1,219
386,018
N/A
15,379,466

Malicious Mal:All
ratio
N/A
1:100k
1:17
1:2.2M
1:45
1:1
1:112
1:2
1:100
1:1
1:333
1:4
1:8
N/A
1:355

samples
N/A
11
5,842k
36
8008
4,591
186,032
32,000
10,000
10,094
6,000
324
49,347
150
43,380

Table 1: Overview of the existing state-of-the-art approaches focusing on classiﬁcation of malicious trafﬁc (U = unsu-
pervised, S = supervised). In contrast to the existing work, our approach proposes novel and optimized representation
of bags, describing the dynamics of each legitimate or malicious sample. The approach is evaluated on latest real
datasets with a realistic ratio of malicious and background ﬂows (proxy log records).

was deployed on corporate networks and evaluated on
imbalanced datasets (see Table 1) as they appear in prac-
tice to show the expected efﬁcacy on these networks.

3 Formalization of the Problem

The paper deals with the problem of creating a robust
representation of network communication that would be
invariant against modiﬁcations an attacker can imple-
ment to evade the detection systems. The representa-
tion is used to classify network trafﬁc into positive (ma-
licious) or negative (legitimate) category. The labels for
positive and negative samples are often very expensive to
obtain. Moreover, sample distribution typically evolves
in time, so the probability distribution of training data
differs from the probability distribution of test data. This
complicates the training of classiﬁers which assume that
the distributions are the same. In the following, the prob-
lem is described in more detail.

Each sample is represented as an n-dimensional fea-
ture vector x ∈ Rn. Samples are grouped into bags, with
every bag represented as a matrix X = (x1, . . . ,x m) ∈
Rn×m, where m is the number of samples in the bag and
n is the number of features. The bags may have different
number of samples. A single category yi can be assigned
to each bag from the set Y = {y1, . . . ,y N}. Only a few
categories are included in the training set. The proba-
bility distribution on training and testing bags for cate-
gory y j will be denoted as PL(X|y j) and PT (X|y j), re-
spectively. Moreover, the probability distribution of the
training data differs from the probability distribution of
the testing data, i.e. there is a domain adaptation problem
[7] (also called a conditional shift [43]):

PL(X|y j) (cid:26)= PT (X|y j), ∀y j ∈ Y .

(1)

4

The purpose of the domain adaptation is to apply
knowledge acquired from the training (source) domain
into test (target) domain. The relation between PL(X|yi)
and PT (X|yi) is not arbitrary, otherwise it would not be
possible to transfer any knowledge. Therefore there is a
transformation τ, which transforms the feature values of
the bags onto a representation, in which PL(τ(X)|yi) ≈
PT (τ(X)|yi). The goal is to ﬁnd this representation, al-
lowing to classify individual bag represented as X into
categories Y = {y1, . . . ,y N} under the above mentioned
conditional shift.

Numerous methods for transfer learning have been
proposed (since the traditional machine learning meth-
ods cannot be used effectively in this case), including
kernel mean matching [14], kernel learning approaches
[11], maximum mean discrepancy [19], or boosting [10].
These methods try to solve a general data transfer with
relaxed conditions on the similarity of the distributions
during the transfer. The downside of these methods is
the necessity to specify the target loss function and avail-
ability of large amount of labeled data.

This paper proposes an effective invariant representa-
tion that solves the classiﬁcation problem with a covari-
ate shift (see Equation 1). Once the data are transformed,
the new feature values do not rely on the original distri-
bution and they are not inﬂuenced by the shift. The pa-
rameters of the representation are learned automatically
from the data together with the classiﬁer as a joint opti-
mization process. The advantage of this approach is that
the parameters are optimally chosen during training to
achieve the best classiﬁcation efﬁcacy for the given clas-
siﬁer, data, and representation.

810  25th USENIX Security Symposium 

USENIX Association

4

Invariant Representation

The problem of domain adaptation outlined in the pre-
vious section is addressed by the proposed representa-
tion of bags. The new representation is calculated with a
transformation that consists of three steps to ensure that
the new representation will be invariant under scaling
and shifting of the feature values and under permutation
and size changes of the bags.

4.1 Scale Invariance
As stated in Section 3, the probability distribution of bags
from the training set can be different from the test set. In
the ﬁrst step, the representation of bags is transformed
to be invariant under scaling of the feature values. The
traditional representation X of a bag that consists of a set
of m samples {x1, . . . ,x m} can be written in a form of a
matrix:

X =

x1
...
xm

 =

x11

x12

xm1

xm2

. . .

...

. . .

x1n

xmn

 ,

(2)

where xlk denotes k-th feature value of l-th sample. This
form of representation of samples and bags is widely
used in the research community, as it is straightforward
to use and easy to compute. It is a reasonable choice in
many applications with a negligible shift in the source
and target probability distributions. However, in the net-
work security domain, the dynamics of the network en-
vironment causes changes in the feature values and the
shift becomes more prominent. As a result, the perfor-
mance of the classiﬁcation algorithms using the tradi-
tional representation is decreased.

In the ﬁrst step, the representation is improved by
making the matrix X to be invariant under scaling of the
feature values. Scale invariance guarantees that even if
some original feature values of all samples in a bag are
multiplied by a common factor, the values in the new
representation remain unchanged. To guarantee the scale
invariance, the matrix X is scaled locally onto the interval
[0,1] as follows:

˜X =

˜x11

˜xm1

. . .

...

. . .

˜x1n

˜xmn

 ˜xlk =

xlk − minl(xlk)

maxl(xlk)− minl(xlk)

(3)

4.2 Shift Invariance
In the second step, the representation is transformed to
be invariant against shifting. Shift invariance guaranties
that even if some original feature values of all samples
in a bag are increased/decreased by a given amount, the

values in the new representation remain unchanged. Let
us deﬁne a translation invariant distance function d : R×
R → R for which the following holds: d(u,v) =d (u +
a,v + a).
Let xpk, xqk be k-th feature values of p-th and q-th
sample from bag matrix X. Then the distance between
these two values will be denoted as d(xpk,xqk) = sk
pq.
The distance d(xpk,xqk) is computed for pairs of k-th
feature value for all sample pairs, ultimately forming a
so called self-similarity matrix Sk. Self-similarity matrix
is a symmetric positive semideﬁnite matrix, where rows
and columns represent individual samples and (i, j)-th
element corresponds to the distance between i-th and j-
th sample. Self-similarity matrix has been already used
thanks to its properties in several applications (e.g. in
object recognition [21] or music recording [31]). How-
ever, only a single self-similarity matrix for each bag has
been used in these approaches. This paper proposes to
compute a set of similarity matrices, one for every fea-
ture. More speciﬁcally, a per-feature set of self-similarity
matrices S = {S1,S2, . . . ,S n} is computed for each bag,
where

Sk =

sk
11

sk
12

sk
m1

sk
m2

. . .

...

. . .

sk
1m

sk
mm

 .

(4)

The element sk
pq = d(xpk,xqk) is a distance between fea-
ture values xpk and xqk of k-th feature. This means that
the bag matrix X with m samples and n features will be
represented with n self-similarity matrices of size m×m.
The matrices are further normalized by local feature scal-
ing described in Section 4.1 to produce a set of matrices
˜S .

The shift invariance makes the representation robust
to the changes where the feature values are modiﬁed by
adding or subtracting a ﬁxed value. For example, the
length of a malicious URL would change by including
an additional subdirectory in the URL path. Or, the num-
ber of transfered bytes would increase when an addi-
tional data structure is included in the communication
exchange.

4.3 Permutation and Size Invariance
Representing bags with scaled matrices { ˜X} and sets of
locally-scaled self-similarity matrices { ˜S } achieves the
scale and shift invariance. Size invariance ensures that
the representation is invariant against the size of the bag.
In highly dynamic environments, the samples may occur
in a variable ordering. Permutation invariance ensures
that the representation should also be invariant against
any reordering of rows and columns of the matrices. The
ﬁnal step of the proposed transformation is the transi-
˜S (introduced in Sec-
tion from the scaled matrices ˜X,

USENIX Association  

25th USENIX Security Symposium  811

5

tions 4.1 and 4.2 respectively) to normalized histograms.
For this purpose, we deﬁne for each bag:

k := vector of values from k-th column of matrix ˜X
zX

zS
k

:=column-wise representation of upper triangular
matrix created from matrix ˜Sk ∈ ˜S .

This means that zX

k ∈ Rm is a vector created from val-
ues of k-th feature of ˜X, while zS
k ∈ Rr,r = (m− 1)· m
2
is a vector that consists of all values of upper triangular
matrix created from matrix ˜Sk. Since ˜Sk is a symmetric
k contains
matrix with zeros along the main diagonal, zS
only values from upper triangular matrix of ˜Sk.
A normalized histogram of vector z = (z1, . . . ,z d)∈ Rd
is a function φ : Rd ×Rb+1 → Rb parametrized by edges
of b bins θ = (θ0, . . . ,θ b) ∈ Rb+1 such that φ (z;θ ) =
(φ (z;θ0,θ1), . . . ,φ (z;θb−1,θb)) where

φ (z,θi,θi+1) =

1
d

d

∑

j=1

[[z j ∈ [θi−1,θi)]]

is the value of the i-th bin corresponding to a portion of
components of z falling to the interval [θi−1,θi).
Each column k of matrix ˜X (i.e. all bag values of k-th
feature) is transformed into a histogram φ (zX
k ,θ X
k ) with
predeﬁned number of b bins and θ X
k bin edges. Such his-
tograms created from the columns of matrix ˜X will be
denoted as feature values histograms, because they carry
information about the distribution of bag feature values.
On the other hand, histogram φ (zS
k) created from
values of self-similarity matrix ˜S j ∈ ˜S will be called fea-
ture differences histograms, as they capture inner feature
variability within bag samples.

k ,θ S

Overall, each bag is represented as a concatenated fea-

ture map φ ( ˜X;

(cid:31)φ (zX

˜S ;θ ): Rn×(m+r) → R2·n·b as follows:
n)(cid:30) (5)

1), . . . ,φ (zS

n ),φ (zS

1 ,θ S

n ,θ S

n ,θ X

1 ,θ X

1 ), . . . ,φ (zX

where n is the number of the original ﬂow-based fea-
tures, m is the number of ﬂows in the bag, and b is the
number of bins. The whole transformation from input
network ﬂows to the ﬁnal feature vector is depicted in
Figure 1. As you can see, two types of invariant his-
tograms are created from values of each ﬂow-based fea-
ture. At the end, both histograms are concatenated into
the ﬁnal bag representation φ ( ˜X;

˜S ;θ ).

5 Learning Optimal Histogram Represen-

tation

˜S ;θ ) proposed in Section 4
The bag representation φ ( ˜X;
has the invariant properties, however it heavily depends
on the number of bins b and their edges θ deﬁning the

vector of flow 1

.
.
.

vector of flow N

g
a
b

flow 1

flow N

e
m
a
n
t
s
o
h
:
r
e
s
u

1

web logs

.
.
.

.
.
.

2

feature values

histogram

1
 
e
r
u
t
a
e
f

3

4

5

combined final 
feature vector

feature values

M
 
e
r
u
t
a
e
f

.
.
.
.
.
.

...

locally-scaled
self-similarity

matrix

feature

differences
histogram

...

Figure 1: Graphical illustration of the individual steps
that are needed to transform the bag (set of ﬂows with the
same user and hostname) into the proposed invariant rep-
resentation. First, the bag is represented with a standard
feature vector (1). Then feature values histograms of lo-
cally scaled feature values are computed for each feature
separately (2). Next, the locally-scaled self-similarity
matrix is computed for each feature (3) to capture inner
differences. This matrix is then transformed into feature
differences histogram (4), which is invariant on the num-
ber or the ordering of the samples within the bag. Finally,
feature values and feature differences histograms of all
features are concatenated into resulting feature vector.

width of the histogram bins. These parameters that were
manually predeﬁned in Section 4 C inﬂuence the clas-
siﬁcation performance. Incorrectly chosen parameters b
and θ leads to suboptimal efﬁcacy results. To deﬁne the
parameters optimally, we propose a novel approach of
learning these parameters automatically from the training
data in such a way to maximize the classiﬁcation separa-
bility between positive and negative samples.

k and zS

When creating histograms in Section 4 C, the input
instances are vectors zX
k , where k ∈ {1, . . . ,n}.
The algorithm transforms the input instances into a con-
˜S ;θ ). To keep the nota-
catenated histogram φ ( ˜X;
tion simple and concise, we will denote the input in-
stances simply as z = (z1, . . . ,z n) ∈ Rn×m (instead of
z = (zX
n )), which is a sequence of n
vectors each of dimension m.

1 , . . . ,z S

1 , . . . ,z X

n ,zS

The input
instance z is represented via a feature
map φ : Rn×m → Rn·b deﬁned as a concatenation of the
normalized histograms of all vectors in that sequence,
that is, φ (z;θ ) = (φ (z1;θ 1), . . . ,θ (zn;θ n)), where θ =
(θ 1, . . . ,θ n) denotes bin edges of all normalized his-
tograms stacked to a single vector.
We aim at designing a classiﬁer h: Rn×m × Rn+1 ×
Rn(b+1) → {−1, +1} working on top of the histogram
representation, that is

812  25th USENIX Security Symposium 

USENIX Association

6

h(z;w,w0,θ ) =sign((cid:31)φ (z,w)(cid:30) + w0)
= sign(cid:31) n
∑

φ (zi,θi, j−1,θi, j)wi, j + w0(cid:30) .

∑

j=1

i=1

b

(6)

The classiﬁer (6) is linear in the parameters (w,w0) but
non-linear in θ and z. We are going to show how to learn
parameters (w,w0) and implicitly also θ via a convex op-
timization.

Assume we are given a training set of examples
{(z1,y1), . . . ,(z m,ym)} ∈ (Rn×m × {+1,−1})m. We ﬁx
the representation φ such that the number of bins b is
sufﬁciently large and the bin edges θ are equally spaced.
We ﬁnd the weights (w,w0) by solving

w∈Rb·p,w0∈R(cid:29)γ

min

+

1
m

n

∑

i=1
m

∑

i=1

b−1
∑
j=1|wi, j − wi, j+1|

max(cid:28)0,1− yi(cid:31)φ (zi;θ ),w(cid:30)}(cid:27) .

(7)

The objective is a sum of two convex terms. The second
term is the standard hinge-loss surrogate of the training
classiﬁcation error. The ﬁrst term is a regularization en-
couraging weights of neighboring bins to be similar. If
it happens that j-th and j + 1 bin of the i-the histogram
have the same weight, wi, j = wi, j+1 = w, then these bins
can be effectively merged to a single bin because
wi, jφ (zi;θi, j−1,θi, j) +w i, j+1φ (zi;θi, j,θi, j+1)

= 2wφ (zi;θi, j−1,θi, j+1) .

(8)
The trade-off constant γ > 0 can be used to control the
number of merged bins. A large value of γ will result
in massive merging and consequently in a small number
of resulting bins. Hence the objective of the problem (7)
is to minimize the training error and to simultaneously
control the number of resulting bins. The number of bins
inﬂuences the expressive power of the classiﬁer and thus
also the generalization of the classiﬁer. The optimal set-
ting of λ is found by tuning its value on a validation set.
Once the problem (7) is solved, we use the result-
ing weights w∗ to construct a new set of bin edges θ∗
such that we merge the original bins if the neighboring
weights have the same sign (i.e. if w∗i, jw∗i, j+1 > 0). This
implies that the new bin edges θ∗ are a subset of the orig-
inal bin edges θ, however, their number can be signiﬁ-
cantly reduced (depending on γ) and they have different
widths unlike the original bins. Having the new bins de-
ﬁned, we learn a new set of weights by the standard SVM
algorithm

w∈Rn,w0∈R(cid:29) λ

min

2 (cid:21)w(cid:21)2 +

1
m

m

∑

i=1

max(cid:28)0,1− yi(cid:31)φ (zi;θ∗),w(cid:30)}(cid:27) .

7

Malicious Bag - Sality v1

Malicious Bag - Sality v2

hxxp://sevgikresi.net/logof.gif?8134c8=846765
hxxp://sevgikresi.net/logof.gif?25aa74=22216212
hxxp://sevgikresi.net/logof.gif?4fa0c=1630780
hxxp://sevgikresi.net/logof.gif?a1d1c8=42420000
hxxp://sevgikresi.net/logof.gif?87ddc=1788312

hxxp://brucegarrod.com/images/logos.gif?645ed3=65778750
hxxp://brucegarrod.com/images/logos.gif?64647e=59213934
hxxp://brucegarrod.com/images/logos.gif?23dfd3=11755295
hxxp://brucegarrod.com/images/logos.gif?3a7d2=1916560
hxxp://brucegarrod.com/images/logos.gif?3b54a=1944144

(45, 47, 45, 47, 45)
(45, 47, 45, 47, 45)

(55, 55, 55, 53, 53)

1

2

3

hF

3

2.5

2

1.5

1

0.5

0
-0.2

h F

3

2.5

2

1.5

1

0.5

0

0.2

0.4

0.6

0.8

1

1.2

0
-0.2

0

0.2

0.4

0.6

0.8

1

h S

3

2.5

2

1.5

1

0.5

0
-0.2

0

0.2

0.4

0.6

0.8

1

h S

3

2.5

2

1.5

1

0.5

0
-0.2

0

0.2

0.4

0.6

0.8

1

4

(0.6, 0, 0, 0.4, 0.4, 0, 0, 0.6)

(0.4, 0, 0, 0.6, 0.4, 0, 0, 0.6)

Figure 2: Illustration of the proposed representation ap-
plied on two versions of malware Sality. First, two bags
of ﬂows are created (1), one bag for each Sality sample.
Next, ﬂow-based feature vectors are created for each bag
(2). For illustrative purposes, only a single feature is used
In the third step, histograms of feature
- URL length.
values φ (zX
k ,θ X
k ) and feature differences φ (zS
k) are
created (3) as described in Section 4.3. Only four bins
for each histogram were used. Finally, all histograms
are concatenated into the ﬁnal feature vector (4). Even
though the malware samples are from two different ver-
sions, they have the same histogram of feature differ-
ences φ (zS
k ) is not invariant against
shift, you can see that half of the values of φ (zX
k ) are
different. Still, φ (zX
k ) values may play an important
role when separating malware samples from other legiti-
mate trafﬁc.

k). Since φ (zX

k ,θ S

k ,θ S

k ,θ X

k ,θ X

k ,θ X

Note that we could add the quadratic regularizer λ
2 (cid:21)w(cid:21)2
to the objective of (7) and learn the weights and the rep-
resentation in a single stage. However, this would re-
quire tuning two regularization parameters (λ and γ) si-
multaneously which would be order of magnitude more
expensive than tuning them separately in the two stage
approach.

6 Malware Representation Example

This Section illustrates how the proposed representation
(nonoptimized version) is calculated for two real-world
examples of malicious behavior. Namely, two versions
of a polymorphic malware Sality are compared. Sality
[13] is a malware family that has become a dynamic and
complex form of malicious infection.
It utilizes poly-
morphic techniques to infect ﬁles of Widows machines.
Signature-based systems or classiﬁers trained on a spe-
ciﬁc malware type often struggles with detecting new
variants of this kind of malware. Note that most of the
conclusions to the discussion that follows can be drawn
for many other malware threats.

USENIX Association  

25th USENIX Security Symposium  813

Figure 2 shows how the two Sality samples are repre-
sented with the proposed approach. First, the input ﬂows
are grouped into two bags (one bag for each Sality sam-
ple), because all ﬂows of each bag have the same user and
the same hostname (1). For the sake of simplicity, only
URLs of the corresponding ﬂows are displayed. Next,
88 ﬂow-based feature vectors are computed for each bag
(2). To simplify illustration, we use only a single fea-
ture – URL length. After this step, each Sality sample
is represented with one feature vector of ﬂow-based val-
ues. Existing approaches use these vectors as the input
for the subsequent detection methods. As we will show
in Section 7, these feature values are highly variable for
malware categories. Classiﬁcation models trained with
such feature values loose generalization capability.

k ,θ X

k ,θ X

k ,θ X

k ,θ S

k ) and feature differences φ (zS

To enhance the robustness of the ﬂow-based features,
the proposed approach computes histograms of feature
values φ (zX
k) (3)
as described in Section 4.3. To make the illustration sim-
ple, only four bins for each histogram were used. Finally,
all histograms are concatenated into the ﬁnal feature vec-
tor (4).
It can be seen that even though the malware
samples are from two different versions, they have the
same histogram of feature differences φ (zS
k). Since
the histogram of feature values φ (zX
k ) is not invariant
against shift, half of the values of φ (zX
k ) are different.
The number of histogram bins and their sizes are then
learned from the data by the proposed algorithm (see
Section 5). The proposed representation describes inner
dynamics of ﬂows from each bag, which is a robust indi-
cator of malware samples, as we will show in the analy-
sis of various malware families in Section 8. In contrast
to the existing methods that use ﬂow-based features or
general statistics such as mean or standard deviation, the
proposed representation reﬂects properties that are much
more difﬁcult for an attacker to evade detection.

k ,θ S

7 Evasion Possibilities

This section discusses evasion options for an attacker
when trying to evade a learning-based classiﬁcation sys-
tem. According to the recent work [35], the essential
components for an evasion are: (1) the set of features
used by the classiﬁer, (2) the training dataset used for
training, (3) the classiﬁcation algorithm with its parame-
ters. Without the knowledge of the features, the attacker
is faced with major challenges and there is not any known
technique for addressing them [35].

Acquire knowledge of classiﬁcation algorithm with its
parameters or the training data is hard if not impossi-
ble. Therefore, in the following analysis, we assume that
only the features are known to the attacker. When clas-
sifying HTTP trafﬁc from proxy logs, it is actually not
difﬁcult to create a set of common features widely used

in practice. These features are the baseline ﬂow-based
features, such as those described in Table 3. When the
attacker performs a mimicry attack, selected features of
malicious ﬂows are modiﬁed to mimic legitimate trafﬁc
(or ﬂows marked as benign by the classiﬁer).

In the following, we will analyze the case when the
attacker performs a mimicry attack to evade detection
by modifying ﬂow attributes, such as URLs, bytes, and
inter-arrival times. Other ﬂow attributes can be altered in
a similar way with analogical results. All modiﬁcations
are divided into two groups, depending on whether the
proposed representation is invariant against them.

The proposed representation is invariant to the follow-

ing changes.

• Malicious code, payload, or obfuscation – The ad-
vantage of all network-based security approaches is
that they extract features from headers of network
communication rather than from the content. As
a result, any changes to the payload including the
usage of pluggable transports designed to bypass
Deep Packet Inspection (DPI) devices will have no
effect on the features. Some pluggable transports
(e.g. ScrambleSuit) are able to change its net-
work ﬁngerprint (packet length distribution, num-
ber of bytes, inter-arrival times, etc.). Since the pro-
posed representation mainly relies on the dynamics
of URLs of ﬂows in the bag, such changes will not
negatively impact the efﬁcacy, which is a great ad-
vantage against DPI devices.

• Server or hostname – The representation operates
at the level of bags, where each bag is a set of ﬂows
with the same user and hostname/domain. If an at-
tacker changes an IP address or a hostname of the
remote server (because the current one has been
blacklisted), the representation will create a new
bag with similar feature values as in the previous
bag with the original IP address or hostname, which
is a great advantage against feeds and blacklists that
need to be updated daily and are always behind.

• URL path or ﬁlename – Straightforward and easy
way of evading existing classiﬁers using ﬂow-based
features or URL patterns is the change in path or
ﬁlename from sample to sample. Since the variabil-
ity of these features remains constant within each
bag, these changes will also have no effect on the
proposed representation.

• Number of URL parameters, their names or val-
ues – This is an alternative to URL path changes.
• Encoded URL content – Hiding information in the
URL string represents another way to exﬁltrate sen-
sitive data. When the URL is encrypted and en-
coded (e.g. with base64), it changes the URL length

814  25th USENIX Security Symposium 

USENIX Association

8

and may globally inﬂuence other features as well.
As the proposed representation is invariant against
shifting, changing the URL length will not change
the histograms of feature differences.

• Number of ﬂows – Another option for an attacker
to hide in the background trafﬁc is increasing or re-
ducing the number of ﬂows related to the attack.
Such modiﬁcation of the attack does not affect the
representation, as long as there are enough ﬂows to
create the feature vectors.

• Time intervals between ﬂows – This feature has
been used in many previous approaches for its de-
scriptive properties.
It is an alternative way to
the proposed representation how to model a rela-
tionship between individual ﬂows. Our analysis
revealed that current malware samples frequently
modify the inter-arrival time to remain hidden in the
background trafﬁc – see Figure 3 for details. There-
fore, we do not rely on this unstable feature that can
be also inﬂuenced by network delays or failures.

• Ordering of ﬂows – An attacker can easily change
the ordering of ﬂows to evade detection based on
patterns or predeﬁned sequences of ﬂows. For the
proposed representation the ordering of ﬂows does
not matter.

The proposed representation is not invariant to the fol-

lowing changes.

• Static behavior – The representation does not
model malware behaviors, where all ﬂows associ-
ated with a malware are identical. Such behavior
has no dynamics and can be classiﬁed with ﬂow-
based approaches with comparable results. In our
dataset, only 10% of ﬂows were removed because
of this constrain.

• Multiple behaviors in a bag – In case more behav-
iors are associated with a bag, such as when a target
hostname is compromised and communicates with
a user with legitimate and malicious ﬂows at once,
the representation does not guarantee the invariance
against the attacker’s changes. Such bags contain a
mixture of legitimate and malicious ﬂows and their
combination could lead to a different representation.
Note that there wasn’t any malware sample in our
data that would satisfy this condition, since the le-
gitimate trafﬁc has to be authentic (not artiﬁcially
injected) to confuse the representation.

Category

Training Positives
Click-fraud mw
DGA malware
Dridex
IntallCore
Monetization
Mudrop
Poweliks
Zeus
Testing Positives
Training Negatives
Testing Negatives

Samples

Signatures

Flows
132,756
12,091
8,629
8,402
17,317
3,107
37,142
11,648
34,420
43,380
862,478
15,379,466

Bags
5,011
819
397
264
1,332
135
701
132
1,275
2,090
26,825
240,549

Recall
0.15
0.29
0.58
0.12
0.00
0.00
0.00
0.00
0.19
0.02

Table 2: Number of ﬂows and bags of malware cate-
gories and legitimate background trafﬁc used for train-
ing and testing the proposed representation and classiﬁer.
Right-most column shows the amount of bags that were
found and blocked by an existing signature-based device.
Majority of the malicious bags from the test were missed,
as the device, relying on a static database of signatures,
was not able to catch evolving versions and new types of
the malicious behaviors.

of ﬂow-based features can be used, which reduces
the discriminative properties of the representation.
However, majority of malware communication is
still over HTTP protocol, because switching to
HTTPS would harm the cyber-criminals’ revenues
due to problems with signed certiﬁcates [18].

• Real-time changes and evolution – In case a mal-
ware sample for a given user and hostname would
start changing its behavior dynamically and fre-
quently, the bag representation will vary in time.
Such inconsistency would decrease the efﬁcacy re-
sults and enlarge the time to detect. However, creat-
ing such highly dynamic malware behavior requires
a considerable effort, therefore we do not see such
samples very often in the real network trafﬁc.

We conclude our analysis with the observation, that
attackers change ﬂow features very frequently (see Fig-
ure 3). The goal of the proposed representation is to be
invariant against most of the changes to successfully de-
tect new, previously unseen malware variants.

8 Experimental Evaluation

• Encrypted HTTPS trafﬁc – Most features pre-
sented in this paper are computed from URLs or
other ﬂow ﬁelds, that are not available in encrypted
HTTPS trafﬁc.
In this case, only a limited set

The proposed approach was deployed on the top of proxy
logs exporters in companies of various types and sizes
to detect unseen malware samples. The system archi-
tecture is shown in Figure 4. Collector connected to a

USENIX Association  

25th USENIX Security Symposium  815

9

s
e
i
r
o
g
e

t

 

a
C
e
r
a
w
a
M

l

Normalized Entropy of Feature Values for 32 Malware Categories

5

10

15

20

25

30

1

2

3

4

5

6

7
8
Features

9

10

11

12

13

14

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

Figure 3: Flow-based features (columns) are chang-
ing for most of the malware categories (rows). The
ﬁgure uses normalized entropy to show the variability
of each feature within each malware category. Yellow
color denotes that the feature value is changed very of-
ten, while blue color means that the feature has the
same values for all samples of the given category. Fea-
tures: 1-URL, 2-interarrival time, 3-URL query values,
4-URL path, 5-number of ﬂows, 6-number of down-
loaded bytes, 7-server IP address, 8-hostname, 9-URL
path length, 10-URL query names, 11-ﬁlename, 12-
ﬁlename length, 13-number of URL query parameters,
14-number of uploaded bytes. Malware categories:
1-Click-fraud (amz), 2-Asterope family 1, 3-Asterope
family 2, 4-Beden, 5-Click-fraud, 6-DGA, 7-Dridex, 8-
Exﬁltration, 9-InstallCore, 10-Mudrop Trojan Dropper,
11-Monetization, 12-Zeus, 13-Mudrop, 14-MultiPlug,
15-mixture of unknown malware, 16-Click-fraud (track-
ing), 17-Poweliks family 1, 18-Poweliks family 2, 19-
Qakbot Trojan, 20-Rerdom Trojan, 21-Ramnit worm,
22-RVX, 23-Sality, 24-Threats related to a trafﬁc direc-
tion system (TDS) 1, 25-TDS 2, 26-TDS 3, 27-Tinba
Trojan, 28-C&C tunneling, 29-Upatre, 30-Vawtrak, 31-
Vittalia, 32-Zbot. Details about the malware categories
are given in Section 8.

proxy server stores incoming and outgoing network traf-
ﬁc in form of proxy log records. The proxy logs represent
information about individual HTTP/HTTPS connections
or ﬂows. Each 5-minute interval, the proxy logs are sent
to the detection engine, where the proposed method de-
tects the malicious behaviors. Report created from the
malicious behaviors is then displayed on a console to an
operator. The next section provides the speciﬁcation of
datasets and malware categories, followed by the results
from the experimental evaluation. Next section provides
the speciﬁcation of datasets and malware categories, fol-
lowed by the results from the experimental evaluation.

8.1 Speciﬁcation of the Datasets
The data was obtained from several months (January -
July 2015) of real network trafﬁc of 80 international

Collector

(Proxy Logs)

Detection

Engine

Reporting
Console

Public IPs

Internet

Intranet (LAN)

Firewall

Proxy Server

Figure 4: Overview of the system architecture. Collector
connected to a proxy server stores incoming and outgo-
ing network trafﬁc in form of proxy log records. Each
5-minute interval, the proxy logs are sent to the detec-
tion engine and the results are displayed to an operator
on the reporting console.

companies of various sizes in form of proxy logs [26].
The logs contain HTTP/HTTPS ﬂows, where one ﬂow is
one connection deﬁned as a group of packets from a sin-
gle host and source port with a single server IP address,
port, and protocol. Summary of the datasets used in the
evaluation is described in Table 2.

Malware samples will be referred as positive bags,
where one positive bag is a set of records (connections)
with the same source towards the same destination. The
bags not labeled as malicious are considered as legiti-
mate/negative. Each bag should contain at least 5 ﬂows
to be able to compute a meaningful histogram representa-
tion. Training dataset contains 5k malicious (8 malware
families) and 27k legitimate bags, while testing dataset
is consist of 2k malicious ((cid:31) 32 malware families) and
241k legitimate bags (more than 15 million ﬂows). Posi-
tive samples for training were acquired using many types
of publicly available feeds, services, and blacklists, while
the results on the testing data were analyzed manually by
security experts. Each HTTP ﬂow consists of the follow-
ing ﬁelds: user name, srcIP, dstIP, srcPort, dstPort, pro-
tocol, number of bytes, duration, timestamp, user agent,
and URL. From these ﬂow ﬁelds, we extracted 115 ﬂow-
based features typically used in the prior art (Table 3).

This means that training and testing data are com-
posed of completely different malware bags from dif-
ferent malware families, which makes the classiﬁcation
problem much harder. This scenario simulates the fact
that new types of threats are created to evade detection.
The benchmarking signature-based network security de-
vice (widely used in many companies) was able to de-
tect only 2% of the malicious bags from the testing set.
Training a classiﬁer for each category separately is an
easier task, however such classiﬁers are typically over-
ﬁtted to a single category and cannot detect further vari-
ations without retraining.

816  25th USENIX Security Symposium 

USENIX Association

10

80

60

40

20

0

-20

-40

-60

2

 

i

n
o
s
n
e
m
D

i

Projection of Feature Vectors of the Flow-Based Representation into 2D

Legitimate
Malicious

2

 

i

n
o
s
n
e
m
D

i

Projection of Feature Vectors of the Proposed Representation into 2D

Malicious
Legitimate

50

40

30

20

10

0

-10

-20

-30

-40

-80

-100

-80

-60

-40

-20

0

Dimension 1

20

40

60

80

100

-50

-60

-40

-20

0
20
Dimension 1

40

60

80

Figure 5: Graphical projection of feature vectors of the
baseline ﬂow-based representation into two dimensions
using t-SNE transformation. Feature vectors from 32
different malware categories are displayed. Due to high
variability of ﬂow-based feature values, legitimate and
malicious samples are scattered without any clear sep-
aration. The results show that the ﬂow-based represen-
tation is suitable for training classiﬁers specialized on a
single malware category, which often leads to classiﬁers
with high precision and low recall.

Figure 6: Graphical projection of feature vectors of the
proposed representation into two dimensions using t-
SNE transformation. Thanks to the invariant properties,
malicious bags from various categories are grouped to-
gether, as they have similar dynamics modeled by the
representation. Most of the legitimate bags are concen-
trated on the left-hand side, far from the malicious bags.
This shows that training a classiﬁer with the proposed
representation will achieve higher recall with compara-
ble precision.

Features applied on URL, path, query, ﬁlename
length; digit ratio
lower/upper case ratio; ratio of digits
vowel changes ratio
ratio of a character with max occurrence
has a special character
max length of consonant/vowel/digit stream
number of non-base64 characters
has repetition of parameters
Other Features
number of bytes from client to server
number of bytes from server to client
length of referer/ﬁle extension
number of parameters in query
number of ’/’ in path/query/referer

Table 3: List of selected ﬂow-based features extracted
from proxy logs. We consider these features as base-
line (as some features were used in previously published
work), and compare it with the proposed representation.

Table 4 from Appendix A describes an important fact
about the URLs from individual malicious bags. As you
can see, URLs within each malicious bag are similar to
each other (as opposed to most of legitimate bags). This
small non-zero variability of ﬂow-based feature values is
captured by the proposed representation using both types
of histograms. The variability is very general but also

descriptive feature, which increases the robustness of the
representation to further malware changes and variants.

8.2 Evaluation on Real Network Trafﬁc
This section shows the beneﬁts of the proposed approach
of learning the invariant representation for two-class
classiﬁcation problem in network security. Feature vec-
tors described in Section 8.1 correspond to input feature
vectors {x1, . . . ,x m} deﬁned in Section 3. These vectors
are transformed into the proposed representation of his-
˜S ;θ ), as described in Section 4. We have
tograms φ ( ˜X;
evaluated two types of invariant representations. One
with predeﬁned number of equidistant bins (e.g. 16, 32,
etc.) computed as described in Section 4, and one when
the representation is learned together with the classiﬁer
to maximize the separability between malicious and le-
gitimate trafﬁc (combination of Section 4 and 5). For the
representation learning, we used 256 bins as initial (and
most detailed) partitioning of the histograms. During the
learning phase, the bins were merged together, creating
12.7 bins per histogram on average.

Both approaches are compared with the baseline ﬂow-
based representation used in previously published work,
where each sample corresponds to a feature vector com-
puted from one ﬂow. Results of a widely used signature-
based security device are also provided (see Table 2)
to demonstrate that the positive samples included in the
evaluation pose a real security risk, as majority of them

USENIX Association  

25th USENIX Security Symposium  817

11

lambda=0.00010, trnerr=2.4%, tsterr=14.8%

lambda=0.01000, trnerr=10.4%, tsterr=13.5%

feature x

y
 

e
r
u

t

a
e

f

y
 
e
r
u
t
a
e
f

t

i

h
g
e
w

2
1.5
1
0.5
0
-0.5
-1
-1.5
-2

1

0.5

0

t

i

h
g
e
w

50

100 150 200 250 300 350 400

feature

feature x

-0.5

-1

50

100 150 200 250 300 350 400

feature

Figure 7: Visualization of the proposed method of learn-
ing the invariant representation on 2-dimensional syn-
thetic data. Figures in the left row show the decision
boundaries of two class classiﬁer learned from the bins
for two different values of parameter λ (0.0001, 0.01)
which controls the number of emerging bins (the corre-
sponding weights are shown in the right row). With in-
creasing λ the data are represented with less bins and the
boundary becomes smoother and less over-ﬁtted to the
training data.

was not detected. Maximum number of ﬂows for each
bag was 100, which ensures that the computational cost
is controlled and does not exceed predeﬁned limits.

Two-dimensional projection of the feature vectors for
the ﬂow-based and the proposed representation is illus-
trated in Figures 5 and 6 respectively. Bags from 32 mali-
cious categories are displayed with red circles, while the
legitimate bags are denoted with green circles. The pro-
jections show that the ﬂow-based representation is suit-
able for training classiﬁers specialized on a single mal-
ware category. In case of the proposed representation,
malicious bags from various categories are grouped to-
gether and far from the legitimate trafﬁc, which means
that the classiﬁers will have higher recall and compara-
ble precision with the ﬂow-based classiﬁers.

Next, we will show the properties of the proposed
method of learning the representation to maximize the
separation between positive and negative samples (see
Section 5 for details). Figure 7 visualizes the proposed
method on synthetic 2-dimensional input data. The input
2D point (x,y) ∈ R2 is represented by 4-dimensional fea-
ture vector (x2,y2,x + y,x− y). Each of the 4 features is
then represented by a histogram with 100 bins (i.e. each
feature is represented by 100 dimensional binary vector
will all zeros but a single one corresponding to the active
bin). Figures in the top row show the decision bound-
aries of two-class classiﬁers learned from data. The bot-

found 130 bins

0.15

0.1

0.05

0

l

e
u
a
v
 
t

-0.05

i

h
g
e
w

-0.1

-0.15

-0.2

50

100

150

200

250

Figure 8: Weights (blue bars) and derived bins of a his-
togram (red line) for a standard SVM and one of the in-
variant features. Since the bins are equidistant and pre-
deﬁned at the beginning, the resulting histogram (deﬁned
by the red line) has complicated structure, leading most
probably to complex boundary and over-ﬁtted results (as
shown in Figure 7 on the left hand side).

found 18 bins

l

e
u
a
v
 
t

i

h
g
e
w

0.4
0.3
0.2
0.1
0
-0.1
-0.2
-0.3
-0.4

50

100

150

200

250

Figure 9: Weights (blue bars) and derived bins of a his-
togram (red line) for the proposed bin optimization. In
this case, the weights show a clear structure and the de-
rived histogram has only 18 bins. The decision boundary
is in this case smoother and the classiﬁer trained from
this representation will be more robust. Green dashed
lines also show how the histogram bins would look like
if they are positioned equidistantly (16 bins).

tom row shows the weights of the linear classiﬁer corre-
sponding to the bins (in total 400 weights resulting from
100 bins for each out of 4 features). The columns corre-
spond to the results obtained for different setting of the
parameter λ which controls the number of emerging bins
and thus also the complexity of the decision boundary.
With increasing λ the data are represented with less bins
and the boundary becomes smoother. Figure 7 shows the
principle of the proposed optimization process. The bins
of the representation are learned in such a way that it
is much easier for the classiﬁer to separate negative and
positive samples and at the same time control the com-

818  25th USENIX Security Symposium 

USENIX Association

12

feature indexfeature indexe
t
a
R
 
e
v
i
t
i
s
o
P
 
e
u
r
T

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

ROC Curve for Test Data

flow-based
bag mean
bag variance
bag combined
optimized bag combined

ROC Curve for Test Data - Log Scale

flow-based
bag mean
bag variance
bag combined
optimized bag combined

1

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

t

 

e
a
R
e
v
i
t
i
s
o
P
e
u
r
T

 

0

0.2

0.4
0.6
False Positive Rate

0.8

1

0
10-5

10-4

10-3
10-2
False Positive Rate

10-1

100

Figure 10: ROC curves of SVM classiﬁer on test data for ﬁve types of representations (logarithmic scale on the right).
Flow-based representation shows very unsatisfactory results showing that ﬂow-based approach cannot be applied in
practice to detect unseen malware variants. The combination of feature values with feature differences histogram (bag
combined) led to signiﬁcantly better efﬁcacy results. These results were further exceeded when the parameters of the
invariant representation were learned automatically from the training data (optimized bag combined).

plexity of the classiﬁer.

Figures 8 and 9 show the bins and weights learned
from the training set of real network trafﬁc. The blue ver-
tical lines represent learned weights associated with 256
bins of a histogram computed on a single input feature.
The red lines show new bins derived from the weights by
merging those neighboring bins which have the weights
with the same sign. Figure 8 shows the weights and the
derived bins for a standard SVM which has no incentive
to have similar weights. The histogram derived from the
SVM weights reduces the number of bins from 256 to
130. Figure 9 shows the results for the proposed method
which enforces the similar weights for neighboring bins.
In this case, the weights exhibit a clear structure and the
derived histogram has only 18 bins. The decision bound-
ary is in this case smoother and the classiﬁer trained from
this representation will be more robust.

k ,θ X

Next, a two-class SVM classiﬁer was evaluated on ﬁve
representations: baseline ﬂow-based, per-feature his-
tograms of values φ (zX
k ) (bag mean), per-feature his-
tograms of feature differences φ (zS
k) (bag variance),
the combination of both (bag combined), and the combi-
nation of both with bin optimization (optimized bag com-
bined). The training and testing datasets were composed
of bags described in Table 2.

k ,θ S

The results on testing data are depicted in Figure 10.
Note that positive bags in the testing set are from dif-
ferent malware categories than bags from the training
set, which makes the classiﬁcation problem much harder.
The purpose of this evaluation is to compare ﬂow-based
representation, which is used in most of previously pub-
lished work, with the proposed invariant representation.
Flow-based representation shows very unsatisfactory re-
sults, mainly due to the fact that the classiﬁer was based
only on the values of ﬂow-based features that are not

i

i

n
o
s
c
e
r
P

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1

Precision-Recall Curve for Testing Data

bag combined (256 bins)
bag combined (128 bins)
bag combined (64 bins)
bag combined (16 bins)
bag combined (8 bins)
optimized bag combined
0.1

0.2

0.3

0

0.4

0.5
Recall

0.6

0.7

0.8

0.9

1

Figure 11: Precision-recall curve of SVM classiﬁer
trained on the proposed representation with different
number of histogram bins for each feature. All classiﬁers
are outperformed by the classiﬁer, where the parameters
of the invariant representation are learned automatically
from the data (optimized bag combined). The classiﬁer
achieved 90% precision (9 of 10 alerts were malicious)
and 67% recall on previously unseen malware families.

robust across different malware categories (as shown in
Section 7). The classiﬁer based on combined bag rep-
resentation performed signiﬁcantly better. These results
were further exceeded when the parameters of the invari-
ant representation were learned automatically from the
training data (optimized bag combined), which is shown
in Figure 10 with logarithmic scale.

Precision-recall curve is depicted in Figure 11 to com-
pare the efﬁcacy results of classiﬁers based on the pro-
posed representation with predeﬁned number of bins per
feature (8, 16, 64, 128, and 256 bins) with the same rep-
resentation, but when the parameters are learned from the
training data (using bin optimization from Section 5).

USENIX Association  

25th USENIX Security Symposium  819

13

Overall, the results show the importance of combin-
ing both types of histograms introduced in Section 4 to-
gether, allowing the representation to be more descrip-
tive and precise without sacriﬁcing recall. But most im-
portantly, when the parameters of the representation are
trained to maximize the separability between malicious
and legitimate samples, the resulting classiﬁer performs
in order of a magnitude better than a classiﬁer with man-
ually predeﬁned parameters.

9 Conclusion

This paper proposes a robust representation suitable for
classifying evolving malware behaviors. It groups sets
of network ﬂows into bags and represents them using a
the combination of invariant histograms of feature val-
ues and feature differences. The representation is de-
signed to be invariant under shifting and scaling of the
feature values and under permutation and size changes
of the bags. The proposed optimization method learns
the parameters of the representation automatically from
the training data, allowing the classiﬁers to create robust
models of malicious behaviors capable of detecting pre-
viously unseen malware variants and behavior changes.
The proposed representation was deployed on corpo-
rate networks and evaluated on real HTTP network traf-
ﬁc with more than 43k malicious samples and more than
15M samples overall. The comparison with a baseline
ﬂow-based approach and a widely-used signature-based
web security device showed several key advantages of
the proposed representation. First, the invariant proper-
ties of the representation result in the detection of new
types of malware. More speciﬁcally, the proposed clas-
siﬁer trained on the optimized representation achieved
90% precision (9 of 10 alerts were malicious) and de-
tected 67% of malware samples of previously unseen
types and variants. Second, multiple malware behav-
iors can be represented in the same feature space while
current ﬂow-based approaches necessitate training a sep-
arate detector for each malware family. This way, the
proposed system considerably increases the capability of
detecting new variants of threats.

References
[1] Cisco netﬂow. http://www.cisco.com/warp/public/732/tech/netﬂow.
[2] ANTONAKAKIS, M., PERDISCI, R., NADJI, Y., VASILOGLOU,
N., ABU-NIMEH, S., LEE, W., AND DAGON, D. From throw-
away trafﬁc to bots: Detecting the rise of dga-based malware. In
Proceedings of the 21st USENIX Conference on Security Sympo-
sium (Berkeley, CA, USA, 2012), Security’12, USENIX Associ-
ation, pp. 24–24.

[3] BAILEY, M., OBERHEIDE, J., ANDERSEN, J., MAO, Z., JAHA-
NIAN, F., AND NAZARIO, J. Automated classiﬁcation and anal-
ysis of internet malware. In Recent Advances in Intrusion Detec-
tion, C. Kruegel, R. Lippmann, and A. Clark, Eds., vol. 4637 of

Lecture Notes in Computer Science. Springer Berlin Heidelberg,
2007, pp. 178–197.

[4] BEN-DAVID, S., BLITZER, J., CRAMMER, K., PEREIRA, F.,
ET AL. Analysis of representations for domain adaptation. Ad-
vances in neural information processing systems 19 (2007), 137.

[5] BERNAILLE, L., TEIXEIRA, R., AKODKENOU, I., SOULE, A.,
AND SALAMATIAN, K. Trafﬁc classiﬁcation on the ﬂy. ACM
SIGCOMM ’06 36, 2 (Apr. 2006), 23–26.

[6] BILGE, L., BALZAROTTI, D., ROBERTSON, W., KIRDA, E.,
AND KRUEGEL, C. Disclosure: Detecting botnet command and
control servers through large-scale netﬂow analysis. In Proceed-
ings of the 28th Annual Computer Security Applications Confer-
ence (New York, NY, USA, 2012), ACSAC ’12, ACM, pp. 129–
138.

[7] BLITZER, J., MCDONALD, R., AND PEREIRA, F. Domain adap-
tation with structural correspondence learning. In Proceedings of
the 2006 conference on empirical methods in natural language
processing (2006), Association for Computational Linguistics,
pp. 120–128.

[8] CHANDOLA, V., BANERJEE, A., AND KUMAR, V. Anomaly
detection: A survey. ACM Comput. Surv. 41 (July 2009), 15:1–
15:58.

[9] CHOI, H., ZHU, B. B., AND LEE, H. Detecting malicious web
links and identifying their attack types. In Proceedings of the 2Nd
USENIX Conference on Web Application Development (Berkeley,
CA, USA, 2011), WebApps’11, USENIX Association, pp. 11–
11.

[10] DAI, W., YANG, Q., XUE, G.-R., AND YU, Y. Boosting for
transfer learning. In Proceedings of the 24th international con-
ference on Machine learning (2007), ACM, pp. 193–200.

[11] DUAN, L., TSANG, I. W., AND XU, D. Domain transfer mul-
tiple kernel learning. Pattern Analysis and Machine Intelligence,
IEEE Transactions on 34, 3 (2012), 465–479.

[12] ERMAN, J., ARLITT, M., AND MAHANTI, A. Trafﬁc classiﬁ-
cation using clustering algorithms. In Proceedings of the 2006
SIGCOMM Workshop on Mining Network Data (New York, NY,
USA, 2006), MineNet ’06, ACM, pp. 281–286.

[13] FALLIERE, N. Sality: Story of a peer-to-peer viral network. Rap-

port technique, Symantec Corporation (2011).

[14] GRETTON, A., SMOLA, A., HUANG, J., SCHMITTFULL, M.,
BORGWARDT, K., AND SCH ¨OLKOPF, B. Covariate shift by ker-
nel mean matching. Dataset shift in machine learning 3, 4 (2009),
5.

[15] GRIFFIN, K., SCHNEIDER, S., HU, X., AND CHIUEH, T.-C.
Automatic generation of string signatures for malware detec-
tion. In Proceedings of the 12th International Symposium on Re-
cent Advances in Intrusion Detection (Berlin, Heidelberg, 2009),
RAID ’09, Springer-Verlag, pp. 101–120.

[16] GU, G., PERDISCI, R., ZHANG, J., LEE, W., ET AL. Botminer:
Clustering analysis of network trafﬁc for protocol-and structure-
independent botnet detection.
In USENIX Security Symposium
(2008), vol. 5, pp. 139–154.

[17] HUANG, H., QIAN, L., AND WANG, Y. A svm-based technique
Information Technology Journal 11, 7

to detect phishing urls.
(2012), 921–925.

[18] INVERNIZZI, L., MISKOVIC, S., TORRES, R., SAHA, S., LEE,
S., MELLIA, M., KRUEGEL, C., AND VIGNA, G. Nazca: De-
tecting malware distribution in large-scale networks. In Proceed-
ings of the Network and Distributed System Security Symposium
(NDSS) (2014).

820  25th USENIX Security Symposium 

USENIX Association

14

[34] RIECK, K., HOLZ, T., WILLEMS, C., DSSEL, P., AND LASKOV,
P. Learning and classiﬁcation of malware behavior.
In Detec-
tion of Intrusions and Malware, and Vulnerability Assessment,
D. Zamboni, Ed., vol. 5137 of Lecture Notes in Computer Sci-
ence. Springer Berlin Heidelberg, 2008, pp. 108–125.

[35] RNDIC, N., AND LASKOV, P. Practical evasion of a learning-
based classiﬁer: A case study. In Security and Privacy (SP), 2014
IEEE Symposium on (May 2014), pp. 197–211.

[36] SCARFONE, K., AND MELL, P. Guide to intrusion detection
and prevention systems ( idps ) recommendations of the national
institute of standards and technology. Nist Special Publication
800, 94 (2007).

[37] SHIMODAIRA, H. Improving predictive inference under covari-
ate shift by weighting the log-likelihood function. Journal of sta-
tistical planning and inference 90, 2 (2000), 227–244.

[38] SONG, D., BRUMLEY, D., YIN, H., CABALLERO, J., JAGER,
I., KANG, M., LIANG, Z., NEWSOME, J., POOSANKAM, P.,
AND SAXENA, P. Bitblaze: A new approach to computer secu-
rity via binary analysis. In Information Systems Security, R. Sekar
and A. Pujari, Eds., vol. 5352 of Lecture Notes in Computer Sci-
ence. Springer Berlin Heidelberg, 2008, pp. 1–25.

[39] SONG, H., AND TURNER, J. Toward advocacy-free evaluation of
packet classiﬁcation algorithms. Computers, IEEE Transactions
on 60, 5 (May 2011), 723–733.

[40] SOSKA, K., AND CHRISTIN, N. Automatically detecting vul-
nerable websites before they turn malicious. In 23rd USENIX Se-
curity Symposium (USENIX Security 14) (San Diego, CA, Aug.
2014), USENIX Association, pp. 625–640.

[41] WANG, K., AND STOLFO, S. Anomalous payload-based net-
work intrusion detection. In Recent Advances in Intrusion Detec-
tion, E. Jonsson, A. Valdes, and M. Almgren, Eds., vol. 3224 of
Lecture Notes in Computer Science. Springer Berlin Heidelberg,
2004, pp. 203–222.

[42] YIN, H., SONG, D., EGELE, M., KRUEGEL, C., AND KIRDA,
E. Panorama: Capturing system-wide information ﬂow for mal-
ware detection and analysis.
In Proceedings of the 14th ACM
Conference on Computer and Communications Security (New
York, NY, USA, 2007), CCS ’07, ACM, pp. 116–127.

[43] ZHANG, K., SCH ¨OLKOPF, B., MUANDET, K., AND WANG, Z.
Domain adaptation under target and conditional shift. In Proceed-
ings of the 30th International Conference on Machine Learning
(ICML-13) (2013), S. Dasgupta and D. Mcallester, Eds., vol. 28,
JMLR Workshop and Conference Proceedings, pp. 819–827.

[44] ZHAO, P., AND HOI, S. C. Cost-sensitive online active learning
with application to malicious url detection.
In Proceedings of
the 19th ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining (New York, NY, USA, 2013), KDD
’13, ACM, pp. 919–927.

A Examples of Bags

[19] IYER, A., NATH, S., AND SARAWAGI, S. Maximum mean dis-
crepancy for class ratio estimation: Convergence bounds and ker-
nel selection. In Proceedings of the 31st International Conference
on Machine Learning (ICML-14) (2014), pp. 530–538.

[20] JAGPAL, N., DINGLE, E., GRAVEL, J.-P., MAVROMMATIS, P.,
PROVOS, N., RAJAB, M. A., AND THOMAS, K. Trends and
lessons from three years ﬁghting malicious extensions. In 24th
USENIX Security Symposium (USENIX Security 15) (Washing-
ton, D.C., Aug. 2015), USENIX Association, pp. 579–593.

[21] JUNEJO, I. N., DEXTER, E., LAPTEV, I., AND PEREZ, P. View-
independent action recognition from temporal self-similarities.
Pattern Analysis and Machine Intelligence, IEEE Transactions
on 33, 1 (2011), 172–185.

[22] KAPRAVELOS, A., SHOSHITAISHVILI, Y., COVA, M.,
KRUEGEL, C., AND VIGNA, G. Revolver: An automated
approach to the detection of evasive web-based malware.
In
USENIX Security (2013), Citeseer, pp. 637–652.

[23] KARAGIANNIS, T., PAPAGIANNAKI, K., AND FALOUTSOS, M.
Blinc: Multilevel trafﬁc classiﬁcation in the dark. In Proceedings
of the 2005 Conference on Applications, Technologies, Architec-
tures, and Protocols for Computer Communications (New York,
NY, USA, 2005), SIGCOMM ’05, ACM, pp. 229–240.

[24] KIM, H., CLAFFY, K., FOMENKOV, M., BARMAN, D.,
FALOUTSOS, M., AND LEE, K. Internet trafﬁc classiﬁcation de-
mystiﬁed: Myths, caveats, and the best practices. In Proceedings
of the 2008 ACM CoNEXT Conference (New York, NY, USA,
2008), CoNEXT ’08, ACM, pp. 11:1–11:12.

[25] KRUEGEL, C., AND VIGNA, G. Anomaly detection of web-
based attacks. In Proceedings of the 10th ACM Conference on
Computer and Communications Security (New York, NY, USA,
2003), CCS ’03, ACM, pp. 251–261.

[26] LOU, W., LIU, G., LU, H., AND YANG, Q. Cut-and-pick trans-
actions for proxy log mining.
In Advances in Database Tech-
nology EDBT 2002, C. Jensen, S. altenis, K. Jeffery, J. Pokorny,
E. Bertino, K. Bhn, and M. Jarke, Eds., vol. 2287 of Lecture Notes
in Computer Science. Springer Berlin Heidelberg, 2002, pp. 88–
105.

[27] MA, J., SAUL, L. K., SAVAGE, S., AND VOELKER, G. M.
Learning to detect malicious urls. ACM Trans. Intell. Syst. Tech-
nol. 2, 3 (May 2011), 30:1–30:24.

[28] MOORE, D., SHANNON, C., BROWN, D. J., VOELKER, G. M.,
Inferring internet denial-of-service activity.

AND SAVAGE, S.
ACM Trans. Comput. Syst. 24, 2 (May 2006), 115–139.

[29] MOSER, A., KRUEGEL, C., AND KIRDA, E. Exploring multiple
execution paths for malware analysis. In Security and Privacy,
2007. SP ’07. IEEE Symposium on (May 2007), pp. 231–245.

[30] MOSER, A., KRUEGEL, C., AND KIRDA, E. Limits of static
analysis for malware detection. In Computer Security Applica-
tions Conference, 2007. ACSAC 2007. Twenty-Third Annual (Dec
2007), pp. 421–430.

[31] M ¨ULLER, M., AND CLAUSEN, M. Transposition-invariant self-
similarity matrices.
In In Proceedings of the 8th International
Conference on Music Information Retrieval (ISMIR) (2007),
pp. 47–50.

[32] NELMS, T., PERDISCI, R., ANTONAKAKIS, M., AND
AHAMAD, M. Webwitness: Investigating, categorizing, and mit-
igating malware download paths. In 24th USENIX Security Sym-
posium (USENIX Security 15) (Washington, D.C., Aug. 2015),
USENIX Association, pp. 1025–1040.

[33] PORTNOY, L., ESKIN, E., AND STOLFO, S. Intrusion detection
with unlabeled data using clustering. In In Proceedings of ACM
CSS Workshop on Data Mining Applied to Security (DMSA-2001
(2001), pp. 5–8.

USENIX Association  

25th USENIX Security Symposium  821

15

Asterope
hxxp://194.165.16.146:8080/pgt/?ver=1.3.3398&id=126&r=12739868&os=6.1—2—8.0.7601.18571&res=4—1921—466&f=1
hxxp://194.165.16.146:8080/pgt/?ver=1.3.3398&id=126&r=15425581&os=6.1—2—8.0.7601.18571&res=4—1921—516&f=1
hxxp://194.165.16.146:8080/pgt/?ver=1.3.3398&id=126&r=27423103&os=6.1—2—8.0.7601.18571&res=4—1921—342&f=1
hxxp://194.165.16.146:8080/pgt/?ver=1.3.3753&id=126&r=8955018&os=6.1—2—8.0.7601.18571&res=4—1921—319&f=1
Click-fraud, malvertising-related botnet
hxxp://directcashfunds.com/opntrk.php?tkey=024f9730e23f8553c3e5342568a70300&Email=name.surname@company.com
hxxp://directcashfunds.com/opntrk.php?tkey=c1b6e3d50632d4f5c0ae13a52d3c4d8d&Email=name.surname@company.com
hxxp://directcashfunds.com/opntrk.php?tkey=7c9a843ce18126900c46dbe4be3b6425&Email=name.surname@company.com
hxxp://directcashfunds.com/opntrk.php?tkey=c1b6e3d50632d4f5c0ae13a52d3c4d8d&Email=name.surname@company.com
DGA
hxxp://uvyqifymelapuvoh.biz/s531ka.ji5
hxxp://uvyqifymelapuvoh.biz/rl59c281.x19
hxxp://uvyqifymelapuvoh.biz/seibpn6.2m0
hxxp://uvyqifymelapuvoh.biz/3854f.u17
Dridex
hxxp://27.54.174.181/8qV578&$o@HU6Q6S/gz$J0l=iTTH 28%2CM/we20%3D
hxxp://27.54.174.181/C4GyRx%7E@RY6x /M&N=sq/bW ra4OTJ
hxxp://27.54.174.181/gPvh+=GO/9RPPfk0%2CzXOYU%20/Vq8Ww/+a m%7Ez
hxxp://27.54.174.181/qE0my4KIz48Cf3H8wG%7Evpz=iJ%26fqMl%24m/46JoELp=GJww%3D%26Ib+Ar.y3 iu%2D1E/sso
InstallCore
hxxp://rp.any-ﬁle-opener.org/?pcrc=1559319553&v=2.0
hxxp://rp.any-ﬁle-opener.org/?pcrc=1132521307&v=2.0
hxxp://rp.any-ﬁle-opener.org/?pcrc=1123945956&v=2.0
hxxp://rp.any-ﬁle-opener.org/?pcrc=1075608192&v=2.0
Poweliks
hxxp://31.184.194.39/query?version=1.7&sid=793&builddate=114&q=nitric+oxide+side+effects&ua=Mozilla%2F5 . . . &lr=7&ls=0
hxxp://31.184.194.39/query?version=1.7&sid=793&builddate=114&q=weight+loss+success+stories&ua=Mozilla%2F5 . . . &lr=0&ls=0
hxxp://31.184.194.39/query?version=1.7&sid=793&builddate=114&q=shoulder+pain&ua=Mozilla%2F5 . . . &lr=7&ls=2
hxxp://31.184.194.39/query?version=1.7&sid=793&builddate=114&q=cheap+car+insurance&ua=Mozilla%2F5 . . . &lr=7&ls=2
Zeus
hxxp://130.185.106.28/m/IbQFdXVjiriLva4KHeNpWCmThrJBn3f34HNwsLVVsUmLXtsumSSPe/zzXtIu9SzwjI9zKlxdE . . . 3RqvGzKN5
hxxp://130.185.106.28/m/IbQJFUVjgZn4vx4KHeNpWCmThrJBn3f34HNwsLVVsUmLfkoPaSS+S+zzXtIu9SzwjI9zKlxdE . . . 3vKwmk0oUi
hxxp://130.185.106.28/m/IbQJFUVjiJwJBX4KHeNpWCmThrJBn3f34HNwsLVVsUmKH7ue2STvSkzzXtIu9SzwjI9zKlxdE . . . 3vKwmk0oUi
hxxp://130.185.106.28/m/IbQNtVVji5/7Yp4KHeNpWCmThrJBn3f34HNwsLVVsUmLz4sO6YRvOjzzXtIu9SzwjI9zKlxdE . . . 3zB9057quqv
Legitimate trafﬁc 1
hxxp://www.cnn.com/.element/ssi/auto/4.0/sect/MAIN/markets wsod expansion.html
hxxp://www.cnn.com/.a/1.73.0/assets/sprite-s1dced3ff2b.png
hxxp://www.cnn.com/.element/widget/video/videoapi/api/latest/js/CNNVideoBootstrapper.js
hxxp://www.cnn.com/jsonp/video/nowPlayingSchedule.json?callback=nowPlayingScheduleCallbackWrapper& =1422885578476
Legitimate trafﬁc 2
hxxp://ads.adaptv.advertising.com/a/h/7g doK40WLPMYHbkD9G2u7HSXjqzIaa7Bqhslod+u7iQl . . . &context=fullUrl%3Dpandora.com
hxxp://ads.adaptv.advertising.com/crossdomain.xml
hxxp://ads.advertising.com/411f1e96-3bde-4d85-b17e-63749e5f0695.js
hxxp://ads.adaptv.advertising.com/applist?placementId=297920&key=&d.vw=1&orgId=8656&hostname=data.rtbfy.com

Monetization
hxxp://utouring.net/search/q/conducing
hxxp://utouring.net/go/u/1/r/1647
hxxp://utouring.net/go/u/0/r/2675
hxxp://utouring.net/search/f/1/q/reﬁles

Table 4: Example URLs of ﬂows from several malicious bags and from two legitimate bags. The URLs within each
malicious bag are similar to each other while the URLs within legitimate bags differ. The small non-zero variability
of ﬂow-based feature values is captured by the proposed representation using histograms of features and feature self-
similarity matrices. Such transformation of the feature values makes the representation robust to malware changes and
unseen variants.

822  25th USENIX Security Symposium 

USENIX Association

16

