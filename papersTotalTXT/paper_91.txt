On Non-cooperative Genomic Privacy

Mathias Humbert1, Erman Ayday2(cid:63), Jean-Pierre Hubaux1, and Amalio Telenti3

1 Laboratory for Communications and Applications, EPFL, Lausanne, Switzerland

2 Bilkent University, Department of Computer Science, erman@cs.bilkent.edu.tr

3 The J. Craig Venter Institute, La Jolla, USA, atelenti@jcvi.org

ﬁrstname.lastname@epﬂ.ch

Abstract. Over the last few years, the vast progress in genome sequenc-
ing has highly increased the availability of genomic data. Today, individ-
uals can obtain their digital genomic sequences at reasonable prices from
many online service providers. Individuals can store their data on per-
sonal devices, reveal it on public online databases, or share it with third
parties. Yet, it has been shown that genomic data is very privacy-sensitive
and highly correlated between relatives. Therefore, individuals’ decisions
about how to manage and secure their genomic data are crucial. People of
the same family might have very diﬀerent opinions about (i) how to pro-
tect and (ii) whether or not to reveal their genome. We study this tension
by using a game-theoretic approach. First, we model the interplay be-
tween two purely-selﬁsh family members. We also analyze how the game
evolves when relatives behave altruistically. We deﬁne closed-form Nash
equilibria in diﬀerent settings. We then extend the game to N players by
means of multi-agent inﬂuence diagrams that enable us to eﬃciently com-
pute Nash equilibria. Our results notably demonstrate that altruism does
not always lead to a more eﬃcient outcome in genomic-privacy games.
They also show that, if the discrepancy between the genome-sharing ben-
eﬁts that players perceive is too high, they will follow opposite sharing
strategies, which has a negative impact on the familial utility.

Keywords: Genomic Privacy, Interdependent Privacy, Game Theory, Altruism.

1

Introduction

The decreasing cost in genome sequencing has dramatically increased the avail-
ability and use of genomic data in many domains such as healthcare, research,
law enforcement, and recreational genomics. Any individual can obtain the se-
quencing of a signiﬁcant part of his genome for less than $100. This availability
raises many questions regarding the management (storage, sharing, etc.) and,
ultimately, the privacy of genomic data. The genome contains very sensitive
information about its owner such as his ethnicity, kinship, and predisposition
to diseases. If this data is leaked, there could be serious consequences such as
genetic discrimination, divorce [1] and blackmail (considering e.g., fatherhood

(cid:63) This work was carried out while the author was at EPFL.

issues) [9]. As genomic data is personal data, we could let individuals manage
it independently of each other. However, as shown in [14], the genomic data of
close relatives is highly correlated, thus leading to interdependent privacy risks.
Hence, all genome-related decisions should be made by considering that genomic
data is not only personal, but also familial data.

Nevertheless, thousands of individuals already spontaneously share their ge-
nomic data online, either anonymously1 or with their real identity (e.g., on
OpenSNP.org). Even for individuals who do not share their genomic data on-
line, important decisions regarding the storage security of their genomes have
to be made. Some will decide to store it on personal devices, others on external
(potentially untrusted) servers. In both cases, guaranteeing security and privacy
has a non-negligible cost. Therefore, in this work, we consider that an individual
whose DNA has been sequenced must make decisions on (i) whether to share his
genomic data, and (ii) how much to invest in securing the storage of this data.
We analyze the strategic behaviors of members of the same family in a
genomic-privacy context by using a game-theoretic approach. Game theory has
been shown to be very useful for analyzing the behavior of strategic agents in
information security settings [3]. In particular, interdependent security (IDS)
games have been proposed [20] for scenarios where agents make decisions that
aﬀect not only their own security risks but also those of others. Following the IDS
works, we deﬁne two interdependent privacy (IDP) games between family mem-
bers with diﬀerent perceived beneﬁts, costs and privacy levels. First, we study
the interplay between two family members. With the two-player setting, we de-
rive a closed-form expression to quantify genomic privacy of any individual given
one of his relatives’ genome, and compute diﬀerent closed-form Nash equilibria
for the two games we study. Furthermore, we consider some altruistic2 behav-
ior within a family. Then, we extend the two-player game to consider N family
members who decide whether to secure or disclose their genomes. To eﬃciently
compute the Nash equilibrium of the N-player game, we make use of multi-agent
inﬂuence diagrams (MAIDs), an extension of Bayesian networks that enables us
to include decision and utility variables. With this approach, we can signiﬁcantly
reduce computational complexity with respect to a classic extensive-form game.
Note that, compared to IDS games that rely upon theoretical models of inter-
dependence, the indirect risks in the IDP games come from the actual familial
correlations evidenced by genetics. Moreover, we quantify genomic-privacy loss
with real genomic data, which provides very tangible results.

Our results show that, if the discrepancy is too high between the players’
perceptions of the genome-sharing beneﬁts, they will follow opposite strategies,
creating externalities. These misaligned incentives lead to ineﬃcient equilibria
that result in a familial utility lower than when incentives are aligned. Our
analysis also shows that, surprisingly, altruism does not always lead to a more

1 Anonymization has been proven to not be an eﬀective technique for protecting iden-

tities of the data owners in the genomic context [12, 26].

2 Each player takes into account the other players’ utility when making a decision.

eﬃcient outcome in a genomic privacy game. Yet, such suboptimal equilibrium
can be avoided if the players coordinate.

2 Model

Users: We consider a set of N users from a family whose genotypes are se-
quenced. We focus on the most common DNA variant, the single nucleotide
polymorphism (SNP).3 We assume that all users have the same number and set
Ω of SNPs sequenced. Users have to make choices regarding the investment in
securing their genomic data and the sharing of this data (e.g., to help research).
A user might prefer storing his genomic data on a personal, and possibly mo-
bile, device. For instance, as suggested in [6], there are various advantages to
keeping a person’s genome on a smartphone. It is portable, highly personal, and
has very good computational and storage capabilities. Unfortunately, malware
in smartphones has exploded over the last few years [25], and keeping a mobile
device secure causes non-negligible costs. Alternatively, a user could decide to
outsource the storage of his genomic data to a third party. A user might also
want to publicly share his SNPs, essentially because his perceived beneﬁts out-
weigh the perceived cost (loss) for his genomic privacy.4 We assume such users
typically do not invest in securing their genomes on their personal devices, as
they are already publicly disclosed.

Adversary: The adversary’s goal is to collect and infer genomic data. His rea-
sons for gathering individuals’ genotypes can be multiple. For instance, he could
sell the collected genomic data to life or health insurance companies that would
then use it to genetically discriminate against potential insurees. As usually as-
sumed in IDS games, the adversary is considered to be an exogenous, persistent
threat [20]. Thus, we do not model him as a strategic agent, but rather as prob-
ability h(·) of a successful breach in the targeted system. If a user decides to
publicly disclose his SNPs online, the probability of a breach is equal to 1.

3 Genomic Privacy Games

The genomes of close family members are highly correlated. Thus, individuals’
behaviors regarding their genomes will not only aﬀect their personal genomic
privacy, but also those of their relatives. Game theory enables us to model the
interplay between users with dependent payoﬀs and potentially conﬂicting inter-
ests, and to predict their behaviors. We deﬁne two interdependent privacy games
between family members: (i) the (storage-)security game Gs, and the disclosure
game Gd. Both Gs and Gd are deﬁned as a triplet (P, S, U), where P is the set
of players, S is the set of strategies, and U is the set of payoﬀ functions.
3 See, e.g., https://genomeprivacy.org/ for an introduction to genomics.
4 See, e.g., http://opensnp.wordpress.com/2011/11/17/ﬁrst-results-of-the-survey-on-
sharing-genetic-information/ to understand users’ motivations for and fears about
genome sharing.

• Players: The set of players P = {P1, ..., PN} corresponds to the set of N
family members having their genomes sequenced, in both games Gs and Gd.
• Strategies: In game Gs, for each player Pi, the strategy xi ∈ S represents the
security investment for the storage of his genomic data. As diﬀerences between
discrete and continuous models of investment appear only in some boundary
cases [11, 20], we consider here the discrete model, i.e., xi ∈ {0, 1}. xi = 1
means “to invest in securing his own device”, and xi = 0 means “to not in-
vest”, by putting his data on his device or outsourced to an untrusted third
party (that could be itself attacked). The strategy proﬁle is then deﬁned as
x = [x1,··· , xN ]T . In game Gd, the strategy is represented by the decision di
to publicly share Pi’s SNPs (e.g., on OpenSNP.org) or not. As the majority of
genome-sharing people currently choose to disclose nothing or their whole set of
SNPs, we consider here a discrete binary model, i.e., di ∈ {0, 1} (0 meaning “no
disclosure” and 1 “full disclosure”). Note that a ﬁner granularity of disclosure is
studied in detail in a cooperative context in [16]. A player will choose di = 1 if
and only if he perceives more utility by sharing than by protecting. The strategy
proﬁle is then represented by d = [d1,··· , dN ]T .
• Payoﬀ Functions: The utility of a player is, by deﬁnition, equal to the beneﬁt
minus the cost. In our setting, the ﬁrst term of the beneﬁt, bg
i , represents the
fact that a user’s genome is sequenced and available for various beneﬁts (e.g.,
personalized medicine). This generic beneﬁt can be added to the beneﬁt bd
i that
player Pi obtains by disclosing his genomic data online in game Gd. The cost
comprises the (unit) cost of a security investment for protecting his genome,
ci, and the potential loss li of genomic privacy.5 For instance, the cost ci can
represent the OS updates that can lead to a non-negligible cost (renewal of the
equipment) once a device becomes too old to support them.

In our genomic context, the privacy loss li can be precisely quantiﬁed by
relying upon the expected estimation error Ei between the SNP values inferred
by the adversary ˆyk
i as
the random variable representing SNP gk of player Pi, the genomic privacy of
Pi is

i ’s, ∀gk ∈ Ω [14].6 Deﬁning Y k

i ’s and the actual values yk

i |YO = yO)(cid:13)(cid:13)yk

i − ˆyk

i

(cid:13)(cid:13)1,

P (Y k

i = ˆyk

(cid:88)

(cid:88)

k:gk∈Ω

i ∈{0,1,2}
ˆyk

Ei =

1
|Ω|

(1)

where YO represents the SNPs observed by the adversary. This set depends on the
strategies of the players in Gs and Gd. We will denote Ei,0 to be the genomic pri-
vacy when no SNP is observed, i.e., when P (Y k
i ).
This initial privacy level is computed by using the minor allele frequencies
(MAFs) given by population statistics [14]. In general, as the observation de-
pends on the strategy proﬁle x (respectively d), Ei will be a function of x
(respectively d) in game Gs (respectively Gd). As assumed in several IDS games

i |YO = yO) = P (Y k

i = ˆyk

i = ˆyk

5 Note that an expected monetary loss would be expressed as a non-decreasing function
of li. This is left for future work.
6 Note that a SNP value is encoded by the set {0, 1, 2} whose elements represent the
number of minor alleles in the SNP.

(e.g., [19]), the probability of successful breach is set to zero when a player in-
vests in security, i.e., h(xi = 1) = 0. Otherwise, h(xi = 0) = pa with 0 < pa ≤ 1.
For game Gd, h(di = 1) = 1 as discussed in Section 2, and h(di = 0) = 0.7 In
our genomic privacy game, contrarily to IDS games, the interdependence lies in
the genomic-privacy loss and not in the breach probability h(·). The genomic-
privacy loss li is deﬁned as Ei,0 − Ei(·), where Ei(·) is a function of the strategy
proﬁle x = (xi, x−i) or d = (di, d−i). Note that the risk is non-additive: Either
the adversary manages to know the player’s genome directly (and the genomic
privacy drops to zero), in which case the knowledge of another genome does not
bring any extra information; or the adversary cannot access the player’s genome
and then there is only an indirect privacy loss. Deﬁning h(x−i) as the probabil-
ity of successful breaches into a subset of players’ devices (other than Pi), the
payoﬀ function of a player Pi in Gs is

ui(xi, x−i) = bg

i − (xici + h(xi)Ei,0 + (1 − h(xi)) h(x−i) (Ei,0 − Ei(x−i))) , (2)

and his payoﬀ in game Gd is

i + dibd

of all players: U (x) =(cid:80)

i:Pi∈P ui(x) for Gs, and U (d) =(cid:80)

i − ((1 − di)ci + diEi,0 + (1 − di) (Ei,0 − Ei(d−i))) .8 (3)
ui(di, d−i) = bg
• Social Welfare: We deﬁne the social welfare function as the sum of the payoﬀs
i:Pi∈P ui(d) for Gd.
• Altruism: Finally, we consider that family members are usually not purely
selﬁsh regarding their relatives, hence some altruistic factors play a role in their
decisions. Following an idea introduced in [21] for social networks, we deﬁne a
familial factor α ∈ [0, 1] that conveys the fact that relatives tend to be altruistic
among themselves. We raise this factor to the power k(i, j) ∈ N∗ that represents
the degree of kinship between relatives i and j.9 α = 0 means that players are
purely selﬁsh, whereas α = 1 implies that they are fully altruistic with their
whole family. For instance, in Gs, the altruistic player Pi will maximize the
following utility (instead of (2)):

(cid:88)

j:Pj∈P,j(cid:54)=i

αk(i,j)uj(xi, x−i).

(4)

ua
i (xi, x−i) = ui(xi, x−i) +

4 Two-Player Games

In this section, we study the interplay between two relatives who are, at ﬁrst,
selﬁsh, and then become partially altruistic depending on their degree of kinship.

7 In Gd, we assume that a player who does not share his SNPs will always invest in

security. Note also that Gd is a special case deriving from Gs.

8 In the following, we will use the more concise notation Ei|−i to express the genomic

privacy of Pi given a subset (that depends on x−i or d−i) of other players’ SNPs.

9 k = 1 for ﬁrst-degree relatives such as parent, child, sibling; k = 2 for second-degree

relatives such as grandparent, grandchild, uncle, aunt, niece, and so on.

Table 1: Normal form of the two-player game Gs.
x2 = 0

P1\P2
x1 = 1
x1 = 0 (bg

x2 = 1
1 − c1, bg
(bg
1 − paE1,0, bg
2 − c2 − pa(E2,0 − E2|1)

2 − c2)

1 − c1 − pa(E1,0 − E1|2), bg
2 − paE2,0)
(bg
1−paE1,0−(1−pa)pa(E1,0−E1|2),
(bg
2−paE2,0−(1−pa)pa(E2,0−E2|1))
bg

Fig. 1: Dependence of the NE of game Gs with respect to the investment cost c.

4.1 Selﬁsh Players

We start our analysis with game Gs whose strategic representation is shown in
Table 1. Assuming the cost of security investment to be the same for all players,
i.e., c1 = c2 = c, we characterize all Nash equilibria.
Lemma 1. For any value c ∈ [0,∞), there exists at least one pure Nash equi-
librium (NE) in Gs. The NE are deﬁned by the best responses (x∗

1, x∗
2):



(x∗

1, x∗

2) =

if c < min(t1, t2)

(1, 1)
(1, 1), mNE if min(t1, t2) < c < max(t1, t2)
if max(t1, t2) < c < pa min(t0
(1, 1), (0, 0)
(0, 0), mNE if pa min(t0
(0, 0)

1, t0
2)
1, t0
2) < c < pa max(t0
2)

1, t0
if c > pa max(t0
2)
a(Ei,0 − Ei|j), t0
2), where ti = paEi,0 − p2

1, t0

1, t0

(5)

if max(t1, t2) < pa min(t0
mNE is a mixed-strategy Nash equilibrium. If max(t1, t2) > pa min(t0
third case NE in (5) become (0, 1) if t0
and pa min(t0

2) are swapped in the inequality bounds on c.

i = Ei,0, and
2), the
2, and max(t1, t2)

2 and (1, 0) if t0

1 > t0

1 < t0

1, t0

1, t0

Due to space constraints, this proof is omitted and can be found in [15].
Fig. 1 depicts how the NE evolves for diﬀerent values of c. In order to obtain
closed-formed Nash equilibria, we must analytically express the genomic privacy
levels Ei,0 and Ei|j. In [14], the authors show that, in the general case, belief
propagation on factor graphs can be used to compute the posterior marginal
i |YO) given some observed genomic data, and thus to quantify
probability P (Y k
genomic privacy. We now show that, if only two members are involved in the
game, and no other familial genomic data is observed, we can derive a closed-form
i |YO), thus for Ei,0 and Ei|j. As we assume that all players
expression for P (Y k
have the same set of SNPs Ω sequenced and potentially exposed, and that the

30(a)

(b)

Fig. 2: Probabilistic models representing a SNP value evolution over multiple
generations. (a) Bayesian network representation of a three-generation family,
and (b) Markov chain representing the probabilities of moving from one SNP
value (state) to another from generation i to i + 1 or i − 1. Probability p is the
major allele frequency of the given SNP.

adversary can access either the whole sequence of SNPs or nothing (as he either
successfully breaches the system or not), linkage disequilibrium (correlations)
between the SNPs would not help the adversary very much, thus it is not used
in the computation of genomic privacy here. Hence, when we want to compute
the privacy at SNP gk of player Pi, we consider only the observation at the
same SNP gk of player Pj. Each SNP can then be considered independently of
other SNPs. In the following two lemmas, we focus on a single SNP, so drop
the superscript k. Assuming Yi is the random variable representing a SNP of an
individual at generation i in a familial branch (see Fig. 2a), and p is the major
allele frequency of the SNP, we have the following lemma.
Lemma 2. The sequence {Yn} is a discrete stochastic process. Moreover, it is
a ﬁrst-order homogeneous Markov chain, i.e., the conditional probability of Yi+1
given (direct) ancestors in one of the parents’ family branches is formally deﬁned
as P (Yi+1 = yi+1|Yi = yi, Yi−1 = yi−1, . . . ) = P (Yi+1 = yi+1|Yi = yi). Its
transition matrix P is deﬁned as follows:

 p 1 − p

p

 ,

P =

p/2 1/2 (1 − p)/2
0

0
1 − p

where pmn = P (Yi+1 = n|Yi = m), m and n belonging to the state space {0, 1, 2}.

This proof can be found in [15]. We have noticed that the reverse process, which
is the conditional probability of Yi−1 given direct descendants Yi, Yi+1, . . . , is
also a ﬁrst-order homogeneous Markov chain deﬁned by the same matrix P where
pmn = P (Yi−1 = n|Yi = m). This means that going up or down the familial tree

33YiYi-1Yi+1Zi280121/21-pp/2p(1-p)/2p1-pleads to the same conditional distributions. The corresponding Markov chain is
shown in Fig. 2b.

Lemma 2 helps us determine the conditional probabilities of SNPs of direct
ancestors or descendants given any relative’s observed SNP. For instance, the
conditional probability P (Yi+k|Yi) of a relative k-degrees apart from another
individual i whose SNP is observed and equal to m is, by deﬁnition of the Markov
chain, given by πi+k = πiP k, where πi is a row vector that is equal to 1 in
the mth coordinate and 0 elsewhere. Note also that the stationary distribution,
deﬁned as the vector π such that π = πP , is equal to the vector of prior
probabilities (P (Yi)), given by the major allele probability p:

π =(cid:0)p2 2p(1 − p) (1 − p)2(cid:1) .

(6)

This follows the intuition, as π is deﬁned to be equal to any of the columns of
P k when k tends to inﬁnity. When the observed relative j is far enough from
the targeted individual i in the family tree, the genome of j has no inﬂuence
on i’s genome. The conditional probabilities are well-deﬁned for direct relatives.
However, if the individual whose SNP is observed is not a relative in direct
line (e.g., an uncle or a niece), the transition matrix P cannot be applied alone
and has to be combined with a matrix M whose elements mab represent the
conditional probabilities P (Yi1 = b|Yi2 = a) of i1 given his sibling i2. M is
derived and expressed in [15]. Deﬁning the 3×3 distance matrix D with elements
dij = |i − j| and the (column) vector yi whose mth coordinate is equal to 1 and
others 0 (where m is the SNP value), we have the following lemma.

Lemma 3. The genomic privacy Ei of individual i at any SNP is:

Ei,0 = πDyi

Ei|j = πjP kDyi
Ei|j = πjP uM P vDyi

if no relative reveals the SNP
if i and j are direct relatives and j’s SNP is revealed
if i and j are not direct relatives and j’s SNP is revealed

where k is the degree of kinship between i and j, u is the degree of kinship between
j and his (direct) ancestor whose sibling is the (direct) ancestor of i, and v is the
degree of kinship between i and his (direct) ancestor whose sibling is j’s (direct)
ancestor.

This proof can be found in [15]. To illustrate the third case of Lemma 3, let us
take for example two close relatives, uncle and nephew. If j is the uncle of i, then
the genomic privacy of i given j at a certain SNP is Ei|j = πjP 1M P 0Dyi =
πjP M Dyi whereas, if j is the nephew of i, the genomic privacy of i is Ei|j =
πjM P Dyi.

We can now quantify genomic privacy for a range of SNPs and get closed-form

NE.
Theorem 1. For any value c ∈ [0,∞), the pure Nash equilibrium is:

(1, 1)

(1, 1), (0, 0)
(0, 0)

(x∗

1, x∗

2) =

if c < max(t1, t2)
if max(t1, t2) < c < pa min(t0
if c > pa min(t0

1, t0
2)

1, t0
2)

(7)

(cid:80)

i =

1|Ω|

l:gl∈Ω πlDyl
i,

ti =

(cid:0)(cid:80)
if max(t1, t2) < pa min(t0
1, t0
l:gl∈Ω((1 − pa)πl + paπl
pa|Ω|
tives, and ti = pa|Ω|
in direct line, u and v as deﬁned in Lemma 3. If max(t1, t2) > pa min(t0
second-case NE (1, 1), (0, 0) becomes (0, 1) if t0
max(t1, t2) and pa min(t0

(cid:1) if i and j are direct kth-degree rela-
(cid:1) if i and j are not

2) are swapped in the inequality bounds.

(cid:0)(cid:80)
2), where t0
jP k
l:gl∈Ω((1 − pa)πl + paπl

l )Dyl
i

2 and (1, 0) if t0

jP u

l M P v

l )Dyl
i

1, t0
1 > t0

2), the
2, and

1 < t0

1, t0

The proof can be found in [15]. In order to make these NE more tangible, we
quantify genomic privacy by relying upon real genomic data. We make use of
the CEPH/Utah Pedigree 1463 that contains the partial DNA sequences of 4
grandparents, 2 parents, and 11 children [8]. We ﬁlter 8 of the 11 children out,
thus keeping 9 relatives in total: GP1, GP2, GP3, GP4, P5, P6, C7, C8, and C9.
We consider all the SNPs that are available on chromosome 1 (around 82,000).
Note that, thanks to our closed-form expression of Ei|j, its computation on
82,000 SNPs takes less than one second. Fig. 3 shows the thresholds separating
the three diﬀerent cases of NE in Theorem 1 with respect to pa and c. (1, 1)
stands below the two (dotted) red and green curves, and (0, 0) stands above
these two curves. Thus, we note that for most values of c and pa, either both
relatives secure their genomes (if c is smaller than around half of pa), or both do
not secure them (if c is greater than around half of pa). This shows that players,
if they have similar cost c, have aligned incentives, leading to an eﬃcient NE.
However, there are some values of c and pa for which two pure NE (1, 1) and
(0, 0) co-exist. It is between the two curves, if the (dotted) red curve lies above
the green one. If the green curve lies above the dotted one,10 then we have either
(0, 1) if E1,0 < E2,0 or (1, 0) if E1,0 > E2,0. The discrepancy between the two
curves is the highest in Fig. 3c, as the diﬀerence between the initial privacy
levels Ei,0’s and posterior levels Ei|j is the most signiﬁcant (see Table 2). On the
contrary, in the game between C7 and GP1, the posterior levels Ei|j are closer
to the initial ones Ei,0 (because the two players are second-degree relatives), and
the Ei,0’s diﬀer between the two players, leading (for a tiny subset of values of
pa of c) to ineﬃcient NE, such as (0, 1), as described above.
Discussion: We conclude that, for most security cost values and probabilities
of successful breach, the players follow the same strategies, even though their
genomic privacy levels are slightly diﬀerent. They both either invest in security,
or do not.

Table 2: Genomic privacy levels of grandparent GP1, parent P5, children C7 and
C8, from the CEPH/Utah pedigree 1463.

E1,0 E1|2 E2,0 E2|1
(P1, P2)
(P5,GP1) 0.4741 0.3579 0.4402 0.3179
(C7,GP1) 0.4788 0.4296 0.4402 0.3878
(C7,C8) 0.4788 0.3310 0.4803 0.3321

10 This happens for pa < 0.29 in Fig. 3a and pa < 0.78 in Fig. 3b.

(a)

(b)

(c)

Fig. 3: Thresholds of Theorem 1 separating the three diﬀerent pure NE cases of
Gs. We show three diﬀerent scenarios with two players: (a) Grandparent GP1
and parent P5, (b) GP1 and child C7, and (c) children C7 and C8.

P1\P2
d1 = 0
d1 = 1 (bg

1 + bd

Table 3: Normal form of the two-player game Gd.
d2 = 1
1 − E1,0, bg

d2 = 0
1 − c1, bg
(bg
2 − c2 − (E2,0 − E2|1)

1 − c1 − (E1,0 − E1|2), bg
(bg
2 + bd

2 − c2)

1 − E1,0, bg

1 + bd

(bg

2 − E2,0)

2 + bd
2 − E2,0)

We now move to the disclosure game Gd. Table 3 shows the resulting payoﬀs

for two players P1 and P2. The following theorem determines its NE.

Theorem 2. For any value bd
rium is:

1 ∈ [0,∞), and bd

2 ∈ [0,∞), the pure Nash equilib-

(cid:80)

where Ei,0 = 1|Ω|
if i and j
are direct kth-degree relatives and, if i and j are not in direct line, Ei|j =
1|Ω|

i, Ei|j = 1|Ω|

l:gl∈Ω πlDyl

l:gl∈Ω πlP k

l:gl∈Ω πlP u

l DM P v

l Dyl
i

l yl
i.

This proof can be found in [15]. Fig. 4 illustrates the NE computed in The-
orem 2. These NE depend essentially on the value of bd
i + ci with respect to
Ei,0 and Ei|j. A player Pi will disclose his genome, given that the other player
discloses it as long as bd
i + ci > Ei|j. Whereas if the other player’s best response
is to not share, Pi will share only if bd
i + ci > Ei,0. Table 2 shows concrete values
of genomic privacy E1,0, E2,0, E1|2, and E2|1, for ﬁrst-degree direct relatives,
second-degree direct relatives, and siblings.

(d∗
1, d∗

2) =



(0, 0)

(1, 1), (0, 0)

(1, 1)

(0, 1)
(1, 0)

(cid:80)

2 < E2|1 − c2)(cid:1)∨
2 < E2,0 − c2)(cid:1)
2 > E2|1 − c2)(cid:1)∨

1 < E1,0 − c1) ∧
2 < E2,0 − c2)

if(cid:0)(bd
(cid:0)(bd
if(cid:0)(bd

1 < E1,0 − c1) ∧ (bd
1 < E1|2 − c1) ∧ (bd

if (E1|2 − c1 < bd
(E2|1 − c2 < bd
1 > E1,0 − c1) ∧ (bd
1 > E1|2 − c1)
(bd
1 < E1|2 − c1) ∧ (bd
if (bd
(cid:80)
1 > E1,0 − c1) ∧ (bd
if (bd

2 > E2,0 − c2)
2 < E2|1 − c2)

00.20.40.60.8100.10.20.30.40.5NE borders with players GP1 and P5pac  max(t1, t2)pamin(t10,t20)00.20.40.60.8100.10.20.30.40.5NE borders with players GP1 and C7pac  max(t1,t2)pa min(t10,t20)00.20.40.60.8100.10.20.30.40.5NE borders with players C7 and C8pac  max(t1,t2)pa min(t10,t20)Fig. 4: Dependence of the NE w.r.t. the genome-sharing beneﬁts bd

1 and bd
2.

Discussion: We conclude that, in Gd, if the discrepancy between the sharing
beneﬁts perceived by the players is high enough, these players follow opposite
strategies, one putting the other’s privacy at risk by sharing his genome.

4.2 Altruistic Players

In this subsection, we analyze how the equilibria evolve when the players are
not purely selﬁsh, but also consider their relatives’ payoﬀs when making their
decisions. Intuitively, by becoming more socially concerned, the players’ deci-
sions and their resulting NE should lead to higher social welfare. However, as
we will see, social welfare does not always increase with altruism, unless some
coordination between players happens.

To evaluate how the NE is aﬀected by altruistic behavior, we focus on
game Gd. Player P1 considers the altruistic payoﬀ ua
1(d1, d2) = u1(d1, d2) +
αk(1,2)u2(d1, d2), instead of merely u1(d1, d2). The same applies symmetrically
for P2. We deﬁne the familial Nash equilibrium (FNE) as a strategy proﬁle
where, given the other player’s strategy, no player can reduce his altruistic pay-
oﬀ ua by unilaterally changing his strategy. Deﬁning bi = bd
i + ci for the ease of
presentation, we have the following theorem.
Theorem 3. For any value b1 ∈ [0,∞), and b2 ∈ [0,∞), the pure FNE is:

(1, 1), (0, 0)

(d∗
1, d∗

2) =



(0, 0)

(1, 1)

(1, 0)
(0, 1)

2 < E2,0 + αk(E1,0 − E1|2))

if(cid:0)(b1 < E1,0 + αk(E2,0 − E2|1)) ∧ (b2 < E2|1)(cid:1)∨
if(cid:0)(b1 > E1,0 + αk(E2,0 − E2|1)) ∧ (b2 > E2|1)(cid:1)∨

(b1 < E1|2) ∧ (bd
if (E1|2 < b1 < E1,0 +αk(E2,0−E2|1)∧
(E2|1 < b2 < E2,0 + αk(E1,0 − E1|2)
(b1 > E1|2) ∧ (b2 > E2,0 + αk(E1,0 − E1|2)
if (b1 > E1,0 + αk(E2,0 − E2|1)) ∧ (b2 < E2|1)
if (b1 < E1|2) ∧ (b2 > E2,0 + αk(E1,0 − E1|2)

31(cid:80)

(cid:80)

where Ei,0 = 1|Ω|
if i and j
are direct kth-degree relatives and, if i and j are not in direct line, Ei|j =
1|Ω|

i, Ei|j = 1|Ω|

l:gl∈Ω πlDyl

l:gl∈Ω πlP k

l:gl∈Ω πlP u

l DM P v

l Dyl
i

l yl
i.

This proof can be found in [15]. These diﬀerent NE are depicted in Fig. 5 by
circled numbers separated by (thick) dotted lines. Note the shift upwards and
to the right of the borders of the (0, 0) FNE, compared to the selﬁsh NE (red
dotted lines). This tells us that, by considering the other’s player utility, the
decision maker will choose to disclose his genome for a value of bi higher than
in the purely selﬁsh scenario.
Discussion: We conclude that altruism, by internalizing externalities into play-
ers’ payoﬀs, tends to reduce the privacy loss caused by the other player.

We now describe the strategies that a social planner would choose on behalf of
the players in order to maximize social welfare, thus to attain the social optimum
U∗.
Theorem 4. For any value b1 ∈ [0,∞), and b2 ∈ [0,∞), the social optimum
U∗ is reached with the following strategies:

(d∗
1, d∗

2) =



(0, 0)

(1, 0)
(0, 1)
(1, 1)

(cid:80)

(cid:80)

(cid:80)

(b2 < E1,0 + E2,0 − E1|2)

if (b1 + b2 < E1,0 + E2,0) ∧ (b1 < E1,0 + E2,0 − E2|1) ∧
if (b1 > E1,0 + E2,0 − E2|1) ∧ (b2 < E2|1)
if (b2 > E1,0 + E2,0 − E1|2) ∧ (b1 < E1|2)
if (b1 + b2 > E1,0 + E2,0) ∧ (b2 > E2|1) ∧ (b1 > E1|2)

(8)

(cid:80)

where Ei,0 = 1|Ω|
if i and j
are direct kth-degree relatives and, if i and j are not in direct line, Ei|j =
1|Ω|

i, Ei|j = 1|Ω|

l:gl∈Ω πlDyl

l:gl∈Ω πlP k

l:gl∈Ω πlP u

l DM P v

l Dyl
i

l yl
i.

This proof can be found in [15]. The socially optimal strategies are repre-
sented schematically with respect to b1 and b2 by the texture of Fig. 5. Given
this social optimum U∗(s), the price of anarchy (PoA), which measures how the
game eﬃciency decreases due to selﬁshness, is deﬁned as U∗(s)/ minN E U (s) [18].
The price of stability (PoS) also measures this ineﬃciency but, assuming that
players coordinate amongst themselves, considers the best NE instead of the
worst one, i.e., is deﬁned as U∗(s)/ maxN E U (s) [4].

Following the notion of windfall of friendship (WoF) proposed in [21], we
deﬁne the windfall of kinship (WoK) as the ratio between the social welfare of
the worst FNE and the social welfare of the worst NE:

κ(α, k) =

minF N E U (s)
minN E U (s)

(9)

Given this deﬁnition, we can state the following theorem.

Fig. 5: Familial NE and social optima with respect to b1 and b2. Circled numbers
represent the ﬁve diﬀerent cases of Theorem 3, in order, separated by (thick)
dotted lines in the ﬁgure. The red (small) dotted lines represent the borders of
Fig. 4. The four diﬀerent texture patterns represent the strategies of the social
optimum, depicted in Theorem 4: white for (0, 0), vertical lines for (1, 0), horizon-
tal lines for (0, 1), and dots for (1, 1). The single asterisk is E1,0 +αk(E2,0−E2|1),
and the double asterisk is E1,0 + E2,0 − E2|1.

Theorem 5. If b1, b2 are such that

b1 + b2 > E1,0 + E2,0

b1 < E1,0 + αk(E2,0 − E2|1)
b2 < E2,0 + αk(E1,0 − E1|2),

(10)

then κ(α, k) < 1 for any k ≥ 1 and 0 < α ≤ 1.

This proof can be found in [15]. This theorem tells us that, contrary to
intuition, altruism in a family does not necessarily lead to higher social welfare,
and induces a price of kinship rather than a windfall if the bi’s are in the range
deﬁned in (10). In this range, the social optimum is to disclose their genomes for
both players, but there is the possibility to end up in a “non-disclose” (0, 0) FNE
due to the altruistic factor, leading to an outcome worse than in the selﬁsh NE.
However, note that the WoK is always less than or equal to the PoA. Indeed, as
for any α ∈ [0, 1], k ≥ 1, minF N E U (s) ≤ U∗(s), it directly follows from (9) that
κ(α, k) ≤ PoA.

If we assume that some coordination can happen between the players, we
can deﬁne the windfall of coordinated kinship (WoCK) as the ratio between the
social welfare of the best FNE and the social welfare of the best NE:

γ(α, k) =

maxF N E U (s)
maxN E U (s)

(11)

This new deﬁnition enables us to state the following theorem.

32***12354(a)

(b)

(c)

(d)

(e)

(f)

Fig. 6: Evaluation of the (in)eﬃciency of the NE and FNE with respect to b1 and
b2. (a) Minimum social welfare at NE, (b) windfall/price of kinship, (c) price of
anarchy, (d) minimum social welfare at FNE, (e) windfall of coordinated kinship,
and (f) price of stability in Gd with GP1 and P5, α = 0.8, and bg

2 = 0.5.

1 = bg

Theorem 6. For any b1 ∈ [0,∞), b2 ∈ [0,∞), k ≥ 1, and α ∈ [0, 1], it holds
that:

1 ≤ γ(α, k) ≤ PoS ≤ PoA.

(12)

1 = bg

This proof can be found in [15]. In order to evaluate how the NE, FNE, WoK,
WoCK, PoA, and PoS evolve in practice, we make use of the genomic data
provided by the Utah family. We choose the two relatives GP1 and P5, and
compute their genomic privacy based on their actual SNPs, as in Subsection 4.1.
We set α = 0.8, bg
2 = 0.5 and compute results (NE, FNE, ...) for b1 and
b2 varying between 0 and 1, with granularity 0.01. Fig. 6 shows the resulting
graphs. First, we notice the shift upwards and to the right of (0, 0) between NE
and FNE; it follows the borders shown in Fig. 5. We also see that minimum
social welfare is minimal in the squares standing in the middle of both Figs. 6a
and 6d. Looking at Fig. 6b, we clearly notice that the WoK is smaller than 1
for the values of b1 and b2 close to 0.5, thus conﬁrming Theorem 5. However,
as soon as both players coordinate amongst themselves, the ratio between the
social welfare of FNE and the social welfare of NE (WoCK) becomes always
greater than or equal to 1, as illustrated in Fig. 6e. Finally, we note that PoA
and PoS are always greater than or equal to 1, that PoS ≤ PoA, and that PoS
≥ WoCK, thus conﬁrming Theorem 6.
Discussion: In conclusion, if players cannot coordinate amongst themselves,
their altruistic prudence about the disclosure of their genomes can lead to a

b1b2Minimum utility at NE  0.20.40.60.810.20.40.60.810.811.21.41.61.82b1b2Windfall/Price of Kinship  0.20.40.60.810.20.40.60.810.850.90.9511.051.1b1b2Price of Anarchy  0.20.40.60.810.20.40.60.8111.051.11.151.21.251.3b1b2Minimum utility at FNE  0.20.40.60.810.20.40.60.810.811.21.41.61.82b1b2Windfall of Coordinated Kinship  0.20.40.60.810.20.40.60.810.850.90.9511.051.1b1b2Price of Stability  0.20.40.60.810.20.40.60.8111.051.11.151.21.251.3worse social outcome than in the purely selﬁsh setting, as shown in Theorem 5
and in Fig. 6b.

5 N-Player Game

In this section, we extend the genomic privacy game to consider N > 2 relatives.
Contrary to the two-player framework that allowed us to derive closed-form
expressions, and thus compute all pure Nash equilibria very eﬃciently, we now
face a more challenging problem. First, in general, all players (family members)
can inﬂuence other players’ payoﬀs, thus all other players’ strategies have to be
taken into account when a family member optimizes his own decision. Second,
privacy levels Ei|−i cannot be expressed in closed form if more than one other
family member discloses their genomes.

In order to represent this complex game in a compact way and reduce its
complexity, we rely upon multi-agent inﬂuence diagrams (MAIDs), introduced
by Koller and Milch [17]. A MAID is an extension of the Bayesian network
framework that embeds, in addition to random variables, decision and utility
variables, and enables us to consider multiple strategic agents, thus represent
games. We deﬁne a MAID Md representing the N-player genomic-privacy game
Gd. We show an example of Md for a trio in Fig. 7. The chance11 variable Yi
is deﬁned as P (Yi = yi) = 1 (other values having probability 0) if di = 1, and
P (Yi = ˆyi|YO) if di = 0. Note that, we represent the chance variable Yi for a
single SNP, but in fact there are |Ω| chance variables that directly depend on di,
and are independent of each other. A child’s SNP is probabilistically determined
by his parents’ genomes, as explained in [14]. We also deﬁne two utility variables:
i − Ei,0, which directly depends on di, and ui2 = Ei, which directly
ui1 = bg
depends on the chance variable Yi. Note that Ei is zero if di = 1 (genomic privacy
drops to zero) and Ei = Ei|−i if di = 0. Then, Pi’s payoﬀ ui is ui1 + ui2.

i + dibd

We assume that players move (decide) sequentially and with perfect infor-
mation of previous decisions made by other players. Variables observed when a
decision is made are depicted by dotted directed edges. For instance, in Fig. 7,
the following decision ordering is shown: mother, father and then child. Under
these assumptions, we can state the following lemma.
Lemma 4. If a player Pi ∈ P moves, i.e., chooses his decision rule, at node Di
before Pj makes his own decision at node Dj, then Di is not s-reachable from
Dj.

The proof directly follows from the concept of s-reachability, deﬁned in Deﬁnition
5.3 of [17]. If Di is s-reachable from Dj, then Di is relevant to Dj or, in other
words, Dj strategically relies on Di. If a decision node Di is observed by Dj
(dotted edge in Fig. 7), it means that the decision rule δ(dj) at Dj will be
conditioned on the instantiations of Di. The decision rule at Dj will be deﬁned
as δ(dj|di),∀di ∈ {0, 1}, thus this decision will not be aﬀected by a change in
11 In MAIDs, random variables are called chance variables.

Fig. 7: Multi-agent inﬂuence diagram representing a trio (mother, father, child)
with one decision variable (square), one chance variable (circle) representing the
SNPs of the individual, and two utility variables (diamonds) per person. Full
lines represent probabilistic or deterministic dependencies, whereas dotted lines
represent the variables that an agent observes when he makes his decision. This
ﬁgure illustrates a game with sequential moves, perfect information, and with
purely selﬁsh players.

Di. However, because Dj is not observed by Pi when he makes his decision,
Dj will be relevant to Di, thus s-reachable from Di. Under perfect information,
we can deﬁne, by using Lemma 4, for any sequence of strategic decision among
players, an acyclic relevance graph12. From this acyclic relevance graph, we can
construct a topological ordering of the decision nodes D1, ..., DN such that if Di is
s-reachable from Dj, then i < j. In the example shown in Fig. 7, the topological
ordering is DC, DF , DM . In the general case, the topological ordering is such
that, if Pi chooses his decision rule before Pj, then j < i. Hence, the topological
ordering corresponds to the reverse decision order.
Theorem 7. By iteratively deriving the optimal decision rule δ∗(di|paDi) for
each node Di in topological order, and every instantiation paDi of its parents in
the MAID, we obtain a strategy proﬁle d∗ that is a Nash equilibrium of Md.
This theorem essentially follows from Algorithm 6.1 and Theorem 6.1 of [17].
Note that, in our scenario, under the perfect information assumption, we do not
need to deﬁne an arbitrary fully-mixed strategy proﬁle at the beginning of the
algorithm. The algorithm deﬁned by Theorem 7 is similar to the one deﬁned
by backward induction in extensive-form games. However, the MAID approach
enables us to run inference on Md in order to compute the expected utilities
given the decision rules of every player, and to eventually ﬁnd a NE in O(|Ω|2N )
instead of O(|Ω|32N ) in the extensive-form game.

12 See the deﬁnition of a relevance graph in Deﬁnition 5.4 of [17].

YMYFYCDCUC2DMDFUF2UM2UM1UF1UC1(a)

(b)

(c)

(d)

(e)

(f)

Fig. 8: Outcome of the N-player game. Number of players disclosing their
genomes (ﬁrst row) and social welfare (second row) at NE in the N-player game
Gd. We set b2 = 0.4 in (a) and (d), b2 = 0.6 in (b) and (e), and b2 = 0.8 in (c)
and (f).

We numerically compute the NE of the N-player game Gd by using the Utah
family dataset. We assume the sequence of decisions to be the following: GP1,
GP2, GP3, GP4, P5, P6, C7, C8, and C9. We skip the details of the algorithm
and inference, and we provide the main numerical results. We focus on 1,000
randomly chosen SNPs of chromosome 1,13, and we compute the NE and result-
ing social welfare of the family for varying values of bi’s. We assume bi = b1 for
all grandparents, bi = b2 for all parents, and bi = b3 for all children. We make
b1 and b3 vary between 0 and 1 with granularity 0.1, and b2 be equal to 0.4
(ﬁrst column of Fig. 8), 0.6 (second column of Fig. 8) and 0.8 (third column of
Fig. 8). In the ﬁrst row of Fig. 8, we see the number of players who disclose their
genomes at NE. In Fig. 8a, because b2 is quite small (0.4), if b1 and b2 are also
small (≤ 0.4), then nobody has the incentive to share his genome. If b1 or b3 are
high enough for the grandparents and the children to share their genomes, this
will automatically lead the parents to do the same because their genomic privacy
will be reduced by their relatives’ decision. We see this in the left strip where
b3 ≥ 0.5 and b1 ≤ 0.2: Five relatives disclose their SNPs, the three children and
the two parents. By increasing b1 to 0.3, then two of the four grandparents have
the incentive to share their SNPs, considering their privacy levels. We notice
that when b2 increases to 0.6 (Fig. 8b) and 0.8 (Fig. 8c), then even if b1 and b3

13 As in Section 4, LD is not used as we assume the same set Ω of SNPs potentially

shared by the players and targeted by the adversary.

b1b3Number of players disclosing their genomes at NE  0.10.30.50.70.900.10.20.30.40.50.60.70.80.910123456789b1b3Number of players disclosing their genomes at NE  0.10.30.50.70.900.10.20.30.40.50.60.70.80.910123456789b1b3Number of players disclosing their genomes at NE  0.10.30.50.70.900.10.20.30.40.50.60.70.80.910123456789b1b3Social welfare at NE  0.10.30.50.70.900.10.20.30.40.50.60.70.80.913.544.555.566.577.588.59b1b3Social welfare at NE  0.10.30.50.70.900.10.20.30.40.50.60.70.80.913.544.555.566.577.588.59b1b3Social welfare at NE  0.10.30.50.70.900.10.20.30.40.50.60.70.80.913.544.555.566.577.588.59are very small, the parents’ best responses are to disclose their SNPs. Then, if
b1 increases to 0.3 while b3 ≤ 0.1 (bottom strip), then two grandparents have
the incentive to share their SNPs (4 players thus share them), and from b1 ≥ 0.4
all grandparents have the incentive to disclose their genomes.
Discussion: We conclude that, in some cases, when the perceived beneﬁts do
not clearly outweigh the genomic privacy losses, some people with the same
perceived beneﬁts might end up with diﬀerent strategies at equilibrium.

Looking now at the social welfare values at NE, the most interesting ﬁnding
is that the social welfare decreases between Fig. 8d and Fig. 8e for values of
b1 and b3 smaller than 0.5, even though b2 increases from 0.4 to 0.6. This is
due to the privacy externalities created by the parents disclosing their SNPs,
whereas grandparents and children have no incentives to do the same. Hence,
misaligned incentives have a negative impact on the social welfare of a family.
In future work, we intend to extend this model to altruistic players and see if
this improves the global outcome. Our MAID Md model can be easily adapted
to take altruism into account.

We note that the proposed N-player game requires all family members to
give their decisions sequentially but at a given time instant, which might not
be feasible in real life, considering infants or even unborn family members. In
future work, we plan to extend our current model in order to take into account
the inherent dynamic nature of life.

6 Related Work

Interdependent risks in privacy have recently been demonstrated and explored
in diﬀerent settings. Due to their intrinsic social nature, online social networks
(OSNs) are especially prone to indirect privacy risks. Mislove et al. evaluate the
fraction of users in an OSN that would be suﬃcient in order to infer attributes
of the remaining users [22]. Henne et al. study how OSN pictures uploaded by
friends can reveal information about one’s own location [13]. Dey et al. analyze
the risk of age inference in OSNs, notably by relying on information posted
by users’ friends and friends-of-friends [7]. In the context of location privacy,
Vratonjic et al. show how mobile users connecting to location-based services
from the same IP address can indirectly compromise the location privacy of
others [27]. Olteanu et al. study how users reporting co-locations with other
users (e.g., on online social networks) can decrease others’ location privacy [23].
In order to precisely quantify the eﬀect of co-location information, they propose
an optimal inference algorithm and two polynomial-time approximate inference
algorithms. Humbert et al. propose a framework to quantify the damage to
genomic privacy caused by relatives [14]. We extend this framework to study the
interplay between rational agents with diﬀerent motivations and utilities related
to their genomic privacy, considering selﬁsh and altruistic behaviors.

Acquisti et al. were among the ﬁrst to propose an economic model for for-
malizing incentives and interactions between rational agents in the context of
privacy [2]. More precisely, the authors rely on a game-theoretic approach in

order to study the incentives and behaviors of participants in anonymity net-
works. Freudiger et al. analyze, by using game theory, the behavior of selﬁsh
mobile nodes that want to protect their location privacy at a minimum cost [10].
Bicz´ok and Chia tackle, by using a game-theoretic framework, the issue of in-
terdependent risks caused by agents with misaligned incentives regarding their
privacy in online social networks [5]. They show how negative externalities can
lead to ineﬃcient equilibria in scenarios where two users decide about the adop-
tion of an app. Pu and Grossklags go one step further by studying large groups
of users who take others’ preferences into account when making their own deci-
sions [24]. These works build upon the literature on IDS games, surveyed in [20].
We follow a similar approach for genomic privacy. In addition, precisely quantify
by using real data the possible direct and indirect privacy losses with a prob-
abilistic framework. The non-linear dependencies between players in genomic
privacy are also novel compared to previous work.

7 Conclusion and Future Work

In this work, focusing on the privacy of genomic data, we have studied the strate-
gic decisions of family members about whether to disclose their genomes and how
to secure their storage on personal devices. By using a game-theoretic approach,
we have modeled the interplay between family members with diﬀerent incentives
and have predicted their behaviors at equilibrium. First, we extensively studied
a two-player game between two either selﬁsh or altruistic family members. Then,
using multi-agent inﬂuence diagrams we have extended this to an N-player game.
We believe that the proposed models can help the family members choose how
to protect the privacy of their genomic data while still helping medical research
and beneﬁting from the merits of genomics. In future work, we will study games
with altruistic behaviors in the N-player game.

Acknowledgments

We would like to thank K´evin Huguenin and Alexandra-Mihaela Olteanu for
their helpful comments and feedback.

References

1. http://www.vox.com/2014/9/9/5975653/with-genetic-testing-i-gave-my-

parents-the-gift-of-divorce-23andme.

2. A. Acquisti, R. Dingledine, and P. Syverson. On the economics of anonymity. In

Financial Cryptography, pages 84–102. Springer, 2003.

3. R. Anderson and T. Moore. The economics of information security. Science,

314(5799):610–613, 2006.

4. E. Anshelevich, A. Dasgupta, J. Kleinberg, E. Tardos, T. Wexler, and T. Rough-
garden. The price of stability for network design with fair cost allocation. SIAM
Journal on Computing, 38(4):1602–1623, 2008.

5. G. Bicz´ok and P. H. Chia. Interdependent privacy: Let me share your data. In

Financial Cryptography and Data Security, pages 338–353. Springer, 2013.

6. E. De Cristofaro, S. Faber, P. Gasti, and G. Tsudik. Genodroid: Are privacy-

preserving genomic tests ready for prime time? In ACM WPES, 2012.

7. R. Dey, C. Tang, K. Ross, and N. Saxena. Estimating age privacy leakage in online

social networks. In IEEE INFOCOM, 2012.

8. R. Drmanac, A. B. Sparks, M. J. Callow, A. L. Halpern, N. L. Burns, B. G.
Kermani, P. Carnevali, I. Nazarenko, G. B. Nilsen, G. Yeung, et al. Human genome
sequencing using unchained base reads on self-assembling dna nanoarrays. Science,
327(5961):78–81, 2010.

9. Y. Erlich and A. Narayanan. Routes for breaching and protecting genetic privacy.

Nature Reviews Genetics, 15(6):409–421, 2014.

10. J. Freudiger, M. H. Manshaei, J.-P. Hubaux, and D. C. Parkes. On non-cooperative

location privacy: A game-theoretic analysis. In ACM CCS, 2009.

11. J. Grossklags, B. Johnson, and N. Christin. The price of uncertainty in security

games. In Economics of Information Security and Privacy. Springer, 2010.

12. M. Gymrek, A. L. McGuire, D. Golan, E. Halperin, and Y. Erlich.

Identifying

personal genomes by surname inference. Science: 339 (6117), Jan. 2013.

13. B. Henne, C. Szongott, and M. Smith. SnapMe if you can: Privacy threats of other

peoples’ geo-tagged media and what we can do about it. In ACM WiSec, 2013.

14. M. Humbert, E. Ayday, J. P. Hubaux, and A. Telenti. Addressing the concerns of

the Lacks Family: Quantiﬁcation of kin genomic privacy. In ACM CCS, 2013.

15. M. Humbert, E. Ayday, J.-P. Hubaux, and A. Telenti.

Interdependent privacy

games: the case of genomics. Technical Report, EPFL-REPORT-203825, 2014.

16. M. Humbert, E. Ayday, J.-P. Hubaux, and A. Telenti. Reconciling utility with

privacy in genomics. In ACM WPES, 2014.

17. D. Koller and B. Milch. Multi-agent inﬂuence diagrams for representing and solving

games. Games and Economic Behavior, 45(1):181–221, 2003.

18. E. Koutsoupias and C. Papadimitriou. Worst-case equilibria. In STACS, 1999.
19. H. Kunreuther and G. Heal. Interdependent security. Journal of Risk and Uncer-

tainty, 26(2-3):231–249, 2003.

20. A. Laszka, M. Felegyhazi, and L. Butty´an. A survey of interdependent security

games. CrySyS Lab Technical Report No. CRYSYS-TR-2012-11-15, 2012.

21. D. Meier, Y. A. Oswald, S. Schmid, and R. Wattenhofer. On the windfall of

friendship: Inoculation strategies on social networks. In ACM EC, 2008.

22. A. Mislove, B. Viswanath, K. P. Gummadi, and P. Druschel. You are who you

know: Inferring user proﬁles in online social networks. In ACM WSDM, 2010.

23. A. M. Olteanu, K. Huguenin, R. Shokri, and J.-P. Hubaux. Quantifying the eﬀect

of co-location information on location privacy. In PETS, 2014.

24. Y. Pu and J. Grossklags. An economic model and simulation results of app adop-
tion decisions on networks with interdependent privacy consequences. In Decision
and Game Theory for Security, pages 246–265. Springer, 2014.

25. G. Suarez-Tangil, J. Tapiador, P. Peris-Lopez, and A. Ribagorda. Evolution, de-
tection and analysis of malware for smart devices. IEEE Communications Surveys
and Tutorials, 2013.

26. L. Sweeney, A. Abu, and J. Winn. Identifying participants in the personal genome

project by name. Available at SSRN 2257732, 2013.

27. N. Vratonjic, K. Huguenin, V. Bindschaedler, and J.-P. Hubaux. How others com-
promise your location privacy: The case of shared public ips at hotspots. In Privacy
Enhancing Technologies, pages 123–142. Springer, 2013.

