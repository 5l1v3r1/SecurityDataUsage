Liar, Liar, Coins on Fire!

Penalizing Equivocation by Loss of Bitcoins

Tim Rufﬁng

CISPA, Saarland University

tim.rufﬁng@mmci.uni-saarland.de

Aniket Kate

∗
Purdue University
aniket@purdue.edu

Dominique Schröder
CISPA, Saarland University

schroeder@cs.uni-saarland.de

ABSTRACT
We show that equivocation, i.e., making conﬂicting state-
ments to others in a distributed protocol, can be monetar-
ily disincentivized by the use of crypto-currencies such as
Bitcoin. To this end, we design completely decentralized
non-equivocation contracts, which make it possible to pe-
nalize an equivocating party by the loss of its money. At
the core of these contracts, there is a novel cryptographic
primitive called accountable assertions, which reveals the
party’s Bitcoin credentials if it equivocates.
Non-equivocation contracts are particularly useful for dis-
tributed systems that employ public append-only logs to
protect data integrity, e.g., in cloud storage and social net-
works. Moreover, as double-spending in Bitcoin is a special
case of equivocation, the contracts enable us to design a
payment protocol that allows a payee to receive funds at
several unsynchronized points of sale, while being able to
penalize a double-spending payer after the fact.

Categories and Subject Descriptors
C2.4 [Computer-communication networks]: Distributed
systems; K4.4 [Computers and society]: Electronic com-
merce—cybercash, digital cash, payment schemes, security

Keywords
crypto-currencies; Bitcoin; equivocation; append-only logs;
accountability; double-spending; payment channels

1.

INTRODUCTION

Making conﬂicting statements to others, or equivocation,
is a simple yet remarkably powerful tool of malicious par-
ticipants in distributed systems of all kinds [4, 19, 20, 33].
In distributed computing protocols, equivocation leads to
Byzantine faults and fairness issues. When feasible, equivo-
cation is handled by assuming an honest majority (i.e., larger
∗The work was done while the author was still at Saarland
University.
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813686.

replication factors [27]), synchrony assumptions and digital
signatures [26], or trusted hardware [4, 19, 20, 33]. Moreover,
publicly veriﬁable append-only logs [22, 23, 24, 35] make it
possible to detect equivocation after the fact but they do not
suﬃce to stop or penalize equivocation.

Decentralized crypto-currency systems such as Bitcoin [10,
36] and its derivatives follow a novel approach to handle
equivocation. To protect against equivocation in the form
of double-spending, i.e., spending the same funds to diﬀer-
ent parties, Bitcoin employs a special decentralized public
append-only log based on proof of work called the blockchain:
In a decentralized crypto-currency, users transfer their funds
by publishing digitally signed transactions. Transactions are
conﬁrmed only when they are included in the blockchain,
which is generated by currency miners that solve proof-of-
work puzzles. Although a malicious owner can sign over the
same funds to multiple receivers through multiple transac-
tions, eventually only one transaction will be approved and
added to the publicly veriﬁable blockchain.

As a result, to stop equivocation, it is possible to record all
messages in a distributed system that are vulnerable to equiv-
ocation in a blockchain. Nevertheless, due to proof-of-work
computations and the decentralized nature of blockchain sys-
tems, the process of reaching consensus is not only expensive
but also only slowly converging. In Bitcoin, it takes tens of
minutes to reach consensus on the set of valid transactions.
To enable transactions be performed faster, a contractual
solution in the form of payment channels [45, 48] is emerging
in the Bitcoin community [39, 47]. Here, a payer makes a
time-locked deposit for his predetermined payee such that
double-spending (or equivocation) is excluded even when pay-
ments are performed oﬄine and without waiting. However,
payment channels are not secure against double-spending
when the payee runs several geographically distributed and
unsynchronized points of sale, e.g., a bus company selling
tickets on buses with only sporadic Internet connectivity.

Our goal in this paper is to address these equivocation
issues by a generic solution that disincentives paltering and
is applicable to various distributed systems and scenarios
including the aforementioned payment channels with unsyn-
chronized points of sale.

1.1 Contributions

Our key idea towards preventing equivocation is to use

Bitcoin to prescribe a monetary penalty for equivocation.
Accountable Assertions. As a ﬁrst step, we establish
a cryptographic connection between equivocation and the
loss of funds by introducing a cryptographic primitive called

219accountable assertions (Section 4). The main idea of this
primitive is to bind statements to contexts in an accountable
way: if the attacker equivocates, i.e., asserts two contradict-
ing statements in the same context, then any observer can
extract the attacker’s Bitcoin secret key and, as a result, use
it to force the loss of the attacker’s funds.

We present a construction of accountable assertions based
on chameleon hash functions [30] and prove it secure in
the random oracle model under the discrete logarithm as-
sumption (Section 5). A performance evaluation of our
construction demonstrates its practicality with respect to
computation, communication, and storage costs.
Non-equivocation Contracts. To ensure that a secret
key obtained through equivocation is indeed associated with
funds, every party that should be prevented from equivo-
cating is required to put aside a certain amount of funds in
a deposit [2, 6, 32, 40]. These funds are time-locked in the
deposit, i.e., the depositor cannot withdraw them during a
predetermined time period. This prevents an attacker from
spending the funds and thus rendering the secret key useless
just before equivocating.

Accountable assertions and deposits together enable us
to design non-equivocation contracts, a generic method to
penalize paltering in distributed systems (Section 6). We
propose several applications of non-equivocation contracts
to ensure the linearity of append-only logs [22, 23, 24, 35].
Asynchronous Payment Channels. Bitcoin payment
channels protocols [45, 48] enable a user to perform pay-
ments to a predetermined party oﬄine and without waiting
for the consensus process.

However, if a payee is a distributed entity (e.g., a bus
service with several buses as points of sale with only spo-
radic Internet connectivity) then even payment channels do
not prevent double-spending. Since double-spending is an
instance of equivocation, non-equivocation contracts enable
us to design asynchronous payment channels, which make it
possible to penalize double-spending payers (Section 7).
Double-Authentication-Preventing Signatures. Of in-
dependent interest, we observe that accountable assertions
are similar to double-authentication-preventing signatures
(DAPS) as proposed by Poettering and Stebila [38]. While
accountable assertions are in general a weaker primitive, cer-
tain accountable assertions are DAPS. It was left as an open
problem to construct DAPS based on trees or chameleon hash
functions [38]. We solve these problems, and our account-
able assertion scheme based on Merkle tress and chameleon
hash functions in the random oracle model yields the ﬁrst
DAPS scheme secure under the discrete logarithm assump-
tion (Appendix A). For practical parameters, it is two orders
of magnitude faster than the original DAPS construction [38],
and uses one order of magnitude less communication.

2. OVERVIEW

We conceptualize decentralized non-equivocation contracts

and discuss their potential applications.
Problem Statement. Equivocation, i.e., making conﬂict-
ing statements to diﬀerent protocol parties, is a universal
problem in malicious fault-tolerant security protocols involv-
ing three or more parties [4, 19, 20, 33]. In all bounded or
partial synchronous communication settings, equivocation
can be detected using digital signatures (together with a
public-key infrastructure) and some interaction among the

parties [20]: two recipients who are expected to receive the
same message from a sender can exchange the received signed
messages to expose and prove equivocation. This principle
underlies many append-only logs [22, 23, 24, 35].

However, it is often not possible to impose a penalty on
the maliciously or carelessly equivocating sender after the
fact, as the sender may be anonymous or pseudonymous.
Even when the sender is not anonymous and may lose her
reputation once a case of equivocation is detected, the eﬀect
of such paltering on the recipient can be damaging.
Key Idea. Our key idea is to let the sender create a time-
locked Bitcoin deposit [2, 6, 32, 40] that can be opened
by the recipients if the sender equivocates. In case of an
equivocation, the funds will be given either to a predeﬁned
beneﬁciary or, once the expiry time of the deposit is reached,
to the miners.
If the expected loss is high enough, the
attacker has no incentive to make conﬂicting statements.
Threat Model. The attacker is a malicious sender whose
goal is to equivocate without losing the deposit. To achieve
that goal, the attacker can deviate arbitrarily from the pre-
scribed protocol but she does not risk to lose her deposit if
the expected loss is higher than the expected gain.

We assume that the attacker cannot break the fundamental
security of Bitcoin, e.g., the attacker does not have the
majority of computing power in the Bitcoin network.
Non-equivocation Contracts. We describe the main idea
of non-equivocation contracts, which are a form of smart
contracts [11, 29, 40], in more detail. The sender A creates
a time-locked deposit as a guarantee for her honest behavior.
The deposit is secured by the sender’s secret key sk A; the
corresponding public key is pk A
. Furthermore, the deposit
expires at some point T in the future. That is, even though
A owns the secret key sk A, she cannot access the funds in
the deposit until time T . Before time T , only A together
with a predeﬁned beneﬁciary P can access the funds. This
beneﬁciary will be given the funds if A equivocates. (There
is also a variant of deposits for which the beneﬁciary is a
randomly selected miner. We will explain this later.)

Once the deposit is conﬁrmed by the Bitcoin network,
parties are ready to receive statements from the sender A.
Non-equivocating contracts are built on the idea that it
is possible to learn the key sk A if the sender A equivocates.
To enforce this cryptographically, we introduce accountable
assertions, which allow the user A to produce assertions τ of
statements st in contexts ct (where st and ct can be arbitrary
bitstrings) under the public key pk A
The sender A is held accountable in the following sense:
If A behaves honestly, sk A will stay secret, and A can use
it to withdraw the deposit once time T has been reached.
However, if A equivocates to some honest users B and C,
i.e., A asserts two diﬀerent statements st0 6= st1 in the same
context ct, then B and C can use st0, st1, ct and the two
corresponding assertions τ0 and τ1 to extract the sender’s
secret key sk A. Due to the way the deposit is created, the
recipients B and C alone cannot make use of sk A. However,
B and C can send sk A to the beneﬁciary P , who can use
sk A together with his credentials to withdraw the deposit
and thereby penalize the malicious sender A.
Note that B, C and P could as well be protocol parties
that belong to essentially the same distributed entity but are
just not synchronized when receiving statements from A.

.

2203. BACKGROUND ON BITCOIN

Bitcoin is an online digital cryptographic currency run
by a decentralized peer-to-peer network. In this section, we
explain the basics of Bitcoin that are relevant to our work.
For a detailed explanation of the mechanics of Bitcoin, we
refer the reader to the Bitcoin developer guide [7].

A user in the Bitcoin network is identiﬁed using one or
more pseudonymous addresses. Technically, an address is
the hash of a public key pk of the ECDSA signature scheme
such that the owner of the corresponding secret key sk can
use it to transfer bitcoins (symbol: B) associated with her
address to another address by signing transactions.
Blockchain. Miners include transactions in blocks. By
solving a proof-of-work (POW) puzzle, a block including its
transactions is added to the blockchain. Once added, a block
and its transactions are diﬃcult to modify because blocks are
cryptographically chained together, and modifying a block
involves re-doing the POW for this and all sequential blocks.
A transaction that has been included in the blockchain and
backed up by the POW computations of several blocks is
thus diﬃcult to invalidate. Most users consider a transaction
conﬁrmed if it has has been backed up by least six blocks,
and the Bitcoin network takes 10 min on average to perform
the POW of one block.
Scripts. Bitcoin employs a scripting language to specify
under which conditions an unspent output, i.e., some unspent
funds in the blockchain, can be spent. The language is a
simple stack-based language. It is intentionally not Turing-
complete to avoid complexity and the possibility of creating
scripts that are expensive to execute, and could consequently
lead to denial-of-service attacks, because every node in the
Bitcoin network must execute them.

Each transaction sends funds to a script (called ScriptPub-
Key), i.e., a small program that speciﬁes the conditions that
must be fulﬁlled to spend the funds. To spend the funds,
the spender must provide an initial execution stack with
input values. The transaction is valid if the script terminates
successfully on this initial stack.
3.1 Deposits

Using specially-crafted scripts, funds can be locked away
in a so-called deposit, where they can only be accessed under
a set of predetermined conditions. While scripts can express
a variety of such conditions [7], we focus on time-locked
deposits with the property that the depositor cannot access
the funds in the deposit until a speciﬁed expiry time.
With non-equivocation contracts in mind, we consider two
types of deposits that diﬀer in the beneﬁciary, i.e., the party
that receives the funds in case of equivocation. The deposits
of the ﬁrst type do not specify a beneﬁciary. In this case, the
beneﬁciary will be a randomly selected miner. Deposits of
the second type are associated with an explicitly beneﬁciary
P identiﬁed by his public key pk P
Creating Deposits. To create time-locked deposits, we
use an upcoming feature [17] in Bitcoin, which introduces a
new script command denoted by CHECKLOCKTIMEVERIFY [48].1
This command takes one argument T , the expiry time, from
the execution stack and compares it to the nLockTime data
ﬁeld of the transaction. If nLockTime < T , the evaluation
1Deposits with explicit beneﬁciaries and payment channels
as described in the following paragraphs are possible even
without CHECKLOCKTIMEVERIFY [1, 40, 45].

.

impl
conf

fails and the transaction is consequently invalid. Thus, only
transactions with nLockTime ≥ T can spend the funds cov-
ered by such a script. By the semantics of nLockTime, those
transactions are valid only in blocks found after time T , and
consequently, the funds protected by CHECKLOCKTIMEVERIFY
are spendable only after T .
We remark that the value of nLockTime can be speciﬁed
either by a UNIX timestamp or a height of a block, which
is the number of blocks that precede it in the blockchain.
Throughout the paper, we use timestamps, and to simplify
presentation, we ignore that miners have some ﬂexibility to
lie about the current time [8]; an safety-margin of at least
120 min must be added to T to account for that issue.
Deposits Without Explicit Beneﬁciary. Suppose that
some user A wishes to create a deposit with expiration time
T without an explicit beneﬁciary. Then, A sends the desired
amount B d to the following script:
(T + T
pkA CHECKSIG
in the script denote push
The literals (T + T
operations that push a constant value on the stack. The
value T
is a safety margin; we postpone its discussion to
the analysis of non-equivocation contracts (Section 6.1).

impl
conf ) CHECKLOCKTIMEVERIFY DROP

conf ) and pk A
impl

The ﬁrst line of the script ensures that the deposit cannot
be spent before time T as explained. (DROP just drops the
constant value from the stack.) In the second line, CHECKSIG
takes the key pk A
and a signature σ from the stack; σ is
supposed to be provided by the spender on the initial stack.
CHECKSIGVERIFY veriﬁes that σ is a valid signature of the
spending transaction under the key pk A
, pushing the boolean
result of the veriﬁcation on the stack. This boolean value
is the output of the script. Thus, if the check succeeds, the
transaction is valid; otherwise it is invalid. In sum, the script
ensures that the funds can only be spent after T and only
by a transaction signed under pk A
If the corresponding secret key sk A is revealed, everybody
can create transactions that try to spend the funds from
time (T + T
conf ) on. Whenever this happens, each miner
impl
has a large incentive to include a transaction in a block that
sends the money to him. Consequently, the miner that ﬁnds
the next block will claim the funds.
Deposits with Explicit Beneﬁciary. Suppose that a user
A wishes to create a deposit with an explicit beneﬁciary P .
Then, A sends the desired amount B d to the following script:
IF

.

pkP CHECKSIGVERIFY

ELSE

(T + T

expl
conf + T

expl
net ) CHECKLOCKTIMEVERIFY DROP

conf and T
expl

ENDIF
pkA CHECKSIG
In this script T
net are safety margins, which will
expl
be discussed below. IF obtains its condition from the stack,
allowing the spender to choose the branch to be executed.
CHECKSIGVERIFY is like CHECKSIG but causes the whole script
to fail immediately if the signature is not valid (instead of
pushing the result of the signature veriﬁcation to the stack).
This script ensures that before time T , the funds can
be spent only if the spending transaction is signed under
both pk A
. Thus, if P learns sk A before time T , he
can spend the funds. Otherwise, A is refunded after time
conf + T
(T + T
expl

and pk P
net ), even if P disappears.
expl

221The safety margins are necessary because the closing trans-
action must have been broadcast to the Bitcoin network and
conﬁrmed by it before the deposit can be spent by A alone.
For the broadcast, T
net = 10 min is more than suﬃcient [21].
expl
For the conﬁrmations, we except the network to ﬁnd 24 blocks
in T
conf = 240 min. Since their arrival is Poisson-distributed,
expl
the probability that fewer than six desired blocks have been
found is Pr[X ≤ 5] < 2−18 for X ∼ Pois(24).
3.2 Payment Channels

Payment channels [45, 48] allow a user A to perform many
transactions to a predeﬁned recipient B up to a predeﬁned
amount B d of money. Although establishing a channel be-
tween A and B involves waiting for a transaction to be
conﬁrmed, the advantages of a payment channels are various:
First, no matter how many payments are sent, only two
transactions have to be included in the blockchain, namely
one to establish and one to close the channel. This makes
payment channels a promising method to scale the Bitcoin
network to many more transactions [39, 47]. Second, A can
perform payments to B even if both parties are oﬄine, once
the channel has been established. Third, fast transactions
are possible through the payment channel, because B does
not have to wait for the transaction to be conﬁrmed.
Creating a Payment Channel. To create a payment
channel from A to B with maximal payment value B d and
expiry time T , A follows the procedure for creating a deposit
with explicit beneﬁciary B.
B waits until the deposit is conﬁrmed by the Bitcoin
network. From now on, the funds can only be spent if both
A and B agree because any spending transaction must be
signed by both A and B to be valid. Since B will only endorse
transactions that send funds to him, B is protected from
attempts by A to send funds to another party (or back to
herself), i.e., B is protected from double-spending attempts.
Paying Through the Channel. The channel has an asso-
ciated state b that speciﬁes how many of the B d have been
paid so far to B. In the beginning, b = 0, i.e., all money
in the channel belongs to A and none belongs to B. To
pay through the channel, i.e., to raise b to b0, A creates an
ordinary Bitcoin transaction that sends B b0 fron the deposit
to B. She signs this transaction with her secret key sk A, and
sends the transaction to B, who validates the transaction and
the correctness of the signature. However, the transaction is
not yet signed by B or published to the Bitcoin network.
Closing the Channel. The channel has to be closed before
time T . If B wants to close the channel at some state ˆb, he
sends the most recently received transaction, i.e., the one
with the value ˆb, to the Bitcoin network. Once the network
conﬁrms the transaction, B has received Bˆb.
If B does not close the channel by time T , e.g., as B has
disappeared, A can claim the whole channel of value B d.

4. ACCOUNTABLE ASSERTIONS

In this section we introduce accountable assertions. In-
tuitively, this primitive allows users to assert statements in
contexts such that users can be held accountable for equiv-
ocation: On the one hand, if the user asserts two diﬀerent
statements st0 6= st1 in the same context ct, then a public
algorithm can extract the secret key ask of the user from the
two assertions. On the other hand, secrecy of the secret key
ask remains intact for a well-behaved non-equivocating user.

Accountable assertions are supposed to be attached to
other public-key primitives, i.e., the key pairs are supposed
to correspond to key pairs of the other primitive. For example,
the key pairs of our scheme will be valid ECDSA key pairs
as used in Bitcoin. Attaching accountable assertions to
other primitives is crucial in practice because the concrete
secret key used in accountable assertions needs to be worth
something, e.g., for redeeming funds. Otherwise, the user
has no incentive to keep it secret in the ﬁrst place.

Definition 1

(Accountable Assertions). An ac-
countable assertion scheme Π is a tuple of ppt algorithms
Π = (Gen, Assert, Verify, Extract) as follows:
• (apk, ask, auxsk) ← Gen(1λ): The key generation algo-
rithm outputs a key pair consisting of a public key apk and a
secret key ask, and auxiliary secret information auxsk. It is
required that for each public key, there is exactly one secret
key, i.e., for all λ and all outputs (apk, ask) and (apk0, ask0)
of Gen(1λ) with apk = apk0, we have ask = ask0.
• τ /⊥ ← Assert(ask, auxsk, ct, st): The stateful assertion
algorithm takes as input a secret key ask, auxiliary secret in-
formation auxsk, a context ct, and a statement st. It returns
either an assertion τ or ⊥ to indicate failure.
• b ← Verify(apk, ct, st, τ): The veriﬁcation algorithm out-
puts 1 if and only if τ is a valid assertion of a statement ct
in the context st under the public key apk.
• ask/⊥ ← Extract(apk, ct, st0, st1, τ0, τ1): The extraction
algorithm takes as input a public key apk, a context ct, two
statements st0, st1, and two assertions τ0, τ1. It outputs either
the secret key ask or ⊥ to indicate failure.
The accountable assertion scheme Π is correct if for all se-
curity parameters λ, all keys (apk, ask, auxsk) ← Gen(1λ), all
statements st, all contexts ct, and all assertions τ 6= ⊥ result-
ing from a successful assertion τ ← Assert(ask, auxsk, ct, st),
we have Verify(apk, ct, st, τ) = 1.
In case of equivocation, only the secret key ask will be guar-
anteed to be extractable, but not the auxiliary secret infor-
mation auxsk.
Completeness. Our deﬁnition of accountable assertions
allows the assertion algorithm to fail. We do not consider
such failure a problem if it happens only with small (but not
necessarily negligible) probability, because failure hurts only
the liveness of the system that makes use of the accountable
assertions. However, liveness is typically not guaranteed
anyway due to unreliable networks. As a consequence, we
do not insist generally on accountable assertions fulﬁlling a
completeness criterion.

At ﬁrst glance, this might look a bit contrived, but the
purpose of this is to trade oﬀ reliability against eﬃciency.
Accountable assertions are, unlike signatures, not required to
be unforgeable, and it turns out that setting unforgeability
aside will enable a more eﬃcient construction.

To understand how failing and unforgeability are related,
suppose an attacker asks a user to assert a statement st0 in
a context ct0, i.e., to output τ0 ← Assert(ask, auxsk, ct0, st0).
Due to the lack of unforgeability, the attacker might use τ0
to obtain another assertion τ1 that is valid for some related
but diﬀerent context ct1 6= ct0 and the same statement st0.
So far, this is not a problem: the attacker cannot use the
extraction algorithm to obtain the secret key ask from τ0
and τ1, because the two assertions are valid in diﬀerent
contexts ct0 6= ct1. However, the attacker can now ask the
user to assert another statement st1 6= st0 in the context

2221, τ1, τ0

1 ← Assert(ask, auxsk, ct1, st1). Observe
ct1, i.e., to output τ0
that this is a valid request: the attacker does not ask the
user to equivocate because the user has not asserted any
statement in the context ct1 so far. But if the user replied to
the request, the attacker could run the extraction algorithm
Extract(apk, ct1, st1, st0
1) to extract the secret key ask.
To avoid this attack, while allowing for a construction
that is “forgeable” as just described, the stateful assertion
algorithm may fail if it detects that the context ct1, for
which an assertion is requested, is related to a previously
used context ct0.
Nevertheless, the ability of the attacker to force failure may
be a problem in certain scenarios, e.g., if it allows the attacker
to perform a denial-of-service attack. In those cases, it is
possible to consider complete accountable assertions, which
are guaranteed to succeed on all honestly chosen inputs.

Definition 2

(Completeness). An accountable asser-
tion scheme Π = (Gen, Assert, Verify, Extract) is complete if
for all security parameters λ, all key pairs (apk, ask) output
by Gen(1λ), all statements st, and all contexts ct, we have
Assert(ask, auxsk, ct, st) 6= ⊥.
Note that the deﬁnition of accountable assertions additionally
demands correctness whenever Assert(ask, auxsk, ct, st) 6= ⊥.
4.1 Security of Accountable Assertions

Accountable assertions need to fulﬁll two security proper-
ties. The ﬁrst security property is extractability, which states
that whenever two distinct statements have been asserted in
the same context, the secret key can be extracted.

Definition 3

(Extractability). An accountable as-
sertion scheme Π = (Gen, Assert, Verify, Extract) is extractable
if for all ppt attackers A,

Pr[Extract(apk, ct, st0, st1, τ0, τ1) 6= ask

∧ ∀b ∈ {0, 1}, Verify(apk, ct, stb, τb) = 1
∧ st0 6= st1 : (apk, ct, st0, st1, τ0, τ1) ← A(1λ)]

is negligible in λ. Here, ask is the unique secret key corre-
sponding to apk.

The second security property secrecy is opposed to ex-
tractability. Secrecy prevents the extraction of the secret
key against an attacker who can ask the challenger to assert
chosen statements in chosen contexts. Since accountable
assertions are extractable, the attacker’s success is excluded
after requesting the assertion of two diﬀerent statements in
the same context.
Definition 4

(Secrecy). An accountable assertion
scheme Π = (Gen, Assert, Verify, Extract) is secret if for all
ppt attackers A, the probability that the experiment SecΠA(λ)
returns 1 is negligible in λ, where the experiment SecΠA(λ) is
deﬁned as follows.
Experiment SecΠA(λ)

∧ ((cid:64)ct, st0, st1. st0 6= st1 ∧ {(ct, st0), (ct, st1)} ⊆ Q)

(apk, ask, auxsk) ← Gen(1λ)
Q := ∅
ask∗ ← AAssert00(ask,auxsk,·,·)(apk)
return 1 iﬀ ask∗ = ask

Oracle Assert00(ask, auxsk, ct, st)
Q := Q ∪ {(ct, st)}
return Assert(ask, ask, ct, st)

Limitations of the Secrecy Deﬁnition. Recall that a
secret key used with accountable assertions must be worth
something, e.g., a valid ECDSA secret key that protects funds
in Bitcoin. We would like to draw the reader’s attention
to the fact that the deﬁnition of secrecy does not take into
account the other usages of the secret key. That is, while
our secrecy deﬁnition of accountable assertions is meaningful
in itself, it is only a heuristic for analyzing their security
when combined with other primitives, and it is formally
not guaranteed that the use of secret accountable assertions
keeps the security of the other primitives intact.2 While
we are conﬁdent that the combined use of our accountable
assertions construction (Section 5) together with ECDSA
does not render ECDSA insecure in practice, a more formal
treatment of the composability of accountable assertions with
other properties is desirable. We leave this for future work.
Relation to DAPS. Double-authentication-preventing sig-
natures (DAPS) [38] have similar properties as accountable
assertions, but are additionally required to be unforgeable.
We have discussed an informal relation between the unforge-
ability of accountable assertions and their completeness. This
intuition can be formalized, and it turns out that a slightly
modiﬁed variant of our accountable assertions construction
(Section 5) and is an eﬃcient DAPS scheme. We refer the
reader to Appendix A for a discussion.

5. CONSTRUCTION AND ANALYSIS

In this section, we propose a construction of accountable
assertions based on chameleon hash functions. Our construc-
tion builds upon the idea of chameleon authentication trees
(CATs), as suggested by Schröder and Schröder [42] and
improved in followup schemes [31, 43]. As opposed to these
schemes, the novelty of our construction is the extractability.
Chameleon Hashes. A chameleon hash function is a ran-
domized hash function that is collision-resistant but provides
a trapdoor to eﬃciently compute collisions [30]. Formally,
a chameleon hash function CH is a tuple of ppt algorithms
(GenCh, Ch, Col). The key generation algorithm GenCh(1λ)
returns a key pair (cpk, csk) consisting of a public key cpk
and a trapdoor csk. The evaluation function Ch(cpk, x; r)
produces a hash value for a message x and a random value
r; we typically write just Ch(x; r) when cpk is clear from the
context. The collision-ﬁnding algorithm Col(csk, x0, r0, x1)
takes as input a trapdoor csk and a triple (x0, r0, x1); it
outputs some value r1 such that Ch(x0; r0) = Ch(x1; r1).
Chameleon hash functions need to fulﬁll collision-resistance
and uniformity as deﬁned by Krawczyk and Rabin [30].

In addition to these standard security properties, we re-
quire the trapdoor to be extractable from a collision. While
this extractability is typically considered a problem [3, 18, 42],
it turns out to be a crucial requirement for our construction.

Definition 5

(Chameleon Hash Extractability).
A chameleon hash function CH = (GenCh, Ch, Col) with
unique keys is extractable if there exists a polynomial-time
algorithm ExtractCsk with the following property: For all
key pairs (cpk, csk) output by GenCh, and for all input pairs
2Indeed, given an unforgeable signature scheme and a secret
accountable assertion scheme, one can construct a pathologi-
cal unforgeable signature scheme that is insecure when f(ask)
is leaked for a one-way function f, and one can construct a
secure accountable assertion scheme that leaks f(ask).

223A1,1, B1,1, C1,1

A2,1, B2,1, C2,1

A2,2, B2,2, C2,2

A2,3, B2,3, C2,3

A3,4, B3,4, C3,4

A3,5, B3,5, C3,5

A3,6, B3,6, C3,6

Figure 1: A tree as in our construction

(x0, r0) and (x1, r1) with x0 6= x1 and Ch(x0; r0) = Ch(x1; r1),
we have ExtractCsk(cpk, x0, r0, x1, r1) = csk.
5.1 Intuition
First Approach. One obvious but ﬂawed approach to
construct accountable assertions is to let the assertion al-
gorithm output a random value r such that ct = Ch(st; r).
The intuition is that if the attacker does this for two dif-
ferent statements st0, st1 in the same context ct, then this
would yield a collision Ch(st0; r0) = ct = Ch(st1; r1) in the
chameleon hash function, and one could extract the trapdoor.
This simple idea does not work: ct would live in the output
space of the chameleon hash function, but in most of the
chameleon hash functions, the trapdoor can only be used to
ﬁnd collisions eﬃciently, not to invert the function.
Full Idea. Observe that the aforementioned approach works,
however, as a scheme that supports only one assertion in an
arbitrary but ﬁxed context, for which inverting the chameleon
hash is not necessary. If the public key of the accountable
assertions scheme includes Ch(x∗; r∗) for randomly chosen
x∗ and r∗, then one can use the trapdoor to compute r as an
assertion for a statement st such that Ch(x∗; r∗) = Ch(st; r).
The basic idea of our construction is to generalize this ap-
proach to many contexts by applying it recursively, resulting
in a Merkle-style tree based on chameleon hash functions.
The contexts are associated with the leafs of the tree, and a
digest of the root node is part of the public key.

Let n denote the arity and ‘ denote the depth of the tree.
We explain the main steps with the help of Fig. 1 for n = 3. In
our construction (a digest of) the context deﬁnes its position
in the tree. That is, the context with the lowest digest is
stored in the leftmost leaf and the context with the highest
digest in the rightmost node. Since the tree is of exponential
size, storing or computing the entire tree at once is not
possible. Instead, we compute each element Ai,j, Bi,j, Ci,j as
a chameleon hash value of its children, i.e., the element Ai,j is
computed as Ai,j ← Ch(Ai+1,s, Bi+1,s, Ci+1,s; ri,j) for some
integer s. So far, we have described an n-ary Merkle tree
whose nodes are computed via a chameleon hash function.
Now we explain how to handle an exponential number
of nodes without computing all of them. The basic idea
is to exploit the collision property of the chameleon hash
Instead of computing the node Ai,j as Ai,j ←
function.
Ch(Ai+1,s, Bi+1,s, Ci+1,s; ri,j), we replace all elements with
i.e., Ai,j ← Ch(xi,j; ri,j). These ele-
dummy elements,
ments are derived via a pseudo-random function F, i.e.,
xi,j ← F(i, j), and can be computed on the ﬂy. That is,
to compute Ai,j, no other tree nodes are necessary. Since
all elements are computed deterministically, it means that
this modiﬁcation results in an exponential number of nodes

without any connection to each other. We re-establish this
connection using the trapdoor of the chameleon hash function
whenever we assert a new element.

We illustrate the assertion operation with Fig. 1. Assume
that we would like to assert a statement in the context (as-
sociated with) C3,6. To do so, we need to compute the the
elements A3,6, B3,6, A2,2, B2,2, A1,1, C1,1 and the correspond-
ing randomness for each node. This information will suﬃce
for the veriﬁer to reconstruct the assertion path from C3,6
to the root as in an ordinary Merkle tree. To compute the
aforementioned elements, we compute all dummy elements
xA3,6, xB2,2, xC1,1 and we also derive the randomness for each
node via F. Now, to assert the statement st in the context
C3,6, we compute the ﬁrst collision in C3,6 ← Ch(xC3,6; rC3,6).
We use the trapdoor of the chameleon hash to ﬁnd a matching
randomness r0 such that Ch(xC3,6; rC3,6) = C3,6 = Ch(S(st); r0),
where S computes a digest of the statement st. Now, to assert
(A3,6, B3,6, C3,6) with respect to the parent C2,2, we need to
ﬁnd a second collision in C2,2, which is computed as C2,2 ←
Ch(xC2,2; rC2,2). Again, we use the trapdoor to compute some
randomness r00 such that Ch(xC2,2; rC2,2) = C2,2 = Ch(h; r00)
where h = (A3,6, B3,6, C3,6). We repeat this procedure up
to the root. Observe that independent of the statements
asserted in the contexts A3,6, B3,6, and C3,6, the value h
will always be the same because the ﬁrst collision is always
computed in the leaf. This concludes the description of the
underlying asserted data structure.

Now, we will explain how to extract the secret key in the
case that the sender asserts two diﬀerent statements in the
same context. Let us assume that the sender asserted two
statements st0, st1 in the context associated with C3,6.
In the simplest case, there exist two pairs (st0, r0), (st1, r1)
such that Ch(S(st0); r0) = C3,6 = Ch(S(st1); r1). (This is like
in the “ﬁrst approach”.)
In a more complicated case, we could have Ch(S(st0); r0) =
C3,6 6= C0
3,6 = Ch(S(st1); r1), because the attacker could
have used a collision in C2,2 to associate its rightmost child
3,6 6= C3,6. But then, this collision can be
with a value C0
used to extract the trapdoor. Generally speaking, we will
ﬁnd a collision somewhere on the path from the leaf to the
root. Observe that this always terminates for valid assertions
because a digest of the root itself is ﬁxed in the public key.

5.2 Construction

We present the full description of our scheme. Let ‘ and
n be arbitrary positive integers deﬁning the height of a tree
and its branching factor. Let Fk be a pseudorandom func-
tion, and H be a collision-resistant hash function. Further-
more, let S and L be two hash functions modeled as random
oracles. L maps arbitrary bitstrings to {1, . . . , n‘}.3 Let
CH = (GenCh, Ch, Col, ExtractCsk) be a uniform, collision-
resistant, and extractable chameleon hash function. The
accountable assertion scheme is deﬁned as follows:
Key Generation: The key generation algorithm chooses
a key for the pseudo-random function k ← {0, 1}λ, and a
key pair (cpk, csk) ← GenCh(1λ) for the chameleon hash
function, Let p be an unique identiﬁer for the position of
the root node. The algorithm computes the root node as
i ← Fk(p, i, 0), r1
i ) for
x1
3Since L is only required for a low failure probability of the
assertion algorithm but not for security, the size of the output
space of L may or may not depend on the security parameter.

i ← Fk(p, i, 1), and y1

i = Ch(x1

i ; r1

224i ∈ {1, . . . , n} and sets z = H(y1
n). Finally, it sets
1, . . . , y1
apk := (cpk, z), ask := csk, and auxsk := k.
Assertion: The stateful assertion algorithm maintains an
initially empty set L of used leaf positions. To assert a
statement st in a context ct, the algorithm veriﬁes that
L(ct) /∈ L and fails otherwise.4 Then, it adds L(ct) to L and
computes the assertion path (Y‘, a‘, Y‘−1, a‘−1, . . . , Y1, a1)
from a leaf Y‘ to the root Y1. Each node Yj = (yj
n)
1, . . . , yj
stores n entries and the position aj ∈ {1, . . . , n} deﬁnes the
position in the node. Y‘ is the leaf that stores the entry
with the number L(ct), counted across all leaves from left to
right, and a‘ is the position of this entry within Y‘. In the
:= Fk(pj, i, 1), where
following, let xj
pj is a unique identiﬁer of the position of the node Yj.
Compute Y‘: Assert the statement st with respect to Y‘
by computing r0‘
a‘ , S(st)). Observe that
Ch(x‘
) = y‘
i; r‘
i)
for i ∈ {1, . . . , n} \ {a‘}. The leaf Y‘ stores the entries
n) and let further f‘ =
(y‘1, . . . , y‘
(y‘1, . . . , y‘

n). Let z‘ ← H(y‘1, . . . , y‘
a‘−1, y‘

Compute the remaining entries in node Y‘ as y‘

a‘ ← Col(csk, x‘
= Ch(S(st); r0‘

:= Fk(pj, i, 0) and rj

Compute the nodes up to the root for h = ‘ − 1, . . . , 1:
• Assert zh+1 with respect to Yh by computing r0h
; rh

a‘ , zh+1). Observe that Ch(xh

i = Ch(x‘

a‘+1, . . . , y‘

a‘ ←
) =

a‘ , r‘
).
a‘

a‘ , rh

n).

; r‘

a‘

a‘

a‘

a‘

a‘

i

i

Col(csk, xh
yh
a‘

= Ch(zh+1; r0h

a‘

).

• Compute the remaining entries in this node Yh as yh

i =
) for i ∈ {1, . . . , n}\{a‘}. The node Yh stores
n) and

i

i

; rp

Ch(xp
the elements (yh1 , . . . , yh
fh = (yh1 , . . . , yh
a‘−1, yh
The assertion is τ := (r0‘

n). Let zh ← H(yh1 , . . . , yh
n).
a‘+1, . . . , yh
a‘ , f‘, a‘, . . . , r01

1, f1, a1).

n) = z.

1, . . . , y1

a‘ , f‘, a‘, . . . , r01

Veriﬁcation: The veriﬁcation algorithm veriﬁes that cpk is
a valid chameleon hash public key and outputs 0 otherwise.
It parses τ as (r0‘
1, f1, a1), and checks the
validity of a statement st in a context ct by reconstructing
the nodes (Y‘, Y‘−1, . . . , Y1) in a bottom-up order, from the
leaf Y‘ to the root Y1. The veriﬁcation algorithm outputs 1
if and only if H(y1
Extraction: The extraction algorithm takes as input (apk,
ct, st0, st1, τ0, τ1). It computes like the veriﬁcation algorithm
the assertion paths for both st0 and st1 from the bottom up
to the root until a position in the tree is found where the
two assertion paths form a collision in the chameleon hash
function, i.e., a position in the tree where values x0, r0 are
used in the assertion path of st0 and values x1, r1 are used
in the assertion path of st1 such that Ch(x0; r0) = Ch(x1; r1).
Then the extraction algorithm outputs the secret key ask =
csk ← ExtractCsk(x0, r0, x1, r1) computed via the extraction
algorithm of the chameleon hash function. If no such position
is found, the extraction algorithm fails.
5.3 Analysis

We establish the security of the construction.
Theorem 1. The construction is extractable.
Proof. Assume for contradiction that there is a ppt
attacker A that breaks extractability. That is, with non-
negligible probability, A outputs a public key apk and two as-
4The set L can be implemented eﬃciently by a Bloom ﬁlter [9,
46], at the cost of a slightly increased failure rate. A Bloom
ﬁlter is a space-eﬃcient probabilistic data structure. It may
indicate x ∈ L wrongly with small probability but it never
indicates x /∈ L wrongly.

sertions τ0, τ1 that are valid for diﬀerent statements st0 6= st1
in the same context ct, but the extraction algorithm fails to
extract the secret key ask given these values.
By construction of the veriﬁcation algorithm, the assertion
paths of τ0 and τ1 belong to two Merkle trees T0 and T1
such that i) the roots of T0 and T1 are identical, and ii) the
two leaves of T0 and T1 that belong to the context ct have
diﬀerent inputs st0 6= st1 for the chameleon hash function;
note that these leaves are at the same position in T0 and T1.
Thus there is a node position on the assertion paths output
by A such that the nodes of T0 and T1 at this position
form a collision in either the chameleon hash function or
the collision-resistant hash function H. By construction of
the extraction algorithm, it would not fail to output ask if
this collision was a collision in the chameleon hash function.
Consequently, it is a collision in the hash function H, and the
existence of A contradicts the collision-resistance of H.

Theorem 2. The construction is secret in the random

oracle model.

Proof sketch. The proof proceeds in two steps. First,
we prove a non-adaptive (or selective) secrecy notion where
the attacker outputs all queries to the assertion oracle in the
beginning. Only afterwards, the attacker obtains the public
key and the responses from the oracle, and the attacker’s
goal is to output the secret key.

In this non-adaptive case, the reduction can answer all
assertion queries without knowing the trapdoor by computing
the tree from the bottom up. Whenever the attacker wins,
the reduction can easily break the collision-resistance of the
chameleon hash function.

In the second step, we reduce adaptive security to non-
adaptive security. The reduction ﬁrst outputs randomly
chosen statements in randomly chosen contexts as its non-
adaptive queries, and obtains a public key and the resulting
assertions. Whenever the attacker queries the assertion
oracle, the reduction programs the random oracles such
that one of the non-adaptively obtained assertions is a valid
response of the assertion oracle.

A complete proof appears in the full version [34].

Failure Probability of the Assertion Algorithm. The
construction allows a context space of {0, 1}∗. The probabil-
ity that the assertion algorithm fails when given q queries
is the probability that there are two contexts ct0 6= ct1 in
the queries with L(ct0) = L(ct1). Under the assumption that
L : {0, 1}∗ → {1, . . . , n‘} has uniform outputs, its (birthday)
collision probability is below (q + 1)2/(2 · (n‘ + 1 − q)) [37].
Complete Accountable Assertions. A variant of the
construction yields a complete accountable assertion scheme.
Suppose n‘ is large enough (with respect to the security pa-
rameter λ) to ensure that L is collision-resistant, e.g., ‘ = 2λ.
Then, we can drop the check for L(ct) /∈ L, which fails now
only with negligible probability. This eliminates the state
from the authentication algorithm and makes the scheme
complete, i.e., the assertion algorithm always succeeds.
5.4 Instantiation and Implementation

We have implemented the construction given in the pre-
vious section.
In this section, we describe the details of
the implementation, and we evaluate the practicality of the
construction, as it will dominate the computation as well
as communication costs of non-equivocation contracts. Our

225implementation is available online [28].
It makes use of
the libsecp256k1 library [49], which has evolved from the
standard Bitcoin client.
Chameleon Hash Function. We use a chameleon hash
function proposed by Krawczyk and Rabin [30], which is
secure if the discrete logarithms assumption holds in the un-
derlying group. In the elliptic curve setting, the chameleon
hash function CH = (GenCh, Ch, Col) with extraction algo-
rithm ExtractCsk is deﬁned as follows.
GenCh(1λ): The key generation algorithm chooses a secure
elliptic curve and a base point g of prime order q where
q is at least 2λ bits long. It chooses a random integer
α ∈ Z∗
q and returns (csk, cpk) = (α, X) with X = gα.
Ch(x; r): The input of the hash algorithm is a public key
cpk = X and a message x ∈ Z∗
q. It picks a random
value r ∈ Z∗
q and outputs gxX r.
Col(csk, x0, r0, x1): The collision ﬁnding algorithm returns
r1 = α−1(x0 − x1) + r0 (mod q).
ExtractCsk(cpk, x0, r0, x1, x1): If the inputs are a collision,
we have gx0+αr0 = gx1+αr1. The extraction algorithm
returns α = (x0 − x1)/(r1 − r0) (mod q).
This chameleon hash function has unique keys. A public
key can be validated by verifying that it is an elliptic curve
point in the correct-prime order group. To be compatible
with Bitcoin keys, we work on the prime-order elliptic curve
secp256k1 [15] at a security level of 128 bits.
Cryptographic Algorithms. We use HMAC-SHA256 to in-
stantiate the pseudorandom function F, SHA256 to instantiate
the collision-resistant hash function H, and HMAC-SHA256 with
ﬁxed keys to instantiate the random oracles L and S.
Other Parameters. We have chosen ‘ = 64 as the height
and n = 2 as the branching factor of the tree, implying that
the failure probability of the assertion algorithm is below
2−37 for q = 10000 queries.
Computation Cost. On a 2.10GHz (Intel Core i7-4600U)
machine with DDR3-1600 RAM, a chameleon hash evaluation
takes 66 µs with a secret key, and the computation time
increases to 85 µs if only a public key is available.

Let ‘ denote the height of the authentication tree. The
assertion algorithm of our accountable assertion scheme in
Section 5.2 requires n‘ chameleon hash function evaluations
using secret keys, while the veriﬁcation algorithm of our
accountable assertion scheme scheme requires ‘ chameleon
hash function evaluations using public keys.
In our test environment, the assertion algorithm takes
around 9 ms, while the veriﬁcation algorithm takes approxi-
mately 4 ms to complete.
Storage Costs. A chameleon hash value is a point on
the elliptic curve secp256k1 and thus requires 257 bits <
33 bytes in compressed form. A randomness input of the
chameleon hash function is an integer in the underlying
ﬁeld of the curve, and requires 32 bytes. An assertion is a
sequence of ‘ = 64 chameleon hash values and chameleon
hash randomness inputs, and thus requires 64 · (33 bytes +
32 bytes) = 4160 bytes. To store q = 10000 assertions, we
need about 42 MB.

6. NON-EQUIVOCATION CONTRACTS

Putting everything together, we explain how to realize non-
equivocation contracts by combining accountable assertions
and deposits. Non-equivocation contracts make it possible
to penalize paltering in distributed protocols monetarily.

Setup. Let A be a party to be penalized by the loss of B p
if it equivocates before time T and let d be a parameter that
depends on p (we will discuss the choice of d in Section 6.1).
1. Party A creates a Bitcoin key pair (pk, sk). Also, A sets
up the accountable assertion scheme given in Section 5.2
with the Bitcoin key pair (pk, sk). That is, A predeﬁnes
the secret key ask := sk of the accountable assertion
scheme and creates the corresponding public key apk
and the auxiliary secret information auxsk as speciﬁed
in the key generation algorithm. Note that apk = (pk, z)
for some root hash z.
2. A creates a deposit of B d with expiry time T (see
Section 3.1) using pk. The deposit may or may not
specify an explicit beneﬁciary P , who will receive the
funds in case of equivocation.
3. Every party B expecting to receive asserted statements
from A waits until the transaction that creates the
deposit has been conﬁrmed by the Bitcoin network.
Usage. The distributed protocol is augmented as follows:
1. Whenever A is supposed to send a statement st to diﬀer-
ent protocol parties in a context ct, party A additionally
sends an assertion τ ← Assert(ask, auxsk, ct, st).
2. Each recipient B veriﬁes that Verify(apk, ct, st, τ) = 1
and that T ≤ t for the current time t. Party B ignores
the message if any of the checks fail.
Otherwise, B sends the record (apk, ct, st, τ) to the
beneﬁciary P , who will store it. (If there is no explicit
beneﬁciary, B publishes the record to the miners, who
have an incentive to store it.)
3. If P (or the miners) detect an equivocation in two
records (apk, ct, st0, τ0) and (apk, ct, st1, τ1), they use
the corresponding assertions to extract A’s secret key
sk ← Extract(apk, ct, st0, st1, τ0, τ1). Using sk, party P
transfers the funds in the deposit to an address fully
under his control. (If there is no explicit beneﬁciary,
the miners wait until the expiry time of the deposit is
reached. Then each miner will try to create a block
that includes a transaction transferring the deposit to
an address under his control.)

If A does not equivocate, A will re-obtain full control over
the deposit after its expiry.
Observe that an honest non-rational miner may not want
to proﬁt from a leaked secret key because the leakage could
be the result of a security breach or carelessness. However,
since the assertions constitute cryptographic proof of A’s
misbehavior, the miner can be assured that he acts honestly
when claiming the deposit.
6.1 Analysis

We analyze the consequences of an equivocation by A.

With Explicit Beneﬁciary. If an explicit beneﬁciary P is
speciﬁed in the deposit, then the properties of the deposit
ensure that only P can spend the deposit in case of an
equivocation. In particular, the safety margins as discussed
in Section 3.1 ensure that the transaction created by P will
have been conﬁrmed already and thus the deposit will have
been withdrawn already when its expiry will be reached. The
size B d of the deposit should be equal to the penalty B p.
Without Explicit Beneﬁciary. If no explicit beneﬁciary
is given, the analysis is more complicated, because a malicious
sender A can participate in the mining process.
The goal of A is to establish the validity of a transaction
tx that withdraws the funds in the deposit to an address

226impl
conf

is too small (say T

controlled by A, even though her secret key has been pub-
lished. Recall that such a transaction cannot be included in
a block before the expiry of the deposit (Section 3.1). First,
we explain how to choose the safety margin T
conf to prevent
impl
A from pre-mining the transaction tx. First observe that,
if T
conf = 0 for simplicity), A can
impl
pursue the following strategy: Before the expiry time T , she
tries to mine a block B that includes tx and builds upon the
most current block Bcur. If A manages to ﬁnd such a block
B, she will keep her block B secret at ﬁrst. If additionally no
other miner ﬁnds another block B0 building upon Bcur, the
malicious sender A will equivocate just before T . Then, by
publishing B after time T , A will have a very high chance
not to lose her deposit because the transaction tx in B will
most likely prevail. However, if A does not manage to ﬁnd a
block B, she will refrain from the equivocation attack.
This strategy is successful because the malicious sender
avoids the risk of losing the deposit by performing the equiv-
ocation only if success is almost guaranteed. This is a variant
of the so-called Finney attack [25].

impl
conf

is larger, e.g., T

However, assume that T

While a safety margin T

conf = 60 min.
impl
Then 60 min before the expiry time of the deposit, A will
need to have secretly pre-mined several sequential blocks
(one of them containing tx) on top of the current block Bcur
to perform the equivocation. Precisely, she will need to
have pre-mined more blocks than she expects to be found
by honest miners within the next 60 min. This is considered
infeasible if A controls only the minority of the computation
power in the network, which is the one of the underlying
assumptions for security of the Bitcoin network.
conf excludes pre-mining attacks,
impl
A can try to mine the ﬁrst block B after time T . Even if
other miners ﬁnd a contradicting block B0 (and maybe more
sequential blocks), A can try to catch up with the blockchain,
which may be worthwhile in the case of a large deposit.
We counter such attacks by a careful selection of the
deposit size B d. Assume that the mining power of the
whole network and the A’s fraction f of it stay constant.
If f < 0.5, the probability that her block B prevails is
f /(1 − f) [41]. Thus the expected penalty E for A is E =
d−d·f /(1−f). At minimum, we require E ≥ p, which yields
d ≥ p(f − 1)/(2f − 1). For example, a deposit of d ≥ 3p/2
is required for a malicious fraction of f = 0.25.
6.2 Application Examples

Many systems require users to trust in a service provider
for data integrity. However, the service provider may choose
to equivocate and show diﬀerent users diﬀerent states of
the system. For instance, this has indeed been reported in
the case of online social networks. A user of the Chinese
microblogging service Sina Weibo claims that Sina Weibo
censored his posts by not showing them to other users [44].
However, the server showed the posts to the user himself to
avoid complaints from him.

To detect misbehavior of the service provider, a variety
of systems have been proposed for diﬀerent scenarios, e.g.,
SUNDR [35] for cloud storage, SPORC [24] for group collab-
oration, Application Transparency [22] for software distribu-
tion, and Frientegrity [23] for social networks.

They basically ensure the following property: If the server
violates the linearity of the system by showing contradicting
states to diﬀerent users, it cannot merge these states again
without being detected. Furthermore, if users that have

received contradicting states exchange messages out of band,
they can detect and prove the wrongdoing of the server. (The
basic property is called fork consistency [12, 35]).
Observe that a violation of linearity is a case of equivo-
cation. Although clients can cryptographically verify the
append-only property, i.e., that a new system state is a proper
extension of an old known system state, a malicious server
can still provide diﬀerent extensions to diﬀerent clients.

Non-equivocation contracts are applicable in these set-
tings. The context is a revision number of the state, and
the statement is a digest of the state itself at this revision
number. Depending on the system, the context may be more
complex than an increasing counter. Frientegrity [23], for
instance, does not maintain a total order on all operations
in the system, but rather a total order per object. This is
to avoid sacriﬁcing performance. So the context in which a
state is asserted is not just an increasing counter but rather
the pair of (objectID, perObjectRevisionNumber).
As a concrete application, imagine a non-equivocation con-
tract between a cloud storage provider and a client company,
which is willing to pay a slightly higher usage fee as an insur-
ance against accidental or malicious equivocation. The client
company is speciﬁed as the beneﬁciary of the deposit. Then,
the resulting contract serves as cryptographically-enforced
insurance. If the service provider equivocates to individual
employees of the company, the company receives the deposit.
In another example scenario, consider a market with two
main providers of app stores. Both providers put down a
global deposit without explicit beneﬁciary.
If one of the
providers becomes malicious and sends diﬀerent binaries of
the same app (and version) to diﬀerent users, then it will
lose its deposit. Thus, after the expiry of the deposit, the
malicious provider will have to put down a new second de-
posit to remain in business and competitive with the honest
provider, even if the loss of reputation was small. In com-
parison, the honest service provider can re-use the funds to
put down a second deposit after the ﬁrst deposit has expired.
Alternatively, the malicious provider could choose not to put
down a second deposit but then the honest provider can do
the same while getting the funds back.

7. ASYNCHRONOUS PAYMENTS

As explained in Section 3.2, payment channels [45, 48]
allow a user A to perform many transactions to a predeﬁned
recipient B up to a predeﬁned cumulative amount B d. Once
the channel is established, it is possible for A to send funds
to B even when both parties are oﬄine.
However, if the recipient B is a distributed system, i.e., B
actually consists of many unsynchronized entities B1, . . . , Bn,
then oﬄine transactions are not secure. The problem is that
A can double-spend the same funds to Bi and Bj, who
cannot talk to each other because they are oﬄine and thus
not synchronized. When B wants to close its channel and
clear the payment in the Bitcoin network, it can clear these
funds only once.

We can secure oﬄine transaction through payment chan-
nels in cases where a reasonable ﬁnite penalty for double-
spending can be found.
Example: Public Transport. For an illustrative example,
assume B is a company oﬀering public transport on buses.
A would like to use B’s services as a passenger. Thus, A
establishes a payment channel to B by sending a transaction

227to the Bitcoin network. Once the transaction is conﬁrmed,
the payment channel is open and A can use it to pay for
several single rides when she enters one of B’s buses Bi up
to the limit B d of the channel. It is reasonable to assume
that A and B have at most sporadic Internet connectivity
in this mobile setting, so the payment should be performed
oﬄine. Still, B’s buses are synchronized every night.
This system is ﬂawed: A can double-spend to B’s buses.
Say the current state in the channel is b = 3. Then A can ride
two (or more) buses Bi and Bj on the same day, by presenting
them proof of updating the channel to b = 4. The bus
company will only notice at night during the synchronization
that it has been defrauded by A.
Using accountable assertions, we can secure this protocol.
Then B can penalize the double-spending user A when closing
the channel. Here, a reasonable penalty is at least the fare
for a day ticket (valid for several rides on the same day).
Basic Idea. The idea of the modiﬁed protocol is as follows:
Since the points of sale Bi are oﬄine and not synchronized,
we let A keep the state of the payment channel. The state
consists essentially of just the current value of the channel,
and a revision number of the state. To ensure that the
user cannot modify the state, it is signed by the individual
points of sale Bi. However, the user can still show an old
signed state and re-use it. This is exactly where we can
use accountable assertions: whenever the user A would like
to perform a payment through the channel and claims that
the latest state has revision number k, we require her to
assert the statement “I buy a ticket with serial number r” in
context ct = k, where r is a fresh nonce created by Bi. Thus,
if A reuses an old signed state, her key will be extractable.
7.1 Full Protocol

• VrfySig(spk Bj
, state∗, σ∗) = 1 (valid state)
• Verify(apk, k∗, r, τ∗) = 1 (valid assertion)
• tx∗ is a valid transaction that updates the state
• b∗ + x ≤ d∗ (unexhausted channel)

of the channel to b∗ + x

), respectively.

Our full protocol for asynchronous payment channels con-
sists of three phases. It uses an unforgeable signature scheme
with algorithms Sign and VrfySig, and assumes that B and its
points of sale Bi have corresponding key pairs (spk B, ssk B)
and (ssk Bi , spk Bi
Setup. To create an asynchronous payment channel from A
to B with amount B d, penalty B p, and expiry time T , the
parties execute the following steps:
1. A sets up a Bitcoin key pair (pk, sk) and account-
able assertions keys (apk, ask = sk, auxsk) as for non-
equivocation contracts (Section 6).
2. A creates a payment channel with B with amount
B (d + p) and expiry time T (Section 3.2).
3. After the channel is conﬁrmed by the Bitcoin net-
work, B provides A with a signed statement σ =
Sign(ssk B, state), where state = (T, d, k = 0, b = 0, B).
Payment. Whenever A would like to pay B x oﬄine at some
point of sale Bi, the parties execute the following protocol:
1. Bi creates a fresh nonce r and sends it to A.
2. A sets b := b + x and τ ← Assert(ask, auxsk, k, r). A
creates a transaction tx updating the channel to state
b, and sends (tx, τ, state, σ) to Bi.
3. Bi receives (tx∗, τ∗, state∗, σ∗), parses state∗ as (T ∗, d∗,
k∗, b∗, Bj), and veriﬁes all the following conditions:

• A /∈ X (A is not blacklisted)
• t < T ∗ for the current time t (unexpired deposit)
If any of the checks fail, Bi aborts the payment. Oth-
erwise, Bi computes a new state state0 = (T ∗, d∗, k∗ +
1, b∗ + x, Bi), signs it via σ0 ← Sign(ssk Bi , state0), and
sends (state0, σ0) to A. Bi records tx and τ and provides
service to A.
4. A updates the variables state and σ with the values
received from Bi.

which can delete the transactions afterwards.

Synchronization. At the end of each time period, B syn-
chronizes with each point of sale Bi:
1. B collects all transactions recorded by point of sale Bi,
2. B veriﬁes that there are no double-spends among all
transactions collected so far. If B detects that A has
double-spent, B extracts A’s secret key sk and uses it
to sign a transaction that spends the whole payment
channel worth B (d + p) to an address under the control
of B. B adds A to the blacklist X, and sends updates
of the blacklist X to each point of sale Bi.
3. Before time T , B closes the channel (Section 3.2). B
adds A to the blacklist X, and sends updates of the
blacklist X to each point of sale Bi.

7.2 Analysis

because she will be blacklisted afterwards.

Observe that A can double-spend on at most one day
Assume A has successfully double-spent. Since all states
are diﬀerent, and the state contains the value b of the payment
channel, she must have shown the same signed state with
some revision number k twice successfully. But then, A has
sent two assertions τ0 and τ1 that are valid in the same
context ct = k. Since the corresponding statements st0 and
st1 are fresh nonces, they diﬀer with overwhelming probability.
Thus B can extract A’s secret key successfully, and close the
payment channel at the maximum value B (d + p). Since the
points of sale Bi accept payments only up to B b, the penalty
for A in case of double-spending is at least B p.

8. RELATED WORK
Trusted Hardware for Non-equivocation. One way
to prevent equivocation is to relay on trusted hardware
assumptions [4, 19, 20, 33].
In particular, the resilience
of tasks such as reliable broadcast, Byzantine agreement,
and multiparty computation have been improved using a
non-equivocation functionality based on a trusted hardware
module, such as a trusted, increment-only local counter and
a signature oracle, at each party.
Unlike our approach, which disincentives parties from
equivocation, these systems fully prevent it, but at the same
time they rely on a much stronger hardware assumption.
Smart Contracts. Crypto-currencies with more expres-
sive, e.g., Turing-complete, script languages [11, 29] oﬀer a
simpler way to achieve non-equivocation contracts. In such
systems, it is possible to create a deposit that can be opened
when presented with cryptographic evidence of equivocation.
As digital signatures suﬃce to provide such evidence and
extractability is not required, they can be used instead of
accountable assertions. The monetary penalty is enforced by
the consensus rules of the currency. While crypto-currencies
with Turing-complete languages are a very promising direc-

228tion, they have not yet withstood the test of time, and their
powerful languages might lead to unforeseen security issues.
Traditional E-cash. Similar to accountable assertions,
Chaumian e-cash systems and one-show anonymous creden-
tial systems [5, 13, 14, 16] allow a secret to be revealed in
case of double-spending. In these settings, the revealed secret
is not used as a key but as the identity of the double-spender,
i.e., her anonymity is revoked upon double-spending.

However, these protocols are not applicable to our scenario,
because they work in a fundamentally diﬀerent setting: They
rely on the property that a central authority (a bank) issues
coins by generating cryptographic tokens. In the decentral-
ized Bitcoin setting, no central bank exists and cryptographic
secrets are generated by the users.

9. CONCLUSION

In this paper, we introduced non-equivocation contracts

in Bitcoin to penalize paltering in distributed systems.

In the process of designing these contracts, we presented a
novel cryptographic primitive called accountable assertions,
which reveals a predeﬁned secret key in case of equivoca-
tion. We analyzed the security as well as the performance of
our accountable assertions construction and found it to be
practical for real-life use.

To prevent double-spending at unsynchronized points of
sale, we further applied non-equivocation contracts to the
Bitcoin network itself.
Acknowledgments
We thank Dario Fiore for insightful discussions on chameleon
hash functions and the anonymous reviewers for their helpful
suggestions and comments.

This work was supported by the German Ministry for Edu-
cation and Research (BMBF) through funding for the Center
for IT-Security, Privacy and Accountability (CISPA) and
the German Universities Excellence Initiative. Dominique
Schröder is also supported by an Intel Early Career Faculty
Honor Program Award.

References
[1] M. Andrychowicz, S. Dziembowski, D. Malinowski,
and L. Mazurek. How to deal with malleability of
BitCoin transactions, 2013. arXiv: 1312.3230 [CoRR].

[2] M. Andrychowicz, S. Dziembowski, D. Malinowski,

and L. Mazurek. Secure multiparty computations on
Bitcoin. S&P’14. IEEE.

[3] G. Ateniese and B. d. Medeiros. On the key exposure

problem in chameleon hashes. SCN’04. Springer.

[4] M. Backes, F. Bendun, A. Choudhury, and A. Kate.

Asynchronous MPC with a strict honest majority
using non-equivocation. PODC’14. ACM.

[5] F. Baldimtsi and A. Lysyanskaya. Anonymous

credentials light. CCS’13. ACM.
I. Bentov and R. Kumaresan. How to use Bitcoin to
design fair protocols. CRYPTO’14. Springer.

[6]

[7] Bitcoin Project. Bitcoin developer guide.
https://bitcoin.org/en/developer-guide.
[8] Block timestamp. Entry in Bitcoin Wiki.

https://en.bitcoin.it/w/index.php?title=Block_
timestamp&oldid=51392.

[28]

[9] B. H. Bloom. Space/time trade-oﬀs in hash coding
with allowable errors. Commun. ACM, 13(7), 1970.
[10] J. Bonneau et al. SoK: Research perspectives and

challenges for Bitcoin and cryptocurrencies. S&P’15.
IEEE.

[11] V. Buterin. A next-generation smart contract and

decentralized application platform. https:
//github.com/ethereum/wiki/wiki/White-Paper.

[12] C. Cachin, A. Shelat, and A. Shraer. Eﬃcient

fork-linearizable access to untrusted shared memory.
PODC’07. ACM.

[13] J. Camenisch, S. Hohenberger, and A. Lysyanskaya.

Compact e-cash. EUROCRYPT’05. Springer.
[14] J. Camenisch and A. Lysyanskaya. An eﬃcient

system for non-transferable anonymous credentials
with optional anonymity revocation.
EUROCRYPT’01. Springer.

[15] Certicom. SEC 2: Recommended elliptic curve domain

parameters. http://www.secg.org/sec2-v2.pdf .
[16] D. Chaum, A. Fiat, and M. Naor. Untraceable

electronic cash. CRYPTO’88. Springer.
[17] CHECKLOCKTIMEVERIFY (BIP65)

IsSuperMajority() soft-fork. Pull request for Bitcoin
client. https://github.com/bitcoin/bitcoin/pull/6351.
[18] X. Chen, F. Zhang, and K. Kim. Chameleon hashing

without key exposure. ISC’04. Springer.
[19] B.-G. Chun, P. Maniatis, S. Shenker, and

J. Kubiatowicz. Attested append-only memory:
Making adversaries stick to their word. SOSP’07.
ACM.

[20] A. Clement, F. Junqueira, A. Kate, and R. Rodrigues.

On the (limited) power of non-equivocation.
PODC’12. ACM.

[21] C. Decker and R. Wattenhofer. Information

propagation in the Bitcoin network. P2P’13. IEEE.
[22] S. Fahl et al. Hey, NSA: Stay away from my market!

Future prooﬁng app markets against powerful
attackers. CCS ’14. ACM.

[23] A. J. Feldman, A. Blankstein, M. J. Freedman, and
E. W. Felten. Social networking with Frientegrity:
privacy and integrity with an untrusted provider.
USENIX Security’12. USENIX.

[24] A. J. Feldman, W. P. Zeller, M. J. Freedman, and
E. W. Felten. SPORC: Group collaboration using
untrusted cloud resources. OSDI’10. USENIX.

[25] H. Finney. Re: Best practice for fast transaction

acceptance - how high is the risk? Post on Bitcoin
forum. https://bitcointalk.org/index.php?topic=3441.
msg48384#msg48384.

[26] M. Fitzi and U. M. Maurer. From partial consistency

to global broadcast. STOC’00. ACM.

[27] C. Ho, R. v. Renesse, M. Bickford, and D. Dolev.

Nysiad: Practical protocol transformation to tolerate
byzantine failures. NSDI’08. USENIX.
Implementation of accountable assertion scheme.
http://crypsys.mmci.uni-
saarland.de/projects/PenalizingEquivocation/.

229[29] A. Kosba, A. Miller, E. Shi, Z. Wen, and

C. Papamanthou. Hawk: the blockchain model of
cryptography and privacy-preserving smart contracts.
IACR: 2015/675.

[30] H. Krawczyk and T. Rabin. Chameleon signatures.

NDSS’00. The Internet Society.

[31] J. Krupp et al. Nearly optimal veriﬁable data

streaming (full version). 2015. IACR: 2015/333.

[32] R. Kumaresan and I. Bentov. How to use Bitcoin to

incentivize correct computations. CCS’14. ACM.

[33] D. Levin, J. R. Douceur, J. R. Lorch, and

T. Moscibroda. TrInc: Small trusted hardware for
large distributed systems. NSDI’09. USENIX.

[34] Liar, liar, coins on ﬁre! — Penalizing equivocation by

loss of bitcoins. Full version of this paper.
Additionally available in IACR ePrint Archive. 2015.
http://crypsys.mmci.uni-saarland.de/projects/
PenalizingEquivocation/penalizing.pdf .

[35] D. Mazières and D. Shasha. Building secure ﬁle

systems out of byzantine storage. PODC’02. ACM.
[36] S. Nakamoto. Bitcoin: A peer-to-peer electronic cash

system. 2008. https://bitcoin.org/bitcoin.pdf .

[37] M. Peyravian, A. Roginsky, and A. Kshemkalyani. On
probabilities of hash value matches. Comput. secur.,
17(2), 1998.

[38] B. Poettering and D. Stebila.

Double-authentication-preventing signatures.
ESORICS’14. Springer.

[39] J. Poon and T. Dryja. The Bitcoin Lightning
Network: Scalable oﬀ-chain instant payments.
Technical Report (draft). https://lightning.network/.

[40] Providing a deposit. Entry in Bitcoin Wiki.

https://en.bitcoin.it/w/index.php?title=Contracts&
oldid=50633#Example_1:_Providing_a_deposit.
[41] M. Rosenfeld. Analysis of hashrate-based double

spending, 2014. arXiv: 1402.2009 [CoRR].

[42] D. Schröder and H. Schröder. Veriﬁable data

streaming. CCS’12. ACM.

[43] D. Schröder and M. Simkin. VeriStream - A

framework for veriﬁable data streaming. FC’15.

[44] S. Song. Why I left Sina Weibo. 2011.

http://songshinan.blog.caixin.com/archives/22322.

[45] J. Spilmann. Re: Anti DoS for tx replacement.

Bitcoin development mailing list.
https://www.mail-archive.com/bitcoin-
development@lists.sourceforge.net/msg02028.html.

[46] S. Tarkoma, C. Rothenberg, and E. Lagerspetz.

Theory and practice of bloom ﬁlters for distributed
systems. IEEE Commun. surveys and tutorials, 14(1),
2012.

[47] P. Todd. Near-zero fee transactions with

hub-and-spoke micropayments. Bitcoin development
mailing list. https://www.mail-archive.com/bitcoin-
development@lists.sourceforge.net/msg06576.html.
[48] P. Todd. OP_CHECKLOCKTIMEVERIFY. Draft
for Bitcoin Improvement Proposal. https://github.
com/petertodd/bips/blob/checklocktimeverify/bip-
checklocktimeverify.mediawiki.

[49] P. Wuille et al. libsecp256k1: Optimized C library for

EC operations on curve secp256k1.
https://github.com/bitcoin/secp256k1.

APPENDIX
A. COMPARISON TO DAPS

Like accountable assertions, double-authentication-preven-
ting signatures (DAPS) [38] prevent the authentication of
diﬀerent statements in the same context by providing an
algorithm that extracts the secret key in case of such double-
authentication.5 DAPS are a stronger primitive than ac-
countable assertions, with two main diﬀerences. First, there
is no “auxiliary secret information” in the strongest security
notion, i.e., the full secret key must be extractable in case of
double-authentication. Second, DAPS are unforgeable.

Theorem 3, whose proof appears in the full version [34],

captures that certain accountable assertions are DAPS.

Theorem 3. A secret and extractable accountable asser-
tion scheme that is additionally complete, has a stateless
assertion algorithm, and has no auxiliary secret information
is a double-signature extractable DAPS scheme.

It was left as an open problem to construct DAPS based on
Merkle tree or chameleon hash functions [38]. We can solve
these problems in the random oracle model. We modify the
complete variant of the construction (Section 5.3) as follows.
Instead of choosing a key k for the pseudorandom function F
at random, we set k := KDF(csk) for a key derivation function
KDF modeled as random oracle, where csk is the trapdoor of
the chameleon hash function. This eliminates the auxiliary
secret information. However, this modiﬁed construction
achieves only extractability with trusted setup, i.e., if the
key is generated honestly. (We share this limitation with the
basic construction proposed by Poettering and Stebila [38].)
Indeed, only the extractability of csk can be guaranteed.
Suppose the attacker can generate the keys. If the attacker
just choose k uniformly at random, knowing csk does not
help to obtain k. Consequently, signing messages is not
possible with csk alone.
Nevertheless, our modiﬁed construction is extractable with
trusted setup, and it is more eﬃcient than the construction
by Poettering and Stebila [38]. On a 2.10GHz (Intel Core i7-
4600U) machine with DDR3-1600 RAM, their construction
takes about 6700 ms for signing and 1500 ms with asymmetric
key size 2048 bits and hash size 160 bits. Our construction
with corresponding parameters (in particular ‘ = 160) takes
about 23 ms for signing and 11 ms for veriﬁcation. Signatures
in their construction need about 40 kB, while signatures in
our construction need about 4 kB.

In terms of security, our construction and their construc-
tion are only extractable with trusted setup [38]. Their
construction can be made secure against malicious key gener-
ation at the cost of adding rather expensive zero-knowledge
proofs to show that the public key is a well-formed Blum
integer (a product of two primes p, q with p ≡ q ≡ 3 mod 4).
In contrast, we are not aware of any practical approach to
make our construction secure without trusted setup.

A detailed discussion on the relationship between account-

able assertions and DAPS appears in the full version [34]
5The terminology in [38] is diﬀerent. While we speak of
“asserting a statement st in a context ct”, Poettering and
Stebila [38] speak of “signing a message st for a subject ct.”

230