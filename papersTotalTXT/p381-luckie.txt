bdrmap: Inference of Borders Between IP Networks

Matthew Luckie

University of Waikato
mjl@wand.net.nz

Amogh Dhamdhere
CAIDA / UC San Diego
amogh@caida.org

Bradley Huffaker

CAIDA / UC San Diego
bradley@caida.org

David Clark

MIT

ddc@csail.mit.edu

kc claffy

CAIDA / UC San Diego

kc@caida.org

ABSTRACT
We tackle the tedious and unsolved problem of auto-
matically and correctly inferring network boundaries in
traceroute. We explain why such a conceptually sim-
ple task is so hard in the real world, and how lack of
progress has impeded a wide range of research and de-
velopment eﬀorts for decades. We develop and validate
a method that uses targeted traceroutes, knowledge of
traceroute idiosyncrasies, and codiﬁcation of topologi-
cal constraints in a structured set of heuristics, to cor-
rectly identify interdomain links at the granularity of
individual border routers. In this study we focus on the
network boundaries we have most conﬁdence we can
accurately infer in the presence of sampling bias:
in-
terdomain links attached to the network launching the
traceroute. We develop a scalable implementation of
our algorithm and validate it against ground truth infor-
mation provided by four networks on 3,277 links, which
showed 96.3% – 98.9% of our inferences were correct.

With 19 vantage points (VPs) distributed across a
large U.S. broadband provider, we use our method to re-
veal the tremendous density of router-level interconnec-
tion between some ASes. In January 2016, the broad-
band provider had 45 router-level links with a Tier-1
peer. We also quantify the VP deployment required
to observe this ISP’s interdomain connectivity, with 17
VPs required to observe all 45 links. Our method forms
the cornerstone of the system we are building to map
interdomain performance, and we release our code.

Keywords
Internet topology; Router ownership

Permission to make digital or hard copies of all or part of this work for personal
or classroom use is granted without fee provided that copies are not made or
distributed for proﬁt or commercial advantage and that copies bear this notice
and the full citation on the ﬁrst page. Copyrights for components of this work
owned by others than ACM must be honored. Abstracting with credit is per-
mitted. To copy otherwise, or republish, to post on servers or to redistribute to
lists, requires prior speciﬁc permission and/or a fee. Request permissions from
permissions@acm.org.
IMC 2016, November 14–16, Santa Monica, CA, USA.
c(cid:13) 2016 ACM. ISBN 978-1-4503-4526-2/16/11. . . $15.00
DOI: http://dx.doi.org/10.1145/2987443.2987467

1.

INTRODUCTION

Every Internet researcher and operator is familiar
with traceroute, but not everyone is aware of the infer-
ential challenges in interpreting traceroute output, the
diverse barriers to developing a more accurate Inter-
net path inference capability, and the resulting imped-
iments to a range of research and development eﬀorts.
Despite these impediments, researchers have relied on
traceroute to support measurement and analysis of In-
ternet router-level topologies for two decades.

Internet router-level topology discovery and inference
is tedious and error-prone for at least ﬁve classes of rea-
sons. Most obviously, the TCP/IP architecture has no
notion of interdomain boundaries at the network layer.
In fact, the architecture does not even have any mecha-
nism to identify a complete router – an IP address iden-
tiﬁes only a single interface on a router, and routers may
have hundreds of (or thousands of virtual) interfaces.

Second, the measurement tool used for IP topology
discovery implements a 30-year old clever hack in which
an end host sends customized probe packets along a for-
ward path toward a destination to trick each router into
revealing one of their interface IP addresses to the end
host. Constructing an Internet-scale topology requires
superimposing millions of such measurements from mul-
tiple sources, onto an interface topology graph, and
then applying heuristic techniques to infer which IP
addresses are interfaces on the same physical router,
i.e., alias resolution. Failure to accurately resolve such
aliases for the same router will result in an inﬂated in-
ference of the number of links between networks.

Third, operator address assignment and router imple-
mentation practices limit the accuracy of the canonical
approach of mapping an IP address observed in tracer-
oute to the organization that announces the longest
matching preﬁx for that IP address in BGP [44]. Fourth,
traceroute measurements repeatedly sample links close
to the vantage point [22], resulting in topologies where
links farther from the network are less likely to be ob-
served. This sampling bias can reduce the accuracy
of router ownership inferences because there are fewer
topological constraints available.

381Finally, operators could overcome all of these issues
by assigning hostnames to router interfaces that identify
the router itself, but concerns about revealing network
topology information to competitors, or to prospective
attackers, align operator incentives away from trans-
parency about their internal network topologies.

These challenges impede many Internet research and
development eﬀorts, from realistic network modeling,
protocol design, to assessment of real-world network
properties such as interdomain congestion, infrastruc-
ture resiliency, and identifying vulnerabilities due to in-
adequate security policies. In light of these challenges,
this paper makes the following ﬁve contributions:

(1) We introduce a scalable method for accu-
rately inferring the boundaries of a given net-
work, and the other networks attached at each
boundary. Our approach eﬃciently infers forward IP
paths from traceroute measurements, resolves IP aliases
to construct a router-level topology [15, 40, 21], and
then uses this topology as well as topological constraints
inferred from BGP data [25] to narrow the possible set
of links and associated IP addresses that represent bor-
ders between networks. Our approach builds on gen-
erally accepted assumptions about industry practices,
such as numbering border router interfaces with IP ad-
dresses that belong to an upstream provider’s network.
Our method explicitly accommodates known limitations
of traceroute, e.g., sometimes a border router responds
to a traceroute probe using a source address belonging
to a third-party AS, i.e., one that maps to neither net-
work constituting the border. Even when a neighbor
network does not respond to our probes, our algorithm
can still pinpoint where they interconnect.

(2) We develop an eﬃcient system to allow
deployment of our method on resource-limited
devices. We show that the probing our algorithm uses
obtains a complete and accurate router-level interdo-
main map, but the densest measurement infrastructure
deployments use resource-limited devices that cannot
maintain state for the entire map themselves. We ex-
tend our measurement tools to support low-resource
devices by interactively oﬄoading data and state to a
centrally-operated system.

(3) We validate our algorithm’s correctness us-
ing ground truth from four network operators
as well as databases of IXP address use. We used
ground truth provided by a research and education net-
work, a large access network, a Tier-1 network, and a
small access network. For these networks, our algorithm
correctly identiﬁed interdomain links and corresponding
ASes for 96.3% – 98.9% of the 3,277 links inferred, ﬁnds
nearly all (92% – 99%) AS neighbors observed in pub-
lic BGP data, and correctly identiﬁes interdomain links
not observed in public BGP data.

(4) We demonstrate the utility of our algo-
rithm by analyzing the topology of a large ac-
cess ISP to understand modern interconnection
agreements. Data we collected in January 2016 shows

the presence of an astounding 45 interdomain links with
one of the ISP’s Tier-1 peers, geographically distributed
throughout the ISP’s network, with 25 of these links
only visible from a vantage point (VP) in speciﬁc re-
gions. For 73% of measured preﬁxes, we observed 5 –
15 distinct border routers carrying probe traﬃc.

(5) We publicly release the source code imple-
mentation. To promote further validation and use of
our network border mapping measurement and analy-
sis algorithm, which we call bdrmap, we publicly release
our source code implementation as part of scamper [23].
Our method infers all interdomain links directly con-
nected to and visible from the network hosting a single
VP. Accurately inferring the parties involved in all inter-
domain links observed in traceroute requires overcoming
the natural sample bias in traceroute [22], i.e., poorer
visibility into distant networks, which limits our abil-
ity to assemble constraints. We build on years of prior
work in topology discovery (e.g. [10, 2]), alias resolution
(e.g. [15, 40, 5, 21]), AS relationship inference [25], and
active probing systems (e.g. [23]). Our contributions are
a scalable system that synthesizes this prior work, and
a set of novel heuristics that correctly infer router-level
interdomain links and the involved parties.

2. MOTIVATION

Network Modeling and Resilience: Early models
of Internet topology considered each AS a node, and an
interdomain link an edge between two ASes [43]. While
this simplistic model does not reﬂect the complexity of
Internet interconnection, it has reﬂected the inferential
capabilities of the research community [43]. Our work
enables the construction of a router-level map of in-
terdomain connectivity, which will empirically ground
eﬀorts to accurately model AS topology evolution.

The capability to correctly identify the interdomain
links of a network also enables analysis of network re-
siliency and robustness in a way not previously possi-
ble. For instance, we can use comprehensive traceroutes
(from archives or targeted) to estimate which routers,
links, and interconnection facilities carry traﬃc to a sig-
niﬁcant fraction of the Internet [37], and the potential
of an attack or outage to disrupt connectivity.

Interdomain congestion: Exploding demand for
high-bandwidth content (e.g., streaming video) has fu-
eled recent peering disputes, creating tension among
ISPs. Although in the past such disputes have some-
times led to de-peering, the Internet’s critical role today
inhibits such behavior by networks. Instead, stalled ne-
gotiation about who should pay to upgrade interdomain
links may lead to congestion as traﬃc grows beyond ca-
pacity, aﬀecting not just the networks in dispute but the
sources and destinations of all traﬃc crossing the link.
The public policy community has growing interest in
identifying persistent congestion on interdomain links,
and its potential harms to consumers. In 2015, the U.S.
Federal Communications Commission (FCC) attached

382conditions to the AT&T-DirectTV merger [12] that re-
quire AT&T report to the FCC performance measure-
ments of its interconnections.

Recent work has explored various methods to identify
interdomain congestion: sending a time series of probes
to the near and far side of an interdomain link [24];
network tomography [36]; and crowd-sourced through-
put measurements [27]. Remarkably, with each of these
techniques, the greatest measurement challenge is not
detecting the presence of congestion, but identifying in-
terdomain links to probe, and associating observed evi-
dence of congestion to speciﬁc interdomain links [24].
Further, placing any isolated signal of congestion in
an appropriate context requires a more comprehensive
network-wide view of interdomain links and their con-
gestion state – ideally, some kind of weather map of
congestion. The surprisingly primitive state of Internet
measurement tools renders such an ambition a grand
challenge in our ﬁeld. Accurate identiﬁcation of net-
work borders is essential to progress on this goal.

3. RELATED WORK

Measurement and analysis of the Internet topology
has been an active area of research for over two decades.
The literature spans the AS, router, and physical topol-
ogy, with recent focus on the rich connectivity at IXPs
(e.g., [3, 1, 14]) and understanding physical infrastruc-
ture facilitating connectivity (e.g., [11, 13]). While our
work overlaps with research seeking to understand how
interconnection is facilitated, our objective is to infer in-
terconnection topology details that enable accurate in-
terpretation of routing and performance measurements.
Techniques for resolving IP addresses to com-
mon routers. The process of mapping IP addresses to
routers is known as alias resolution; it is a critical step
in counting and characterizing interdomain connections
between networks. Although researchers have made sig-
niﬁcant progress, this problem is not entirely solved. A
survey of existing alias resolution techniques and im-
plementations, including utilizing reverse DNS informa-
tion, record route data, and IGMP (multicast) protocol
messages, is available in [19]. Early techniques [31, 15,
20] probe unused ports on routers and collect the result-
ing error messages. Probing one interface and getting
an error response from a diﬀerent interface is evidence
that the two interfaces belong to the same router.

In 2002, Spring et al. developed a method and tools
to map individual ISP networks using focused tracer-
outes and BGP routing tables [40]. Their Ally tool was
the ﬁrst to infer that two addresses are aliases if probe
packets sent to them produce responses with increasing
but appropriately proximate IP ID values, since the IP
ID ﬁeld increments with each packet sent from some
routers. RadarGun [5] reﬁned this method by looking
for similarities in IP ID time series collected from mul-
tiple addresses. More recently, Sherwood et al. de-
veloped Discarte [39] which uses the IP record-route

option, traceroute, and disjunctive logic programming
to accurately derive a router-level topology from the
IP-interface topology. APAR [16] and kapar [19] used
sophisticated graph analysis techniques to infer subnets
linking routers, and from that, aliases. Sherry [38] de-
scribes iPlane’s use of the IP prespeciﬁed timestamp op-
tion to infer aliases. MIDAR [21] expanded on the IP ve-
locity techniques of RadarGun by implementing an ex-
tremely precise ID comparison test based on monotonic-
ity rather than proximity, integrating multiple probing
methods from multiple VPs, and using a probe schedul-
ing algorithm that scales to millions of IP addresses.
While these eﬀorts have contributed great progress to
the ﬁeld of router-level topology inference, they have
focused on structural properties of individual ASes; our
work here focuses on the accurate inference of router-
level interdomain connectivity between ASes.

Inference of AS-level connectivity. Despite its
limitations, traceroute can provide a source of AS-level
connectivity information, and compensate for a funda-
mental limitation of interdomain routing (BGP) data.
Speciﬁcally, BGP routers usually propagate to other
routers only their best path to a given destination, leav-
ing a rich database of connectivity knowledge available
only to the network’s operator. A dense deployment of
traceroute VPs does not rely on cooperation of network
operators, allowing each VP to observe the best path
to a given destination. However, deriving AS-level con-
nectivity from traceroute requires some level of heuristic
inference, and caution when applying it. The canoni-
cal approach to convert IP-level traceroute output to an
AS-level path is to map each observed IP address to the
AS originating a BGP announcement of the longest pre-
ﬁx containing that address. But this approach can in-
duce substantial false AS-link inferences, because some
routers respond to traceroute packets with a source IP
address belonging to a diﬀerent network [44]. Chen et
al. proposed a set of robust heuristics to distill missing
AS-level links from traceroute data [8], although they
did not attempt to attribute router ownership. The
primary motivation and focus of these eﬀorts has been
extending coverage of the AS-level graph by conserva-
tively supplementing BGP-based AS-level topology in-
formation.
In contrast, our work focuses on eﬃcient,
scalable, and automatable inference of router owner-
ship at network boundaries, although we must navigate
all the same pitfalls associated with IP- and AS-level
measurement data.

The closest prior works are two eﬀorts led by Mao
to build an accurate AS-level traceroute tool [29, 28], a
study by Huﬀaker et al. correlating AS- and router-level
connectivity [17], and a study by Chandrasekaran et
al. assessing the performance of paths between servers
operated by a large content distribution network [7].
Mao’s “AS traceroute” [29] correlated BGP and tracer-
oute views from the same VP, as well as DNS names
and WHOIS data to adjust IP-AS mappings so that the
traceroute-derived and BGP-observed AS paths were

383more congruent. In follow-on work, Mao et al. used a
dynamic programming technique to adjust IP-AS map-
pings at a /24 preﬁx granularity using co-located BGP
and traceroute views [28]. However, private intercon-
nection between networks usually uses /30 or /31 pre-
ﬁxes (rather than /24s) to use address space eﬃciently.
The source code for both systems is not publicly avail-
able. Huﬀaker et al. evaluated router ownership heuris-
tics based around router alias resolution, relationships,
and degree [17]. The best performing heuristic was val-
idated to be correct 71% of the time. Neither of these
works attempted to identify interdomain connectivity at
the router level. Our work does not require a correlated
BGP view or DNS data to correctly infer border routers.
Finally, Chandrasekaran et al. developed a method for
inferring ownership of interfaces observed in pair-wise
traceroutes between servers operated by a large content
distribution network [7]. Their heuristics are similar
to heuristics in this work. However, they acknowledge
that the collected IP-level paths are sparse and lack
ideal constraints; as a result, not all addresses had an
owner inferred. Further, there was no opportunity to
use alias resolution to infer a router-level graph as the
paths included historically collected data. Our method
deliberately collects paths towards every routed preﬁx
to obtain an ideal set of constraints, performs alias res-
olution to extract routers, and focuses on interdomain
links attached to the network hosting the VP.

Concurrent to our work, Marder et al. proposed the
MAP-IT algorithm to infer router ownership [30]. Sim-
ilar to Chandrasekaran et al. [7], their method works on
an interface-level graph, and infers the operator of all
addresses observed in the middle of a traceroute path,
using IP-AS mappings of adjacent addresses observed
before and after an address in a path. Half the inter-
domain links in our inferences are at the end of paths,
with no adjacent addresses in neighbor address space.
They validate their method against a published Inter-
net2 topology (100% correct) and using DNS strings on
interfaces from Level3’s address space (95.4% correct).

4. CHALLENGES

Inferring a router’s owner is surprisingly complicated
because the obvious inference – the origin AS of the
longest matching BGP preﬁx covering the IP address on
a router interface – may be incorrect for at least the fol-
lowing seven reasons, many of which are covered in [44,
24]. Yet, lack of a better method leaves researchers us-
ing simple but error-prone IP-AS mappings.

1. The router interface’s IP address may be
from a neighbor’s address space. When two ASes
interconnect with a point-to-point link, they typically
assign the link a subnet (usually a /30 or /31 in IPv4)
from address space held by one of the two networks. In
a customer-provider relationship, the provider usually
supplies the address space. When crossing a provider-
customer link, the customer’s router will usually use

Figure 1: Responses to traceroute probes de-
pend on the router software implementation and
placement in the network. A response from R2
may be naively interpreted as coming from a
router operated by AS A, B, or C.

an address from the provider’s space when responding
to a traceroute probe, so the ﬁrst hop in the customer’s
network in traceroute will usually use an address routed
by the provider. There is no convention who supplies
the address space in peer-peer relationships. Figure 1
illustrates this challenge: router R2 may respond with
address a3 originated by AS A, but be operated by B.
2. Border routers may use a third-party ad-
dress when responding to traceroute probes. A
third-party address is an IP address corresponding to
an AS that is not on the path toward a destination.
A third-party address arises from IETF advice to im-
plementers that a router use the source address of the
interface that transmits the response [4].
If a border
router’s best route to the VP is via a third-party AS,
and that AS provides the address space for the interdo-
main link, then the source address of response will map
to the third-party AS. In ﬁgure 1, c1 is a third-party
address on router R2 in a R1 − R2 − R3 path.

Sometimes R2 will respond using c1 regardless of the
interface it uses to transmit a response; for example, the
source address of an ICMP echo response is the destina-
tion address of the corresponding ICMP echo request.
We therefore avoid using the source address of an ICMP
response that matches the destination address probed,
as the position of that address on a router does not nec-
essarily correspond to the interface a traceroute probe
arrived at or departed from. For example, if we ob-
served an IP path segment a1−c1 in traceroute towards
c1, a naive IP-AS interpretation would incorrectly infer
an interdomain link between ASes A and C with border
routers R1 and R2.

3. Border routers may be conﬁgured to ﬁre-
wall traceroute probes. Due to security concerns,
operators of enterprise networks may conﬁgure their
border routers to discard packets that do not match
a permitted ﬂow at the edge of their network. In ﬁg-
ure 1, R5 will respond to traceroute probes with a TTL
expired message from address b5, but will not allow sub-
sequent probes into the network which will reveal IP

b1a1R1R2R3AS AAS BAS Ca2a3b2b3c1c2R4AS ER6AS DR5b4b5b6b?d?c3e?384addresses routed by D. Therefore, the only address ob-
served by traceroute on a router operated by D on a
path to D may be b5, originated by B. Similarly, R6 is
both conﬁgured to discard packets that do not match a
permitted ﬂow, and to not send ICMP messages, includ-
ing the TTL expired message. Therefore, we may not
have the ability to observe a border router in traceroute
for some neighbor networks.

4. Virtual routers may use a diﬀerent respond-
ing interface. Operators can use virtual router func-
tionality to isolate individual routing tables. Each vir-
tual router uses one IP address to form a BGP session
with a single neighbor. When the router responds to
a traceroute probe, it uses an address from the virtual
router that would have forwarded the packet had the
TTL not expired, even if that interface does not send
the response. In ﬁgure 1, if R3 has a virtual router con-
nected to AS D with address b4, and a virtual router
connected to AS E with b6, then the router will respond
to packets whose TTL has expired towards these ASes
with addresses b4 and b6 respectively. Therefore, we re-
quire the ability to infer that b4 and b6 belong to the
same router R3, although not all routers are responsive
to alias resolution probes.

5. Sibling AS behavior confuses attempts to
infer connectivity between organizations. Diﬀer-
ent ASes under the same administrative control (sib-
lings) may originate diﬀerent preﬁxes. WHOIS-based
inference of siblings [6, 18] suﬀers from limitations in
raw WHOIS data, which is not only inconsistently for-
matted across regions, but also becomes stale if not up-
dated as mergers occur. The only public sibling infer-
ences are derived at three-month intervals, with recog-
nized false and missing inferences [18].

6. IXP-owned addresses appear inconsistently
in paths. Most interconnection links are automatically
established between ASes at an IXP using the IXP’s
route server [14]. To promote public peering, IXP op-
erators provide a shared peering fabric and associated
IP subnet for participants to use. The IXP’s own AS
may or may not originate this subnet, and/or an IXP
member ASes may inadvertently announce it, mislead-
ing inferences based on IP-AS mapping.

7. Multiple ASes may originate a preﬁx into
BGP. Some preﬁxes are originated by multiple ASes,
which might be siblings or distinct organizations. The
more ASes originating a preﬁx, the more challenging it
is to interpret the appearance of a matching IP address
in a traceroute path, as the address could be on a router
operated by any of the originating ASes.

In prior work, we discussed how a subset of these
challenges impacted our ability to measure performance
of interdomain links at scale [24].
In this paper, we
build and validate a system for mapping the interdo-
main connectivity of a hosting network. This system
supports the CAIDA/MIT congestion project [9], mon-
itoring interdomain links for congestion using 40 VPs
in 28 networks as of May 2016.

Figure 2: The bdrmap system collects raw data
to build an interdomain router-level map for the
hosting network (§5.3), and applies heuristics to
infer its border routers (§5.4).

5. BORDER MAPPING METHOD

Figure 2 summarizes our approach to border map-
ping. Our approach begins with assembling routing and
addressing data used to inform data collection and anal-
ysis. Then, we deploy an eﬃcient variant of traceroute
to trace the path from each VP to every routed pre-
ﬁx observed in the global BGP routing system. We
apply alias resolution techniques to infer routers and
point-to-point links used for interdomain interconnec-
tion. We use this collected data to assemble constraints
that guide our execution of heuristics to infer router
ownership. §5.1 discusses our approach to developing
our system, and §5.2 outlines the input data the system
requires. §5.3 describes our preliminary construction
of a router-level map, and §5.4 explains how we apply
heuristics to the collected data to infer routers and their
owners. §5.5 presents some limitations of our algorithm,
§5.6 reports on our validation, and §5.7 compares our
inferences to the public BGP view. Finally, §5.8 dis-
cusses how we addressed systems challenges.
We developed a specialized measurement utility that
we call bdrmap to drive data collection (§5.3) and infer
border routers (§5.4). The goal of bdrmap is to obtain
as much information available about the links observed
from a given network toward every other network, in
order to constrain our subsequent border router infer-
ences. We implemented bdrmap as a driver to scam-
per [23], a parallelized measurement system that eﬃ-
ciently gathers raw traceroute and alias resolution data.

ASrelationshipsRIRdelegationsASpreﬁxesVPASesIXPpreﬁxesbdrmapscamper§5.3: Data CollectionRouter-level topologybdrmap§5.4: Infer interdomainlinksBorderrouters3855.1 Development Approach

The goal of our system is to correctly identify owners
of border routers, with minimal manual work, so that
our system will support applied research of network be-
havior. In §5.6, we report that the system produced in-
ferences for four networks that validated well – 96.3% to
98.9%, depending on the network. However, we empha-
size that we did not develop our algorithm with ground
truth. Anticipating diﬃculty obtaining ground truth,
we developed our data collection and heuristic methods
iteratively, over the course of a year, without validation
data. We used DNS-naming, where available, to infer
if our methods appeared to yield correct inferences, as
well as manual investigation of inferred routers and their
neighbors; e.g., border routers with high out-degree to
routers in a single neighbor AS usually implied an in-
correct inference. We could not perform automated val-
idation using DNS-based heuristics, as we found inter-
domain links labeled incorrectly as well as links labeled
with organization names, rather than AS numbers.

5.2 Input Data

We seed our measurements with four data sources:
public BGP data to obtain origin ASes for each routed
preﬁx as well as to infer AS relationships between net-
worked organizations; a list of known IXP preﬁxes; del-
egation ﬁles published by RIRs, and a list of sibling
ASes for the networks we measure.

Public BGP data: We obtained BGP data from
routing table snapshots collected by the Route Views
(RV) and RIPE’s Routing Information Service (RIS)
projects [35, 34]. For each IPv4 preﬁx of size at least /8
and no smaller than a /24, we recorded the origin ASes
we observed in BGP paths to those preﬁxes. We also
used the process described in [25] to infer AS relation-
ships for the same BGP data. This algorithm annotates
each AS-link observed in the BGP data with either a
peer-peer (p2p) or customer-provider (c2p) label.

RIR delegation ﬁles: Because some networks do
not advertise all preﬁxes used to number their inter-
faces, we use the public datasets supplied by the ﬁve
Regional Internet Registries (RIRs) that report address
blocks they have delegated to networks. Some RIRs
provide an opaque ID that allows researchers to group
preﬁxes that are delegated to a single organization, al-
though the ID cannot be directly tied to an AS.

List of IXP preﬁxes: We compiled a list of IXP
preﬁxes from database snapshots provided by the Peer-
ingDB and Packet Clearing House (PCH) projects [33,
32]. PeeringDB is a database that allows Internet ex-
change point operators (IXPs) to record information
such as the IP preﬁxes used to establish public peerings
at their IXP, and allows network operators to record the
IP addresses they have been assigned by IXP operators
to establish peering. PCH records IP subnets, as well
as pairs of IP addresses and ASNs used by BGP routers
to establish peering at PCH-operated route collectors.

Because not all PeeringDB records are correct (they
may be entered erroneously and may become stale) and
many IXPs are missing from the database, we combined
both PeeringDB and PCH data to produce lists of net-
work preﬁxes used by IXPs to establish peering. Where
available, we used IP addresses recorded by operators
to validate our ownership inferences (§5.6).

VP ASes: For each VP we probed from, we assem-
bled a list of sibling ASes the network hosting the VP
uses to organize its routing. We seeded our manual in-
ference with CAIDA’s public AS-to-organization map-
ping ﬁle [18] which is derived from information encoded
in WHOIS databases, manually added missing siblings,
and removed spurious siblings. Sibling inferences are
the only input data that requires manual oversight.
5.3 Construction of Router-level Topology
Our inference of the router-level topology of the host-
ing network builds on years of previous work in topology
measurement, and proceeds as follows.

Generate list of address blocks to probe: We
begin by assembling address space blocks that each AS
routes. If X originates 128.66.0.0/16, and Y originates
128.66.2.0/24 (a more speciﬁc subnet of the /16), we
associate the 128.66.0.0 – 128.66.1.255 and 128.66.3.0
– 128.66.255.255 blocks with X, and the 128.66.2.0 –
128.66.2.255 block with Y. As our goal is to infer in-
terdomain connectivity, bdrmap does not include any
blocks originated by the network hosting the VP.

Gather traceroutes: We use the Paris traceroute
method [2], sending ICMP echo packets toward each ad-
dress block in the list, probing each target AS one block
at a time to minimize the impact on target ASes. To re-
duce run-time, bdrmap probes multiple target ASes at a
time in parallel. For each traceroute, we record the ﬁrst
IP address originated by an external network, and then
supply these addresses (the stop set [10]) to other tracer-
outes involving the same target AS to prevent subse-
quent traceroutes toward that AS from probing beyond
the ﬁrst interdomain link in the path that has been seen
before. For each address block, bdrmap ﬁrst probes the
ﬁrst (.1) IP address.
If bdrmap does not observe any
IP addresses in the traceroute path that map to an ex-
ternal network, or if the only address observed outside
the VP’s network was the address probed, then bdrmap
tries the next address in the block, up to ﬁve addresses
per block, to avoid interpreting potential third-party
addresses as neighbors (see §4).

Resolve IP address aliases to routers: We use
alias resolution techniques to reduce the interface-level
graph to a router-level graph reﬂecting the underlying
physical topology. This reduction allows us to include
constraints collected for all paths traversing a given
router. As bdrmap proceeds, it assembles sets of IP
addresses that might belong to the same router (can-
didate alias sets) and probes candidate pairs of IP ad-
dresses using alias resolution methods Ally and Merca-
tor. Ally [40] infers two IP addresses are aliases if the

386IP-ID values in responses from the two IP addresses sug-
gest they were derived from the same central counter;
we use UDP, TCP, ICMP-echo, and TTL-limited probes
to maximize our ability to infer aliases when routers are
unresponsive to speciﬁc types of probes. Mercator [15]
infers two IP addresses are aliases if the source address
of ICMP port unreachable responses is the same.

Infer point-to-point links: We use the preﬁxs-
can algorithm [26] to try to conﬁrm that we observe
the inbound interface of a router in traceroute, rather
than a third-party address. The preﬁxscan algorithm
assumes common peering practice: routers connected
with point-to-point links often use /30 or /31 subnets
between them. Preﬁxscan thus infers if an address in a
traceroute path corresponds to the interface on a router
that received the packet (the inbound interface), by at-
tempting to infer if its /30 or /31 subnet mate is an
alias of the previous hop. We also used the Ally and
Mercator techniques to infer the same alias pair.

Limit false aliases: Because Ally infers false aliases
if two IPID time series from diﬀerent central counters
temporarily overlap, we repeat Ally measurements ﬁve
times at ﬁve minute intervals. We only include alias
inferences if further Ally measurements do not reject a
shared counter hypothesis. We use MIDAR’s test [21]
that requires non-overlapping IPID samples to strictly
increase, rather than be within a fudge factor.

Build router-level graph: We use the alias reso-
lution data collected with Ally, Mercator, and Preﬁxs-
can to collapse the interface graph to a router graph.
When building a router using Ally and Preﬁxscan infer-
ences through transitive closure (i.e., if x1,x2 and x2,x3
are pairs of inferred aliases, then x1 and x3 are also
aliases) we only used pairs of IP addresses where none
of the measurements suggested a pair of IP addresses
were not aliases. For each router, we then identiﬁed
which interfaces we observed in ICMP time exceeded
messages in traceroute probes, as we focus on these in-
terfaces when making ownership inferences: ICMP time
exceeded messages are less likely than other ICMP mes-
sages (such as echo reply and destination unreachable)
to have third-party source IP addresses. For example, a
router will use the destination IP address from an echo
request as the source address of an echo reply, providing
no indication whose router the address is on.

Parts of our data collection process are similar to
Rocketfuel’s process [40]. However, Rocketfuel’s goal
was to map topologies of networks from outside. To
gain eﬃciency, Rocketfuel collected paths to customer
preﬁxes of each network, as these are more likely than
other preﬁxes to cross the network. bdrmap infers in-
terdomain connectivity for the network hosting the VP,
and uses doubletree’s stop set concept to gain eﬃciency.
bdrmap’s run-time depends on the diameter and com-
plexity of the hosting network: at 100pps, the shortest
run-time we observed was for a research and education
network at ≈12 hours. bdrmap’s run-time on large U.S.
broadband provider networks takes ≈48 hours.

Figure 3: Conceptual mapping of heuristics we
use to infer interdomain routers (§5.4.) Heuris-
tics are numbered in the order that bdrmap eval-
uates them for a given router.

5.4 Algorithm to infer interdomain links
We traverse each router in the graph structure, in the
order of observed hop distance from the VP, and apply
a set of heuristics (conceptually mapped in ﬁgure 3) to
infer the owner of each router. The overall approach of
bdrmap is to ﬁrst infer the routers operated by the net-
work hosting the VP, and then use as much information
as possible to make inferences for routers operated by
neighbor networks. bdrmap evaluates the heuristics in
the order we present them; the heuristics for inferring
neighbor routers are ordered by available constraints.
First, (§5.4.1) we try to infer if the router is oper-
ated by the AS hosting the VP, as this may allow us
to infer an adjacent router with interfaces numbered
from address space originated by the network hosting
the VP is actually operated by a neighbor AS. Because
we traverse the graph in order of observed hop distance,
we identify routers operated by the AS hosting the VP
(the near side of an interdomain link) before we infer
routers operated by neighbor ASes (the far side of an
interdomain link). We infer the near side of an interdo-
main link using only this ﬁrst step, and all subsequent
heuristics infer owners for the far side.
In this step,

Infer routersoperated bythe networkhosting the VPVPInfer operator ofneighbor routerswith ﬁrewallsInfer operator ofneighbor routersusing unroutedIP addressesx?xxx?Use IP-ASmappings to inferoperator ofneighbor routersaxbbaUse AS relationshipsto infer operator ofneighbor routersaxxcxInfer additionalaliases for routersin the networkhosting the VPCAABCCBInfer operator ofneighbor routersthat did not send TTLexpired messagesAcC§5.4.2§5.4.3§5.4.4§5.4.6§5.4.5§5.4.7§5.4.8§5.4.1xccabcbb387bdrmap also estimates ownership of address space not
originated in BGP by the network hosting the VP. We
have used VPs in several networks who do not announce
some of their own address space; fortunately these net-
works usually announce other infrastructure addresses
that bdrmap observes nearby in a traceroute. When
bdrmap observes an address in traceroute originated in
BGP by a VP AS, it assumes all previous addresses in
the traceroute path back to the VP were delegated to
the network hosting the VP, and identiﬁes the missing
address blocks by ﬁnding the match for each IP address
in the RIR-published delegation ﬁles.
Second, (§5.4.2) if we observed no other interfaces
adjacent to a router, and we only observed interfaces
numbered from address space originated by the net-
work hosting the VP, then we reason about ownership
based on the destination networks probed, as we have
no other constraints. Third, (§5.4.3) if we visit a router
where the address space it uses is unrouted, then we rea-
son about the router based on adjacent networks and
destination networks probed, as we have no other con-
straints. Fourth, (§5.4.4) if we visit a router where two
consecutive hops are routed by the same external AS,
we reason that the addresses do not represent a third-
party AS and infer the router is operated by the external
AS. Fifth, (§5.4.5) if we know of an existing relationship
from BGP, then we infer that router is likely operated
by that network, with exceptions made for third-party
addresses also inferred using BGP-derived relationships.
Sixth, (§5.4.6) we reason about ownership using IP-AS
mappings as we have exhausted better methods (§5.4.1-
§5.4.5). Seventh, (§5.4.7) we use our interdomain link
inferences to infer additional aliases for near-side routers
of interdomain links where we infer a point-to-point link
was used to establish connectivity to their neighbor.
Eighth, (§5.4.8) we reason about border routers that
did not send TTL-expired messages, as we can now
place these routers into a topological context using our
inferred router-level graph. Until §5.4.8, we only con-
sider router addresses from ICMP TTL-expired mes-
sages when we infer router ownership. As discussed in
§4, the source address of an ICMP echo reply is the
destination address probed, which can be any of the
interfaces on the router, whereas ICMP time exceeded
messages usually identify ingress interfaces [26].

Finally, for each router, bdrmap deﬁnes nextas as the
most common provider AS of all destination ASes it
probed through that router from that VP, if the router
appears in paths to multiple destination ASes. In the
ﬁrst three steps, we use nextas as a candidate owner AS
for these routers, reasoning that the AS may be provid-
ing transit to the ASes reached through these routers.
5.4.1 Infer routers operated by the network
hosting the VP (ﬁgure 4): Interfaces subsequent to a
router R1 that are also routed by the network hosting
the VP (AS X) usually imply R1 belongs to X. There-
fore, in step 1.2, if the IP addresses bdrmap observes are
originated by X (as for R1), and bdrmap observes other

Figure 4: (§5.4.1) Interfaces subsequent to R1
that are also routed by the network hosting the
VP usually imply R1 belongs to the VP.

Figure 5: (§5.4.2): It is not common for an ad-
dress from A to appear in a traceroute toward
A, because a ﬁrewall usually discards packets at
the edge of A.

IP addresses originated by X subsequent in the path
(e.g., x2 and x3 on routers R2 and R3), then bdrmap in-
fers R1 is operated by X. An exception is when neighbor
A is multihomed to X via routers adjacent to each other
– step 1.1 in ﬁgure 4, routers R1 and R2. If bdrmap ob-
served those routers as x1 and x2 in a traceroute path,
and bdrmap observed addresses originated by A also ad-
jacent to R1, we infer A operates both R1 and R2. To
limit false inferences, we consider owner AS inferences
we would have made for routers subsequent to R1:
if
any is a customer of X, but not a known neighbor of A,
then we infer X operates R1.

As a result of these heuristics, we also infer that any
other router bdrmap observes with addresses originated
by the network hosting the VP is operated by a neigh-
bor network. That is, the hosting network provided the
address space for the interconnection link to the neigh-
bor. In §5.6 we show this logic is nearly always correct.
5.4.2 Infer operator of neighbor routers with
ﬁrewalls (ﬁgure 5): It is not common for an address
from AS A to be recorded in a traceroute path toward A,
because a ﬁrewall usually discards probe packets at the
edge of A. Therefore, the last router observed by bdrmap

1.1 R1 has interface in x, subsequent interface in x, but majority in A and nextas A Assign A1.2 subsequent interface in X? yesx1multihomedstep 1VPR1x1R2R3R4nextas AR1x2a1a2Assign XﬁrstR1x1VPx1R1R2R3x2x3yesno2.1 no subsequent routers observed?x1Assign Ax1yesR1nextas AR1ﬁrewallstep 2VP388(§5.4.4) IP-AS mappings can lead
Figure 7:
to incorrect
in the presence of
third-party addresses, but subsequent interfaces
routed by the same network suggest a1 is not a
third-party address.

inferences

5.4.4 Use IP-AS mappings to infer operator
of neighbor routers (ﬁgure 7): Using IP-AS map-
pings to infer ownership can be error-prone because a
router may respond with an IP address that represents
a third-party (see §4). However, we hypothesize that
we are unlikely to observe two third-party addresses in
a row, so if we observe addresses originated by the same
AS at two consecutive hops, we infer that AS is the in-
terconnecting party.

Therefore, if all interface addresses bdrmap observes
on router R1 map to the same origin AS A in BGP, and
at least one adjacent router R2 subsequent in a tracer-
oute path also has an address in A, then we infer A
operates R1 (step 4.1). Similarly, if bdrmap observes
a border router R1 operated by neighbor A using ad-
dresses that the network hosting our VP (X) originates
in BGP, and bdrmap observes two consecutive routers
R2 and R3 with interface addresses originated in BGP
by external network A, then we also infer A operates
R1 (step 4.2).

5.4.5 Use AS relationship inferences to infer
operator of neighbor routers: (ﬁgure 8): If we do
not observe two hops with addresses from the same AS
(§5.4.4), we have less router-level information to reason
about router ownership. Therefore, we use AS relation-
ships (§5.2) to guide router operator inference.

We ﬁrst infer if the IP-AS mapping of a router inter-
face is a third-party AS mapping, as follows. If bdrmap
observed an address on R2 that A originates in BGP,
but bdrmap only observed R2 on paths toward B, it is
possible the address bdrmap observed on R2 is a third-
party address.
If A is a provider of B (per our BGP
inference), then we infer R2 used a route from their
provider to respond to traceroute (a third-party ad-
dress) and that AS B operates R2. If (step 5.1) bdrmap
only observed addresses that the network hosting our
VP (X) originated in BGP on a router R1 preceding
R2, then we also infer that AS B operates R1. Similarly,

Figure 6: (§5.4.3): Some operators do not route
infrastructure IP addresses in BGP, so we in-
fer their routers based on subsequent routed ad-
dresses in traceroute paths.

in a traceroute path to A (and A’s siblings) is usually
A’s edge router, as is the case for router R1 operated
by A. If bdrmap observes R1 with interfaces originated
by the network hosting the VP (X), and no adjacent
interfaces in A, it assumes X provided the address for
interconnection to A and infers R1 is operated by A.

5.4.3 Infer operator of neighbor routers that
use unrouted IP addresses (ﬁgure 6): Some opera-
tors do not advertise routes to the IP addresses on some
of their routers. This practice can hamper inference of
border routers because the origin AS can provide con-
straints to narrow down the owner of the router. There
are two related scenarios that bdrmap addresses.

A neighbor router R1 might have addresses that our
VP-hosting network (X) originates in BGP, but the ad-
dresses observed on subsequent routers (e.g., R2) might
be unrouted. Or, not illustrated in ﬁgure 6, R1 might
have unrouted addresses but be connected to a router
we have previously inferred to belong to X. In both
cases, bdrmap assembles the set of ASes that originate
the ﬁrst routed interfaces in traceroute paths after R1,
and uses these interfaces to infer R1’s operator. If there
is only one AS (step 3.1), bdrmap infers that AS op-
erates R1.
If there are multiple (step 3.2), for each
AS in the set bdrmap identiﬁes the providers of the AS
using BGP-derived relationships, and infers that R1 is
operated by the most frequent provider AS among the
provider AS set, reasoning that this AS provides tran-
sit to networks observed by bdrmap. If bdrmap does not
observe any routed addresses in traceroute paths after
the border router, it infers that nextas operates R1.

3.1 unannounced address space followed addresses only in A?step 3Assign AyesunroutedR1x1Assign CyesunroutedR1x1Assign DyesunroutedR1x1R1R2Rnx1a1?13.2 subsequent majority common provider C?R1R2Rnx1a1?1RmCAB3.3 no subsequent topology observed?R1R2x1?1nextas Dnonob14.1 All interfaces in A and least one subsequent interface in A?Assign Ayesa1a2onenet4.2 two subsequent interfaces in A?yesstep 4R1R2x1VPR1a1R2a2R3x1R1VPAssign AR1a1a2oneneta3no389Figure 9: (§5.4.6) If there are multiple possible
IP-AS mappings, we infer the neighbor router is
operated by the AS with the most subsequent
interfaces.

Figure 8: (§5.4.5) AS relationship inferences de-
rived from public BGP data assist in identifying
the operator of a router responding with a third-
party addresses, as well as known peers and cus-
tomers of the network hosting the VP.

if (step 5.2) bdrmap instead observed R1 with address
space originated by A only on paths to B, then we infer
B operates R1.

For steps 5.3, 5.4, and 5.5, we start with R1 which we
observed using an address from the network hosting our
VP (X). If (step 5.3) adjacent interfaces only have ad-
dresses originated in BGP by a known peer or customer
A, then we infer that AS A operates R1. We make these
inferences after detecting third-party addresses because
a neighbor might use a third-party address that hap-
pens to be a known peer or customer of X. If (step
5.4) adjacent interfaces only have addresses originated
in BGP by a network A which is not an inferred peer
or customer of X, but B is a provider of A and X is a
provider of B, then bdrmap infers AS B operates R1; sib-
ling AS relationships (§4) can cause this scenario, where
the same organization operates ASes A and B. If none
of the above hold, and (step 5.5) subsequent interfaces
are originated in BGP by a single AS A, then we infer
that A operates R1.

Figure 10: (§5.4.7) Interdomain links are usu-
ally point-to-point links between two routers, so
multiple apparent IP links to the same neighbor
router are likely to be caused by IP aliases.

5.4.6 Use IP-AS mappings to infer operator
of neighbor routers in ambiguous scenarios (ﬁg-
ure 9): Some neighbor routers are also border routers
to other networks. This impacts analysis of traceroute,
as multiple adjacent IP addresses can be originated in
BGP by diﬀerent ASes.
In ﬁgure 9, R1 precedes in-
terfaces a1 and a2 on R2 and R3 routed by A, and b1
routed by B on R4; both R1 and R4 could be border
routers operated by diﬀerent networks. When (step 6.1)
we observe a neighbor router R1 using an address from
the network hosting our VP (X) to form the interdomain
link with, and multiple adjacent IP addresses originated
in BGP by diﬀerent ASes, then bdrmap infers the op-
erator of R1 to be the AS with the most adjacent IP
addresses. If there is a tie, we select the ﬁrst AS with a
known relationship (per our BGP inference) to the VP.
Otherwise, if the addresses bdrmap observes on a border
router R5 are originated by a diﬀerent AS, then bdrmap
infers the operator of R5 to be operated by that AS.

5.4.7 Infer additional aliases for border routers
(ﬁgure 10): We undertake a ﬁnal analytical alias reso-
lution step to address the cases where we were unable
to resolve likely aliases because the routers did not re-
spond favorably to our alias resolution probes. That is,
the routers did not respond to UDP probes with a com-
mon source-IP address, and did not assign IP-ID values
to responses from a single central counter. We assume

5.1 path to B and A is provider of B?yesx1a1path to B5.3 A is peer or customer of X peer/customerAXAor5.4 no X-A relationship, B provider of A, and X provider of Bstep 55.2 if interface in A on path to B, and A is provider of B?noXAB5.5 all interfaces adjacent to R1 in AVPR1R2Assign BthirdpartyR1x1VPR1a1path to ByesAssign BthirdpartyR1a1x1VPR1R2a1Assign AR1x1x1VPR1R2a1x1VPR1R2a1Assign BmissingR1hiddenpeerAssign AR1x1ABABnononoXA?yesyesyesx16.1 majority of interfaces in A?R1x1R2a1R3b1R4a2Assign Ax1R1countR5a1R5a1step 6 yes7.1 R1 and R2 (owned by X)connect to R3 (owned by A)step 7 R1x1R2x2R3x1 and x2 are aliasesR4R3x1x2yesalias390(§5.4.8) If a known neighbor (per
Figure 11:
BGP) ﬁrewalls selected probes from entering
their network, but paths towards that AS always
visit the same VP border router R0, we infer the
neighbor is connected to the VP router.

that a neighbor router R3 operated by A connects to
a single router in the VP’s AS by point-to-point link,
and (step 7.1) collapse single interface routers R1 and
R2 we previously inferred to be operated by X (in step
1.2) into into a single border router R4.

5.4.8 Infer operator of neighbor routers with-
out TTL expired messages (ﬁgure 11): Some oper-
ators conﬁgure their routers to never send TTL expired
messages, so these routers are not processed by previous
heuristics. Some routers respond to probes using other
messages, such as ICMP echo replies and destination
unreachables. The remainder of them remain silent. We
distinguish these cases from routers that rate limit their
response (are periodically responsive) by comparing the
set of VP neighbors we inferred borders for, from those
known to exist through public BGP data.

First, we assemble a list of neighbors observed in BGP
for the network hosting the VP for which we have not
inferred any interdomain links, and the traceroutes to-
ward those ASes. We then process the traceroutes for
each AS as a set. If the ﬁnal router observed by bdrmap
in the network hosting the VP was always the same
router (step 8.1), and bdrmap observed no other inter-
faces after that router when tracerouting toward a sin-
gle AS, then we infer the neighbor AS connects to that
router.
In this scenario, the AS has disabled ICMP
time exceeded messages and blocked our probe pack-
ets. While we cannot identify this (silent) router, we
can identify where it connects to the VP. Otherwise, if
the ﬁnal router bdrmap observed in the network host-
ing the VP was always the same router (step 8.2), and
bdrmap observed ICMP echo reply or destination un-
reachable messages with a source address that maps to
that neighbor AS, then we infer that neighbor AS con-
nects to the speciﬁc VP router.
In this scenario, the
neighbor’s border router has ﬁrewalled our probes from
entering the network, but sends speciﬁc ICMP messages
in response to our probes.

Figure 12: If an AS uses provider-aggregatable
address space from their provider on interfaces
on their internal routers, bdrmap may incorrectly
infer the position of interdomain link.

Figure 13:
If router R1 responds with diﬀer-
ent IP addresses depending on the destination
probed, and those addresses are not inferred to
be aliases, bdrmap may incorrectly infer the po-
sition of an interdomain link.

5.5 Limitations

bdrmap relies on the router-level map providing ad-
equate constraints so that our heuristics may correctly
infer border routers and their owners. However, not all
inferences we make are correct, as there are multiple
possible explanations for the topological arrangements
observed by bdrmap. In this section, we focus on topo-
logical limitations that can result in incorrect inferences
in where the network hosting the VP ends.

A provider may delegate provider-aggregatable (PA)
address space to their customer, and the customer may
conﬁgure part of that address space on their router in-
terfaces. In ﬁgure 12, AS A operates routers R1 and R2,
and uses PA address space from provider X on those
routers. When bdrmap observes these interfaces, it in-
fers an interdomain link between routers R1 and R2
operated by X and A, respectively, instead of correctly

8.1 R0 inferred, no response towards Ax1path to Astep 8 R0VPAssign AR1silentAssign AR1a1ICMPR1yesno8.2 R1 does not respond with ICMPTTL expired messagesx1R0VPR1a1yespath to Ax1VPR0R1x2x3R2x4x5nextas A(a) Actual router ownership x1VPR0R1x2x3R2x4x5nextas A(b) Inferred router ownership AS XAS XAS AAS Ax1VPR0R1x2R2(a) Actual router ownership x1VPR0R1x2x3x4nextas A(b) Inferred router ownership without alias resolution x3R3x4R1R3AS AAS BAS XAS BAS AAS X391Observed in BGP
Observed in bdrmap
Coverage of BGP
1. Multihomed to VP
2. Firewall
3. Unrouted interface
4. IP-AS (onenet)
5. Third party
5. AS relationship
5. Missing customer
5. Hidden peer
6. Count
6. IP-AS
8. Silent neighbor
8. Other ICMP
Neighbor routers

cust
30
28

R&E network
peer
prov

2
2

93.9%

1
1

Large access network

trace

82

cust
652
599

peer
26
26

prov

trace

5
5

65

cust
1644
1602

Tier-1 network
prov

peer
70
58
96.8%

0
0

92.2%
2.0%
36.5% 60.4% 5.9%
1.0%

0.4%

0.1%

51.4%

39.1% 64.7% 9.2%
3.0%
5.0%
8.6% 100% 100% 31.2% 3.9% 39.2% 87.5% 26.3% 6.7% 36.9%
8.6%
20.0%

0.4%
29.4% 41.2%

0.5%

2.1%

5.3%

0.2%
20.8% 34.0%
0.2%

2.9%
8.6%

24.0%
4.2%
1.0%

35

2

3

96

0.6%
0.5%
2.7%
1.5%
775

8.4%
4.2%

24.1%

2.3%

7.8%

3.9%

51

24

133

0.8%

4.0%
2.0%
2088

7.1%
2.1%
5.0%
0.7%
141

trace

58

62.2%
8.5%
2.4%
15.9%

4.9%
2.4%
3.7%

0

82

Table 1: Evaluation of bdrmap heuristics against BGP observations and AS relationship inferences for
three networks. We validated the R&E and large access network inferences against ground truth
(§5.6). For these networks, between 92.2% and 96.8% of BGP-observed links had a neighbor border
router inferred by bdrmap. bdrmap also inferred interdomain links that were not BGP-visible, and these
links and border routers are reported in the “trace” columns. For all three networks, the ﬁrewall
heuristic inferred most customer routers, i.e., the last interface observed by bdrmap was the ingress
interface address assigned by the network hosting our VP on their border router.

inferring the interdomain link between routers R0 and
R1. This occurs because bdrmap ﬁrst infers X operates
R1 as adjacent interface x5 on R2 implies R1 is oper-
ated by X (§5.4.1, ﬁgure 4). Note that bdrmap correctly
infers R2 is operated by A using the ﬁrewall heuristic
in §5.4.2 or the customer heuristic in §5.4.5, but the
inferred location of the interdomain link is incorrect.

Similarly, a router may respond to traceroute with
diﬀerent IP addresses, particularly if there are multiple
load balanced paths involving the router, or if the opera-
tor conﬁgures virtual routers to establish BGP sessions
with neighbors and the router uses a single interface
from each virtual router to respond to traceroute (§4).
In ﬁgure 13, R1 is owned by AS X, and R1’s interfaces
x2 and x3 were observed in traceroute paths preceding
routers R2 and R3, respectively. However, if bdrmap did
not infer x2 and x3 to be aliases, and if bdrmap only ob-
served x2 in paths towards A, bdrmap incorrectly infers
x2 to belong to a router operated by AS A. bdrmap cor-
rectly infers x3 to belong to a router operated by X, as
adjacent interface x4 implies x3 is on a router operated
by X (§5.4.1, ﬁgure 4). If bdrmap had correctly inferred
x2 and x3 to be aliases, it would have correctly inferred
the existence of a silent router R2 operated by A, and
that R1 is operated by X.
5.6 Validation against ground truth

During the validation phase, we contacted 10 net-
works seeking ground-truth, and received data from 4:
a research and education (R&E) network, a large access
network, a Tier-1 network, and a small access network.
When we received a response declining to provide vali-

dation, the response highlighted commercial sensitivity,
as commercial networks view their interconnection as
proprietary, particularly at the router-level. We only
asked about interdomain links we observed, as we as-
sumed the networks would not provide ground truth on
links we had missed.

We were able to validate all our neighbor router in-
ferences for the R&E and small access networks; the
R&E network supplied us a sanitized router conﬁgu-
ration dump, and the small access network operator
manually checked inferred adjacencies. Validation for
the larger networks was challenging, both because the
engineers we spoke with only had detailed visibility into
part of the network, and because sometimes the address
we observed in traceroute was not the address that the
interconnecting party used on the interface peering with
the network oﬀering us validation.

R&E network: We obtained a sanitized router con-
ﬁguration dump from an R&E network.
In January
2016, the network consisted of 17 routers with BGP ses-
sions involving 48 ASes and three IXPs. Of the 45 inter-
domain links we inferred outside of the IXP, 44 correctly
identiﬁed the presence of an interdomain link and the
correct AS. We also correctly inferred the location of a
further three interdomain links with ASes that disabled
any form of ICMP response. Further, we validated the
interdomain links established via route servers at the
three IXPs where the network was present by using the
IXP-published information on which ASes are present
and the IP addresses they use. Of the 88 ASes for which
we had validation data, we correctly identiﬁed the AS
for 82, with 2 more identifying a sibling of the correct

392AS, i.e. 84/88 (95.4%). Overall, we correctly identiﬁed
131 of 136 interdomain links (96.3%).

Large access network: We obtained a ﬁltered snap-
shot of a router conﬁguration dump for the backbone of
a large access network. The backbone connects the net-
work’s largest peers and customers, while other parts of
the network connect its enterprise customers. We sent
an operator of this network a list of all IP addresses
we believed to be on border routers, and received in re-
turn ground truth on whether each address was on an
internal or interdomain link. For those that were an in-
terdomain link, we received ground truth on which AS
the link was with. We evaluated the correctness of infer-
ences from three VPs within this network, where each
VP observed between 188 and 198 interdomain links.
We correctly inferred between 97.0% and 98.9% of in-
terdomain links and associated neighbor networks with
an AS reﬂecting the correct organization.

Tier-1 network: We sent an operator of a Tier-
1 network a list of all IP addresses we believed to be
on their neighbors’ side of an interdomain link, and re-
ceived validation data for 2691 interfaces. Using this
data, we found 2584 of the 2650 routers we inferred
were neighbor routers identiﬁed with an AS reﬂecting
the correct organization (97.5%).

Small access network: An operator at a small ac-
cess network manually validated our inferences for 14
routers with less than 12 interdomain links, and pro-
vided a sanitized dump of their interconnection partners
for three routers at interconnection facilities. In total,
they supplied validation data for 293 interconnections
we inferred, with 283 (96.6%) reported as correct.
5.7 Comparing traceroute and BGP views
Table 1 reports the coverage of interdomain connec-
tivity observed by one VP in each of three diﬀerent net-
works. We also used bdrmap to infer border routers of
25 other networks, with similar results. Table 1 catego-
rizes observed links into those observed in BGP (broken
down by inferred AS relationship), and those inferred
only in bdrmap’s traceroutes. bdrmap observed routers
connecting between 92.2% and 96.8% of BGP-observed
networks, with links for providers and peers the best
represented (at least one neighbor router observed for
all peers and providers for two of the three networks).
The rows in Table 1 list the results of the heuristics in
the order in which bdrmap applies them against an in-
ferred neighbor router. bdrmap infers at least half of in-
ferred customer routers with the ﬁrewall heuristic: i.e.,
bdrmap did not observe any interface originated by the
customer in a traceroute. The challenge in inferring cus-
tomers with traceroute is further illustrated by the rela-
tive use of the onenet and silent heuristics: only 3.9% –
8.6% of customers in these three networks had two con-
secutive interfaces in their network, but these heuristics
inferred 36.9% of peers and provider routers. Similarly,
bdrmap inferred that 2.7% – 8.6% of customers had dis-
abled time exceeded messages and ﬁrewalled our probes.

Figure 14: Distribution of number of border
routers and next hop ASes observed on paths
to all routed preﬁxes from 19 VPs in a large ac-
cess network. We found signiﬁcant redundancy
in the number of egress points towards a desti-
nation preﬁx. Most preﬁxes are routed via the
same next hop AS irrespective of VP location.

Figure 15: Marginal utility of VPs in discover-
ing interconnectivity of a large access network.
Some networks require a dense VP deployment
for bdrmap to uncover their links.

5.8 Supporting resource-limited devices

Some of the densest measurement infrastructure de-
ployments use extremely resource-limited devices. A
mapping of IP addresses to originating ASes, stop lists,
as well as state to guide alias resolution can require
substantial CPU time and memory storage relative to
resources available on some devices that could use our
technique. For example, the most powerful RIPE atlas
probes and SamKnows Whitebox measurement devices
use a MIPS-based processor operating at 400Mhz with
32MB of RAM and 4MB ﬂash, while bdrmap required
approximately 150MB of RAM to operate.

 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 5 10 15 20CDFBorder routersNext hop ASNsNumber of exits (border routersornext hop ASNs)GoogleNetflixAkamaiAppleLevel3Cogent 5 10 15 20 25 30 35 40 45 0 2 4 6 8 10 12 14 16 18 20Cumulative number of linksVPEdgecast393Figure 16: The impact of the VP’s geographic location (hollow circles) on the interdomain links (ﬁlled
symbols) observed by the VP for a large access network. Each row plots the longitude of the VP-side
of an interdomain link observed by a single VP in the access network. For Level3, the location of
the VP strongly inﬂuences the interdomain links observed. Because Akamai originates some preﬁxes
exclusively across individual interdomain links, all VPs observe all interdomain links.

We extended our data collection tools so that the
prober (scamper) can run on low-resource devices and
call back to a centrally-operated system, which has ac-
cess to greater compute resources and runs bdrmap.
We used VPs from the BISmark project [41] to prove
the system can feasibly run on other densely deployed
measurement systems. Similar to the SamKnows sys-
tems, the BISmark systems are OpenWrt-based with
a 450Mhz MIPS processor, 64-128MB of RAM, and
16MB of ﬂash storage. During our measurement, the
maximum CPU consumption used by scamper on the
BISmark VPs was 3%, and it used 3.5MB of RAM, or
11% of the total memory on the RIPE atlas and Sam-
Knows Whitebox devices. We use data we collected
from BISmark in §6.

6.

INTERCONNECTION INSIGHTS

We used 19 VPs deployed in a single large U.S. ac-
cess network to measure the diversity of its interdomain
paths in January 2016. Speciﬁcally, we computed the
number of border routers and next hop ASes traversed
on paths from these VPs towards all routed preﬁxes (ﬁg-
ure 14). This measure reﬂects network resiliency; many
border routers and next hop ASes able to reach a desti-
nation implies many redundant paths available in case
of network disruptions. The diversity in interconnection
is remarkable: we inferred that fewer than 2% of pre-
ﬁxes left this access network via the same border router
from each VP. For 73% of preﬁxes, we observed 5–15
distinct border routers, and 13% of preﬁxes had more
than 15 exit points. These numbers suggest astonishing

US East CoastUS West CoastInterconnection LocationPompano, FLAtlanta, GADetroit, MINashville, TNChicago, ILMinneapolis, MNHouston, TXBoulder, COAlbuquerque, NMSalt Lake City, UTSan Jose, CAMonterey, CASeattle, WABeaverton, ORUTCOTXMAILTNMNNYNJVAMDMIGAPAFLWAORCALevel3VP LocationAkamaiGoogleRockville, MDVP LocationVP LocationConcord, MAHillsborough, NJWashington, DCPittsburgh, PA394resiliency and redundancy toward most of the IPv4 In-
ternet. The AS-level density is lower: we inferred that
most (67%) preﬁxes are routed via the same next hop
AS regardless of VP location.

A driving motivation for this work is the ability to ac-
curately measure interdomain congestion and network
resiliency, which requires comprehensive coverage of in-
terdomain links of a network being studied. We thus
need to quantify how many VPs we need in a host-
ing network, and where we need them, to discover all
router-level interconnections. Using the same large ac-
cess network, we measured the marginal utility of ad-
ditional VPs for discovering interdomain links with two
large transit providers and ﬁve CDNs (ﬁgure 15). Aka-
mai and Level3 appear to be at two extremes in terms of
our ability to discover their interconnections from VPs
in the access network, revealing an interesting diﬀerence
in routing and interconnection strategies across these
networks. Speciﬁcally, a single VP in the access network
observes all the network’s interconnections with Aka-
mai, because Akamai advertises certain preﬁxes only at
speciﬁc interconnection points. In contrast, each addi-
tional VP reveals progressively more interconnections
with Level3, consistent with Level3 advertising most
preﬁxes at each interconnection point so that the ac-
cess network can hand oﬀ traﬃc toward a preﬁx at its
closest interconnection point – hot potato routing [42].
We observed all 45 router-level interconnections this ac-
cess network has with Level3 (as of January 2016), but
required 17 VPs in diverse geographical regions across
the U.S. to do so.

Figure 16 illustrates that it is not just number of VPs
but their geographical diversity within the VP that af-
fects the number of distinct interdomain links observed
for a large access network. For this access network, we
used the location information embedded in reverse DNS
mappings for IP addresses on their border routers to in-
fer their geographical location. Akamai’s announcement
policy allows a single VP anywhere to identify all points
of interconnection to this network. Visibility of inter-
connections to Google requires west and east coast VPs,
but visibility to all of Level3’s interconnections requires
VPs spread across the U.S. due to hot potato routing.

7. CONCLUSIONS

It would shock most people that something as basic
as connections between TCP/IP networks remains so
opaque to researchers and regulators, and the range of
research that is handicapped by lack of this measure-
ment capability. Although we have only taken the ﬁrst
step – identifying interdomain links directly connected
to and visible from the network hosting a measurement
vantage point – it is transformative for Internet map-
ping research. Our method uses targeted traceroutes,
detailed knowledge of traceroute behavior, and codiﬁ-
cation of topological constraints in a structured set of
heuristics, to correctly identify network boundaries at

the router-level. We applied our method to reveal the
tremendous density and diversity of router-level inter-
connection between some pairs of ASes. We explored
the parameter space of this method by computing the
marginal gains of VP deployment inside one large access
ISP, and the geographical diversity of VPs required to
achieve a full view of this ISP’s interconnectivity. This
topology measurement and analysis capability forms an
essential cornerstone of the system we are developing to
map interdomain performance measurements at Inter-
net scale, and we publicly release our source code.
Acknowledgments
We thank the operators who discussed aspects of their
network’s operations, the Research and Education Ad-
vanced Network New Zealand (REANNZ), Guilherme
Martins (Princeton) who deployed scamper on BISmark
nodes to support this work, and the anonymous review-
ers for their feedback. BISmark was supported by NSF
CNS-1422680 and CNS-1405781. This work was sup-
ported by NSF CNS-1414177 and CNS-1413905, by the
Department of Homeland Security (DHS) Science and
Technology Directorate, Cyber Security Division (DHS
S&T/CSD) via contract number HHSP233201600010C,
and by a grant from Comcast, but this paper represents
only the position of the authors.
8. REFERENCES
[1] B. Ager, N. Chatzis, A. Feldmann, N. Sarrar,

S. Uhlig, and W. Willinger. Anatomy of a large
European IXP. In SIGCOMM, 2012.

[2] B. Augustin, X. Cuvellier, B. Orgogozo, F. Viger,

T. Friedman, M. Latapy, C. Magnien, and
R. Teixeira. Avoiding traceroute anomalies with
Paris traceroute. In IMC, Oct. 2006.
[3] B. Augustin, B. Krishnamurthy, and

W. Willinger. IXPs: Mapped? In IMC, 2009.

[4] F. Baker. Requirements for IP version 4 routers,

June 1995.

[5] A. Bender, R. Sherwood, and N. Spring. Fixing
Ally’s growing pains with velocity modeling. In
IMC, pages 337–342, Oct. 2008.

[6] X. Cai, J. Heidemann, B. Krishnamurth, and
W. Willinger. Towards an AS-to-organization
map. In IMC, pages 199–205, Nov. 2010.

[7] B. Chandrasekaran, G. Smaragdakis, A. Berger,

M. Luckie, and K.-C. Ng. A server-to-server view
of the Internet. In CoNEXT, 2015.

[8] K. Chen, D. R. Choﬀnes, R. Potharaju, Y. Chen,

F. E. Bustamante, D. Pei, and Y. Zhao. Where
the sidewalk ends: Extending the Internet AS
graph using traceroutes from P2P users. In
CoNEXT, Dec. 2009.

[9] K. Claﬀy, A. Dhamdhere, M. Luckie, D. Clark,
and S. Bauer. Mapping interconnection in the
Internet: Colocation, connectivity and congestion.
http://www.caida.org/funding/nets-congestion/.

395[10] B. Donnet, T. Friedman, and M. Crovella.
Improved algorithms for network topology
discovery. In PAM, pages 149–162, Mar. 2005.

[11] R. Durairajan, P. Barford, J. Sommers, and

W. Willinger. InterTubes: A study of the US
long-haul ﬁber-optic infrastructure. In
SIGCOMM, Aug. 2015.

[12] Federal Communications Commission. MB Docket

No. 14-90), Memorandum Opinion and Order,
FCC 15-94, July 2015. https://apps.fcc.gov/
edocs public/attachmatch/FCC-15-94A1.pdf.

[13] V. Giotsas, G. Smaragdakis, B. Huﬀaker,
M. Luckie, and k claﬀy. Mapping peering
interconnections to a facility. In CoNEXT, 2015.

[14] V. Giotsas, S. Zhou, M. Luckie, and k claﬀy.

Inferring multilateral peering. In CoNEXT, Dec.
2013.

[15] R. Govindan and H. Tangmunarunkit. Heuristics
for Internet map discovery. In INFOCOM, pages
1371–1380, Mar. 2000.

[16] M. Gunes and K. Sarac. Analytical IP alias
resolution. In IEEE International Conf. on
Communications, pages 459–464, 2006.

[17] B. Huﬀaker, A. Dhamdhere, M. Fomenkov, and
kc claﬀy. Toward topology dualism: Improving
the accuracy of AS annotations for routers. In
PAM, Apr. 2010.

[18] B. Huﬀaker, K. Keys, R. Koga, M. Luckie, and

kc claﬀy. CAIDA inferred AS to organization
mapping dataset.
https://www.caida.org/data/as-organizations/.

[19] K. Keys. Internet-scale IP alias resolution

techniques. CCR, 40(1):50–55, 2010.

[20] K. Keys. iﬃnder alias resolution tool, 2012. http:

//www.caida.org/tools/measurement/iﬃnder/.

[21] K. Keys, Y. Hyun, M. Luckie, and k claﬀy.

Internet-scale IPv4 alias resolution with MIDAR:
System architecture. IEEE/ACM Transactions on
Networking, 21(2):383–399, Apr. 2013.

[22] A. Lakhina, J. W. Byers, M. Crovella, and P. Xie.
Sampling biases in IP topology measurements. In
INFOCOM, Apr. 2003.

[23] M. Luckie. Scamper: a scalable and extensible

packet prober for active measurement of the
Internet. In IMC, pages 239–245, Nov. 2010.

[27] M-Lab Research Team. ISP interconnection and
its impact on consumer Internet performance - a
measurement lab consortium technical report.
http://www.measurementlab.net/publications/,
2014.

[28] Z. M. Mao, D. Johnson, J. Rexford, J. Wang, and

R. Katz. Scalable and accurate identiﬁcation of
AS-Level forwarding paths. In INFOCOM, Mar.
2004.

[29] Z. M. Mao, J. Rexford, J. Wang, and R. H. Katz.
Towards an accurate AS-level traceroute tool. In
SIGCOMM, pages 365–378, Aug. 2003.

[30] A. Marder and J. M. Smith. MAP-IT: Multipass

accurate passive inferences from traceroute. In
IMC, 2016.

[31] J.-J. Pansoit and D. Grad. On routes and

multicast trees in the Internet. In SIGCOMM,
1998.

[32] Packet Clearing House. https://preﬁx.pch.net/

applications/ixpdir/menu download.php.

[33] PeeringDB. https://www.peeringdb.com/.
[34] RIPE RIS. http://www.ripe.net/ris/.
[35] U. Oregon Route Views Project.

http://www.routeviews.org/.

[36] S. Roy and N. Feamster. Characterizing correlated

latency anomalies in broadband access networks.
In SIGCOMM, pages 525–526, Aug. 2013.

[37] M. Sanchez, F. Bustamante, B. Krishnamurthy,

W. Willinger, G. Smaragdakis, and J. Erman.
Inter-domain traﬃc estimation for the outsider. In
IMC, Nov. 2014.

[38] J. Sherry, E. Katz-Bassett, M. Pimenova, H. V.

Madhyastha, T. Anderson, and A. Krishnamurthy.
Resolving IP aliases with prespeciﬁed timestamps.
In IMC, pages 172–178, 2010.

[39] R. Sherwood, A. Bender, and N. Spring.

DisCarte: A disjunctive Internet cartographer. In
SIGCOMM, pages 303–314, Aug. 2008.

[40] N. Spring, R. Mahajan, and D. Wetherall.

Measuring ISP topologies with Rocketfuel. In
SIGCOMM, pages 133–145, Aug. 2002.

[41] S. Sundaresan, S. Burnett, N. Feamster, and

W. de Donato. BISmark: A testbed for deploying
measurements and applications in broadband
access networks. In USENIX, June 2014.

[24] M. Luckie, A. Dhamdhere, D. Clark, B. Huﬀaker,

[42] R. Teixeira, A. Shaikh, T. Griﬃn, and J. Rexford.

and k claﬀy. Challenges in inferring Internet
interdomain congestion. In IMC, Nov. 2014.

[25] M. Luckie, B. Huﬀaker, A. Dhamdhere,

V. Giotsas, and k claﬀy. AS relationships,
customer cones, and validation. In IMC, Oct.
2013.

Dynamics of hot-potato routing in IP networks.
In SIGMETRICS, June 2004.

[43] W. Willinger, D. Alderson, and J. C. Doyle.

Mathematics and the Internet: a source of
enormous confusion and great potential. Notices
of AMS, 56(5), May 2009.

[26] M. Luckie and kc claﬀy. A second look at

[44] Y. Zhang, R. Oliveira, H. Zhang, and L. Zhang.

detecting third-party addresses in traceroute
traces with the IP timestamp option. In PAM,
Mar. 2014.

Quantifying the pitfalls of traceroute in AS
connectivity inference. In PAM, 2010.

396