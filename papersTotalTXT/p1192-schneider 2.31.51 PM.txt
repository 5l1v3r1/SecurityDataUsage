Efﬁcient Cryptographic Password Hardening Services

from Partially Oblivious Commitments

Jonas Schneider

CISPA, Saarland University
Saarland Informatics Campus

Nils Fleischhacker

CISPA, Saarland University
Saarland Informatics Campus

Dominique Schröder

Friedrich-Alexander-University,

Erlangen-Nürnberg

Michael Backes

CISPA, Saarland University &

MPI-SWS

Saarland Informatics Campus

ABSTRACT
Password authentication still constitutes the most widespread
authentication concept on the Internet today, but the human
incapability to memorize safe passwords has left this concept
vulnerable to various attacks ever since. Aﬀected enterprises
such as Facebook now strive to mitigate such attacks by
involving external cryptographic services that harden pass-
words. Everspaugh et al. provided the ﬁrst comprehensive
formal treatment of such a service, and proposed the Pythia
PRF-Service as a cryptographically secure solution (Usenix
Security’15). Pythia relies on a novel cryptographic primi-
tive called partially oblivious pseudorandom functions and its
security is proven under a strong new interactive assumption
in the random oracle model.

In this work, we prove that this strong assumption is inher-
ently necessary for the Pythia construction, i.e., it cannot be
weakened without invalidating the security of Pythia. More
generally, it is impossible to reduce the security of Pythia
to any non-interactive assumptions. Hence any eﬃcient,
scalable password hardening service that is secure under
weaker assumptions necessarily requires a conceptually diﬀer-
ent construction. To this end, we propose a construction for
password hardening services based on a novel cryptographic
primitive called partially oblivious commitments, along with
an eﬃcient secure instantiation based on simple assumptions.
The performance and storage evaluation of our prototype
implementation shows that our protocol runs almost twice
as fast as Pythia, while achieving a slightly relaxed security
notion but relying on weaker assumptions.

1.

INTRODUCTION

Password-based authentication is still the most widespread
means of authentication on the Internet today. In such a
system, a user sends her username and password to a server,
which compares both values against its stored record. Se-

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24 - 28, 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978375

curely realizing such a system turns out to be diﬃcult. In
addition to numerous usability pitfalls [25, 17], attackers
can steal password databases and mount eﬃcient brute-force
attacks, even in the face of known security properties of
a password scheme [41]. Practical attacks against several
enterprises, such as Target, Adobe, or AOL (an overview is
given in [42]) have shown that storing passwords as salted
hash values is not suﬃcient to ensure conﬁdentiality in case
of a breach. From this insuﬃciency arose a multitude of pro-
posals for authentication mechanisms which avoid passwords
altogether, e.g. [13, 30, 12]. However, if a password-based
authentication system has already been established it is of-
ten more economically viable to harden it against possible
attacks than to replace it from scratch.

One way to harden the security of password-based au-
thentication which has recently seen adoption from large
companies like Facebook [32] is to involve external crypto-
graphic PRF-Services [6, 38]. The basic idea is to physically
separate the database that stores the password records from
the server which computes the corresponding hashes. This
way, stealing a database of password records is not suﬃcient
to mount oﬄine attacks and the adversary has to compro-
mise the cryptographic service as well. Failing to do this the
adversary is forced to interact with the service, pretending to
be a legitimate client. This interaction can then be detected
via ﬁne-grained monitoring of suspicious use of the API.

While cryptographic PRF-Services have received attention
in industrial systems [32], a comprehensive formal treatment
of such a service was only recently provided by Everspaugh
et al. [19], who described the Pythia PRF-Service and gave
the ﬁrst formal consideration to its security. The Pythia
PRF-Service is ﬂexible and eﬃcient enough to be deployed
within an enterprise and it oﬀers several security features
that conventional PRF-Services do not oﬀer. Among others,
Pythia supports message privacy, rate-limiting, and individ-
ual key rotation. To achieve these properties, the authors
introduced a novel cryptographic primitive called partially
oblivious pseudorandom functions (PO-PRFs). A PO-PRF
is a two-party protocol where one party, a cryptographic
service provider, holds a key k for a function fk and a client
wishes to learn y ← fk(t, m), where t is called a tweak and
m the message. The output of the function is pseudorandom
and the service provider is partially oblivious about the input
meaning that the value t is public and m remains hidden.
The main motivation for revealing t is to enable rate-limiting
of online attacks, as a speciﬁc t being requested over and

1192over again is visible in the requests. Going beyond password
hardening applications, [19] discusses additional applications
of PO-PRFs such as Bitcoin brainwallets.

Partially oblivious PRFs are clearly an extremely pow-
erful primitive and realizing them seems to require strong
assumptions. Indeed, the construction of Everspaugh et al. is
similar to the left-or-right constrained PRF of Boneh and
Waters [9] and the non-interactive key-agreement protocol
of Sakai, Ohgishi, and Kasahara [39], thus the scheme also
requires similar assumptions. That is, the security of their
scheme is proven under an interactive assumption and the
proof is given in the random oracle model. The authors
leave open the question if these (trusted) assumptions are
necessary or if one could ﬁnd a scheme based on simple
assumptions in the standard model.

In this work, we show that this is not the case. We give
an impossibility result that rules out any security proof to
an arbitrary non-interactive assumption (using black-box
techniques only). Driven by the idea to develop an eﬃcient
password hardening service based on simple assumptions, we
develop a diﬀerent cryptographic primitive in order to bypass
this impossibility result. This primitive is general enough
to capture all requirements for a modern password harden-
ing system, yet it is not aﬀected by the impossibility result.
This is achieved by relaxing the requirement of pseudoran-
dom protocol outputs. Pseudorandomness provides ample
security for password hashes but is not ultimately necessary
to achieve a suﬃcient level of security. We call this new
primitive Partially Oblivious Commitments and propose an
instance based on simple assumptions. The main diﬀerence
to PO-PRFs is that the record output is not required to be
pseudorandom, although it can be, and that there exists a ver-
iﬁcation algorithm to check whether a stored record matches
(t, m) (rather than an equality test). Our comprehensive
performance evaluations demonstrate the practicability of
our approach and also show that our scheme is nearly twice
as fast as the scheme suggested by Everspaugh et al. [19] in
terms of latency in common settings.

1.1 Our Contribution

Our main contribution is the ﬁrst eﬃcient and scalable
password hardening scheme that is provably secure under
simple assumptions. The construction is based on a novel
cryptographic primitive called Partially Oblivious Commit-
ment (PO-COM). A PO-COM is an interactive two-party
protocol which allows one party to commit to a message
m and a tweak t. The commitment is binding in the usual
sense and partially hiding meaning that t is public, but m
remains hidden. In addition, there exists an eﬃcient protocol
that allows to verify whether a commitment contains (t, m).
PO-COMs are similar to partially oblivious pseudorandom
functions as introduced by Everspaugh et al. [19]. However,
we show that the security of their scheme inherently relies on
strong interactive assumptions and cannot be reduced to any
simple assumptions in the standard model (using black-box
techniques only). In fact, our result is more general as it
also rules out achieving weaker security notions. This result
answers a question explicitly left open by Everspaugh et
al. [19].

Our deﬁnition of PO-COMs is general enough to capture all
(functional) properties speciﬁed by the Pythia framework for
password hardening mechanisms and yet remains impervious
to the impossibility result. We give a simple and eﬃcient

instantiation of PO-COM that can be seen as a “twin-key”
variant of the Pedersen commitment scheme [36]. The main
idea of our twin-key technique is to derive a second key
s ← Fk(t) via a pseudorandom function and to use this key
to blind its twin key x. The purpose of the twin key is to
deterministically bind the stored record to the non-hidden
tweak t.

We demonstrate the eﬃciency of our construction via com-
prehensive performance evaluations and compare it to the
original implementation of Pythia. Our performance evalua-
tions show the practicability of our scheme. In particular, our
scheme is almost twice as fast as the construction Everspaugh
et al. [19], which is somewhat surprising given that our con-
struction is provably secure under simple assumptions and
fulﬁlls all properties put forward in the work of Everspaugh
et al. [19].
1.2 Related Work

Primitives that are related to partially oblivious pseudo-
random functions, and by extension to our generalization,
include delegatable PRFs [29], fully oblivious PRFs, intro-
duced in [33, 24] and variants of those which also provide
veriﬁability [26]. These primitives are close in functionality
to the requirements of our setting, but as noted in [19] do
not allow (only partial) obliviousness.

The security properties introduced in [19] are similare to
the security properties of blind signature schemes [14, 27, 37,
21, 23, 40, 34]. This similarity to blind signatures opens the
possibility for a translation of results regarding the ability
to instantiate the primitive under various assumptions.

Our analysis in this respect draws from the results of [22]
which say that there cannot be a black-box reduction from
the unforgeability of a three-move blind signature scheme to
any non-interactive problem. Moreover, there are a number
of separation results regarding “one-more” type assumptions
and security notions, e.g. [10, 11] and there is recent progress
on automatically analyzing certain classes of assumptions [4].
Our goal of oﬄine attack resistance is similar to that of

threshold password-authenticated key-exchange (t-PAKE) [31],
where a client has to interact with a threshold k out of n
available servers to authenticate. However, our primitive
is not distributed as we only consider protocols between a
client and a single server. Additionally, although the schemes
presented in [31, 3, 16] support blinding, they do not sup-
port partial blinding and the rate-limiting enabled by it, as
required for our primitive. The overall result of the protocol
execution in our case is a binary decision on a provided piece
of information, whereas PAKE, t-PAKE, and group key ex-
change [2] aim to derive a new key each time the protocol is
executed.

Our primitive is similar to P-Signatures [5], in that there
is a way to verify whether two commitments are for the
same value. However, this capability is restricted to the
client in our setting, whereas in P-Signatures, the client
should convince the server that they hold a signature for a
committed value.

2. PASSWORD AUTHENTICATION

In this section, we discuss the main security and functional
properties that modern password authentication services
should have, following the discussion in [19]. A password-
based authentication scheme has two phases:

1193Registration. A user registers at a service providing user-
name and password of her choice. The service stores the
username together with an authentication token, such as a
salted hash value.

Verification. A registered user sends her username and
password to the server, which checks if this information
matches the stored record.

The aim of a password registration and veriﬁcation pro-
cedure is to ensure that legitimate users have access to the
service. At the same time, an attacker should not be able to
use/guess the credentials of an honest user. Sophisticated
online and oﬄine attacks have shown that the passwords
should not be permanently stored in plain anywhere on the
server. Instead, the server has to derive a check value, such
as a salted hash, from the password upon registration, which
can then be derived also from the oﬀered password in the
veriﬁcation phase.

In oﬄine brute-force attacks, an attacker has obtained the
information used by the server to verify a password. This
information typically consists of the hash of the original
password together with a random salt per password, which
is stored together with the hash. The attacker now tries to
verify a large number of (precomputed) password guesses to
determine the correct password.

While such attacks are hard to prevent in general, it is
possible to inhibit their eﬀectiveness, e.g., through the in-
troduction of a third party, a cryptographic PRF Service,
which was formalized in [19]. The third party manages a
high entropy secret, which is used to compute high entropy
authentication tokens, stored by the server. The separation
of data and the secret used to compute the data introduces
an additional barrier a brute-force adversary has to overcome.
We describe the main functional and security properties that
should be provided. Subsequently, we show how to build
such a service based on a novel cryptographic primitive called
partially oblivious commitments (PO-COM’s).

Message Privacy. The cryptographic service should be
oblivious about the password m. This ensures that a cor-
rupted service provider does not leak any information about
the password.

Tweak Visibility. The username t must be visible to the
service to allow ﬁne-grained rate-limiting of requests.

Secure Key Rotation. On compromise of the service
master secret key there must a way to issue key updates to
all clients which allow migration of client data to a fresh,
uncompromised key. This key rotation should be secure in
the sense that an attacker who obtains a client and service
state of diﬀerent rotation levels should not be able to make
use of the client database.

In the subsequent sections, we propose our novel cryp-
tographic primitive, PO-COMs, and show how to build a
system as described above based on PO-COMs.

3. PO-COMMITMENTS

We introduce the notion of partially oblivious commitments
(PO-COM). Loosely speaking, a PO-COM is a two-party
protocol between a client C and a server S. The input of C
is a public key pk , a hidden message m, a public tweak t,
and a client secret csk . The server’s input is a secret key

sk (that corresponds to pk ). At the end of the protocol the
client outputs a commitment T and we call T the enrollment
record for t and m. Subsequently, the client can interact
with the server and check that (t, m) is stored in T . We call
this phase the validation phase and the client outputs either
accept or reject.

The security properties of PO-COM follow the ones of
commitment schemes. That is, the enrollment record T is
partially hiding, meaning that T and also the interactive
protocol to compute T hide all information about m, but t
may be leaked. Moreover, PO-COM is binding in the sense
that it is (computationally) hard to a ﬁnd a second pair
(t(cid:48), m(cid:48)) such that the client outputs accept in the validation
phase.
3.1 Deﬁnition of PO-COM

To deﬁne partially oblivious commitments formally, we
introduce the following notations for interactive executions
between algorithms X and Y. Let n ∈ N denote the security
parameter and X be a set. By x ←$ X we denote the uniform
drawing of a random element x from set X. Unless stated
otherwise, all algorithms run in probabilistic polynomial time
(PPT). For an algorithm A, let x ←$A(y) denote the event
that A on input y outputs x. If A is a deterministic algorithm
we write instead x ← A(y). For two PPT algorithms X ,Y
we denote by (a, b) ←$(cid:104)X (x),Y(y)(cid:105) the event that the joint
execution of X on input x and Y on input y produces local
output a for X and b for Y, respectively. If there is only one
output, then it is assumed to be for X . We denote with M
the space of messages and with T the space of tweaks. We
write Y(cid:104)X (x),·(cid:105)(y) if Y can invoke an unbounded number of
executions of the interactive protocol with X in arbitrarily
interleaved order.

Deﬁnition 1 (Partially Oblivious Commitments). A par-
tially oblivious commitment scheme consists of a tuple of
eﬃcient algorithms Π = (Setup,(cid:104)C,S(cid:105)enrl,(cid:104)C,S(cid:105)val), in three
phases:

Setup Phase. On input the security parameter, Setup(1n)
outputs a client secret csk as well as a pair (pk , sk ).
The client is provided with public key pk and client
secret csk , while the server gets secret key sk .

Enrollment Phase. The joint execution (cid:104)C(csk , pk , t, m),
S(sk )(cid:105)enrl for a message m ∈ M and tweak t ∈ T
generates an enrollment record T (the commitment)
for the client.

Validation Phase. The joint execution (cid:104)C(csk , pk , T, t, m),
S(sk )(cid:105)val for an enrollment record T , a message m ∈
M, and tweak t ∈ T generates a binary decision
{accept, reject} for the client.

A partially oblivious commitment scheme Π is correct if
for all n ∈ N, all keys (csk , pk , sk ) ←$ Setup(1n), all pairs of
messages and tweaks (t, m), and all T ←$(cid:104)C(csk , pk , t, m),
S(sk )(cid:105)enrl, the probability that (cid:104)C(csk , pk , T, t, m),S(sk )(cid:105)val
outputs accept is 1.

Deﬁnition 2 (Key Rotation). A PO-COM Π has key rota-
tion if there exists a key rotation protocol between client and
server such that the joint execution (cid:104)C(csk , pk , T ),S(sk )(cid:105)rot
for an enrollment record T generates an updated record T (cid:48),
a new public key pk(cid:48), and client secret csk(cid:48) for the client as
well as an updated secret key sk(cid:48) for the server.

1194Key rotation is correct, if for all (csk , pk , sk ) ←$ Setup(1n)
and tweak-message pairs (t, m) it holds that for an en-
rollment record T ←$(cid:104)C(csk , pk , t, m),S(sk )(cid:105)enrl after key
rotation ((csk(cid:48), pk(cid:48), T (cid:48)), sk(cid:48)) ←$(cid:104)C(csk , pk , T ),S(sk )(cid:105)rot the
updated T (cid:48) validates with the new key, i.e., accept ←$
(cid:104)C(csk(cid:48), pk(cid:48), T (cid:48), t, m),S(sk(cid:48))(cid:105)val.
3.2 Security of PO-COM

A partially oblivious commitment protocol allows to prove
that a tweak-message pair (t, m) is contained in a jointly
generated enrollment record T , which leaks no information
about m. The enrollment record T is veriﬁable, meaning
that there exists an interactive protocol to check whether
(t, m) is contained in T . Based on the applications we have
in mind, we derive the following security goals.

Hiding. In all interactions between both parties, the tweak is
revealed to the server, while the message should stay private
to the client.

Binding. The enrollment record must be binding, which
means that given some enrollment record T an attacker
should not be able to produce a diﬀerent, valid input pair
other than the originally enrolled pair.

Obliviousness. Given only an enrollment record, an at-
tacker should be oblivious about m, meaning that he should
not able to verify a guess for the input message that was
used to create the record.

In the following, we formalize these requirements in terms

of cryptographic games.
3.2.1 Partial Hiding
Our notion of partial hiding says that the enrollment record
T hides all information about the message m, but may leak
information about the tweak t. This security notion is useful
in settings like password-based authentication, where input
t, the username, is revealed to the server, while input m, the
password, should stay hidden.

Deﬁnition 3 (Partial Hiding). A partially oblivious com-
mitment protocol Π = (Setup,(cid:104)C,S(cid:105)enrl,(cid:104)C,S(cid:105)val) is partially
hiding if for any two-stage PPT adversary A = (A1,A2)
there exists a negligible function negl(n) such that

Π,A(1n) = 1(cid:3) − Pr(cid:2)Hiding1

Π,A(1n) = 1(cid:3)(cid:12)(cid:12) ≤ negl(n) ,

(cid:12)(cid:12)Pr(cid:2)Hiding0

where the randomness is taken over the random coins of the
experiments and the adversary. The two experiments are
deﬁned as follows:

Π,A(1n)

Hidingb
(csk , pk , sk , t, m0, m1, T, st) ←$ A1(1n)
b(cid:48) ←$ A(cid:104)C(csk ,pk ,t,mb),·(cid:105)enrl,(cid:104)C(csk ,pk ,T,t,mb),·(cid:105)val
return (b = b(cid:48))

2

(st)

3.2.2 Binding
A partially oblivious commitment protocol must be bind-
ing in the sense that it should be computationally hard to
ﬁnd two distinct pairs (t, m), (t(cid:48), m(cid:48)) for a record T , such that
the validation protocol outputs accept for both pairs. In
the context of password-based authentication, this property
ensures that the validation protocol will fail with overwhelm-
ing probability if the pair (t, m) does not have a matching

enrollment record T generated by the enrollment protocol
T ←$(cid:104)C(csk , pk , t, m),S(sk )(cid:105)enrl.

Deﬁnition 4 (Binding). A partially oblivious commitment
protocol Π = (Setup,(cid:104)C,S(cid:105)enrl,(cid:104)C,S(cid:105)val) is binding if for any
PPT adversary A there exists a negligible function negl(n)
such that

Pr(cid:2)BindingΠ,A(1n) = 1(cid:3) ≤ negl(n) ,

where the randomness is taken over the random coins of the
experiment and the adversary. The experiment is deﬁned as
follows:

BindingΠ,A(1n)
(csk , pk , sk ) ←$ Setup(1n)
((t0, m0), (t1, m1), T ) ←$ A(cid:104)·,S(sk )(cid:105)enrl,(cid:104)·,S(sk )(cid:105)val (csk , pk )
d0 ←$ (cid:104)C(csk , pk , T, t0, m0), S(sk )(cid:105)val
d1 ←$ (cid:104)C(csk , pk , T, t1, m1), S(sk )(cid:105)val
if (t0, m0) (cid:54)= (t1, m1) and d0 = d1 = accept

return 1

else return 0

3.2.3 Obliviousness
An enrollment record T is oblivious in the sense that the
adversary in unable to verify a guess for (t, m) without run-
ning the validation protocol with the server. We formalize
this intuition in a game where the adversary chooses two
messages, obtains an enrollment record T and can only guess
which of the two messages is stored in T . In our applica-
tion, this property prevents oﬄine brute-force attacks at
reproducing the values t and m from their enrollment record
T .

Deﬁnition 5 (Obliviousness). A partially oblivious commit-
ment protocol Π = (Setup,(cid:104)C,S(cid:105)enrl,(cid:104)C,S(cid:105)val) is oblivious if
for any two-stage PPT adversary A = (A1,A2) there exists
a negligible function negl(n) such that

(cid:12)(cid:12)Pr(cid:2)Obliv0

Π,A(1n) = 1(cid:3) − Pr(cid:2)Obliv1

Π,A(1n) = 1(cid:3)(cid:12)(cid:12) ≤ negl(n) ,

where the randomness is taken over the random coins of the
experiments and the adversary. The two experiments are
deﬁned as follows:

Π,A(1n)

Oblivb
(csk , pk , sk ) ←$ Setup(1n)
(t, m0, m1, st) ←$ A(cid:104)·,S(sk )(cid:105)enrl,(cid:104)·,S(sk )(cid:105)val
T ←$ (cid:104)C(csk , pk , t, mb), S(sk )(cid:105)enrl
b(cid:48) ←$ A(cid:104)·,S(sk )(cid:105)enrl
return (b = b(cid:48))

(st, T )

1

2

(csk , pk )

Secure Key Rotation

3.2.4
Key rotation should render an old client state useless to
the adversary and further an old server secret key should
not help in recovering information from an updated client
database. All security properties must hold in the presence
of key- rotations. Please refer to the full version of this paper
for a formal deﬁnition of secure key-rotation and further
discussions about hiding, binding, and obliviousness in the
presence of key-rotations.

1195Client C(csk , pk , t, m)

r ←$ Zq
v := mr·csk

parse c := (c1, c2, c3), π := (z, A, B)
(cid:48) ← H(g, pk , A, B, c2, c3/v)
h
if A = gz · ch(cid:48)
then return T := (c1, c2, c3/m(r−1)·csk )
else return ⊥

2 and B = pk z(c3/v)h(cid:48)

Server S(sk )

parse sk := (x, k)
y ←$ Zq; s ← Fk(t)
c = (c1, c2, c3) := (gy, gsy, gsxy · v)

−−−−−−−−−−−−−−−−−−−−−−−−→

(t, v)

T (cid:48) := (c, π)

←−−−−−−−−−−−−−−−−−−−−−−−−// Compute the proof of correctness

(cid:96) ←$ Zq; A := g(cid:96); B := Ax
h ← H(g, gx, A, B, gsy, gsxy)
z := (cid:96) − (hsy); π := (z, A, B)

Figure 1: The enrollment protocol.

4. CONSTRUCTION OF PO-COM

In this section we present our construction of partially
oblivious commitments. Due to space constraints, we omit
the deﬁnition of pseudorandom function, non-interactive
zero-knowledge proofs, and the deﬁnition of the decisional
Diﬃe-Hellman (DDH) problem.
4.1 Intuition

The core part of our construction can be seen as a “twin
key” variant of the Pedersen commitment scheme [36]. To
illustrate this idea, let x be a secret key, gx the corresponding
public key, and k the key of a pseudorandom function F .
To commit to a tweak t and a message m, the client sends
a blinded version (t, mr) to the server. The server derives
a twin-key via the PRF as s ←$ Fk(t) and computes the
enrollment record T (the commitment) choosing a random
value y and using both keys s and x. That is, it computes
T as T = (gy, gsy, gsxy · mr). Computing the twin key s
via a PRF ensures that the record depends deterministically
on the non-hidden tweak t and the PRF property ensures
that the output is computationally indistinguishable from
random. To enable client speciﬁc secure key rotation, each
client keeps its own client secret csk, which is used to shift
the message m.

In the validation phase, we perform two checks against a
previously generated enrollment record T . First, we check
whether the twin key was correctly generated from the tweak.
If this is not the case, we abort, because it means the server
is not following the protocol. The second check concerns the
validity of the message compared to the one committed to
in the record at hand.

Because of the randomization factor y, which is unique to
every run of the enrollment and validation protocols, two
enrollment records for the same message appear indistinguish-
able, unless one knows the enrolled message. This prevents
an adversary from verifying message guesses by repeatedly
modifying a given record and comparing against the server
response for the guessed message.
4.2 Our Scheme
Construction 1. Let G = (cid:104)g(cid:105) be a cyclic group of prime or-
der q, and let g be a generator of G. Let F : {0, 1}n ×
{0, 1}n → Zq be a pseudorandom function and let H :
{0, 1}∗ → Zq be a hash function.

Setup Phase. The setup algorithms Setup(1n) chooses
random values x, z ←$ Zq and a random key k ←${0, 1}n. It
returns (csk , pk , sk ) := (z, gx, (x, k)).
Enrollment Phase. The full enrollment protocol is de-
scribed in Figure 1 and consists of the following steps: The
client chooses a random blinding factor r ←$ Zq and sends as
its ﬁrst message the blinded message v = mr·csk and tweak
t . Once the server receives (t, v) it computes the twin key
s ← Fk(t) corresponding to t and the preliminary record
T (cid:48) = ((c1, c2, c3), π) consisting of (gy, gsy, gsxy · v), for some
randomly chosen value y ∈ Zq, and a proof of correctness
π. It sends the preliminary record T (cid:48) to the client. The
client parses the server’s response and checks the proof of
correctness. If the proof veriﬁes, the client outputs the record
T := (c1, c2, c2/m(r−1)·csk ).
Validation Phase. The full validation protocol is described
in Figure 2 and consists of the following steps: The client
parses the stored enrollment record T = (T1, T2, T3) and
chooses a random blinding factor r ←$ Zq. It then sends the
blinded message v = mr·csk together with tweak t and the
value T1 to the server. Once the server receives (T1, t, v), it
computes the twin key s ← Fk(t) corresponding to t, the
tuple c = (c1, c2, c3) := (gy, gsy, gsxy · v) and two proofs: The
ﬁrst proof shows that the server has used the same twin
key s ← Fk(t) which was also used during enrollment. The
second proof indicates whether the message m is equal to the
committed message in T . The server sends the preliminary
record c and the proofs to the client. The client parses the
server’s response and checks the proofs of correctness. If both
proofs verify, the client outputs accept, otherwise reject.

Both proofs resemble a Fiat-Shamir transformed [20] ver-
sion of a protocol for proving the equivalence of discrete
logarithms ﬁrst given by Chaum and Pedersen [15]. In order
to see why the scheme is correct, consider the case that we
perform a validation run for the pair (t, m) and a record T
originally generated for the pair (t, m(cid:48)).

The ﬁrst check guarantees that

A1 =T z1
1

· T h(cid:48)

1

2

i.e., T (cid:96)1

1 = T (cid:96)1−h1s

1

· T h(cid:48)

1

1s

and that

B1 =cz1

1 · ch(cid:48)

2

1

i.e.,

gy(cid:96)1 = gy((cid:96)1−h1s) · gyh(cid:48)

1s.

Thus, both equations are fulﬁlled if h1 = h(cid:48)
the server used the correct twin key s.

1 implying that

1196Client C(csk , pk , T, t, m)

parse T = (T1, T2, T3)
r ←$ Zq
v := mr·csk

parse c := (c1, c2, c3)

Server S(sk )

−−−−−−−−−−−−−−−−−−−−−−−−→ y ←$ Zq; s ← Fk(t)

(T1, t, v)

parse sk := (x, k)

c = (c1, c2, c3) := (gy, gsy, gsxy · v)

T (cid:48) := (c, π1, π2)

←−−−−−−−−−−−−−−−−−−−−−−−−// Compute the proof of correctness

h

parse π1 := (z1, A1, B1), π2 := (z2, A2, B2)
1 ← H(T1, c1, A1, B1, T2, c2)
(cid:48)
2 ← H(T1, c1, A2, B2, T3/mcsk , c3/v)
(cid:48)
if A1 = T z1

h

1

1 T h(cid:48)
and A2 = T z2

1

2 and B1 = cz1
1 (T3/mcsk )h(cid:48)

1 ch(cid:48)
2 and B2 = cz2

2

1 (c3/v)h(cid:48)

2

then return accept
else return reject

Figure 2: The validation protocol.

(cid:96)1 ←$ Zq; A1 := T (cid:96)1
(cid:96)2 ←$ Zq; A2 := T (cid:96)2
h1 ← H(T1, gy, A1, B1, T s
h2 ← H(T1, gy, A2, B2, T sx
z1 := (cid:96)1 − h1s; z2 := (cid:96)2 − h2sx
π1 := (z1, A1, B1); π2 ← (z2, A2, B2)

1 ; B1 := gy(cid:96)1
1 ; B2 := gy(cid:96)2
1 , gsy)
1 , gsxy)

The second check determines whether the submitted mes-
sage is the same as the enrolled message in T . In detail, it
works as follows:

i.e., T (cid:96)2

1 = T (cid:96)2−h2sx

1

· T h(cid:48)

1

2sx

·

(cid:18) m(cid:48)

(cid:19)h(cid:48)

2

mcsk

2

·

(cid:18) T3
(cid:19)h(cid:48)
1 ·(cid:16) c3

mcsk

mr·csk

(cid:17)h(cid:48)

2

A2 =T z2
1

and

B2 =cz2

i.e., gy(cid:96)2 = gy((cid:96)2−h2sx) · gh(cid:48)

2ysx

The ﬁrst equation is fulﬁlled if m(cid:48) = m · csk , which is the
case for a correct enrollment of m, and the second equation is
fulﬁlled if the validation record was created using the correct
public key.

Key Rotation. Key Rotation in our construction consists
of one round of interaction where the server draws a fresh
random secret key x(cid:48) ←$ Zq and provides the client with an
update token δ = x(cid:48)/x where x is the old secret key. The
client updates each record T = (T1, T2, T3) of the database
by raising the third element of each record to the power of δ,
such that the new record is T (cid:48) = (T1, T2, T δ
3 ). Further, the
client updates the stored public key and the client secret:
pk(cid:48) = pk δ and csk(cid:48) = csk · δ.

We defer the proof of correctness of this key rotation

mechanism to the full version of this paper.
4.3 Proof of Security

In this section, we show that our construction is partially-
hiding, binding, and oblivious. We prove the stronger state-
ment that Construction 1 is secure with any perfectly sound
non-interactive zero knowledge (NIZK) proof system for
equality of discrete logarithms.
In our construction, this
NIZK is then instantiated with the Fiat-Shamir transformed
protocol of Chaum and Pedersen. More formally, we prove
the following theorem:
Theorem 1. If the DDH problem is hard in G, the non-
interactive proof system is zero-knowledge and perfectly
sound, and H is modeled as a random oracle, then Con-
struction 1 is partially hiding, binding, and oblivious.

Informally, the scheme is hiding, because the message m
is information-theoretically blinded with an exponent drawn
independently and uniformly at random for every interaction
with the server.
For binding, consider that a binding adversary has to ﬁnd a
“forgery” pair (t∗, m∗), which validates correctly for a record
enrolled from a diﬀerent pair. Such a forgery amounts to
ﬁnding a collision for the PRF on t and t∗, which cannot be
eﬃcient if F is pseudorandom.

Obliviousness is guaranteed under the DDH-assumption.
We use a game-hopping approach with a series of intermediate
experiments, where we ﬁrst replace every occurrence of the
PRF with a truly random function with negligible loss in
security since F is pseudorandom. Then, we can reduce the
indistinguishability of records for two diﬀering messages to
the DDH assumption. In the following, we give formal proofs
for each property.

Partial Hiding.

Consider the view of an adversary A in one of the partial
hiding experiments. In the ﬁrst phase of the game, the view
of A consists solely of its own outputs. In the second phase,
A engages in executions of the enrollment and validation
protocols. When A engages in an execution of the enrollment
protocol, it receives a tuple (t, v), where v = mr
b for some
uniformly random r ∈ Zq and t is some ﬁxed part of A’s
challenge output. When A engages in an execution of the
validation protocol, it receives a tuple (T1, t, v), where v = mr
for some uniformly random r ∈ Zq and t and T1 some ﬁxed
b
parts of A’s challenge output.

By construction t and T1 in all these executions are identi-
cal and independent of the message and thus independent
of b. Further, since the r in all protocol runs are chosen
independently and uniformly at random, all v seen by the
attacker are uniformly distributed elements of G and thus
independent of b.

We thus can conclude that the two games are perfectly

indistinguishable to an (even unbounded) attacker. I.e.,

(cid:12)(cid:12)Pr(cid:2)Hiding0

Π,A(1n) = 1(cid:3) − Pr(cid:2)Hiding1

Π,A(1n) = 1(cid:3)(cid:12)(cid:12) = 0,

and Construction 1 is thus perfectly partially-hiding.

1197Let A be an adversary, such that Pr(cid:2)BindingΠ,A(1n) = 1(cid:3) =

Binding.
. Let ((t0, m0), (t1, m1), T ) denote the output of A. Further
let y0 and y1 denote the random values chosen by server
in the validation protocol executions for t0, m0 and t1, m1
respectively.
We can split the probability of A succeeding into two cases,
namely depending on whether t0 = t1 or not. I.e., we have

Pr(cid:2)BindingΠ,A(1n) = 1(cid:3)
≤ Pr[t0 (cid:54)= t1 ] · Pr(cid:2)BindingΠ,A(1n) = 1(cid:12)(cid:12) t0 (cid:54)= t1
(cid:3)
+ Pr[t0 = t1 ] · Pr(cid:2)BindingΠ,A(1n) = 1(cid:12)(cid:12) t0 = t1

(cid:3)

(1)

Consider the case where t0 (cid:54)= t1. Let a be an element of
Zq such that T a
1 = T2, i.e., let a be the discrete logarithm of
T2 relative to base T1. Observe, that the ﬁrst zero-knowledge
proof in the validation protocol proves that gyba = gybFk(tb)
for b ∈ {0, 1}. Therefore, by the perfect soundness of the
NIZK, we have that Fk(t0) = a = Fk(t1). I.e., the adversary
has found a collision in the pseudorandom function. From
this we can construct a distinguisher D against the security
of the pseudorandom function as follows:
The distinguisher D gets as input the security parame-
ter and access to an oracle that is either the PRF with a
uniformly chosen key k or a uniformly random function. It
then samples a random exponent x ←$ Zq and invokes A on
input pk = gx. A may now invoke arbitrary enrollment and
validation protocol executions. To simulate these, D honestly
simulates the server as speciﬁed in the protocol, except that
it uses its oracle to compute the values s.
Eventually, A outputs ((t0, m0), (t1, m1), T ). If t0 = t1, the
distinguisher outputs a random bit b ←${0, 1}. Otherwise, it
queries t0 and t1 to its function oracle, receiving responses s0
and s1 respectively. If s0 = s1, then D outputs 1, otherwise
0.
We now analyze the advantage of D. Consider ﬁrst the
case where the function oracle is the PRF F . In this case, D
performs a perfect simulation of the binding challenger for
A. Hence, we get

(cid:104)DFk(·)(1n) = 1
+ Pr[t0 (cid:54)= t1 ] · Pr(cid:2)BindingΠ,A(1n) = 1(cid:12)(cid:12) t0 (cid:54)= t1

= Pr[t0 = t1 ] · 1
2

(cid:3) .

(cid:105)

Pr

Now consider the case where the function oracle is a truly
random function H. Since the adversary only makes a poly-
nomial number of queries, the probability that it was able
to ﬁnd a collision in a truly random function is negligible.
Hence, we get

= Pr[t0 = t1 ] · 1
2

(cid:104)DH(·)(1n) = 1
(cid:105)
(cid:12)(cid:12)(cid:12)Pr
(cid:104)AH(·)(1n) = 1
(cid:104)AFk(·)(1n) = 1
(cid:12)(cid:12)(cid:12)(cid:12) Pr[t0 (cid:54)= t1 ] · Pr(cid:2)BindingΠ,A(1n) = 1(cid:12)(cid:12) t0 (cid:54)= t1
=⇒ Pr[t0 (cid:54)= t1 ] · Pr(cid:2)BindingΠ,A(1n) = 1(cid:12)(cid:12) t0 (cid:54)= t1

− Pr[t0 (cid:54)= t1 ] · negl(n)

(cid:105) − Pr

=⇒

(cid:105)(cid:12)(cid:12)(cid:12) ≤ negl(n)
(cid:12)(cid:12)(cid:12)(cid:12) ≤ negl(n)
(cid:3)
(cid:3) ≤ negl(n)

(2)

Pr

We thus get

+ Pr[t0 (cid:54)= t1 ] · negl(n) .

Now consider the case where t0 = t1. Let a0, a1 be elements
of Zq such that T ab
, i.e., let ab be the discrete
logarithm of T3/mcsk
relative to base T1. Observe, that
the second zero knowledge proof in the validation protocol

1 = T3/mcsk

b

b

proves that gybab = gybsk Fk(tb) for b ∈ {0, 1}. Therefore,
by the perfect soundness of the NIZK, we have that ab =
sk Fk(tb), however, since t0 = t1, this implies a0 = a1 and –
by deﬁnition of ab – it thus follows that m0 = mb.
(t0, m0) (cid:54)= (t1, m1). Thus we can conclude that

if A outputs t0 = t1,

it never holds that

Therefore,

(cid:3) = 0

(3)

Pr[t0 = t1 ] · Pr(cid:2)BindingΠ,A(1n) = 1(cid:12)(cid:12) t0 = t1
Pr(cid:2)BindingΠ,A(1n) = 1(cid:3) ≤ negl(n)

and ﬁnally combining Equations (1) to (3), we get that

and Construction 1 is thus binding.

Obliviousness.

Let A be an adversary, such that

(cid:12)(cid:12)Obliv0

Π,A(1n) − Obliv1

Π,A(1n)(cid:12)(cid:12) = (n).

We will bound  using a series of games.

Game 1. The ﬁrst game is Obliv0

Π,A(1n).

Game 2. The second game behaves exactly like the ﬁrst
game, except that the values s are no longer chosen via a
PRF and are instead computed using a lazily sampled truly
random function.

Game 3. The third game behaves exactly like the second
game, except that all zero-knowledge proofs are now simu-
lated.

Game 4. The fourth game behaves exactly like the third
game, except that b = 1.

Game 5. The ﬁfth game behaves exactly like the fourth game,
except that zero-knowledge proofs are once again computed
honestly.

Game 6. The sixth game is Obliv1

Π,A(1n).

We will now bound the diﬀerence between each pair of
consecutive games.
Let |Pr[Game1(1n) = 1] − Pr[Game2(1n) = 1]| = δ1(n).
Consider the distinguisher D against the pseudorandomness
of F as follows: The distinguisher D gets as input the se-
curity parameter and access to an oracle that is either the
PRF with a uniformly chosen key k or a uniformly random
function. It then samples random elements z, x ←$ Zq and
invokes A1 on input (csk = z, pk = gx). A1 may now invoke
arbitrary enrollment and validation protocol executions. To
simulate these, D honestly simulates the server as speciﬁed
in the protocol, except that it uses its oracle to compute the
values s. Once A1 outputs (t, m0, m1, st), D once again hon-
estly computes T ←$(cid:104)C(csk , pk , t, mb),S(sk )(cid:105)enrl computing
s using its oracle. D then invokes A2 on st and T , simulating
the enrollment protocol executions as before. Eventually, A2
outputs a bit b(cid:48) and D outputs the same bit.
It should be clear, that if the function oracle is the PRF F ,
then D perfectly simulates Game1, while with a truly random
oracle, D provides a perfect simulation of Game2. Therefore,
by assumption that F is a pseudorandom function, we get
that

(cid:104)DFk(·)(1n) = 1

(cid:105) − Pr

(cid:104)DH(·)(1n) = 1

δ1(n) =

(cid:12)(cid:12)(cid:12)Pr

(cid:105)(cid:12)(cid:12)(cid:12) ≤ negl(n) .

1198(cid:104)

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) Pr

(cid:104)

(cid:105)

(cid:105) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) ≤ negl(n) .

Let |Pr[Game2(1n) = 1] − Pr[Game3(1n) = 1]| = δ2(n).
Consider the reduction B against the zero-knowledge prop-
erty of the NIZK. Let Sim = (Sim0, Sim1) be the simulator
of the non-interactive zero-knowledge proof system. The
reduction B gets as input the common reference string and
access to an oracle that is either the Prove algorithm, or the
simulator Sim(cid:48). It then samples random elements z, x ←$ Zq
and invokes A1 on input (csk = z, pk = gx). A1 may now
invoke arbitrary enrollment and validation protocol execu-
tions. To simulate these, B honestly simulates the server as
speciﬁed in the protocol, except that it computes s using
a lazily sampled truly random function and computes all
proofs π, π1 and π2 by querying statement and witness to the
oracle. Once, A1 outputs (t, m0, m1, st), B once again hon-
estly computes T ←$(cid:104)C(csk , pk , t, mb),S(sk )(cid:105)enrl computing
s using its lazily sampled truly random function and com-
puting π by querying its oracle. B then invokes A2 on st and
T , simulating the enrollment protocol executions as before.
Eventually A2 outputs a bit b(cid:48) and B outputs the same bit.
It should be clear, that if the oracle is the Prove algorithm,
then B perfectly simulates Game2. And if the oracle is in fact
the simulator, then B provides a perfect simulation of Game3.
Therefore, by assumption that the NIZK is zero knowledge,
we get that

δ2(n) =

σ ← ZKSetup(1n) : BProve(σ,·,·)(σ) = 1

− Pr

(σ, τ ) ← Sim0(1n) : BSim(cid:48)(σ,τ,·,·)(σ) = 1

Let |Pr[Game3(1n) = 1] − Pr[Game4(1n) = 1]| = δ3(n).
Consider the reduction D against the hardness of DDH. The
reduction D gets as input a tuple (G, g, A, B, C) that is ei-
ther a DDH tuple, or a random tuple. It draws a random
element z ←$ Zq and invokes A1 on input (csk = z, pk = B).
A1 may now invoke arbitrary enrollment and validation
protocol executions. In the protocol executions D follows
the description of Game3, except that c is computed as
(c1, c2, c3) := gy, gys, Bys·v. Once, A1 outputs (t, m0, m1, st),
D samples a bit b ←${0, 1} at random, computes the s for t
according to its lazily sampled random function, and com-
putes T = (T1, T2, T3) := (As−1
). D then invokes
A2 on st and T , simulating the enrollment protocol execu-
tions as before. Eventually A2 outputs a bit b(cid:48) and D outputs
1, if b = b(cid:48) and outputs a random bit otherwise.
Now consider the two cases. If (A, B, C) is a DDH tuple,
then D perfectly simulates Game3 if b = 0 and Game4 if b = 1.
It is easy to see that answers to the protocol invocations
are well formed. But also the challenge is well formed. To
see this, consider that we have (A, B, C) = (ga, gb, gab) and
therefore (gas−1
b ) is a well-formed enrollment
record for y = as−1, which is a uniform random element.
Therefore, Pra,b

(cid:2)D(G, g, ga, gb, gab) = 1(cid:3) = 1

, ga, gab · mcsk

, A, C · mcsk

b

2 + δ3.

Now consider the other case. If (A, B, C) is a random tuple,
then the challenge enrollment record contains no information
about the bit b, since mb is blinded by a uniformly distributed
element C. Therefore, Pra,b,c
2 ,
and thus by the DDH assumption in G,

(cid:2)D(G, g, ga, gb, gc) = 1(cid:3) = 1
(cid:2)D(G, g, ga, gb, gc) = 1(cid:3) (cid:12)(cid:12)(cid:12)(cid:12) ≤ negl(n) .
(cid:2)D(G, g, ga, gb, gab) = 1(cid:3)

(cid:12)(cid:12)(cid:12)(cid:12) Pra,b

− Pra,b,c

δ3(n) =

The ﬁfth game simply reverts the changes introduced in
game three and an almost identical reduction lets us bound
δ4 by the assumption that the NIZK is zero knowledge. Sim-
ilarly, it is easy to see that the sixth game simply reverts

the changes introduced in game two and an almost identical
reduction lets us bound δ5 by the assumption that F is a
pseudorandom function. Finally, we conclude that

(n) ≤ 5(cid:88)

δi(n) ≤ negl(n) ,

and Construction 1 is thus oblivious.

i=1

Secure Key Rotation.

We defer the proof of secure key rotation to the full version
of this paper for brevity. Intuitively, the proof follows from
the fact that each key rotation unconditionally hides the
previous key material unless the initial client state is known.
4.4 Password Authentication Using Our Con-

struction

In this section, we show how to build a password authenti-
cation system that enjoys all functional properties described
in Section 2.
Setup. The client and the PO-COM-Service run the setup
of the PO-COM protocol meaning that the client receives a
public key and unique client secret of the PO-COM protocol
and can now make enrollment and validation queries to the
PO-COM-Service.
Enrollment. The user provides her password and user-
name to the client. The client sets t = username and m =
password and makes an enrollment query for (t, m), storing
the resulting enrollment record T alongside t.
Password verification. If a user contacts the client pro-
viding a tentative password’ for a username, the client sets
(cid:48) and performs a
again t = username and m = password
validation query for the enrollment record stored for t and
(cid:48) was the correct
(t, m). If validation is successful, password
password for username.
Key Rotation. To perform key rotation, each client exe-
cutes the key rotation protocol with the server to obtain a
new public key and an updated unique client secret.
Stretching. Orthogonal to the functionality of our con-
struction, one could introduce an additional step of password
stretching on the client side by not enrolling the message
itself, but the result of a key derivation function such as
PBKDF2 [28] or Argon2 [7].
Intuitively this step could
further inhibit oﬄine-brute force attacks.

5. EVALUATION

We have implemented a prototype of our construction
using the Charm framework [1] for cryptographic prototyp-
ing and using NIST curve P-256 as the base group for our
construction. This group choice reﬂects a security level of
approximately 128 bits. The average runtime across 10,000
iteration of all the common group operations on our server
machine is given on the right side of Table 1.

The server is implemented as an HTTPS web service using
the falcon framework in Python and served via a standard
conﬁguration of the nginx web server.
Latency. Latency test were performed with an amazon web
services t2.micro instance on the client side and an amazon
web services c4.2xlarge instance on the server side. The client
instance has access to 1 CPU core (Intel Xeon) and 1 GB of

1199HTTP-Keepalive
Enrollment
Validation
Validation Failure
Pythia-Eval
Network RTT

Local

WAN

EC Operations(µs)

On
7.28
9.51
9.01
13.79

Oﬀ
11.70
13.80
13.47
17.24

On
24.54
21.56
23.96
34.25

Oﬀ
64.62
Sampling
56.8
67.00 Group op.
3.2
68.96 Mod. Exp.
191.1
76.91 Hash to G 65.4

0.338

6.656

Table 1: Average latency in milliseconds of diﬀerent
client requests for 1000 requests each and average
runtime in µs of diﬀerent group operations.

RAM. The server instance has access to 8 CPU cores (Intel
Xeon) and 15 GB of RAM.

For comparison purposes, we set up an instance of Pythia
using the code provided at [18] and ran performance mea-
surements using the same web server setup.

The results of the latency tests appear on the left side
of Table 1 and show client latency for LAN and WAN set-
tings as the average latency of 1000 client requests for an
enrollment or a validation request. We provide measurements
for HTTP-Keep-alive turned on and turned oﬀ.

In the WAN setting, which resembles a multi-tenant setup
as envisioned in [19], we can achieve latency which is at least
1.4 times lower than that of Pythia if HTTP-Keep-alive is
active. Given the additional overhead without HTTP-Keep-
alive we achieve a speedup by a factor of 1.1.

In the LAN setting, which is similar to most local enter-
prise networks, our implementation outperforms the Pythia
prototype with 1.4 times lower latency in the case of suc-
cessful validation and even better 1.9 times lower latency for
enrollment.

Throughput. We have used the automated HTTP web
server load testing tool autobench to perform throughput
testing for our test setup. We use a static web page served
using the same web server as the baseline comparison for
throughput measurements of all the protocol operations the
web service oﬀers For the static web page, the maximum
connection rate is at 6050 connections per second (cps), pa-
rameter retrieval is similarly high at 6000 cps. For validation
queries, the reply rate levels oﬀ at around 1100 cps while
enrollment can withstand request rates up to 1900 cps.

Storage. We used our setup to test the typical storage
requirements of our password-authentication scheme both
on client side and server side. To this end, we performed
100,000 enrollment queries for randomly chosen tweaks and
passwords to generate 100,000 enrollment records on the
client side and 100,000 time-stamped tweaks on the server
side. On both sides, the information is stored in an indexed
mongoDB instance.
Server-side storage For rate-limiting purposes, the server
stores a 32-byte hash of any tweak which is queried
together with a 32-byte timestamp. The average size
of one such entry in the database is 83 bytes, with the
additional overhead resulting from the database index
structure.

Client-side storage On the client side, the enrollment re-
cords are stored together with a 32-byte hash of the
given tweak. The average size of one database entry
is approximately 444 bytes bringing the total size of
our record database of 100,000 successful enrollments
to a mere 43MB. Extrapolating linearly suggests that

a database of 20 million enrollment records could ﬁt
within 8.5GB of memory.

6. REVISITING PO-PRFS

Partially oblivious pseudorandom functions (PO-PRFs)
allow the computation of pseudorandom function values in a
protocol between two parties, such that one party holds the
function key and the other party holds the function inputs.
After the execution of the protocol, the party which has
provided the inputs learns the function output. Furthermore,
the evaluation is (partially) oblivious, meaning that the re-
spective inputs of both parties stay hidden to the other party,
except one part of the function inputs which is known to
both parties. The possibility to partially reveal the function
input separates the primitive from previous work on fully
oblivious PRFs [33, 24], where no information on the inputs
may be revealed.

In [19], the authors left open the question if the security
of their scheme can be based on weaker assumption. In this
section, we answer this question negatively.
6.1 Preliminaries
Partially Oblivious PRFs. We recall the formal deﬁnition
of partially oblivious pseudorandom functions given in [19].

Deﬁnition 6 (Partially Oblivious Pseudorandom Functions).
A partially oblivious PRF protocol (PO-PRF) is a tuple of
three algorithms (KeyGen, Client, Server) and a keyed function
fk : {0, 1}∗ × {0, 1}∗ → {0, 1}∗ which behave as follows:
KeyGen. The key generation algorithm outputs a public and
secret key pair (pk , sk ).

Server. The server algorithm takes as input the secret key
sk and a client request bit string. It outputs a response bit
string.

Client. The client algorithm takes as input a tweak t and a
message m. It can perform a single invocation of the server
algorithm before outputting a value x.

A PO-PRF protocol is said to be correct if for all security
parameters n and all key-pairs (pk , sk ) ←$ KeyGen(1n), the
protocol (cid:104)Client(t, m), Server(sk )(cid:105) always results in client-side
output fsk (t, m).

The primitive supports veriﬁability of outputs, i.e., the
client is able to verify the correctness of the server computa-
tion. Additionally the server does not learn the clients input
m. Leakage of the tweak t, however, is allowed.
One-More Unpredictability. We recall the formal se-
curity property of one-more unpredictability [19]. On a
high-level, one-more unpredictability says that an adversary
cannot predict the value of the function f associated with
the scheme on new inputs, except with negligible probability.
This is formalized in the following experiment.

Deﬁnition 7. A PO-PRF Π = (KeyGen, Client, Server) is
called one-more unpredictable if for any PPT adversary A
there exists a negligible function such that

Pr(cid:2)UnpredictabilityΠ,A(1n) = 1(cid:3) ≤ negl(n) ,

where the randomness is taken over the random coins of the
experiment and the adversary and the experiment is deﬁned
as follows:

1200UnpredictabilityΠ,A(1n)
(sk , pk ) ←$ KeyGen(1n); c ← 0
((t1, m1, T1), . . . , (tq, mq, Tq)) ←$ AO(·,·)(pk )
if q > c and Ti = fsk (ti, mi) for all i ∈ {1, . . . , q}

return 1

else return 0

where O(t, X) responds with Server(sk , t, X) and sets c ←
c + 1.

The authors also deﬁned a stronger property similar to
one-more unpredictability, but where the outputs must be
pseudorandom. Since we are interested in proving an im-
possibility result it is suﬃcient to only consider one-more
unpredictability as this property is strictly weaker and thus
our impossibility result is strictly stronger.

Hard Non-interactive Problem. We recall the deﬁnition
of a hard non-interactive problem following [22].

Deﬁnition 8 (Hard Non-interactive Problem). A non-interactive
problem P = (I, V ) consists of two eﬃcient algorithms:

Instance Generation I(1n). The instance generation algo-
rithm takes as input the security parameter 1n and outputs
an instance x.

Instance Verification V (x, y). The instance veriﬁcation
algorithm takes as input a value y as well as an instance x
of a cryptographic problem, and outputs a decision bit.

We say that a problem is hard if for any PPT algorithm
A, the probability that A solves the problem, i.e. on input
x ←$ I(1n) outputs y such that with overwhelming probabil-
ity V (x, y) = 1 is negligible.
6.2 The Pythia Protocol

In this section, we recall Pythia, the PO-PRF protocol
given in [19]. We consider the deﬁnition of one-more un-
predictability and show that there cannot be a black-box
reduction of this property to any non-interactive assumption.
To prove this formally, we use meta-reduction techniques as
put forward in e.g., [35, 8, 22]. Meta-reduction techniques
can be seen as building a “reduction against the reduction”.
Before showing our meta-reduction and explaining the main
ideas, we recall the basics of bilinear maps and the PO-PRF
from [19].
Bilinear Setting. Let G1, G2, GT be groups of order q
and let g1 ∈ G1, g2 ∈ G2 be generators, such that there is
a bilinear map e : G1 × G2 → GT and it holds e(gα
2 ) =
e(g1, g2)α·β for all α, β ∈ Zq. Furthermore, e is non-degenerate
meaning that e(g1, g2) (cid:54)= 1 and e(g1, g2) is a generator of GT .
The Pythia PO-PRF. To describe the Pythia PO-PRF, we
ﬁrst recall the underlying language to verify the computations
of the server. Let LPythia describe the following language of
valid server responses:

1 , gβ

LPythia = {(g, h, x, y) | ∃sk .gsk = h ∧ xsk = y}.

Based on this language, we describe the Pythia protocol.
Construction 2 (Pythia). Let H1 : {0, 1}∗ → G1, H2 :
{0, 1}∗ → G2 be hash functions modeled as random oracles,
with G1, G2 groups as described in the bilinear setting above

and let P = (P, V) be a non-interactive zero-knowledge proof
system for LPythia.
Setup(1n). picks a random exponent sk ←$ Zq and computes
a public key pk = gsk
1 . The secret key sk is sent to the server,
the public key to the client.
Client(pk , t, m). picks a random r ←$ Zq and sends (t, H2(m)r)
to the server. Upon response (y, π) from the server, the client
veriﬁes the proof π and if it is valid, outputs y1/r.

Server(sk , t, x). computes ˆx = e(H1(t), x) and y = ˆxsk as well
as π ←$ P((g1, pk , ˆx, y), sk). It sends (y, π) back to the client.
6.3 Impossibility Result

Our meta-reduction is similar to [22] and it shows that
there does not exists (using black-box techniques) a reduction
of the unpredictability of the protocol to any non-interactive
problem. Note that the result from [22] applies to blind
signature schemes and not to partially oblivious PRFs. For
clarity and succinctness, we show the impossibility result
for a version of the protocol which omits the non-interactive
zero-knowledge proofs. However, the result also holds for the
veriﬁable version presented above.

To show that no reduction to a non-interactive problem
exists, we introduce a magic adversary, which has access
to a computationally unbounded oracle Σ which allows the
adversary to break the scheme. A reduction R using the
magic adversary, could therefore solve the non-interactive
problem. This alone does not lead to a contradiction, since
the magic adversary has access to an unbounded oracle and
can thus not be considered eﬃcient. However, in our proof we
show that this adversary can be simulated eﬃciently, proving
that there cannot be an eﬃcient reduction if the problem is
indeed computationally diﬃcult.

We construct the simulation of the adversary, the so-called
meta-reduction M , in the same way as [22], by resetting the
execution of the reduction at an appropriate point and thus
fooling the reduction with the result of computations that
have occurred before the reset.

Let Σ be an unbounded DLOG oracle such that on input

two group elements (g, h), Σ returns x, such that gx = h.

The magic adversary uses Σ to generate a valid output of
the protocol by extracting the secret key from the public key
and performing all computations locally.

Deﬁnition 9 (Magic Adversary). The magic adversary is
deﬁned as follows: Choose messages m0, m1 ←${0, 1}∗ and
tweak t ←${0, 1}∗ as well as randomness r ←${0, 1}∗. Upon
input pk from the challenger, compute x = H2(m0)r and
send it along with tweak t to the challenger to obtain response
y. Now invoke Σ(g, pk ) to obtain the secret key sk . Finally,
compute z1 = e(t, H2(m1))sk and z0 = y1/r and output
(m0, z0) , (m1, z1).

Now for the main result.

Theorem 2. The unpredictability of Pythia cannot be
reduced to a non-interactive problem.

Proof. Assume R was a reduction of the unpredictability of
Pythia to some non-interactive problem P = (I, V ).

Upon input a problem instance x, the meta-reduction
M forwards x to R to receive a public key pk generated
by R. M draws uniformly and independently at random

1201a tweak t ←${0, 1}∗, two messages m0, m1 ←${0, 1}∗ and
r0, r1 ←${0, 1}∗.

M executes one run of the protocol, behaving like an honest
user instance C(t, m0) started on randomness r0 by sending
(t, H2(m0)r0 ) to R. It saves the result y0 output by R.

Next, M resets R to the point where R had just output

the public key pk .

M again executes a run of the protocol, emulating C(t, m1)

on randomness r1 by sending (t, H2(m1)r1 ) to R.

0

1

), (t, m1, y1/r1

Upon receiving the result y1 of this run, the meta-reduction
sends (t, m0, y1/r0
) to the reduction. When R
outputs a tentative problem solution y(cid:48), M also outputs y(cid:48).
Assuming the reduction always let’s the adversary compute
a valid output on the ﬁrst run, the pairs (m0, z0), (m1, z0)
output by the magic adversary and by the meta-reduction
are distributed identically. To see this, observe that m0
and m1 are chosen independently in both cases, so their
respective results z0 and z1 are also independent and we can
consider the distributions of (m0, z0) and (m1, z1) separately
in both cases. Furthermore, the transcripts resulting from
m0 and m1 respectively are independent of the messages and
uniformly distributed because the blinding is unconditional.
For (m0, z0) note, that in both cases z0 is the result of a
valid run of the protocol, so the pair is identically distributed
for the magic adversary case and the meta-reduction case.

To obtain (m1, z1), the meta-reduction executes an honest
run of the protocol, while the magic adversary does not use
the protocol, but uses Σ to perform all computations locally.
This does not aﬀect the distribution of the result, as it is
the same as if the protocol had run with input t, m1 and
the reduction as server. Thus the distributions are again the
same. It follows that
) = 1 | y

(x)] = Pr[V (x, y

) = 1 | y

Pr[V (x, y

(cid:48)

(cid:48)

(cid:48) ←$ R

AΣ

(cid:48) ←$ RM (x)].

As our eﬃcient meta-reduction can solve P by running
R locally, we have shown, that the existence of R is in
contradiction of the hardness of P .
7. ACKNOWLEDGEMENTS

We thank the anonymous reviewers for their valuable feed-
back. This work was supported by the German Federal
Ministry of Education and Research (BMBF) through fund-
ing for the Center for IT-Security, Privacy and Accountability
(CISPA) (FKZ: 16KIS0345) and for the project PROMISE.
Moreover, it was supported by the German Research Foun-
dation (DFG) via the collaborative research center “Methods
and Tools for Understanding and Controlling Privacy” (SFB
1223).
8. REFERENCES
[1] J. A. Akinyele, C. Garman, I. Miers, M. W. Pagano,
M. Rushanan, M. Green, and A. D. Rubin. Charm: a
framework for rapidly prototyping cryptosystems.
Journal of Cryptographic Engineering, 3(2):111–128,
2013.

[2] F. Armknecht and J. Furukawa. On the minimum

communication eﬀort for secure group key exchange. In
A. Biryukov, G. Gong, and D. R. Stinson, editors, SAC
2010, volume 6544 of LNCS, pages 320–337, Waterloo,
Ontario, Canada, Aug. 12–13, 2011. Springer,
Heidelberg, Germany.

[3] A. Bagherzandi, S. Jarecki, N. Saxena, and Y. Lu.

Password-protected secret sharing. In Y. Chen,

G. Danezis, and V. Shmatikov, editors, ACM CCS 11,
pages 433–444, Chicago, Illinois, USA, Oct. 17–21,
2011. ACM Press.

[4] G. Barthe, E. Fagerholm, D. Fiore, J. Mitchell,

A. Scedrov, and B. Schmidt. Automated analysis of
cryptographic assumptions in generic group models. In
Advances in Cryptology–CRYPTO 2014, pages 95–112.
Springer, 2014.

[5] M. Belenkiy, M. Chase, M. Kohlweiss, and

A. Lysyanskaya. P-signatures and noninteractive
anonymous credentials. In R. Canetti, editor,
TCC 2008, volume 4948 of LNCS, pages 356–374, San
Francisco, CA, USA, Mar. 19–21, 2008. Springer,
Heidelberg, Germany.

[6] T. Berson, D. Dean, M. Franklin, D. Smetters, and
M. Spreitzer. Cryptography as a network service. In
Proceedings of the ISOC Network and Distributed
System Security Symposium (NDSS). Citeseer, 2001.

[7] A. Biryukov, D. Dinu, D. Khovratovich, and

S. Josefsson. The memory-hard Argon2 password hash
and proof-of-work function. Internet-Draft
draft-irtf-cfrg-argon2-00, Internet Engineering Task
Force, 2016. Work in Progress.

[8] D. Boneh and R. Venkatesan. Breaking RSA may not

be equivalent to factoring. In K. Nyberg, editor,
EUROCRYPT’98, volume 1403 of LNCS, pages 59–71,
Espoo, Finland, May 31 – June 4, 1998. Springer,
Heidelberg, Germany.

[9] D. Boneh and B. Waters. Constrained pseudorandom

functions and their applications. In K. Sako and
P. Sarkar, editors, ASIACRYPT 2013, Part II, volume
8270 of LNCS, pages 280–300, Bengalore, India,
Dec. 1–5, 2013. Springer, Heidelberg, Germany.

[10] E. Bresson, J. Monnerat, and D. Vergnaud. Separation
results on the “one-more” computational problems. In
T. Malkin, editor, CT-RSA 2008, volume 4964 of
LNCS, pages 71–87, San Francisco, CA, USA,
Apr. 7–11, 2008. Springer, Heidelberg, Germany.

[11] D. R. L. Brown. Irreducibility to the one-more
evaluation problems: More may be less, 2007.
dbrown@certicom.com 13850 received 23 Nov 2007, last
revised 3 Dec 2007.

[12] H. Busch, S. Katzenbeisser, and P. Baecher. PUF-based
authentication protocols - revisited. In H. Y. Youm and
M. Yung, editors, WISA 09, volume 5932 of LNCS,
pages 296–308, Busan, Korea, Aug. 25–27, 2009.
Springer, Heidelberg, Germany.

[13] J. Camenisch, S. Hohenberger, M. Kohlweiss,

A. Lysyanskaya, and M. Meyerovich. How to win the
clonewars: Eﬃcient periodic n-times anonymous
authentication. In A. Juels, R. N. Wright, and
S. Vimercati, editors, ACM CCS 06, pages 201–210,
Alexandria, Virginia, USA, Oct. 30 – Nov. 3, 2006.
ACM Press.

[14] D. Chaum. Blind signatures for untraceable payments.
In D. Chaum, R. L. Rivest, and A. T. Sherman, editors,
CRYPTO’82, pages 199–203, Santa Barbara, CA, USA,
1982. Plenum Press, New York, USA.

[15] D. Chaum and T. P. Pedersen. Wallet databases with

observers. In E. F. Brickell, editor, CRYPTO’92,
volume 740 of LNCS, pages 89–105, Santa Barbara, CA,
USA, Aug. 16–20, 1993. Springer, Heidelberg, Germany.

1202[16] M. Di Raimondo and R. Gennaro. Provably secure
threshold password-authenticated key exchange. In
E. Biham, editor, EUROCRYPT 2003, volume 2656 of
LNCS, pages 507–523, Warsaw, Poland, May 4–8, 2003.
Springer, Heidelberg, Germany.

[17] J. Engler, C. Karlof, E. Shi, and D. Song. Is it too late

for pake? indicators, 5(9):17, 2009.

[18] A. Everspaugh. Pythia server (prototype)

implementation. https://github.com/ace0/pythia, 2015.

[19] A. Everspaugh, R. Chaterjee, S. Scott, A. Juels, and

T. Ristenpart. The pythia prf service. In 24th USENIX
Security Symposium (USENIX Security 15), pages
547–562, Washington, D.C., 2015. USENIX
Association.

[20] A. Fiat and A. Shamir. How to prove yourself:

Practical solutions to identiﬁcation and signature
problems. In A. M. Odlyzko, editor, CRYPTO’86,
volume 263 of LNCS, pages 186–194, Santa Barbara,
CA, USA, Aug. 1987. Springer, Heidelberg, Germany.

[21] M. Fischlin and D. Schr¨oder. Security of blind

signatures under aborts. In S. Jarecki and G. Tsudik,
editors, PKC 2009, volume 5443 of LNCS, pages
297–316, Irvine, CA, USA, Mar. 18–20, 2009. Springer,
Heidelberg, Germany.

[22] M. Fischlin and D. Schr¨oder. On the impossibility of

three-move blind signature schemes. In H. Gilbert,
editor, EUROCRYPT 2010, volume 6110 of LNCS,
pages 197–215, French Riviera, May 30 – June 3, 2010.
Springer, Heidelberg, Germany.

[23] M. Fischlin and D. Schr¨oder. Security of blind

signatures under aborts and applications to adaptive
oblivious transfer. J. Mathematical Cryptology,
5(2):169–204, 2012.

[24] M. J. Freedman, Y. Ishai, B. Pinkas, and O. Reingold.
Keyword search and oblivious pseudorandom functions.
In J. Kilian, editor, TCC 2005, volume 3378 of LNCS,
pages 303–324, Cambridge, MA, USA, Feb. 10–12,
2005. Springer, Heidelberg, Germany.

conference on Computer & communications security,
pages 669–684. ACM, 2013.

[30] E. Kiltz, K. Pietrzak, D. Cash, A. Jain, and D. Venturi.

Eﬃcient authentication from hard learning problems.
In K. G. Paterson, editor, EUROCRYPT 2011, volume
6632 of LNCS, pages 7–26, Tallinn, Estonia,
May 15–19, 2011. Springer, Heidelberg, Germany.

[31] P. D. MacKenzie, T. Shrimpton, and M. Jakobsson.
Threshold password-authenticated key exchange. In
M. Yung, editor, CRYPTO 2002, volume 2442 of
LNCS, pages 385–400, Santa Barbara, CA, USA,
Aug. 18–22, 2002. Springer, Heidelberg, Germany.

[32] A. Muﬀet. Facebook: Password hashing and

authentication.
https://video.adm.ntnu.no/pres/54b660049af94, 2015.
Video.

[33] M. Naor and O. Reingold. Number-theoretic

constructions of eﬃcient pseudo-random functions. In
38th FOCS, pages 458–467, Miami Beach, Florida,
Oct. 19–22, 1997. IEEE Computer Society Press.

[34] T. Okamoto. Eﬃcient blind and partially blind

signatures without random oracles. In S. Halevi and
T. Rabin, editors, TCC 2006, volume 3876 of LNCS,
pages 80–99, New York, NY, USA, Mar. 4–7, 2006.
Springer, Heidelberg, Germany.

[35] P. Paillier and D. Vergnaud. Discrete-log-based

signatures may not be equivalent to discrete log. In
B. K. Roy, editor, ASIACRYPT 2005, volume 3788 of
LNCS, pages 1–20, Chennai, India, Dec. 4–8, 2005.
Springer, Heidelberg, Germany.

[36] T. P. Pedersen. Non-interactive and

information-theoretic secure veriﬁable secret sharing. In
J. Feigenbaum, editor, CRYPTO’91, volume 576 of
LNCS, pages 129–140, Santa Barbara, CA, USA,
Aug. 11–15, 1992. Springer, Heidelberg, Germany.

[37] D. Pointcheval and J. Stern. Security arguments for

digital signatures and blind signatures. Journal of
Cryptology, 13(3):361–396, 2000.

[25] A. Herzberg and R. Margulies. Forcing johnny to login

[38] P. Robinson. Cryptography as a service.

safely - long-term user study of forcing and training
login mechanisms. In V. Atluri and C. D´ıaz, editors,
ESORICS 2011, volume 6879 of LNCS, pages 452–471,
Leuven, Belgium, Sept. 12–14, 2011. Springer,
Heidelberg, Germany.

[26] S. Jarecki, A. Kiayias, and H. Krawczyk.

Round-optimal password-protected secret sharing and
t-pake in the password-only model. In P. Sarkar and
T. Iwata, editors, Advances in Cryptology –
ASIACRYPT 2014, volume 8874 of Lecture Notes in
Computer Science, pages 233–253. Springer Berlin
Heidelberg, 2014.

[27] A. Juels, M. Luby, and R. Ostrovsky. Security of blind
digital signatures (extended abstract). In B. S. Kaliski
Jr., editor, CRYPTO’97, volume 1294 of LNCS, pages
150–164, Santa Barbara, CA, USA, Aug. 17–21, 1997.
Springer, Heidelberg, Germany.

[28] B. Kaliski. PKCS #5: Password-Based Cryptography

Speciﬁcation Version 2.0. RFC 2898, RFC Editor,
September 2000.

[29] A. Kiayias, S. Papadopoulos, N. Triandopoulos, and

T. Zacharias. Delegatable pseudorandom functions and
applications. In Proceedings of the 2013 ACM SIGSAC

RSAConference Europe, 2013.

[39] R. Sakai, K. Ohgishi, and M. Kasahara. Cryptosystem

based on pairing, 2000.

[40] D. Schr¨oder and D. Unruh. Security of blind signatures

revisited. In M. Fischlin, J. Buchmann, and
M. Manulis, editors, PKC 2012, volume 7293 of LNCS,
pages 662–679, Darmstadt, Germany, May 21–23, 2012.
Springer, Heidelberg, Germany.

[41] D. Wagner and I. Goldberg. Proofs of security for the

Unix password hashing algorithm. In T. Okamoto,
editor, ASIACRYPT 2000, volume 1976 of LNCS,
pages 560–572, Kyoto, Japan, Dec. 3–7, 2000. Springer,
Heidelberg, Germany.

[42] Wikipedia. List of data breaches — wikipedia, the free
encyclopedia, 2016. [Online; accessed 14-August-2016].

1203