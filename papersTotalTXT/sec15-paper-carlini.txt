Control-Flow Bending: On the Effectiveness of 

Control-Flow Integrity

Nicolas Carlini, University of California, Berkeley; Antonio Barresi, ETH Zürich;  

Mathias Payer, Purdue University; David Wagner, University of California, Berkeley;  

Thomas R. Gross, ETH Zürich

https://www.usenix.org/conference/usenixsecurity15/technical-sessions/presentation/carlini

This paper is included in the Proceedings of the 24th USENIX Security SymposiumAugust 12–14, 2015 • Washington, D.C.ISBN 978-1-931971-232Open access to the Proceedings of  the 24th USENIX Security Symposium is sponsored by USENIXControl-Flow Bending:

On the Effectiveness of Control-Flow Integrity

Nicolas Carlini
UC Berkeley

Antonio Barresi

ETH Zurich

Mathias Payer

Purdue University

David Wagner
UC Berkeley

Thomas R. Gross

ETH Zurich

Abstract

Control-Flow Integrity (CFI) is a defense which pre-
vents control-ﬂow hijacking attacks. While recent re-
search has shown that coarse-grained CFI does not stop
attacks, ﬁne-grained CFI is believed to be secure.

We argue that assessing the effectiveness of practi-
cal CFI implementations is non-trivial and that common
evaluation metrics fail to do so. We then evaluate fully-
precise static CFI — the most restrictive CFI policy that
does not break functionality — and reveal limitations in
its security. Using a generalization of non-control-data
attacks which we call Control-Flow Bending (CFB), we
show how an attacker can leverage a memory corruption
vulnerability to achieve Turing-complete computation on
memory using just calls to the standard library. We use
this attack technique to evaluate fully-precise static CFI
on six real binaries and show that in ﬁve out of six cases,
powerful attacks are still possible. Our results suggest
that CFI may not be a reliable defense against memory
corruption vulnerabilities.

We further evaluate shadow stacks in combination
with CFI and ﬁnd that their presence for security is nec-
essary: deploying shadow stacks removes arbitrary code
execution capabilities of attackers in three of six cases.

1

Introduction

Attacking software systems by exploiting memory-
corruption vulnerabilities is one of the most common
attack methods today according to the list of Common
Vulnerabilities and Exposures. To counter these threats,
several hardening techniques have been widely adopted,
including ASLR [29], DEP [38], and stack canaries [10].
Each has limitations: stack canaries protect only against
contiguous overwrites of the stack, DEP protects against
code injection but not against code reuse, and ASLR does
not protect against information leakage.

We classify defense mechanisms into two broad cat-
egories: prevent-the-corruption and prevent-the-exploit.

Defenses that prevent the corruption stop the actual
memory corruption before it can do any harm to the pro-
gram (i.e., no attacker-controlled values are ever used
out-of-context). Examples for prevent-the-corruption
defenses are SoftBound [22], Data-Flow Integrity [6],
or Code-Pointer Integrity [18].
In contrast, prevent-
the-exploit defenses allow memory corruption to occur
but protect the application from subsequent exploitation;
they try to survive or tolerate adversarial corruption of
memory. Examples for prevent-the-exploit defenses are
DEP [38] or stack canaries [10].

Control-Flow Integrity (CFI) [1, 3, 12, 15, 27, 30, 31,
39, 41–44] is a promising stateless prevent-the-exploit
defense mechanism that aims for complete protection
against control-ﬂow hijacking attacks under a threat
model with a powerful attacker that can read and write
into the process’s address space. CFI ensures that pro-
gram execution follows a valid path through the static
Control-Flow Graph (CFG). Any deviation from the
CFG is a CFI violation, terminating the application. CFI
is not speciﬁc to any particular exploitation vector for
control-ﬂow hijacking. Rather, it enforces its policy on
all indirect branch instructions. Therefore any attempt by
an attacker to alter the control-ﬂow in an invalid manner
will be detected, regardless of how the attacker changes
the target of the control-ﬂow transfer instruction.

CFI is often coupled with a protected shadow stack,
which ensures that each return statement matches the
corresponding call and thereby prevents an attacker from
tampering with return addresses. While the foundational
work [1, 15] included a shadow stack as part of CFI,
some more recent research has explored variants of CFI
that omit the shadow stack for better performance [9].
Whereas conformance to the CFG is a stateless policy,
shadow stacks are inherently dynamic and are more pre-
cise than any static policy can be with respect to returns.
Many prior attacks on CFI have focused on attacking a
weak or suboptimal implementation of CFI. Our focus is
on evaluating the effectiveness of CFI in its best achiev-

USENIX Association  

24th USENIX Security Symposium  161

able form, instead of artifacts of some (possibly weak)
CFI implementation. We deﬁne fully-precise static CFI
as the best achievable CFI policy as follows: a branch
from one instruction to another is allowed if and only
if some benign execution makes that same control-ﬂow
transfer. Such a policy could be imagined as taking any
CFG over-approximation and removing edges until re-
moving additional edges would break functionality.

Thus, fully-precise static CFI is the most restrictive
stateless CFI policy that still allows the program to run as
intended. Both coarse-grained and ﬁne-grained CFI are
less precise than fully-precise static CFI, because they
both over-approximate the set of valid targets for each
indirect transfer (though to a different degree). In con-
trast, fully-precise static CFI involves no approximation
by deﬁnition. We acknowledge that fully-precise static
CFI might be stricter than anything that can be prac-
tically implemented, but this makes any attacks all the
more meaningful: our results help us understand funda-
mental limits on the effectiveness of the strongest possi-
ble CFI policy.

Through several methods of evaluation, we argue that
fully-precise static CFI is neither completely broken (as
most coarse-grained defenses are) nor totally secure. We
explore what CFI can and cannot prevent, and hope that
this will stimulate a broader discussion about ways to fur-
ther strengthen CFI.

We evaluate the security of fully-precise static CFI
both with and without shadow stacks. Recent research
achieves better performance by omitting the shadow
stack in favor of a static policy on return statements. We
still call it fully-precise static CFI when we have added
a shadow stack, because the shadow stack is orthogonal.
This does not change the fact that the CFI policy is static.
CFI works by preventing an attacker from deviating
from the control-ﬂow graph. Our attacks do not involve
breaking the CFI mechanism itself: we even assume the
mechanism is implemented perfectly to its fullest extent.
Rather, our analysis demonstrates that an attacker can
still create exploits for most real applications, without
causing execution to deviate from the control-ﬂow graph.

This paper provides the following contributions:

1. formalization and evaluation of a space of different

kinds of CFI schemes;

2. new attacks on fully-precise static CFI, which reveal

fundamental limits on the effectiveness of CFI;

3. evidence that existing metrics for CFI security are

ineffective;

4. evidence that CFI without a shadow stack is broken;
5. widely applicable Turing-complete attacks on CFI

with shadow stacks; and,

6. practical case studies of the security of fully-precise

static CFI for several existing applications.

2 Background and software attacks

Over the past few decades, one of the most common at-
tack vectors has been exploitation of memory corruption
within programs written in memory-unsafe languages.In
response, operating systems and compilers have started
to support countermeasures against speciﬁc exploitation
vectors and vulnerability types, but current hardening
techniques are still unable to stop all attacks. We brieﬂy
provide an overview of these attacks; more information
may be found elsewhere [37].

2.1 Control-Flow Hijacking
One way to exploit a memory corruption bug involves
hijacking control ﬂow to execute attacker-supplied or
already-existing code in an application’s address space.
These methods leverage the memory corruption bug to
change the target of an indirect branch instruction (ret,
jmp *, or call *). By doing so, an attacker can completely
control the next instructions to execute.

2.2 Code-Reuse Attacks
Data Execution Prevention (DEP) prevents executing
attacker-injected code. However, redirecting control-
ﬂow to already-existing executable code in memory re-
mains feasible. One technique, return-to-libc [25, 36],
reuses existing functions in the address space of the vul-
nerable process. Runtime libraries (such as libc) often
provide powerful functions, e.g., wrapper functions for
most system calls. One example is libc’s system()
function, which allows the attacker to execute shell com-
mands. Code-reuse attacks are possible when attacker-
needed code is already available in the address space of
a vulnerable process.

2.3 Return Oriented Programming
Return Oriented Programming (ROP) [25, 36] is a more
advanced form of code-reuse attack that lets the attacker
perform arbitrary computation solely by reusing existing
code. It relies upon short instruction sequences (called
“gadgets”) that end with an indirect branch instruction.
This allows them to be chained, so the attacker can
perform arbitrary computation by executing a carefully-
chosen sequence of gadgets. ROP can be generalized
to use indirect jump or call instructions instead of re-
turns [4, 7].

2.4 Non-Control-Data Attacks
A non-control-data attack [8] is an attack where a mem-
ory corruption vulnerability is used to corrupt only data,

162  24th USENIX Security Symposium 

USENIX Association

2

but not any code pointer. (A code pointer is a pointer
which refers to the code segment, for example, a re-
turn address or function pointer.) Depending on the
circumstances, these attacks can be as effective as ar-
bitrary code-execution attacks. For instance, corrupt-
ing the parameter to a sensitive function (e.g., libc’s
execve()) may allow an attacker to execute arbitrary
programs. An attacker may also be able to overwrite se-
curity conﬁguration values and disable security checks.
Non-control-data attacks are realistic threats and hard to
defend against, due to the fact that most defense mecha-
nisms focus on the protection of code pointers.

2.5 Control-Flow Bending

We introduce a generalization of non-control-data at-
tacks which we call Control-Flow Bending (CFB). While
non-control-data attacks do not directly modify any
control-ﬂow data (e.g., return addresses, indirect branch
targets), in control-ﬂow bending we allow these modi-
ﬁcations so long as the modiﬁed indirect branch target
is still in the valid set of addresses as deﬁned by the
CFI policy (or any other enforced control-ﬂow or code
pointer integrity protection). CFB allows an attacker to
bend the control-ﬂow of the application (compared to hi-
jacking it) but adheres to an imposed security policy.

We deﬁne a “data-only” attack as a non-control-data
attack where the entire execution trace is identical to
some feasible non-exploit execution trace. (An execution
trace is the ordered sequence of instructions which exe-
cute, and does not include the effects those instructions
have except with respect to control ﬂow.) While data-
only attacks may change the control ﬂow of an applica-
tion, the traces will still look legitimate, as the observed
trace can also occur during valid execution. In contrast,
CFB is more general: it refers to any attack where each
control-ﬂow transfer is within the valid CFG, but the ex-
ecution trace is not necessarily required to match some
valid non-exploit trace.

In general, defense mechanisms implement an abstract
machine and can only observe security violations accord-
ing to the restrictions of that machine, e.g., CFI enforces
that control ﬂow follows a ﬁnite state machine.

For example, an attacker who directly overwrites the
arguments to exec() is performing a data-only attack:
no control ﬂow has been changed. An attacker who over-
writes an is admin ﬂag half-way through processing a
request is performing a non-control-data attack: the data
that was overwritten is non-control-data, but it affects the
control-ﬂow of the program. An attacker who modiﬁes a
function pointer to point to a different (valid) call target
is mounting a CFB attack.

3 Threat model and attacker goals

Threat model. For this paper we assume a powerful
yet realistic threat model. We assume the attacker can
write arbitrarily to memory at one point in time during
the execution of the program. We assume the process
is running with non-executable data and non-writeable
code which is hardware enforced.

This threat model is a realistic generalization of mem-
ory corruption vulnerabilities: the vulnerability typically
gives the attacker some control over memory. In practice
there may be a set of speciﬁc constraints on what the at-
tacker can write where; however, this is not something
a defender can rely upon. To be a robust defense, CFI
mechanisms must be able to cope with arbitrary memory
corruptions, so in our threat model we allow the attacker
full control over memory once.

Limiting the memory corruption to a single point in
time does weaken the attacker. However, this makes our
attacks all the more meaningful.

Attacker goals. There are three kinds of outcomes an
attacker might seek, when exploiting a vulnerability:

1. Arbitrary code execution: The attacker can execute
arbitrary code and can invoke arbitrary system calls
with arbitrary parameters. In other words, the at-
tacker can exercise all permissions that the appli-
cation has. Code execution might involve injecting
new code or re-using already-existing code; from
the attacker’s perspective, there is no difference as
long as the effects are the same.

2. Conﬁned code execution: The attacker can exe-
cute arbitrary code within the application’s address
space, but cannot invoke arbitrary system calls. The
attacker might be able to invoke a limited set of sys-
tem calls (e.g., the ones the program would usually
execute, or just enough to send information back to
the attacker) but cannot exercise all of the applica-
tion’s permissions. Reading and leaking arbitrary
memory of the vulnerable program is still possible.

3. Information leakage: The attacker can read and leak

arbitrary values from memory.

Ideally, a CFI defense would prevent all three attacker
goals. The more it can prevent, the stronger the defense.

4 Deﬁnition of CFI ﬂavors

Control-Flow Integrity (CFI) [1, 15] adds a stateless
check before each indirect control-ﬂow transfer (indirect
jump/call, or function return) to ensure that the target lo-
cation is in a static set deﬁned by the control-ﬂow graph.

USENIX Association  

24th USENIX Security Symposium  163

3

4.1 Fully-Precise Static CFI
We deﬁne Fully-Precise Static CFI as follows: an in-
direct control-ﬂow transfer along some edge is allowed
only if there exists a non-malicious trace that follows that
edge. (An execution is not malicious if it exercises only
intended program behavior.)
In other words, consider
the most restrictive control-ﬂow graph that still allows all
feasible non-malicious executions, i.e., the CFG contains
an edge if and only if that edge is used by some benign
execution. Fully-precise static CFI then enforces that ex-
ecution follows this CFG. Thus, fully-precise static CFI
enforces the most precise (and most restrictive) policy
possible that does not break functionality.

We know of no way to implement fully-precise static
CFI: real implementations often use static analysis and
over-approximate the CFG and thus are not fully precise.
We do not design a better CFI scheme. The goal of our
work is to evaluate the strongest form of CFI that could
conceptually exist, and attempt to gain insight on its lim-
itations. This notion of fully-precise static CFI allows
us to transcend the recent arms race caused by defenders
proposing forms of CFI [9,28] and then attackers defeat-
ing them [5, 14, 16].

4.2 Practical CFI
Practical implementations of CFI are always limited by
the precision of the CFG that can be obtained. Cur-
rent CFI implementations face two sources of over-
approximation. First, due to challenges in accurate static
analysis,
the set of allowed targets for each indirect
call instruction typically depends only upon the function
pointer type, and this set is often larger than necessary.

Second, most CFI mechanisms use a static points-to
analysis to deﬁne the set of allowed targets for each in-
direct control transfer. Due to imprecisions and lim-
itations of the analysis (e.g., aliasing in the case of
points-to analysis) several sets may be merged, leading
to an over-approximation of allowed targets for individ-
ual indirect control-ﬂow transfers. The degree of over-
approximation affects the precision and effectiveness of
practical CFI mechanisms.

Previous work has classiﬁed practical CFI defenses
into two categories: coarse-grained and ﬁne-grained. In-
tuitively, a defense is ﬁne-grained if it is a close approx-
imation of fully-precise static CFI and coarse-grained if
there are many unnecessary edges in the sets.

4.3 Stack integrity
The seminal work on CFI [1] combined two mecha-
nisms: restricting indirect control transfers to the CFG,
and a shadow call stack to restrict return instructions.

The shadow stack keeps track of the current functions
on the application call stack, storing the return instruc-
tion pointers in a separate region that the attacker cannot
access. Each return instruction is then instrumented so
that it can only return to the function that called it. For
compatibility with exceptions, practical implementations
often allow return instructions to return to any function
on the shadow stack, not just the one on the top of the
stack. As a result, when a protected shadow stack is
in use, the attacker has very limited inﬂuence over re-
turn instructions: all the attacker can do is unwind stack
frames. The attacker cannot cause return instructions to
return to arbitrary other locations (e.g., other call-sites)
in the code.

Unfortunately, a shadow stack does introduce perfor-
mance overhead, so some modern schemes have pro-
posed omitting the shadow stack [9]. We analyze both
the security of CFI with a shadow stack and CFI without
a shadow stack. We assume the shadow stack is protected
somehow and cannot be overwritten; we do not consider
attacks against the implementation of the shadow stack.

5 Evaluating practical CFI

While there has been considerable research on how to
make CFI more ﬁne-grained and efﬁcient, most CFI pub-
lications still lack a thorough security evaluation. In fact,
the security evaluation is often limited to coarse metrics
such as Average Indirect target Reduction (AIR) or gad-
get reduction. Evaluating the security effectiveness of
CFI this way does not answer how effective these poli-
cies are in preventing actual attacks.

In this section, we show that metrics such as AIR and
gadget reduction are not good indicators for the effec-
tiveness of a CFI policy, even for simple programs. We
discuss CFI effectiveness and why it is difﬁcult to mea-
sure with a single value and propose a simple test that
indicates if a CFI policy is trivially broken.

5.1 AIR and gadget reduction
The AIR metric [44] measures the relative reduction in
the average number of valid targets for all indirect branch
instructions that a CFI scheme provides: without CFI, an
indirect branch could target any instruction in the pro-
gram; CFI limits this to a set of valid targets. The gadget
reduction metric measures the relative reduction in the
number of gadgets that can be found at locations that are
valid targets for an indirect branch instruction.

These metrics measure how effectively a CFI imple-
mentation reduces the set of valid targets (or gadgets) for
indirect branch instructions, on average. However, they
fail to capture both (i) the target reduction of individual
locations (e.g., a scheme can have high AIR even if one

164  24th USENIX Security Symposium 

USENIX Association

4

branch instruction has a large set of surplus targets, if
the other locations are close to optimal) and (ii) the im-
portance and risk of the allowed control transfers. Simi-
larly, the gadget reduction metric does not weight targets
according to their usefulness to an attacker: every code
location or gadget is considered to be equally useful.

For example, consider an application with 10MB of
executable memory and an AIR of 99%. An attacker
would still have 1% of the executable memory at their
disposal — 100,000 potential targets — to perform code-
reuse attacks. A successful ROP attack requires only
a handful of gadgets within these potential targets, and
empirically, 100,000 targets is much more than is usu-
ally needed to ﬁnd those gadgets [35]. As this illustrates,
averages and metrics that are relative to the code size can
be misleading. What is relevant is the absolute number of
available gadgets and how useful they are to an attacker.

5.2 CFI security effectiveness
Unfortunately, it is not clear how to construct a sin-
gle metric that accurately measures the effectiveness of
CFI. Ideally, we would like to measure the ability of
CFI to stop an attacker from mounting a control-ﬂow hi-
jack attack. More speciﬁcally, a CFI effectiveness met-
ric should indicate whether control-ﬂow hijacking and
code-reuse attacks are still possible under a certain at-
tacker model or not, and if so, how much harder it is for
an attacker to perform a successful attack in the presence
of CFI. However, what counts as successful exploitation
of a software vulnerability depends on the goals of the
attacker (see Section 3) and is not easily captured by a
single number.

These observations suggest that assessing CFI effec-
tiveness is hard, especially if no assumptions are made
regarding what a successful attack is and what the binary
image of the vulnerable program looks like.

5.3 Basic exploitation test
We propose a Basic Exploitation Test (BET): a simple
test to quickly rule out some trivially broken implemen-
tations of CFI. Passing the BET is not a security guar-
antee, but failing the BET means that the CFI scheme is
insecure.

In particular, the BET involves selecting a minimal
program — a simple yet representative program that con-
tains a realistic vulnerability — and then determining
whether attacks are still possible if that minimal pro-
gram is protected by the CFI scheme under evaluation.
The minimal program should be chosen to use a subset
of common run-time libraries normally found in real ap-
plications, and constructed so it contains a vulnerability
that allows hijacking control ﬂow in a way that is seen

in real-life attacks. For instance, the minimal program
might allow an attacker to overwrite a return address or
the target of an indirect jump/call instruction.

The evaluator then applies the CFI scheme to the mini-
mal program, selects an attacker goal from Section 3, and
determines whether that goal is achievable on the pro-
tected program. If the attack is possible, the CFI scheme
fails the BET. We argue that if a CFI scheme is unable
to protect a minimal program it will also fail to protect
larger real-life applications, as larger programs afford the
attacker even more opportunities than are found in the
minimal program.

5.4 BET for coarse-grained CFI
We apply the BET to a representative coarse-grained CFI
policy. We show that the scheme is broken, even though
its AIR and gadget reduction metrics are high. This
demonstrates that AIR and gadget reduction numbers are
not reliable indicators for the security effectiveness of a
CFI scheme even for small programs. These results gen-
eralize the conclusion of recent work [5,14,16], by show-
ing that coarse-grained CFI schemes are broken even for
trivially small real-life applications.

Minimal program and attacker goals. Our mini-
mal vulnerable program is shown in Figure 1.
It is
written in C, compiled with gcc version 4.6.3 under
Ubuntu LTS 12.04 for x86 32-bit, and dynamically
linked against ld-linux and libc. The program con-
tains a stack-based buffer overﬂow. A vulnerability in
vulnFunc() allows an attacker to hijack the return tar-
get of vulnFunc() and a memory leak in memLeak()
allows the attacker to bypass stack canaries and ASLR.

Coarse-grained CFI policy. The coarse-grained CFI
policy we analyze is a more precise version of several
recently proposed static CFI schemes [43, 44]: each im-
plementation is less accurate than our combined version.
We use a similar combined static CFI policy as used in
recent work [14, 16].

Our coarse-grained CFI policy has three equivalence
classes, one for each indirect branch type. Returns and
indirect jumps can target any instruction following a call
instruction. Indirect calls can target any deﬁned symbol,
i.e., the potential start of any function. This policy is
overly strict, especially for indirect jumps; attacking a
stricter coarse-grained policy makes our results stronger.

Results. We see in Table 1 that our minimal program
linked against its libraries achieves high AIR and gad-
get reduction numbers for our coarse-grained CFI pol-
icy. However, as we will show, all attacker goals from
Section 3 can be achieved.

USENIX Association  

24th USENIX Security Symposium  165

5

# include < stdio .h >
# include < string .h >
# define STDIN 0

void memLeak () {

char buf [64];
int nr , i ;
u n s i g n e d int * value ;
value = ( u n s i g n e d int *) buf ;
scanf ( " % d " , & nr );
for ( i = 0; i < nr ; i ++)

printf ( " 0 x %08 x Š " , value [ i ]);

}

void v u l n F u n c () {

char buf [1024];
read ( STDIN , buf , 2048);

}

int main ( int argc , char * argv []) {

setbuf ( stdout , NULL );
printf ( " echo > Š " );
memLeak ();
printf ( " \ nread > Š " );
v u l n F u n c ();
printf ( " \ ndone .\ n " );
return 0;

}

G1 # arbitrary load (1/2)

f38ff:
f3900:
f3901:
f3902:

pop
pop
pop
ret

%edx
%ecx
%eax

G2 # arbitrary load (2/2)

412d2:
412d5:
412d7:
412d8:
412d9:
412da:

add
xor
pop
pop
pop
ret

$0x20,%esp
%eax,%eax
%ebx
%esi
%edi

G3 # arbitrary read
add
mov
ret

2ee25:
2ee2b:
2ee31:

G4 # arbitrary write

$0x1771cf,%ecx
0x54(%ecx),%eax

3fb11:
3fb12:
3fb18:
3fb1a:

pop
add
mov
ret

%ecx
$0xa,%ecx
%ecx,(%edx)

G5 # arbitrary call
mov
call

1b008:
1b00b:

%esi,(%esp)
*%edi

Figure 1: Our minimal vulnerable program that allows
hijacking a return instruction target.

Figure 2: Our call-site gadgets within libc.

AIR Gadget red.
0%
99.06%

98.86%

Targets Gadgets
128929
1462

0% 1850580
19611

No CFI
CFI

Table 1: Basic metrics for the minimal vulnerable pro-
gram under no CFI and our coarse-grained CFI policy.

We ﬁrst identiﬁed all gadgets that can be reached with-
out violating the given CFI policy. We found ﬁve gadgets
that allow us to implement all attacker goals as deﬁned
in Section 3. All ﬁve gadgets were within libc and be-
gan immediately following a call instruction. Two gad-
gets can be used to load a set of general purpose registers
from the attacker-controlled stack and then return. One
gadget implements an arbitrary memory write (“write-
what-where”) and then returns. Another gadget imple-
ments an arbitrary memory read and then returns. Fi-
nally, we found a ﬁfth gadget — a “call gadget” — that
ends with an indirect call through one of the attacker-
controlled registers, and thus can be used to perform ar-
bitrary calls. The ﬁve gadgets are shown in Figure 2. By
routing control-ﬂow through the ﬁrst four gadgets and
then to the call gadget, the attacker can call any function.
The attacker can use these gadgets to execute arbitrary
kernel vsyscall. In Linux
system calls by calling
systems (x86 32-bit), system calls are routed through
a virtual dynamic shared object
(linux-gate.so)
mapped into user space by the kernel at a random ad-
dress. The address is passed to the user space pro-

000 b8d60 < execve >:
...

b8d72 :
b8d77 :
b8d7d :
b8d81 :
b8d83 :
b8d88 :

call
add
mov
xchg
mov
call

...
$0xed27d ,% ebx
0 xc (% esp ) ,% edi
% ebx ,% edi
$0xb ,% eax
*% gs :0 x10

Figure 3: Disassembly of libc’s execve() function.
There is an instruction (0xb8d77) that can be returned
to by any return gadget under coarse-grained CFI.

cess. If the address is leaked, the attacker can execute
arbitrary system calls by calling
kernel vsyscall
using a call gadget.
Calls to
kernel vsyscall
are within the allowed call targets as libc itself calls

kernel vsyscall.
Alternatively, the attacker could call libc’s wrappers
for each speciﬁc system call. For example, the attacker
could call execve() within libc to execute the execve
system call. Interestingly, if the wrapper functions con-
tain calls, we can directly return to an instruction after
such a call and before the system call is issued. For an
example, see Figure 3: returning to 0xb8d77 allows us to
directly issue the system call without using the call gad-
get (we simply direct one of the other gadgets to return
there). There are some side effects on register ebx and
edi but it is straightforward to take them into account.

Arbitrary code execution is also possible. In the ab-
sence of CFI, an attacker might write new code some-
where into memory, call mprotect() to make that mem-
ory region executable, and then jump to that location

166  24th USENIX Security Symposium 

USENIX Association

6

USENIX Association  

24th USENIX Security Symposium  167

toexecutetheinjectedcode.CFIwillpreventthis,asthelocationoftheinjectedcodewillneverbeinoneofthetargetsets.Webypassthisprotectionbyusingmprotect()tomakealready-mappedcodewriteable.Theattackercanoverwritethesealready-availablecodepageswithmaliciouscodeandthentransfercontroltoitusingourcallgadget.Theresultisthattheattackercaninjectandexecutearbitrarycodeandinvokearbitrarysystemcallswitharbitraryparameters.Asanalternativemmap()couldalsobeusedtoallocatereadableandexe-cutablememory(ifnotprohibited).TheminimalprogramshowninFigure1containsavulnerabilitythatallowstheattackertooverwriteare-turnaddressonthestack.Wealsoanalyzedothermini-malprogramsthatallowtheattackertohijackanindirectjumporindirectcallinstruction,withsimilarresults.Weomitthedetailsoftheseanalysesforbrevity.AminimalvulnerableprogramforinitialindirectjumporindirectcallhijackingisfoundinAppendixA.Basedontheseresultsweconcludethatcoarse-grainedCFIpoliciesarenoteffectiveinprotectingevensmallandsimpleprograms,suchasourminimalvulnera-bleprogramexample.OuranalysisalsoshowsthatAIRandgadgetreductionmetricsfailtoindicatewhetheraCFIschemeiseffectiveatpreventingattacks;ifsuchat-tacksarepossibleonasmallprogram,thenattackswillbeeasieronlargerprogramswheretheabsolutenumberofvalidlocationsandgadgetsisevenhigher.6AttacksonFully-PreciseStaticCFIWenowturntoevaluatingfully-precisestaticCFI.RecallfromSection2.5thatwedeﬁnecontrol-ﬂowbendingasageneralizationofnon-control-dataattacks.Weexam-inethepotentialforcontrol-ﬂowbendingattacksonCFIschemeswithandwithoutashadowstack.6.1NecessityofashadowstackTobegin,wearguethatCFImusthaveashadowstacktobeastrongdefense.Withoutone,anattackercaneasilytraversetheCFGtoreachalmostanyprogramlocationdesiredandtherebybreaktheCFIscheme.Forastatic,statelesspolicylikefully-precisestaticCFIwithoutashadowstack,thebestpossiblepolicyforreturnsistoallowreturninstructionswithinafunctionFtotargetanyinstructionthatfollowsacalltoF.How-ever,forfunctionsthatarecalledoften,thissetcanbeverylarge.Forexample,thenumberofpossibletargetsforthereturnstatementsinmalloc()isimmense.Eventhoughdynamicallyonlyoneoftheseshouldbeallowedatanygiventime,astatelesspolicymustallowalloftheseedges.Figure4:Acontrol-ﬂowgraphwherethelackofashadowstackallowsanattackertomountacontrol-ﬂowbendingattack.ThisiselaboratedinFigure4.FunctionsAandCbothcontaincallstofunctionB.ThereturninfunctionBmustthereforebeabletotargettheinstructionfollowingbothofthesecalls.Innormalexecution,theprogramwillex-ecuteedge1followedbyedge2,oredge3followedbyedge4.However,anattackermaybeabletocauseedge3tobefollowedbyedge2,oredge1tobefollowedbyedge4.Inpracticethisisevenmoreproblematicwithtail-calloptimizations,whensignalhandlersareused,orwhentheprogramcallssetjmp/longjmp.Weignorethesecases.Thismakesourjobasanattackermoredifﬁcult,butwebaseourattacksonthefundamentalpropertiesofCFIinsteadofcornercaseswhichmightbehandledseparately.6.1.1DispatcherfunctionsForanattackertocauseafunctiontoreturntoadiffer-entlocationthanitwascalledfrom,shemustbeabletooverwritethereturnaddressonthestackafterthefunc-tioniscalledyetbeforeitreturns.Thisiseasytoarrangewhenthememorycorruptionvulnerabilityoccurswithinthatspeciﬁcfunction.However,oftenthevulnerabilityisfoundinuncommonlycalled(notwelltested)functions.Toachievemorepower,wemakeuseofdispatcherfunctions(analogoustodispatchergadgetsforJOP[4]).Adispatcherfunctionisonethatcanoverwriteitsownreturnaddresswhengivenargumentssuppliedbyanat-tacker.Ifwecanﬁndadispatcherfunctionthatwillbecalledlaterandusethevulnerabilitytocontrolitsargu-ments,wecanmakeitoverwriteitsownreturnaddress.Thisletsusreturntoanylocationwherethisfunctionwascalled.Anyfunctionthatcontainsa“write-what-where”primitivewhentheargumentsareundertheattacker’scontrolcanbeusedasadispatcherfunction.Alterna-tively,afunctionthatcanwritetoonlylimitedaddressescanstillworkaslongasthereturnaddressiswithinthelimits.Noteveryfunctionhasthisproperty,butasignif-icantfractionofallfunctionsdo.Forexample,assumewecontrolalloftheargumentstomemcpy().Wecan7168  24th USENIX Security Symposium 

USENIX Association

Figure5:Anexampleofloopinjection.Executionfol-lowscalledge3(cid:31),thenreturnsalongedge2(cid:31).pointthesourcebuffertoanattacker-controlledlocation,thetargetbuffertotheaddresswherememcpy()’sreturnaddresswillbefound,andsetthelengthtothewordsize.Then,whenmemcpy()isinvoked,memcpy()willoverwriteitsownreturnaddressandthenreturntosomeotherlocationinthecodechosenbytheattacker.IfthisotherlocationisinthevalidCFG(i.e.,itisaninstructionfollowingsomecalltomemcpy()),thenitisanallowededgeandCFIwillallowthereturn.Thus,memcpy()isasimpleexampleofadispatcherfunction.Wefoundmanydispatcherfunctionsinlibc,e.g.,1.memcpy()—Asdescribedabove.2.printf()—Usingthe“%n”formatspeciﬁer,theattackercanwriteanarbitraryvaluetoanarbitrarylocationandthuscauseprintf()tooverwriteitsownreturnaddress.3.strcat()—Similartomemcpy().Onlyworksiftheaddresstoreturntodoesnotcontainnullbytes.4.fputs()—Werelyonthefactthatwhenfputs()iscalled,charactersareﬁrsttemporarilybufferedtoalocationasspeciﬁedintheFILEargument.Anat-tackercanthereforespecifyaFILEwherethetem-porarybufferisplacedontopofthereturnaddress.MostfunctionsthattakeaFILEstructasanargu-mentcanbeusedinasimilarmanner.SimilarfunctionsalsoexistinWindowslibraries.Application-speciﬁcdispatcherfunctionscanbeusefulaswell,astheymaybecalledmoreoften.Anyfunctionthatcallsadispatcherfunctionisitselfadispatcherfunction:insteadofhavingthecalleeover-writeitsownaddress,itcanbeusedtooverwritethere-turnaddressofitscaller(orhigheronthecallchain).6.1.2LoopinjectionOnefurtherpotentialuseofdispatcherfunctionsisthattheycanbeusedtocreateloopsinthecontrol-ﬂowgraphwhennonewereintended,aprocesswhichwecallloopinjection.WecanusethistohelpusachieveTuring-completecomputationifwerequirealoop.Considerthecasewheretherearetwocallstothesamedispatcherfunction,wheretheattackercontrolsthear-gumentstothesecondcallanditispossibletoreachthesecondcallfromtheﬁrstthroughavalidCFGpath.Forexample,itiscommonforprogramstomakemulti-plesuccessivecallstoprintf().Ifthesecondcalltoprintf()allowsanattackertocontrolthearguments,thenthiscouldcauseapotentialloop.Thisisachievablebecausethesecondcalltoprintf()canreturntotheinstructionfollowingtheﬁrstcalltoprintf().Wecanthenreachthesecondcalltoprintf()fromthere(byassumption)andwehavecompletedtheloop.Figure5containsanexampleofthiscase.Undernor-malexecution,functionAwouldbeginbyexecutingtheﬁrstcalltofunctionBonedge1.FunctionBreturnsonedge2,afterwhichfunctionAcontinuesexecuting.ThesecondcalltofunctionBisthenexecuted,onedge3.Bthistimereturnsonedge4.NoticethatthereturninstructioninfunctionBhastwovalidoutgoingedges.AnattackercanmanipulatethistoinjectaloopwhenfunctionBisadispatcherfunction.TheattackerallowstheﬁrstcalltoBtoproceednormallyonedge1,re-turningonedge2.TheattackersetsupmemorysothatwhenBiscalledthesecondtime,thereturnwillfollowedge2insteadoftheusualedge4.Thatis,eventhoughthecodewasoriginallyintendedasstraight-lineexecu-tion,thereexistsaback-edgethatwillbeallowedbyanystatic,statelessCFIpolicywithoutashadowstack.Ashadowstackwouldblockthetransferalongedge2.6.2Turing-completecomputationCFIensuresthattheexecutionﬂowofaprogramstayswithinapredeﬁnedCFG.CFIimplicitlyassumesthattheattackermustdivertfromthisCFGforsuccessfulex-ploitation.WedemonstratethatanattackercanachieveTuring-completecomputationwhilefollowingtheCFG.ThisisnotdirectlyoneoftheattackergoalsoutlinedinSection3,howeveritisoftenausefulstepinachievingattacks[14].Speciﬁcally,weshowthatasinglecalltoprintf()allowsanattackertoperformTuring-completecomputa-tion,evenwhenprotectedwithashadowstack.Wedubthisprintf-orientedprogramming.Inourevaluation,wefounditwaspossibletomountthiskindofattackagainstallbutonebinary(whichrewrotetheirownlimitedver-sionofprintf).Ourattacktechniqueisnotspeciﬁctoprintf():wehaveconstructedasimilarattackusingfputs()whichiswidelyapplicablebutrequiresaloopobtainedinthecontrol-ﬂowgraph(vialoopinjectionorotherwise)tobe8Turing-complete. See Appendix C.

6.2.1 Printf-oriented programming
When we control the arguments to printf(), it is pos-
sible to obtain Turing-complete computation. We show
this formally in Appendix B by giving calls to printf()
which create logic gates. In this section, we give the intu-
ition behind our attacks by showing how an attacker can
conditionally write a value at a given location.

Assume address C contains a condition value, which is
an integer that is promised to be either zero or one. If the
value is one, then we wish to store the constant X at target
address T . That is, we wish to perform the computation
*T = *C ? X : *T. We show how this can be achieved
using one call to printf().

To do this, the attacker supplies the specially-crafted
format string “%s%hhnQ%*d%n” and passes arguments
(C,S,X − 2,0,T ), deﬁned as follows:
1. C — the address of the condition. While the “%s”
format speciﬁer expects a string, we pass a pointer
to the condition value, which is either the integer 0
or the integer 1. Because of the little-endian nature
of x86, the integer 1 contains the byte 0x01 in the
ﬁrst (low) byte and 0x00 in the second byte. This
means that when we print it as a string, if the condi-
tion value is 1 then exactly one byte will be written
out whereas if it is 0 then nothing will be be printed.
2. S — the address of the Q in the format string
(i.e., the address of the format string, plus 6). The
“%hhn” speciﬁer will write a single byte of output
consisting of the number of characters printed so
far, and will write it on top of the Q in the format
string. If we write a 0, the null byte, then the format
string will stop executing. If we write a 1, the for-
mat string will keep going. It is this action which
creates the conditional.

3. X − 2 — the constant we wish to store, minus two.
This speciﬁes the number of bytes to pad in the in-
teger which will be printed. It is the value we wish
to save minus two, because two bytes will have al-
ready been printed.

4. 0 — an integer to print. We do not care that we are

actually printing a 0, only the padding matters.

5. T — the target save location. At this point in time,
we have written exactly X bytes to the output, so
“%n” will write that value at the target address.

Observe that in this example, we have made use of a self-
modifying format string.

the case. We show using simple techniques it is possible
to achieve the same results without this control.

We ﬁrst deﬁne the destination of a printf() call ac-
cording to its type. The destination of an sprintf() call
is the address the ﬁrst argument points to (the destination
buffer). The destination of a fprintf() call is the ad-
dress of the temporary buffer in the FILE struct. The
destination of a plain printf() call is the destination
buffer of fprintf() when called with stdout.
Our attack requires three conditions to hold:
• the attacker controls the destination buffer;
• the format string passed to the call to printf() al-
• the attacker controls the argument to the format
speciﬁer as well as a few of the words further down
on the stack.

ready contains a “%s” speciﬁer; and,

We mount our attack by pointing the destination buffer
on top of the stack. We use the “%s” plus the controlled
argument to overwrite the pointer to the format string
(which is stored on the stack), replacing it with a pointer
to an attacker-controlled format string. We then skip
past any uncontrolled words on the stack with harmless
‘‘%x’’ speciﬁers. We can then use the remaining con-
trolled words to pivot the va_list pointer.

If we do not control any buffer on the stack, we can
obtain partial control of the stack by continuing our ar-
bitrary write with the %s speciﬁer to add arguments to
printf(). Note that this does not allow us to use null
bytes in arguments, which in 64-bit systems in particular
makes exploitation difﬁcult.

Implications

6.3
Our analysis of fully-precise static CFI, the strongest
imaginable static CFI policy, shows that preventing at-
tackers with partial control over memory from gain-
ing Turing-complete computation is almost impossible.
Run-time libraries and applications contain powerful
functions that are part of the valid CFG and can be used
by attackers to implement their malicious logic. Attack-
ers can use dispatcher functions to bend control ﬂow
within the valid CFG to reach these powerful functions.
Furthermore, we see that if an attacker can ﬁnd one of
these functions and control arguments to it, the attacker
will be able to both write to and read from arbitrary ad-
dresses at multiple points in time. Defenses which allow
attackers to control arguments to these functions must be
able to protect against this stronger threat model.

6.2.2 Practical printf-oriented programming
The previous section assumed that the attacker has con-
trol of the format string argument, which is usually not

7 Fully-Precise Static CFI Case Studies

We now look at some practical case studies to examine
how well fully-precise static CFI can defend against real-

USENIX Association  

24th USENIX Security Symposium  169

9

Binary

nginx
apache
smbclient
wireshark
xpdf
mysql

Arbitrary
write

yes
no
yes
yes
?
?

CFI without shadow stack

Info.
leakage

Conﬁned code
execution

Arbitrary code
execution

write
write
printf
printf
dispatcher
dispatcher

dispatcher
printf
printf
printf
printf
printf

dispatcher
dispatcher
printf
dispatcher
dispatcher
dispatcher

Arbitrary
write

yes
no
yes
yes
?
?

CFI with shadow stack

Info.
leakage

Conﬁned code
execution

write
write
printf
printf
write
write

no
write
printf
write
printf
printf

Arbitrary code
execution

no
write
printf
write
no
no

Table 2: The results of our evaluation of the 6 binaries. The 2nd and 6th columns indicate whether the vulnerability we
examined allows an attacker to control memory. The other columns indicate which attack goals would be achievable,
assuming the attacker controls memory. A “no” indicates that we were not able to achieve that attack goal; anything
else indicates it is achievable, and indicates the attack technique we used to achieve the goal. A “?” indicates we were
not able to reproduce the exploit.

life exploits on vulnerable programs, both with and with-
out a shadow stack. We split our evaluation into two
parts. First, we show that attackers can indeed obtain
arbitrary control over memory given actual vulnerabili-
ties. Second, we show that given a program where the
attacker controls memory at one point in time, it is pos-
sible to mount a control-ﬂow bending attack. Our results
are summarized in Table 2.

Our examples are all evaluated on a Debian 5 system
running the binaries in x86 64-bit mode. We chose 64-
bit mode because most modern systems are running as
64-bit, and attacks are more difﬁcult on 64-bit due to the
increased number of registers (data is loaded off of the
stack less often).

We do not implement fully-precise static CFI. Instead,
for each of our attacks, we manually verify that each
indirect control-ﬂow transfer is valid by checking that
the edge taken occurs during normal program execution.
Because of this, we do not need to handle dynamically
linked libraries specially: we manually check those too.

7.1 Control over memory
The threat model we deﬁned earlier allows the attacker
to control memory at a single point in time. We argue
that this level of control is achievable with most vulnera-
bilities, by analyzing four different binaries.

7.1.1 Nginx stack buffer overﬂow
We examined the vulnerability in CVE-2013-2028 [19]:
a signedness bug in the chunked decoding component of
nginx. We found it is possible to write arbitrary values
to arbitrary locations, even when nginx is protected by
fully-precise static CFI with a shadow stack, by modi-
fying internal data structures to perform a control-ﬂow
bending attack.

The vulnerability occurs when an attacker supplies a
large claimed buffer size, overﬂowing an integer and trig-

gering a stack-based buffer overﬂow. An attacker can
exploit this by redirecting control ﬂow down a path that
would never occur during normal execution. The Server
Side Includes (SSI) module contains a call to memcpy()
where all three arguments can be controlled by the at-
tacker. We can arrange memory so after memcpy() com-
pletes, the process will not crash and will continue ac-
cepting requests. This allows us to send multiple requests
and set memory to be exactly to the attacker’s choosing.
Under benign usage, this memcpy() method is called
during the parsing of a SSI ﬁle. The stack overﬂow al-
lows us to control the stack and overwrite the pointer to
the request state (which is passed on the stack) to point
to a forged request structure, constructed to contain a
partially-completed SSI structure. This lets us re-direct
control ﬂow to this memcpy() call. We are able to con-
trol its source and length arguments easily because they
point to data on the heap which we control. The desti-
nation buffer is not typically under our control: it is ob-
tained by the result of a call to nginx’s memory allocator.
However, we can cause the allocator to return a pointer
to an arbitrary location by controlling the internal data
structures of the memory allocator.

7.1.2 Apache off by one error
We examined an off-by-one vulnerability in Apache’s
handling of URL parameters [11]. We found that it is no
longer exploitable in practice, when Apache is protected
with CFI.

The speciﬁc error overwrites a single extra word on
the stack; however, this word is not under the attacker’s
control. Instead, the word is a pointer to a string on the
heap, and the string on the heap is under the attacker’s
control. This is a very contrived exploit, and it was not
exploitable on the majority of systems in the ﬁrst place
due to the word on the stack not containing any mean-
ingful data. However, on some systems the overwrit-
ten word contained a pointer to a data structure which

170  24th USENIX Security Symposium 

USENIX Association

10

contains function pointers. Later, one of these function
pointers would be invoked, allowing for a ROP attack.

When Apache is protected with CFI, the attacker is not
able to meaningfully modify the function pointers, and
therefore cannot actually gain anything. CFI is effective
in this instance because the attacker never obtains control
of the machine in the ﬁrst place.

7.1.3 Smbclient printf vulnerability

We examined a format string vulnerability in smb-
client [26]. Since we already fully control the format
string of a printf() statement, we can trivially control
all of memory with printf-oriented programming.

7.1.4 Wireshark stack buffer overﬂow

A vulnerability in Wireshark’s parsing of mpeg ﬁles al-
lows an attacker to supply a large packet and overﬂow a
stack buffer. We identify a method of creating a repeat-
able arbitrary write given this vulnerability even in the
presence of a shadow stack.

occurs

in

The

vulnerability

the
packet_list_dissect_and_cache_record function
where a ﬁxed-size buffer is created on the stack. An
attacker can use an integer overﬂow to create a buffer
of an arbitrary size larger than the allocated space. This
allows for a stack buffer overﬂow.

We achieve an arbitrary write even in the presence of
a shadow stack by identifying an arbitrary write in the
packet_list_change_record function. Normally,
this would not be good enough, as this only writes a
single memory location. However, an attacker can loop
this write due to the fact that the GTK library method
gtk_tree_view_column_cell_set_cell_data,
which is on the call stack, already contains a loop that
iterates an attacker-controllable number of times. These
two taken together give full control over memory.

7.1.5 Xpdf & Mysql

For two of our six case studies, we were unable to re-
produce the public exploit, and as such could not test if
memory writes are possible from the vulnerability.

7.2 Exploitation assuming memory control
We now demonstrate that an attacker who can control
memory at one point in time can achieve all three goals
listed in Section 3, including the ability to issue attacker-
desired system calls. (Our assumption is well-founded:
in the prior section we showed this is possible.) Prior
work has already shown that if arbitrary writes are possi-
ble (e.g., through a vulnerability) then data-only attacks

are realistic [8]. We show that control-ﬂow bending at-
tacks that are not data-only attacks are also possible.

7.2.1 Evaluation of nginx

Assuming the attacker can perform arbitrary writes, we
show that the attacker can read arbitrary ﬁles off of the
server and relay them to the client, read arbitrary mem-
ory out of the server, and execute an arbitrary program
with arbitrary arguments. The ﬁrst two attack goals can
be achieved even with a shadow stack; our third attack
only works if there is no shadow stack. Nginx is the only
binary which is not exploitable by printf-oriented pro-
gramming, because nginx rewrote their own version of
printf() and removed “%n”.

An attacker can read any ﬁle that nginx has access
to and cause their contents to be written to the out-
put socket, using a purely non-control-data attack. For
brevity, we do not describe this attack in detail: prior
work has described that these types of exploits are possi-
ble.

Our second attack can be thought of as a more
controlled version of the recent Heartbleed vulnerabil-
ity [21], allowing the attacker to read from an arbitrary
address and dump it to the attacker. The response han-
dling in nginx has two main phases. First, it handles the
header of the request and in the process initializes many
structs. Then, it parses and handles the body of the re-
quest, using these structs. Since the vulnerability in ng-
inx occurs during the parsing of the request body, we use
our control over memory to create a forged struct that
was not actually created during the initialization phase.
In particular, we initialize the postpone_filter mod-
ule data structure (which is not used under normal exe-
cution) with an internally-inconsistent state. This causes
the module to read data from an arbitrary address of an
arbitrary length and copy it to the response body.

Our ﬁnal attack allows us to invoke execve() with
arbitrary arguments, if fully-precise static CFI is used
without a shadow stack. We use memcpy() as a dis-
patcher function to return into ngx sprintf() and then
again into ngx exec new binary(), which later on
calls execve(). By controlling its arguments, the at-
tacker gets arbitrary code execution.

In contrast, when there is a shadow stack, we believe
it is impossible for an attacker to trigger invocation of
execve() due to privilege separation provided by fully-
precise static CFI. The master process spawns children
via execve(), but it is only ever called there — there is
no code path that leads to execve() from any code point
that is reachable within a child process. Thus, in this case
CFI effectively provides a form of privilege separation
for free, if used with a shadow stack.

USENIX Association  

24th USENIX Security Symposium  171

11

7.2.2 Evaluation of apache
On Apache the attacker can invoke execve() with ar-
bitrary arguments. Other attacks similar to those on ng-
inx are possible; we omit them for brevity. When there
is no shadow stack, we can run arbitrary code by using
strcat() as a dispatcher gadget to return to a function
which later invokes execve() under compilations which
link the Windows main method. When there is a shadow
stack, we found a loop that checks, for each module, if
the module needs to be executed for the current request.
By modifying the conditions on this loop we can cause
mod cgi to execute an arbitrary shell command under
any compilation. Observe that this attack involves over-
writing a function pointer, although to a valid target.

7.2.3 Evaluation of smbclient
Smbclient contains an interpreter that accepts commands
from the user and sends them to a Samba ﬁleserver. An
attacker who controls memory can drive the interpreter to
send any action she desired to the ﬁleserver. This allows
an attacker to perform any action on the Samba ﬁlesys-
tem that the user could. This program is a demonstration
that on some programs, CFI provides essentially no value
due to the expressiveness of the original application.

This is one of the most difﬁcult cases for CFI. The
only value CFI adds to a binary is restricting it to its
CFG: however, when the CFG is easy to traverse and
gives powerful functions, CFI adds no more value than
a system call ﬁlter.

7.2.4 Evaluation of wireshark
An attacker who controls memory can write to any ﬁle
that the current user has access to. This gives power
equivalent to arbitrary code execution by, for example,
overwriting the authorized keys ﬁle. This is possible
because wireshark can save traces, and an attacker who
controls memory can trivially overwrite the ﬁlename be-
ing written to with one the attacker picks.

If the attacker waits for the user to click save and sim-
ply overwrites the ﬁle argument, this would be a data-
only attack under our deﬁnitions. It is also possible to
use control-ﬂow bending to invoke file save as cb()
directly, by returning into the GTK library and overwrit-
ing a code pointer with the ﬁle save method, which is
within the CFG.

7.2.5 Evaluation of xpdf
Similar to wireshark, an attacker can use xpdf to write
to arbitrary ﬁles using memcpy() as a dispatcher gadget
when there is no shadow stack. When a shadow stack is
present, we are limited to a printf-oriented programming

attack and we can only write ﬁles with speciﬁc exten-
sions, which does not obviously give us ability to run
arbitrary code.

7.2.6 Evaluation of mysql
When no shadow stack is present, attacks are trivial.
A dispatcher gadget lets us return into do system(),
do exec(), or do perl() from within the mysql client.
(For this attack we assume a vulnerable client to connects
to a malicious server controlled by the attacker.) When a
shadow stack is present the attacker is more limited, but
we still can use printf-oriented programming to obtain
arbitrary computation on memory. We could not obtain
arbitrary execution with a shadow stack.

7.3 Combining attacks
As these six case studies indicate, control-ﬂow bending
is a realistic attack technique. In the ﬁve cases where CFI
does not immediately stop the exploit from occurring, as
it does for Apache, an attacker can use the vulnerabil-
ity to achieve arbitrary writes in memory. From here, it
is possible to mount traditional data-only attacks (e.g.,
by modifying conﬁguration data-structures). We showed
that using control-ﬂow bending techniques, more power-
ful attacks are possible. We believe this attack technique
is general and can be applied to other applications and
vulnerabilities.

8 Related work

Control-ﬂow integrity. Control-ﬂow integrity was orig-
inally proposed by Abadi et al. [1, 15] a decade ago.
Classical CFI instruments indirect branch target loca-
tions with equivalence-class numbers (encoded as a la-
bel in a side-effect free instruction) that are checked at
branch locations before taking the branch. Many other
CFI schemes have been proposed since then.

The most coarse-grained policies

(e.g., Native
Client [40] or PittSFIeld [20]) align valid targets to the
beginning of chunks. At branches, these CFI schemes
ensure that control-ﬂow is not transferred to unaligned
addresses. Fine-grained approaches use static analy-
sis of source code to construct more accurate CFGs
(e.g., WIT [2] and HyperSafe [39]). Recent work by
Niu et al. [27] added support for separate compilation
and dynamic loading. Binary-only CFI implementa-
tions are generally more coarse-grained: MoCFI [13] and
BinCFI [44] use static binary rewriting to instrument in-
direct branches with additional CFI checks.

CFI evaluation metrics. Others have attempted to cre-
ate methods to evaluate practical CFI implementations.
The Average Indirect target Reduction (AIR) [44] metric

172  24th USENIX Security Symposium 

USENIX Association

12

was proposed to measure how much on average the set of
indirect valid targets is reduced for a program under CFI.
We argue that this metric has limited utility, as even high
AIR values of 99% are insecure, allowing an attacker to
perform arbitrary computation and issue arbitrary system
calls. The gadget reduction metric is another way to eval-
uate CFI effectiveness [27], by measuring how much the
set of reachable gadgets is reduced overall. Gadget ﬁnder
tools like ROPgadget [34] or ropper [33] can be used to
estimate this metric.

CFI security evaluations. There has recently been a
signiﬁcant effort to analyze the security of speciﬁc CFI
schemes, both static and dynamic. G¨oktas¸ et al. [16] an-
alyzed the security of static coarse-grained CFI schemes
and found that the speciﬁc policy of requiring returns to
target call-preceded locations is insufﬁcient. Following
this work, prevent-the-exploit-style coarse-grained CFI
schemes with dynamic components that rely on runtime
heuristics were defeated [5, 14]. The attacks relied upon
the fact that the attacks could hide themselves from the
dynamic heuristics, and then reduced down to attacks on
coarse-grained CFI. Our evaluation of minimal programs
builds on these results by showing that coarse-grained
CFI schemes which have an AIR value of 99% are still
vulnerable to attacks on trivially small programs.

Non-control data attacks. Attacks that target only sen-
sitive data structures were categorized as pure data at-
tacks by Pincus and Baker [32]. Typically, these at-
tacks would overwrite application-speciﬁc sensitive vari-
ables (such as the “is authenticated” boolean which exists
within many applications). This was expanded by Chen
et al. [8] who demonstrated that non-control data attacks
are practical attacks on real programs. Our work general-
izes these attacks to allow modiﬁcations of control-ﬂow
data, but only in a way that follows the CFI policy.

Data-ﬂow integrity. Nearly as old of an idea as CFI,
Data-Flow Integrity (DFI) provides guarantees for the in-
tegrity of the data within a program [6]. Although the
original scheme used static analysis to compute an ap-
proximate data-ﬂow graph — what we would now call
a coarse-grained approach — more reﬁned DFI may be
able to protect against our attacks. We believe security
evaluation of prevent-the-corruption style defenses such
as DFI is an important future direction of research.

Type- and memory-safety. Other defenses have tried
to bring type-safety and memory-safety to unsafe lan-
guages like C and C++. SoftBound [22] is a compile-
time defense which enforces spatial safety in C, but at
a 67% performance overhead. CETS [23] extends this
work with a compile-time defense that enforces tempo-
ral safety in C, by protecting against memory manage-
ment errors. CCured [24] adds type-safe guarantees to
C by attempting to statically determine when errors can-
not occur, and dynamically adding checks when nothing

can be proven statically. Cyclone [17] takes a more rad-
ical approach and re-designs C to be type- and memory-
safe. Code-Pointer Integrity (CPI) [18] reduces the over-
head of SoftBound by only protecting code pointers.
While CPI protects the integrity of all indirect control-
ﬂow transfers, limited control-ﬂow bending attacks using
conditional jumps may be possible by using non-control-
data attacks. Evaluating control-ﬂow bending attacks on
CPI would be an interesting direction for future work.

9 Conclusion

Control-ﬂow integrity has historically been considered a
strong defense against control-ﬂow hijacking attacks and
ROP attacks, if implemented to its fullest extent. Our re-
sults indicate that this is not entirely the case, and that
control-ﬂow bending allows attackers to perform mean-
ingful attacks even against systems protected by fully-
precise static CFI. When no shadow stack is in place, dis-
patcher functions allow powerful attacks. Consequently,
CFI without return instruction integrity is not secure.
However, CFI with a shadow stack does still provide
value as a defense, if implemented correctly. It can sig-
niﬁcantly raise the bar for writing exploits by forcing at-
tackers to tailor their attacks to a particular application; it
limits an attacker to issue only system calls available to
the application; and it can make speciﬁc vulnerabilities
unexploitable under some circumstances.

Our work has several implications for design and de-
ployment of CFI schemes. First, shadow stacks appear
to be essential for the security of CFI. We also call for
adversarial analysis of new CFI schemes before they are
deployed, as our work indicates that many published CFI
schemes have signiﬁcant security weaknesses. Finally, to
make control-ﬂow bending attacks harder, deployed sys-
tems that use CFI should consider combining CFI with
other defenses, such as data integrity protection to en-
sure that data passed to powerful functions cannot be cor-
rupted in the presence of a memory safety violation.

More broadly, our work raises the question: just how
much security can prevent-the-exploit defenses (which
allow the vulnerability to be triggered and then try to pre-
vent exploitation) provide? In the case of CFI, we argue
the answer to this question is that it still provides some,
but not complete, security. Evaluating other prevent-the-
exploit schemes is an important area of future research.
We hope that the analyses in this paper help establish
a basis for better CFI security evaluations and defenses.

10 Acknowledgments

We would like to thank Jay Patel and Michael Theodor-
ides for assisting us with three of the case studies. We

USENIX Association  

24th USENIX Security Symposium  173

13

would also like to thank Scott A. Carr, Per Larsen, and
the anonymous reviewers for countless discussions, feed-
back, and suggestions on improving the paper. This
work was supported by NSF grant CNS-1513783, by the
AFOSR under MURI award FA9550-12-1-0040, and by
Intel through the ISTC for Secure Computing.

References
[1] ABADI, M., BUDIU, M., ERLINGSSON, U., AND LIGATTI, J.

Control-ﬂow integrity. In CCS’05 (2005).

[2] AKRITIDIS, P., CADAR, C., RAICIU, C., COSTA, M., AND
CASTRO, M. Preventing memory error exploits with WIT. In
IEEE S&P’08 (2008).

[3] BLETSCH, T., JIANG, X., AND FREEH, V. Mitigating code-

reuse attacks with control-ﬂow locking. In ACSAC’11 (2011).

[4] BLETSCH, T., JIANG, X., FREEH, V. W., AND LIANG, Z.
Jump-oriented programming: a new class of code-reuse attack.
In ASIACCS’11 (2011).

[5] CARLINI, N., AND WAGNER, D. ROP is still dangerous: Break-

ing modern defenses. In USENIX Security’14 (2014).

[6] CASTRO, M., COSTA, M., AND HARRIS, T. Securing software

by enforcing data-ﬂow integrity. In OSDI ’06 (2006).

[7] CHECKOWAY, S., DAVI, L., DMITRIENKO, A., SADEGHI, A.-
R., SHACHAM, H., AND WINANDY, M. Return-oriented pro-
gramming without returns. In CCS’10 (2010), pp. 559–572.

[8] CHEN, S., XU, J., SEZER, E. C., GAURIAR, P., AND IYER,
R. K. Non-control-data attacks are realistic threats. In USENIX
Security’05 (2005).

[9] CHENG, Y., ZHOU, Z., YU, M., DING, X., AND DENG,
R. H. ROPecker: A generic and practical approach for defending
against ROP attacks. In NDSS’14 (2014).

[10] COWAN, C., PU, C., MAIER, D., HINTONY, H., WALPOLE, J.,
BAKKE, P., BEATTIE, S., GRIER, A., WAGLE, P., AND ZHANG,
Q. StackGuard: automatic adaptive detection and prevention of
buffer-overﬂow attacks. In USENIX Security’98 (1998).

[11] COX, M. CVE-2006-3747: Apache web server off-by-one buffer
http://cve.mitre.org/cgi-bin/

overﬂow vulnerability.
cvename.cgi?name=CVE-2006-3747, 2006.

[12] CRISWELL, J., DAUTENHAHN, N., AND ADVE, V. KCoFI:
Complete control-ﬂow integrity for commodity operating system
kernels. In IEEE S&P’14 (2014).

[13] DAVI, L., DMITRIENKO, R., EGELE, M., FISCHER, T., HOLZ,
T., HUND, R., NUERNBERGER, S., AND SADEGHI, A. MoCFI:
A framework to mitigate control-ﬂow attacks on smartphones. In
NDSS’12 (2012).

[14] DAVI, L., SADEGHI, A.-R., LEHMANN, D., AND MONROSE,
F. Stitching the gadgets: On the ineffectiveness of coarse-grained
control-ﬂow integrity protection. In USENIX Security’14 (2014).
[15] ERLINGSSON, ´U., ABADI, M., VRABLE, M., BUDIU, M., AND
NECULA, G. C. XFI: Software guards for system address spaces.
In OSDI’06 (2006).

[16] GOKTAS, E., ATHANASOPOULOS, E., BOS, H., AND POR-
TOKALIDIS, G. Out of control: Overcoming control-ﬂow in-
tegrity. In IEEE S&P’14 (2014).

[18] KUZNETSOV, V., PAYER, M., SZEKERES, L., CANDEA, G.,
SEKAR, R., AND SONG, D. Code-pointer integrity. In OSDI’14
(2014).

[19] MACMANUS, G. CVE-2013-2028: Nginx http server chunked
encoding buffer overﬂow. http://cve.mitre.org/cgi-bin/
cvename.cgi?name=CVE-2013-2028, 2013.

[20] MCCAMANT, S., AND MORRISETT, G. Evaluating SFI for a

CISC architecture. In USENIX Security’06 (2006).

[21] MEHTA, N., RIKU, ANTTI, AND MATTI. The Heartbleed bug.

http://heartbleed.com/, 2014.

[22] NAGARAKATTE, S., ZHAO,

J., MARTIN, M. M., AND
ZDANCEWIC, S. SoftBound: Highly compatible and complete
spatial memory safety for C. In PLDI’09 (2009).

[23] NAGARAKATTE, S., ZHAO,

J., MARTIN, M. M., AND
ZDANCEWIC, S. CETS: Compiler enforced temporal safety for
C. In ISMM’10 (2010).

[24] NECULA, G., CONDIT, J., HARREN, M., MCPEAK, S., AND
WEIMER, W. CCured: Type-safe retroﬁtting of legacy soft-
ware. ACM Transactions on Programming Languages and Sys-
tems (TOPLAS) 27, 3 (2005), 477–526.

[25] NERGAL. The advanced return-into-lib(c) exploits. Phrack 11,
58 (Nov. 2007), http://phrack.com/issues.html?issue=
67&id=8.

[26] NISSL, R. CVE-2009-1886: Formatstring vulnerability in sm-
http://cve.mitre.org/cgi-bin/cvename.cgi?

bclient.
name=CVE-2009-1886, 2009.

[27] NIU, B., AND TAN, G. Modular control-ﬂow integrity.

PLDI’14 (2014).

In

[28] PAPPAS, V., POLYCHRONAKIS, M., AND KEROMYTIS, A. D.
Transparent ROP exploit mitigation using indirect branch tracing.
In USENIX Security (2013), pp. 447–462.

[29] PAX-TEAM. PaX ASLR (Address Space Layout Randomiza-
tion). http://pax.grsecurity.net/docs/aslr.txt, 2003.
[30] PAYER, M., BARRESI, A., AND GROSS, T. R. Fine-grained

control-ﬂow integrity through binary hardening. In DIMVA’15.

[31] PHILIPPAERTS, P., YOUNAN, Y., MUYLLE, S., PIESSENS,
F., LACHMUND, S., AND WALTER, T. Code pointer mask-
ing: Hardening applications against code injection attacks.
In
DIMVA’11 (2011).

[32] PINCUS, J., AND BAKER, B. Beyond stack smashing: Recent
advances in exploiting buffer overruns. IEEE Security and Pri-
vacy 2 (2004), 20–27.

[33] ROPPER. Ropper – rop gadget ﬁnder and binary information tool.

https://scoding.de/ropper/, 2014.

[34] SALWAN, J. ROPgadget – Gadgets ﬁnder and auto-roper. http:

//shell-storm.org/project/ROPgadget/, 2011.

[35] SCHWARTZ, E. J., AVGERINOS, T., AND BRUMLEY, D. Q:

Exploit hardening made easy. In USENIX Security’11 (2011).

[36] SHACHAM, H. The geometry of innocent ﬂesh on the bone:
Return-into-libc without function calls (on the x86). In CCS’07.
[37] SZEKERES, L., PAYER, M., WEI, T., AND SONG, D. SoK:

Eternal war in memory. In IEEE S&P’13 (2013).

[38] VAN DE VEN, A., AND MOLNAR,

I.

Exec shield.

https://www.redhat.com/f/pdf/rhel/WHP0006US_
Execshield.pdf, 2004.

[17] JIM, T., MORRISETT, J. G., GROSSMAN, D., HICKS, M. W.,
CHENEY, J., AND WANG, Y. Cyclone: A safe dialect of C. In
ATC’02 (2002).

[39] WANG, Z., AND JIANG, X. Hypersafe: A lightweight approach
In IEEE

to provide lifetime hypervisor control-ﬂow integrity.
S&P’10 (2010).

174  24th USENIX Security Symposium 

USENIX Association

14

[40] YEE, B., SEHR, D., DARDYK, G., CHEN, J. B., MUTH, R.,
ORMANDY, T., OKASAKA, S., NARULA, N., AND FULLAGAR,
N. Native client: A sandbox for portable, untrusted x86 native
code. In IEEE S&P’09 (2009).

[41] ZENG, B., TAN, G., AND ERLINGSSON, U. Strato: A retar-
getable framework for low-level inlined-reference monitors. In
USENIX Security’13 (2013).

[42] ZHANG, C., WEI, T., CHEN, Z., DUAN, L., MCCAMANT, S.,
AND SZEKERES, L. Protecting function pointers in binary. In
ASIACCS’13 (2013).

[43] ZHANG, C., WEI, T., CHEN, Z., DUAN, L., SZEKERES, L.,
MCCAMANT, S., SONG, D., AND ZOU, W. Practical control
ﬂow integrity and randomization for binary executables. In IEEE
S&P’13 (2013).

[44] ZHANG, M., AND SEKAR, R. Control ﬂow integrity for COTS

binaries. In USENIX Security’13 (2013).

A Minimal vulnerable program for indi-

rect jump or call hijacking

The program in Figure 6 contains a bug that allows the
attacker to reliably hijack an indirect jump or indirect call
target. The function overflow() allows an attacker to
overﬂow a struct allocated on the stack that contains two
pointers used as the targets for an indirect jump or an
indirect call, respectively. The attacker can use the indi-
rect jump or call to divert control ﬂow to a return gadget
and continue with a classic ROP attack. Alternatively, an
attacker may rely on JOP or COP techniques. We also
examined variations of this minimal vulnerable program,
e.g., putting the struct somewhere on the heap or requir-
ing the attacker to ﬁrst perform a stack pivot to ensure
that the stack pointer points to attacker-controlled data.

B Printf is Turing-complete

The semantics of printf() allow for Turing-complete
computation while following the minimal CFG.

At a high level, we achieve Turing-completeness by
creating logic gates out of calls to printf(). We show
how to expand a byte to its eight bits, and how to com-
pact the eight bits back to a byte. We will compute on
values by using them in their base-1 (unary) form and
we will use string concatenation as our primary method
of arithmetic. That is, we represent a true value as the
byte sequence 0x01 0x00, and the false value by the byte
sequence 0x00 0x00, so that when treated as strings their
lengths are 1 and 0 respectively.

Figure 7 contains an implementation of an OR gate us-
ing only calls to printf(). In the ﬁrst call to printf(),
if either of the two inputs is non-zero, the output length
will be non-zero, so the output will be set to a non-zero
value. The second call to printf() normalizes the value
so if it was any non-zero value it becomes a one. Figure 7

# include < stdio .h >
# include < string .h >
# define STDIN 0

void j m p t a r g e t ();
void c a l l t a r g e t ();

struct data {

char buf [1024];
int arg1 ;
int arg2 ;
int arg3 ;
void (* jmpPtr )();
void (* callPtr )( int , int , int );

};

void o v e r f l o w () {

struct data o u r _ d a t a ;
o u r _ d a t a . jmpPtr = && label ;
o u r _ d a t a . callPtr = & c a l l t a r g e t ;
printf ( " % x \ n " , ( u n s i g n e d int )& o u r _ d a t a . buf );
printf ( " \ ndata > ‘ " );
read ( STDIN , o u r _ d a t a . buf , 1044);
printf ( " \ n " );
asm ( " push ‘ %0; push ‘ %1; push ‘ %2; call ‘ *%3; add ‘ $12 ,%% esp ; "
: :" r " ( o u r _ d a t a . arg3 ) ,
" r " ( o u r _ d a t a . arg2 ) ,
" r " ( o u r _ d a t a . arg1 ) ,
" r " ( o u r _ d a t a . callPtr ));

asm ( " jmp ‘ *%0 " : : " r " ( o u r _ d a t a . jmpPtr ));
printf ( " ?\ n " );

label :

printf ( " label ‘ reached \ n " );

}

void j m p t a r g e t () {

printf ( " j m p t a r g e t () ‘ called \ n " );

}

void c a l l t a r g e t ( int arg1 , int arg2 , int arg3 ) {

printf ( " c a l l t a r g e t () ‘ called ‘ ( args : ‘ %x , ‘ %x , ‘ % x )\ n " ,
arg1 , arg2 , arg3 );

}

int main ( int argc , char * argv []) {

setbuf ( stdout , NULL );
o v e r f l o w ();
printf ( " \ ndone .\ n " );
return 0;

}

Figure 6: A minimal vulnerable program that allows hi-
jack of an indirect jump or indirect call target.

implements a NOT gate using the fact that adding 255 is
the same as subtracting one, modulo 256.

In order to operate on bytes instead of bits in our con-
trived format, we implement a test gate which can test if
a byte is equal to a speciﬁc value. By repeating this test
gate for each of the 256 potential values, we can con-
vert a 8-bit value to its “one-hot encoding” (a 256-bit
value with a single bit set, corresponding to the orig-
inal value). Splitting a byte into bits does not use a
pointer to a byte, but a byte itself. This requires that
the byte is on the stack. Moving it there takes some
effort, but can still be done with printf(). The eas-
iest way to achieve this would be to interweave calls
to memcpy() and printf(), copying the bytes to the
stack with memcpy() and then operating on them with

USENIX Association  

24th USENIX Security Symposium  175

15

void or ( int * in1 , int * in2 , int * out ) {

printf ( " % s % s % n " , in1 , in2 , out );
printf ( " % s % n " , out , out );

}

void not ( int * in , int * out ) {

printf ( " %* d % s % n " , 255 , in , out );
printf ( " % s % n " , out , out );

}

void test ( int in , int const , int * out ) {

printf ( " %* d %* d % n " , in , 0 , 256 - const , 0 , out );
printf ( " % s % n " , out , out );
printf ( " %* d % s % n " , 255 , out , out );
printf ( " % s % n " , out , out );

}

char * pad = m e m a l i g n (257 , 256);
memset ( pad , 1 , 256);
pad [256] = 0;
void s i n g l e _ n o t ( int * in , int * out ) {

printf ( " %* d % s % n % hhn % s % s % n " , 255 , in , out ,

a d d r _ o f _ a r g u m e n t , pad , out , out );

}

Figure 7: Gadgets for logic gates using printf.

printf(). However, this requires more of the program
CFG, so we instead developed a technique to achieve
the same goal without resorting to memcpy(). When
printf() is invoked, the characters are not sent di-
rectly to the stdout stream. Instead, printf() will use
the FILE struct corresponding to the stdout stream to
buffer the data temporarily. Since the struct is stored
in a writable memory location, the attacker can invoke
printf() with the “%n” format speciﬁer to point the
buffer onto the stack. Then, by reading values out of
memory with “%s” the attacker can move these values
onto the stack. Finally, the buffer can be moved back to
its original location.

It is possible to condense multiple calls to printf()
to only one. Simply concatenating the format strings is
not enough, because the length of the strings is important
with the “%n” modiﬁer. That is, after executing a NOT
gate, the string length will either be 255 or 256. We can-
not simply insert another NOT gate, as that would make
the length be one of 510, 511, or 512. We ﬁx this by in-
serting a length-repairing sequence of “%hhn%s”, which
pads the length of the string to zero modulo 256. We use
it to create a NOT gate in a single call to printf() in
Figure 7. Using this technique, we can condense an ar-
bitrary number of gates into a single call to printf().
This allows bounded Turing-complete computation.

To achieve full Turing-complete computation, we need
a way to loop a format string. This is possible by over-
writing the pointer inside printf() that tracks which
character in the format string is currently being executed.
The attacker is unlucky in that at the time the “%n” for-
mat speciﬁer is used, this value is saved in a register on
our 64-bit system. However, we identify one point in

time in which the attacker can always mount the attack.
The printf() function makes calls to puts() for the
static components of the string. When this function call
is made, all registers are saved to the stack. It turns out
that an attacker can overwrite this pointer from within the
puts() function. By doing this, the format string can be
looped.

An attacker can cause puts() to overwrite the desired
pointer. Prior to printf() calling puts(), the attacker
uses “%n” format speciﬁers to overwrite the stdout FILE
object so that the temporary buffer is placed directly on
top of the stack where the index pointer will be saved.
Then, we print the eight bytes corresponding to the new
value we want the pointer to have. Finally, we use more
“%n” format speciﬁers to move the buffer back to some
other location so that more unintended data will not be
overwritten.

C Fputs-oriented programming

These printf-style attacks are not unique to printf():
many other functions can be exploited in a similar man-
ner. We give one further attack using fputs(). For
brevity, we show how an attacker can achieve a condi-
tional write, however other computation is possible.

The FILE struct contains three char* ﬁelds to tem-
porarily buffer character data before it is written out:
a base pointer, a current pointer, and an end pointer.
fputs() works by storing bytes sequentially starting
from the base pointer keeping track with the current
pointer. When it exceeds the end pointer, the data is
written out, and the current pointer is set back to the
base. Programmatically, the way this works is that if the
current pointer is larger than the end pointer, fputs()
ﬂushes the buffer and then sets the current pointer to the
base pointer and continues writing.

This can be used to conditionally copy from source
address S to target address T if the byte address C is non-
zero. Using fputs(), the attacker copies the byte at C
on top of each of the 8 bytes in the end pointer. Then,
the attacker sets the current pointer to T and then calls
fputs() with this FILE and argument S. If the byte at C
is zero, the end pointer is the NULL pointer, and no data
is written. Otherwise, the data is written.

This attack requires two calls to fputs(). We initial-
ize memory with the constant pointers that are desired.
The ﬁrst call to fputs() moves the C byte over the end
pointer. The second call is the conditional move. The
two calls can be obtained by loop injection, or by identi-
fying an actual loop in the CFG.

176  24th USENIX Security Symposium 

USENIX Association

16

