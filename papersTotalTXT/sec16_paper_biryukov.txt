Egalitarian Computing

Alex Biryukov and Dmitry Khovratovich, University of Luxembourg

 https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/biryukov

This paper is included in the Proceedings of the 25th USENIX Security SymposiumAugust 10–12, 2016 • Austin, TXISBN 978-1-931971-32-4Open access to the Proceedings of the 25th USENIX Security Symposium is sponsored by USENIX Egalitarian computing

Alex Biryukov

University of Luxembourg

alex.biryukov@uni.lu

Abstract
In this paper we explore several contexts where an ad-
versary has an upper hand over the defender by using
special hardware in an attack. These include password
processing, hard-drive protection, cryptocurrency min-
ing, resource sharing, code obfuscation, etc.

We suggest memory-hard computing as a generic
paradigm, where every task is amalgamated with a cer-
tain procedure requiring intensive access to RAM both in
terms of size and (very importantly) bandwidth, so that
transferring the computation to GPU, FPGA, and even
ASIC brings little or no cost reduction. Cryptographic
schemes that run in this framework become egalitarian
in the sense that both users and attackers are equal in the
price-performance ratio conditions.

Based on existing schemes like Argon2 and the re-
cent generalized-birthday proof-of-work, we suggest a
generic framework and two new schemes:

• MTP, a memory-hard Proof-of-Work based on the
memory-hard function with fast veriﬁcation and
short proofs. It can be also used for memory-hard
time-lock puzzles.

• MHE,

the concept of memory-hard encryption,
which utilizes available RAM to strengthen the en-
cryption for the low-entropy keys (allowing to bring
back 6 letter passwords).

Keywords: MTP, MHE, Argon2, memory-hard,
asymmetric, proof-of-work, botnets, encryption, time-
lock puzzles.

1

Introduction

1.1 Motivation
Historically attackers have had more resources than de-
fenders, which is still mostly true. Whether it is se-
cret key recovery or document forgery, the attackers are

Dmitry Khovratovich

University of Luxembourg
khovratovich@gmail.com

ready to spend tremendous amount of computing power
to achieve the goal.
In some settings it is possible to
make most attacks infeasible by simply setting the key
length to 128 bits and higher. In other settings the secret
is limited and the best the defender can do is to increase
the time needed for the attack, but not to render the attack
impossible.

Passwords, typically stored in a hashed form, are a
classical example. As people tend to choose passwords
of very low entropy, the security designers added unique
salts and then increased the number of hash iterations.
In response the attackers switched to dedicated hardware
for password cracking, so that the price of single pass-
word recovery dropped dramatically, sometimes by a few
orders of magnitude.

A similar situation occurred in other contexts. The
Bitcoin cryptocurrency relies on continuous preimage
search for the SHA-256 hash function, which is much
cheaper on custom ASICs, consuming up to 30,000 times
less energy per solution than most efﬁcient x86 lap-
tops [2]. Eventually, the original concept of an egali-
tarian cryptocurrency [25] vanished with the emergence
of huge and centralized mining pools.

Related problems include password-based key deriva-
tion for hard-drive encryption, where the data conﬁden-
tiality directly depends on the password entropy, and
where ofﬂine attack is exceptionally easy once the drive
is stolen. Similar situation arise in the resource sharing
and spam countermeasures. In the latter it is proposed
that every user presents a certain proof (often called
proof-of-work), which should be too expensive for spam-
mers to generate on a large scale. Yet another setting
is that of code obfuscation, in which powerful reverse-
engineering/de-compilation tools can be used in order to
lift the proprietary code or secrets embedded in the soft-
ware.

USENIX Association  

25th USENIX Security Symposium  315

1.2 Egalitarian computing
Our idea is to remedy the disparity between ordinary
users and adversaries/cheaters, where latter could use
botnets, GPU, FPGA, ASICs to get an advantage and run
a cheaper attack. We call it egalitarian computing as it
should establish the same price for a single computation
unit on all platforms, so that the defender’s hardware is
optimal both for attack and defence. Equipped with egal-
itarian crypto schemes, defenders may hope to become to
be on par with the most powerful attackers.

The key element of our approach is large (in size) and
intensive (in bandwidth) use of RAM as a widely avail-
able and rather cheap unit for most defenders. In turn,
RAM is rather expensive on FPGA and ASIC1, and slow
on GPU, at least compared to memoryless computing
tasks. All our schemes use a lot of memory and a lot
of bandwidth — almost as much as possible.

We suggest a single framework for this concept and
concrete schemes with an unique combination of fea-
tures.

In the future, adoption of our concept could allow a
homogenization of computing resources, a simpliﬁed se-
curity analysis, and relaxed security requirements. When
all attackers use the same hardware as defenders, auto-
mated large-scale attacks are no longer possible. Shorter
keys, shorter passwords, faster and more transparent
schemes may come back to use.

Related work The idea of extensive memory use in the
context of spam countermeasures dates back at least to
2003 [5, 13] and was later reﬁned in [15]. Fast memory-
intensive hash functions were proposed ﬁrst by Percival
in 2009 [27] an later among the submissions of the Pass-
word Hashing Competition. Memory-intensive proofs-
of-work have been studied both in theory [16] and prac-
tice [6, 32].

Paper structure We describe the goals of our con-
cept and give a high level overview in Section 2. Then
we describe existing applications where this approach
is implicitly used: password hashing and cryptocur-
rency proofs of work (Section 3). We present our own
progress-free Proof-of-Work MTP with fast veriﬁcation,
which can also serve as a memory-hard time-lock puz-
zle, in Section 4. The last Section 5 is devoted to the

1The memory effect on ASICs can be illustrated as follows. A com-
pact 50-nm DRAM implementation [17] takes 500 mm2 per GB, which
is equivalent to about 15000 10 MHz SHA-256 cores in the best Bit-
coin 40-nm ASICs [1] and is comparable to a CPU size. Therefore, an
algorithm requiring 1 GB for 1 minute would have the same AT cost as
an algorithm requiring 242 hash function calls, whereas the latter can
not ﬁnish on a PC even in 1 day. In other words, the use of memory
can increase the AT cost by a factor of 1000 and more at the same time
cost for the desktop user.

novel concept of memory-hard encryption, where we
present our scheme MHE aimed to increase the security
of password-based disk encryption.

2 Egalitarian computing as framework

2.1 Goal

Our goal is to alter a certain function H in order to max-
imize its computational cost on the most efﬁcient archi-
tecture – ASICs, while keeping the running time on the
native architecture (typically x86) the same. We ignore
the design costs due to nontransparent prices, but instead
estimate the running costs by measuring the time-area
product [8, 31]. On ASICs the memory size M translates
into certain area A. The ASIC running time T is deter-
mined by the length of the longest computational chain
and by the ASIC memory latency.

Suppose that an attacker wants to compute H using
only a fraction αM of memory for some α < 1. Using
some tradeoff speciﬁc to H , he has to spend C(α) times
as much computation and his running time increases by
the factor D(α) (here C(α) may exceed D(α) as the at-
tacker can parallelize the computation). In order to ﬁt the
increased computation into time, the attacker has to place
C(α)
D(α) additional cores on chip. Therefore, the time-area
product changes from AT1 to ATα as

ATα = A· (α +

βC(α)
D(α)

)T · D(α) =
= AT1(αD(α) +C(α)β ),

(1)

where β is the fraction of the original memory occu-
pied by a single computing core.
If the tradeoff re-
quires signiﬁcant communication between the comput-
ing cores, the memory bandwidth limit Bwmax may also
increase the running time.
In practice we will have
D(α) ≥ C(α) · Bw/Bwmax, where Bw is the bandwidth
for α = 1.

Deﬁnition 1 We call function F memory-hard (w.r.t.
M) if any algorithm A that computes H using αM
memory has the computation-space tradeoff C(α) where
C() is at least a superlinear function of 1/α.

It is known [19] that any function whose computation is
interpreted as a directed acyclic graph with T vertices
of constant in-degree, can be computed using O( T
logT )
space, where the constant in O() depends on the degree.
However, for concrete hash functions very few tradeoff
strategies have been published, for example [9].

316  25th USENIX Security Symposium 

USENIX Association

2

2.2 Framework
Our idea is to combine a certain computation H with a
memory-hard function F . This can be done by modify-
ing H using input from F (amalgamation) or by trans-
forming its code to an equivalent one (obfuscation).

The amalgamation is used as follows. The execution
of H is typically a sequence of smaller steps Hi,i < T ,
which take the output Vi−1 from the previous step and
produce the next output Vi. For our purpose we need an-
other primitive, a memory-hard function F , which ﬁlls
the memory with some blocks X[i],i < T . We suggest
combining H with F , for example like:
H (cid:30) = H(cid:30)T ◦ H(cid:30)T−1 ◦···◦ H(cid:30)1,

where

H(cid:30)i (Vi−1) =H (Vi−1 ⊕ X[i− 1]).

Depending on the application, we may also modify X[i]
as a function of Vi−1 so that it is impossible to precom-
pute F . The idea is that any computation of H (cid:30) should
use T blocks of memory, and if someone wants to use
less, the memory-hardness property would impose com-
putational penalties on him. This approach will also
work well for any code that uses nonces or randomness
produced by PRNG. PRNG could then be replaced by (or
intermixed with the output of) F.

The obfuscation principle works as follows. Consider
a compiler producing an assembly code for some func-
tion H . We make it to run a memory-hard function F
on a user-supplied input I (password) and produce cer-
tain number of memory blocks. For each if-statement of
the form
if x

then A
else B

the compiler computes a memory-hard bit bi which is
extracted from the block X[i] (the index can also depend
on the statement for randomization) and alters the state-
ment as

then A
else B

if x⊕ bi
for bi = 0 and
if x⊕ bi
for bi = 1. This guarantees that the program will have
to run F at least once (the bits bi can be cached if this
if-statement is used multiple times, ex. in a loop).

then B
else A

Accessing the memory block from a random memory
location for each conditional statement in practice would
slow down the program too much, so compiler can per-
form a tradeoff depending on the length of the program,
the number of conditional statements in it and accord-
ing to a tunable degree of required memory-hardness
for a program. Memory-hard bits could be mixed into
opaque predicates or other code obfuscation constructs
like code-ﬂattening logic.

We note that in order for a program to run correctly,
the user needs to supply correct password for F , even
though the source code of the program is public. A smart
decompiler, however, when supplied with the password,
can obtain clean version of the program by running F
only once.

Our schemes described in the further text use the amal-
gamation principle only, so we leave the research direc-
tions in obfuscation for future work.

3 Egalitarian computing in applications

In this section we outline several applications, where
memory-hard functions are actively used in order to
achieve egalitarian computing.

3.1 Password hashing with a memory-hard

function

The typical setting for the password hashing is as fol-
lows. A user selects a password P and submit it to the
authentication server with his identiﬁer U. The server
hashes P and unique salt S with some function F , and
stores (U,S,F(P,S)) in the password ﬁle. The common
threat is the password ﬁle theft, so that an attacker can
try the passwords from his dictionary ﬁle D and check if
any of them yields the stolen hash. The unique S ensures
that the hashes are tried one-by-one.

Following massive password cracking attacks that use
special hardware [23, 30], the security community initi-
ated the Password Hashing Competition [3] to select the
hash function that withstands the most powerful adver-
saries. The Argon2 hash function [10] has been recently
selected as the winner. We stress that the use of memory-
hard function for password hashing does not make the
dictionary attacks infeasible, but it makes them much
more expensive in terms of the single trial cost.

Deﬁnition and properties of Argon2 We use Argon2
in our new schemes described in Sections 4 and 5. Here
we outline the key elements of the Argon2 design that are
used in our scheme. For more details and their rationale
we refer the reader to [10].

Argon2 takes P, S, and possibly some additional data
U as inputs. It is parametrized by the memory size M,
number of iterations t, and the available parallelism l.
It ﬁlls M blocks of memory X[1],X[2], . . . ,X [M] (1 KB
each) and then overwrites them (t −1) times. Each block
X[i] is generated using internal compression function F,
which takes X[i − 1] and X[φ (i)] as inputs. For t = 1
this works as follows, where H is a cryptographic hash

USENIX Association  

25th USENIX Security Symposium  317

3

function (Blake2b).

X[1] = H(P,S);
X[i] = F(X[i− 1],X[φ (i)]), i > 1;
Out → H(X[M]).

• The time-space tradeoffs must be steep to prevent

any price-performance reduction.

(2)

• The time and memory parameters must be tunable

independently to sustain constant mining rate.

The indexing function φ (i) is deﬁned separately for each
of two versions of Argon2: 2d and 2i. The Argon2d ver-
sion, which we use, compute it as a function of the pre-
vious block X[i− 1].
The authors proved [10] that all the blocks are gen-
erated distinct assuming certain collision-resistant-like
properties of F. They also reported the performance of
0.7 cpb on the Haswell CPU with 4 threads, and 1.6 cpb
with 1 thread.

Tradeoff security of Argon2 Using the tradeoff algo-
rithm published in [9], the authors report the values C(α)
and D(α) up to α = 1/7 with t = 1. It appears that C(α)
is exponential in α, whereas D(α) is linear.

α
C(α)
D(α)

1
2
1.5

1.5

1
3
4

1
4

20.2

1
5
344

1
6

4660

2.8

5.5

10.3

17

1
7
218
27

Table 1: Time and computation penalties for the ranking
tradeoff attack for Argon2d.

3.2 Proofs of work
A proof-of-work scheme is a challenge-response proto-
col, where one party (Prover) has to prove (maybe prob-
abilistically) that it has performed a certain amount of
computation following a request from another party (Ver-
iﬁer).
It typically relies on a computational problem
where a solution is assumed to have ﬁxed cost, such as
the preimage search in the Bitcoin protocol and other
cryptocurrencies. Other applications may include spam
protection, where a proof-of-work is a certiﬁcate that is
easy to produce for ordinary sender, but hard to generate
in large quantities given a botnet (or more sophisticated
platform).

The proof-of-work algorithm must have a few proper-

ties to be suitable for cryptocurrencies:

• It must be amortization-free, i.e. producing q out-

puts for B should be q times as expensive;

• The solution must be short enough and veriﬁed
quickly using little memory in order to prevent DoS
attacks on the veriﬁer.

4

• To avoid a clever prover getting advantage over the
others the advertised algorithm must be the most ef-
ﬁcient algorithm to date (optimization-freeness).

• The algorithm must be progress-free to prevent cen-
tralization: the mining process must be stochastic so
that the probability to ﬁnd a solution grows steadily
with time and is non-zero for small time periods.

• Parallelized implementations must be limited by the

memory bandwidth.

As demonstrated in [11], almost any hard problem can
be turned into a proof-of-work, even though it is difﬁcult
to fulﬁll all these properties. The well-known hard and
NP-complete problems are natural candidates, since the
best algorithms for them run in (sub)exponential time,
whereas the veriﬁcation is polynomial. The proof-of-
work scheme Equihash [11] is built on the generalized-
birthday, or k-XOR, problem, which looks for a set of
n-bit strings that XOR to zero. The best existing algo-
rithm is due to Wagner [34]. This problem is particularly
interesting, as the time-space tradeoff steepness can be
adjusted by changing k, which does not hold, e.g., in hard
knapsacks.

Drawbacks of existing PoW We brieﬂy discuss exist-
ing alternatives here. The ﬁrst PoW schemes by Dwork
and Naor [14] were just computational problems with
fast veriﬁcation such as the square root computation,
which do not require large memory explicitly. The sim-
plest scheme of this kind is Hashcash [7], where a par-
tial preimage to a cryptographic hash function is found
(the so called difﬁculty test). Large memory comes into
play in [13], where a random array is shared between the
prover and the veriﬁer thus allowing only large-memory
veriﬁers. This condition was relaxed in [15], where su-
perconcentrators [28] are used to generate the array, but
the veriﬁer must still hold large memory in the initial-
ization phase. Superconcentrators were later used in the
Proof-of-Space construction [16], which allows fast veri-
ﬁcation. However, the scheme [16] if combined with the
difﬁculty test is vulnerable to cheating (see Section 4.4
for more details) and thus can not be converted to a
progress-free PoW. We note that the superconcentrators
make both [15] and [16] very slow.

Ad-hoc but faster schemes started with scrypt [27],
but fast veriﬁcation is possible only with rather low

318  25th USENIX Security Symposium 

USENIX Association

amount of memory. Using more memory (say, using Ar-
gon2 [10]) with a difﬁculty test but verifying only a sub-
set of memory is prone to cheating as well (Section 4.4).
The scheme [11] is quite promising, but the reference
implementation reported is quite slow, as it takes about
30 seconds to get a proof that certiﬁes the memory allo-
cation of 500 MB. As a result, the algorithm is not truly
progress-free: the probability that the solution is found
within the ﬁrst few seconds is actually zero. It can be ar-
gued that this would stimulate centralization among the
miners. In addition, the memory parameter does not have
sufﬁcient granularity and there is no correlation between
the allocated memory and the minimal time needed to
ﬁnd the proof.

Finally, we mention schemes Momentum [21] and
Cuckoo cycle [32], which provide fast veriﬁcation due
to their combinatorial nature. They rely on the mem-
ory requirements for the collision search (Momentum)
or graph cycle ﬁnding (Cuckoo). However, Momen-
tum is vulnerable to a sublinear time-space tradeoff [11],
whereas the ﬁrst version of the Cuckoo scheme was re-
cently broken in [6].

We summarize the properties of the existing proof-of-
work constructions in Table 2. The AT cost is estimated
for the parameters that enable 1-second generation time
on a PC.

4 MTP: Proofs of work and time-lock puz-

zles based on memory-hard function

In this section we present a novel proof-of-work algo-
rithm MTP (for Merkle Tree Proof) with fast veriﬁca-
tion, which in particular solves the progress-free prob-
lem of [11]. Our approach is based on the memory-hard
function, and the concrete proposal involves Argon2.

Since fast memory-hard functions F such as Argon2
perform a lengthy chain of computations, but do not
solve any NP-like problem, it is not fast to verify that
Y is the output of F. Checking some speciﬁc (say, last)
blocks does not help, as explained in detail in the fur-
ther text. We thus have to design a scheme that lower
bounds the time-area product for the attacker, even if he
computes a slightly modiﬁed function.

Algorithm 1 MTP: Merkle-tree based Proof-of-Work.
Prover’s algorithm
Input: Challenge I, parameters L,d.

1. Compute F (I) and store its T blocks X[1], X[2],

. . ., X[T ] in the memory.

2. Compute the root Φ of the Merkle hash tree (see

Appendix A).

3. Select nonce N.

4. Compute Y0 = H(Φ,N) where G is a cryptographic

hash function.
5. For 1 ≤ j ≤ L:

i j = Yj−1
(mod T );
Yj = H(Yj−1,X[i j]).

6. If YL has d trailing zeros, then (Φ,N, Z ) is the
proof-of-work, where Z is the opening of 2L
blocks {X[i j − 1],X[φ (i j)]}. Otherwise go to Step
3.

Output: Proof (Φ,N, Z ).

The veriﬁer, equipped with F and H, runs Algo-

rithm 2.

Algorithm 2 MTP: Veriﬁer’s algorithm
Input: Proof (Φ,N, Z ), parameters L,d.

1. Compute Y0 = H(Φ,N).
2. Verify all block openings using Φ.
3. Compute from Z for 1 ≤ j ≤ L:

X[i j] = F(X[i j − 1],X[φ (i j)]);

Yj = G(Yj−1,X[i j]).

4. Check whether YL has t trailing zeros.

Output: Yes/No.

4.1 Description of MTP
Consider a memory-hard function F that satisﬁes Equa-
tion (2) (for instance, Argon2) with a single pass over the
memory producing T blocks and a cryptographic hash
function H (possibly used in F ). We propose the fol-
lowing non-interactive protocol for the Prover (Figure 1)
in Algorithm 1, where L and d are security parameters.
The average number of calls to F is T + 2dL.

4.2 Cheating strategies
Let the computation-space tradeoff for H and the de-
fault memory value T be given by functions C(α) and
D(α) (Section 2).

Memory savings Suppose that a cheating prover wants
to reduce the AT cost by using αT memory for some
α < 1. First, he computes F (I) and Φ, making C(α)T

USENIX Association  

25th USENIX Security Symposium  319

5

Scheme

Dwork-Naor I [14]
Dwork-Naor II [13]
Dwork-Naor III [15]
Hashcash/Bitcoin [7]

Pr.-of-Space [16]+Diff.test

Litecoin

Argon2-1GB + Diff.test

Momentum [21]
Cuckoo cycle [32]

Equihash [11]

MTP

Medium

Low
High

Low
High

AT cost

Speed

Veriﬁcation
Fast M/less
Yes
Yes
Yes
Yes
Yes
Yes
No
Yes
Medium [6] Medium Yes
Medium Yes
Yes

Yes
No
No
Yes
Yes
Yes
No
Yes
Yes
Yes
Yes

High
Low
Low
High
Low
High
High
High

High
High

Medium

High

Medium

High

Tradeoff

Paral-sm Progress

Memoryless
Memoryless
Exponential
Memoryless
Exponential

Linear

Exponential
Attack [11, 33]

Linear [6]
Exponential
Exponential

Yes

Constr.
Constr.

Yes
No
No
No
Yes
Yes

Constr.
Constr.

-free
Yes
Yes
Yes
Yes
No
Yes
Yes
Yes
Yes
Yes
Yes

Table 2: Review of existing proofs of work. Litecoin utilizes scrypt with 128KB of RAM followed by the difﬁculty
test). M/less – memoryless; constr. – constrained.

calls to F. Then for each N he has to get or recompute
L blocks using only αT stored blocks. The complexity
of this step is equal to the complexity of recomputing
random L blocks during the ﬁrst computation of F . A
random block is recomputed by a tree of average size
C(α) and depth D(α). Therefore, to compute the proof-
of-work, a memory-saving prover has to make C(α)(T +
2dL) calls to F, so his amount of work grows by C(α).

Block modiﬁcation The second cheating strategy is to
compute a different function F (cid:31) (cid:30)= F . More precisely,
the cheater produces some blocks X[i(cid:31)] (which we call
inconsistent as in [16]) not as speciﬁed by Equation (2)
(e.g. by simply computing X[i(cid:31)] = H(i(cid:31))). In contrast to
the veriﬁable computation approach, our protocol allows
a certain number of inconsistent blocks. Suppose that the
number of inconsistent blocks is εT , then the chance that
no inconsistent block is detected by L opened blocks is

γ = (1− ε)L.

Therefore, the probability for a proof-of-work with εM
inconsistent blocks to pass the opening test is γ. In other
words, the cheater’s time is increased by the factor 1/γ.
We note that it does not make sense to alter the blocks
after the Merkle tree computation, as any modiﬁed block
would fail the opening test.

Overall cheating penalties Let us accumulate the two
cheating strategies into one. Suppose that a cheater

stores αT blocks and additionally allows εT inconsis-
tent blocks. Then he makes at least

C(α + ε)(T + 2dL)

γ

(3)

calls to F. The concrete values are determined by the
penalty function C(), which depends on F .

4.3 Parallelism
Both honest prover and cheater can parallelize the com-
putation for 2t different nonces. However, the latency of
cheater’s computation will be higher, since each block
generates a recomputation tree of average depth D(α +
ε).

4.4 Why simpler approach does not work:

grinding attack

Now we can explain in more details why the composition
of F and the difﬁculty test is not a good proof-of-work
even if some internal blocks of H are opened. Suppose
that the proof is accepted if H(X[T ]) has certain number
d of trailing zeros. One would expect that a prover has
to try 2d distinct I on average and thus call F 2t times to
ﬁnd a solution. However, a cheating prover can simply
try 2d values for X[T ] and ﬁnd one that passes the test
in just 2d calls to H. Although X[T ] is now inconsistent,
it is unlikely to be selected among L blocks to open, so
the cheater escapes detection easily. Additionally check-
ing X[T ] would not resolve the problem since a cheater

320  25th USENIX Security Symposium 

USENIX Association

6

iL

i1

Argon2

I

Merkle tree

Nonce
N

Φ

Open 2L blocks

H

i1

H

iL

H

Y

No

d trailing zeros?

Yes

Figure 1: MTP: Merkle-tree based Proof-of-Work with
light veriﬁcation.

would then modify the previous block, or X[φ (T )], or an
earlier block and then propagate the changes. A single
inconsistent block is just too difﬁcult to catch2.

4.5 MTP-Argon2
As a concrete application, we suggest a cryptocurrency
proof-of-work based on Argon2d with 4 parallel lanes.
We aim to make this PoW unattractive for botnets, so we
suggest using 2 GB of RAM, which is very noticeable
(and thus would likely alarm the user), while being bear-
able for the regular user, who consciously decided to use
his desktop for mining. On our 1.8 GHz machine a single
call to 2-GB Argon2d runs in 0.5 seconds, but the Merkle
tree computation is more expensive, as we have to hash
2 GB of data splitted into 1 KB blocks. We suggest us-
ing Blake2b for H, as it is already used in Argon2d, but
restrict to 128-bit output, so that the total running time is
about 3 seconds. In this case a single opening has 16· 21
bytes of hashes, or 1.3 KB in total.
We suggest L = 70, so that the entire proof consists
of 140 blocks and their openings, or 180 KB in total.
Let us ﬁgure out the cheating advantage. The C() and
D() functions are given in Table 1). Assuming certain
ratio between the area needed to implement Blake2b and

2We have not seen any formal treatment of this attack in the liter-
ature, but it appears to be known in the community. It is mentioned
in [26] and [4].

the area needed for DRAM, we get the following lower
bound on the ASIC-equipped cheater.

Proposition 1 For L = 70 and 2 GB of RAM the time-
area product can be reduced by the factor of 12 at most,
assuming that each Blake2b core occupies an equivalent
of 216 bytes.

Proof. Assuming that each core occupies 216 bytes, we
obtain β = 2−15 in terms of Equation (1). Since the
cheater has the success chance γ = (1−ε)L, Equation (1)
is modiﬁed as follows:

ATα = AT1

αD(α + ε) +C(α + ε)/215

(1− ε)L

.

(4)

Consider three options:

• α,ε < 1/12. Then C(α + ε) ≥ 4660 (Table 1) and

we have

ATα ≥ AT1 ·

4660
32768 ≥ AT1 · 0.12.

• α < 1/12, 1/6 ≥ ε > 1/12. Then C(α + ε) ≥ 20,
(1− ε)L > 1/441, and we have
20· 441
32768 ≥ AT1 · 0.27.

ATα ≥ AT1 ·

• α < 1/12, 1/6 ≤ ε. Then (1− ε)L > 215, and the
time-area product increases.

• α > 1/12. Then ATα ≥ AT1 · 1/12.

This ends the proof.

We conclude that a cheater can gain at most 12x-
advantage, whereas he can still be detected in the future
by memory-rich veriﬁers. Tradeoffs are also not helpful
when implementing this Proof-of-Work on ASIC. Alto-
gether, our proposal should reduce the relative efﬁciency
of potential ASIC mining rigs and allow more egalitarian
mining process. Even if someone decides to use large
botnets (10,000 machines and more), all the botnets ma-
chines would have to use the same 2 GB of memory, oth-
erwise they would suffer large penalty. We note that if
ε = 0, i.e. the prover is honest, then his maximal advan-
tage is max

1

αD(α) ≤ 2.

4.6 MTP as a tool for time-lock puzzles and

timestamping

The paradigm of inherently sequential computation was
developed by [12] in the application to CPU benchmark-
ing and [29] for timestamping, i.e. to certify that the doc-
ument was generated certain amount of time in the past.
Rivest et al. suggested time-lock puzzles for this purpose.

USENIX Association  

25th USENIX Security Symposium  321

7

In our context, a time-lock puzzle solution is a proof-of-
work that has lower bound on the running time assuming
unlimited parallelism.

The veriﬁer in [20, 29] selects a prime product N =
pq and asks the prover to compute the exponent 22D
It is conjectured that the
(mod N) fpr some D ≈ N.
prover who does not know the factors can not exponen-
tiate faster than do D consecutive squarings. In turn, the
veriﬁer can verify the solution by computing the expo-
nent 2D modulo φ (N), which takes log(D) time. So far
the conjecture has not been refuted, but the scheme in-
herently requires a secret held by the veriﬁer, and thus
is not suitable for proofs-of-work without secrets, as in
cryptocurrencies.

Time-lock puzzles without secrets were suggested by
Mahmoody et al. [22]. Their construction is a graph
of hash computations, which is based on depth-robust
graphs similarly to [16]. The puzzle is a deterministic
graph such that removing any constant fraction of nodes
keeps its depth above the constant fraction of the original
one (so the parallel computation time is lower bounded).
A Merkle tree is put atop of it with its root determining
a small number of nodes to open. Therefore, a cheater
who wants to compute the graph in less time has to sub-
vert too many nodes and is likely to be caught. As [16],
the construction by Mahmoody et al., if combined with
the difﬁculty ﬁlter, is subject to the grinding attack de-
scribed above.

The MTP-Argon2 construction can be viewed as
a time-lock puzzle and an improvement over these
schemes. First, the difﬁculty ﬁlter is explicitly based on
the grinding attack, which makes it a legitimate way to
solve the puzzle. Secondly, it is much faster due to high
speed of Argon2d. The time-lock property comes from
the fact that the computation chain can not be parallelized
as the graph structure is not known before the computa-
tion.

Suppose that MTP-Argon2 is parallelized by the ad-
ditional factor of R so that each core computes a chain
of length about T /R. Let core j compute j-th (out of
R) chain, chronologically. Then bu step i each core has
computed i blocks and has not computed T /R−i blocks,
so the probability that core j requests a block that has not
been computed is

( j− 1)(T /R− i)
( j− 1)T /R + i ≤

( j− 1)(T /R− i)

jT /R

.

2R

Summing by all i, we obtain that core j misses at least
T (1−1/ j)
, so the total fraction of inconsistent blocks is
about 0.5 − lnR
2R . Therefore, ε quickly approaches 0.5,
which is easily detectable. We thus conclude that a par-
allel implementation of MTP-Argon2 is likely to fail the
Merkle tree veriﬁcation.

5 Memory-hard
entropy keys

encryption

on

low-

5.1 Motivation
In this section we approach standard encryption from
the memory-hardness perspective. A typical approach to
hard-drive encryption is to derive the master key from the
user password and then use it to encrypt chunks of data in
a certain mode of operation such as XTS [24]. The major
threat, as to other password-based security schemes, are
low-entropy passwords. An attacker, who gets access to
the hard drive encrypted with such password, can deter-
mine the correct key and then decrypt within short time.
A countermeasure could be to use a memory-hard
function for the key derivation, so that the trial keys can
be produced only on memory-rich machines. However,
the trial decryption could still be performed on special
memoryless hardware given these keys. We suggest a
more robust scheme which covers this type of adversaries
and eventually requires that the entire attack code have
permanent access to large memory.

5.2 Requirements
We assume the following setting, which is inspired by
typical disk-encryption applications. The data consists
of multiple chunks Q ∈ Q, which can be encrypted and
decrypted independently. The only secret that is avail-
able to the encryption scheme E is the user-input pass-
word P ∈ P, which has sufﬁciently low entropy to be
memorized (e.g., 6 lowercase symbols). The encryption
syntax is then as follows:

E : P × S × Q → C ,

where S ∈ S is associated data, which may contain salt,
encryption nonce or IV, chunk identiﬁer, time, and other
secondary input; and C ∈ C is ciphertext. S serves both
to simplify ciphertext identiﬁcation (as it is public) and
to ensure certain cryptographic properties. For instance,
unique salt or nonce prevents repetition of ciphertexts for
identical plaintexts. We note that in some settings due to
storage restriction the latter requirement can be dropped.
Decryption then is naturally deﬁned and we omit its for-
mal syntax.

In our proposal we do not restrict the chunk size. Even
though it can be deﬁned for chunks as small as disk sec-
tors, the resistance to cracking attacks will be higher for
larger chunks, up to a megabyte long.

A typical attack setting is as follows. An attacker ob-
tains the encrypted data via some malicious channel or
installs malware and then tries different passwords to de-
crypt it. For the sake of simplicity, we assume that the

322  25th USENIX Security Symposium 

USENIX Association

8

plaintext contains sufﬁcient redundancy so that a suc-
cessful guess can be identiﬁed easily. Therefore, the ad-
versary tries D passwords from his dictionary D ⊂ P.
Let T be the time needed for the fastest decryption op-
eration that provides partial knowledge of plaintext suf-
ﬁcient to discard or remember the password, and A0 be
the chip area needed to implement this operation. Then
the total amount of work performed by the adversary is

W = D· T · A0.

At the same time, the time to encrypt T(cid:29) for a typical user
should not be far larger than T . Our goal is to maximize
W with keeping T(cid:29) the same or smaller.

The memory-hard functions seem to serve perfectly
for the purpose of maximizing W . However, it remains
unclear how to combine such function F with E to get
memory-hard encryption (MHE).

Now we formulate some additional features that

should be desirable for such a scheme:

• The user should be able to choose the requested
memory size A independently of the chunk length
|Q|. Whereas the chunk length can be primarily de-
termined by the CPU cache size, desirable process-
ing speed, or the hard drive properties, the memory
size determines the scheme’s resistance to cracking
attacks.

• The memory can be allocated independently for
each chunk or reused. In the former case the user
can not allocate too much memory as the mas-
sive decryption would be too expensive. How-
ever, for the amounts of memory comparable to
the chunk size the memory-hard decryption should
take roughly as much as memoryless decryption. If
the allocated memory is reused for distinct chunks,
much more memory can be allocated as the alloca-
tion time can be amortized. However, the decryp-
tion latency would be quite high. We present both
options in the further text.

• Full ciphertext must be processed to decrypt a single
byte. This property clearly makes T larger since
the adversary would have to process an entire chunk
to check the password. At the same time, for disk
encryption it should be ﬁne to decrypt in the “all-or-
nothing” fashion, as the decryption time would still
be smaller than the user could wait.

• Encryption should be done in one pass over data.
It might sound desirable that the decryption should
be done in one pass too. However, this would con-
tradict the previous requirement. Indeed, if the de-
cryption can be done in one pass, then the ﬁrst bytes

of the plaintext can be determined without the last
bytes of the ciphertext3.

• Apart from the memory parameter, the total time
needed to allocate this memory should be tunable
too. It might happen that the application does not
have sufﬁcient memory but does have time. In this
case, the adversary can be slowed down by making
several passes over the memory during its initial-
ization (the memory-hard function that we consider
support this feature).

Our next and ﬁnal requirement comes from adversary’s
side. When the malware is used, the incoming network
connection and memory for this malware can be limited.
Thus, it would be ideal for the attacker if the memory-
intensive part can be delegated to large machines under
attacker’s control, such as botnets. If we just derived the
secret-key K for encryption as the output of the memory-
hard hash function F , this would be exactly this case.
An adversary would then run F for dictionary D on his
own machine, produce the set K of keys, and supply
them to malware (recall that due to low entropy there
would be only a handful of these keys). Thus the ﬁnal
requirement should be the following:

• During decryption, it should be impossible to del-
egate the entire memory-hard computation to the
external device without accessing the ciphertext.
Therefore, there could be no memory-hard precom-
putation.

5.3 Our scheme
Our scheme is based on a recent proposal by Za-
verucha [35], who addresses similar properties in the
scheme based on Rivest’s All-or-Nothing transform
(ANT). However, the scheme in [35] does not use an ex-
ternal memory-hard function, which makes it memory
requirements inevitably bound to the chunk size. Small
chunks but large memory is impossible in [35].

Our proposal is again based on the All-or-Nothing
transformation, though we expect that similar proper-
ties can be obtained with deterministic authenticated en-
cryption scheme as a core primitive. The chunk length
q (measured in blocks using by F ) and memory size
M ≥ q are the parameters as well as some blockcipher
E (possibly AES). First, we outline the scheme where
the memory is allocated separately for each chunk. The
reader may also refer to Figure 2.

The underlying idea is to use both the header and the
body blocks to produce the ciphertext. In tun, to recom-
pute the body blocks both the ciphertext and the header
must be available during trial decryption.

3The similar argument is made for the online authenticated ciphers

9

USENIX Association  

25th USENIX Security Symposium  323

pwd

H

header

body

Argon2

H

K1

K0

E
CBC

Cq+1

H

K0

random

K1

E
ECB

K1

E
ECB

m1

m2

C(cid:31)(cid:31)1

E
CBC

C1

K0

C(cid:31)(cid:31)2

E
CBC

C2

Figure 2: MHE: Disk encryption using memory-hard function Argon2.

The version of the MHE scheme which allocates the
same memory for multiple chunks is very similar. The
S input is ignored at the beginning, so that the header
memory blocks do not depend on the data. Instead, we
set K0 = H(X0,S), so that the body blocks are affected
by S and M, and thus are different for every chunk. In
this case the body blocks have to be stored separately
and should not overwrite the header blocks for t > 1.

Let us verify that the scheme in Algorithm 3 satisﬁes

the properties we listed earlier:

• The allocated memory size M can be chosen inde-
pendently of the chunk length q (as long as M > q).
• The body memory blocks are allocated and pro-
cessed for each chunk independently. In addition,
the header blocks are also processed independently
for each chunk in the single-chunk version.

• In order to decrypt a single byte of the ciphertext,
an adversary would have to obtain K1, which can be
done only by running F up to the ﬁnal block, which
requires all C(cid:30)(cid:30)i , which are in turn must be derived
from the ciphertext blocks.

• Encryption needs one pass over data, and decryp-

tion needs two passes over data.

• The total time needed to allocate and ﬁll the header

is tunable.

• The computation of the body memory blocks dur-
ing decryption can not be delegated, as it requires
knowledge both of the header and the ciphertext. It

in [18].

might be possible to generate the header on an ex-
ternal machine, but then random access to its blocks
to decrypt the ciphertext is required.

We note that properties 1, 5, and 6 are not present in [35].

Security First, we address traditional CPA security.
We do not outline the full proof here, just the basic steps.
We assume that the adversary does not have access to the
internals of Argon2, and that blockcipher E is a secure
PRF. Next, we assume collision-resistance of the com-
pression function F used in F . Given that, we prove
that all the memory blocks are distinct, which yields the
CPA security for C(cid:30). From the latter we deduce the CPA
security for the ﬁnal ciphertext. We note that in the case
when the collision-resistance of F can not be guaranteed,
we may additionally require that Xi undergo hashing by
a cryptographic hash function H(cid:30) before encryption, so
that the plaintext blocks are still distinct. All these prop-
erties hold up to the birthday bound of the blockcipher.
Next, we ﬁgure out the tradeoff security. The genuine
decrypting user is supposed to spend M memory blocks
for F and q memory blocks to store the plaintext and
intermediate variables (if the ciphertext can be overwrit-
ten, then these q blocks are not needed). Suppose that
an adversary wants to use αM memory for header and
body. Then each missing block, if asked during decryp-
tion, must be recomputed making C(α) calls to F. The
best such strategy for Argon2, described in [9], yields
C(α) that grows exponentially in 1/α. For example, us-
ing 1/5 of memory, an adversary would have to make
344 times as many calls to F, which makes a memory-
reducing encryption cracking inefﬁcient even on special
hardware.

324  25th USENIX Security Symposium 

USENIX Association

10

Algorithm 3 Memory-hard encryption with independent
memory allocation (for each chunk).
Input: Password P, memory size M, associated data S,
chunk Q, number of iterations t, memory-hard function
F (preferably Argon2), blockcipher E, cryptographic
hash function H (e.g. SHA-3).

1. Run F on (P,S) with input parameters M and t but
ﬁll only M − q blocks (the header) in the last itera-
tion. Let X0 be the last memory block produced by
F .

2. Produce K0 = H(X0) — the ﬁrst session key.

3. Generate a random session key K1.

4. Generate the remaining blocks X1, X2, . . ., Xq (body)
for F as follows. We assume that each chunk M
consists of smaller blocks m1, m2, . . ., mq of length
equal to the block size of F . For each i ≥ 1:

• Encrypt Xi−1 by E in the ECB mode under K1
and get the intermediate ciphertext block C(cid:28)i.
• Add the chunk data: C(cid:28)(cid:28)i = C(cid:28)i ⊕ mi.
• Encrypt C(cid:28)(cid:28)i under K0 in the CBC mode and
produce the ﬁnal ciphertext block Ci.
• Modify the memory: Xi−1 ← Xi−1 ⊕C(cid:28)(cid:28)i .
• Generate the block Xi according to the speci-
ﬁcation of F . In Argon2, the modiﬁed Xi−1
and some another block X[φ (Xi−1)] would be
used.

5. After the entire chunk is encrypted, encrypt also the

key K1 :

Ct+1 = EK0(H(Xt )⊕ K1).

Output: C1, . . . ,Ct+1.

Performance We suggest taking l = 4 in Argon2 in or-
der to ﬁll the header faster using multiple cores, which
reportedly takes 0.7 cpb (about the speed of AES-GCM
and AES-XTS). The body has to be ﬁlled sequentially
as the encryption process is sequential. As AES-CBC
is about 1.3 cpb, and we use two of it, the body phase
should run at about 4 cpb.
In a concrete setting, sup-
pose that we tolerate 0.1 second decryption time (about
300 Mcycles) for the 1-MB chunk. Then we can take the
header as large as 256 MB, as it would be processed in
170 Mcycles + 4 Mcycles for the body phase.

6 Conclusion

We have introduced the new paradigm of egalitarian
computing, which suggests amalgamating arbitrary com-
putation with a memory-hard function to enhance the
security against off-line adversaries equipped with pow-
erful tools (in particular with optimized hardware). We
have reviewed password hashing and proofs of work as
applications where such schemes are already in use or
are planned to be used. We then introduce two more
schemes in this framework. The ﬁrst one is MTP, the
progress-free proof-of-work scheme with fast veriﬁca-
tion based on the memory-hard function Argon2, the
winner of the Password Hashing Competition. The sec-
ond scheme pioneers the memory-hard encryption — the
security enhancement for password-based disk encryp-
tion, also based on Argon2.

References
[1] Avalon asic’s 40nm chip to bring hashing boost for less power,
2014. http://www.coindesk.com/avalon-asics-40nm-/
/chip-bring-hashing-boost-less-power/.

[2] Bitcoin: Mining hardware comparison,

avail-
able at https://en.bitcoin.it/wiki/Mining_hardware_
comparison. We compare 232 hashes per joule on the best
ASICs with 217 hashes per joule on the most efﬁcient x86-
laptops.

2014.

[3] Password Hashing

Competition,

//password-hashing.net/.

2015.

https:

[4] 2016. Andrew Miller, Bram Cohen, private communication.

[5] ABADI, M., BURROWS, M., AND WOBBER, T. Moderately
hard, memory-bound functions. In NDSS’03 (2003), The Internet
Society.

[6] ANDERSEN, D. A public review of cuckoo cycle. http://www.

cs.cmu.edu/~dga/crypto/cuckoo/analysis.pdf, 2014.

[7] BACK, A. Hashcash – a denial of service counter-measure, 2002.
available at http://www.hashcash.org/papers/hashcash.
pdf.

[8] BERNSTEIN, D. J., AND LANGE, T. Non-uniform cracks
in the concrete: The power of free precomputation.
In ASI-
ACRYPT’13 (2013), vol. 8270 of Lecture Notes in Computer Sci-
ence, Springer, pp. 321–340.

USENIX Association  

25th USENIX Security Symposium  325

11

[9] BIRYUKOV, A., AND KHOVRATOVICH, D. Tradeoff cryptanaly-
sis of memory-hard functions. In Asiacrypt’15 (2015). available
at http://eprint.iacr.org/2015/227.

[27] PERCIVAL, C. Stronger key derivation via sequential memory-
hard functions. http://www.tarsnap.com/scrypt/scrypt.
pdf.

[10] BIRYUKOV, A., AND KHOVRATOVICH, D. Argon2: new gener-
ation of memory-hard functions for password hashing and other
applications.
available at https:
//www.cryptolux.org/images/0/0d/Argon2.pdf.

In Euro S&P’16 (2016).

[11] BIRYUKOV, A., AND KHOVRATOVICH, D. Equihash: Asym-
metric proof-of-work based on the generalized birthday problem.
In NDSS’16 (2016). available at https://eprint.iacr.org/
2015/946.pdf.

[12] CAI, J., LIPTON, R. J., SEDGEWICK, R., AND YAO, A. C. To-
wards uncheatable benchmarks. In Structure in Complexity The-
ory Conference (1993), IEEE Computer Society, pp. 2–11.

[13] DWORK, C., GOLDBERG, A., AND NAOR, M. On memory-
bound functions for ﬁghting spam.
In CRYPTO’03 (2003),
vol. 2729 of Lecture Notes in Computer Science, Springer,
pp. 426–444.

[14] DWORK, C., AND NAOR, M. Pricing via processing or combat-
ting junk mail. In CRYPTO’92 (1992), vol. 740 of Lecture Notes
in Computer Science, Springer, pp. 139–147.

[15] DWORK, C., NAOR, M., AND WEE, H. Pebbling and proofs
of work. In CRYPTO’05 (2005), vol. 3621 of Lecture Notes in
Computer Science, Springer, pp. 37–54.

[16] DZIEMBOWSKI, S., FAUST, S., KOLMOGOROV, V., AND
PIETRZAK, K. Proofs of space. In CRYPTO’15 (2015), R. Gen-
naro and M. Robshaw, Eds., vol. 9216 of Lecture Notes in Com-
puter Science, Springer, pp. 585–605.

[17] GIRIDHAR, B., CIESLAK, M., DUGGAL, D., DRESLINSKI,
R. G., CHEN, H., PATTI, R., HOLD, B., CHAKRABARTI, C.,
MUDGE, T. N., AND BLAAUW, D. Exploring DRAM organi-
zations for energy-efﬁcient and resilient exascale memories. In
International Conference for High Performance Computing, Net-
working, Storage and Analysis 2013 (2013), ACM, pp. 23–35.

[18] HOANG, V. T., REYHANITABAR, R., ROGAWAY, P., AND
VIZ ´AR, D. Online authenticated-encryption and its nonce-
reuse misuse-resistance. In CRYPTO’15 (2015), R. Gennaro and
M. Robshaw, Eds., vol. 9215 of Lecture Notes in Computer Sci-
ence, Springer, pp. 493–517.

[19] HOPCROFT, J. E., PAUL, W. J., AND VALIANT, L. G. On time

versus space. J. ACM 24, 2 (1977), 332–337.

[20] JERSCHOW, Y. I., AND MAUVE, M. Ofﬂine submission with
RSA time-lock puzzles. In CIT (2010), IEEE Computer Society,
pp. 1058–1064.

[21] LORIMER, D. Momentum – a memory-hard proof-of-work via
available at http://www.

ﬁnding birthday collisions, 2014.
hashcash.org/papers/momentum.pdf.

[22] MAHMOODY, M., MORAN, T., AND VADHAN, S. P. Publicly
In ITCS (2013), ACM,

veriﬁable proofs of sequential work.
pp. 373–388.

[23] MALVONI,

K.

2014.

crack-
available
http://www.openwall.com/presentations/

ing,
at
Passwords14-Energy-Efficient-Cracking/.

Energy-efﬁcient

Passwords’14

conference,

bcrypt

[28] PIPPENGER, N. Superconcentrators. SIAM J. Comput. 6, 2

(1977), 298–304.

[29] RIVEST, R. L., SHAMIR, A., AND WAGNER, D. A. Time-lock
puzzles and timed-release crypto. https://people.csail.
mit.edu/rivest/pubs/RSW96.pdf.

[30] SPRENGERS, M., AND BATINA, L. Speeding up GPU-based
password cracking. In SHARCS’12 (2012). available at http:
//2012.sharcs.org/record.pdf.

[31] THOMPSON, C. D. Area-time complexity for VLSI. In STOC’79

(1979), ACM, pp. 81–88.

[32] TROMP, J. Cuckoo cycle: a memory bound graph-theoretic
proof-of-work. Cryptology ePrint Archive, Report 2014/059,
2014.
available at http://eprint.iacr.org/2014/059,
project webpage https://github.com/tromp/cuckoo.

[33] VAN OORSCHOT, P. C., AND WIENER, M. J. Parallel colli-
sion search with cryptanalytic applications. J. Cryptology 12, 1
(1999), 1–28.

[34] WAGNER, D. A generalized birthday problem. In CRYPTO’02
(2002), vol. 2442 of Lecture Notes in Computer Science,
Springer, pp. 288–303.

[35] ZAVERUCHA, G. Stronger password-based encryption using
available at http://research.

all-or-nothing transforms.
microsoft.com/pubs/252097/pbe.pdf.

A Merkle hash trees

We use Merkle hash trees in the following form. A
prover P commits to T blocks X[1],X[2], . . . ,X [T ] by
computing the hash tree where the blocks X[i] are at
leaves at depth logT and nodes compute hashes of their
branches. For instance, for T = 4 and hash function G
prover P computes and publishes

Φ = G(G(X[1],X[2]),G(X[3],X[4])).

Prover stores all blocks and all intermediate hashes. In
order to prove that he knows, say, X[5] for T = 8, (or to
open it) he discloses the hashes needed to reconstruct the
path from X[5] to Φ:

open(X[5]) = (X[5],X[6],g78 = G(X[7],X[8]),

g1234 = G(G(X[1],X[2]),G(X[3],X[4])),Φ),

so that the veriﬁer can make all the computations. If G
is collision-resistant, it is hard to open any block in more
than one possible way.

[24] MARTIN, L. Xts: A mode of aes for encrypting hard disks. IEEE

Security & Privacy, 3 (2010), 68–69.

[25] NAKAMOTO, S. Bitcoin: A peer-to-peer electronic cash system.

http://www.bitcoin.org/bitcoin.pdf.

[26] PARK, S., PIETRZAK, K., ALWEN, J., FUCHSBAUER, G., AND
GAZI, P. Spacecoin: A cryptocurrency based on proofs of space.
IACR Cryptology ePrint Archive 2015 (2015), 528.

326  25th USENIX Security Symposium 

USENIX Association

12

