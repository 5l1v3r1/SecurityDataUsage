SEDA: Scalable Embedded Device Attestation

N. Asokan1, Ferdinand Brasser2, Ahmad Ibrahim2, Ahmad-Reza Sadeghi2,

Matthias Schunter3, Gene Tsudik4, and Christian Wachsmann2
1Aalto University and University of Helsinki, Espoo and Helsinki, Finland

2Technische Universität Darmstadt, Germany

3Intel Labs, Portland, OR, U.S.A.

4University of California, Irvine, CA, U.S.A.

{ferdinand.brasser, ahmad.ibrahim, ahmad.sadeghi,

christian.wachsmann}@trust.cased.de,

asokan@acm.org, matthias.schunter@intel.com, gene.tsudik@uci.edu

Abstract
large numbers of smart interconnected devices provide
Today,
safety and security critical services for energy grids, industrial con-
trol systems, gas and oil search robots, home/ofﬁce automation,
transportation, and critical infrastructure. These devices often oper-
ate in swarms – large, dynamic, and self-organizing networks. Soft-
ware integrity veriﬁcation of device swarms is necessary to ensure
their correct and safe operation as well as to protect them against at-
tacks. However, current device attestation schemes assume a single
prover device and do not scale to swarms.

We present SEDA, the ﬁrst attestation scheme for device swarms.
We introduce a formal security model for swarm attestation and
show security of our approach in this model. We demonstrate two
proof-of-concept implementations based on two recent (remote) at-
testation architectures for embedded systems, including an Intel re-
search platform. We assess performance of SEDA based on these
implementations and simulations of large swarms. SEDA can efﬁ-
ciently attest swarms with dynamic and static topologies common
in automotive, avionic, industrial control and critical infrastructures
settings.
Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection
Keywords
remote attestation; device swarms; security

1.

INTRODUCTION

Current and emerging industrial trends envision systems consist-
ing of large numbers of heterogeneous embedded and mobile de-
vices, forming so-called Internet of Things (IoT). Analysts predict
billions of connected devices that will enable many new services
and experiences. Examples include: (1) industrial control systems,

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
c(cid:13) 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813670.

where large numbers of connected autonomously operating devices
collaborate to monitor and control safety-critical processes (e.g.,
smart factories), (2) connected IoT devices in smart environments
(e.g., smart homes and smart buildings) and (3) self-organizing
dynamic networks where a multitude of devices form collectively
intelligent systems (e.g., robots used for oil and gas search). In-
spired by nature, such systems are often referred to as device
swarms [13, 19, 45]. To ensure their correct operation, it is crucial
to maintain their software integrity and protect them against attacks.
For instance, large-scale industrial control systems or robot swarms
are vulnerable to a wide range of attacks [6, 12, 19, 21, 23, 36, 43].
Verifying correct and safe operation of these systems requires an
efﬁcient mechanism to collectively verify software integrity of all
devices in order to detect software modiﬁcations. However, naïve
applications of remote attestation do not scale to these systems. In
particular, device swarms with dynamic topologies, such as vehic-
ular ad-hoc networks, robot swarms, and sensors in ﬂuid environ-
ments, require novel and ﬂexible solutions.

Many approaches to remote attestation have been proposed to-
date. Common to all of them is that the entity (device) to be at-
tested, called prover, sends a status report of its current software
conﬁguration to another party, called veriﬁer, to demonstrate that it
is in a known and, thus trustworthy, state. All existing attestation
techniques consider only a single prover and veriﬁer. Since mali-
cious software on the prover could forge this report, its authenticity
is typically assured by secure hardware [16, 26, 27, 42, 46, 51]
and/or trusted software [2, 24, 27, 29, 47, 48, 52]. Attestation
based on secure hardware is most suitable for advanced comput-
ing platforms, such as smartphones, tablets, laptops, personal com-
puters, and servers. However, underlying security hardware is of-
ten too complex and/or expensive for low-end embedded systems.
In contrast, software-based attestation [24, 29, 47, 48] require nei-
ther secure hardware nor cryptographic secrets. However, security
guarantees of software-based attestation methods rely on strong as-
sumptions, such as the adversary being passive while the attestation
protocol is executed and optimality of the attestation algorithm and
its implementation. They also rely on tight time constraints, on
strict estimation of round-trip time and on the existence of an out-
of-band authentication channel as no secrets are shared between
the prover and the veriﬁer. Such assumptions are hard to achieve in
practice [3] and restrict applicability of software-based attestation
to the one-hop setting. Hence, a secure and practical remote attes-
tation scheme requires minimal security features in hardware such

964as read-only memory (ROM) and memory isolation (e.g., memory
protection unit) [16, 17].

Consequently, designing efﬁcient and secure attestation of de-
vice swarms poses several challenges. In particular, in swarms with
dynamic topology, attestation needs to be combined with key man-
agement, network discovery, and routing in a secure and efﬁcient
way. Clearly, it is important to ensure that compromised devices
cannot evade detection during attestation and honest devices must
not be double-counted. Furthermore, computation and communi-
cation costs for the veriﬁer and (possibly many) provers should
be minimized. This requires a cumulative and efﬁcient attestation
scheme that cannot be instantiated by trivial combinations of exist-
ing attestation protocols. Moreover, a swarm attestation protocol
should ideally distribute its burden – including computation, com-
munication, and energy costs – over all devices in the swarm.
Contributions:
First Swarm Attestation Scheme: We design SEDA, Scalable Em-
bedded Device Attestation, which is, to the best of our knowledge,
the ﬁrst attestation scheme for large-scale swarms. SEDA repre-
sents the ﬁrst step in a new line of research on multi-device attesta-
tion. Although SEDA adheres to the common assumption – made
in most (single-prover) attestation techniques – of ruling out phys-
ical attacks on devices, we discuss mitigation techniques for such
attacks in Section 9.
Security Model & Analysis: We present the ﬁrst security model for
swarm attestation and demonstrate security of SEDA in this model.
Two Working Prototypes: We describe two concrete instantiations
of SEDA based on state-of-the-art security architectures for low-
end embedded systems: SMART [16] and TrustLite [25], the latter
based on an Intel research platform [44]. They demonstrate fea-
sibility of SEDA on swarms of low-end embedded devices with
minimal hardware security features.
Performance Analysis: We assess performance of two SEDA in-
stantiations and present simulation results for swarms with up to
1, 000, 000 devices, thus demonstrating SEDA’s scalability. Our re-
sults clearly indicate that SEDA performs signiﬁcantly better than
individually attesting each device separately.
Outline: We begin with an overview of swarm attestation (Sec-
tion 2) and our notation (Section 3). We then describe SEDA proto-
col in detail (Section 4), two implementations of it (Section 5) and
performance results (Section 6). We examine security of SEDA
(Section 7), discuss several extensions (Section 8) and revisit the
question of physical attacks (Section 9). Finally we summarize re-
lated work (Section 10).
2. SWARM ATTESTATION
2.1 Problem Description and System Model

A swarm S is a set of s devices with possibly different hardware
and software conﬁgurations, as shown in Figure 1. Devices are ini-
tialized and deployed by swarm operator OP in a trusted manner.
Table 1 summarizes our notation.
The goal of swarm attestation is to assure a veriﬁer VRF, which
may be different from OP, of S’s overall software integrity or lack
thereof. VRF may be a remote entity. An important property of
swarms is that each device can communicate only with its direct
neighbors [13, 19, 45]. S might be dynamic in terms of both topol-
ogy and membership. Device mobility might be voluntary (i.e.,
self-locomotion) or involuntary (i.e., guided by ambient factors).
Hence, S’s current topology may be unknown to OP and VRF.
The main idea is that S is trustworthy if all of its devices have been
deployed by OP, and are running a software conﬁguration certi-
ﬁed by OP, i.e., S is trustworthy if all its devices are successfully

attested by VRF. SEDA focuses on swarm attestation and leaves
policies to VRF. It guarantees that VRF reliably learns the total
number of participating and correctly operating devices.1 Note that
devices not responding to protocol messages2 cannot be attested
successfully and are considered compromised. When determining
the swarm’s current state, the distinction between compromised and
unreachable devices can be ignored, since, in each case, the device
is not functioning correctly.
2.2 Requirements Analysis
Objectives. A secure swarm attestation scheme must have the fol-
lowing properties:

• Property (1): Support the ability to remotely verify integrity
of S as a whole.
• Property (2): Be more efﬁcient than individually attesting
each device Di in S.
• Property (3): Not require VRF to know the detailed conﬁg-
uration of S (e.g., the type and software version of devices
and network topology).
• Property (4): Support multiple parallel or overlapping attes-
• Property (5): Be independent of the underlying integrity mea-

tation protocol instances.
surement mechanism used by devices in S.

Property (1) is the core objective of swarm attestation. Property (2)
is essential for scalability in large swarms. Property (3) simpliﬁes
attestation and is needed if system conﬁguration must not be dis-
closed to VRF. For example, in smart factories, the maintenance
may be outsourced, and maintenance staff may need to check over-
all trustworthiness of the production system while the exact setup
remains secret [30, 35, 56]. Property (4) is relevant to applica-
tions where multiple veriﬁers need to independently verify system
integrity without coordination. Property (5) is needed for extensibil-
ity, to support a wide range of single-device attestation mechanisms
and to be able to adapt to future attestation schemes, e.g., those that
allow detection of code-reuse attacks.
Adversary model. As common in the attestation literature [16,
24, 47, 48] we consider software-only attacks. This means that,
although the adversary, denoted as ADV, can manipulate the soft-
ware of (i.e., compromise) any device D in S, it cannot physically
tamper with any device. However, ADV can eavesdrop on, and ma-
nipulate, all messages between devices, as well as between devices
and VRF. Furthermore, we rule out denial-of-service (DoS) at-
tacks since ADV typically aims to remain stealthy and undetected
while falsifying the attestation result for VRF. This is also in line
with our primary goal of detecting device compromise that occurs
via remote malware infestations.
Nevertheless, we sketch out several approaches for mitigating phys-
ical attacks in Section 9 and address DoS attack mitigation tech-
niques in Section 7.
Device requirements.
In order to satisfy properties (1), (2) and
(3), a secure swarm attestation scheme should be able to remotely
verify integrity of each D and aggregate the results.These impose
the following requirements on each device D [16, 17]:

• Integrity measurement: It must be infeasible for ADV to tam-
per with the mechanism that attests integrity of D’s software.
• Integrity reporting: It must be infeasible for ADV to forge
the integrity measurement report sent from D to VRF.

1Section 8 describes a more efﬁcient variant of SEDA that uses
sampling.
2These devices are detected via a time-out mechanism at a lower
network layer.

965• Secure storage: It must be infeasible for ADV to access any

cryptographic secret(s) used by D as part of attestation.

In Section 5, we demonstrate viability of SEDA implemented on
top of two recent attestation architectures which satisfy the above
requirements with minimal hardware support: SMART [16] and
TrustLite [25].
Assumptions. Following recent literature on attestation of low-
end embedded systems [16, 17, 25], we assume that each D in
S satisﬁes minimal requirements for secure remote attestation, as
discussed above. Furthermore, following swarm robotics litera-
ture [13, 19, 45], we assume that D can communicate with all its
neighboring devices in S, and that the network is connected, i.e.,
each D is reachable, at least while the attestation protocol executes.
We consider all underlying cryptographic primitives and their im-
plementations to be secure. We also assume that OP is trusted.
Finally, we assume that swarm topology remains static for the du-
ration of a given attestation protocol instance. This does not pre-
clude so-called “herd mobility” (entire swarm moving as a whole)
or micro-mobility (devices move while retaining overall topology).
Topology can change between attestation protocol instances.
In
Section 8 we discuss how SEDA can be modiﬁed to allow mobility
of devices even during attestation.
3. PRELIMINARIES AND NOTATION
Let |M| denote the number of elements in a ﬁnite set M. If n
is an integer (or a bit-string) |n| means the bit-length of n. Let
m $← M denote the assignment of a uniformly sampled element
of M to variable m. Furthermore, let {0, 1}(cid:96) be the set of all
bit-strings of length (cid:96).
If E is some event (e.g., the result of a
security experiment), then Pr[E] denotes the probability that E oc-
curs. Probability ((cid:96)) is called negligible if, for all polynomials f,
((cid:96)) ≤ 1/f ((cid:96)) for all sufﬁciently large (cid:96) ∈ N.
Let A be a probabilistic algorithm. Then y ← A(x) means
that on input x, A assigns its output to variable y. We denote
with AB an algorithm A that arbitrarily interacts with algorithm B
while it is executing. The term prot [A : xA; B : xB; ∗ : xpub] →
[A : yA; B : yB] denotes an interactive protocol prot between two
probabilistic algorithms A and B. Hereby, A (resp. B) gets private
input xA (resp. xB) and public input xpub. While A (resp. B) is op-
erating, it can interact with B (resp. A). As a result of the protocol,
A (resp. B) outputs yA (resp. yB).
Signature scheme. A signature scheme is a tuple of (proba-
bilistic polynomial time) algorithms (genkeysign, sign, versig).
(sk , pk ) ← genkeysign(1(cid:96)sign ) outputs a secret signing key sk and
a public veriﬁcation key pk with security parameter (cid:96)sign ∈ N. On
input of message m and sk, sign outputs a signature σ on m, i.e.,
σ ← sign(sk ; m); versig(pk ; m, σ) ∈ {0, 1} veriﬁes σ given m
and pk.
Message authentication code.
A message authentication
code (MAC) is a tuple of (probabilistic polynomial time) algo-
rithms (genkeymac, mac, vermac). k ← genkeymac(1(cid:96)mac ) out-
puts a secret key k with security parameter (cid:96)mac ∈ N. h ←
mac(k; m) outputs a MAC digest h on input of m and k.
vermac(k; m, h) ∈ {0, 1} veriﬁes h on input of m and k.
4. PROTOCOL DESCRIPTION

SEDA has two phases: (1) an off-line phase whereby devices
are introduced into the swarm, and (2) an on-line phase performing
actual attestation. The off-line phase is executed only once and
consists of device initialization and device registration. The on-line
phase is executed repeatedly for every attestation request from a
veriﬁer VRF. In this phase, each device Di is attested individually

Table 1: Variables and parameters

Entities
OP
VRF
D1
Di
Swarm parameters

Swarm operator
Veriﬁer (can be distinct from OP)
Initiator (any device in S, selected by VRF)
Device i

Total number of devices in S
Number of neighbors of Di

s
gi
pi ≤ gi − 1 Number of children of Di in the spanning tree
Device parameters

Secret signing key of Di
Public signature veriﬁcation key of Di
Platform conﬁguration of Di(e.g., its code hash)
Identity certiﬁcate of Di (issued by OP)
Code certiﬁcate of Di (issued by OP)
Symmetric key shared between Di and Dj
Set of all symmetric keys of Di
Set of active global session identiﬁers stored on Di

sk i
pk i
ci
cert(pk i)
cert(ci)
kij
Ki
Qi
Protocol parameters

q

N
bi
βi

τi

h

σ

Global session identiﬁer
Nonce
Attestation result of Di
Number of devices successfully attested in the
subtree rooted at Di (excluding Di)
Total number of devices attested in the
subtree rooted at Di (excluding Di)
MAC digest
Digital signature

and accumulated attestation is reported to VRF. Figure 1 shows
a sample swarm formed initially of seven devices with an eighth
device D8 being initialized by the swarm operator OP and joining
It also shows VRF running an attestation protocol
the swarm.
instance.
4.1 Ofﬂine Phase
Device initialization. Each Di in a swarm S is initialized bythe
swarm operator OP with a software conﬁguration ci (e.g., a hash
digest of software binaries of Di) and a code certiﬁcate cert(ci)
signed by OP which guarantees that ci is a valid software conﬁg-
uration of Di.3 Furthermore, Di is initialized with a signing key
pair (sk i, pk i) along with an identity certiﬁcate cert(pk i) signed
by OP, guaranteeing that pk i belongs to Di. Each device is initial-
ized with the public key of OP in order to later verify cert(c) and
cert(pk ) of other devices. Note that, both cert(c) and cert(pk ) are
3Device certiﬁcates are issued and managed by OP using its
own public-key infrastructure (PKI). Industry consortia (e.g., the
Car Connectivity Consortium) are already deﬁning PKIs for cross-
certiﬁcation of devices.

966Figure 1: Swarm attestation in 8-device swarm.

∗ : cert(pk i), cert(pk j), cert(ci), cert(cj)(cid:3)

→ [Di : kij; Dj : kij] .

public information. Finally, Di initializes its list of active session
identiﬁers Qi to an empty list. More formally:

init(ci, 1(cid:96)) → (sk i, pk i, cert(pk i), cert(ci),Qi) .

Device registration. Whenever Di initially joins S or changes its
position it executes join with each new neighbor Dj. In Figure 1
D8 joins S and runs the protocol with its neighbors D5 and D7.
Through join Di learns cj of each of its neighbors by receiving Dj’s
cert(cj). If certiﬁcate veriﬁcation succeeds, Di stores cj for later
validation of Dj’s attestation reports.
If veriﬁcation of cert(cj)
fails, Di does not accept Dj as a neighbor.4

An attestation key kij, shared between Di and each neighbor
Dj is established during join. The set of attestation keys Di estab-
lished with its neighbors is denoted Ki. Key establishment can be
done using an authenticated key agreement protocol based on de-
vices’ sk i, sk j, cert(pk i) and cert(pk j). Alternatively, it can be
achieved using a key pre-distribution techniques, e.g., [7]. In fact,
any key establishment protocol can be used with SEDA as long as it
provides integrity of key agreement and secrecy of generated keys.
Formally:

join(cid:2)Di : sk i; Dj : sk j;

4.2 Online Phase
The online phase of SEDA includes two protocols: attest and
attdev. attest is initiated by VRF by contacting an arbitrary
D1 ∈ S, called the initiator. Starting from D1 attestation of S
is performed recursively using attdev. Eventually, D1 receives the
accumulated attestation result of all devices and reports it to VRF.
Single device attestation. Each attestation protocol instance has a
global session identiﬁer q. It is used to construct a spanning tree
over the entire swarm. Whenever Dj receives a new q from Di it
accepts Di as its parent and stores q in the list Qj of active session
identiﬁers. The spanning-tree5 is constructed from the communica-
tion graph, where two nodes are connected in the spanning-tree if
they are neighbors in the communication graph. Setting the max-
imum number of children per node inﬂuences the construction of
the spanning tree: it limits the fan-out of the tree and forces it to
grow in height, e.g., transforms mesh topologies into balanced span-
ning trees. This allows us to optimize SEDA’s performance, as dis-
cussed in Section 6. Dj attests all its children in this spanning tree.
It then accumulates the attestation results reported by its children,
which correspond to the subtrees rooted at each of them, and sends
the accumulated result along with an attestation report for itself to
its parent Di.
4If Di’s software is updated after it joins S, Di must securely com-
municate its new code certiﬁcate to all its neighbors.
5The spanning-tree is reusable if both the topology and the initiator-
node persist between attestation-runs

To attest each child Dk, Dj uses kjk and ck from the join pro-
tocol. The result of attdev for Di (parent of Dj) is a bit b = 1
if attestation of Dj was successful (b = 0 otherwise), the number
β of devices in the subtree rooted at Dj (excluding Dj) that have
been successfully attested, and the total number τ of devices in the
subtree rooted at Dj (also excluding Dj).

If Dj already participated in an attdev protocol instance with
global session identiﬁer q or does not respond (i.e., a time-out oc-
curs), the result of attdev for Di is b = 0, β = 0, and τ = −1 to
prevent double-counting. Formally:

attdev(cid:2)Di : kij; Dj : Qj,Kj, c(cid:48)j;∗ : q, cj

(cid:3)

→ [Di : b, β, τ ; Dj : −] .

Figure 1 shows a sample swarm with eight devices: D1 . . . D8.
The spanning tree is denoted by thick lines between devices and the
root is D1, which is selected by VRF to be the initiator.
Details of attdev are as follows: Di sends a nonce Ni and q to
Dj. If q is already in the list Qj of active session identiﬁers, Dj
responds with βj ← ⊥ and τj ← ⊥. Otherwise, Dj adds q to Qj
and runs the attdev protocol with each neighbor Dk. Eventually,
Dj receives attestation reports from all of its neighbors, accumu-
lates them into (βj, τj), authenticates (βj, τj) via MAC digest h0,
and attests itself to Di with h1. Di accepts if h0 and h1 are success-
fully veriﬁed.
Swarm attestation. VRF starts attestation of S by sending an
attestation request attest (containing a random challenge) to D1.
VRF can randomly chose any device in S as D1 or depending on
its location or preference. Recall that VRF might be remote, or
within direct communication range of one or more swarm devices.
Eventually, VRF receives an attestation report from D1. VRF
outputs a bit b = 1 indicating that attestation of S was successful,
or b = 0 otherwise. Formally:

attest(cid:2)VRF : −; D : Q,K, sk , c(cid:48);∗ : s, cert(pk ), cert(c)(cid:3)

→ [VRF : b; D : −] .

As shown in Figure 3, attest operates as follows: VRF starts
the protocol by sending a nonce N to D1. It, in turn, generates a
new q and runs attdev with all its neighbors, which recursively run
attdev with their neighbors. Note that N prevents replay attacks on
communication between VRF and D1 while the purpose of q is to
identify the protocol instance and to build the spanning tree. Even-
tually, D1 receives the accumulated attestation reports of all other
devices in S. Then, D1 accumulates these reports into (β, τ ), com-
putes σ over (β, τ ) and its own c, and sends its cert(pk ), cert(c),
(β, τ ), c, and σ to VRF. Using OP’s public key, cert(pk ) and
cert(c), VRF authenticates pk and c and veriﬁes σ. Attestation
succeeds if σ veriﬁes. If D1 does not respond to VRF (i.e., a time-
out occurs), swarm attestation fails. After responding to VRF, D1
starts the clear protocol to delete q from all devices.
Clear. Di sends q authenticated with kij to Dj. On receipt of q,
Dj removes q from its list Qj of active session identiﬁers and runs

967Figure 2: Protocol attdev

clear protocol with each neighbor. More formally:

clear [Di : q, kij; Dj : Qj,Kj;∗ : −] → [VRF : −; D : −] .

5. PROTOTYPE AND IMPLEMENTATION
In this section, we discuss two implementations of SEDA based
on SMART [16] and TrustLite [25] architectures. We chose these
architectures due to their minimal hardware assumptions, although
they provide different security properties and functional capabili-
ties, as discussed below.
SMART-based implementation. SMART [16] provides remote at-
testation for low-end embedded systems. Its main components are:
(1) a read-only memory (ROM), which stores program code used
for attestation and the attestation key k,6 and (2) a simple memory
protection unit (MPU), which controls access to ROM where k is
stored as shown in Figure 4. The idea is that program code in ROM
cannot be altered by any software running on the device, which en-
sures integrity of attestation code. MPU grants access to k only to
ROM code by checking whether the program counter is within the
ROM address space whenever k is accessed. This ensures that only
genuine attestation code can access k.

Our implementation of SEDA is based on a slightly modiﬁed ver-
sion of SMART, shown in Figure 4. The only difference from the

6Using one-time programmable ROM allows initializing each de-
vice with a distinct device-speciﬁc key during manufacturing.

Figure 4: Implementation based on SMART [16]

original SMART architecture is that MPU also controls access to
a small area of rewritable non-volatile memory, needed for storing
global session identiﬁers and attestation keys established as part of
the join protocol. In more detail, code for join, attest, attdev, and
clear as well as signing key sk are stored in ROM, which ensures
their integrity. The list of attestation keys K and the list of active
session identiﬁers Q (which need to be changed during the lifetime
of the device) are stored in rewritable non-volatile memory labeled
RAM in Figure 4. MPU controls access to ROM and RAM ac-

q,kij,cjDeviceDiβj,τj,h0,h1DeviceDjQj,Kj,c0jh0←mac(cid:0)kij;Nikqkβjkτj(cid:1)ifvermac(kij;Nikqkβjkτj,h0)=1thenelseb←0endifq,NiNi∈R{0,1}‘Nforeachkl∈Kj\{kij}doattdev(cid:2)Dj:kl;Dl:Ql,Kl,c0l;∗:q,cl(cid:3)→(cid:2)Dj:bl,βl,τl;Dl:−(cid:3)endforβj←βj+bl+βlβj←0,τj←0h1←mac(cid:0)kij;Nikqkc0j(cid:1)endififvermac(kij;Nikqkcj,h1)=1thenb←1elseb←0,β←0,τ←0τj←τj+1+τlifq∈QjthenelseendifQj←Qj∪{q}βj←⊥,τj←⊥ifβ6=⊥∧τ6=⊥thenβ←βj,τ←τjelseb←0,β←0,τ←−1endif968Figure 3: Protocol attest

cording to the table in Figure 4. For example, MPU ensures that
only join can read and write K (rule 2 in Figure 4). Note that com-
bined attestation code (attest, attdev, join and clear) constitute a
minimal software trusted computing base (TCB).
TrustLite-based implementation. TrustLite [25] is a security ar-
chitecture for embedded systems, based on Intel’s Siskiyou Peak
research platform [44]. It enables execution of arbitrary code, (e.g.,
attest and attdev) isolated from the rest of the system. Such iso-
lated code chunks are called trustlets. As in SMART, an MPU en-
sures that data can be accessed only by code of trustlets that owns
that data. Data access permissions depend on the currently exe-
cuting code – therefore TrustLite’s MPU is called execution-aware
memory protection unit (EA-MPU). EA-MPU can be used to con-
trol access to hardware components, such as peripherals. Authentic-
ity and conﬁdentiality of both code and data of trustlets are ensured
via secure boot.

TrustLite can be seen as a generalization of SMART. The main
difference is that memory access control rules of EA-MPU in
TrustLite can be programmed as required by trustlets. In contrast,
memory access control rules of SMART MPU are static. Also,
TrustLite supports interrupt handling for trustlets, while security-
critical code in ROM of SMART cannot be interrupted during exe-
cution.

We implemented SEDA on TrustLite as trustlets – join, attest,
attdev, and clear are each implemented as a single trustlet.
In-
tegrity of these trustlets is ensured by the secure boot component
secureBoot. EA-MPU controls access to ROM and RAM such
that only the SEDA trustlets can access secret data. For instance,
in Figure 5 the set of attestation keys K can only be written by join
(rule 3) and read by attest, attdev and clear (rule 4).
6. PERFORMANCE EVALUATION

We evaluated computation, memory, communication, and energy
costs of SEDA based on two implementations in Section 5. For the
evaluation we assume that the swarm is static throughout protocol
execution. However, in Section 8 we sketch out a protocol exten-
sion to handle highly dynamic swarms. Our evaluation results do

Figure 5: Implementation based on TrustLite [25]

not include the join protocol, mainly because it is expected to be ex-
ecuted seldom, perhaps only once per device. The costs of join are
in the same order as the costs of attest. Simulation results for our
implementation based on TrustLite are similar to those of SMART,
in terms of showing the efﬁciency of SEDA compared to traditional
attestation, and are therefore omitted. However, TrustLite is a more
advanced embedded device than SMART and has more computing
power. Thus, TrustLite can run SEDA considerably faster. For
more details you can refer to the technical report [4].
Computation cost. The dominating component of the computation
cost is due to cryptographic operations, e.g., MACs. Initiator D1,
which directly communicates with the veriﬁer VRF, computes one
digital signature and veriﬁes at most 2g MACs, where g is the num-
ber of D1’s neighbors. Every other device Di computes two MACs
and veriﬁes at most 2pi MACs, where pi ≤ gi − 1 and gi is the
number of neighbors of Di.
Communication cost. We implemented MAC as HMAC with
SHA-1, and the signature scheme with ECDSA, where (cid:96)mac = 160
and (cid:96)sign = 320. Also, we use (cid:96)N = 160, (cid:96)q = 64, and 64-bit

sVeriﬁerVcert(pk),cert(c),β,τ,σDeviceDQ,K,sk,c0,cert(pk),cert(c)σ←sign(sk;Nkβkτkc0)elseb←0endifN∈R{0,1}‘Nattdev(cid:2)D:ki;Di:Qi,Ki,c0i;∗:q,ci(cid:3)→(cid:2)D:bi,βi,τi;Di:−(cid:3)β←β+bi+βiβ←0,τ←0τ←τ+1+τiNforeachki∈Kdoendforifversig(pk;Nkβkτkc,σ)=1∧β=τ=s−1thenb=1q$←{0,1}‘qforeachki∈Kdoclear[D:q,ki;Di:Qi,Ki;∗:−]→[V:−;D:−]endforQ←Q∪{q}Q←Q\{q}969Table 2: Performance of cryptographic functions

Function

Run-time (8 MHz)
SMART [16] (ms)

Create

Verify

Run-time (24 MHz)
TrustLite [25] (ms)
Create
Verify

HMAC (SHA-1)
ECDSA
PRNG (20 Bytes)

48

56, 900

160

48
—
—

0.3

347.2

3.8

0.3
—
—

Figure 6: Run-time of SEDA per device

Table 3: Performance of SEDA per device as function of the
number of neighbors g
Node Type

Run-time (8 MHz)
SMART [16] (ms)

Run-time (24 MHz)
TrustLite [25] (ms)

Initiator
Other Devices

56, 900 + 256g
96 + 256(g − 1)

347.2 + 4.4g

0.6 + 4.4(g − 1)

counter values for β and τ. This means that global session iden-
tiﬁers and counter values are 8 bytes, nonces are 20 bytes, MACs
are 20 bytes, signing and veriﬁcation keys are 20 bytes, signatures
are 40 bytes, and certiﬁcates are 20 + 40 = 60 bytes. Maximum
communication overhead for D1 is sending 48g + 176 and receiv-
ing 20 + 56g bytes. For every other Di, communication is at most
sending 56gi + 68 and receiving 68gi + 56 bytes.
Memory cost. Each Di must store at least: (1) one q for the du-
ration of each swarm attestation protocol instance, (2) its signing
key pair (sk , pk ), (3) its identity certiﬁcate cert(pk ), (4) code
certiﬁcate cert(c), and (5) the set of attestation keys K shared
with its neighbors. Hence, storage costs can be estimated as
20gi + 168 bytes, where gi is the number of Di’s neighbors. Note
that low-end embedded systems, such as TI MSP430 (which are tar-
geted by SEDA), provide at least 1, 024 bytes of non-volatile Flash
memory. Using only half of that sufﬁces for 12 neighbors, while,
in most applications (such as smart factories and vehicular ad-hoc
networks) devices will most likely have fewer neighbors or more
memory resources.
Run-time. SEDA is designed such that all devices at the same
height in the spanning tree can perform computation in parallel.
However, MAC veriﬁcation at height l depends on that at height l−
1. Hence, overall run-time of the protocol depends on the spanning
tree height7 d = f (s) ∈ O(log(s)). Another factor that affects
run-time performance is the average number of neighbors of each
device.

Let tmac, tsign, tprng, and ttr represent the times needed by a de-
vice to compute mac or vermac, sign, to generate 20 random bytes,
and to transmit one byte of information, respectively. Total run-
time t of the protocol can thus be estimated as:

d(cid:88)

(cid:17)

(cid:16)

d(cid:88)

(cid:17)

t ≤(cid:16)

280 + 168d +

gi

ttr +

2 + 4d +

gi

tmac

i=0

i=0

+ (d + 1)tprng + tsign

(1)

Run-times of cryptographic operations in SMART [16] are
shown in Table 2.8 Overall performance results are depicted in

7Note that tree height d does not include the root, e.g., d = 0 for a
tree with only the root.
8Run-time of HMAC was reported in [16]; run-times of ECDSA
and PRNG on SMART are estimations based on HMAC run-time.

Figure 7: Energy consumption of SEDA

Table 3 and Figure 6. As Figure 6 shows, run-time of SEDA on a
single device is linear in the number of its neighbors, as reﬂected
in Equation 1. Run-time of the initiator is longer than that of other
devices, due to computation of sign. Note that, the run-time of
Trustlite is linear although it looks constant due to the scale of the
graph. Furthermore, it is faster than the SMART implementation
since TrustLite hardware runs at a higher clock speed.
Energy costs. Let Esend, Erecv, Eprng, Emac, and Esign denote en-
ergy required to send one byte, receive one byte, generate 20 ran-
dom bytes, compute mac or vermac, and sign, respectively. Esti-
mated energy consumption E of the initiator is:
E ≤ (176 + 68g)Esend + (20 + 56g)Erecv

+ 3gEmac + gEprng + Esign

Meanwhile, energy consumption Ei for every other device is:

Ei ≤ (56 + 68gi)Esend + (68 + 56gi)Erecv

+ (3 + 3gi)Emac + giEprng

(2)

Figure 7 shows the energy consumption estimates of SEDA. Our
estimates are based on two types of sensor nodes.9 MICAz and
TelosB fall into the same class of low-end embedded devices as
SMART and TrustLite. We used previously reported energy con-
sumption for communication and cryptographic operations of MI-
CAz and TelosB [14] to estimate energy consumption of SEDA.

Energy consumption is linear in the number of device’s neigh-
bors, per Equation 2. Hence, if the number of neighbors is about
the same for every device, energy consumption is evenly distributed
over the whole swarm.
Initiator’s energy consumption is higher
than that of other devices, mainly due to computing sign. How-
ever, the cost of sign can be amortized among all devices by using
a different initiator in each attestation instance.
Simulation results. To evaluate performance of SEDA for large
numbers of devices, we simulated it in the OMNeT++ [38] simu-

9Neither TurstLite nor SMART are available as manufactured
chips. FPGA implementations consume more energy than manu-
factured chips.

970Figure 8: Performance of SEDA for tree topologies

Figure 10: Performance of SEDA for swarms with varying
numbers of devices and tree topology, as a function of the num-
ber of neighbors per device

Figure 9: Performance of SEDA for chain and star topologies

lation environment. We implemented the protocol at the applica-
tion layer and simulated cryptographic operations by delays that
correspond to their real execution times when implemented on
SMART [16] and TrustLite [25]. We also simulated the naïve alter-
native, where VRF attests all devices individually. We excluded
VRF’s veriﬁcation time from our simulations; it is constant in
SEDA and linear in the number of devices for the naïve approach.
Simulations use 20 ms as average end-to-end delay of a wireless
communication link between two devices, which is the average in
ZigBee sensor networks [50]. We simulated some popular network
topologies: a chain, a star, and a tree, with varying numbers of
child nodes (2, 4, 8, and 12). We chose these topologies since
they reﬂect the best and worst case scenarios, in terms of efﬁciency
for SEDA. Moreover, we varied the number of devices from 10 to
1, 000, 000. Simulation results for the SMART-based implementa-
tion are shown in Figures 8, 9 and 10.

For tree topologies, run-time of SEDA is logarithmic in the num-
ber of devices (Figure 8) and linear for chain and star topologies
(Figure 9). The optimal number of neighbors per device with re-
spect to a given swarm size depends on the network and device
characteristics (mainly the time to compute MACs and network
delays). Figure 10 shows run-time of SEDA as a function of the
number of neighbors per device for different swarm sizes. For
1,000 and 10,000 devices, run-time decreases along with the num-
ber of neighbors up to a certain threshold and then starts to grow.
We believe that this occurs because higher number of neighbors
inﬂuences SEDA’s performance in two ways: (1) it increases par-
allelism and decreases spanning-tree depth, thus lowering overall
runtime; and (2) it increases runtime for individual devices, result-
ing in longer overall runtime. Hence, performance increases with
number of neighbors until the effect of (2) overshadows that of (1).
The optimal number of neighbors depends on the total number of
nodes, regardless of swarm topology and density. For example, the
optimal number of neighbors in swarms with 10 and 100 devices is
2; it grows to 4 for swarms of 1,000 and 10,000 devices.

Figure 11 compares performance of SEDA to the naïve approach,
where each device is attested individually: SEDA’s performance
protocol is signiﬁcantly better than that of the naïve approach,

Figure 11: Performance of SEDA compared to the naïve ap-
proach

which is quadratic in the number of devices for chain topologies,
and linear for tree topologies.

Evaluation results in Figures 8, 9, and 10 show that SEDA per-
forms best in swarms that allow establishing spanning trees with a
limited number of children. The reason is that tree topologies allow
attestation of multiple nodes in parallel and limiting the number of
children also limits the number of MAC veriﬁcations performed by
each node. However, even for topologies that are not conducive to
such spanning trees (e.g., star and chain), SEDA performs signif-
icantly better than the naïve approach, as illustrated in Figure 11.
Furthermore, in such worst case scenarios the random sampling ap-
proach discussed later in Section 8 can be used to reduce SEDA’s
run-time.

ADV

7. SECURITY ANALYSIS
The goal of swarm attestation is for a veriﬁer VRF to accept
only if all devices in a swarm S are running a software certiﬁed by
the swarm operator OP. This is formalized by a security experi-
, where an adversary ADV interacts with devices in
ment Exp
S and VRF. Speciﬁcally, ADV modiﬁes the software of at least
one device D, i.e., compromises that D. ADV can eavesdrop on,
delete, and modify any message sent from any D ∈ S and VRF.
Furthermore, ADV can send arbitrary messages to any D ∈ S
. After a polynomial number (in terms of the security parameters
(cid:96)N , (cid:96)q, (cid:96)mac, and (cid:96)sign) of steps by ADV, VRF outputs its deci-
sion bit b = 1 indicating that attestation of S was successful, or
b = 0 otherwise. The result is deﬁned as the output of VRF, i.e.,
Exp

= b. A secure swarm attestation scheme is deﬁned as:

ADV

attestation scheme is secure if Pr(cid:2)b = 1|Exp

DEFINITION 1

(1(cid:96)) = b(cid:3) is neg-

(SECURE SWARM ATTESTATION). A swarm

ligible in (cid:96) = f ((cid:96)N , (cid:96)q , (cid:96)mac, (cid:96)sign), where function f is polynomial
in (cid:96)N , (cid:96)q, (cid:96)mac, and (cid:96)sign.

ADV

971THEOREM 1

(SECURITY OF SEDA). SEDA is a secure
swarm attestation scheme (Deﬁnition 1) if the underlying signature
and MAC scheme are selective forgery resistant.

accepts

PROOF (SKETCH) OF THEOREM 1. VRF
it

only
if
receives a message (β, τ, σ, cert(pk ), cert(sk )) where
versig(pk ; N(cid:107)β(cid:107)τ(cid:107)c, σ) = 1, pk is the public key in cert(pk ), N
is the nonce previously sent by VRF, c is the reference software
conﬁguration in cert(c), and β = τ = s − 1. We distinguish
among two cases: (1) ADV modiﬁes software conﬁguration of
the initiator device D1 interacting with VRF; (2) ADV modiﬁes
software conﬁguration of any other Dj ∈ S. Note that these two
cases and all combinations of them cover all possibilities of ADV
modifying software conﬁguration of at least one device in S.
We start with the case where ADV modiﬁes software conﬁgura-
tion of D1. Since according to the assumption made in Section 2,
ADV cannot tamper with code performing integrity measurements
on D and code of attest, c(cid:48) is different from c in cert(c) and
σ = sign(sk ; N(cid:107)q(cid:107)β(cid:107)τ(cid:107)c(cid:48)). This means that ADV must forge
σ to make VRF accept. Due to selective forgery resistance of the
signature scheme, ADV can forge σ with probability negligible in
(cid:96)sign.
Next, we consider the case of ADV modifying software of any
other Dj. Let Di be the device that veriﬁes software integrity of
Dj, i.e., its parent in the spanning tree. Again, since ADV can-
not tamper with Dj’s code performing software integrity measure-
ments and code of attdev, c(cid:48)j will be different from cj expected
by Di and h1 = mac(kij; Ni(cid:107)q(cid:107)c(cid:48)j). Hence, ADV must either
forge h1 or compensate for the fact that attestation fails for Dj.
Due to selective forgery resilience of MAC, ADV can forge h1
with probability negligible in (cid:96)mac. To compensate for failed attes-
tation of Dj, ADV could increase βj or decrease τj reported to
Di, or ADV could cause another device Dl send multiple attesta-
tion reports. Furthermore, β and τ are computed and authenticated
with h0 = mac(kij; Ni(cid:107)q(cid:107)βj(cid:107)τj) by code of attdev, which can-
not be tampered with by ADV. Now, ADV could forge h0 or the
report (βl, τl) of a neighbor Dl of Dj, which is used as input to
computation of (βj, τj). However, (βl, τl) are authenticated via
mac(kij; Nj(cid:107)q(cid:107)βl(cid:107)τl). Moreover, due to global session identiﬁer
q included in MAC authenticating the accumulated attestation re-
port, ADV cannot cause any device in S to send its attestation
report twice for the same value of q. Hence, in both cases, ADV
succeeds with probability negligible in (cid:96)mac.
This means that the probability of ADV making VRF accept
in the case where ADV modiﬁed software conﬁguration of at least
one device in S is negligible in (cid:96)sign and (cid:96)mac.

8. PROTOCOL EXTENSIONS

In this section we discuss several variants and extensions of
SEDA which go beyond the scope of the adversary model described
in Section 2.2.
Identifying compromised devices. In some applications it may be
necessary to identify compromised devices. SEDA can be easily ex-
tended to report the identiﬁers of devices whose software integrity
could not be veriﬁed. Speciﬁcally, whenever a device Di detects
that one of its neighbors Dj reported a software conﬁguration c(cid:48)j
that is different from expected software conﬁguration cj, Di ap-
pends the identiﬁer of Dj to its report. Eventually, VRF receives
a complete list of identiﬁers of all devices that could not be attested
successfully. However, this approach increases message complex-
ity and is best suited for small swarms or applications where the
number of compromised devices is expected to be low.

Devices with different priorities. In some applications some de-
vices may be more important than others. For instance, in a wireless
sensor network (WSN), software integrity of a cluster head may
be much more important than software integrity of a sensor node.
SEDA can support such scenarios by weighting attestation results.
Speciﬁcally, when attesting a high-priority device, counters β and
τ are not incremented by one but by a weighted factor.
Random sampling. Performance of SEDA in a very large swarm S
can be improved by attesting only a randomly sampled statistically
representative subset S(cid:48) ⊂ S. In this case, the veriﬁer VRF gets
assurance that with probability p all devices in S are authentic and
running certiﬁed software. Speciﬁcally, VRF sends the desired
sample set size z together with nonce N in attest. All devices in
S broadcast z along with a global session identiﬁer q in attdev to
their neighboring devices. A global deterministic function which
takes the device identity as a parameter (along with other parame-
ters like q, z, s) is used to determine if a device Dj ∈ S \ {D} is
to be part of S(cid:48). This way the parent of each Dj knows if Dj needs
to be attested and can detect if Dj does not provide an attestation
report. Finally, only attestation results of devices in S(cid:48) are accu-
mulated and reported to VRF. As a result, VRF is assured that –
with a certain conﬁdence level and conﬁdence interval – attestation
result of S(cid:48) is also valid for S. For example, in swarms with more
than 105 devices only about 9 % of devices need to be attested to
achieve a conﬁdence level of 95 % and a conﬁdence interval of 1 %.
Software updates. SEDA allows updating device software ver-
ifying whether the update has been performed correctly. More
concretely, new software comes with a code certiﬁcate cert(cnew).
After new software has been installed on device Di,
it sends
cert(cnew) authenticated with keys in Ki to all its neighbors, which
then update their reference software conﬁguration for Di to cnew, if
veriﬁcation of cert(cnew) was successful. Otherwise, they keep the
old software conﬁguration. To prove that software update has been
performed successfully, Di can either attest itself to all its neigh-
bors using keys in Ki (similar as in attdev), or to an external veri-
ﬁer using its secret key sk i (similar as in attest). Roll-back attacks,
where an adversary ADV installs old software versions (that may
contain exploitable security vulnerabilities) are detected by VRF
when attesting the swarm.
Highly dynamic swarms. SEDA can be extended to support
highly dynamic swarms that change their topology even while the
attestation protocol is executing.
In this case SEDA generates a
virtual spanning tree, i.e., nodes which are neighbors in the span-
ning tree may not be neighbors in the topology after it has changed.
An appropriate routing mechanism is used to ensure that messages
of child nodes are delivered to parent nodes. However, this basic
approach increases communication overhead of SEDA since mes-
sages must be sent over multiple hops.
Denial of Service (DoS) Attack Mitigation. In general, DoS at-
tacks are hard to mitigate. SEDA is designed to use mostly sym-
metric cryptography, thus making it less appealing for DoS attacks.
However, ADV can still target portions of SEDA that use asym-
metric cryptography, i.e., join and attest. For example, a compro-
mised D can send fake join requests with incorrect certiﬁcates to
its neighbors. This would cause each neighbor to waste resources,
since verifying public key certiﬁcates is computationally expensive.
Mitigating such attacks can be done by: (1) limiting join request fre-
quency, or (2) processing join requests with lower priority. Indeed,
some current embedded security architectures with support for real-
time execution, such as TyTAN [5], can handle certain events (e.g.,
join requests) with low priority. This allows system resources to be
preferentially allocated to more critical tasks, while assuring that

972only otherwise idle CPU cycles are dedicated to processing (poten-
tially malicious) join requests.

9. PHYSICAL ATTACKS

In some swarm settings it is reasonable to assume that physical
attacks are either impossible or unlikely, e.g., automotive, avionics,
shipboard, or satellite. In these examples, the swarm is either phys-
ically unreachable and/or has a secure perimeter. However, in other
scenarios, it might be infeasible to assure physical security of all
devices, e.g., drones (or robots) used for military, surveillance, law
enforcement and prospecting purposes, or devices used in factory
or building automation. Since in SEDA aggregation of individual
device attestation results is done within the swarm, if ADV learns
all keys of just one device, it can forge the attestation result for that
device as well as any of its descendants in the spanning tree. Fur-
thermore, an adversary ADV can create clones of the compromised
device and spread them across the swarm. Consequently, we need
to expand our adversary model to include the possibility of a de-
vice being captured and physically attacked to extract keys and/or
modify software. We now sketch out several mitigation techniques.
PUF-based attestation. Physical unclonable functions (PUFs) are
(believed to be) tamper-resistant primitives that can be integrated
into attestation protocols to mitigate physical attacks. PUFs are
based on the variations inherently present in various hardware com-
ponents of a computing device, such as memory. PUFs can be used
for device identiﬁcation and authentication, or as a seed for random
number generation. Uniqueness of components upon which PUFs
are constructed comes from variations in the manufacturing pro-
cesses which are assumed not to be controllable by the adversary,
and thus are not clonable. Therefore, an on-board PUF can thwart
a physical attack that aims to clone a compromised device. Also,
since components used for PUFs, such as on-chip static random-
access memory (SRAM), are anyhow part of the device (regardless
of their use as PUFs) additional costs of PUFs are minimal. Several
approaches to PUF-based attestation have been proposed [26, 49].
However, all PUF-based attestation schemes impose additional re-
quirements on the device. Furthermore, recent work on PUF secu-
rity demonstrated that conjectured security of certain PUF families,
such as Arbiter PUFs, does not hold in practice [33], speciﬁcally,
their unpredictability and unclonability properties.
Double veriﬁcation. The basic idea for double veriﬁcation is
to make attestation and aggregation secure against one physically
compromised device, i.e., whose keys are known to ADV. This can
be achieved by mandating that integrity veriﬁcation of each device
Di be done by both its parent and its grandparent in the spanning
tree. This idea was also used in [22] in order to make hop-by-hop
aggregation secure against the compromise of one node.
In par-
ticular, upon joining the swarm, each Di shares a symmetric key
ki with every one-hop and two-hop neighbor. At attestation time,
(βi, τi, c) are authenticated using keys shared with both the parent
and the grandparent. Thus, one fully-compromised device would
be unable to forge the attestation response of its neighbors. This
extension is secure as long as no two neighboring devices are phys-
ically compromised. However, it involves extra computation and
communication costs.
Absence detection. As in prior literature on WSN security, we as-
sume that, in order to physically attack a device, ADV has to take
it out of the ﬁeld for a certain amount of time [11], e.g., to dis-
assemble its components in order to extract its secrets. Therefore,
absence detection of at least one device can be a sign of a physical
attack. Recall that we earlier assumed that the swarm is always con-
nected. In a static swarm, a device can detect whenever a neighbor

is missing by running a periodic heartbeat check with each neigh-
bor, using a current shared key. If a neighbor disappears, the device
can ﬂood the swarm with the announcement reﬂecting the missing
device. However, the same is hard to achieve in a dynamic swarm
where topology can change unpredictably. We consider two alter-
natives overviewed below. They assume: (1) global knowledge of
some x < X, where X denotes the minimum time ADV needs to
take a victim device out of circulation, for physical attack purposes,
and (2) loosely synchronized clocks among all swarm devices.
Option 1: The easiest option is for a swarm S to periodically
self-check by running SEDA without an explicit veriﬁer request.
This requires almost no extra functionality, except one: we use the
SEDA extension to identify compromised devices, as described in
section 8. However, instead of identifying compromised devices,
we identify all present, uncompromised ones. Suppose that, after
every x-long interval, all devices deterministically select the device
that will serve as the root of the spanning tree – D1, e.g., by taking
the hash of current time modulo s, where s is the total number of
devices. Then, D1 acts as prescribed by SEDA, with the aforemen-
tioned extension. Once it receives all reports from all direct neigh-
bors, D1 identiﬁes nodes from a master list that are missing from
the current list and informs the rest of the swarm of their identities.
An optimization of the ﬁrst approach is to create a special-
purpose version of SEDA that works in much the same way as
described above, except that, instead of full-blown attestation, the
self-checking protocol simply veriﬁes the presence (but not soft-
ware integrity) of each device. In other words, communication re-
mains the same, while computation for each Di becomes negligible;
Di simply replies to its parent with just a list of identities of present
(i.e., alive and responsive) devices in its subtree.
Option 2: Another mitigation technique is via periodic fully dis-
tributed swarm self-checking via link state-like veriﬁcation.
In
brief, after each interval of duration x, every Di broadcasts – over
existing pairwise secure channels – an update to its neighbors. An
update includes at least the device identiﬁer and current time-stamp.
For each update received from Dj, Di re-broadcasts it to its other
neighbors. It is easy to see that this approach generates a lot of ex-
tra trafﬁc since every device’s update message is ﬂooded through-
out the swarm; each device forwards and receives O(s) messages
per protocol instance. At the end of each self-checking, Di collects
a list of all current devices and compares it against its master list.
Any device on the latter that is absent from the former is assumed
to be untrusted from here on, i.e., it is potentially physically com-
promised.
Implications. Both physical attack countermeasures outlined
above have certain consequences for SEDA. Notably, due to dis-
tributed maintenance of a master list, seamless introduction of new
devices into an already deployed swarm is no longer possible. How-
ever, this can be easily remedied by requiring a new device to “an-
nounce” its presence via a public key signature-based authenticated
message that includes appropriate certiﬁcates. Upon receipt of such
a join announcement, each current device can independently au-
thenticate it and add the new device to its master list. Among the
solutions explained above, Absence Detection is most suited to our
protocol. We will include a thorough security and performance
analysis of this technique in the technical report [4].

10. RELATED WORK
Attestation. Numerous remote attestation techniques have been
proposed. Common to all of them is that the prover sends a status
report of its current software conﬁguration to another platform to
demonstrate that it is in a known and thus trustworthy state. Au-

973thenticity of this report is typically assured by secure hardware [16,
26, 27, 42, 46, 51] and/or trusted software [2, 24, 27, 29, 47, 48, 52].
Attestation based on secure hardware is often too complex and/or
expensive for low-end embedded systems. Software-based attesta-
tion [24, 29, 47, 48] does not require secure hardware and does not
use cryptographic secrets. However, security properties of software-
based attestation typically rely on strong assumptions, such as the
adversary being passive while the attestation protocol is executed
and optimality of the attestation algorithm and its implementation,
that are hard to achieve in practice [3]. Hence, a secure and practi-
cal attestation scheme requires at least some basic security features
in hardware [16, 17, 25]. SEDA follows this philosophy and uses
only minimal security functionalities in hardware such as read only
memory (ROM) or lightweight memory access control extensions.
Moreover, existing attestation schemes consider only a single
prover and veriﬁer and do not support efﬁcient attestation of a large
number of devices. We are aware of only one proposal to attest
multiple provers running the same software at once [41]. The idea
is that the veriﬁer does not verify each individual attestation report,
but just compares integrity measurements of multiple provers. In
contrast, our attestation scheme supports a large number of provers
running the same or different software and distributes veriﬁcation
of attestation reports over the whole swarm.
Secure boot. With secure boot, integrity of a device’s conﬁgura-
tion is not veriﬁed by an external entity but by the device itself [2].
Secure boot ensures that only a known and trustworthy software
can be loaded on a device. Hence, secure boot is limited to verify-
ing software integrity of a device at load-time. Attestation enables
integrity veriﬁcation of a system at any point in time.
Secure data aggregation. Secure data aggregation aims at re-
ducing communication overhead in WSNs by combining data re-
ported by individual sensor nodes while preserving authenticity
of this data. Some approaches are based on cryptographic tech-
niques [8, 9, 28, 32, 40, 54]. Others rely on trust relations [39]
or witness-based solutions [15]. However, they require the entire
swarm to share global keys [32], or involve computationally ex-
pensive asymmetric cryptography [28]. Further, most proposed ag-
gregation techniques have a high computation and communication
complexity [10, 15, 37]. SEDA overcomes these limitations by ag-
gregating attestation results similar to [31, 55], leveraging minimal
hardware security features.
Random sampling. Similar to the statistical sampling approach
discussed in Section 8, Secure Implicit Sampling [34] aims to de-
tect whether some nodes in a sensor network failed to receive a
broadcast message. The idea is that a randomly chosen subset of the
nodes must reply to the broadcast with an authenticated acknowl-
edgment. Security of the scheme is based on infeasibility of ADV
correctly predicting the randomly sampled subset.
Sensor networks. There is a large body of literature on sensor and
ad-hoc networks. Most of it concerns topics such as secure key
management [18, 53], secure routing [20, 57], and secure broad-
casting [1, 49]. However, we are not aware of any work on integrity
veriﬁcation of a large number of devices in this area.

11. CONCLUSIONS

We presented SEDA, the ﬁrst efﬁcient attestation protocol for
device swarms, i.e., systems consisting of large numbers of hetero-
geneous devices with dynamic topology. We constructed a security
model for swarm attestation and showed security of SEDA against
software-only attacks in this model. We also discussed some direc-
tions for mitigating physical attacks on devices. We demonstrated
feasibility of SEDA on low-end embedded platforms via two con-

crete implementations based on recently proposed security archi-
tectures for embedded devices: SMART [16] and TrustLite [25].
Evaluation results demonstrate efﬁciency of SEDA for swarms of
up to 1, 000, 000 devices. Advantages of SEDA include: (1) re-
duced overall protocol runtime; (2) constant veriﬁer overhead; as
well as (3) lower and evenly distributed overhead. Furthermore, the
veriﬁer does not need any prior knowledge about devices or their
conﬁguration.

Future work includes optimizing SEDA for highly dynamic
swarms and minimizing required device assumptions by reducing
the amount of code and data to be protected in hardware. More-
over, we plan to investigate the case whereby a subset of devices
do not have hardware security features and can only be attested via
software-based attestation techniques. Another future direction is a
swarm attestation mechanism that can detect code-reuse attacks.
Acknowledgement
We thank the anonymous reviewers and, in particular, Roberto Di
Pietro for his constructive feedback. This work has been co-funded
by the German Science Foundation as part of project S2 within the
CRC 1119 CROSSING, EC-SPRIDE, and the Intel Collaborative
Research Institute for Secure Computing (ICRI-SC).
References
[1] N. Ababneh, S. Selvakennedy, and K. Almi’Ani. NBA: A
novel broadcasting algorithm for wireless sensor networks.
In IFIP International Conference on Wireless and Optical
Communications Networks, 2008.

[2] W. Arbaugh, D. Farber, and J. Smith. A secure and reliable
bootstrap architecture. In IEEE Symposium on Security and
Privacy, 1997.

[3] F. Armknecht, A.-R. Sadeghi, S. Schulz, and C. Wachsmann.
A security framework for the analysis and design of software
attestation. In ACM Conference on Computer and
Communications Security, 2013.

[4] N. Asokan, F. Brasser, A. Ibrahim, A.-R. Sadeghi,
M. Schunter, G. Tsudik, and C. Wachsmann. Seda.
Technical report. URL https://trust.cased.de/
publications/publication-details/?tx_
bibtex_pi1%5Bpub_id%5D=TUD-CS-2015-1195.
[5] F. Brasser, B. El Mahjoub, A.-R. Sadeghi, C. Wachsmann,

and P. Koeberl. Tytan: Tiny trust anchor for tiny devices. In
Proceedings of the 52Nd Annual Design Automation
Conference, 2015.

[6] E. Byres and J. Lowe. The myths and facts behind cyber

security risks for industrial control systems. Technical report,
PA Consulting Group, 2004.

[7] S. A. Camtepe and B. Yener. Key distribution mechanisms

for wireless sensor networks: a survey. Technical report,
2005.

[8] H. Chan, A. Perrig, and D. Song. Secure hierarchical
in-network aggregation in sensor networks. In ACM
Conference on Computer and Communications Security,
2006.

[9] H. Chan, A. Perrig, B. Przydatek, and D. Song. SIA: Secure

information aggregation in sensor networks. Journal of
Computer Security, 2007.

[10] C.-M. Chen, Y.-H. Lin, Y.-C. Lin, and H.-M. Sun. RCDA:

Recoverable concealed data aggregation for data integrity in
wireless sensor networks. IEEE Transactions on Parallel and
Distributed Systems, 2012.

[11] M. Conti, R. Di Pietro, L. V. Mancini, and A. Mei. Emergent

properties: Detection of the node-capture attack in mobile
wireless sensor networks. In Proceedings of the First ACM
Conference on Wireless Network Security, 2008.

[12] A. Costin, J. Zaddach, A. Francillon, and D. Balzarotti. A
large-scale analysis of the security of embedded ﬁrmwares.
In USENIX Security Symposium, 2014.

974[13] E. ¸Sahin. Swarm robotics: From sources of inspiration to

domains of application. In Swarm Robotics. 2005.

[14] G. de Meulenaer, F. Gosset, O.-X. Standaert, and O. Pereira.

On the energy cost of communication and cryptography in
wireless sensor networks. In IEEE International Conference
on Wireless and Mobile Computing, 2008.

[15] W. Du, J. Deng, Y.-S. Han, and P. Varshney. A witness-based

approach for data fusion assurance in wsn. In IEEE Global
Telecommunications Conference, 2003.

[16] K. Eldefrawy, G. Tsudik, A. Francillon, and D. Perito.

SMART: Secure and minimal architecture for (establishing a
dynamic) root of trust. In Network and Distributed System
Security Symposium, 2012.

[17] A. Francillon, Q. Nguyen, K. B. Rasmussen, and G. Tsudik.

A minimalist approach to remote attestation. In Design,
Automation & Test in Europe, 2014.

[18] F. Gandino, B. Montrucchio, and M. Rebaudengo. Key

management for static wireless sensor networks with node
adding. IEEE Transactions on Industrial Informatics, 2014.
[19] F. Higgins, A. Tomlinson, and K. M. Martin. Threats to the

swarm: Security considerations for swarm robotics.
International Journal on Advances in Security, 2009.

[20] Y.-C. Hu, A. Perrig, and D. Johnson. Packet leashes: A

defense against wormhole attacks in wireless networks. In
IEEE Computer and Communications, 2003.

[21] A. G. Illera and J. V. Vidal. Lights off! The darkness of the

smart meters. In BlackHat Europe, 2014.

[22] P. Jadia and A. Mathuria. Efﬁcient secure aggregation in

sensor networks. In High Performance Computing - HiPC
2004, Lecture Notes in Computer Science. 2005.

[23] M. E. Kabay. Attacks on power systems: Hackers, malware,

2010.

[24] R. Kennell and L. H. Jamieson. Establishing the genuinity of
remote computer systems. In USENIX Security Symposium,
2003.

[25] P. Koeberl, S. Schulz, A.-R. Sadeghi, and V. Varadharajan.

TrustLite: A security architecture for tiny embedded devices.
In European Conference on Computer Systems, 2014.

[26] J. Kong, F. Koushanfar, P. K. Pendyala, A.-R. Sadeghi, and

C. Wachsmann. PUFatt: Embedded platform attestation
based on novel processor-based PUFs. In Design Automation
Conference, 2014.

[27] X. Kovah, C. Kallenberg, C. Weathers, A. Herzog, M. Albin,
and J. Butterworth. New results for timing-based attestation.
In IEEE Symposium on Security and Privacy, 2012.

[28] V. Kumar and S. Madria. Secure hierarchical data

aggregation in wireless sensor networks: Performance
evaluation and analysis. In IEEE International Conference
on Mobile Data Management, 2012.

[29] Y. Li, J. M. McCune, and A. Perrig. VIPER: Verifying the
integrity of peripherals’ ﬁrmware. In ACM Conference on
Computer and Communications Security, 2011.

[30] J. Liu, Y. Xiao, S. Li, W. Liang, and C. L. P. Chen. Cyber

security and privacy issues in smart grids. IEEE
Communications Surveys Tutorials, 2012.

[31] S. Madden, M. J. Franklin, J. M. Hellerstein, and W. Hong.

TAG: A tiny aggregation service for ad-hoc sensor networks.
SIGOPS Operating Systems Review, 2002.

[32] A. Mahimkar and T. Rappaport. SecureDAV: A secure data
aggregation and veriﬁcation protocol for sensor networks. In
IEEE Global Telecommunications Conference, 2004.

[33] A. Mahmoud, U. RÃ 1

4 hrmair, M. Majzoobi, and

F. Koushanfar. Combined modeling and side channel attacks
on strong pufs. IACR Cryptology ePrint Archive, 2013.

[34] J. McCune, E. Shi, A. Perrig, and M. Reiter. Detection of

denial-of-message attacks on sensor network broadcasts. In
IEEE Symposium on Security and Privacy, 2005.

[35] C. Medaglia and A. Serbanati. An overview of privacy and
security issues in the Internet of Things. In The Internet of
Things. 2010.

[36] B. Miller and D. Rowe. A survey of SCADA and critical

infrastructure incidents. In Research in Information
Technology, 2012.

[37] S. Nath, H. Yu, and H. Chan. Secure outsourced aggregation

via one-way chains. In ACM International Conference on
Management of Data, 2009.

[38] OpenSim Ltd. OMNeT++ discrete event simulator.

http://omnetpp.org/, 2015.

[39] S. Ozdemir. Secure and reliable data aggregation for wireless

sensor networks. In Ubiquitous Computing Systems. 2007.

[40] S. Papadopoulos, A. Kiayias, and D. Papadias. Exact

in-network aggregation with integrity and conﬁdentiality.
IEEE Transactions on Knowledge and Data Engineering,
2012.

[41] H. Park, D. Seo, H. Lee, and A. Perrig. SMATT: Smart meter

attestation using multiple target selection and copy-proof
memory. In Computer Science and its Applications. 2012.
[42] B. Parno, J. McCune, and A. Perrig. Bootstrapping trust in

commodity computers. In IEEE Symposium on Security and
Privacy, 2010.

[43] J. Pollet and J. Cummins. Electricity for free — The dirty

underbelly of SCADA and smart meters. In BlackHat USA,
2010.

[44] J. Rattner. Extreme scale computing. ISCA Keynote, 2012.
[45] M. Rubenstein, A. Cornejo, and R. Nagpal. Programmable

self-assembly in a thousand-robot swarm. Science, 2014.

[46] S. Schulz, A.-R. Sadeghi, and C. Wachsmann. Short paper:
Lightweight remote attestation using physical functions. In
ACM Conference on Wireless Network Security, 2011.

[47] A. Seshadri, A. Perrig, L. van Doorn, and P. Khosla. SWATT:

Software-based attestation for embedded devices. In IEEE
Symposium on Security and Privacy, 2004.

[48] A. Seshadri, M. Luk, and A. Perrig. SAKE: Software

attestation for key establishment in sensor networks. In
Distributed Computing in Sensor Systems. 2008.
[49] M. Shah, S. Gala, and N. Shekokar. Lightweight

authentication protocol used in wireless sensor network. In
International Conference on Circuits, Systems,
Communication and Information Technology Applications,
2014.

[50] G. Spanogiannopoulos, N. Vlajic, and D. Stevanovic. A

simulation-based performance analysis of various multipath
routing techniques in ZigBee sensor networks. Lecture
Notes of the Institute for Computer Sciences, Social
Informatics and Telecommunications Engineering. 2010.

[51] Trusted Computing Group (TCG). Website.

http://www.trustedcomputinggroup.org, 2015.
[52] A. Vasudevan, J. McCune, J. Newsome, A. Perrig, and L. van

Doorn. CARMA: A hardware tamper-resistant isolated
execution environment on commodity x86 platforms. In
ACM Symposium on Information, Computer and
Communications Security, 2012.

[53] Z. Yu and Y. Guan. A key management scheme using

deployment knowledge for wireless sensor networks. IEEE
Transactions on Parallel and Distributed Systems, 2008.

[54] W. Zhang, Y. Liu, S. K. Das, and P. De. Secure data

aggregation in wireless sensor networks: A watermark based
authentication supportive approach. Pervasive and Mobile
Computing, 2008.

[55] J. Zhao and R. Govindan. Understanding packet delivery

performance in dense wireless sensor networks. In
International Conference on Embedded Networked Sensor
Systems, 2003.

[56] K. Zhao and L. Ge. A survey on the Internet of Things
security. In International Conference on Computational
Intelligence and Security, 2013.

[57] C. Zhong, Y. Mo, J. Zhao, C. Lin, and X. Lu. Secure
clustering and reliable multi-path route discovering in
wireless sensor networks. In Symposium on Parallel
Architectures, Algorithms and Programming, 2014.

975