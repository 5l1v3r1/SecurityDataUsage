2015 IEEE Symposium on Security and Privacy
2015 IEEE Symposium on Security and Privacy

Privacy and Access Control for
Outsourced Personal Records

Matteo Maffei, Giulio Malavolta, Manuel Reinert, Dominique Schr¨oder

{maffei,malavolta,reinert,schroeder}@cs.uni-saarland.de

Saarland University & CISPA

Abstract—Cloud storage has rapidly become a cornerstone
of many IT infrastructures, constituting a seamless solution for
the backup, synchronization, and sharing of large amounts of
data. Putting user data in the direct control of cloud service
providers, however, raises security and privacy concerns related
to the integrity of outsourced data, the accidental or intentional
leakage of sensitive information, the proﬁling of user activities
and so on. Furthermore, even if the cloud provider is trusted,
users having access to outsourced ﬁles might be malicious and
misbehave. These concerns are particularly serious in sensitive
applications like personal health records and credit score systems.
To tackle this problem, we present GORAM, a cryptographic
system that protects the secrecy and integrity of outsourced
data with respect to both an untrusted server and malicious
clients, guarantees the anonymity and unlinkability of accesses
to such data, and allows the data owner to share outsourced
data with other clients, selectively granting them read and write
permissions. GORAM is the ﬁrst system to achieve such a wide
range of security and privacy properties for outsourced storage.
In the process of designing an efﬁcient construction, we developed
two new, generally applicable cryptographic schemes, namely,
batched zero-knowledge proofs of shufﬂe and an accountability
technique based on chameleon signatures, which we consider
of independent interest. We implemented GORAM in Amazon
Elastic Compute Cloud (EC2) and ran a performance evaluation
demonstrating the scalability and efﬁciency of our construction.

I.

INTRODUCTION

Cloud storage has rapidly gained a central role in the digital
society, serving as a building block of consumer-oriented
applications (e.g, Dropbox, Microsoft SkyDrive, and Google
Drive) as well as particularly sensitive IT infrastructures, such
as personal record management systems. For instance, credit
score systems rely on credit bureaus (e.g., Experian, Equifax,
and TransUnion in US) collecting and storing information
about the ﬁnancial status of users, which is then made available
upon request. As a further example, personal health records
(PHRs) are more and more managed and accessed through web
services (e.g., private products like Microsoft HealthVault and
PatientsLikeMe in US and national services like ELGA in
Austria), since this makes PHRs readily accessible in case of
emergency even without the physical presence of the e-health
card and eases their synchronization across different hospitals.
Despite its convenience and popularity, cloud storage poses
a number of security and privacy issues. The ﬁrst problem is
related to the secrecy of user data, which are often sensitive
(e.g., PHRs give a complete picture of the health status of
citizens) and,
thus, should be concealed from the server.
A crucial point to stress is that preventing the server from
reading user data (e.g., through encryption) is necessary but not

sufﬁcient to protect the privacy of user data. Indeed, as shown
in the literature [1], [2], the capability to link consecutive
accesses to the same ﬁle can be exploited by the server to learn
sensitive information: for instance, it has been shown that the
access patterns to a DNA sequence allow for determining the
patient’s disease. Hence the obliviousness of data accesses is
another fundamental property for sensitive IT infrastructures:
the server should not be able to tell whether two consecutive
accesses concern the same data or not, nor to determine the
nature of such accesses (read or write). Furthermore, the server
has in principle the possibility to modify client’s data, which
can be harmful for several reasons: for instance, it could drop
data to save storage space or modify data to inﬂuence the
statistics about the dataset (e.g., in order to justify higher
insurance fees or taxes). Therefore another property that should
be guaranteed is the integrity of user data.

Finally, it is often necessary to share outsourced documents
with other clients, yet in a controlled manner, i.e., selectively
granting them read and write permissions: for instance, PHRs
are selectively shared with the doctor before a medical treat-
ment and a prescription is shared with the pharmacy in order to
buy a medicine. Data sharing complicates the enforcement of
secrecy and integrity properties, which have to be guaranteed
not only against a malicious server but also against malicious
clients. Notice that the simultaneous enforcement of these
properties is particularly challenging, since some of them are
in seeming contradiction. For instance, access control seems to
be incompatible with the obliviousness property: if the server
is not supposed to learn which ﬁle the client is accessing, how
can he check that the client has the rights to do so?

A. Our Contributions

In this work, we present GORAM, a novel framework for
privacy-preserving cloud-storage. Users can share outsourced
data with other clients, selectively granting them read and
write permissions, and verify the integrity of such data. These
are hidden from the server and access patterns are oblivious.
GORAM is the ﬁrst system to achieve such a wide range of
security and privacy properties for storage outsourcing. More
speciﬁcally, the contributions of this work are the following:
• We formalize the problem statement by introducing the
notion of Group Oblivious RAM (GORAM). GORAM
extends the concept of Oblivious RAM [3] (ORAM) 1
by considering multiple, possibly malicious clients, with

1ORAM is a technique originally devised to protect the access pattern of
software on the local memory and then used to hide the data and the user’s
access pattern in storage outsourcing services.

© 2015, Matteo Maffei. Under license to IEEE.
© 2015, Matteo Maffei. Under license to IEEE.
DOI 10.1109/SP.2015.28
DOI 10.1109/SP.2015.28

341
341

read and/or write access to outsourced data, as opposed to
a single client. We propose a formal security model that
covers a variety of security and privacy properties, such
as data integrity, data secrecy, obliviousness of access
patterns, and anonymity.
• We ﬁrst introduce a cryptographic instantiation based on
a novel combination of ORAM [4], predicate encryp-
tion [5], and zero-knowledge (ZK) proofs (of shufﬂe) [6],
[7]. This construction is secure, but building on off-
the-shelf cryptographic primitives is not practical. In
particular, clients prove to the server that the operations
performed on the database are correct through ZK proofs
of shufﬂe, which are expensive when the entries to be
shufﬂed are tuples of data, as opposed to single entries.
• As a ﬁrst step towards a practical instantiation, we main-
tain the general design, but we replace the expensive
ZK proofs of shufﬂe with a new proof technique called
batched ZK proofs of shufﬂe. A batched ZK proof of
shufﬂe signiﬁcantly reduces the number of ZK proofs
by “batching” several instances and verifying them to-
gether. Since this technique is generically applicable in
any setting where one is interested to perform a zero-
knowledge proof of shufﬂe over a list of entries, each of
them consisting of a tuple of encrypted blocks, we believe
that it is of independent interest. This second realization
greatly outperforms the ﬁrst solution and is suitable for
databases with relatively small entries, accessed by a few
users, but it does not scale to large entries and many users.
• To obtain a scalable solution, we explore some trade-offs
between security and efﬁciency. First, we present a new
accountability technique based on chameleon signatures.
The idea is to let clients perform arbitrary operations on
the database, letting them verify each other’s operation
a-posteriori and giving them the possibility to blame
misbehaving parties. Secondly, we replace the relatively
expensive predicate encryption, which enables sophisti-
cated role-based and attribute-based access control poli-
cies, with the more efﬁcient broadcast encryption, which
sufﬁces to enforce per-user read/write permissions, as
required in the personal record management systems we
consider. This approach leads to a very efﬁcient solution
that scales to large ﬁles and thousands of users, with a
combined communication-computation overhead of only
7% (resp. 8%) with respect to state-of-the-art, single-
client ORAM constructions for reading (resp. writing) on
a 1GB storage with 1MB block size (for larger datasets
or block sizes, the overhead is even lower).

We have implemented GORAM in Amazon Elastic Com-
pute Cloud (EC2) and conducted a performance evaluation
demonstrating the scalability and efﬁciency of our construc-
tion. Although GORAM is generically applicable, the large
spectrum of security and privacy properties, as well as the
efﬁciency and scalability of the system, make GORAM par-
ticularly suitable for the management of large amounts of
sensitive data, such as personal records.

B. Outline

Section II introduces the notion of Group ORAM. We
discuss the general cryptographic instantiation in Section III,
the accountability-based construction in Section IV, and the

efﬁcient scheme with broadcast encryption in Section V.
Section VI formalizes the security properties of Group ORAM
and Section VII states the security and privacy results. We
implemented our system and conducted an experimental eval-
uation, as discussed in Section VIII. Section IX presents a case
study on PHRs. The related work is discussed in Section X.
Section XI concludes and outlines future research directions.
Due to space constraints, we postpone the proofs to the

long version [8].

II. SYSTEM SETTINGS

We detail the problem statement by formalizing the con-
cept of Group ORAM (Section II-A), presenting the relevant
security and privacy properties (Section II-B), and introducing
the attacker model (Section II-C).

A. Group ORAM
We consider a data owner O outsourcing her database DB
= d1, . . . , dm to the server S. A set of clients C1, . . . ,Cn
can accesses parts of the database, as speciﬁed by the access
control policy set by O. This is formalized as an n-by-m
matrix AC, deﬁning the permissions of the clients on the ﬁles
in the database: AC(i, j) (i.e., the j-th entry of the i-th row)
denotes the access mode for client i on data dj. Each entry in
the matrix is an element of the set {⊥, r , rw} of access modes,
denoting no access, read access, and write access, respectively.
At registration time, each client Ci receives a capability
capi, which gives Ci access to DB as speciﬁed in the corre-
sponding row of AC. Furthermore, we assume the existence
of a capability capO, which grants permissions for all of the
operations that can be executed by the data owner only.

In the following we formally characterize the notion of
Group ORAM. Intuitively, a Group ORAM is a collection of
two algorithms and four interactive protocols, used to setup the
database, add clients, add an entry to the database, change the
access permissions to an entry, read an entry, and overwrite an
entry. In the sequel, we let (cid:3)A, B(cid:4) denote a protocol between
the PPT machines A and B, |a| the length of the vector a of
access modes, and a(i) the element at position i in a. In all
our protocols |DB| is equal to the number of columns of AC.

Deﬁnition 1 (Group ORAM): A Group ORAM scheme is a
tuple of (interactive) PPT algorithms GORAM = (gen, addCl,
addE, chMode, read, write), such that:
(capO, DB) ← gen(1λ, n) : The gen algorithm initializes the
] and the access control matrix
database DB := [
AC := [ ], and generates the access capability capO of
the data owner. The parameter n determines the maximum
number of clients. This algorithm returns (capO, DB),
while AC is a global variable that maintains a state across
the subsequent algorithm and protocol executions.
{capi, deny} ← addCl(capO, a) : The addCl algorithm is run
by the data owner, who possesses capO, to register a new
client, giving her access to the database as speciﬁed by
the vector a. If |a| is equal to the number of columns
of AC, a is appended to AC as the last row and the
algorithm outputs a fresh capability capi that is assigned
to that row. Otherwise, it outputs deny.

342342

(cid:2)

; otherwise it outputs deny.

{DB’, deny} ← (cid:3)CaddE(capO, a, d),SaddE(DB)(cid:4) : This proto-
col is run by the data owner, who possesses capO, to
append an element d to DB, assigning the vector a of
access modes. If |a| is equal to the number of rows of
AC then d is appended to DB, a is appended to AC as
the last column, and the protocol outputs the new database
DB
(cid:3)CchMode(capO, a, j),SchMode(DB)(cid:4) : This protocol is used by
the data owner, who possesses capO, to change the access
permissions for the j-th entry as speciﬁed by the vector
a of access modes. If j ≤ |DB| and |a| is equal to the
number of rows of AC, then the j-th column of AC is
replaced by a.
{d, deny} ← (cid:3)Cread(capi, j),Sread(DB)(cid:4) : The interactive read
protocol is used by the owner of capi to read the j-th
entry of DB. This protocol returns either d := DB(j) or
deny if |DB| < j or AC(i, j) = ⊥.
(cid:2), deny} ← (cid:3)Cwrite(capi, j, d),Swrite(DB)(cid:4) : The
interac-
tive write protocol is used by the owner of the capa-
bility capi
to overwrite the j-th entry of DB with d.
(cid:2)
This protocol succeeds and outputs DB
if and only if
AC(i, j) = rw, otherwise it outputs deny.

{DB

B. Security and Privacy Properties

Here we brieﬂy outline the fundamental security and pri-
vacy properties achieved by a Group ORAM. We refer to
Section VI for a precise formalization of these properties based
on cryptographic games.
Secrecy: clients can only read entries they hold read permis-

Integrity: clients can only write entries they hold write per-

sions on.

missions on.

Tamper-resistance: clients, eventually colluding with the
server, cannot modify an entry they do not hold write
permission on without being detected by the data owner.
Obliviousness: the server cannot determine the access pattern

on the data given a clients’ sequence of operation.

Anonymity: the server and the data owner cannot determine
who performed a given operation, among the set of clients
that are allowed to perform it.

Accountable Integrity: clients cannot write entries they do

not hold write permission on without being detected.

C. The Attacker Model
We consider an adversarial model in which the data owner
O is honest, the clients C1, . . . ,Cn may be malicious, and
the server S is assumed to be honest-but-curious (HbC)2 and
not to collude with clients. These assumptions are common in
the literature (see, e.g., [9], [10]) and are well justiﬁed in a
cloud setting, since it is of paramount importance for service
providers to keep a good reputation, which discourages them
from visibly misbehaving, while they may have an incentive in
passively gathering sensitive information given the commercial
interest of personal data.

Although we could limit ourselves to reason about all
security and privacy properties in this attacker model, we
ﬁnd it interesting to state and prove some of them even in

2I.e., the server is regarded as a passive adversary, following the protocol

but seeking to gather additional information

343343

a stronger attacker model, where the server can arbitrarily
misbehave. This allows us to characterize which properties
unconditionally hold true in our system, i.e., even if the server
gets compromised (cf. the discussion in Section VI).

III. OUR CONSTRUCTION (GORAM)

In this section, we ﬁrst show how to realize a Group ORAM
using a novel combination of ORAM, predicate encryption,
and zero-knowledge proofs (Section III-A and Section III-B).
Since even the usage of the most efﬁcient zero-knowledge
proof system still yields an inefﬁcient construction, we in-
troduce a new proof technique called batched ZK proofs of
shufﬂe (Section III-C) and instantiate our general framework
with this primitive.

A. Prerequisites

In the following, we describe the database layout, the basic

cryptographic primitives, and the system assumptions.

Layout of the database. The layout of the database DB
follows the one proposed by Stefanov et al. [4]. To store N
data entries, we use a binary tree T of depth D = O(log N ),
where each node stores a bucket of entries, say b entries per
bucket. We denote a node at depth d and row index i by Td,i.
The depth at the root ρ is 0 and increases from top to bottom;
the row index increases from left to right, starting at 0. We
often refer to the root of the tree as ρ instead of T0,0. Moreover,
Path-ORAM [4] uses a so-called stash as local storage to save
entries that would overﬂow the root bucket. We assume the
stash to be stored and shared on the server like every other
node, but we leave it out for the algorithmic description. The
stash can also be incorporated in the root node, which does
not carry b but b + s entries where s is the size of the stash.
The extension of the algorithms is straight-forward (only the
number of downloaded entries changes) and does not affect
their computational complexity. In addition to the database,
there is an index structure LM that maps entry indices i to
leaf indices li. If an entry index i is mapped in LM to li then
the entry with index i can be found in some node on the path
from the leaf li to the root ρ of the tree. Finally, to initialize
the database we ﬁll it with dummy elements.

Cryptographic preliminaries. We informally review the cryp-
tographic building blocks and introduce a few useful notations.
We denote by ΠSE = (GenSE,E,D) a private-key encryp-
tion scheme, where GenSE is the key-generation algorithm and
E (resp. D) is the encryption (resp. decryption) algorithm.
Analogously, we denote by ΠPKE = (GenPKE, Enc, Dec) a
public-key encryption scheme. We also require a publicly
available function Rerand to rerandomize public-key cipher-
texts. We require that both encryption schemes fulﬁll the IND-
CPA-security property [11].

A predicate encryption scheme [5] ΠPE = (PrGen,
PrKGen, PrEnc, PrDec) consists of a setup algorithm PrGen,
a key-generation algorithm PrKGen, and an encryption (resp.
decryption) algorithm PrEnc (resp. PrDec). In a predicate
encryption scheme, one can encrypt a message m under an
attribute x. The resulting ciphertext can only be decrypted
with a secret key that encodes a predicate f such that

c1

c2

Enc(pk ,·)

Enc(pk ,·)

  j

cj
Auth

c3

Enc(pk ,·)

cj
Key

PoEnc(opk ,·)

PrEnc(mpk ,·,·)

E

xw

xr, kj

c4

Enc(pk ,·)

cj
Data
E(kj,·)

d

Figure 1. The structure of an entry with index j, payload d, write access
regulated by the attribute xw, and read access regulated by the attribute xr.

f (x) = 1. The choice of predicates determines who can
decrypt which ciphertext, which makes predicate encryption a
ﬂexible cryptographic tool to enforce access control policies.
We further use a predicate-only encryption scheme ΠPO =
(PoGen, PoKGen, PoEnc, PoDec). The difference from ΠPE
is that the attribute x is encrypted only. As for public-key
encryption, we require rerandomization functions PrRR and
PoRR for ΠPE and ΠPO. We require that both ΠPE and ΠPO
are (selectively) attribute-hiding [5]. This security notion says
that the adversary learns nothing about the message and the
associated attribute (except the information that is trivially
leaked by the keys that the adversary has).

Intuitively, a zero-knowledge (ZK) proof system ZKP is
a proof system that combines two fundamental properties. The
ﬁrst property, soundness, says that it is (computationally) infea-
sible to produce a ZK proof of a wrong statement. The second
property, zero-knowledge, means that no information besides
the validity of the proven statement is leaked. A non-interactive
zero-knowledge proof is a zero-knowledge protocol consisting
of one message sent by the prover to the veriﬁer. A zero-
knowledge proof of knowledge additionally ensures that the
prover knows the witnesses to the given statement. We denote
by PK {((cid:3)x) : F} a zero-knowledge proof of knowledge of
the variables in (cid:3)x such that the statement F holds. Here, (cid:3)x is
the set of witnesses, existentially quantiﬁed in the statement,
and the proof does not reveal any of them. For instance, the
proof PK {(r) : c = Rerand(pk , d, r)} shows that two public-
key ciphertexts c and d, encrypted with the same public key pk,
encrypt the same plaintext, i.e., c is obtained by rerandomizing
d with the secret randomness r.

Structure of an entry and access control modes. Abstractly,
database entries are tuples of the form E = (c1, c2, c3, c4)
where c1, . . . , c4 are ciphertexts obtained using a public-key
encryption scheme (see Figure 1). In particular, c1 is the
encryption of an index j identifying the j-th entry of the
database; c2 is the encryption of a predicate-only ciphertext
cj
Auth, which regulates the write access to the payload stored
at j using the attribute xw; c3 is the encryption of a ciphertext
cj
Key, which is in turn the predicate encryption of a private
key kj with attribute xr, regulating the read access; c4 is
the encryption of the ciphertext cj
Data, which is the encryption
with the private key kj of the data d stored at position j in
the database. We use the convention that an index j > |DB|
indicates a dummy entry and we maintain the invariant that
every client may write each dummy entry.

Algorithm 1 (capO, DB) ← gen(1λ, n).
Input: security parameter 1λ, number of clients n
Output: the capability of the data owner capO
1: (pk , sk ) ← GenPKE(1λ)
2: (opk , osk ) ← PoGen(1λ, n)
3: (mpk , psk ) ← PrGen(1λ, n)
4: give pk to the server S
5: initialize DB on S, ADB := {}, cntC := 0, cnt E := 0
6: return capO := (cntC, cnt E, sk , osk , psk )

Intuitively, in order to implement the access control modes
⊥, r, and rw on a data index j, each client Ci is provided
with a capability capi that is composed of three keys, the
secret key corresponding to the top level public-key encryption
scheme, a secret key for the predicate-only encryption scheme,
and a secret key for the predicate encryption scheme. More
speciﬁcally, if Ci’s mode for j is ⊥, then capi allows for
Key. If Ci’s mode for j is r, then
Auth nor cj
decrypting neither cj
Auth. Finally, if Ci’s
capi allows for decrypting cj
Key but not cj
mode for j is rw, then capi allows for decrypting both cj
and cj
to successfully prove that she can decrypt the ciphertext cj

Auth
Key. Intuitively, in order to replace an entry, a client has
Auth.

System assumptions. We assume that each client has a local
storage of O(log N ). Notice that the leaf index mapping has
size O(N ), but
the local client storage can be decreased
to O(log N ) by applying a standard ORAM construction
recursively to it, as proposed by Shi et al. [12]. Additionally,
the data owner stores a second database ADB that contains
the attributes xw and xr associated to every entry in DB as
well as predicates fi associated to the client identities Ci.
Intuitively, ADB implements the access control matrix AC
used in Deﬁnition 1. Since also ADB has size O(N ), we use
the same technique as the one employed for the index structure.
We further assume that clients establish authenticated channels
with the server. These channels may be anonymous (e.g., by
using anonymity networks [13] and anonymous credentials for
the login [14]–[17]), but not necessarily.

B. Description of the Algorithms

(capO, DB) ← gen(1λ, n)

(Algo-
Implementation of
rithm 1). Intuitively, the data owner initializes the crypto-
graphic schemes (lines 1.1–1.3) as well as the rest of the
infrastructure (lines 1.4–1.5), and ﬁnally outputs O’s capability
(line 1.6).3 Notice that this algorithm takes as input the maxi-
mum number n of clients in the system, since this determines
the size of the predicates ruling access control, which the
predicate(-only) encryption schemes are parameterized by.
Implementation of {capi, deny} ← addCl(capO, a) (Algo-
rithm 2). This algorithm allows O to register a new client in
the system. Speciﬁcally, O creates a new capability for the new
client Ci according to the given access permission list a (lines
2.5–2.8). If O wants to add more clients than n, the maximum

3For simplifying the notation, we assume for each encryption scheme that

the public key is part of the secret key.

344344

for the client to be added

Algorithm 2 {capi, deny} ← addCl(capO, a).
Input: the capability of O capO and an access control list a
Output: a capability capi for client Ci in case of success,
1: parse capO as (cntC, cnt E, sk , osk , psk )
2: if |a| (cid:7)= cnt E then return deny
3: end if
4: cntC := cntC + 1
5: compute fi s.t. the following holds for 1 ≤ j ≤ |a| and

deny otherwise

all (xw,j, xr,j) := ADB(j)

if a(j) = ⊥ then fi(xw,j) = fi(xr,j) = 0
if a(j) = r then fi(xw,j) = 0 and fi(xr,j) = 1
if a(j) = rw then fi(xw,j) = fi(xr,j) = 1

6: ADB := ADB[Ci (cid:8)→ fi]
7: osk fi
8: return capi := (sk , osk fi

← PoKGen(osk , fi), sk fi
, sk fi )

← PrKGen(psk , fi)

(cid:2), deny} ← (cid:3)CaddE(capO, a, d),SaddE(DB)(cid:4).
Algorithm 3 {DB
Input: the capability of O capO, an access control list a and
on S in case of success,
Output: a changed database DB

the data d for the entry to be added

(cid:2)

deny otherwise

1: parse capO as (cntC, cnt E, sk , osk , psk )
2: if |a| (cid:7)= cntC then return deny
3: end if
4: cnt E := cnt E + 1, j := cnt E, lj ← {0, 1}D, LM :=
LM[j (cid:8)→ lj]
5: let E1, . . . , Eb(D+1) be the path from ρ to TD,lj down-
loaded from S (Ei = (c1,i, c2,i, c3,i, c4,i))
6: let k be such that Dec(sk , c1,k) > |DB|
7: compute (xw,j, xr,j) s.t. the following holds for 1 ≤ i ≤

|a| and all fi := ADB(Ci)

if a(i) = ⊥ then fi(xw,j) = fi(xr,j) = 0
if a(i) = r then fi(xw,j) = 0, fi(xr,j) = 1
if a(i) = rw then fi(xw,j) = fi(xr,j) = 1

8: ADB := ADB[j (cid:8)→ (xw,j, xr,j)]
9: Ek := (c1,k, c2,k, c3,k, c4,k) where

kj ← GenSE(1λ)
Auth ← PoEnc(opk , xw,j)
cj
Key ← PrEnc(mpk , xr,j, kj)
cj
Data ← E(kj, d)
cj
10: for all 1 ≤ (cid:4) ≤ b(D + 1), (cid:4) (cid:7)= k do
select r(cid:3) uniformly at random
11:
(cid:3) ← Rerand(pk , E(cid:3), r(cid:3))
E(cid:2)
12:
13: end for
k−1, Ek, E(cid:2)
14: upload E(cid:2)

1, . . . , E(cid:2)

c1,k ← Enc(pk , j)
c2,k ← Enc(pk , cj
c3,k ← Enc(pk , cj
c4,k ← Enc(pk , cj

Auth)
Key)
Data)

k+1, . . . , E(cid:2)

b(D+1) to S

number she initially decided, she can do so at the price of re-
initializing the database. In particular, she has to setup new
predicate-and predicate-only encryption schemes, since these
depend on n. Secondly, she has to distribute new capabilities
to all clients. Finally, for each entry in the database, she has
to re-encrypt the ciphertexts cAuth and cKey with the new keys.
(cid:2), deny} ← (cid:3)CaddE(capO, a, d),
Implementation of {DB
SaddE(DB)(cid:4) (Algorithm 3). In this algorithm, O adds a new
entry that contains the payload d to the database. Furthermore,

345345

4

Algorithm
Evict(E1, . . . , Eb(D+1), s, j, k).
Input: a list of entries E1, . . . , Eb(D+1), a bit s, an index j,

b(D+1), π, [P ])

(E(cid:2)(cid:2)

1 , . . . , E(cid:2)(cid:2)

←

Output: a permuted and rerandomized list of

entries
b(D+1), a permutation π, and a proof of shufﬂe

and a position k in the list
E(cid:2)(cid:2)
1 , . . . , E(cid:2)(cid:2)
correctness (if s = 1)

1: lj ← {0, 1}D, LM := LM[j (cid:8)→ lj]
2: compute a permutation π s.t. π(k) = 1 and for all other
(cid:4) (cid:7)= k, π pushes (cid:4) down on the path from ρ (= E1, . . . , Eb)
to the current leaf node (= EbD+1, . . . , Eb(D+1)) as long
as the index of the (cid:4)-th entry still lies on the path from ρ
to its designated leaf node.
3: E(cid:2)
1, . . . , E(cid:2)
4: let E(cid:2)(cid:2)
E(cid:2)
b(D+1) as described in 3.10–3.13 (including k)

1 , . . . , E(cid:2)(cid:2)
b(D+1) be the rerandomization of E(cid:2)
(cid:2)

b(D+1) := Eπ−1(1), . . . , Eπ−1(b(D+1))

1, . . . ,
(cid:3)

5: if s = 1 then
P := PK
6:
return E(cid:2)(cid:2)
return E(cid:2)(cid:2)

7:
8: else
9:
10: end if

(π, r1, . . . , rb(D+1)) :

∀(cid:4). E(cid:3) = Rerand(pk , Eπ−1((cid:3)), r(cid:3))
b(D+1), π, P

1 , . . . , E(cid:2)(cid:2)
1 , . . . , E(cid:2)(cid:2)

b(D+1), π

the new entry is protected according to the given access per-
mission list a. Intuitively, O assigns the new entry to a random
leaf and downloads the corresponding path in the database
(lines 3.4–3.5). It then creates the new entry and substitutes it
for a dummy entry (lines 3.6–3.9). Finally, O rerandomizes the
entries so as to hide from S which entry changes, and ﬁnally
uploads the modiﬁed path to S (lines 3.10–3.14).

Eviction. In all ORAM constructions, the client has to rear-
range the entries in the database in order to make subsequent
accesses unlinkable to each other. In the tree construction we
use [4], this is achieved by ﬁrst assigning a new, randomly
picked, leaf index to the read or written entry. After that, the
entry might no longer reside on the path from the root to
its designated leaf index and, thus, has to be moved. This
procedure is called eviction (Algorithm 4).

This algorithm assigns the entry to be evicted to a new
leaf index (line 4.1). It then locally shufﬂes and rerandomizes
the given path according to a permutation π (lines 4.2–4.4).
After replacing the old path with a new one, the evicted entry is
supposed to be stored in a node along the path from the root to
the assigned leaf, which always exists since the root is part of
the permuted nodes. A peculiarity of our setting is that clients
are not trusted and, in particular, they might store a sequence
of ciphertexts in the database that is not a permutation of the
original path (e.g., they could store a path of dummy entries,
thereby cancelling the original data).

Integrity proofs. To tackle this problem, a ﬁrst technical novelty
in our construction is, in the read and write protocols, to let the
client output the modiﬁed path along with a proof of shufﬂe
correctness [18], [7], which has to be veriﬁed by the server
(s = 1, lines 4.6–4.7). As the data owner is assumed to be
honest, she does not have to send a proof in the chMode
protocol (s = 0, line 4.9).

an index j

Algorithm 5 (cid:3)CchMode(capO, a, j),SchMode(DB)(cid:4).
Input: the capability of O capO, an access control list a, and
Output: deny if the algorithm fails
1: parse capO as (cntC, cnt E, sk , osk , psk )
2: if |a| (cid:7)= cntC or j > cnt E then return deny
3: end if
4: lj := LM(j)
5: let E1, . . . , Eb(D+1) be the path from ρ to TD,lj down-

loaded from S (Ei = (c1,i, c2,i, c3,i, c4,i))

6: let k be s.t. Dec(sk , c1,k) = j
7: compute (xw,j, xr,j) according to 3.7 and subject to all fi
8: (x(cid:2)
9: let f be s.t. f (x(cid:2)

in ADB, also add them to ADB (3.8)
r,j) := ADB(j)
w,j, x(cid:2)
sk f ← PrKGen(psk , f )
j ← PrDec(sk f , cj
k(cid:2)
10:
Key)
d ← D(k(cid:2)
j, cj
Data)
11: compute E(cid:2)
k as in 3.9
b(D+1), π) := Evict(E1, . . . , Ek−1, E(cid:2)
1 , . . . , E(cid:2)(cid:2)
12: (E(cid:2)(cid:2)
. . . , Eb(D+1), 0, j, k)
13: upload E(cid:2)(cid:2)
1 , . . . , E(cid:2)(cid:2)

w,j) = f (x(cid:2)
r,j) = 1
Key ← Dec(sk , c3,k)
cj
Data ← Dec(sk , c4,k)
cj

b(D+1) to S

k, Ek+1,

Implementation of (cid:3)CchMode(capO, a, j),SchMode(DB)(cid:4) (Al-
gorithm 5). In this protocol, O changes the access mode of
the j-th entry in DB according to the new access permission list
a. Intuitively, she does so by downloading the path where the
entry resides on (lines 5.4–5.5), changing the entry accordingly
(lines 5.6–5.11), and uploading a modiﬁed and evicted path
to the server (lines 5.12–5.13). Na¨ıvely, O could simply re-
encrypt the old key with the new attributes. However, if a
client keeps a key for index j locally and his access on j is
revoked, then he can still access the payload. Hence, O also
picks a new key and re-encrypts the payload.

Implementation of {d, deny} ← (cid:3)Cread(capi, j),Sread(DB)(cid:4)
(Algorithm 6). Intuitively, the client downloads the path which
index j is assigned to and searches for the corresponding entry
(lines 6.4–6.6). She then evicts the downloaded path, subject
to the restriction that some dummy entry afterwards resides in
the top position of the root node (lines 6.7–6.8). C uploads the
evicted path together with a proof of shufﬂe correctness to S
who veriﬁes the proof and replaces the old with the new path
in case of successful veriﬁcation (line 6.9).
Obliviousness in presence of integrity proofs. C could in princi-
ple stop here since she has read the desired entry. However, in
order to fulﬁll the notion of obliviousness, the read and write
operations must be indistinguishable. In single-client ORAM
constructions, C can make write indistinguishable from read
by simply modifying the content of the desired entry before
uploading the shufﬂed path to the server. This approach does
not work in our setting, due to the presence of integrity proofs.
Intuitively, in read, it would sufﬁce to produce a proof of
shufﬂe correctness, but this proof would not be the same as
the one used in write, where one element in the path changes.
Hence another technical novelty in our construction is the last
part of the read protocol (lines 6.10–6.14), which “simulates”

Algorithm 6 {d, deny} ← (cid:3)Cread(capi, j),Sread(DB)(cid:4).
Input: the capability of the client executing the protocol capi

and the index j to be read

Output: the data payload d in case of success, deny otherwise
1: parse capi as (sk , osk f , sk f )
2: if j > |DB| then return deny
3: end if
4: lj := LM(j)
5: let E1, . . . , Eb(D+1) and k be as in lines 5.5–5.6
6: extract d from Ek as in line 5.10
7: let (cid:4) be s.t. Dec(sk , c1,(cid:3)) > |DB|
1 , . . . , E(cid:2)(cid:2)
8: (E(cid:2)(cid:2)
b(D+1), π, P ):= Evict(E1, . . . , Eb(D+1), 1, j, (cid:4))
9: upload E(cid:2)(cid:2)
1 , . . . , E(cid:2)(cid:2)
(cid:4)
Auth ← Dec(sk , c(cid:2)(cid:2)
10: cj
(osk f ) : PoDec(osk f , cj
11: PAuth := PK
1 := (c(cid:2)(cid:2)(cid:2)
12: E(cid:2)(cid:2)(cid:2)
3,1, c(cid:2)(cid:2)(cid:2)
2,1, c(cid:2)(cid:2)(cid:2)
1,1, c(cid:2)(cid:2)(cid:2)
4,1) where
r1, . . . , r4 are selected uniformly at random
l,1 ← Rerand(pk , c(cid:2)(cid:2)
l,1, rl) for l ∈ {1, 3, 4}
c(cid:2)(cid:2)(cid:2)
2,1 ← Enc(pk , PoRR(opk , cj
c(cid:2)(cid:2)(cid:2)
Auth, r2))
1,1 = Rerand(pk , c(cid:2)(cid:2)(cid:2)
(r1) : c(cid:2)(cid:2)

b(D+1) and P to S

Auth) = 1

1,1, r1)

(cid:5)

2,1)

(cid:6)

13: PInd := PK
14: upload E(cid:2)(cid:2)(cid:2)
access cj

1 , PAuth, PInd, and the necessary information to
Auth to S

(cid:7)

the write protocol despite the presence of integrity proofs. This
is explained below, in the context of the write protocol.
(cid:2), deny} ← (cid:3)Cwrite(capi, j, d),Swrite(DB)(cid:4).
Algorithm 7 {DB
Input: the capability of the client executing the protocol capi,

the index j to be written, and the payload d

2,1, c(cid:2)(cid:2)(cid:2)

4,1) where

Output: deny if the algorithm fails
1: execute 6.1–6.6
1 , . . . , E(cid:2)(cid:2)
8: (E(cid:2)(cid:2)
b(D+1), π, P ):=Evict(E1, . . . , Eb(D+1), 1, j, k)
9: execute 6.9–6.11
12: E(cid:2)(cid:2)(cid:2)
1 := (c(cid:2)(cid:2)(cid:2)
3,1, c(cid:2)(cid:2)(cid:2)
1,1, c(cid:2)(cid:2)(cid:2)
r1, r2, r3 are selected uniformly at random
1,1 ← Rerand(pk , c(cid:2)(cid:2)
c(cid:2)(cid:2)(cid:2)
1,1, r1)
2,1 ← Enc(pk , PoRR(opk , cj
c(cid:2)(cid:2)(cid:2)
3,1 ← Enc(pk , PrRR(mpk , cj
c(cid:2)(cid:2)(cid:2)
Data ← E(kj, d)
cj
4,1 ← Enc(pk , cj
c(cid:2)(cid:2)(cid:2)
13: execute 6.13–6.14

Auth, r2))
Key, r3))

Data)

(cid:2), deny} ← (cid:3)Cwrite(capi, j, d),
Implementation of {DB
Swrite(DB)(cid:4) (Algorithm 7). Firstly, C reads the element that
she wishes to change (line 7.1). Secondly, C evicts the path
with the difference that here the ﬁrst entry in the root node is
the element that C wants to change, as opposed to a dummy
entry like in read (line 7.8). It is important to observe that the
shufﬂe proof sent to the server (line 4.6) is indistinguishable
in read and write since it hides both the permutation and the
randomness used to rerandomize the entries. So far, we have
shown how C can upload a shufﬂed and rerandomized path to
the server without modifying the content of any entry.

In write, C can now replace the ﬁrst entry in the root node
with the entry containing the new payload (lines 7.12–7.13).

346346

In read, this step is simulated by rerandomizing the ﬁrst entry
of the root node, which is a dummy entry (line 6.12).

The integrity proofs PAuth and PInd produced in read and
write are indistinguishable (lines 6.11 and 6.13 for both): in
both cases, they prove that C has the permission to write on the
ﬁrst entry of the root node and that the index has not changed.
Notice that this proof can be produced also in read, since all
clients have write access to dummy entries.

in the case of PHRs,

Permanent Entries. Some application scenarios of GORAM
might require determined entries of the database not to be
modiﬁable nor deletable, not even by the data owner herself
(for instance,
the user should not
be able to cancel diagnostic results in order to pay lower
insurance fees). Even though we did not explicitly describe the
construction, we mention that such a property can be achieved
by assigning a binary attribute (modiﬁable or permanent) to
each entry and storing a commitment to this in the database.
Every party that tries to modify a given entry, including the
data owner, has to provide a proof that the respective attribute
is set to modiﬁable. Due to space constraints we omit the
algorithm, but it can be efﬁciently instantiated using El Gamal
encryption and Σ-protocols.

C. Batched Zero-Knowledge Proofs of Shufﬂe

A zero-knowledge proof of a shufﬂe of a set of ciphertexts
proves in zero-knowledge that a new set of ciphertexts contains
the same plaintexts in permuted order. In our system the
encryption of an entry, for reasonable block sizes, yields in
practice hundreds of ciphertexts, which means that we have
to perform hundreds of shufﬂe proofs. These are computable
in polynomial-time but, even using the most efﬁcient known
solutions (e.g., [7], [19]), not fast enough for practical pur-
poses. This problem has been addressed in the literature but
the known solutions typically reveal part of the permutation
(e.g., [20]), which would break obliviousness and, thus, are
not applicable in our setting.

To solve this problem we introduce a new proof technique
that we call batched zero-knowledge proofs of shufﬂe, based
on the idea of “batching” several
instances and verifying
them together. Our interactive protocol takes advantage of the
homomorphic property of the top layer public-key encryption
scheme in order to batch the instances. On a high level, we
represent the path, which the client proves the shufﬂe of, as
an n-by-m matrix where n is the number of entries (i.e., the
path length) and m is the number of blocks of ciphertexts per
entry. The common inputs of the prover P and the veriﬁer V
are the two matrices A and A(cid:2) characterizing the path stored
on the database and the path shufﬂed and re-randomized by
the client, respectively. P additionally knows the permutation
π and the randomnesses R used for rerandomizing the entries.
Intuitively, the batching algorithm randomly selects a sub-
set of columns (i.e., block indices) and computes the row-
wise product of the corresponding blocks for each row. It
then computes the proof of shufﬂe correctness on the resulting
single-block ciphertexts. The property we would like to achieve
is that modifying even a single block in a row should lead to
a different product and, thus, be detected. Notice that na¨ıvely
multiplying all blocks together does not achieve the intended

Algorithm 8 Batched ZK Proofs of Shufﬂe.
Input of P: A, A(cid:2), π, R
Input of V: A, A(cid:2)
1: V randomly selects (cid:3)a ← {0, 1}m and sends it to P.
2: P computes for all 1 ≤ i ≤ n the partial ciphertext

products
θi =

(cid:8)m
j=1 ajA(cid:2)

i,j

(cid:8)m
j=1 ajAi,j and θ(cid:2)
(cid:9)m
j=1 ajRi,j

i =

ri =

and the corresponding partial randomness sum
where aj is the j-th bit of (cid:3)a. V also computes (cid:3)θ and (cid:3)θ(cid:2).
3: V and P run the protocol for the proof of shufﬂe correct-
ness [7] on (cid:3)θ, (cid:3)θ(cid:2), π, and (cid:3)r.

(cid:10)
property, as illustrated by the following counterexample:
Enc(pk , 3) Enc(pk , 4)
Enc(pk , 5) Enc(pk , 2)

(cid:10)
Enc(pk , 2) Enc(pk , 6)
Enc(pk , 5) Enc(pk , 2)

(cid:11)

(cid:11)

the rows have not been permuted
In the above matrices,
but rather changed. Still, the row-wise product is preserved,
i.e., 12 in the ﬁrst and 10 in the second. Hence, we cannot
compute the product over all columns. Instead, as proved
in the long version, the intended property can be achieved
with probability at least 1
2 if each column is included in the
product with probability 1
2. Although a probability of 1
2 is not
sufﬁcient in practice, repeating the protocol k times increases
the probability to (1 − 1
2k ).
The detailed construction is depicted in Algorithm 8. In
line 8.1, V picks a challenge, which indicates which column
to include in the homomorphic product. Upon receiving the
challenge, in line 8.2, P and V compute the row-wise multi-
plication of the columns indicated by the challenge. Finally,
V and P run an off-the-shelf shufﬂe proof on the resulting
ciphertext lists (line 8.3).

It follows from the protocol design that our approach does
not affect the completeness of the underlying proof of shufﬂe
correctness, the same holds true for the zero-knowledge and
proof of knowledge properties. Furthermore, any malicious
prover who does not apply a correct permutation is detected
by the veriﬁer with probability at least 1/2.

Finally, the protocol can be made non-interactive by using

the Fiat-Shamir heuristic [21].

To summarize, our new approach preserves all of the prop-
erties of the underlying shufﬂe proof while being signiﬁcantly
more efﬁcient. Our proof system eliminates the dependency of
the number of proofs with respect to the block size, making it
dependent only on k and on the complexity of the proof itself.

IV. ACCOUNTABLE INTEGRITY (A-GORAM)

In this section we relax the integrity property by intro-
ducing the concept of accountability. In particular, instead of
letting the server check the correctness of client operations,
we develop a technique that allows clients to detect a poste-
riori non-authorized changes on the database and blame the
misbehaving party. Intuitively, each entry is accompanied by a
tag (technically, a chameleon hash along with the randomness
corresponding to that entry), which can only be produced by
clients having write access. All clients can verify the validity

347347

of such tags and, eventually, determine which client inserted
an entry with an invalid tag. This makes the construction more
efﬁcient and scalable, signiﬁcantly reducing the computational
complexity both on the client and on the server side, since zero-
knowledge proofs are no longer necessary and, consequently,
the outermost encryption can be implemented using symmetric,
as opposed to asymmetric, cryptography. Such a mechanism
is supposed to be paired with a data versioning protocol in
order to avoid data losses: as soon as one of the clients detects
an invalid entry, the misbehaving party is punished and the
database is reverted to the last safe state (i.e., a state where all
entries are associated with a valid tag).

A. Prerequisites

In the following, we review some additional cryptographic

primitives and explain the structure of the log ﬁle.

Cryptographic preliminaries. Intuitively, a chameleon hash
function is a randomized collision-resistant hash function that
provides a trapdoor. Given the trapdoor it
is possible to
efﬁciently compute collisions. A chameleon hash function is a
tuple of PPT algorithms ΠCHF = (GenCHF, CH, Col). The setup
algorithm GenCHF takes as input a security parameter 1λ and
outputs a key pair (cpk , csk ), where cpk is the public key and
csk is the secret key. The chameleon hash function CH takes
as input the public key cpk, a message m, and randomness
r; it outputs a hash tag t. The collision function Col takes as
input the secret key csk, a message m, randomness r, and
another message m(cid:2); it outputs a new randomness r(cid:2) such that
CH(cpk , m, r) = CH(cpk , m(cid:2), r(cid:2)
). For our construction, we
use chameleon hash functions providing key-exposure free-
ness [22]. Intuitively, this property states that no adversary
is able to ﬁnd a fresh collision, without knowing the secret
key csk, even after seeing polynomially many collisions.

We denote by ΠDS = (GenDS, sign, verify) a digital signa-
ture scheme. We require a signature scheme that is existentially
unforgeable. Intuitively, this notion ensures that it is infeasible
for any adversary to output a forgery (i.e., a fresh signature σ
on a message m without knowing the signing key) even after
seeing polynomially many valid (σ, m) pairs.

Structure of the log ﬁle. We use a log ﬁle Log so as to detect
who has to be held accountable in case of misbehavior. Log is
append-only and consists of the list of paths uploaded to the
server, each of them signed by the respective client.

B. Construction

Structure of entries. The structure of an entry in the database
is depicted in Figure 2. An entry E is protected by a top-level
private-key encryption scheme with a key K that is shared by
the data owner O and all clients C1, . . . ,Cn. Under the encryp-
tion, E contains several elements, which we explain below:

• j is the index of the entry;
• cAuth is a predicate encryption ciphertext that encrypts the
private key csk of a chameleon hash function under an
attribute xw, which regulates the write access;

• cKey and cData are unchanged;
• cpk is the public key of a chameleon hash function, i.e.,

the counterpart of csk encrypted in cAuth;

cAuth

j
PrEnc(mpk ,·,·)

cKey

PrEnc(mpk ,·,·)

E
E(K,·)
cData
E(kj,·)

xw, csk

xr, kj

d

sign(skO,·)

cpk

r

t

σ

CH(cpk , j || cAuth || cKey

|| cData || cpk , r)

Figure 2. The structure of an entry in the database.

• r is some randomness used in the computation of t;
• t is a chameleon hash tag, produced by hashing the
concatenation of j, cAuth, cKey, cData, and cpk under
randomness r using the public key cpk;
• σ is a signature on the chameleon hash tag t, signed by
the data owner O.
Intuitively, only clients with write access are able to decrypt
cAuth, and thus to retrieve the key csk required to compute
a collision for the new entry d(cid:2) (i.e., to ﬁnd a randomness
r(cid:2) such that the chameleon hash t for the old entry d and
randomness r is the same as the one for d(cid:2) and r(cid:2)). The
fundamental observation is that the modiﬁcation of an entry is
performed without changing the respective tag. Consequently,
the signature σ is the same for the old and for the new
entry. Computing a collision is the only way to make the tag
t, originally signed by the data owner, a valid tag also for
the new entry d(cid:2). Therefore verifying the signature and the
chameleon hash sufﬁces to make sure that the entry has been
only modiﬁed by authorized clients.

Basic Algorithms. The basic algorithms follow the ones
deﬁned in Section III-B, except for natural adaptions to the new
entry structure. Furthermore, the zero-knowledge proofs are no
longer computed and the rerandomization steps are substituted
by re-encryptions. Finally, clients upload on the server signed
paths, which are stored in the Log.

Entry Veriﬁcation. We introduce an auxiliary veriﬁcation
function that clients run in order to verify the integrity of an
entry. During the execution of any protocol below we maintain
the invariant that, whenever a client i (or the data owner
himself) parses an entry j that he downloaded from the server,
he executes Algorithm 9. If the result is ⊥, then the client runs
blame(capi, Log, j).

Algorithm 9 The pseudo-code for the veriﬁcation of an entry
in the database which is already decrypted.
Input: An entry (j, cAuth, cKey, cData, r, cpk , t, σ) and the ver-
Output: (cid:12) if veriﬁcation succeeds, ⊥ otherwise.
1: if t = CH(cpk , j || cAuth || cKey || cData || cpk , r) and

iﬁcation key vkO of O.

(cid:12) = verify(σ, vkO, t) then

return (cid:12)
return ⊥

2:
3: else
4:
5: end if

Blame. In order to execute the function blame(capi, Log, j),
the client must ﬁrst retrieve Log from the server. Afterwards,

348348

she parses backwards the history of modiﬁcations by decrypt-
ing the paths present in the Log. The client stops only when
she ﬁnds the desired entry indexed by j in a consistent state,
i.e., the data hashes to the associated tag t and the signature
is valid. At this point the client moves forwards on the Log
until she ﬁnds an uploaded path where the entry j is supposed
to lay on (the entry might be associated with an invalid tag
or missing). The signature on the path uniquely identiﬁes the
client, whose identity is added to a list L of misbehaving
clients. Finally, all of the other clients that acknowledged the
changes of the inconsistent entry are also added to L, since
they did not correctly verify its chameleon signature.

Discussion. As explained above, the accountability mechanism
allows for the identiﬁcation of misbehaving clients with a min-
imal computational overhead in the regular clients’ operation.
However, it requires the server to store a log that is linear in
the number of modiﬁcations to the database and logarithmic in
the number of entries. This is required to revert the database
to a safe state in case of misbehaviour. Consequently, the
blame algorithm results expensive in terms of computation and
communication with the server, in particular for the entries that
are not regularly accessed. Nonetheless, blame is supposed to
be only occasionally executed, therefore we believe this design
is acceptable in terms of service usability. Furthermore, we can
require all the parties accessing the database to synchronize on
a regular basis so as to verify the content of the whole database
and to reset the Log, in order to reduce the storage on the
server side and, thus, the amount of data to transfer in the
blame algorithm. Such an approach could be complemented
by an efﬁcient versioning algorithm on encrypted data, which
is however beyond the scope of this work and left as a future
work. Finally, we also point out that the accountable-integrity
property, as presented in this section, sacriﬁces the anonymity
property, since users have to sign the paths they upload to
the server. This issue can be easily overcome by using any
anonymous credential system that supports revocation [23].

V. SCALABLE SOLUTION (S-GORAM)

Even though the personal record management systems we
consider rely on simple client-based read and write permis-
sions, the predicate encryption scheme used in GORAM and
A-GORAM support in principle a much richer class of access
control policies, such as role-based access control (RBAC) or
attribute-based access control (ABAC) [5]. If we stick to client-
based read and write permissions, however, we can achieve a
more efﬁcient construction that scales to thousands of clients.
To this end, we replace the predicate encryption scheme with
a broadcast encryption scheme [24], which guarantees that a
speciﬁc subset of clients is able to decrypt a given ciphertext.
This choice affects the entry structure as follows (cf. Figure 2):

• cKey is the broadcast encryption of kj;
• cAuth is the broadcast encryption of csk.

The subset of clients that can decrypt cKey (resp. cAuth) is then
set to be the same subset that holds read (resp. write) per-
missions on the given entry. By applying the aforementioned
modiﬁcations on top of A-GORAM, we obtain a much more
efﬁcient and scalable instantiation, called S-GORAM, that
achieves a smaller constant in the computational complexity
(linear in the number of clients). For more details on the

b: {0,1},
capO

CHALLENGER

write(DB, db, j)

read, write, 

chMode, addEntry, 

addClient
((d0, d1), j)
WIN iff b = b’ 

ADVERSARY

corruptClient

DB

b’

Figure 3. Game for Secrecy.

capO 

		
 



 






 


	



j* 

 


iff j*≠ j* 

Figure 4. Game for Integrity.

performance evaluation and a comparison with A-GORAM,
we refer to Section VIII.

VI. SECURITY AND PRIVACY FOR GROUP ORAM
In order to prove the security of our constructions, we for-
malized the security and privacy properties of a Group ORAM
by cryptographic games, which are intuitively introduced be-
low. The formal deﬁnitions can be found in the appendix.

A. Security and Privacy of Group ORAM

Secrecy. Intuitively, a Group ORAM preserves the secrecy of
outsourced data if no party is able to deduce any information
about the content of any entry she does not have access to. We
formalize this intuition through a cryptographic game, which
is illustrated in Figure 3. Intuitively, the challenger initializes
an empty database locally and it hands it over to the adversary
so as to give him the possibility to adaptively and arbitrarily
ﬁll the content of the database. Additionally, the adversary is
given the possibility of spawning and corrupting a polynomial
number of clients, allowing him to perform operations on the
database on their behalf. Hence, this property is proven in a
strong adversarial model, without placing any assumption on
the server’s behavior. At some point of the game the adversary
outputs two data and a database index, the challenger ﬂips a
coin and it randomly inserts either one of the two payloads
in the desired database entry. In order to make the game
not trivial, it must be the case that the adversary should not
have corrupted any client that holds read permission on such
index. We deﬁne the adversary to win the game if he correctly
guesses which of the two entries has been written. Since the
adversary can always randomly guess, we deﬁne the system
to be secrecy-preserving if the adversary cannot win the game
with probability non-negligibly greater than 1
2.

Integrity. A Group ORAM preserves the integrity of its entries
if none of the clients can modify an entry to which she does
not have write permissions. The respective cryptographic game
is depicted in Figure 4. Intuitively, the challenger initializes an
empty database DB and a copy DB’, providing the adversary
with the necessary interfaces to ﬁll the content of DB and to
generate and corrupt clients. Every time the adversary queries
an interface, the challenger interacts with the respective client
playing the server’s role and additionally executes locally the

349349

capO 

 



		
 


	



j* 


iff j*≠ j* 

Figure 5. Game for Tamper-resistance.




b: {0,1}

CHALLENGER

capO

ADVERSARY

 

 

read(DB, j; capb) or 
write(DB, d, j; capb)

read, write, 

chMode, addEntry
((cap0, cap1), j) or 
((cap0, cap1), j, d) 
WIN iff b = b’ 

DB

b’

Figure 7. Game for Anonymity.

b: {0,1}, 
capO 

	


 

		
 







iff b = b’  

 

b’ 

Figure 6. Game for Obliviousness.

same operation on DB’ in an honest manner. Note that here
the adversary cannot directly operate on the database but he
can only operate through the clients: this constraint reﬂects
the honesty assumption of the server. At some point of the
execution, the adversary outputs an index of the database (that
none of his corrupted clients can write on) and the challenger
compares the two entries stored in DB and DB’, if they are not
the same we say that the adversary wins the game. Since that
would imply that a client could potentially be able to modify
the content of an entry she does not have access to, we say
that the system is integrity-preserving if any possible adversary
cannot win the game with non-negligible probability.

Tamper-resistance. Intuitively, a Group ORAM is tamper-
resistant if the server, even colluding with a subset of ma-
licious clients, is not able to convince an honest client about
the integrity of some maliciously modiﬁed data. Notice that
this property refers to a strong adversarial model, where the
adversary may arbitrarily misbehave and collude with clients.
Naturally, tamper-resistance holds true only for entries which
none of the corrupted clients had ever access to. The respective
cryptographic game is depicted in Figure 5. The game is
described exactly as in the previous deﬁnition except for the
fact that the database is this time handed over to the adversary
at the very beginning of the experiment so as to allow him to
operate directly on it. The challenger maintains a local copy
of the database where it performs the same operations that are
triggered by the adversary but in an honest way. The winning
conditions for the adversary are the same as stated above and
we say that the system is tamper-resistant if no adversary can
win this game with probability greater than a negligible value.
Note that there exists a class of attacks where the adversary
wins the game by simply providing an old version of the
database, which are inherent to the cloud storage setting. We
advocate the usage of standard techniques to deal with this
kind of attacks (e.g., a gossip protocol among the clients for
versioning of the entries [25]) and hence, we rule them out in
our formal analysis by implicitly assuming that the information
provided by the adversary are relative to the most up to date
version of the database that he possesses locally.

Obliviousness. Intuitively, a Group ORAM is oblivious if
the server cannot distinguish between two arbitrary query
sequences which contain read and write operations. In the
cryptographic game depicted in Figure 6, the adversary holds
the database on his side and he gets access to the interfaces

in the
needed to adaptively and arbitrarily insert content
database. Thus the server may arbitrarily misbehave but it is
not allowed to collude with clients: the adversary can only
spawn a polynomial number of them, but he cannot corrupt
them. In this game the challenger offers an additional interface
where the adversary can input two arbitrary queries, i.e., on be-
half of arbitrary clients and on arbitrary indices of the database.
This interface can be used by the adversary polynomially many
times, thus creating the two query sequences at the core of
the obliviousness deﬁnition. In the beginning of the game the
challenger ﬂips a coin and then it always executes either one
of the two queries, depending on the outcome of the initial
random coin. In order to win, the adversary has to tell the value
of the random coin of the challenger, thus distinguishing which
query sequence has been executed. This would then mean that
the adversary has been able to link some access to a speciﬁc
memory location, hence we say that a system is oblivious if
the adversary does not win the game with probability non-
negligibly greater than 1
2.

Anonymity. A Group ORAM is anonymity-preserving if the
data owner cannot efﬁciently link a given operation to a
client, among the set of clients having access to the queried
index. In the cryptographic game depicted in Figure 7, the
setting is equivalent to the secrecy deﬁnition except that the
challenger also hands over the capability of the data owner to
the adversary. Clearly the adversary does not need to corrupt
clients since he can spawn them by himself. Additionally, the
challenger provides the adversary with an interface that he
can query with an operation associated with two arbitrary
capabilities. To make the game not
it must hold
that both of the capabilities hold the same read and write
permissions on the entry selected by the adversary. Based on
some initial randomness, the challenger always executes the
desired command with either one of the two capabilities and
the adversary wins the game if and only if he can correctly
determine which capability has been selected. Since this would
imply a de-anonymization of the clients, we say that the system
is anonymity-preserving if the adversary cannot win the game
with probability non-negligibly greater than 1
2.

trivial,

Accountable Integrity. The server maintains an audit log Log,
which holds the evidence of client operations on the database
DB. Speciﬁcally, each path uploaded to the server as a result
of an eviction procedure is signed by the client and appended
by the server to the log. After detecting an invalid or missing
entry with index j, the client retrieves Log from the server
and performs the algorithm blame(capi, Log, j). The output is
a list of identities, which correspond to misbehaving parties.
We deﬁne the accountable integrity property through a
cryptographic game, illustrated in Figure 8. The game is the
same as the one for integrity, except for the winning condition,

350350

capO

CHALLENGER
ENGER

DB’

update

corruptClient

ADVERSARY

read, write, 

chMode, addEntry, 

addClient

j*

DB

WIN iff read(DB, j*) ≠ read(DB’, j*) AND 
(∃ i ∈ L: i ∉ corruptClient OR L = []) 

Property
Secrecy
Integrity
Tamper-resistance
Obliviousness
Anonymity
Access control

G.






A-G.



S-G.


Accountable Accountable









ABAC

ABAC

R/W

Figure 8. Game for Accountable Integrity.

Property
Secrecy
(Accountable) Integrity
Tamper-resistance
Obliviousness
Anonymity

Server
malicious
HbC
malicious
malicious
malicious

Collusion







Table I: Security and privacy properties together with their
minimal assumptions.

which is adjusted according to the accountability requirements.
Intuitively, the adversary wins the game if he manages to
modify the entry in the index he provided and the challenger
is not able to identify at least one of the corrupted clients that
contributed to modify that entry or it erroneously blames some
honest party. This means that the blaming procedure always
returns at least one of the misbehaving parties and never an
honest one. The literature deﬁnes this notion of accountability
as fairness (never blame honest parties) and completeness
(blame at least one dishonest party) [26]. We say that a system
preserves accountable integrity if the adversary cannot win the
game with more than negligible probability.

Discussion. Table I summarizes the security and privacy prop-
erties presented in this section, along with the corresponding
assumptions. The HbC assumption is in fact only needed for
integrity, since the correctness of client operations is checked
by the server, thus avoiding costly operations on the client
side. We will see in Section IV that the HbC assumption is
still needed for the accountable integrity property, since the
server maintains a log of accesses, which allows for blaming
misbehaving parties. All other properties hold true even if the
server is malicious as long as it does not collude with clients.
Furthermore, secrecy, tamper-resistance, and anonymity hold
true even if the server is malicious and colludes with clients.
The non-collusion assumption is due to the obliviousness
property, which is meant to protect the access patterns from the
server. Extending this property to non-authorized clients and
devising corresponding enforcement mechanisms is beyond the
scope of this paper and left as an interesting future work.

VII. SECURITY AND PRIVACY RESULTS

In this section, we show that

the Group ORAM in-
stantiations presented in Section III, in Section IV, and in
Section V achieve the security and privacy properties stated
in Section VI-A. The proofs are reported in the technical
report [8]. A brief overview of the properties guaranteed
by each construction is shown in Table II. As previously
discussed, dropping the computationally expensive integrity
checks in favor of an accountability mechanism is crucial to
achieve efﬁciency. It follows that A-GORAM and S-GORAM

Table II: Security and privacy properties achieved by each
construction where G. stands for GORAM.

provide accountable integrity as opposed to integrity and tam-
per resistance. Having an accountable system trivially implies
the loss of anonymity, as deﬁned in Section VI-A, although
it is still possible to achieve pseudonym-based anonymity by
employing anonymous credentials. The other privacy prop-
erties of our system, namely secrecy and obliviousness, are
fulﬁlled by all of our instantiations. Moreover, by replacing
predicate encryption with broadcast encryption (S-GORAM),
we sacriﬁce the possibility to enforce ABAC policies, although
we can still handle client-based read/write permissions.

Before we present the security and privacy results, we start
with a soundness result for the batched ZK proof of shufﬂe.
Theorem 1 (Soundness): Let ZKP be a zero-knowledge
proof system for a proof of shufﬂe correctness. Then the
batched ZK proof of shufﬂe deﬁned in Algorithm 8 is sound
with probability at least 1/2.

The following theorems characterize the security and pri-
vacy properties achieved by each cryptographic instantiation
presented in this paper.

Theorem 2 (GORAM): Let ΠPE and ΠPO be an attribute-
hiding predicate and predicate-only encryption scheme, ΠPKE
(resp. ΠSE) be a CPA-secure public-key (resp. private-key)
encryption scheme, and ZKP be a zero-knowledge proof
system. Then GORAM achieves secrecy, integrity, tamper-
resistance, obliviousness, and anonymity.

Theorem 3 (A-GORAM): Let ΠPE be an attribute-hiding
predicate encryption scheme, ΠSE be a CPA-secure private-
key encryption scheme, ΠDS be an existentially unforgeable
digital signature scheme, and ΠCHF be a collision-resistant,
key-exposure free chameleon hash function. Then A-GORAM
achieves secrecy, accountable integrity, and obliviousness.

Theorem 4 (S-GORAM): Let ΠBE be an adaptively se-
cure broadcast encryption scheme, ΠSE be a CPA-secure
private-key encryption scheme, ΠDS be an existentially un-
forgeable digital signature scheme, and ΠCHF be a collision-
resistant, key-exposure free chameleon hash function. Then S-
GORAM achieves secrecy, accountable integrity, and oblivi-
ousness.

VIII.

IMPLEMENTATION AND EXPERIMENTS

In this section, we present the concrete instantiations of
the cryptographic primitives that we previously described
(Section VIII-A), we study their asymptotic complexity (Sec-
tion VIII-B), describe our implementation (Section VIII-C),
and discuss the experimental evaluation (Section VIII-D).

351351

A. Cryptographic Instantiations

Private-key and public-key encryption. We use AES [27]
as private-key encryption scheme with an appropriate message
padding. Furthermore, we employ the El Gamal encryption
scheme [28] for public-key encryption as it fulﬁlls all prop-
erties that we require for GORAM, i.e., it is rerandomizable
and supports zero-knowledge proofs.

Encryption schemes for access control. We utilize the
predicate encryption scheme introduced by Katz et al. [5]. Its
ciphertexts are rerandomizable and we also show them to be
compatible with the Groth-Sahai proof system [6]. Concerning
the implementation, the predicate encryption scheme by Katz
et al. [5] is not efﬁcient enough since it relies on elliptic curves
on composite-order groups. In order to reach a high security
parameter, the composite-order setting requires us to use much
larger group sizes than in the prime-order setting, rendering the
advantages of elliptic curves practically useless. Therefore, we
use a scheme transformation proposed by David Freeman [29],
which works in prime-order groups and is more efﬁcient.

For implementing S-GORAM we use an adaptively secure

broadcast encryption scheme by Gentry and Waters [24].

Zero-knowledge proofs. We deploy several non-interactive
zero-knowledge proofs. For proving that a predicate-only ci-
phertext validly decrypts to 1 without revealing the key, we use
Groth-Sahai non-interactive zero-knowledge proofs4 [6]. More
precisely, we apply them in the proofs created in line 6.11
(read and write, see Algorithm 6 and Algorithm 7). We
employ plaintext-equivalence proofs (PEPs) [19], [30] for the
proofs in line 6.13. Furthermore, we use a proof of shufﬂe
correctness [7] and batched shufﬂe proofs in lines 6.8 and 7.8.

Chameleon hashes and digital
signatures. We use a
chameleon hash function by Nyberg and Rueppel [22], which
has the key-exposure freeness property. We combine the
chameleon hash tags with RSA signatures [31].

B. Computational Complexity

The computational and communication complexity of our
constructions, for both the server and the client, is O((B +
G) log N ) where N is the number of the entries in the
database, B is the block size of the entries in the database, and
G is the number of clients that have access to the database.
O(B log N ) originates from the ORAM construction and we
add O(G log N ) for the access structure. Hence, our solution
only adds a small overhead to the standard ORAM complexity.
The client-side storage is O(B log N ), while the server has to
store O(BN ) many data.

C. Java Implementation

We implemented the four different versions of GORAM in
Java (GORAM with off-the-shelf shufﬂe proofs and batched
shufﬂe proofs, A-GORAM, and S-GORAM). Furthermore,

4Groth-Sahai proofs are generally not zero-knowledge. However, in our case

the witnesses fulﬁll a special equation for which they are zero-knowledge.

we also implemented A-GORAM and S-GORAM on Ama-
zon EC2. For zero-knowledge proofs, we build on a li-
brary [32] that
implements Groth-Sahai proofs [6], which
internally relies on jPBC/PBC [33], [34].

Cryptographic setup. We use MNT curves [35] based on
prime-order groups for primes of length 224 bits. This results
in 112 bits of security according to different organizations [36].
We deploy AES with 128 bit keys and we instantiate the El
Gamal encryption scheme, the RSA signature scheme, and the
chameleon hash function with a security parameter of 2048
bits. According to NIST [36], this setup is secure until 2030.

D. Experiments

We evaluated the four different implementations. As a ﬁrst
experiment, we measured the computation times on client and
server for the read and write operation for the constructions
without accountable integrity. We performed these experiments
on an Intel Xeon with 8 cores and 2.60GHz in order to show
the efﬁciency gained by using batched shufﬂe proofs instead
of off-the-shelf zero-knowledge proofs of shufﬂe correctness.
We vary different parameters: the database size from 1GB to
1TB, the block size from 4KB to 1MB, the number of clients
from 1 to 10, the number of cores from 1 to 8, and for batched
shufﬂe proofs also the number of iterations k from 1 to 128.
We ﬁx a bucket size of 4 since Stefanov et al. [4] showed that
this value is sufﬁcient to prevent buckets from overﬂowing.

The second experiment focuses on the solution with ac-
countability. Here we measure also the overhead introduced
by our realization with respect to a state-of-the-art ORAM
construction, i.e., the price we pay to achieve a wide range
of security and privacy properties in a multi-client setting.
Another difference from the ﬁrst experiment is the hardware
setup. We run the server side of the protocol in Amazon
EC2 and the client side on a MacBook Pro with an Intel i7
and 2.90GHz. We vary the parameters as in the previous
experiment, except for the number of clients which we vary
from 1 to 100 for A-GORAM and from 1 to 10000 for S-
GORAM, and the number of cores which are limited to 4. In
the experiments where the number of cores is not explicitly
varied, we use the maximum number of cores available.

Discussion. The results of the experiments are reported in
Figure 9–14 and Table III. As shown in Figure 9a, varying
the block size has a linear effect in the construction without
batched shufﬂe proofs. As expected, the batched shufﬂe proofs
improve the computation time signiﬁcantly (Figure 9b). The
new scheme even seems to be independent of the block size,
at least for block sizes less than 64KB. This effect is caused
by the parallelization. Still, the homomorphic multiplication
of the public-key ciphertexts before the batched shufﬂe proof
computation depends on the block size (line 8.2). Figure 9c and
Figure 9d show the results for A-GORAM and S-GORAM.
Since the computation time is in practice almost independent
of the block size, we can choose larger block sizes in the case
of databases with large ﬁles, thereby allowing the client to read
(resp. write) a ﬁle in one shot, as opposed to running multiple
read (resp. write) operations. We identify a minimum compu-
tation time for 128KB as this is the optimal trade-off between
the index map size and the path size. The server computation

352352

Client read/write

Server

Client read/write

Server

Client read

Server

Client write

Client read

Server

Client write

10000
1000
100

s

n
i

e
m
T

i

4

16

64

256 1024

Block size in KB

(a) GORAM.

s

n
i

e
m
T

i

30

20

10

0

s

n
i

e
m
T

i

2

1

0

s

n
i

e
m
T

i

1
0.5
0

4

16

64

256 1024

4

16

64

256 1024

4

16

64

256 1024

Block size in KB

(b) GORAM with batched shufﬂe
proofs and k=3.

Block size in KB

(c) A-GORAM.

Block size in KB

(d) S-GORAM.

Figure 9. The average execution time for the read and write protocol on client and server for varying B where BN = 1GB and G = 4.

s

n
i

e
m
T

i

200
150
100
50
0

1

4

16 64 256 1024

Storage size in GB

s

n
i

e
m
T

i

10
8
6
4
2

s

n
i

e
m
T

i

2

1

0

s

n
i

e
m
T

i

2

1

0

1

4

16 64 256 1024

Storage size in GB

1

4

16 64 256 1024

Storage size in GB

1

4

16 64 256 1024

Storage size in GB

(a) GORAM with B = 4KB.

(b) GORAM with batched shufﬂe
proofs, B = 4KB, and k = 4.

(c) A-GORAM with B = 128KB.

(d) S-GORAM with B = 128KB.

Figure 10. The average execution time for the read and write protocol on client and server for varying BN where G = 4.

s

n
i

e
m
T

i

200
150
100
50
0

1 2 3 4 5 6 7 8 9 10

Number of clients

s

n
i

e
m
T

i

6

4

2

1 2 3 4 5 6 7 8 9 10

Number of clients

s

n
i

e
m
T

i

20
15
10
5
0

s

n
i

e
m
T

i

4

2

0

10

40

70

100

Number of clients

100 101 102 103 104

Number of clients

(a) GORAM with B = 4KB.

(b) GORAM with batched shufﬂe
proofs, B = 4KB, and k = 4.

(c) A-GORAM with B = 128KB.

(d) S-GORAM with B = 128KB.

Figure 11. The average execution time for the read and write protocol on client and server for varying G where BN = 1GB.

time is low and varies between 15ms and 345ms, while client
operations take less than 2 seconds for A-GORAM and less
than 1.3 seconds for S-GORAM. As we obtained the best
results for 4KB in the experiments for GORAM and 128KB
for the others, we use these block sizes in the sequel.

The results obtained by varying the storage size (Figure 10)
and the number of clients (Figure 11) prove what the compu-
tational complexity suggests. Nevertheless, it is interesting to
see the tremendous improvement in computation time between
GORAM with and without batched shufﬂe proofs. The results
obtained by varying the iteration time of the batched shufﬂe
proof protocol are depicted in Figure 13 and we verify the
expected linear dependency. Smaller values of k are more
efﬁcient but higher values give a better soundness probability.
If we compare A-GORAM and S-GORAM in Figure 11c and
Figure 11d we can see that S-GORAM scales well to a large
amount of users as opposed to A-GORAM. The good scaling
behavior is due to the used broadcast encryption scheme: it
only computes a constant number of pairings independent of
the number of users for decryption while the opposite holds for
predicate encryption. Nevertheless, we identify a linear growth
in the times for S-GORAM, which arises from the linear
number of exponentiations that are computed. For instance,

in order to write 128KB in a 1GB storage that is used by 100
users, A-GORAM needs about 20 seconds while S-GORAM
only needs about 1 second. Even when increasing the number
of users to 10000, S-GORAM requires only about 4 seconds,
a time that A-GORAM needs for slightly more than 10 users.
Figure 12 shows the results obtained by varying the number
of cores. In GORAM most of the computation, especially
the zero-knowledge proof computation, can be easily paral-
lelized. We observe this fact in both results (Figure 12a and
Figure 12b). In the efﬁcient construction we can parallelize
the top-level encryption and decryption, the veriﬁcation of
the entries, and the predicate ciphertext decryption. Also in
this case parallelization signiﬁcantly improves the performance
(Figure 12c and Figure 12d). Notice that we run the experi-
ments in this case for 20 clients, as opposed to 4 as done
for the other constructions, because the predicate ciphertext
decryption takes the majority of the computation time and,
hence, longer ciphertexts take longer to decrypt and the paral-
lelization effect can be better visualized.

Finally, Table III compares S-GORAM with the underly-
ing Path-ORAM protocol. Naturally, since Path-ORAM only
uses symmetric encryption, no broadcast encryption, and no
veriﬁcation with chameleon signatures, the computation time

353353

s

n
i

e
m
T

i

800
600
400
200
0

Client
Server

1

2

4

8

Number of cores

s

n
i

e
m
T

i

30

20

10

0

Client
Server

1

2

4

8

Number of cores

s

n
i

e
m
T

i

10
8
6
4
2

Client read
Client write

2

1.5

1

s

n
i

e
m
T

i

Client read
Client write

1

2

4

Number of cores

1

2

4

Number of cores

(a) GORAM with B = 4KB, and
G = 4.

(b) GORAM with batched shufﬂe
proofs, B = 4KB, G = 4, and
k = 4.

(c) A-GORAM with BN = 1GB,
B = 128KB, and G = 20.

(d) S-GORAM with BN = 1GB,
B = 128KB, and G = 20.

Figure 12. The average execution time for the read and write protocol on client and server for a varying number of cores where BN = 1GB.

s

n
i

e
m
T

i

80
60
40
20
0

Client
Server

1

2

3 4 5

10 16

32

64

128

Number of iterations k of the shufﬂe proof

Figure 13. The average execution time for the read and write protocol on
client and server for GORAM with batched shufﬂe proofs and varying k
where BN = 1GB, B = 8KB, and G = 4.

B
M
n
i

a
t
a
D

50
40
30
20
10
0

GORAM
Path-ORAM

4

16

64

256 1024

B in KB

%
n
i

d
a
e
h
r
e
v
O

1.05

1.04

1.03

1.02

Overhead

4

16

64

256 1024

B in KB

Figure 14.
The up-/download amount of data compared between Path-
ORAM [4] and S-GORAM for varying B while BN = 1GB and G = 4.

is much lower. However, the bottleneck of both constructions
is actually the amount of data that has to be downloaded and
uploaded by the client (Figure 14). The time required to upload
and download data may take much more time than the com-
putation time, given today’s bandwidths. Here the overhead
is only between 1.02% and 1.05%. For instance, assuming
a mobile client using LTE (100Mbit/s downlink and 50Mbit/s
uplink in peak) transferring 2 and 50 MB takes 480ms and 12s,
respectively. Under these assumptions, considering a block size
of 1MB, we get a combined computation and communication
overhead of 8% for write and 7% for read, which we consider
a relatively low price to pay to get a wide range of security
and privacy properties in a multi-client setting.

IX. CASE STUDY: PERSONAL HEALTH RECORDS
We brieﬂy discuss a potential application of GORAM,
namely, a privacy-preserving personal health record (PHR)

Client Read Client Write

Scheme
S-GORAM 0.981s
Path-ORAM 0.042s

1.075s
0.042s

Server
0.068s
0.002s

management system. As the patient should have the control
of her own record, the patient is the data owner. The server
is some cloud storage provider, which may be chosen by the
patient or directly by the state for all citizens (e.g., ELGA in
Austria). The healthcare personal (doctors, nurses, pharmacies,
and so on) constitutes the clients.

to sell

We discuss now possible real-world attacks on PHRs and
how the usage of GORAM prevents them. One typical threat
is the cloud provider trying to learn customer information
(e.g.,
it or to use it for targeted advertising). For
instance, as previously discussed, monitoring the accesses to
DNA sequences would allow the service provider to learn
the patient’s disease: these kinds of attacks are not possible
because of obliviousness and data secrecy. Another possible
attack could be a pharmacy that tries to increase its proﬁt
by changing a prescription for a cheap medicine into one
that prescribes an expensive medicine. However, in GORAM
pharmacies would not have write access to prescriptions,
and hence, these cannot be changed or, in A-GORAM, the
misbehaving pharmacy can be blamed by the data owner. A
common procedure in order to sign a contract with a health
insurance is the health check. The patient might want to hide
health information from the insurance in order to get a lower
fee. To this end, the patient could simply try to drop this
information. Dropping of entries in the database is, however,
either prevented by making such documents permanent or, in
A-GORAM, by letting the insurance, who sees that some
documents are missing, blame the patient. Using the backup
strategy, the missing documents can be restored.

Finally, we think that GORAM with batched shufﬂe proofs
(even more so A-GORAM and S-GORAM) is a practical
solution for the management of today’s PHRs, since they are
of rather small size. For instance, the data today stored in e-
health cards is at most 128KB. The current trend is to store the
remaining medical information (e.g., DNA information) on an
external server, which can be accessed by using the card. This
is exactly our setting, except that we allow for accessing PHRs
even without the card, which is crucial in emergency situations.
DNA information takes approximately 125MB5 [37] and all
our constructions offer an adequate performance for databases
of a few gigabytes, with A-GORAM and S-GORAM per-
forming better for the retrieval of large amounts of data, thanks
to the possibility of using larger block sizes.

Table III: Comparison of the computation times between Path-
ORAM [4] (single-client!) and S-GORAM on 1GB storage
size, 128KB block size and 100 clients.

5The actual DNA sequence takes about 200GB but one usually shares only
the mutations, i.e., the differences of the considered genome to the average
human genome. These mutations are only 0.1% of the overall sequence.

354354

X. RELATED WORK

Privacy-preserving outsourced storage. Oblivious RAM
(ORAM) [3] is a technique originally devised to protect the
access pattern of software on the local memory and thus to pre-
vent the reverse engineering of that software. The observation
is that encryption by itself prevents an attacker from learning
the content of any memory cell but monitoring how memory
is accessed and modiﬁed may still leak a great amount of
sensitive information. Recent advances in ORAM show that
it is efﬁcient enough to hide the data and the user’s access
pattern in storage outsourcing services [2], [12], [38]–[45].

While a few ORAM constructions guarantee the integrity of
user data [46], [47], none of them is suitable to share data with
potentially distrustful clients. Goodrich et al. [48] studied the
problem of multi-client ORAM, but their attacker model does
not include malicious, and potentially colluding, clients. Fur-
thermore, their construction does not provide ﬁne-grained ac-
cess control mechanisms, i.e., either all members of a group
have access to a certain data, or none has. Finally, this scheme
does not allow the clients to verify the data integrity.

The fundamental problem in existing ORAM constructions
is that all clients must have access to the ORAM key, which
allows them to read and potentially disrupt the entire database.
A few recent works have started to tackle this prob-
lem. Franz et al. have introduced the concept of delegated
ORAM [49]. The idea is to encrypt and sign each entry with
a unique set of keys, initially only known to the data owner:
giving a client the decryption key (resp. the decryption and
signing keys) sufﬁces to grant read (resp. write) access to
that entry. This solution, however, has two drawbacks that
undermine its deployment in practice. First, the data owner
has to periodically visit the server for checking the validity
of the signatures accompanying the data to be inserted in
the database (thus tracking the individual client accesses) and
reshufﬂing the ORAM according to the access history in order
to enable further unlinkable ORAM accesses. Furthermore,
revoking access for a single client requires the data owner to
change (and distribute) the capabilities of all other users that
have access to that ﬁle.

Huang and Goldberg have recently presented a protocol for
outsourced private information retrieval [50], which is obtained
by layering a private information retrieval (PIR) scheme on top
of an ORAM data layout. This solution is efﬁcient and conceals
client accesses from the data owner, but it does not give clients
the possibility to update data. Moreover, it assumes (cid:4) non-
colluding servers, which is due to the usage of information
theoretic multi-server PIR.

De Capitani di Vimercati et al. [51] proposed a storage
service that uses selective encryption as a means for providing
ﬁne-grained access control. The focus of their work is to study
how indexing data in the storage can leak information to clients
that are not allowed to access these data, although they are
allowed to know the indices. The authors do, however, neither
consider veriﬁability nor obliviousness, which distinguishes
their storage service from ours.

intentionally tried to strive for a solution without
hardware, only making use of cryptographic primitives.

trusted

Veriﬁable outsourced storage. Verifying the integrity of data
outsourced to an untrusted server is a research problem that
has recently received increasing attention in the literature.
Schr¨oder and Schr¨oder introduced the concept of veriﬁable
data streaming (VDS) and an efﬁcient cryptographic realization
thereof [56], [57]. In a veriﬁable data streaming protocol, a
computationally limited client streams a long string to the
server, who stores the string in its database in a publicly
veriﬁable manner. The client has also the ability to retrieve
and update any element in the database. Papamathou et al.
[58] proposed a technique, called streaming authenticated data
structures,
to delegate certain com-
putations over streamed data to an untrusted server and to
verify their correctness. Other related approaches are proofs-
of-retrievability [59]–[62], which allow the server to prove to
the client that it is actually storing all of the client’s data,
veriﬁable databases [63], which differ from the previous ones
in that the size of the database is ﬁxed during the setup phase,
and dynamic provable data possession [64]. All the above do
not consider the privacy of outsourced data. While some of the
latest work has focused on guaranteeing the conﬁdentiality of
the data [65], to the best of our knowledge no existing paper
in this line of research takes into account obliviousness.

that allows the client

Personal Health Records. Security and privacy concerns seem
to be one of the major obstacles towards the adoption of cloud-
based PHRs [66], [67], [68]. Different cloud architectures have
been proposed [69], as well as database constructions [70],
[71], in order to overcome such concerns. However, none
of these works takes into account the threat of a curious
storage provider and, in particular, none of them enforces the
obliviousness of data accesses.

XI. CONCLUSION AND FUTURE WORK

This paper introduces the concept of Group ORAM, which
captures an unprecedented range of security and privacy prop-
erties in the cloud storage setting. The fundamental idea un-
derlying our instantiation is to extend a state-of-the-art ORAM
scheme [4] with access control mechanisms and integrity
proofs while preserving obliviousness. To tackle the challenge
of devising an efﬁcient and scalable construction, we devised a
novel zero-knowledge proof technique for shufﬂe correctness
as well as a new accountability technique based on chameleon
signatures, both of which are generically applicable and thus
of independent interest. We showed how GORAM is an ideal
solution for personal record management systems.

As a future work, we intend to relax the assumptions on the
server behavior, under which some of the security and privacy
properties are proven, developing suitable cryptographic tech-
niques. A further research goal is the design of cryptographic
solutions allowing clients to learn only limited information
(e.g., statistics) about the dataset.

ACKNOWLEDGMENTS

Finally, there have been a number of works leveraging
trusted hardware to realize ORAM schemes [52], [53] includ-
ing some in the multi-client setting [54], [55]. We, however,

This work was supported by the German research foun-
dation (DFG) through the Emmy Noether program, by the
German Federal Ministry of Education and Research (BMBF)

355355

through the Center for IT-Security, Privacy and Accountability
(CISPA), and by an Intel Early Career Faculty Honor Program
Award. Finally, we thank the reviewers for their helpful com-
ments.

REFERENCES

[1] M. Islam, M. Kuzu, and M. Kantarcioglu, “Access Pattern Disclosure
on Searchable Encryption: Ramiﬁcation, Attack and Mitigation,” in
NDSS’12.

Internet Society, 2012.

[2] B. Pinkas and T. Reinman, “Oblivious RAM Revisited,” in CRYPTO’10,

ser. LNCS. Springer, 2010, pp. 502–519.

[5]

[3] O. Goldreich and R. Ostrovsky, “Software Protection and Simulation
on Oblivious RAMs,” J. ACM, vol. 43, no. 3, pp. 431–473, May 1996.
[4] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren, X. Yu, and
S. Devadas, “Path ORAM: An Extremely Simple Oblivious RAM
Protocol,” in CCS’13. ACM, 2013.
J. Katz, A. Sahai, and B. Waters, “Predicate Encryption Supporting
Disjunctions, Polynomial Equations, and Inner Products,” in EURO-
CRYPT’08. Springer, 2008, pp. 146–162.
J. Groth and A. Sahai, “Efﬁcient Noninteractive Proof Systems for
Bilinear Groups,” SIAM J. Comp., vol. 41, no. 5, pp. 1193–1232, 2012.
[7] S. Bayer and J. Groth, “Efﬁcient Zero-Knowledge Argument for Cor-
rectness of a Shufﬂe,” in EUROCRYPT’12, ser. LNCS. Springer, 2012,
pp. 263–280.

[6]

[8] M. Maffei, G. Malavolta, M. Reinert, and D. Schr¨oder, “Privacy and
Access Control for Outsourced Personal Records,” Cryptology ePrint
Archive, Report 2015/224, 2015, http://eprint.iacr.org/.
I. E. Akkus, R. Chen, M. Hardt, P. Francis, and J. Gehrke, “Non-tracking
Web Analytics,” in CCS’12. ACM, 2012, pp. 687–698.

[9]

[10] R. Chen, I. E. Akkus, and P. Francis, “SplitX: High-Performance Private

Analytics,” in SIGCOMM’13. ACM, 2013, pp. 315–326.

[11] S. Goldwasser and S. Micali, “Probabilistic Encryption & How To Play
Mental Poker Keeping Secret All Partial Information,” in STOC’82.
ACM, 1982, pp. 365–377.

[12] E. Shi, T.-H. H. Chan, E. Stefanov, and M. Li, “Oblivious RAM
With O((log n)3) Worst-Case Cost,” in ASIACRYPT’11, ser. LNCS.
Springer, 2011, pp. 197–214.

[13] R. Dingledine, N. Mathewson, and P. Syverson, “Tor: The Second-
Generation Onion Router,” in USENIX’04. USENIX Association, 2004,
pp. 303–320.

[14] M. Maffei, K. Pecina, and M. Reinert, “Security and Privacy by

Declarative Design,” in CSF’13.

IEEE Press, 2013, pp. 81–96.

[15] M. Backes, S. Lorenz, M. Maffei, and K. Pecina, “Anonymous Webs

of Trust,” in PETS’10, ser. LNCS. Springer, 2010, pp. 130–148.

[16] M. Backes, M. Maffei, and K. Pecina, “Automated Synthesis of Privacy-
Internet Society,

Preserving Distributed Applications,” in NDSS’12.
2012.

[17] F. Baldimtsi and A. Lysyanskaya, “Anonymous Credentials Light,” in

CCS’13. ACM, 2013, pp. 1087–1098.

[18] D. L. Chaum, “Untraceable Electronic Mail, Return Addresses, and

Digital Pseudonyms,” Comm. ACM, vol. 24, no. 2, pp. 84–90, 1981.

[19] M. Jakobsson and A. Juels, “Millimix: Mixing in Small Batches,”

DIMACS, Tech. Rep. 99-33, 1999.

[20] M. Jakobsson, A. Juels, and R. L. Rivest, “Making Mix Nets Robust
for Electronic Voting by Randomized Partial Checking,” in USENIX’02.
USENIX Association, 2002, pp. 339–353.

[21] A. Fiat and A. Shamir, “How to Prove Yourself: Practical Solutions
Springer,

to Identiﬁcation and Signature Problems,” in CRYPTO’86.
1987, pp. 186–194.

[22] G. Ateniese and B. de Medeiros, “On the Key Exposure Problem in
Chameleon Hashes,” in SCN’04, ser. LNCS. Springer, 2004, pp. 165–
179.
J. Camenisch, M. Kohlweiss, and C. Soriente, “An Accumulator Based
on Bilinear Maps and Efﬁcient Revocation for Anonymous Credentials,”
in PKC’09, ser. LNCS. Springer, 2009, pp. 481–500.

[23]

[24] C. Gentry and B. Waters, “Adaptive Security in Broadcast Encryption
Systems (with Short Ciphertexts),” in EUROCRYPT’09, ser. LNCS.
Springer, 2009, pp. 171–188.

[25] A. Demers, D. Greene, C. Hauser, W. Irish, J. Larson, S. Shenker,
H. Sturgis, D. Swinehart, and D. Terry, “Epidemic Algorithms for
Replicated Database Maintenance,” in PODC’87. ACM, 1987, pp.
1–12.

[26] R. K¨usters, T. Truderung, and A. Vogt, “Accountability: Deﬁnition and
Relationship to Veriﬁability,” in CCS’10. ACM, 2010, pp. 526–535.
J. Daemen and V. Rijmen, The Design of Rijndael, AES - The Advanced
Encryption Standard. Springer, 2002.

[27]

[28] T. El Gamal, “A Public Key Cryptosystem and a Signature Scheme
Based on Discrete Logarithms,” in CRYPTO’84, ser. LNCS. Springer,
1985, pp. 10–18.

[29] D. M. Freeman, “Converting Pairing-Based Cryptosystems

from
Composite-Order Groups to Prime-Order Groups,” in EUROCRYPT’10,
ser. LNCS. Springer, 2010, pp. 44–61.

[30] C. P. Schnorr, “Efﬁcient Identiﬁcation and Signatures for Smart Cards,”

in CRYPTO’89, ser. LNCS. Springer, 1989, pp. 239–252.

[31] R. L. Rivest, A. Shamir, and L. Adleman, “A Method for Obtaining Dig-
ital Signatures and Public-key Cryptosystems,” Comm. ACM, vol. 21,
no. 2, pp. 120–126, Feb. 1978.
J. Backes, S. Lorenz, and K. Pecina, “Zero-knowledge Library,” online
at github.com/peloba/zk-library.

[32]

[33] A. D. Caro, “jPBC - Java Library for Pairing Based Cryptography,”

online at http://gas.dia.unisa.it/projects/jpbc/.

[34] B. Lynn, “PBC - C Library for Pairing Based Cryptography,” online at

http://crypto.stanford.edu/pbc/.

[35] A. Miyaji, M. Nakabayashi, and S. Takano, “Characterization of Elliptic
Curve Traces under FR-Reduction,” in ICISC’00, ser. LNCS, vol. 2015.
Springer, 2001, pp. 90–108.

[36] BlueKrypt, “Cryptograhpic Key Length Recommendation,” online at

genome?”
https://medium.com/precision-medicine/

human

the

[37] R.

www.keylength.com.
Robinson,
at

J.
Online
how-big-is-the-human-genome-e90caa3409b0.

“How big

is

[38] B. Carbunar and R. Sion, “Regulatory Compliant Oblivious RAM,” in

ACNS’10, ser. LNCS. Springer, 2010, pp. 456–474.

[39] M. Ajtai, “Oblivious RAMs Without Cryptographic Assumptions,” in

STOC’10. ACM, 2010, pp. 181–190.

[40] M. T. Goodrich and M. Mitzenmacher, “Privacy-Preserving Access of
Outsourced Data via Oblivious RAM Simulation,” in ICALP’11, ser.
LNCS. Springer, 2011, pp. 576–587.
I. Damg˚ard, S. Meldgaard, and J. B. Nielsen, “Perfectly Secure Oblivi-
ous RAM Without Random Oracles,” in TCC’11, ser. LNCS. Springer,
2011, pp. 144–163.

[41]

[42] E. Stefanov and E. Shi, “Multi-Cloud Oblivious Storage,” in CCS’13.

ACM, 2013, pp. 247–258.

[43] M. Maas, E. Love, E. Stefanov, M. Tiwari, E. Shi, K. Asanovic, J. Ku-
biatowicz, and D. Song, “PHANTOM: Practical Oblivious Computation
in a Secure Processor,” in CCS’13. ACM, 2013, pp. 311–324.

[44] E. Stefanov and E. Shi, “ObliviStore: High Performance Oblivious

Cloud Storage,” in S&P’13.

IEEE Press, 2013, pp. 253–267.

[45] D. Apon, J. Katz, E. Shi, and A. Thiruvengadam, “Veriﬁable Oblivious

Storage,” in PKC’14, ser. LNCS. Springer, 2014, pp. 131–148.

[46] P. Williams, R. Sion, and B. Carbunar, “Building Castles out of Mud:
Practical Access Pattern Privacy and Correctness on Untrusted Storage,”
in CCS’08. ACM, 2008, pp. 139–148.

[47] E. Stefanov, E. Shi, and D. Song, “Towards Practical Oblivious RAM,”

in NDSS’12.

Internet Society, 2012.

[48] M. T. Goodrich, M. Mitzenmacher, O. Ohrimenko, and R. Tamassia,
“Privacy-Preserving Group Data Access via Stateless Oblivious RAM
Simulation,” in SODA’12. SIAM, 2012, pp. 157–167.

[49] M. Franz, C. Carbunar, R. Sion, S. Katzenbeisser, M. Sotakova,
P. Williams, and A. Peter, “Oblivious Outsourced Storage with Del-
egation,” in FC’11. Springer, 2011, pp. 127–140.

[50] Y. Huang and I. Goldberg, “Outsourced Private Information Retrieval

with Pricing and Access Control,” in WPES’13. ACM, 2013.

[51] S. De Capitani di Vimercati, S. Foresti, S. Jajodia, S. Paraboschi, and
P. Samarati, “Private Data Indexes for Selective Access to Outsourced
Data,” in WPES’11. ACM, 2011, pp. 69–80.

356356

[52] M. Backes, A. Kate, M. Maffei, and K. Pecina, “ObliviAd: Provably
IEEE

Secure and Practical Online Behavioral Advertising,” in S&P’12.
Press, 2012, pp. 257–271.

[53] A. Kate, M. Maffei, P. Moreno-Sanchez, and K. Pecina, “Privacy
Internet

Preserving Payments in Credit Networks,” in NDSS’15.
Society, 2015.

[54] A. Iliev and S. W. Smith, “Protecting Client Privacy with Trusted
Computing at the Server,” IEEE Security and Privacy, vol. 3, no. 2,
pp. 20–28, Mar. 2005.
J. R. Lorch, B. Parno, J. Mickens, M. Raykova, and J. Schiffman,
“Shroud: Ensuring Private Access to Large-scale Data in the Data
Center,” in FAST’13. USENIX Association, 2013, pp. 199–214.

[55]

[56] D. Schr¨oder and H. Schr¨oder, “Veriﬁable Data Streaming,” in CCS’12.

ACM, 2012, pp. 953–964.

[57] D. Schr¨oder and M. Simkin, “VeriStream - A Framework for Veriﬁable

Data Streaming,” in FC’15. Springer, 2015.

[58] C. Papamanthou, E. Shi, R. Tamassia, and K. Yi, “Streaming Authen-

ticated Data Structures ,” in EUROCRYPT’13, 2013.

[59] H. Shacham and B. Waters, “Compact Proofs of Retrievability,” in

ASIACRYPT’08, ser. LNCS. Springer, 2008, pp. 90–107.

[60] D. L. G. Filho and P. S. L. M. Barreto, “Demonstrating Data Possession
and Uncheatable Data Transfer,” Cryptology ePrint Archive, Report
2006/150, 2006, http://eprint.iacr.org/.

[61] T. Schwarz and E. L. Miller, “Store, Forget, and Check: Using Algebraic

Signatures to Check Remotely Administered Storage,” 2006.

[62] E. Stefanov, M. van Dijk, A. Oprea, and A. Juels, “Iris: A Scalable
Cloud File System with Efﬁcient Integrity Checks,” Cryptology ePrint
Archive, Report 2011/585, 2011, http://eprint.iacr.org/.

[63] S. Benabbas, R. Gennaro, and Y. Vahlis, “Veriﬁable Delegation of Com-
putation Over Large Datasets,” in CRYPTO’11, ser. LNCS. Springer,
2011, pp. 111–131.

[64] C. Erway, A. K¨upc¸ ¨u, C. Papamanthou, and R. Tamassia, “Dynamic

Provable Data Possession,” in CCS’09. ACM, 2009, pp. 213–222.

[66]

[65] M. van Dijk, A. Juels, A. Oprea, R. L. Rivest, E. Stefanov, and
N. Triandopoulos, “Hourglass Schemes: How to Prove That Cloud Files
Are Encrypted,” in CCS’12. ACM, 2012, pp. 265–280.
I. Carri´on Se˜nor, L. J. Fern´andez-Alem´an, and A. Toval, “Are Personal
Health Records Safe? A Review of Free Web-Accessible Personal
Health Record Privacy Policies,” J. Med. Int. Res., vol. 14, no. 4, 2012.
[67] D. Daglish and N. Archer, “Electronic Personal Health Record Systems:
A Brief Review of Privacy, Security, and Architectural Issues,” World
Congress on Privacy, Security, Trust and the Management of e-Business,
pp. 110–120, 2009.

[68] K. T. Win, W. Susilo, and Y. Mu, “Personal Health Record Systems and
Their Security Protection,” J. Med. Sys., vol. 30, no. 4, pp. 309–315,
2006.

[69] H. L¨ohr, A.-R. Sadeghi, and M. Winandy, “Securing the e-Health

Cloud,” in IHI’10. ACM, 2010, pp. 220–229.

[70] M. Li, S. Yu, K. Ren, and W. Lou, “Securing Personal Health Records
in Cloud Computing: Patient-Centric and Fine-Grained Data Access
Control in Multi-owner Settings,” in SECURECOMM’10, 2010.

[71] P. Korde, V. Panwar, and S. Kalse, “Securing Personal Health Records
in Cloud using Attribute Based Encryption,” Int. J. Eng. Adv. Tech.,
2013.

APPENDIX

FORMAL DEFINITIONS

A. Secrecy

Deﬁnition 2 (Secrecy): A Group ORAM GORAM = (gen,
addCl, addE, chMode, read, write) preserves secrecy, if for ev-
ery PPT adversary A the following probability is negligible in
(cid:12)(cid:12)(cid:12)Pr[ExpSec
(cid:12)(cid:12)(cid:12)
the security parameter λ:

A
GORAM(λ, 0) = 1]

GORAM(λ, 1) = 1] − Pr[ExpSec
A
A
GORAM(λ, b) is the following game:

where ExpSec

357357

(2) On input addE(a, d) by A,

Setup: The challenger runs (capO, DB) ← gen(1λ), sets
AC := [], and runs a black-box simulation of A to which
it hands over DB.
Queries: The challenger provides A with interactive interfaces
addCl, addE, chMode, read, write, and corCl that A may query
adaptively and in any order. Each round A can query exactly
one interface. These interfaces are described below:
(1) On input addCl(a) by A,

the challenger executes
addCl(capO, a) locally and stores the capability capi
returned by the algorithm.
the challenger executes
(cid:3)CaddE(capO, a, d),SaddE(DB)(cid:4) in interaction with A,
where the former plays the role of the client while the
latter plays the role of the server.
(3) On input chMode(a, j) by A,
the challenger executes
(cid:3)CchMode(capO, a, j),SchMode(DB)(cid:4) in interaction with A.
(4) On input corCl(i) by A, the challenger hands over the
capability capi related to the i-th client in the access
control matrix AC.
(cid:3)Cread(capi, j),Sread(DB)(cid:4) in interaction with A.
(cid:3)Cwrite(capi, j, d),Swrite(DB)(cid:4) in interaction with A.

read(i, j) by A,
(5) On input
(6) On input write(i, j, d) by A,

the challenger executes

the challenger executes

Challenge: Finally, A outputs (j, (d0, d1)), where j is an index
denoting the database entry on which A wants to be challenged
and (d0, d1) is a pair of entries such that |d0| = |d1|. The
challenger accepts the request only if AC(i, j) = ⊥, for every
i corrupted by A in the query phase. Afterwards it invokes
(cid:3)Cwrite(capO, j, db),Swrite(DB)(cid:4) in interaction with A.
Output: In the output phase A still has access to the interfaces
except for addCl on input a such that a(j) (cid:7)= ⊥; corCl on input
i such that AC(i, j) (cid:7)= ⊥; and chMode on input a, i with
a(i) (cid:7)= ⊥ for some previously corrupted client i. Eventually,
A stops, outputting a bit b(cid:2). The challenger outputs 1 if and
only if b = b(cid:2).

B. Integrity

Deﬁnition 3 (Integrity): A Group ORAM GORAM =
(gen, addCl, addE, chMode, read, write) preserves integrity, if
for every PPT adversary A the following probability is negli-
gible in the security parameter:

Pr[ExpInt

A
GORAM(λ) = 1]

A
GORAM(λ) is the following game:

where ExpInt
Setup: The challenger runs (capO, DB) ← gen(1λ), sets
AC := [], and runs a black-box simulation of A. Furthermore,
(cid:2)
the challenger initializes a second database DB
:= [] which is
managed locally.
Queries: The challenger provides A with the same interfaces
as in Deﬁnition 2, which A may query adaptively and in any
order. Since DB is maintained on the challenger’s side, the
queries to addE, chMode, read and write are locally executed
(cid:2)
by the challenger. Furthermore, the challenger updates DB
locally for all affecting interface calls.

Challenge: Finally, the adversary outputs an index j∗ which
he wants to be challenged on. If there exists a capability capi
provided to A with AC(i, j∗
) = rw, the challenger aborts.
Otherwise it runs d∗ ← (cid:3)Cread(capO, j∗
),Sread(DB)(cid:4) locally.
Output: It outputs 1 if and only if d∗ (cid:7)= DB

(j∗

).

(cid:2)

C. Tamper Resistance

Deﬁnition 4 (Tamper resistance): A

ORAM
GORAM = (gen, addCl, addE, chMode, read, write)
is
tamper-resistant, if for every PPT adversary A the following
probability is negligible in the security parameter:

Group

Pr[ExpTamRes

A
GORAM(λ) = 1]

(cid:2)

A
GORAM(λ) is the following game:

which is managed locally.

where ExpTamRes
Setup: The challenger runs the Setup phase as in Deﬁnition 2.
Furthermore, it forwards DB to A and initializes a second
database DB
Queries: The challenger provides A with the same interfaces
as in Deﬁnition 2, which A may query adaptively and in any
order. Furthermore, the challenger updates DB
locally for all
affecting interface calls.
Challenge: Finally, the adversary outputs an index j∗ which
he wants to be challenged on. If there exists a capability capi
that has ever been provided to A such that AC(i, j∗
) =
rw, then the challenger aborts. The challenger runs d∗ ←
(cid:3)Cread(capO, j∗
Output: It outputs 1 if and only if d∗ (cid:7)= DB

),Sread(DB)(cid:4) in interaction with A.
(j∗
).

(cid:2)

(cid:2)

D. Obliviousness

Deﬁnition 5 (Obliviousness): A Group ORAM GORAM
= (gen, addCl, addE, chMode, read, write) is oblivious, if for
every PPT adversary A the following probability is negligible
in the security parameter:

(cid:12)(cid:12)(cid:12)Pr[ExpObv

GORAM(λ, 1) = 1]−
A

Pr[ExpObv

A
GORAM(λ, 0) = 1]

(cid:12)(cid:12)(cid:12)

A
GORAM(λ, b) is the following game:

where ExpObv
Setup: The challenger runs (capO, DB) ← gen(1λ) as in
Deﬁnition 2 and it forwards DB to A.
Queries: The challenger provides A with the same interfaces
as in Deﬁnition 2 except corCl, which A may query adap-
tively and in any order. Furthermore, A is provided with the
following additional interface:

(1) On

j1 ≤ |DB|, and i0, i1

query({(i0, j0), (i0, j0, d0)},{(i1, j1),
input
(i1, j1, d1)}) by A,
the challenger checks whether
j0 ≤ |DB|,
are valid
clients. Furthermore,
the operations
that
requested by A are allowed by AC. If not it aborts.
, jb),Sread(DB)(cid:4) or
Otherwise it executes
, jb, db),Swrite(DB)(cid:4) depending on the input,
(cid:3)Cwrite(capib
in interaction with A. Here the challenger plays the role
of the client and A plays the role of the server.

checks
(cid:3)Cread(capib

it

Output: Finally, A outputs a bit b(cid:2). The challenger outputs 1
if and only if b = b(cid:2).

358358

E. Anonymity

= (gen, addCl, addE, chMode, read, write)
preserving,
probability is negligible in the security parameter:

Deﬁnition 6 (Anonymity): A Group ORAM GORAM
is anonymity-
for every PPT adversary A the following
(cid:12)(cid:12)(cid:12)Pr[ExpAnon

GORAM(λ, 1) = 1]−
A

if

Pr[ExpAnon

A
GORAM(λ, 0) = 1]

(cid:12)(cid:12)(cid:12)

A
GORAM(λ, b) is the following game:

(4) On input write(capi, j, d) by A,

where ExpAnon
Setup: The challenger runs (capO, DB) ← gen(1λ) and it
forwards capO and DB to A.
Queries: The challenger provides A with read and a write
interactive interfaces that A may query adaptively and in any
order. Each round A can query exactly one interface. The
interfaces are described below:
(3) On input read(capi, j) by A, the challenger executes
(cid:3)Cread(capi, j),Sread(DB)(cid:4) in interaction with A, where
the former plays the role of the server and the latter plays
the role of the client.
the challenger exe-
cutes (cid:3)Cwrite(capi, j, d),Swrite(DB)(cid:4) in interaction with A,
where the former plays the role of the server and the latter
plays the role of the client.
Challenge: A outputs
, capi1 ),{j, (j, d)}), where
((capi0
(capi0
, capi1 ) is a pair of capabilities, j is an index denoting
the database entry on which A wishes to be challenged, and
d is some data. The challenger checks whether AC(i0, j) =
AC(i1, j):
then it aborts, otherwise it executes
if not,
(cid:3)Cread(capib
, j, d),Swrite(DB)(cid:4)
, j),Sread(DB)(cid:4) or (cid:3)Cwrite(capib
in interaction with A.
Output: Finally, A outputs a bit b(cid:2). The challenger outputs 1
if and only if b = b(cid:2).

F. Accountability

Deﬁnition 7 (Accountability): A Group ORAM GORAM
= (gen, addCl, addE, chMode, read, write, blame) is account-
able, if for every PPT adversary A the following probability is
negligible in the security parameter:

Pr[ExpAcc

A
GORAM(λ) = 1]

A
GORAM(λ) is the following game:

where ExpAcc
Setup: The challenger runs the Setup phase as in Deﬁnition 3.
Queries: The challenger runs the Query phase as in Deﬁni-
tion 3.
Challenge: Finally, the adversary outputs an index j∗ which
he wants to be challenged on. If there exists a capability capi
provided to A such that AC(i, j∗
) = rw, then the challenger
aborts. The challenger runs d∗ ← (cid:3)Cread(capO, j∗
),Sread(DB)(cid:4)
and L ← blame(capO, Log, j∗
) and ∃ i ∈ L
Output: It outputs 1 if and only if d∗ (cid:7)= DB
(j∗
that has not been queried by A to the interface corCl(·) or
L = [].

) locally.

(cid:2)

