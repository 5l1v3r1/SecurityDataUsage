Unearthing Stealthy Program Attacks

Buried in Extremely Long Execution Paths

Xiaokui Shu

Department of Computer
Science, Virginia Tech
Blacksburg, VA 24060
subx@cs.vt.edu

Danfeng (Daphne) Yao
Department of Computer
Science, Virginia Tech
Blacksburg, VA 24060
danfeng@cs.vt.edu

Naren Ramakrishnan
Department of Computer
Science, Virginia Tech
Blacksburg, VA 24060
naren@cs.vt.edu

ABSTRACT
Modern stealthy exploits can achieve attack goals without
introducing illegal control ﬂows, e.g., tampering with non-
control data and waiting for the modiﬁed data to propa-
gate and alter the control ﬂow legally. Existing program
anomaly detection systems focusing on legal control ﬂow at-
testation and short call sequence veriﬁcation are inadequate
to detect such stealthy attacks. In this paper, we point out
the need to analyze program execution paths and discover
event correlations in large-scale execution windows among
millions of instructions. We propose an anomaly detection
approach with two-stage machine learning algorithms to rec-
ognize diverse normal call-correlation patterns and detect
program attacks at both inter- and intra-cluster levels. We
implement a prototype of our approach and demonstrate its
eﬀectiveness against three real-world attacks and four syn-
thetic anomalies with less than 0.01% false positive rates
and 0.1~1.3 ms analysis overhead per behavior instance (1k
to 50k function or system calls).

Categories and Subject Descriptors
K.6 [Management Of Computing And Information
Systems]: Security and Protection; D.4 [Operating Sys-
tems]: Security and Protection

General Terms
Security

Keywords
Intrusion Detection; Program Attack; Long Execution Path;
Function Call; Event Correlation; Machine Learning

1.

INTRODUCTION

Injecting library/system calls and tampering with return
addresses on the stack are popular early-age exploit tech-
niques. Modern exploits, however, are developed with more

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’15, October 12–16, 2015, Denver, Colorado, USA.
© 2015 ACM. ISBN 978-1-4503-3832-5/15/10 ...$15.00.
DOI: http://dx.doi.org/10.1145/2810103.2813654.

subtle control ﬂow manipulation tactics to hide them from
existing detection tools. One example is the sshd ﬂag vari-
able overwritten attack (an example of non-control data at-
tacks [5]). An attacker overwrites a ﬂag variable, which
indicates the authentication result, before the authentica-
tion procedure. As a result, the attacker bypasses critical
security control and logs in after a failed authentication.

Besides the aforementioned attack, stealthy attacks can
also be constructed based on existing exploits. Wagner and
Soto ﬁrst diluted a compact exploit (several system calls)
into a long sequence (hundreds of system calls) [46]. Kruegel
et al. further advanced this approach by building an attack
into an extremely long execution path [27].
In their pro-
posed exploit, the attacker accomplishes one element of an
attack vector, relinquishes the control of the target program,
and waits for another opportunity (exploited vulnerability)
to construct the next attack element. Therefore, the ele-
ments of the attack vector are buried in an extreme long
execution path (millions of instructions). We refer stealthy
attacks whose construction and/or consequence are buried
into long execution paths and cannot be revealed by any
small fragment of the entire path as aberrant path attacks.

Call-based program anomaly detection systems have been
proposed as a general solution to detect program attacks
without specifying attack signatures. Most existing pro-
gram anomaly detection systems can be categorized into
two detection paradigms: short call sequence validation and
ﬁrst-order automaton transition veriﬁcation. The former is
primarily based on deterministic [10, 11, 21] or probabilis-
tic [14, 29] n-grams (short fragments of a long trace) veri-
ﬁcation. The latter veriﬁes individual state transitions in
legal control ﬂows (a state refers to a system call plus the
program counter [39], a system call plus the call stack [9,23],
a user-space routine [16], or a code block [1]). Advanced ap-
proaches in these two paradigms adopt argument/data-ﬂow
analysis [3, 15, 16, 31], probabilistic measurement [18], and
event frequency analysis [13, 14, 47].

Existing anomaly detection solutions are eﬀective as long
as an attack can be discovered in a small detection window
on attack traces, e.g., an invalid n-gram or an illegal control
ﬂow transition (the latter can be accompanied by data-ﬂow
analysis). The aforementioned diluting attack [46] may be
detected if it involves illegal control ﬂows. However, there
does not exist eﬀective solutions for detecting general aber-
rant path attacks, because these attacks cannot be revealed
in a small detection window on traces.

Mining correlations among arbitrary events in a large-
scale execution window is the key to the detection of aber-

401rant path attacks that are buried in long execution paths.
The scale of the window may vary from thousands to millions
of instructions. However, straightforward generalization of
existing approaches is inadequate for large-scale execution
window analysis because of two challenges described below.
Training scalability challenge: existing automaton-based
methods are ﬁrst-order and only verify state transition indi-
vidually. One needs a linear bounded automaton or a Tur-
ing machine to enforce the relation among arbitrary events.
The generalization results in exponential time complexity
for training. n-gram based methods (e.g., lookahead pair,
practical hidden Markov model) have a similar exponential
convergence complexities in terms of n; large n (e.g., 40)
usually leads to false positives due to insuﬃcient training.

Behavior diversity challenge: real-world programs usually
realize various functionalities, which result in diverse pro-
gram behaviors within large-scale execution windows. The
distance between a normal program behavior and an anoma-
lous one can be less than the distance between two normal
ones. The diversity of normal behaviors makes traditional
single-threshold probabilistic methods (e.g., hidden Markov
model, one-class SVM) diﬃcult to ﬁne-tune for achieving
both a low false positive rate and a high detection rate.

To defend against aberrant path attacks, we propose a de-
tection approach that analyzes program behaviors in large-
scale execution windows. Our approach maps program be-
havior instances extracted from large-scale execution win-
dows into data points in a high-dimensional detection space.
It then leverages speciﬁcally designed machine learning tech-
niques to i) recognize diverse program behaviors, ii) discover
event correlations, and iii) detect anomalous program be-
haviors in various subspaces of the detection space.

In addition to the binary representation of event rela-
tions in an execution window, our approach further mod-
els quantitative frequency relations among occurred events.
Some aberrant path attacks deliberately or unintentionally
result in anomalous event frequency relations, e.g., Denial of
Service (DoS), directory harvest attack. The advantage of
modeling frequency relations over individual event frequen-
cies (used in existing anomaly detection [13]) is the low false
positive rates in case of program/service workload variation.
The contributions of our work are summarized as follows.
• We study the characteristics of aberrant path attacks
and identify the need to analyze program behaviors in
large-scale execution windows. We present a security
model for eﬃcient program behavior analysis through
event correlations in large-scale execution windows. The
security model covers the detection of two types of anoma-
lous program behaviors abstracted from four known cat-
egories of aberrant path attacks. The ﬁrst type contains
events (and their corresponding control-ﬂow segments)
that are incompatible in a single large-scale execution
window, e.g., non-control data attacks. The second type
contains aberrant relations among event occurrence fre-
quencies, e.g., service abuse attacks.

• We design a two-stage detection approach to discover
anomalous event correlations in large-scale execution win-
dows and detect aberrant path attacks. Our approach
contains a constrained agglomerative clustering algorithm
for addressing the behavior diversity challenge and di-
viding the detection problem into subproblems. Our
approach addresses the scalability challenge by utiliz-

1: void do_authentication(char *user, ...) {
2:

int authenticated = 0;
...
while (!authenticated) {

3:
4:
5:

6:

7:
8:
9:
10:
11:
12:

13:
14:
15:
16:

17:

type = packet_read();
switch (type) {

...
case SSH_CMSG_AUTH_PASSWORD:

...
if (auth_password(user, password)) {

memset(password, 0, strlen(password));
xfree(password);
log_msg("...", user);
authenticated = 1;
break;

}
memset(password, 0, strlen(password));
debug("...", user);
xfree(password);
break;

...

}
if (authenticated) break;
...

Figure 1: sshd ﬂag variable overwritten attack [5].

ing ﬁxed-size proﬁling matrices and by estimating nor-
mal behavior patterns from an incomplete training set
through probabilistic methods in each cluster. The unique
two-stage design of our approach enables eﬀective detec-
tions of i) legal-but-incompatible control-ﬂow segments
and ii) aberrant event occurrence frequency relations at
inter- and intra-cluster levels.

• We implement a prototype of our approach on Linux
and evaluate its detection capability, accuracy, and per-
formance with sshd, libpcre and sendmail. The evalu-
ation contains over 22,000 normal proﬁles and over 800
attack traces. Our approach successfully detects all at-
tack attempts with less than 0.01% false positive rates.
We demonstrate the high detection accuracy of our clus-
tering design through the detection of four types of syn-
thetic anomalies. Our prototype takes 0.3~1.3 ms to an-
alyze a single program behavior instance, which contains
1k to 50k function/system call events.

2. SECURITY MODEL

We describe the attack model, explain our security goals,

and discuss three basic solutions toward the goals.
2.1 Aberrant Path Attack

We aim to detect aberrant path attacks, which contain
infeasible/inconsistent/aberrant execution paths but obey
legitimate control-ﬂow graphs. Aberrant path attacks can
evade existing detection mechanisms because of the follow-
ing properties of the attacks:

• not conﬂicting with any control-ﬂow graph
• not incurring anomalous call arguments
• not introducing unknown short call sequences

Aberrant path attacks are realistic threats and gain pop-
ularity since early-age attacks have been eﬃciently detected
and blocked. Concrete aberrant path attack examples are:

402a) Non-control data attacks hijack programs without ma-
nipulating their control data (data loaded into program
counter in an execution, e.g., return addresses). One
such attack, ﬁrst described by Chen et al. [5], takes
advantage of an integer overﬂow vulnerability found in
several implementations of the SSH1 protocol [28]. Il-
lustrated in Fig. 1, an attacker can overwrite the ﬂag
integer authenticated when the vulnerable procedure
packet_read() is called.
If authenticated is over-
written to a nonzero value, line 17 is always True and
auth_password() on line 7 is no longer eﬀective.

b) Workﬂow violation attacks can be used to bypass access
control [6], leak critical information, disable a service
(e.g., trigger a deadlock), etc. One example is presen-
tation layer access control bypass in web applications. If
the authentication is only enforced by the presentation
layer, an attacker can directly access the business logic
layer (below presentation layer) and read/write data.

c) Exploit preparation is a common step preceding the
launch of an exploit payload.
It usually utilizes legal
control ﬂows to load essential libraries, arranges mem-
ory space (e.g., heap feng shui [41]), seeks addresses
of useful code and data fragments (e.g., ASLR prob-
ing [40]), and/or triggers particular race conditions.

d) Service abuse attacks do not take control of a program.
Instead, the attacks utilize legal control ﬂows to com-
promise the availability (e.g., Denial of Service attack),
conﬁdentiality (e.g., Heartbleed data leak [19]), and ﬁ-
nancial interest (e.g., click fraud) of target services.
2.2 Anomalous Program Behaviors within

Large-scale Execution Windows

Aberrant path attacks cannot be detected by analyzing
events in small windows on program traces. We deﬁne se-
mantically meaningful execution windows and unearth aber-
rant path attacks in large-scale execution windows.

Definition 2.1. An execution window W is the entire
or an autonomous portion of a transactional or continuous
program execution.

Execution windows can be partitioned based on bound-
aries of program functionalities, e.g., login, session handling,
etc. Since aberrant path attacks can lead to delayed attack
consequences, e.g., non-control data attacks, the analysis
should be performed on large-scale execution windows. One
such window could contain tens of thousands of system calls
and hundreds of times more function calls.

We give some examples of practical large-scale execution

window partitioning for security analysis purposes:

i) partitioning by routines/procedures/functions,
ii) partitioning by threads or forked processes,
iii) partitioning by activity intervals, e.g., sleep(),
iv) an entire execution of a small program.

In large-scale execution windows, we abstract two com-
mon anomalous behavior patterns of aberrant path attacks.

1. Montage anomaly is an anomalous program behavior
composed of multiple legitimate control ﬂow fragments
that are incompatible in a single execution.

yes

x<0

no

call s1
other calls

call s2
other calls

y = -1

y = 1

yes

y<0

no

call s3

call s4

no

no

no

0<x<n

call s1

0<x<n

call s2

0<x<n

call s3

(a) The executions of s1
and s3 occur in the same
run, similarly for s2 and s4.

(b) s1, s2 and s3 occur
at the same frequency in a
run.

Figure 2: Examples of control ﬂows that illustrate event
co-occurrence patterns and occurrence frequency relations.

One example of a montage anomaly is the sshd ﬂag vari-
able overwritten attack presented in Fig. 1. The attack
incurs an execution path that contains two incompatible
execution segments:
i) fail-auth handling (line 13-16)
and ii) pass-auth execution (line 18-).

2. Frequency anomaly is an anomalous program behavior
with aberrant ratios/relations between/among event oc-
currence frequencies. Normal relations among frequen-
cies are established by: i) mathematical relations among
induction variables that are speciﬁed in the binary (e.g.,
Fig. 2b), and ii) normal usage patterns of the program.

One example of a frequency anomaly is a directory har-
vest attack against a mail server. The attack probes le-
gitimate usernames on the server with a batch of emails
targeting possible users. The attack results in an aber-
rant ratio between event frequencies in the server’s han-
dling procedures of existent/nonexistent receivers.

Sometimes an event occurrence frequency alone can in-
dicate an attack, e.g., DoS. However, the workload of a
real-world service may vary rapidly, and the individual
frequencies are imprecise to model program behaviors.

2.3 Security Goals

The key to the detection of montage anomalies and fre-
quency anomalies is to model and analyze the relations among
control-ﬂow segments that occur in a large-scale execution
window. We further deduce two practical security goals for
detecting aberrant path attacks. The deduction is based on
the fact that events (e.g., call, jmp, or generic instructions)
in dynamic program traces mark/indicate the control-ﬂow
segment to which they belong.

1. Event co-occurrence analysis examines the patterns of
co-occurred events in a large-scale execution window1.
We illustrate an event co-occurrence analysis in Fig. 2a.
Rules should be learned that events (cid:2)s1, s3(cid:3) or (cid:2)s2, s4(cid:3)
always occur together, but not (cid:2)s1, s4(cid:3) or (cid:2)s2, s3(cid:3).

2. Event occurrence frequency analysis examines the event
occurrence frequencies and the relations among them.
1We deﬁne the co-occurrence of events in the scope of an
execution window, not essentially at the same time.

403For instance, s1, s2 and s3 always occur at the same
frequency in Fig. 2b. Another type of event occurrence
frequency relation is generated utterly due to speciﬁc
usage patterns (mail server example in Sect. 2.2), which
can be only learned from dynamic traces.

2.4 Basic Solutions and Their Inadequacy

There are several straightforward solutions providing event
co-occurrence and occurrence frequency analysis. We point
out their limitations, which help motivate our work.

Basic Solution I: One can utilize a large n in an n-
gram approach (either deterministic approaches, e.g., [11],
or probabilistic approaches, e.g., hidden Markov model [14,
47]). This approach detects aberrant path attacks because
long n-grams are large execution windows. However, it re-
sults in exponential training convergence complexity and
storage complexity. Unless the detection system is trained
with huge number of normal traces, which is exponential to
n, a large portion of normal traces will be detected as anoma-
lous. The exponential convergence complexity explains why
no n-gram approach employs n >40 in practice [10].

Basic Solution II: One can patch existing solutions with
frequency analysis components to detect some aberrant path
attacks, e.g., DoS. The possibility has been explored by Hub-
balli et al. on n-grams [20] and Frossi et al. on automata
state transitions [13]. Their solutions successfully detect
DoS attacks through unusually high frequencies of particular
n-grams and individual automata state transitions. How-
ever, the underlying detection paradigms restrict the solu-
tions from correlating arbitrary events in a long trace. Thus,
their solutions do not detect general aberrant path attacks.
Basic Solution III: One can perform episodes mining
within large-scale execution windows.
It extends existing
frequent episode mining [25, 29] by extracting episodes (fea-
tured subsequences) at all frequencies so that infrequent-
but-normal behaviors can be characterized. In order to an-
alyze all episodes (the power set of events in a large-scale
execution window), this approach faces a similar exponen-
tial complexity of training convergence as Basic Solution I.

3. OVERVIEW OF OUR APPROACH

We present an overview of our approach analyzing event
co-occurrence and event occurrence frequencies in large-scale
execution windows. We develop a constrained agglomera-
tive clustering algorithm to overcome the behavior diversity
challenge. We develop a compact and ﬁxed-length matrix
representation to overcome the scalability problem for stor-
ing variable-length trace segments. We utilize probabilis-
tic methods to estimate normal behaviors in an incomplete
training dataset for overcoming the training scalability issue.
3.1 Proﬁling Program Behaviors

We design our approach to expose user-space program ac-
tivities (executed control ﬂow segments) via call instruc-
2 are responsible for call stack changes
tions. call and ret
and provide a natural boundary for determining execution
windows as discussed in Section 2.2.

2

ret is paired with call, which can be veriﬁed via existing
CFI technique. We do not involve the duplicated correlation
analysis of ret in our model, but we trace ret to mark
function boundaries for execution window partitioning.

We denote the overall activity of a program P within an
execution window W as a behavior instance b. Instance b
recorded in a program trace is proﬁled in two matrices:

Definition 3.1. An event co-occurrence matrix O is an
m × n Boolean matrix recording co-occurred call events in
a behavior instance b. oi,j = True indicates the occurrence
of the call from the i-th row symbol (a routine) to the j-th
column symbol (a routine). Otherwise, oi,j = False.

Definition 3.2. A transition frequency matrix F is an
m× n nonnegative matrix containing occurrence frequencies
of all calls in a behavior instance b. fi,j records the oc-
currence frequency of the call from the i-th row symbol (a
routine) to the j-th column symbol (a routine). fi,j = 0 if
the corresponding call does not occur in W .

For one speciﬁc b, O is a Boolean interpretation of F that

(cid:2)

oi,j =

True
False

if fi,j > 0
if fi,j = 0

(1)

i,j AND o(cid:2)(cid:2)

i,j .

AND O(cid:2)(cid:2)

Bitwise operations, such as AND, OR, andXOR apply to co-
computes a

O and F are succinct representations of the dynamic call
graph of a running program. m and n are total numbers
of possible callers and callees in the program, respectively.
Row/column symbols in O and F are determined through
static analysis. m may not be equal to n, in particular when
calls inside libraries are not counted.
occurrence matrices. For example, O(cid:2)
new O that oi,j = o(cid:2)
Proﬁles at diﬀerent granularities Although designed to
be capable of modeling user-space program activities via
function calls, our approach can also digest coarse level pro-
gram traces for learning program behaviors. For example,
system calls can be traced and proﬁled into O and F to
avoid excessive tracing overheads in performance-sensitive
deployments. The semantics of the matrices changes in this
case; each cell in O and F represents a statistical relation
between two system calls. The detection is not as accurate
as our standard design because system calls are coarse de-
scriptions of program executions.
3.2 Architecture of Our Approach

Our approach consists of two complementary stages of
modeling and detection where montage/frequency anomalies
are detected in the ﬁrst/second stage, respectively.
The ﬁrst stage models the binary representation of event
co-occurrences in a large-scale execution window via event
co-occurrence matrix O.
It performs event co-occurrence
analysis against montage anomalies. It consists of a training
operation Behavior Clustering and a detection operation
Co-occurrence Analysis.
The second stage models the quantitative frequency re-
lation among events in a large-scale execution window via
transition frequency matrix F . It performs event occurrence
frequency analysis against frequency anomalies. It consists
of a training operationIntra-cluster Modeling and a
detection operation Occurrence Frequency Analysis.

We illustrate the architecture of our approach in Fig. 3

and brief the functionalities of each operation below.

1. Behavior Profiling recognizes target execution win-
dows {W1, W2, . . .} in traces and proﬁles b from each
W into O and F . Symbols in F and O are retrieved via
static program analysis or system call table lookup.

404Training Phase

Detecting Phase

Program Traces (Normal)

Program Traces (Unknown)

Behavior Instance Recognition

Behavior Profiling

Behavior Clustering

Co-occu. Analysis

Intra-cluster Modeling

Occu. Freq. Analysis

Normal

i

l

s
s
y
a
n
A
 
c
i
t

t

a
S

s
e

i
l

a
m
o
n
A

Figure 3: Information ﬂows among operations in two stages
and two phases of our program anomaly detection approach.

2. Behavior Clustering is a training operation. It takes
in all normal behavior instances {b1, b2, . . .} and out-
puts a set of behavior clusters C = {C1, C2, . . .} where
Ci = {bi1 , bi2 , . . .} .

3. Intra-cluster Modeling is a training operation. It is
performed in each cluster. It takes in all normal behav-
ior instances {bi1 , bi2 , . . .} for Ci and constructs one de-
terministic model and one probabilistic model for com-
puting the reﬁned normal boundary in Ci.

4. Co-occurrence Analysis is an inter-cluster detection
operation that analyzes O (of b) against clusters in C to
seek montage anomalies. If behavior instance b is nor-
mal, it reduces the detection problem to subproblems
within a set of behavior clusters Cb = {Cb1 , Cb2 , . . .} ,
in which b closely ﬁts.

5. Occurrence Frequency Analysis is an intra-cluster
detection operation that analyzes F (of b) in eachC b to
seek frequency anomalies. Behavior instance b is normal
if F abides by the rules extracted from Cb and F is
within the normal boundary established in Cb.

4.

INTER-/INTRA-CLUSTER DETECTION
We detail the training/modeling and detection operations
in our two-stage approach. The key to the ﬁrst stage is a
customized clustering algorithm, which diﬀerentiates diverse
program behaviors and divides the detection problem into
subproblems. Based on the clustering, inter-/intra-cluster
detection is performed in the ﬁrst/second stage, respectively.
4.1 Behavior Clustering (Training)

We develop a constrained agglomerative clustering algo-
rithm that addresses two special needs to handle program
behavior instances for anomaly detection: i) long tail elim-
ination, and ii) borderline behavior treatment. Standard
agglomerative clustering algorithms result in a large num-
ber of tiny clusters in a long-tail distribution (shown in Sec-
tion 6.1). Tiny clusters do not provide suﬃcient numbers of
samples for statistical learning of the reﬁned normal bound-
ary inside each cluster. Standard algorithms also do not

Algorithm 1 Constrained agglomerative clustering for
grouping similar program behavior instances.
Require: a set of normal program behavior instances B and a
termination threshold Td. dist() is the distance function be-
tween behaviors/clusters. pen() is the penalty function for
long tail elimination.

continue if vO1 < v[O1] orv O2 < v[O2]
O ← O1 OR O2
v[O] ← v[O1] +v [O2]
remove O1 from V
remove O2 from V
for all O(cid:2) ∈ V do
dp ← dist(O, O(cid:2)
push (cid:4)dp, O, v[O], O(cid:2), v[O(cid:2)

) × pen(v[O], v[O(cid:2)
])
](cid:5) onto h

end for
add O to V

pop (cid:4)dp, O1, vO1 , O2, vO2(cid:5) from h
break if dp > Td
if O1 ∈ V and O2 ∈ V then

Ensure: a set of behavior clusters C.
1: h ← ∅heap
2: v ← ∅hashtable
3: V ← ∅set
4: for all b ∈ B do
O ← Ob
5:
v[O] ← v[O] + 1
6:
for all O(cid:2) ∈ V do
7:
dp ← dist(O, O(cid:2)
8:
push (cid:4)dp, O, v[O], O(cid:2), v[O(cid:2)
9:
10:
11:
12: end for
13: while h (cid:6)= ∅heap do
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
end if
28: end while
29: w[O] ← ∅set for all O ∈ V
30: for all b ∈ B do
O ← Ob
31:
m ← MAXINT
32:
for all O(cid:2) ∈ V do
33:
if O OR O(cid:2)
= O(cid:2)
34:
then
if dist(O, O(cid:2)
) < m then
35:
m ← dist(O, O(cid:2)
36:
V (cid:2) ← {O(cid:2)}
37:
else if dist(O, O(cid:2)
38:
add O(cid:2)
to V (cid:2)
39:
40:
41:
42:
43:
44: end for
45: C ← {w[O] for all O ∈ V }

end for
add b to w[O] for all O ∈ V (cid:2)

end for
add O to V

end if

end if

) × pen(v[O], v[O(cid:2)
])
](cid:5) onto h

)

) = m then

handle borderline behaviors, which could be trained in one
cluster and tested in another, resulting in false alarms.

Our algorithm (Algorithm 1) clusters program behavior
instances based on the co-occurred events shared among in-
stances. To deal with the borderline behavior issue, we alter
the standard process into a two-step process:
i) generate
scopes of clusters in an agglomerative way (line 13-28), and
ii) add behavior instances to generated clusters (line 30-44).
We use a lazily updated heap h in Algorithm 1 to minimize
the calculation and sorting of distances between intermedi-
ate clusters. We perform lazy removal of dead clusters in
h. Dead clusters refer to the clusters that are merged into
others and no longer exist.
The scope of a cluster C = {bi | 0 ≤ i ≤ k} is represented
by its event co-occurrence matrix OC . OC records occurred
events in any behavior instances in C. It is calculated using

405(2) where Obi is the event co-occurrence matrix of bi.
OC = Ob1 OR Ob2 OR . . . OR Obk , 0 ≤ i ≤ k

(2)

The distances between i) two behavior instances, ii) two
clusters, and iii) a behavior instance and a cluster are all
measured by their co-occurrence matrices O1 and O2 in (3)
where |O| counts the number of True in O.

dist(O1, O2) =

Hamming(O1, O2)
min(|O1|,|O2|)

(3)

Hamming distance alone is insuﬃcient to guide the cluster
it loses the semantic meaning of O, and it
agglomeration:
weighs True and False the same. However, in co-occurrence
matrices, only True contributes to the co-occurrence of events.

We explain the unique features of our constrained agglom-

erative clustering algorithm over the standard design:
• Long tail elimination A standard agglomerative cluster-
ing algorithm produces clusters with a long tail distri-
bution of cluster sizes – there are a large number of tiny
clusters, and the unbalanced distribution remains at var-
ious clustering thresholds. Tiny clusters provide insuﬃ-
cient number of behavior instances to train probabilistic
models in Intra-cluster Modeling.

In order to eliminate tiny/small clusters in the long tail,
our algorithm penalizes dist(O1, O2) by (4) before push-
ing it onto h. |Ci| denotes the size of cluster Ci.
pen(|C1|,|C2|) = max(log(|C1|), log(|C2|))

(4)
• Penalty maintenance The distance penalty between C1
and C2 changes when any size of C1 and C2 changes. In
this case, all entries in h containing a cluster whose size
changes should be updated or nulliﬁed.

We use a version control to mark the latest and depre-
cated versions of clusters inh. The version of a cluster C
is recorded as its current size (an integer). It is stored in
v[O] where O is the event co-occurrence matrix of C. v
is a hashtable that assigns 0 to an entry when the entry
is accessed for the ﬁrst time. A heap entry contains two
clusters, their versions and their distance when pushed
to h (line 9 and line 24). An entry is abandoned if any
of its two clusters are found deprecated at the moment
the entry is popped from h (line 17).

• Borderline behavior treatment It may generate a false
positive when i) dist(b, C1) =dist (b, C2), ii) b is trained
only in C1 during Intra-cluster Modeling, and iii)
a similar behavior instance b(cid:2)
is tested against C2 in
operation Occurrence Frequency Analysis (intra-
cluster detection).

To treat this type of borderline behaviors correctly, our
clustering algorithm duplicates b in every cluster, which
b may belong to (line 30-44). This operation also in-
creases cluster sizes and results in suﬃcient training in
Intra-cluster Modeling.

4.2 Co-occurrence Analysis (Detection)

This operation performs inter-cluster detection to seek
montage anomalies. A behavior instance b is tested against
all normal clusters C to check whether the co-occurred events
in b are consistent with co-occurred events found in a single

cluster. An alarm is raised if no such cluster is found. Other-
wise, b and its most closely ﬁtted clusters Cb = {C1, . . . , Ck}
are passed to Occurrence Frequency Analysis for intra-
cluster detection.

An incoming behavior instance b ﬁts in a cluster C if
Ob OR OC = OC where OC and Ob are the event co-occurrence
matrices of C and b. The detection process searches for all
clusters in which b ﬁts. If this set of clusters is not empty,
distances between b and each cluster in this set are calcu-
lated using (3). The clusters with the nearest distance (there
could be more than one cluster) are selected as Cb.
4.3
Intra-cluster Modeling (Training)
Within a cluster C, our approach analyzes behavior in-
stances through their transition frequency matrices {Fb | b ∈
C}. The matrices are vectorized into data points in a high-
dimensional detection space where each dimension records
the occurrence frequency of a speciﬁc event across proﬁles.
Two analysis methods reveal relations among frequencies.
The probabilistic method. We employ a one-class
SVM, i.e., ν-SVM [38], to seek a frontier F that envelops
all behavior instances {b | b ∈ C}.

a) Each frequency value is preprocessed with a logarith-
mic function f (x) = log2 (x + 1) to reduce the variance
between extreme values (empirically proved necessary).

b) A subset of dimensions are selected through frequency
variance analysis (FVA)3 or principle component analy-
sis (PCA)4 before data points are consumed by ν-SVM.
This step manages the curse of dimensionality, a com-
mon concern in high-dimensional statistical learning.

c) We pair the ν-SVM with a kernel function, i.e., radial
basis function (RBF)5, to search for a non-linearly F
that envelops {b | b ∈ C} tightly. The kernel function
transforms a non-linear separating problem into a lin-
early separable problem in a high-dimensional space.

The deterministic method. We employ variable range
analysis to measure frequencies of events with zero or near
zero variances across all program behaviors {b | b ∈ C}.

Frequencies are discrete integers. If all frequencies of an
event in diﬀerent behavior instances are the same, PCA sim-
ply drops the corresponding dimension. In some clusters, all
behavior instances (across all dimensions) in C are the same
or almost the same. Duplicated data points are treated as a
single point, and they cannot provide suﬃcient information
to train probabilistic models, e.g., one-class SVM.

Therefore, we extract deterministic rules for events with
zero or near zero variances. This model identiﬁes the fre-
quency range [fmin, fmax] for each of such events. fmin can
equal to fmax.
4.4 Occurrence Frequency Analysis (Detection)

This operation performs intra-cluster detection to seek
frequency anomalies:
i) deviant relations among multiple
event occurrence frequencies, and/or ii) aberrant occurrence
3FVA selects dimensions/events with larger-than-threshold
frequency variances across all behavior instances in C.
4PCA selects linear combinations of dimensions/events with
larger-than-threshold frequency variances, which is a gener-
alization of FVA.
5Multiple functions have been tested for selection.

406frequencies. Given a program behavior instance b and its
closely ﬁtted clusters Cb = {C1, . . . , Ck} discovered in Co-
occurrence Analysis, this operation tests b in every Ci (0 ≤
i ≤ k) and aggregates the results using (5).

∃C ∈ C Nclt(b, C) ⇒ b is normal

(5)

The detection inside C is performed with 3 rules, and the

result is aggregated into Nclt(b, C).

(cid:2)

normal by all 3 rules

Nclt(b, C) =

True
False anomalous by any rule

(6)
• Rule 1: normal if the behavior instance b passes the prob-
abilistic model detection. The frequency transition ma-
trix F of b is vectorized into a high-dimensional data
point and tested against the one-class SVM model built
in Intra-cluster Modeling. This operation computes
the distance d between b and the frontier F established in
the ν-SVM. If b is within the frontier or b is on the same
side as normal behavior instances, then d >0. Other-
wise, d <0. d is compared with a detection threshold
Tf that Tf ∈ (−∞, +∞). b is abnormal if d < Tf .

• Rule 2: normal if the behavior instance b passes the
range model detection. Events in b with zero or near
zero variances are tested against the range model (the
deterministic method) built in Intra-cluster Model-
ing. b is abnormal if any event frequency of b exceeds
its normal range.

• Rule 3: presumption of innocence in tiny clusters. If no
frequency model is trained in C because the size of C
is too small, the behavior instance b is marked as nor-
mal. This rule generates false negatives. It sacriﬁces the
detection rate for reducing false alarms in insuﬃciently
trained clusters.
4.5 Discussion

Our program anomaly detection approach is a context-
sensitive language parser from the formal language perspec-
tive, i.e., Bach language parser [37]. In comparison, exist-
ing automata methods are at most context-free language
parsers (pushdown automata methods) [8]. n-gram meth-
ods are regular language parsers (ﬁnite state machine equiv-
alents [46]). Existing probabilistic methods are stochastic
languages parsers (probabilistic regular language parsers).

A context-sensitive language parser is more precise than
a context-free language parser or a regular language parser
in theory.
It is accepted by a linear bounded automaton
(LBA), which is a restricted Turing machine with a ﬁnite
tape. The advantage of a context-sensitive parser is its abil-
ity to characterize cross-serial dependencies, or to correlate
far away events in a long program trace.

Our approach explores the possibility to construct an eﬃ-
cient program anomaly detection approach on the context-
sensitive language level. Potential mimicry attacks could be
constructed to exploit the gap between Bach and the most
precise program execution description. However, it is more
diﬃcult to do so than constructing mimicry attacks against
regular or context-free language level detection tools. For
example, padding is a simple means to construct regular
language level mimicry attacks, and our approach can de-
tect padding attacks. Our analysis characterizes whether
two function calls should occur in one execution window, so

padding rarely occurred calls can be detected. Our approach
recognizes the ratios between call pairs in one execution win-
dow. Thus, excessive padding elements can be discovered.

Potential mimicry attacks may exploit the monitoring gran-
ularity of a detection approach. Our current approach uti-
lizes call instructions to mark control-ﬂow segments, which
can be generalized to any instruction for detecting mimicry
attacks that do not involve call in any part of their long
attack paths.

5.

IMPLEMENTATION

We implement a prototype of our detection approach on
Linux (Fedora 21, kernel 3.19.3). The static analysis is real-
ized through C (ParseAPI [34]). The proﬁling, training, and
detection phases are realized in Python. The dynamic trac-
ing and behavior recognition are realized through Intel Pin,
a leading dynamic binary instrumentation framework, and
SystemTap, a low-overhead dynamic instrumentation frame-
work for Linux kernel. Tracing mechanisms are independent
of our detection design; more eﬃcient tracing techniques can
be plugged in replacing Pin and SystemTap to improve the
overall performance in the future.

Static analysis before proﬁling: symbols and address ranges
of routines/functions are discovered for programs and li-
braries. The information helps to identify routine symbols
if not found explicitly in dynamic tracing. Moreover, we
leverage static analysis to list legal caller-callee pairs.

Proﬁling: Our prototype i) veriﬁes the legality of events
(function calls) in a behavior instance b and ii) proﬁles b
into two matrices (Sect. 3.1). The event veriﬁcation ﬁlters
out simple attacks that violate control ﬂows before our ap-
proach detects stealthy aberrant path attacks. We imple-
ment proﬁle matrices in Dictionary of Keys (DOK) format
to minimize storage space for sparse matrices.

Dynamic tracing and behavior recognition: We develop a
Pintool in JIT mode to trace function calls in the user space
and to recognize execution windows within entire program
executions. Our Pintool is capable of tracing i) native func-
tion calls, ii) library calls iii) function calls inside dynamic
libraries, iv) kernel thread creation and termination. Traces
of diﬀerent threads are isolated and stored separately. Our
Pintool recognizes whether a call is made within a given
routine and on which nested layer the given routine exe-
cutes (if nested execution of the given routine occurs). This
functionality enables the recognition of large-scale execution
windows through routine boundary partitioning.

We demonstrate that our approach is versatile recognizing
program behaviors at diﬀerent granularities. We develop a
SystemTap script to trace system calls with timestamps. It
enables execution window partitioning via activity intervals
when the program is monitored as a black box.

6. EVALUATIONS

To verify the detection capability of our approach, we test
our prototype against diﬀerent types of aberrant path at-
tacks (Sect. 6.2). We investigate its detection accuracy using
real and synthetic program traces (Sect. 6.3). We evaluate
the performance of our prototype with diﬀerent tracing and
detection options (Sect. 6.4).

407Table 1: The proﬁle information of programs/libraries and statistics of normal proﬁles.

Proﬁle Overview

Average Single Normal Proﬁle

Program Version Events in Proﬁle Execution Window #(N.P.) #(Symbols) #(Event) #(U.E.)

sshd
libpcre
sendmail

1.2.30
8.32
8.14.7

function calls
function calls
†
system calls

routine boundary
library call
continuous operation

4800
11027
6579

415
79
350

34511
44893
1134

180
45
213

N.P. is short for normal proﬁle. U.E. is short forunique event.
†
Function calls are not traced due to its complex process spawning logic. Customization of our Pintool is needed to trace them.

10000

1000

100

10

1

e
z
i
s
 
r
e
t
s
u
l
C

Standard

Ours

libpcre

sendmail

2.0
29

1.6
20

sshd

1.6
6

Td
|C|

(a) libpcre cluster size distribution
(sorted in descending order).

(b) Overview of program
behavior clustering.

Figure 4: Clustering of program behavior instances.

6.1 Experiment Setup

We study three programs/libraries (Table 1) in distinct
categories. We demonstrate that our approach is a versatile
detection solution to be applied to programs and dynamic li-
braries with various large-scale execution window deﬁnitions
and event deﬁnitions. We detail the programs/libraries and
their training dataset (normal proﬁles) below.

[sshd] Execution window deﬁnition: program activities of
sshd within routine do_authentication(). The routine
do_authentication() is called in a forked thread after a
client initializes its connection to sshd. All session activi-
ties are within the execution window if the authentication
is passed. Normal runs cover three authentication methods
(password, public key, rhost), each of which contains 800
successful and 800 failed connections. 128 random com-
mands are executed in each successful connection.

[libpcre] Execution window deﬁnition: program activi-
ties of libpcre when a library call is made. Library calls
are triggered through grep -P. Over 10,000 normal tests
are used from the libpcre package.

[sendmail] Execution window deﬁnition: a continuous sys-
tem call sequence wrapped by long no-op (no system call)
intervals. sendmail is an event-driven program that only
emits system calls when sending/receiving emails or per-
forming a periodical check. We set up this conﬁguration to
demonstrate that our detection approach can consume var-
ious events, e.g., system calls. We collect over 6,000 normal
proﬁles on a public sendmail server during 8 hours.

We list clustering threshold Td used for the three stud-
ied programs/libraries in Fig. 4b6. |C| denotes the number
of clusters computed with the speciﬁc Td.
In Fig. 4a, we
6The value is empirically chosen to keep a balance between
an eﬀective recognition of diverse behaviors and an adequate
elimination of tiny clusters.

demonstrate the eﬀectiveness of our constrained agglomer-
ative clustering algorithm to eliminate tiny clusters. The
standard agglomerative clustering approach results in a long-
tail distribution of cluster sizes shown in Fig. 4a.

In operation Occurrence Frequency Analysis, the
detection threshold Tf is determined by a given false pos-
itive rate (FPR) upper bound, i.e., FPRu, through cross-
validation. In the training phase of cross-validation, we per-
form multiple random 10-fold partitioning. Among distances
from all training partitions, Tf is initialized as the kth small-
est distance within distances7 between a behavior instance
and the ν-SVM frontier F. k is calculated using FPRu and
the overall number of training cases. The FPR is calculated
in the detection phase of cross-validation. If FPR > FPRu,
a smallerk is selected until FPR ≤ FPRu.
6.2 Discovering Real-World Attacks

We reproduce three known aberrant path attacks to test
the detection capability of our approach. Our detection ap-
proach detects all attack attempts with less than 0.0001 false
positive rate. The overview of the attacks and detection re-
sults are presented in Table 2.
6.2.1 Flag Variable Overwritten Attack
Flag variable overwritten attack is a non-control data at-
tack. An attacker tampers with decision-making variables.
The exploit takes eﬀect when the manipulated data aﬀects
the control ﬂow at some later point of execution.

We reproduce the ﬂag variable overwritten attack against
sshd introduced by Chen et al. [5]. We describe the attack
in Sect. 2.1, bullet (a) and in Fig. 1. We simplify the attack
procedure by placing an inline virtual exploit in sshd right
after the vulnerable routine packet_read():

if (user[0] == ’e’ && user[1] == ’v’

&& user[2] == ’e’) authenticated = 1;

This inline virtual exploit produces the immediate conse-
quence of a real exploit – overwriting authenticated.
It
does not interfere with our tracing/detection because no
call instruction is employed. For each attack attempt, 128
random commands are executed after a successful login.

Our approach (conﬁgured at FPRu 0.0001) successfully
detects all attack attempts in inter-cluster detection (Co-
occurrence Analysis)8. We present normal and attack
traces inside the execution window (selected routine
do_authentication()) in Fig. 5 to illustrate the detection.
7The distance can be positive or negative. More details are
speciﬁed in Rule 1 (Sect. 4.4).
8One-class SVM in Occurrence Frequency Analysis
only detects 3.8% attack attempts if used alone.

408Table 2: Overview of reproduced attacks and detection results.

Attack Name

Target

Attack Settings

#(A.) D.R. FPRu

ﬂag variable overwritten attack
Regular expression Denial of Service
directory harvest attack

sshd
libpcre
sendmail

an inline virtual exploit that matches a username
3 deleterious patterns paired with 8-23 input strings
probing batch sizes: 8, 16, 32, 64, 100, 200, and 400

800
46
14

100% 0.0001
100% 0.0001
100% 0.0001

A. is short for attack attempt. D.R. is short for detection rate. FPRu is the false positive rate upper bound (details in Sect. 6.1).

Normala
. . .
auth p > xfree
do auth > xfree
do auth > log msg
do auth > p start
p start > buf clr
. . .
phdtw > buf len
do auth > do autd
. . .

Normalb
. . .
auth p > xfree
do auth > debug
do auth > xfree
do auth > p start
p start > buf clr
. . .
phdtw > buf len
do auth > p read
. . .

Attack
. . .
auth p > xfree
do auth > debug
do auth > xfree
do auth > p start
p start > buf clr
. . .
phdtw > buf len
do auth > do autd
. . .

aA successfully authenticated session.
bA failed (wrong password) authentication.
“caller > callee” denotes a function call.
Routine names are abbreviated to save space.

Figure 5: Samples of normal and anomalous sshd traces.

Table 3: Deleterious patterns used in ReDoS attacks.

Deleterious Pattern

#(attack)

Pattern 1
Pattern 2
Pattern 3

^(a+)+$
((a+)*)+$
^(([a-z])+.)+[A-Z]([a-z])+$

15
8
23

In Fig. 5, the Attack and Normalb bear the same trace
prior to the last line, and the Attack and Normala bear the
same trace after (including) the last line. Our approach de-
tects the attack as a montage anomaly: the control-ﬂow seg-
ment containing do_auth > debug should not co-occur with
the control-ﬂow segment containing do_auth > do_authed
(and following calls) in a single execution window.

In the traces, there are identical 218 call events including
library routines (36 calls excluding library ones) between
the third line and the last line in Fig. 5. We test an n-gram
detection tool, and it requires at least n = 37 to detect the
speciﬁc attack without libraries routine traced. The 37-gram
model results in an FPR of 6.47% (the FPR of our approach
is less than 0.01%). This indicates that n-gram models with
a large n is diﬃcult to converge at training. We do not test
automaton-based detection because they cannot detect the
attack in theory. The attack does not contain any illegal
function calls.

6.2.2 Regular Expression Denial of Service
Regular expression Denial of Service (ReDoS) is a service
abuse attack. It exploits the exponential time complexity of
a regex engine when performing backtracking. The attacks
construct extreme matching cases where backtracking is in-
volved. All executed control ﬂows are legal, but the regex
engine hangs due to the extreme complexity.

 

e
t
a
R
n
o
i
t
c
e
t
e
D

1

0.8

0.6

0.4

0.2

0

FPR
0.01
0.001
0.0001

Pattern1 Pattern2 Pattern3 Pattern1 Pattern2 Pattern3

FVA                                     PCA

Figure 6: Detection rates of ReDoS attacks.

9.
We produce 46 ReDoS attack attempts targeting libpcre
Three deleterious patterns are used (Table 3). For each dele-
terious pattern, attacks are constructed with an increasing
length of a in the input string starting at 6, e.g., aaaaaaaab.
We stop attacking libpcre at diﬀerent input string lengths
so that the longest hanging time periods for diﬀerent delete-
rious patterns are about the same (a few seconds). A longer
input string incurs a longer hanging time; it results in a more
severe ReDoS attack than a shorter one.

ReDoS attacks are detected in intra-cluster detection op-
eration (Occurrence Frequency Analysis) by the prob-
abilistic method, i.e., ν-SVM. We test our approach with
both PCA and FVA feature selection (Sect. 4.3, the prob-
abilistic method, bullet b). The detection results (Fig. 6)
show that our approach conﬁgured with PCA is more sensi-
tive than it conﬁgured with FVA. Our approach (with PCA)
detects all attack attempts at diﬀerent FPRs10. The unde-
tected attack attempts (with FVA) are all constructed with
the small amount of a in the input strings, which do not
result in very severe ReDoS attacks.

6.2.3 Directory Harvest Attack
Directory harvest attack (DHA) is a service abuse attack.
It probes valid email users through brute force. We produce
14 DHA attack attempts targeting sendmail. Each attack
attempt consists of a batch of closely sent probing emails
with a dictionary of possible receivers. We conduct DHA
attacks with 7 probing batch sizes from 8 to 400 (Table 2).
Two attack attempts are conducted for each batch size.

Our approach (conﬁgured at FPRu 0.0001) successfully
detects all attack attempts with either PCA or FVA feature
selection10. DHA attacks are detected in intra-cluster de-
tection (Occurrence Frequency Analysis) by the prob-
abilistic method, i.e., ν-SVM. The attacks bypass the inter-

9Internal deep recursion prevention of libcpre is disabled.
10No attack is detected if only Co-occurrence Analysis is
performed.

409Our approach (w/ FVA)

Our approach (w/ PCA)

One-class SVM (w/ FVA)

One-class SVM (w/ PCA)

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

0.1

0.04

0.06

0.02
0.08
Montage anomaly

0.04

0.08

0.02

0.1
Incomplete path anomaly

0.06

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

0.02

0.04

0.06

0.08

0.1

High-frequency anomaly

1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

0

0.02

0.04

0.06

0.08

0.1

Low-frequency anomaly

Figure 7: libpcre ROC of our approach and basic one-class SVM. X-axis is false positive rate, and y-axis is detection rate.

cluster detection (Co-occurrence Analysis) because in-
valid usernames occur in normal training dataset.

This experiment demonstrates that our approach can con-

sume coarse program behavior descriptions (e.g., system calls)
to detect attacks. Most of the probing emails do not have
valid receivers. They result in a diﬀerent processing proce-
dure than that for normal emails; the batch of DHA emails
processed in an execution window gives anomalous ratios
between frequencies of valid email processing control ﬂows
and frequencies of invalid email processing control ﬂows. In
sendmail, these diﬀerent control ﬂows contain diﬀerent sets
of system calls, so they are revealed by system call proﬁles.
More precise detection requires the exposure of internal pro-
gram activities, such as function calls.
6.3 Systematic Accuracy Evaluation

We systematically demonstrate how sensitive and accu-
rate our approach is through receiver operating characteris-
tic (ROC). Besides normal program behaviors ground truth
(Sect. 6.1), we generate four types of synthetic aberrant path
anomalies. We ﬁrst construct F (cid:2)
for each synthetic anoma-
lous behavior instance b(cid:2)
, and then we use (1) to derive O(cid:2)
(of b(cid:2)
1. Montage anomaly: two behavior instance b1 and b2 are
randomly selected from two diﬀerent behavior clusters.
For a cell f(cid:2)
, if one of f1i,j (of F1) andf 2i,j
(of F2) is 0, the value of the other is copied into f(cid:2)
i,j.
Otherwise, one of them is randomly selected and copied.

) from F (cid:2)

i,j in F (cid:2)

.

2. Incomplete path anomaly: random one-eighth of non-
zero cells of a normal F are dropped to 0 (indicating
events that have not occurred) to construct F (cid:2)

.

3. High-frequency anomaly: three cells in a normal F are
randomly selected, and their values are magniﬁed 100
times to construct F (cid:2)

.

4. Low-frequency anomaly: similar to high-frequency anoma-

lies, but the values of the three cells are reduced to 1.

To demonstrate the eﬀectiveness of our design in handling
diverse program behaviors, we compare our approach with
a basic one-class SVM (the same ν-SVM and same conﬁgu-
rations, e.g., kernel function, feature selection, and parame-
ters, as used in ourIntra-cluster Modeling operation).
We present the detection accuracy results on libpcre in
Fig. 7, which has the most complicated behavior patterns

among the three studied programs/libraries11. In any sub-
ﬁgure of Fig. 7, each dot is associated with a false positive
rate (multi-round 10-fold cross-validation with 10,000 test
cases) and a detection rate (1,000 synthetic anomalies). We
denote an anomaly result as a positive.

Fig. 7 shows the eﬀectiveness of our clustering design.
The detection rate of our prototype (with PCA12) is usu-
ally higher than 0.9 with FPR less than 0.01. Because of
diverse patterns, basic one-class SVM fails to learn tight
boundaries that wrap diverse normal patterns as expected.
A loose boundary results in false negatives and low detection
rates.
6.4 Performance Analysis

Although performance is not a critical issue for the train-
ing phase, a fast and eﬃcient detection is important for en-
abling real-time protection and minimizing negative user ex-
perience [32]. The overall overhead of a program anomaly
detection system comes from tracing and analysis in general.
We evaluate the performance of our analysis procedures
(inter- and intra-cluster detections) with either function call
proﬁles (libpcre) or system call proﬁles (sendmail). We
test the analysis on all normal proﬁles (libpcre: 11027,
sendmail: 6579) to collect overhead for inter-cluster detec-
tion alone and the combination of inter- and intra-cluster
detection 13. The analysis of each behavior instance is re-
peated 1,000 times to obtain a fair timing. The performance
results in Fig. 8 illustrate that
• It takes 0.1~1.3 ms to analyze a single behavior instance,
which contains 44893 function calls (libpcre) or 1134
system calls (sendmail) on average (Table 1).

• The analysis overhead is positively correlated with the
number of unique events in a proﬁle (Table 1), which is
due to our DOK implementation of proﬁle matrices.

• Montage anomalies takes less time to detect than fre-
quency anomalies, because they are detected at the ﬁrst
stage (Co-occurrence Analysis).

11Results of the other two programs share similar character-
istics as libpcre and are not presented.
12PCA proves itself more accurate than FVA in Fig. 7.
13PCA is used for feature selection. FVA (results omitted)
yields a lower overhead due to its simplicity.

410-
v
a
h
e
b

r
e
p

e
m

i
t

n
o
i
t
c
e
t
e
D

)
d
n
o
c
e
s
i
l
l
i

m

(

e
c
n
a
t
s
n

i

r
o
i

0.4

0.35

0.3

0.25

0.2

0.15

0.1

1.3

1.2

1.1

1

0.9

0.8

0.7

(C.A.+F.A.)

(C.A.)

(C.A.+F.A.)

(C.A.)

(a) libpcre

(b) sendmail

C.A.+F.A.: Inter- and intra-cluster detection combined.
C.A.: Inter-cluster detection only.

Figure 8: Detection (analysis) overhead of our approach.

Compared with the analysis procedure, dynamic function
call tracing incurs a noticeable overhead. sshd experiences
a 167% overhead on average when our Pintool is loaded. A
similar 141% overhead is reported by Jalan and Kejariwal in
their dynamic call graph Pintool Trin-Trin [24]. Advanced
tracing techniques, e.g., probe mode pintool, branch target
store [48], etc., can potentially reduce the tracing overhead
to less than 10% toward a real-time detection system.

Another choice to deploy our detection solution is to pro-
ﬁle program behaviors through system calls as we demon-
strate using sendmail. System calls can be traced through
SystemTap with near-zero overhead [43], but it sacriﬁces the
capability to reveal user-space program activities and down-
grades the modeling/detection accuracy.

Our approach can support oﬄine detection or forensics of
program attacks, in which case accuracy is the main concern
instead of performance [42]. Our Pintool enables analysts to
locate anomalies within execution windows, and our matri-
ces provide caller information for individual function calls.
This information helps analysts quickly reduce false alarms
and locate vulnerable code segments.

Summary We evaluate the detection capability, accuracy,
and performance of our detection prototype on Linux.
• Our approach successfully detects all reproduced aber-
rant path attack attempts against sshd, libpcre and
sendmail with less than 0.0001 false positive rates.

• Our approach is accurate in detecting diﬀerent types of
synthetic aberrant path anomalies with a high detection
rate (> 0.9) and a low false positive rate (< 0.01).

• Our approach analyzes program behaviors fast; it only
incurs 0.1~1.3 ms analysis overhead (excluding tracing)
per behavior instance (1k to 50k function/system calls
in our experiments).

7. RELATED WORK

Conventional program anomaly detection systems (aka
host-based intrusion detection systems) follow Denning’s in-
trusion detection vision [7]. They were designed to detect
illegal control ﬂows or anomalous system calls based on two
i) n-gram short call sequence validation
basic paradigms:
that was introduced by Forrest et al. [11]; and ii) automaton
transition veriﬁcation, which was ﬁrst described by Kosore-

sow and Hofmeyr [26] (DFA) and formalized by Sekar et
al. [39] (FSA) and Wagner and Dean [45] (NDPDA).

The basic n-gram model was further studied in [10,21] and
several advanced forms of it were developed, e.g., machine
learning models [22, 29] and hidden Markov models [14, 47].
The essence of n-gram is to model and analyze local fea-
tures of program traces with a small n. Enlarging n results
in exponential convergence and storage issues. However,
small n (local feature analysis) makes it possible for attack-
ers to evade the detection by constructing a malicious trace
of which any small fragment is normal. Wagner and Soto
ﬁrst demonstrated such a mimicry attack with a malicious
sequence of system calls diluted to normal [46].

Although Wagner and Soto’s attack evades the detection
from n-gram methods, it is system-call-level tactics, and it
may introduce illegal control ﬂows, which can be captured
by pushdown automaton (PDA) methods [8, 9, 15, 16]. This
mimicry attack could also involve anomalous call arguments,
which can be detected by argument analysis [15, 31].

Research on automaton detection started with the goal
of performing trace analysis on a large scale. However, all
existing automaton models are equivalents to FSA/PDA.
They only verify state transitions individually, i.e., they are
ﬁrst-order models. Program counter and call stack infor-
mation were used to help precisely deﬁne each state (a sys-
tem call) in an automaton [8, 9, 39]. Function calls/returns
are included as automaton states in the Dyck model [16].
Models combining static and dynamic analysis were devel-
oped [23,30], and individual transition frequencies have been
employed to detect DoS attacks [13].

All existing automaton detection methods cannot be di-
rectly used for detecting aberrant path anomalies, as ex-
plained earlier in the paper. Existing detection methods
lack the ability to correlate events in diﬀerent control-ﬂow
segments in a large-scale execution window. An automaton
that is capable to do so would have an exponential complex-
ity in term of training overhead and storage.

The relation among events that occur far away has not
been systematically studied in the literature.
In this pa-
per, we formalize the problem of event correlation analysis
within large-scale execution windows and bring forward the
ﬁrst solution that correlates events in a large-scale execution
window for anomaly detection purpose.

Clustering and classiﬁcation techniques have been widely
used in malware classiﬁcation [2, 12, 25, 36]. Malware clas-
siﬁcation aims at extracting abstract malware behavior sig-
natures and identiﬁes a piece of malware using one or multi-
ple signatures. However, program anomaly detection mod-
els normal behaviors and exams an entire proﬁle to decide
whether it is normal. It is not suﬃcient to conclude an in-
coming behavior is normal that one feature of it is normal.
Correlation analysis techniques were developed to detect
network intrusions. Valeur et al. described a comprehensive
framework to correlate alerts from various IDS systems [44].
Perdisci et al. proposed 2v-gram scheme to discover related
bytes v positions apart in traﬃc payload [35]. Gu et al.
developed a system to correlate temporal network events
for detecting botnets under speciﬁc bot behavior hypothe-
ses [17]. In comparison, we address the program anomaly de-
tection problem by developing new algorithms to overcome
the unique behavior diversity and scalability challenges.

Defenses against speciﬁc known program attacks have been
investigated besides anomaly detection. For example, Moore

411introduced backscatter analysis to discover DoS at-
et al.
tacks [33], and Brumley et al.
invented RICH to prevent
integer overﬂow [4]. These defenses target speciﬁc attack sig-
natures and cannot detect unknown attacks. Therefore, they
are diﬀerent from general anomaly detection approaches.

8. CONCLUSIONS AND FUTURE WORK
In this paper, we studied aberrant path attacks and de-
signed a two-stage anomaly detection approach to unearthing
these attacks from extreme long program traces. The sig-
niﬁcance of our work is the new capability to eﬃciently dis-
cover subtle program inconsistencies and anomalies that oc-
cur far apart. Our work advances the state-of-the-art pro-
gram anomaly detection by demonstrating the eﬀectiveness
of large-scale program behavioral modeling and enforcement
against runtime anomalies that are buried in extremely long
execution paths. In future work, we plan to adopt advanced
dynamic tracing techniques and build real-time security in-
cidence response systems on top of our detection solution.

9. ACKNOWLEDGMENTS

This work has been supported by ONR grant N00014-
13-1-0016 and ARO YIP W911NF-14-1-0535. The authors
would like to thank Barbara Ryder for her feedback on the
work. The authors would like to thank Changhee Jung and
Dongyoon Lee for their comments on performance analysis.

10. REFERENCES
[1] M. Abadi, M. Budiu, U. Erlingsson, and J. Ligatti.

Control-ﬂow integrity. In Proceedings of the ACM
Conference on Computer and Communications
Security, pages 340–353, 2005.

[2] U. Bayer, P. M. Comparetti, C. Hlauschek, C. Kr¨ugel,

and E. Kirda. Scalable, behavior-based malware
clustering. In Proceedings of the Network and
Distributed System Security Symposium, 2009.

[3] S. Bhatkar, A. Chaturvedi, and R. Sekar. Dataﬂow

anomaly detection. In Proceedings of the IEEE
Symposium on Security and Privacy, May 2006.

[4] D. Brumley, D. X. Song, T. cker Chiueh, R. Johnson,
and H. Lin. RICH: Automatically protecting against
integer-based vulnerabilities. In Proceedings of the
Network and Distributed System Security Symposium,
2007.

[5] S. Chen, J. Xu, E. C. Sezer, P. Gauriar, and R. K.

Iyer. Non-control-data attacks are realistic threats. In
Proceedings of the USENIX Security Symposium,
volume 14, pages 12–12, 2005.

[6] M. Cova, D. Balzarotti, V. Felmetsger, and G. Vigna.

Swaddler: An approach for the anomaly-based
detection of state violations in web applications. In
Proceedings of the International Symposium on
Research in Attacks, Intrusions and Defenses, pages
63–86, 2007.

[7] D. E. Denning. An intrusion-detection model. IEEE

Transactions on Software Engineering, 13(2):222–232,
1987.

[8] H. H. Feng, J. T. Giﬃn, Y. Huang, S. Jha, W. Lee,

and B. P. Miller. Formalizing sensitivity in static
analysis for intrusion detection. In Proceedings of the
IEEE Symposium on Security and Privacy, pages
194–208, 2004.

[9] H. H. Feng, O. M. Kolesnikov, P. Fogla, W. Lee, and

W. Gong. Anomaly detection using call stack
information. In Proceedings of the IEEE Symposium
on Security and Privacy, pages 62–75, 2003.

[10] S. Forrest, S. Hofmeyr, and A. Somayaji. The

evolution of system-call monitoring. In Proceedings of
the Annual Computer Security Applications
Conference, pages 418–430, 2008.

[11] S. Forrest, S. A. Hofmeyr, A. Somayaji, and T. A.

Longstaﬀ. A sense of self for Unix processes. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 120–128, 1996.

[12] M. Fredrikson, S. Jha, M. Christodorescu, R. Sailer,

and X. Yan. Synthesizing near-optimal malware
speciﬁcations from suspicious behaviors. In
Proceedings of the IEEE Symposium on Security and
Privacy, pages 45–60, 2010.

[13] A. Frossi, F. Maggi, G. L. Rizzo, and S. Zanero.

Selecting and improving system call models for
anomaly detection. In Detection of Intrusions and
Malware, and Vulnerability Assessment, pages
206–223. Springer, 2009.

[14] D. Gao, M. K. Reiter, and D. Song. Behavioral

distance measurement using hidden Markov models.
In Proceedings of the International Symposium on
Research in Attacks, Intrusions and Defenses, pages
19–40, 2006.

[15] J. T. Giﬃn, D. Dagon, S. Jha, W. Lee, and B. P.

Miller. Environment-sensitive intrusion detection. In
Proceedings of the International Symposium on
Research in Attacks, Intrusions and Defenses, pages
185–206, 2006.

[16] J. T. Giﬃn, S. Jha, and B. P. Miller. Eﬃcient

context-sensitive intrusion detection. In Proceedings of
the Network and Distributed System Security
Symposium, 2004.

[17] G. Gu, P. A. Porras, V. Yegneswaran, M. W. Fong,

and W. Lee. BotHunter: Detecting malware infection
through IDS-driven dialog correlation. In Proceedings
of the USENIX Security Symposium, volume 7, pages
1–16, 2007.

[18] Z. Gu, K. Pei, Q. Wang, L. Si, X. Zhang, and D. Xu.

LEAPS: Detecting camouﬂaged attacks with
statistical learning guided by program analysis. In
Proceedings of the Annual IEEE/IFIP International
Conference on Dependable Systems and Networks,
pages 491–502, 2014.

[19] The heartbleed bug, http://heartbleed.com/.
[20] N. Hubballi, S. Biswas, and S. Nandi. Sequencegram:

n-gram modeling of system calls for program based
anomaly detection. In Proceedings of the International
Conference on Communication Systems and Networks,
pages 1–10, January 2011.

[21] H. Inoue and A. Somayaji. Lookahead pairs and full
sequences: a tale of two anomaly detection methods.
In Proceedings of the Annual Symposium on
Information Assurance, pages 9–19, 2007.

[22] M. R. Islam, M. S. Islam, and M. U. Chowdhury.
Detecting unknown anomalous program behavior
using API system calls. In Informatics Engineering
and Information Science, pages 383–394. Springer
Berlin Heidelberg, 2011.

412[23] J. H. Jafarian, A. Abbasi, and S. S. Sheikhabadi. A
gray-box DPDA-based intrusion detection technique
using system-call monitoring. In Proceedings of the
Annual Collaboration, Electronic messaging,
Anti-Abuse and Spam Conference, pages 1–12, 2011.
[24] R. Jalan and A. Kejariwal. Trin-Trin: Who’s calling?

a Pin-based dynamic call graph extraction framework.
International Journal of Parallel Programming,
40(4):410–442, 2012.

[25] S. Karanth, S. Laxman, P. Naldurg, R. Venkatesan,
J. Lambert, and J. Shin. Pattern mining for future
attacks. Technical Report MSR-TR-2010-100,
Microsoft Research, 2010.

[26] A. P. Kosoresow and S. A. Hofmeyr. Intrusion

detection via system call traces. IEEE software,
14(5):35–42, 1997.

[27] C. Kruegel, E. Kirda, D. Mutz, W. Robertson, and
G. Vigna. Automating mimicry attacks using static
binary analysis. In Proceedings of the USENIX
Security Symposium, pages 11–11, 2005.

[28] J. P. Lanza. SSH CRC32 attack detection code

contains remote integer overﬂow. Vulnerability Notes
Database, 2001.

[29] W. Lee and S. J. Stolfo. Data mining approaches for

intrusion detection. In Proceedings of the USENIX
Security Symposium, pages 6–6, 1998.

[37] G. K. Pullum. Context-freeness and the computer

processing of human languages. In Proceedings of the
annual meeting on Association for Computational
Linguistics, pages 1–6, Stroudsburg, PA, USA, 1983.

[38] B. Sch¨olkopf, R. C. Williamson, A. J. Smola,

J. Shawe-Taylor, and J. C. Platt. Support vector
method for novelty detection. In Proceedings of the
annual conference on Neural Information Processing
Systems, volume 12, pages 582–588, 1999.

[39] R. Sekar, M. Bendre, D. Dhurjati, and P. Bollineni. A
fast automaton-based method for detecting anomalous
program behaviors. In Proceedings of the IEEE
Symposium on Security and Privacy, pages 144–155,
2001.

[40] H. Shacham, M. Page, B. Pfaﬀ, E.-J. Goh,

N. Modadugu, and D. Boneh. On the eﬀectiveness of
address-space randomization. In Proceedings of the
ACM Conference on Computer and Communications
Security, pages 298–307, 2004.

[41] A. Sotirov. Heap Feng Shui in JavaScript. Black Hat

Europe, 2007.

[42] S. Sundaramurthy, J. McHugh, X. Ou,

S. Rajagopalan, and M. Wesch. An anthropological
approach to studying CSIRTs. IEEE Security &
Privacy, 12(5):52–60, September 2014.

[43] Systemtap overhead test, https://sourceware.org/

[30] Z. Liu, S. M. Bridges, and R. B. Vaughn. Combining

ml/systemtap/2006-q3/msg00146.html.

static analysis and dynamic learning to build accurate
intrusion detection models. In Proceedings of IEEE
International Workshop on Information Assurance,
pages 164–177, 2005.

[44] F. Valeur, G. Vigna, C. Kruegel, and R. A. Kemmerer.
A comprehensive approach to intrusion detection alert
correlation. IEEE Transactions on Dependable and
Secure Computing, 1(3):146–169, July 2004.

[31] F. Maggi, M. Matteucci, and S. Zanero. Detecting

[45] D. Wagner and R. Dean. Intrusion detection via static

intrusions through system call sequence and argument
analysis. IEEE Transactions on Dependable and
Secure Computing, 7(4):381–395, 2010.

analysis. In Proceedings of the IEEE Symposium on
Security and Privacy, pages 156–168, 2001.
[46] D. Wagner and P. Soto. Mimicry attacks on

[32] J. S. Mertoguno. Human decision making model for
autonomic cyber systems. International Journal on
Artiﬁcial Intelligence Tools, 23(06):1460023, 2014.

host-based intrusion detection systems. In Proceedings
of the ACM Conference on Computer and
Communications Security, pages 255–264, 2002.

[33] D. Moore, C. Shannon, D. J. Brown, G. M. Voelker,

[47] C. Warrender, S. Forrest, and B. Pearlmutter.

and S. Savage. Inferring internet Denial-of-Service
activity. ACM Transactions on Computer Systems,
24(2):115–139, 2006.

[34] The paradyn project, http://www.paradyn.org/.
[35] R. Perdisci, G. Gu, and W. Lee. Using an ensemble of

one-class SVM classiﬁers to harden payload-based
anomaly detection systems. In Proceedings of the
International Conference on Data Mining, pages
488–498, December 2006.

[36] R. Perdisci, W. Lee, and N. Feamster. Behavioral
clustering of HTTP-based malware and signature
generation using malicious network traces. In
Proceedings of the USENIX Symposium on Networked
Systems Design and Implementation, pages 26–26,
2010.

Detecting intrusions using system calls: Alternative
data models. In Proceedings of the IEEE Symposium
on Security and Privacy, pages 133–145, 1999.

[48] Y. Xia, Y. Liu, H. Chen, and B. Zang. CFIMon:
Detecting violation of control ﬂow integrity using
performance counters. In Proceedings of the Annual
IEEE/IFIP International Conference on Dependable
Systems and Networks, pages 1–12, June 2012.

413