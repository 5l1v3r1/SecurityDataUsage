PERM: Practical Reputation-Based Blacklisting

without TTPs

School of Computer Science and Software

School of Informatics and Computing

Apu Kapadia

Indiana University

Bloomington, IN, USA

kapadia@indiana.edu

Man Ho Au

Engineering

University of Wollongong

Wollongong, NSW, Australia

aau@uow.edu.au

ABSTRACT
Some users may misbehave under the cover of anonymity
by, e.g., defacing webpages on Wikipedia or posting vul-
gar comments on YouTube. To prevent such abuse, a few
anonymous credential schemes have been proposed that re-
voke access for misbehaving users while maintaining their
anonymity such that no trusted third party (TTP) is in-
volved in the revocation process. Recently we proposed
BLACR, a TTP-free scheme that supports ‘reputation-based
blacklisting’ — the service provider can score users’ anony-
mous sessions (e.g., good vs. inappropriate comments) and
users with insuﬃcient reputation are denied access.

The major drawback of BLACR is the linear computa-
tional overhead in the size of the reputation list, which allows
it to support reputation for only a few thousand user ses-
sions in practical settings. We propose PERM, a revocation-
window-based scheme (misbehaviors must be caught within
a window of time), which makes computation independent
of the size of the reputation list. PERM thus supports mil-
lions of user sessions and makes reputation-based blacklist-
ing practical for large-scale deployments.

Categories and Subject Descriptors
K.6.5 [Operating Systems]: Security and Protection—
Authentication; E.3 [Data Encryption]: Public key cryp-
tosystems

Keywords
accountable anonymity, anonymous blacklisting, revocation

1.

INTRODUCTION

Anonymous access to services can be of great value in
many circumstances. For example, journalists and activists
can avoid censorship and persecution while posting con-
tent to Wikipedia and YouTube anonymously. Nevertheless,

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
CCS’12, October 16–18, 2012, Raleigh, North Carolina, USA.
Copyright 2012 ACM 978-1-4503-1651-4/12/10 ...$15.00.

users can and do abuse their anonymity by defacing web-
pages and posting inappropriate material. Repeated abuse
has led service providers (SPs) like Wikipedia to ban access
though anonymizing networks such as Tor [15].
Anonymous blacklisting and subjective judging. To en-
able a less drastic reaction than banning anonymous access,
several credential schemes for accountable anonymity have
been proposed recently. These schemes support the subjec-
tive judging of misbehaviors [19, 27], allowing SPs to ar-
bitrarily ﬂag behaviors as inappropriate. Subjective judg-
ing is useful in applications in which a mathematical or
algorithmic formulation of misbehaviors such as ‘inappro-
priate edits’ is unlikely.1 It has been recognized that since
the subjective judging of users’ behaviors is arbitrary, it is
desirable for such schemes to support anonymous blacklist-
ing [19, 27] such that users can be blocked from returning
while maintaining their anonymity.2 Thus users are held
accountable, but they are not worried about arbitrary, sub-
jective deanonymization.
TTP vs. TTP-Free schemes. Several approaches to pro-
viding anonymous blacklisting with subjective judging in-
clude some kind of trusted third party (TTP). Group
signature-based schemes feature a group manager who can
revoke access for users [1, 8, 13, 20]. ‘Nymble’ schemes make
authentication at the SP eﬃcient, but they also feature some
kind of TTP [19, 27, 21, 18]. Since users must still rely on
the judgment of the TTP, users can never be certain of their
anonymity.

Thus, several TTP-free schemes have been proposed re-
cently to eliminate this point of trust. BLAC was the ﬁrst
such scheme [24, 26].
In BLAC users must prove in zero
knowledge that each entry on the blacklist does not cor-
respond to an authentication made earlier using their cre-
dential, resulting in authentication times linear in the size
of the blacklist. PEREA removed this linear dependence
on the size of the blacklist by requiring misbehaviors to be
‘caught’, i.e., identiﬁed, within a revocation window of the
past K authentications [25, 4]. Authentication times are
now linear in the size of K, and thus K cannot be too large;
typically K = 10 provides much better performance than
BLAC. When combined with rate limiting, PEREA would

1In contrast, schemes supporting digital cash can easily
characterize misbehavior such as the “double spending” of
a coin.
2In contrast many existing schemes for subjective judging
deanonymize or reduce the privacy of users.

929allow enough (i.e., K) authentications per day and be able
to block users who were blacklisted within a day of their mis-
behavior. We refer to the rate limiting time period as the
“revocation period”. Under this revocation-window model
FAUST signiﬁcantly improves authentication times using a
novel whitelisting approach [22].
TTP-free reputation-based blacklisting. While previous
schemes revoke access to users who are on the blacklist, the
most recent advance was made by BLACR, i.e., BLAC with
Reputation [2]. Hereafter we shall use the terminology “rep-
utation list” instead of “blacklist” in order to reﬂect the list’s
nature in reputation-based blacklisting systems. In BLACR
the SP can score each entry with a positive or negative score
on the reputation list along with a category identiﬁer. For
example, the SP can use diﬀerent scoring schemes in the
categories of comments (e.g., foul language: −2, racist com-
ments: −10, and helpful comments: +5) and content (e.g.,
popular videos: +5, copyright violations: −2 or −5 depend-
ing on how egregious the violations are). SPs can then re-
quire an authenticating user’s reputation (total of scores in a
category) to be above a particular threshold. Furthermore,
SPs can specify policies that are boolean combinations of
such category-threshold statements (e.g., reputation in the
comments category should be above −5 AND reputation
in the content category should be above −15).3 BLACR
guarantees that users who do not satisfy the policy are de-
nied access without revealing any other information beyond
whether the policy was satisﬁed or not.

While BLACR oﬀers a good solution for reputation-based
blacklisting, it is slow because it has the same linear de-
pendence of BLAC. BLACR improves performance by im-
plementing the concept of an ‘express lane token’, which
amounts to incremental proofs over the previous authenti-
cation. Nevertheless, BLACR supports reputation lists with
only a few thousand entries. While useful, BLACR’s scala-
bility is limited, and a more eﬃcient solution is needed for
SPs like Wikipedia or YouTube that can have millions of
sessions where anonymous users edit or upload content.

The recent PEREA scheme does oﬀer a form of
reputation-based blacklisting (albeit for only a single cat-
egory) that is eﬃcient at the SP, but it suﬀers from two
major drawbacks. First, the reputation of an authenticating
user is calculated over the current revocation window, e.g.,
a day. Thus, the user’s reputation in only the last day would
be taken into account, which severely limits the scheme’s ap-
plicability to systems in which reputation is built over much
longer time periods than a few days. Second, the time at
the user is linear in the size of the reputation list and it
would take hours of computation at the user to generate
authentication proofs. FAUST alleviates the computation
problem [22], but oﬀers an even more limited form of repu-
tation than PEREA. As pointed out earlier [2, §1], FAUST
cannot support boolean combinations of reputation policies
across categories and is not collusion resistant to attacks in
which users can pool their credentials to gain unauthorized
access. A scheme that can ﬁx these two problems of func-
tionality and performance would oﬀer a major improvement
in reputation-based blacklisting by oﬀering the ﬁrst scalable

3We used examples with negative thresholds to indicate
some leeway with misbehavior.
Indeed reputation-based
blacklisting schemes are useful when varying degrees of mis-
behavior may be tolerated, but “up to a point.”

alternative to BLACR. We propose such a scheme, which we
call “PERM”.
Our contributions.
• Persistence of reputation scores. We propose a ‘re-
construction’ of PEREA called “PERM”. Our ﬁrst con-
tribution is to add ‘memory’ to PEREA, hence the name
“PERM” (viz. PEREA with Memory). As long as a con-
nection is scored within its revocation window, the score
persists over time. For example, if a user’s anonymous
comment a year ago was scored within a day of making
that comment, then that score will always factor into the
user’s reputation.
• Free reputation upgrades. To ensure that users
necessarily acquire negative reputation for misbehav-
iors, PEREA-like schemes require that such behaviors be
scored within a revocation window. But the concept of
a memory in PERM also allows for voluntary updates to
reputation outside of this window. While users have no
incentive to voluntarily reduce their reputation, they will
certainly be motivated to apply higher reputation scores
if the score of one of their sessions is later revised. Con-
sider a video upload that receives high user ratings after
several months. At this point a user may want to acquire
a higher reputation for that video. PERM provides such
a voluntary reputation upgrade mechanism through a
memory update protocol and thus positive scores can be
applied at any time.
• Multiple scores per session. In PERM a single ses-
sion can be scored under multiple categories. For exam-
ple, a webpage edit may contain both a copyright viola-
tion as well as objectionable content. BLACR, however,
requires the SP to pick a single category when scoring a
session.
• Much more eﬃcient at the user. Authentications
in BLACR and PEREA are slow at the user and require
computation linear in the size of the blacklist. PERM
requires only a constant amount computation, regardless
of the blacklist size, and is thus much more eﬃcient at
the user end. What would take PEREA half an hour
of computation at the user (over 200,000 reputation list
entries) takes PERM only 0.3 seconds (Section 4.2).
• Eﬃcient at the server. The SP’s computational over-
head is still O(K), as it is for PEREA, and is independent
of the reputation list size. The constant factor is a little
higher than for PEREA, but remains much more eﬃcient
than BLACR.

Paper outline. In Section 2 we provide an overview of the
system goals and our approach with PERM. We provide
the full cryptographic construction of PERM in Section 3
followed by a quantitative analysis in Section 4. We discuss
various issues in Section 5 and conclude in Section 6. The
Appendix provides the security model and sketches the proof
of security for PERM.

2. OVERVIEW

Before we provide the details of our construction, we will
give an overview of our approach. Service Providers (SPs)
issue credentials to users, who can then authenticate anony-
mously to the SP. SPs record transaction identiﬁers with
each authenticated session. Later, if the SP wants to reward
or penalize users for their behavior in that session, then

930the SP uses the transaction identiﬁer to record a reputation
score for that transaction under a particular category (or
categories). These scores are recorded in a reputation list.
SPs can then specify authentication policies, which specify
boolean combinations of reputation thresholds across vari-
ous categories. Users authenticate by proving they satisfy
the policy with respect to the reputation list.
2.1 Authentication policies

l=1((cid:86)J
(cid:87)(cid:96)

Similar

the

to BLACR [2], policies are of

form
j=1 Plj), i.e., a disjunction of conjunctive clauses.
Each conjunctive clause can include J ‘sub policies’ Plj that
correspond to categories. Plj is of the form (ζlj, ηlj), which
states that the authenticating user’s reputation in category
j must be within the range of [ζlj, ηlj]. Not all J categories
need to be covered in each clause, and Plj is set to ⊥ if a sub
policy for that category is skipped. Each transaction iden-
tiﬁer is associated with J scores, representing the scores of
that authentication with respect to each category. The SP
maintains a reputation list L of all transaction identiﬁers
and their corresponding scores. Plj evaluates to 1 if the
reputation of the user based on this reputation list is within
the range [ζlj, ηlj]. We assume there exists an integer Rmax,
which is the maximum value of reputation for any user in
the system. In our analysis we assume Rmax = 1024. A sub-
policy of (−10, Rmax) requires the user to have a reputation
higher than the threshold of −10.

Scores assigned within the revocation window will nec-
essarily be factored into the reputation calculation of an
authenticating user. Reputation scores can be credited to
users beyond the revocation window through a voluntary
‘reputation upgrade’ protocol.
2.2 Security goals

We present informal deﬁnitions of the desired security
properties. They are similar to previous schemes in this
space (BLAC, PEREA, and BLACR); formalized versions
are in the Appendix.

Authenticity: In a system with authenticity, SPs accept
authentications only from users who satisfy the authentica-
tion policy. This property also implies collusion resistance,
i.e., a group of revoked users should not be able to collude
and somehow authenticate.

Anonymity: In a system with anonymity, all that SPs can
infer about the identity of an authenticating user is whether
the user satisﬁes the authentication policy at the time of
protocol execution, regardless of future actions by the SP.

Non-frameability: A user is framed if she satisﬁes the au-
thentication policy, but is unable to successfully authenti-
cate to an honest SP.
In a system with non-frameability,
users satisfying the authentication policy can always suc-
cessfully authenticate to honest SPs.
2.3 PERM: Conceptual approach

We sketch the central ideas of our PERM scheme with
the aid of Figure 1. Like in PEREA, the main idea be-
hind our construction is for the user to maintain a queue of
its K most recent transaction identiﬁers t1, . . . , tK . These
transaction identiﬁers are assigned sequentially by the SP.
The user will use this queue to prove in zero knowledge that
his/her reputation scores with respect to those transaction
identiﬁers, and the reputation list satisfy the authentication
policy. The authentication time at the server is linear in

Figure 1: Structure of a user’s queue before and af-
ter authentication. During authentication the user
1) sends serial number q to the SP, which checks the
freshness of the queue by verifying q has not been
reused, 2) proves the integrity of the queue using
σQ, 3) proves the user satisﬁes the authentication
policy using stored values of each mj and scores cor-
responding to t1, . . . , tK in category j, 4) obtains a
new signature σQ(cid:48) for the updated queue, where s(cid:48)
is a new random number generated by the user.

K, and so K = 10 to keep authentication practical. Similar
to PEREA, after each authentication the oldest transaction
identiﬁer t1 is dropped from the queue, and the new transac-
tion identiﬁer t is added to the queue, adjacent to the most
recent identiﬁer tK .
Adding memory. Our ﬁrst ‘trick’ is to keep state of repu-
tation scores associated with dropped identiﬁers; the queue
stores the user’s cumulative reputation for each of the J
categories as m1, . . . , mJ . The user updates the stored rep-
utation scores based on the scores on the reputation list
associated with the dropped identiﬁer t1 for each category.
These stored reputation values are combined with the repu-
tation values corresponding to identiﬁers in the queue during
authentication. The challenge is: 1) to ensure all these oper-
ations take place in zero knowledge, i.e., the SP should not
learn the previous transaction IDs of an authenticating user
and the reputation scores must be updated without reveal-
ing the scores to the SP; and 2) the user should be able to
prove the integrity of the queue, i.e., the reputation scores
were constructed correctly.
Improving efﬁciency. Our second trick to improve over
PEREA involves eliminating its use of accumulators [7].4
In contrast with PEREA’s random transaction identiﬁers
chosen by the user, transaction identiﬁers are now assigned

4An accumulator [7], allows the representation of a set of el-
ements by a constant value. Elements may be added to (i.e.,
accumulated), or removed from, the accumulator. For each
accumulated element one can compute a short witness that
demonstrates this fact (and, in some cases, in zero knowl-
edge). Thus, an accumulator is an eﬃcient cryptographic
construct for proving set membership, e.g., proving whether
your transaction identiﬁer is on a blacklist (or whitelist)
without revealing the identiﬁer.

Queue before authenticationQueue after authenticationOne-show serial number of queuePrevious K transaction identiﬁersStored reputation for J categoriesm'j = mj + score of removed t1 in category jnew transaction identiﬁerxm1. . .mJtK-1. . .t1tKq QSP issued signature on queuexm'1. . .m'JtK. . .t2tq' Q0User's long-term secret931serially by the SP, and if the SP judges the misbehaviors
sequentially, the SP can maintain a single value, which we
call the “judgment pointer”, indicating the transaction iden-
tiﬁer of the last judged authentication. Transaction iden-
tiﬁers larger than the pointer are ‘unjudged’. Note that
this requirement of judging transitions serially is reasonable
for revocation-window-based schemes because regardless of
what sessions were judged, the judgment pointer must ad-
vance as the revocation window expires for a transaction
identiﬁer or a set of identiﬁers. For example, if the revo-
cation period is one day, the SP can advance the judgment
pointer one day at a time. We refer to the maximum number
of unjudged transactions at any given time as the “judgment
window” N . N will depend on how many anonymous trans-
actions typically occur within a revocation window and can
be set high enough by the server so that it is unlikely for
more transactions to occur within any revocation window.
N aﬀects the size of the public parameter, thus N should
represent a pragmatic choice (20,000 is reasonable as dis-
cussed in Section 4.1).

For the judged transactions, the SP publishes signatures
that bind each score to the corresponding transaction iden-
tiﬁer. These signatures are commonly known as “CL-
signatures” [10], and come with two eﬃcient protocols. The
ﬁrst one is an eﬃcient protocol for a user to obtain a sig-
nature on a committed message (we discuss commitments
in Section 2.4) without revealing the message, while the sec-
ond protocol allows a user to demonstrate in zero knowledge
the possession of a signature on a committed message. These
signatures can later be used by authenticating users to prove
their reputation in zero knowledge. During authentication,
for each identiﬁer in the user’s queue, the user proves that
either the identiﬁer is greater than the judgment pointer or,
using the appropriate signature, that the identiﬁer is asso-
ciated with a particular score and that score is factored into
the (more complex) reputation calculation. This entire au-
thentication takes place in zero knowledge, so the SP learns
only whether the policy was satisﬁed or not and learns no
other information about the individual scores for example.
Next we describe each step at a high level.
2.4 PERM: Construction overview

We present a high-level description of PERM with a single
category. This section is intended to give the reader an
idea of how we achieve constant computational cost while
abstracting the construction details.
Building blocks. Our construction makes use of ‘commit-
ments’ and ‘interval proofs’, which we now describe.
Commitments: C(x) denotes a ‘commitment’ of x. Given
C(x), it is computationally infeasible for the SP to determine
x, but the user can prove various properties about x without
revealing x. We make use of a commitment scheme that
is homomorphic. That is, given C(x), C(y), their product
C(x)C(y) is a commitment of the value x + y. An example
of such a commitment scheme is provided by Pedersen [23].
Interval proofs: Given a commitment C(x), there exists
an eﬃcient interval proof that proves in zero knowledge the
value of x is within a given interval {1, . . . , N}. An example
of such a construction is provided by Camenisch et al. [9].
SP Setup. The SP initializes various public parameters, in-
cluding the revocation window K and the judgment window
N . The SP maintains a list L, which is empty initially and

two counters tc and jp. tc is the current transaction iden-
tiﬁer and jp is the judgment pointer (the identiﬁer of the
last-judged behavior).
User Registration. The user randomly picks two values
x, q ∈R Zp and prepares a queue of size K + 3 as Q =
(x, q, 0, 0, . . . , 0). x is the user’s long-term secret, and q is
a value unique to the queue. The next value represents the
current reputation in the memory while the last K entries
store the past K transaction identiﬁers. Upon completion
of the registration protocol, the user obtains a signature σQ
on the queue Q from the SP. The ﬁrst diagram in Figure 1
illustrates this queue before authentication for the general
case with J categories.
Authentication. Given a queue Q = (x, q, m, t1, . . . , tK )
and a signature σQ, the user obtains the current list L. L is
a list of the following form: (i, si, σi,si )jp
i=1. i is the transac-
tion identiﬁer, si is the score associated with that authen-
tication, and σi,si is the SP’s signature on the tuple (i, si).
We assume the public parameters include (0, 0, σ0,0), which
certiﬁes that the score of the initial values of a queue is zero.
Part I (Queue Validation): Commit every entry of Q in-

dividually as:

C(x), C(q), C(m), C(t1), . . . , C(tK ).

The user then proves that he/she has a signature σQ on
the tuple (x, q, m, t1, . . . , tK ) (thus proving the integrity of
the committed queue). The user also commits the score
related to each of his past K transaction identiﬁers:

C(st1 ), C(st2 ), . . . , C(stK ).

For each value a for a = 1 to K, the user proves to the

SP one of the following is true:

• Transaction with identiﬁer ta is unjudged: C(sta ) is
a commitment of score 0 and C(ta)C(−jp) is a com-
mitment of a value within the range 1 to N . In other
words, 1 ≤ ta − jp ≤ N ;

• Transaction with identiﬁer ta is judged with score sta :
the user has a signature σta,sta on a tuple (ta, sta ),
and C(ta) and C(sta ) are commitments of ta and sta .
The proof that ta−jp is within the range 1 to N is done via
the interval proof discussed before. Nonetheless, the whole
proof can be computed in time linear to K. This proof
assures the SP that the score is committed in each C(sta )
properly. The user further reveals the serial number q to
show that he has not used this queue before (thus proving
the freshness of the queue). This prevents the user from
repeatedly using the same queue.

Part II (Subpolicy Satisfaction): Using the homomorphic
property of the commitment scheme, the user then proves
to the SP that the value C(R) = C(m)C(st1 )··· C(st1 ) is
a commitment of a value R and that R is above the rep-
utation threshold speciﬁed in the policy. For multiple cat-
egories this approach is used for each individual category,
and the boolean policy across categories can be proved in
zero knowledge as described in Section 3.3.
Part III (Queue Update): The user sends a commitment
C(q(cid:48)), which is a commitment of a random number q(cid:48) that
represents the new serial number for the queue. Using all
the commitments, the SP issues a new signature σQ(cid:48) on a
new queue Q(cid:48) = (x, q(cid:48), m + st1 , t2, . . . , tK , t(cid:48)), where t(cid:48) = tc

932is the current transaction identiﬁer. After that, the SP in-
creases the value of tc by 1. The second diagram in Figure 1
illustrates this queue after the update for the general case
with J categories. For the purpose of a possible score up-
date in the future for transaction t1, which was moved to
the memory, the SP also issues a signature σx,t1 on the tu-
ple (x, t1). The signature σx,t1 is a ‘receipt’ for transaction
t1.
Scoring an entry. The SP judges entry jp + 1 and gives
it a score sjp+1. It then creates a signature σjp+1,sjp+1 and
puts the tuple (jp + 1, sjp+1, σjp+1,sjp+1 ) on the reputation
list L. Note that sjp+1 can be positive or negative. After
putting (jp + 1, sjp+1, σjp+1,sjp+1 ) on the list, the value of jp
is increased by 1. These scores will be reﬂected in the user’s
reputation only if the transaction was judged within the re-
vocation window for that transaction.
Upgrading a score. Suppose later (outside of the revoca-
tion window) the score of an entry t on the reputation list L
is changed from st to s(cid:48)
t. Let d be the diﬀerence. A user with
queue Q = (x, q, m, t1, . . . , tK ) and a receipt σx,t approaches
the SP, reveals the value q and t, and demonstrates that he
has a signature on σQ and σx,t. At the end of the protocol,
he receives a new signature σQ(cid:48) with the updated score in his
memory as Q(cid:48) = (x, q(cid:48), m + d, t1, . . . , tK ). The SP marks the
entry t as having been upgraded to prevent attacks where
users try to apply the same credit multiple times. If the SP
decides to further change the score in the future, the user
can again apply the new balance, and as before this balance
can be credited only once.

3. PERM CONSTRUCTION

In our construction we require digital schemes that sup-
port various zero-knowledge, proof-of-knowledge protocols.
For clarity we employ the pairing-based variant (BBS+) [3]
of the well-known CL signature [10, 11]. It should be noted
that speciﬁc signature schemes can be employed in diﬀerent
protocols of our system for eﬃciency considerations.
3.1 Parameters
Let λ be a suﬃciently large security parameter. Let ˆe :
G1 × G2 → GT be a bilinear pairing such that |G1| = |G2| =
|GT| = p for a λ-bit prime p. Let g0, g1, g2 ∈ G1 (resp.
h0 ∈ G2) be generators of G1 (resp. G2) such that the
relative discrete logarithm of the generators is unknown.5
Let H : {0, 1}∗ → Zp be a collision-resistant hash function.
Throughout this section these parameters will be available
to all parties.
3.2 Building blocks

3.2.1 Zero-Knowledge Proofs of knowledge
In a Zero-Knowledge Proof of Knowledge (ZKPoK) pro-
tocol [16], a prover convinces a veriﬁer that some statement
is true while the veriﬁer learns nothing except the validity
of the statement. Σ-protocols are a type of ZKPoK pro-
tocol, which can be converted into non-interactive Signa-
ture Proof of Knowledge (SPK) schemes, or simply signature
schemes [17], that are secure under the Random Oracle (RO)
Model [6]. We follow the notation introduced by Camenisch

and Stadler [12]. For instance, PK{(x) : y = gx} denotes a
ZKPoK protocol in which a prover proves the knowledge of
an integer x such that the relationship y = gx holds. Sym-
bols appearing on the left of the colon denote values whose
knowledge is being proved while symbols appearing on the
right, but not the left, of the colon denote public values.
We use SPK{(x) : y = gx} (M ) to denote the corresponding
signature proof of knowledge.
3.2.2 Commitment scheme
Our construction uses the well-known, non-interactive
commitment scheme due to Pedersen [23], which is brieﬂy
reviewed below. Let G be a cyclic group of prime order p
and g, h be independent generators of G. On input of value
x ∈ Zp, the committer randomly chooses r ∈ Zp, computes
and outputs C = gxhr as a commitment of value x. To re-
veal the value committed in C, the committer outputs (x, r).
Everyone can test if C = gxhr. C is a commitment of a value
x with opening r.

Pedersen Commitment is perfect hiding and computation-
ally binding. That is, even a computationally unbounded
receiver cannot learn anything about the value committed
from the commitment. On the other hand, a probabilistic
polynomial time (PPT) sender can only reveal the commit-
ment with one value under the discrete log assumption.

We use “C(x)” to denote a Pedersen Commitment of a
value x. Note that Pedersen Commitment is homomorphic
in the sense that on input C(a) and C(b), C(a) ∗ C(b) gives
a commitment of a + b.
3.2.3 Credential signature scheme
We brieﬂy review the signature scheme proposed by Au
et al. [3], which is called BBS+. Their scheme is based
on the schemes of Camenisch and Lysyanskaya [11] and of
Boneh et al. [8]. BBS+ is employed to certify queues as
well as binding scores to transaction identiﬁers in PERM.
Let g, g0, g1, g2, . . . , gk ∈ G1 be generators of G1 and h be a
generator of G2. The signer’s secret is a value γ ∈ Zp and the
public key is w = hγ. BBS+ supports a block of messages
as follows. To sign a message block (x0, x1, . . . , xk) ∈ Zk+1
,
the signer randomly picks e, y ∈R Zp, and computes A =
(ggx0
γ+e . The signer outputs (A, e, y) as the
signature on the block of messages (x0, . . . , xk). To verify
a BBS+ signature, one can test if the following equation
holds:

1 ··· gxk

0 gx1

k gy

k+1)

p

1

ˆe(A, whe) = ˆe(ggx0

1 ··· gy

0 gx1

k+1, h).

They also derive the two useful protocols below.
Protocol SIss. SIss allows a user to obtain a credential sig-
nature from the signer on a block of values (x0, . . . , xk) com-
mitted in C0, . . . , Cm. Let the user’s additional input be
x0, r0, . . . , xk, rk such that Ci = gxi

1. The user computes CM = gx0

k+1 for some
randomly generated y(cid:48) ∈R Zp, sends CM to the signer
along with the following proof:

1 gri
0 gx1

2 for i = 0 to k.
1 ··· gxk

k gy(cid:48)





({xi, ri}, y

(cid:48)

PK

CM = gx0

0 gx1

) :
1 ··· gxk

k gy(cid:48)

k+1

k(cid:94)

(Ci = gxi

1 gri
2 )

i=0

5This can be done by setting the generators to the output of
a cryptographic hash function of some publicly known seeds.

2. The signer returns 0 if veriﬁcation of the proof fails.
Otherwise the signer randomly generates e, y(cid:48)(cid:48) ∈R Zp,

933computes A = (gCM gy(cid:48)(cid:48)
to the user.

k+1)

1

e+γ , and returns (A, e, y(cid:48)(cid:48))

3. The user computes y = y(cid:48) + y(cid:48)(cid:48). She returns 0 if
k+1, h). Otherwise the user

1 ··· gy

ˆe(A, whe) (cid:54)= ˆe(ggx0
0 gx1
outputs σ as (A, e, y).

Protocol SSig. In protocol SSig a prover convinces a veriﬁer
he/she knows a signature σ = (A, e, s) on a block of mes-
sages (x0, . . . , xk) committed in C0, . . . , Ck. Additionally,
the prover knows the values and openings of the commit-
ments x0, r0, . . . , xk, rk such that Ci = gxi
for i = 0 to
k.

1 gri

2

1. Let M be the random challenge. The prover randomly
2 , A2 =

generates k1, k2 ∈R Zp, computes A1 = gk1
Agk1

2 , and the following SPK Π.

1 gk2

({xi, ri}, e, y, k1, k2, β1, β2) :

k(cid:94)

i=0

1 gri

(Ci = gxi

2 ) ∧
2 ∧
1 gk2
A1 = gk1
−e
1 gβ1
1 gβ2

2 ∧





SPK

1 = A
= ˆe(g0, h)x0 ··· ˆe(gk, h)xk

ˆe(A2, w)
ˆe(g, h)

(cid:48)

)

(M

ˆe(gk+1, h)y ˆe(g2, w)k1
ˆe(g2, h)β1 /ˆe(A2, h)e

where M(cid:48) = M||A1||A2 and β1 = k1e, β2 = k2e.

2. The prover outputs pSig as (Π, A1, A2).

3. Upon receiving (pSig, M ), the veriﬁer parses pSig as

(Π, A1, A2) and outputs accept if Π is a valid proof.

3.2.4 Signature-based interval proof
To demonstrate that the reputation of a user is within a
certain range, we employ the signature-based interval proof
due to Camenisch et al. [9]. In a nutshell the veriﬁer pro-
vides a set of ‘digital signatures’ on the elements of the re-
quired range under a veriﬁcation key. We consider this set
of digital signatures to be the public parameter. In order
for the prover to demonstrate that a certain value commit-
ted in a commitment is within the range, the prover proves
in zero-knowledge that he/she knows a signature under the
veriﬁcation key for the element committed. This proof is of
constant size and is useful when the range is small.
3.3 Actual construction
SP Setup. The SP selects the revocation window K, judg-
ment window N , and the total number of categories J. The
SP further creates two instances of the BBS+ signatures
(P K1, SK1) and (P K2, SK2). The ﬁrst BBS+ signature in-
stance supports a message block of size K + J + 2 and the
second instance supports a message block of size J + 2.

The public parameter is (P K1, P K2, K, N, J) together
with the judgment pointer jp and the current transaction
counter tc which are both initialized to zero.

The secret key is (SK1, SK2).

mj +(cid:80)K

Registration. The user randomly picks two values x(cid:48), q ∈R
Zp and prepares a queue of size K + J + 2 as Q =
(x(cid:48), q, 0, . . . , 0).
The user computes C(x(cid:48)), C(q) and sends them to the SP.
The SP randomly picks another random number x(cid:48)(cid:48) ∈R Zp
and computes C(x(cid:48) + x(cid:48)(cid:48)). The value x(cid:48)(cid:48) is sent to the user.
The user computes x = x(cid:48) + x(cid:48)(cid:48) and sets the ﬁrst element of
his queue Q to x. The value x is used as his long-term secret
key. Note that this is possible due to the homomorphic
property of the commitment scheme.

tion policy P = (cid:87)(cid:96)

The user and SP engage in the protocol SIss of the BBS+
signature scheme with public key P K1. Upon successful
completion of the protocol, the user obtains a signature σQ
on his queues Q. The user stores (σQ, x, q).
Authentication. The user is in possession of σQ on his
queue Q = (x, q, m1, . . . , mJ , t1, . . . , tK ). The user down-
loads the latest list from the SP as well as the authentica-
j=1 Plj). Each Plj is of the form
(ζlj, ηlj) and requires the user’s reputation in category j to
be within the range (ζlj, ηlj). The list L is a list of jp en-
tries (i, s1,i, . . . , sJ,i, σi)jp
i=1, where σi is a BBS+ signature
on the tuple (i, s1,i, . . . , sJ,i) under P K2. sj,i is the score of
transaction with identiﬁer i in category j.

l=1((cid:86)J

The user computes his reputation in category j as Rj =
a=1,ta≤jp sj,ta and checks that there exists an index
l ∈ {1, . . . , (cid:96)} such that ζlj ≤ Rj ≤ ηlj. If yes, the user sat-
isﬁes the policy and computes the following commitments.

C(x), C(m1), . . . , C(mJ ), C(t1), . . . , C(tK )

Next, the user send q to the SP and employs SSig to show
that he has a signature σQ. This assures the SP the set of
commitments is computed correctly. The SP also checks the
freshness of q and stores it in the database.
{C(s1,ta ), . . . , C(sJ,ta )}K
of the following two statements is true for a = 1 to K:

set of commitments
a=1 to the SP, and proves that one

sends another

the user

Next

1. 1 ≤ (ta − jp) ≤ N and sj,ta = 0 for j = 1 to J;
2. The user has a signature σi on message block
(ta, s1,ta , . . . , sJ,ta ) and sj,ta = sj,i for all j = 1 to
J.

a=1

both

Next,

parties

compute

C(sj,ta ).

locally C(Rj)

The above proof assures the SP that C(sj,ta ) is the score

of the user’s authentication ta in category j.

C(mj)(cid:81)K
sub-clause of ((cid:86)J

=
The value C(Rj) is a commit-
ment of the user’s reputation in category j.
In order to
show that the user satisﬁes the boolean policy, the user
proves in zero-knowledge that the set {Rj}J
j=1 satisﬁes one
j=1 Plj) of the policy P, which states that:
∃l ∈ {1, . . . (cid:96)} : ζlj ≤ Rj ≤ ηlj for i = 1 to J. Proving
in zero-knowledge that ζlj ≤ Rj ≤ ηlj is accomplished by
the interval proof. We assume the scores are small so that
the interval proof discussed in Section 3 can be employed.
Further, since we are working in a cyclic group of prime
i=0 si < p to prevent the sum of
positive reputation scores from wrapping around and being
interpreted as negative. Combining the zero-knowledge
proofs in a 1-out-of-(cid:96) manner can be accomplished using
the technique described by Cramer et al. [14]. Thus, the
user can prove in zero-knowledge that the boolean policy is
satisﬁed.

order p, we assume (cid:80)tc

934Finally, the user randomly generates q(cid:48) ∈R Zp and com-
putes C(q(cid:48)). Using protocol SIss, the SP issues two signa-
tures to the user. The ﬁrst one is σQ(cid:48) which is a BBS+
signature on the queue Q(cid:48) = (x, q(cid:48), m1 + s1,t1 , . . . , mJ +
sJ,t1 , t2, . . . , tK , t). Note that t = tc is the value of the cur-
rent transaction counter.

SP adds

The SP also issues another BBS+ signature σx,t1 , which
is a signature on message (x, t1). The user stored this should
he want to use the free upgrade in the future. The SP in-
creases the value of tc by 1.
Scoring a transaction. The
entry
(jp, s1,jp, . . . , sJ,jp, σjp) after giving the appropriate score to
authentication j. Then the SP increases jp by 1.
Upgrading a score. After some time, the SP could in-
crease the scores for transaction identiﬁer t. Let’s say
the original score is s1,t, . . . , sJ,t and the updated score is
s(cid:48)
1,t, . . . , s(cid:48)
J,t. To conduct an upgrade, the user uses his cur-
rent secret σQ, which is a signature on his current queue
Q = (x, q, m1, . . . , mJ , t1, . . . , tK ) as well as a signature σx,t,
which he obtains when the transaction identiﬁer t shifts out
from his queue.

the

Similar to an authentication, the user releases q and pro-

duces the following commitments:

C(x), C(m1), . . . , C(mJ ), C(t1), . . . , C(tK ).

The SP checks the freshness of the value q and stores it in
its database.

The user proves to the SP in zero-knowledge that he has
σx,t and σQ using the protocol SSig.
If the SP accepts
the proof, the user further randomly generates q(cid:48) ∈R Zp.
They then engage in the protocol SIss. Upon termination of
the protocol, the user obtains a signature σQ(cid:48) on messages
j,t−sj,t.
(x, q(cid:48), m1 +d1, . . . , mJ +dJ , t1, . . . , tK ), where dj = s(cid:48)
The SP marks the update as complete and no score update
request on this entry will be entertained.
3.4 Security of our construction

The security model for PERM, and the proof of security

for our construction is sketched in the Appendix.

4. QUANTITATIVE ANALYSIS

We now analyze the communication and computational
performance of PERM and show that PERM is the ﬁrst
practical and scalable scheme to support reputation-based
blacklisting. Note that for PEREA we assume the ‘PEREA
with Naughtiness’ extension [4], which adds some form of
reputation (albeit only negative reputation and the score
computed is only over the most recent revocation window).
4.1 Data transfer

Assume each score is of 5 bits and the maximum reputa-
tion of the user in any category is in a 10-bit range. Fur-
ther, assume the total number of authentications is less than
250 (an entirely reasonable assumption considering that the
total number of edits made to all pages in Wikimedia is
about 231.6). Following the parameters in BLACR [2], we
have Zp = 249 bits and elements in G1 and G2 are of size
320 and 944 bits. Each entry in the reputation list is of
868 + 5J bits, where J is the number of categories. Together
with the random challenge, the total downlink complexity is

6http://toolserver.org/~emijrp/wikimediacounter/

((868+5J)L+249) bits, where L is the size of the reputation
list, which is the value of jp in PERM. Further, assume we
have 5 categories. Each entry in the list is less than 1Kb.
Suppose the number of anonymous authentications per day
is 20,000 (this would correspond to about 1 in 5 edits on
Wikipedia being anonymous, which is what Au et al. as-
sume [2, §5.2]), a user would need to download 2.2MB of
data a day to keep its list up-to-date. The overhead of each
authentication is 0.2KB, which corresponds to the receipt
plus a signature on the new queue. Here we assume the pol-
icy is not changed frequently and is thus treated as part of
the public parameters.

The size of the uploaded proof by the user (with J = 5)
is (2K + 8 + 10(cid:96))*320 + (78K + 5(cid:96) + 27)*249 bits. Further,
assume (cid:96) = 5, K = 10, a proof is of constant size at 28KB.
Note that this is a conservative estimate, since further opti-
mizations are possible. For instance, one could replace the
commitment of an individual transaction identiﬁer with a
commitment of all in a single group element. We leave such
optimizations for future work, although, given that the size
is only 28KB, these may not be necessary.

The public parameter size is linear to the judgment win-
dow. Again, assume the total number of authentications per
day is 20,000 and that each authentication is to be judged
within one day and the public parameter size will be around
2MB. Even if the judgment window is computed over a week,
a one-time download of about 14MB is reasonable.

4.2 Computation

We now compare the performance of PERM at the SP and
the user. We compare PERM with BLACR and PEREA, as
those are the two closest schemes that support reputation-
based blacklisting with strong security properties.

We have identiﬁed the major operations for each of the
schemes as shown in Table 1. The symbols EN1 and EN2
represent the time cost of an exponentiation of a small expo-
nent to a random base without pre-processing and a range
exponent to a ﬁxed base with pre-processing modulo a large
RSA modulus, respectively. The symbols “E1”, “E2”, and
“ET” represent the time cost of a multi-based exponentia-
tion without pre-processing in the groups G1, G2, and GT ,
respectively. Likewise, “EP1”, “EP2”, and “EPT” represent
the time cost of an exponentiation with respect to a known
single base with pre-processing in the groups G1, G2, and
GT , respectively. Finally, P represents the time cost of a
bilinear pairing operation. Since these parameters are the
same as those in BLACR, we reuse the benchmarks from
BLACR [2, Table 3], which were obtained on a Lenovo X200s
with an Intel Core 2 Duo CPU L9400 and 4GB RAM run-
ning Windows Vista as the host.

For PERM the amount of computation at the user is
drastically reduced as compared to other schemes. In fact,
nearly all exponentiation operations at the user side are pre-
computable. Since the score of each transaction identiﬁer is
from a limited range (e.g. 5 bits), it is possible to pre-
compute commitments of all possible scores. At the same
time, the reputation is also from a limited range (e.g. 10
bits) and thus the range proof is pre-computable. The ﬁrst
move of the three-move, zero-knowledge proof can always be
pre-computed, and the last move of the proof only consists of
additions and subtractions in Zp. The only step that cannot
be pre-computed relates to the digital signatures of the en-
tries on the list, where the commitments of such signatures

935Schemes
BLACR Normal

BLACR Express

Parties
User (w/pre-computation)
SP

User (w/pre-computation)
SP

PEREA (w/ Naughtiness) User

PERM

SP
User

User (w/pre-computation)
SP

Computation

(cid:0)(3 − ζ)L(cid:1)E1 + 1EPT + 1P
(cid:0)12L + 3(cid:96)J + 8J + 5(cid:1)E1 + 4J EP1 +(cid:0)5L + 5(cid:96)J + 5(cid:1)EPT +
(cid:0)L + (cid:96)J + 1)P +(cid:0)2L + 2(cid:96)J + 2(cid:1)EP2
(cid:0)(3 − ζ)L(cid:1)E1 + 1EPT + 1P
(cid:0)12∆L + 3(cid:96)J + 12J + 7(cid:1)E1 + 4JEP1 +(cid:0)5∆L + 5(cid:96)J + 4J + 9(cid:1)EPT +
(cid:0)∆L + (cid:96)J + 2)P +(cid:0)2∆L + 2(cid:96)J + 4(cid:1)EP2

3 (cid:101) + 12]EN2

3 (cid:101) + 8]EN2

[(A + 1)∆L]EN1 + [16K + (cid:100) K−1
[15K + (cid:100) K
[15KJ + 15K + 3J + 6(cid:96)J + 16]E1 +
[2K(cid:100) J+6
[K] E1 + (2K + 2)P
[5KJ + 6K + 2J + 4(cid:96)J + 16]E1 +
[3KJ + 3(cid:96)J + (cid:100) J+K+7
(cid:101) + K(cid:100) J+7

3 (cid:101) + 4KJ + (cid:100) J+K+6

3

(cid:101) + 2(cid:96)J]ET + [2KJ + 2K + J]P

3

3 (cid:101)]ET + [2KJ + 2K + 2J + 2]P

Table 1: Complexity analysis for BLAC, PEREA, and PERM. J is the total number of categories (cid:96) is the
number of sub-policies in the boolean policy, where each sub-policy is assumed to involve all J categories. For
BLACR and PEREA ∆L is the number of new entries on the reputation list since the previous time period.
Speciﬁc to BLACR, ζ is the fraction of entries belonging to the user in the reputation list.

are needed during the zero-knowledge proof. Each authen-
tication identiﬁer is associated with one signature, and thus
the user needs to compute K commitments online. Specif-
ically, the value A2 is not known oﬀ-line in protocol SSig.
Note that computing A2 does not require any exponentia-
tions (since the value gk1
2 does not depend on the value A
and can be pre-computed). However, in the proof two values
related to A2 are required: ˆe(A2, g) and ˆe(A2, w). Another
exponentiation to base A2 is needed in the production of the
‘OR’ part of the proof.
Performance at the SP. Figure 2(a) shows the perfor-
mance of authentication of PERM compared to the other
schemes at the SP. Au et al. argue that a server through-
put of 25 authentications/minute would be practical for SPs
such as Wikipedia [2, §5.2], and we use that as our baseline.
The amount of computation at the SP in both PEREA and
PERM are independent of the reputation list size and corre-
spond to the two horizontal lines. For PERM with K = 10,
the SP can support 10 authentications/minute as compared
to 23 for PEREA (PEREA is faster, but recall the severe
limitations to its functionality, i.e., reputation is calculated
over only the short revocation window). Since authentica-
tions are easily parallelized, additional servers can be used to
bring authentication rates higher. With 2–3 servers (costing
about $5–7.5K/year on Amazon EC2) these rates are more
than adequate for anonymous authentications on a large SP
such as Wikipedia.

For BLACR the worst case performance is too slow for
reputation lists with 1 million entries. Assuming three
servers, BLACR would be able to support only 3 authen-
tications every 1–2 hours. BLACR uses an ‘express lane’
technique to allow users who authenticated in the previous
time period to prove their reputation incrementally from the
last authentication. If we assume all users regularly authen-
ticate in the express lane (with 2% new entries since the
previous authentication), the SP can support 2 authentica-
tions per minute, which is still almost 10 times slower than
PERM. Since the performance of BLACR in the normal lane
is so slow, we do not attempt to ﬁt it into the graph (in
which case the curves for PEREA and PERM would not be
visible). Now consider the case of Wikimedia where the run-
ning count of edits exceeds 1.5 billion.7 In this case, PERM

7http://toolserver.org/~emijrp/wikimediacounter/

would be many thousands of times faster than BLACR for
those users who authenticate in the normal lane.
Performance at the user. Figure 2(b) shows the per-
formance of authentication of PERM compared to other
schemes at the user. PEREA’s main drawback was the lin-
ear increase in performance in both K and the reputation
list size at the user. Both BLACR in the normal lane and
PEREA (assuming only 2% new entries since the last au-
thentication) are unacceptably slow and we do not attempt
to ﬁt them within the graph. PEREA would take 38 minutes
of computation, and BLACR would take about 74 minutes
for a reputation list with 1 million entries. Assuming express
lane authentication, BLACR would take 88 seconds for the
user, which is much better (but recall the performance for
BLACR is unacceptable at the SP at this scale).
In con-
trast, PERM requires only 0.3 seconds of computation, and
is close to the X-axis in the graph.

Thus, considering both the performance at the SP and the
user for millions of entries on the reputation list, it is clear
that only PERM oﬀers a viable solution for reputation-based
blacklisting. As one can note, even for tens of millions (or
billions!) of entries, the performance at the SP and the user
would remain unchanged.

A note on BLACR-Unweighted. Since we compare PERM
to BLACR, we now describe our basis for this comparison.
The authors of BLACR propose a weighted extension in
which reputation scores can be increased for repeated misbe-
haviors by the same user, but we currently do not attempt to
replicate this ramp-up functionality. Referring to their tech-
nical report [5], the computational complexity of BLACR-
Unweighted at the user side is the same as that of BLACR-
Weighted. At the SP, BLACR-Unweighted is roughly 3 to 4
times faster than BLACR-Weighted. While the express-lane
authentication trick is not applied to BLACR-Unweighted,
their analysis shows that it is also applicable. Since we are
concerned with reputation list sizes of around a million, the
overhead applicable to the express-lane trick becomes neg-
ligible, and the rate-determining step is the number of ex-
ponentiations and pairing operations per entry of the list.
In BLACR-weighted the value is 19 exponentiations plus 1
pairing while the ﬁgure is 8 exponentiations for BLACR-
unweighted. Since 1 pairing operation takes roughly the
same time as 5 exponentiations, one can safely deduce that
BLACR-unweighted is at most 4 times faster than BLACR-

936(a) Authentication time at the SP. The horizontal curves cor-
respond to PEREA and PERM. BLACR with Normal Lane
is too slow and we do not attempt to ﬁt it into the graph. In-
stead, one could assume BLACR with Express Lane is always
used. As we can see, the authentication rates at the SP would
be too low for BLACR with 1 million reputation list entries,
whereas PERM supports practical authentication rates.

(b) Authentication time at User (includes precomputation).
As we can see authentication rates for BLACR with Normal
Lane and PEREA are unacceptably slow at the user. BLACR
with Express Lane is somewhat acceptable, and in comparison
the time taken by PERM is negligible at the user (and is close
to the X-axis).

Figure 2: Estimated authentication times at the SP and User and the cost for the SP. For the SP we assume
a server with 8 CPU cores, since such conﬁgurations are standard for servers. Likewise, we assume 4 CPU
cores for the user, since such conﬁgurations are more standard for consumer desktops and laptops.

weighted with the express lane trick applied. We make this
(conservative) assumption in our performance analysis.

5. DISCUSSION

Recently proposed alternative. FAUST [22] is the most re-
cent scheme in the revocation window paradigm and aims
to improve performance over PEREA. While FAUST is not
designed speciﬁcally for reputation, it can simulate at least
part of the functionality by making users maintain a col-
lection of tokens. As individual tokens get revoked (for a
misbehavior with score 5, for example, 5 tokens can be re-
voked), users may eventually not have the threshold number
of tokens left to authenticate. The downside with this ap-
proach is that it is not collusion resistant and individual
revoked users can pool their tokens together to gain access.
Existing schemes such as BLACR, PEREA, and our PERM
do not suﬀer from this drawback. Furthermore, FAUST can-
not support general reputation-based policies (across cate-
gories for example) and thresholds cannot be changed after
tokens have been issued (the number of authenticator to-
kens needs to be determined after the policy has been set).
Because of these limitations we do not consider FAUST to
be a viable solution for reputation-based blacklisting. Nev-
ertheless, FAUST has novel features that can be leveraged
by PERM. For example, we assume that users download all
the signatures for entries on the reputation lists (so as not
to reveal which transaction identiﬁers are in their queue).
FAUST shows how users can selectively download diﬀerent
subsets while maintaining statistical privacy. We leave such
combinations to future work, although we believe that the
downlink complexity of PERM is already reasonable.

Revocation window. While PERM greatly improves per-
formance over BLACR, BLACR can score sessions at any
time, even long after the session (e.g., months later). PERM

on the other hand requires that sessions be scored within the
revocation window, which is on the order of hours to a couple
of days in practical settings. The authors of FAUST argue,
“89% of vandalism instances were repaired within 100 views
[on Wikipedia]...[revocation windows] as low as 30 minutes
seem feasible” [22]. Thus, while some ﬂexibility is traded
oﬀ for performance, the revocation-window-based setting is
practical for SPs such as Wikipedia. Nevertheless, we point
out that positive scores may materialize over longer time
periods, where, for example, an uploaded video becomes
popular after several months. In those cases we show how
reputation can be upgraded in PERM, thus oﬀering a novel
improvement to revocation-window-based schemes.

Unblacklisting. Related to the previous discussion point,
SPs can unblacklist (forgive) misbehaviors by simply up-
grading negative scores to zero.

Sybil attacks. Any credential scheme (including BLACR
and PEREA) is vulnerable to the Sybil attack, where if one
credential is revoked by PERM, the user may attempt to
obtain another credential. We assume some Sybil-resistant
mechanism while issuing credentials, as must be assumed
with any such scheme. For example, an organization (e.g. a
company or a university) already has the means to issue one
credential per member in the organization. Online services
could require a credit card and make note of which identities
(using the identity on the credit card) have been issued cre-
dentials. This identity-revealing step is reasonable because
future authentications are anonymous and the identity is
used only during the step of issuing credentials.

Side channels. In PERM the amount of time taken to ver-
ify an authentication at the SP and the user is independent
of the list size and is the same for all authenticating users.
Therefore, PERM is resistant to side-channel leaks related
to the time it takes to authenticate. Of course, users on

 0 20 40 60 80 100 0 200000 400000 600000 800000 1e+06Authentication time (sec)Reputation List size (L)Authentication time at the server vs. Reputation List size, 8 CoresBLACR Normal LaneBLACR Express Lane (2% New)PERM K=10PEREA-Naughtiness K=10 0 20 40 60 80 100 0 200000 400000 600000 800000 1e+06Authentication time (sec)Reputation List size (L)Authentication time at the user vs. Reputation list size, 4 CoresBLACR Normal LanePEREA-Naughtiness K=10 (2% New)BLACR Express Lane (2% New)PERM K=10937diﬀerent platforms would exhibit diﬀerent latencies, and the
client software can delay each authentication to some small
constant (e.g. 2 seconds) so that all users exhibit uniform
behavior. Other side channels are out of scope for this work.

6. CONCLUSION

Since TTP-free anonymous blacklisting was ﬁrst intro-
duced, several advances have been made in an attempt to
make such schemes more practical and useful to service
providers. Recent work on BLACR attempted to generalize
the concept of anonymous blacklisting to allow reputation-
based blacklisting, but did not oﬀer a scalable solution. We
believe PERM is the ﬁrst scheme to support scalable and
practical reputation-based blacklisting and thus presents a
major advance in the progression of such schemes.

7. ACKNOWLEDGMENTS

We thank the late Patrick P. Tsang for his work on BLAC
and PEREA, which provided inspiration for the ideas in this
paper. We also thank the anonymous reviewers for their
comments and John McCurley for his editorial help.

8. REFERENCES
[1] G. Ateniese, J. Camenisch, M. Joye, and G. Tsudik. A

Practical and Provably Secure Coalition-Resistant
Group Signature Scheme. In CRYPTO, volume 1880
of Lecture Notes in Computer Science, pages 255–270.
Springer, 2000.

[2] M. H. Au, A. Kapadia, and W. Susilo. BLACR:

TTP-Free Blacklistable Anonymous Credentials with
Reputation. In Proceedings of The 19th Annual
Network and Distributed System Security Symposium
(NDSS), Feb. 2012.

[10] J. Camenisch and A. Lysyanskaya. A Signature

Scheme with Eﬃcient Protocols. In SCN, volume 2576
of Lecture Notes in Computer Science, pages 268–289.
Springer, 2002.

[11] J. Camenisch and A. Lysyanskaya. Signature Schemes

and Anonymous Credentials from Bilinear Maps. In
CRYPTO, volume 3152 of Lecture Notes in Computer
Science, pages 56–72, 2004.

[12] J. Camenisch and M. Stadler. Eﬃcient Group

Signature Schemes for Large Groups (Extended
Abstract). In B. S. K. Jr., editor, CRYPTO, volume
1294 of Lecture Notes in Computer Science, pages
410–424. Springer, 1997.

[13] D. Chaum and E. van Heyst. Group Signatures. In

EUROCRYPT, pages 257–265, 1991.

[14] R. Cramer, I. Damg˚ard, and B. Schoenmakers. Proofs
of Partial Knowledge and Simpliﬁed Design of Witness
Hiding Protocols. In Y. Desmedt, editor, CRYPTO,
volume 839 of Lecture Notes in Computer Science,
pages 174–187, 1994.

[15] R. Dingledine, N. Mathewson, and P. Syverson. Tor:

The Second-Generation Onion Router. In Usenix
Security Symposium, pages 303–320, Aug. 2004.

[16] S. Goldwasser, S. Micali, and C. Rackoﬀ. The

Knowledge Complexity of Interactive Proof Systems.
SIAM J. Comput., 18(1):186–208, 1989.

[17] S. Goldwasser, S. Micali, and R. L. Rivest. A Digital

Signature Scheme Secure Against Adaptive
Chosen-Message Attacks. SIAM J. Comput.,
17(2):281–308, 1988.

[18] R. Henry, K. Henry, and I. Goldberg. Making a

Nymbler Nymble Using VERBS. In Privacy
Enhancing Technologies, volume 6205 of Lecture Notes
in Computer Science, pages 111–129, 2010.

[3] M. H. Au, W. Susilo, and Y. Mu. Constant-Size

[19] P. C. Johnson, A. Kapadia, P. P. Tsang, and S. W.

Dynamic k-TAA. In SCN, volume 4116 of Lecture
Notes in Computer Science, pages 111–125. Springer,
2006.

[4] M. H. Au, P. P. Tsang, and A. Kapadia. PEREA:

Practical TTP-Free Revocation of Repeatedly
Misbehaving Anonymous Users. ACM Transactions on
Information and System Security, 14:29:1–29:34, Dec.
2011.

Smith. Nymble: Anonymous IP-Address Blocking. In
Privacy Enhancing Technologies, volume 4776 of
Lecture Notes in Computer Science, pages 113–133.
Springer, 2007.

[20] A. Kiayias, Y. Tsiounis, and M. Yung. Traceable

Signatures. In C. Cachin and J. Camenisch, editors,
EUROCRYPT, volume 3027 of Lecture Notes in
Computer Science, pages 571–589. Springer, 2004.

[5] M. H. Au, P. P. Tsang, A. Kapadia, and W. Susilo.

[21] Z. Lin and N. Hopper. Jack: Scalable

BLACR: TTP-Free Blacklistable Anonymous
Credentials with Reputation. Technical Report
TR695, Indiana University Bloomington, May 2011.

[6] M. Bellare and P. Rogaway. Random Oracles are

Practical: A Paradigm for Designing Eﬃcient
Protocols. In ACM Conference on Computer and
Communications Security, pages 62–73, 1993.

[7] J. C. Benaloh and M. de Mare. One-Way

Accumulators: A Decentralized Alternative to Digital
Sinatures (Extended Abstract). In EUROCRYPT,
pages 274–285, 1993.

[8] D. Boneh, X. Boyen, and H. Shacham. Short Group

Signatures. In CRYPTO, volume 3152 of Lecture
Notes in Computer Science, pages 41–55, 2004.

[9] J. Camenisch, R. Chaabouni, and A. Shelat. Eﬃcient

Protocols for Set Membership and Range Proofs. In
ASIACRYPT, volume 5350 of Lecture Notes in
Computer Science, pages 234–252. Springer, 2008.

accumulator-based Nymble system. In WPES, pages
53–62, 2010.

[22] P. Lofgren and N. Hopper. FAUST: Eﬃcient,

TTP-Free Abuse Prevention by Anonymous
Whitelisting. In Proceedings of the Workshop on
Privacy in the Electronic Society (WPES), Oct. 2011.

[23] T. P. Pedersen. Non-Interactive and

Information-Theoretic Secure Veriﬁable Secret
Sharing. In CRYPTO’91, volume 576 of LNCS, pages
129–140, 1992.

[24] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.

Blacklistable Anonymous Credentials: Blocking
Misbehaving Users without TTPs. In ACM
Conference on Computer and Communications
Security, pages 72–81. ACM, 2007.

[25] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.

PEREA: Towards Practical TTP-Free Revocation in
Anonymous Authentication. In ACM Conference on

938Computer and Communications Security, pages
333–344, 2008.

[26] P. P. Tsang, M. H. Au, A. Kapadia, and S. W. Smith.
BLAC: Revoking Repeatedly Misbehaving Anonymous
Users without Relying on TTPs. ACM Trans. Inf.
Syst. Secur., 13(4):39, 2010.

[27] P. P. Tsang, A. Kapadia, C. Cornelius, and S. W.

Smith. Nymble: Blocking Misbehaving Users in
Anonymizing Networks. IEEE Trans. Dependable Sec.
Comput., 8(2):256–269, 2011.

APPENDIX
A. SECURITY ANALYSIS

We adopt the simulation-based security deﬁnition as in
PEREA [4]. In the real world there are a number of play-
ers who communicate via cryptographic protocols while in
the ideal world the same players communicate via a trusted
party T who is responsible for handling all the inputs and
outputs for the players. The adversary A controls the same
players in the real world and the ideal world. All the inputs
and the scheduling of the players’ interactions are decided
by another probabilistic polynomial time (PPT) algorithm,
and the environment E. A can communicate arbitrarily with
E. Informally speaking, PERM is secure if for any PPT al-
gorithms A and E, there exists another algorithm S control-
ling the same players in the ideal world as A does in the real
world such that E cannot tell if it is interacting with A or
S. S has black-box access to A.

PERM supports a set of functionalities. An invocation of
a functionality is an event. We assume all events are sched-
uled according to E’s wishes. We use a static model and
assume the number of players, and whether they are honest
or not is ﬁxed before the system starts. All communications
with T are not anonymous, meaning that T knows the iden-
tity of the communicating parties. It is also assumed that
communication between honest parties is not observed by A
and when A receives a message, it does not learn its origin.
PERM supports the following functionalities:

1. SP Setup. The system begins when E speciﬁes the
number of honest and dishonest users and SPs.
• Real World. The SP generates a key pair (P K, SK).
P K is made available to all players in the system.
• Ideal World.
The trusted party T initializes a
database, which stores the registration status and
authentication history of all the users. To capture
the functional requirement of PERM, T keeps track
of the score of every user with respect to each cate-
gory as well as all authentications that the user has
participated in.

2. Registration. E instructs user i to register with the
SP. Note that this procedure is not anonymous in the
view of the SP. For all i, an honest SP would allow user
i to register only once.
• Real World. User i sends a request for registration
to the SP. The user, as well as the SP, outputs indi-
vidually the outcome of this transaction to E. If user
i has obtained a credential in a previous registration
event, then an honest SP would reject the request.
Likewise, an honest user would discard the second
credential it obtains from the SP if it has success-
fully registered in a previous registration event.

• Ideal World. User i sends a registration request
to T , who informs the SP that user i would like
to register and whether user i has obtained a cre-
dential before. The SP returns its decision to T ,
who forwards it back to the user. If the SP accepts
the request and that user i has not registered be-
fore, T stores the registration status of user i in its
database. The user, as well as the SP, individually
output the outcome of this transaction to E.

• Ideal World.

3. Authentication. E instructs user i to authenticate
with the SP and instructs the SP to impose an access
policy P.
• Real World. User i conducts the authentication pro-
tocol with the SP imposing the access policy P. The
user, as well as the SP, output individually the out-
come of this transaction as well as the transaction
identiﬁer t to E.
User i sends a request to T , who
informs the SP some anonymous user requests an
authentication. The SP replies with the list L, the
current transaction identiﬁer t and the policy P.
T forwards the reputation lists, the value t and P
back to user i and whether i satisﬁes the authenti-
cation policy or not. User i then decides if he/she
would continue. If yes, T informs the SP whether
the anonymous user satisﬁes the authentication pol-
icy or not. The SP replies with accept or reject to
T , who forwards the reply to user i. If the authen-
tication is successful, T stores t as one of the user’s
transaction identiﬁers. The user, as well as the SP,
output individually the outcome of this transaction
as well as the transaction identiﬁer t to E.

4. Scoring a transaction. E instructs the SP to give
a score of (s1, . . . , sJ ) to transaction identiﬁer t. If t is
not a valid authentication or has already been put on
reputation list L, an honest SP ignores this request.

5. Updating a score. E instructs the SP to update a
score of (s1, . . . , sJ ) for transaction identiﬁer t. If t is
not a valid transaction identiﬁer on L, then an honest
SP would ignore this request.

6. Score Update. E instructs user i to update his score
on transaction identiﬁer t. If t is not a past identiﬁer
of the user, an honest user ignores the request.
• Real World. User i conducts the score update proto-
col with the SP. The user, as well as the SP, output
individually the outcome of this transaction as well
as the transaction identiﬁer t to E.
• Ideal World. User i sends a request to T , who in-
forms the SP some anonymous user requests a score
update on transaction identiﬁer t. The SP replies
with accept or reject. If the SP replies accept,
T updates the stored reputation of the user. The
user, as well as the SP, output individually the out-
come of this transaction as well as the transaction
identiﬁer t to E.

The ideal-world PERM provides all the desired security
properties and functionalities of PERM. Firstly, all the
transactions, in the view of the SP, are anonymous. T only
informs the SP that some anonymous user would like to au-
thenticate and thus anonymity is guaranteed. Secondly, T
veriﬁes whether the authenticating user satisﬁes the access

939policy and thus the system functions correctly. The real-
world PERM is secure if its behavior is the same as the
ideal-world PERM. Thus, assuming negl(λ) is a negligible
function in security parameter λ, we have the following def-
inition of security for any construction of PERM.

Deﬁnition 1. Security.

(resp.
IdealE,S (λ) ) be the probability that E outputs 1 when
ideal world) with adversary A
run in the real world (resp.
(resp. S having black-box access to A). PERM is secure if
for all PPT algorithms E, A, the following expression holds:

Let RealE,A(λ)

|RealE,A(λ) − IdealE,S (λ)| = negl(λ)

To prove that PERM is secure, we have to construct an
ideal-world adversary S given any real-world adversary A
in such a way that no PPT environment E can distinguish
whether it is interacting with S or A.
The proof is divided into two cases according to the subset
of players controlled by A. In the ﬁrst case, A controls the
SP and a subset of users while, in the second case, only a
subset of users is dishonest. Note, the latter is not a special
case of the former. An adversary controlling the SP covers
the security requirements of anonymity, while an adversary
controlling a subset of users covers the security requirements
of authenticity and non-frameability.
Adding players controlled by A does not necessarily make
the construction of S more diﬃcult. On one hand, the con-
struction of S is trivial if A controls all players in the system,
for S can simply forward all messages exchanged between E
and A. On the other hand, the construction of S is also
In that
trivial when all players in the system are honest.
case, A did not participate in the system and the indistin-
guishability depends only on the correctness of the system.
We sketch the proof strategy of how S can be constructed
in these two cases. Firstly, S maintains a list of ‘current’
credentials issued to A during the lifespan of the system.
At the same time, S acts as an ideal-world adversary to the
trusted party T . S simply forwards any messages between
E and A. Next, we specify how S responds to each possible
event in the two diﬀerent cases.
Case 1: The SP is honest
• SP Setup.

• Representing an Honest SP to A. S generates the

key pair (P K, SK) and gives P K to A.

• Registration.

• Representing a dishonest user i to T / an honest SP
to A. Using the zero-knowledge extractor, S extracts
from A the value x. x will be used to identify the
dishonest user i. S sends the request to T on behalf
of user i. If T replies accept, S issues the credential
to A and also stores that credential.
• Authentication. Note that S does not receive P from
E directly since P is sent to the honest SP in the ideal
world. However, S learns about P from T on behalf of
the dishonest user i in the ideal world.
• Representing a dishonest user i to T / an honest SP
to A. The diﬃculty here is that S does not know
which credential A is using for the authentication.
For instance, while E speciﬁes the user i should per-
form the authentication, it is entirely possible for A
to use the credential from another dishonest user say,
ˆi, to perform the authentication. To locate the ac-

tual user, S extracts and uses the value x during the
authentication to locate the correct user.
The outputs of S and the honest users in the ideal world
are always indistinguishable to A and the honest users in
the real world unless the following happen. We also explain
why such cases happen with negligible probability below.

1. During a Registration event, S fails to extract from
A the value x. This happens with negligible probability
under the soundness property of the protocol SIss of the
BBS+ signature scheme.
2. During a successful Authentication event, S fails to
extract from A the values x. This happens with neg-
ligible probability under the soundness property of the
protocol SSig of the BBS+ signature scheme.
3. There exists a successful Authentication event from
A such that S on behalf of an honest SP outputs ac-
cept, but T indicates the authenticating user does not
satisfy the policy. This represents either that A has
been able to fake one of the proofs in the authentica-
tion or A can forge a signature on a new queue that
has never been signed. All these happen with negligi-
ble probability under the assumption that BBS+ signa-
tures are existentially unforgeable and that the interval
proof is sound.

Note that in the security proof, we require S to run
the zero-knowledge extractor on A for each registration
and authentication event. To keep S in polynomial-time,
we have to require authentication and registration events
are to be executed sequentially (security proofs of BLACR
and PEREA also impose this restriction) or to employ the
stronger universally composable proofs of knowledge.
Case 2: The SP is dishonest
• SP Setup.

• Representing Honest users to A. S receives P K from

A.

• Registration.

• Representing a dishonest user to T / an honest user
i to A. Upon receiving a registration request from T
on behalf of user i, S engages A in the registration
protocol, using the zero-knowledge simulator to sim-
ulate the ZKPoK in SIss. If S fails to obtain a valid
credential from A, then S replies reject to T .

• Authentication.

• Representing a dishonest SP to T / an honest user to
A. Upon receiving an authentication request from T
on behalf of an anonymous user, S engages A in the
If T replies with a bit in-
authentication protocol.
dicating that the underlying user would proceed and
satisﬁes the authentication policy, S uses the zero-
knowledge simulator to simulate the ZKPoK proofs
in the authentication protocol using a random value
q. If A rejects the authentication, S replies reject
to T .
The simulation provided to A is perfect due to the zero-
knowledgeness of the ZKPoK protocols and the perfect hid-
ing property of the commitment scheme. At the same time,
the behavior of S in the ideal world is the same as that of A
in the real world. Thus, the output of S to the environment
E is indistinguishable from that of A.
Based on this dual strategy in the construction of S, our
construction of PERM is secure according to Deﬁnition 1.

940