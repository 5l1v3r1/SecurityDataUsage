Computational Soundness for Dalvik Bytecode

Michael Backes CISPA,

Saarland University &

MPI-SWS

Saarland Informatics Campus

backes@cs.uni-

saarland.de

Robert Künnemann

CISPA, Saarland University
Saarland Informatics Campus

robert.kuennemann
@uni-saarland.de

Esfandiar Mohammadi
mohammadi@inf.ethz.ch

ETH Zurich

ABSTRACT
Automatically analyzing information ﬂow within Android
applications that rely on cryptographic operations with their
computational security guarantees imposes formidable chal-
lenges that existing approaches for understanding an app’s
behavior struggle to meet. These approaches do not distin-
guish cryptographic and non-cryptographic operations, and
hence do not account for cryptographic protections: f (m)
is considered sensitive for a sensitive message m irrespective
of potential secrecy properties oﬀered by a cryptographic
operation f . These approaches consequently provide a safe
approximation of the app’s behavior, but they mistakenly
classify a large fraction of apps as potentially insecure and
consequently yield overly pessimistic results.

In this paper, we show how cryptographic operations can
be faithfully included into existing approaches for automated
app analysis. To this end, we ﬁrst show how cryptographic
operations can be expressed as symbolic abstractions within
the comprehensive Dalvik bytecode language. These ab-
stractions are accessible to automated analysis and can be
conveniently added to existing app analysis tools using mi-
nor changes in their semantics. Second, we show that our
abstractions are faithful by providing the ﬁrst computational
soundness result for Dalvik bytecode, i.e., the absence of at-
tacks against our symbolically abstracted program entails
the absence of any attacks against a suitable cryptographic
program realization. We cast our computational soundness
result in the CoSP framework, which makes the result mod-
ular and composable.

Keywords
Android, Computational Soundness, Secure Information
Flow

1.

INTRODUCTION

Android constitutes an open-source project not only in
terms of source code but also in terms of the whole ecosys-
tem, allowing practically everyone to program new apps and

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16 October 24–28, 2016, Vienna, Austria
c(cid:13) 2016 ACM. ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978418

make them publicly available in Google Play. This open na-
ture of Android has facilitated a rapid pace of innovation,
but it has also led to the creation and widespread deploy-
ment of malicious apps [1, 2]. Such apps often cause privacy
violations that leak sensitive information such as location
or the user’s address book, either as an intended function-
ality or as a result of uninformed programming.
In some
cases such apps can even extract sensitive information from
honest apps.

A comprehensive line of research has, hence, strived to
rigorously analyze how apps are accessing and processing
sensitive information. These approaches typically employ
the concept of information ﬂow control (IFC), i.e., certain
information sources such as GPS position and address book
are declared to be sensitive, and certain information sinks
are declared to be adversarially observable. An IFC-based
analysis then traces the propagation of sensitive information
through the program, i.e., if sensitive data m is input to a
function f , then the result f (m) is considered sensitive as
well. IFC-based analyses thereby determine if information
from sensitive sources can ever reach an observable sink, and
in that case report a privacy violation.

A considerable number of apps rely on cryptographic op-
erations, e.g., for encrypting sensitive information before it is
sent over the Internet. However, analyzing information ﬂow
within Android apps that rely on such cryptographic opera-
tions with their computational security guarantees imposes
formidable challenges that all existing approaches for auto-
mated app analysis struggle to meet, e.g., [3–5]. Roughly,
these approaches do not distinguish cryptographic opera-
tions from other, non-cryptographic functions. Thus, the
standard information-tracing mechanism for arbitrary func-
tions applies: f (m) is considered sensitive for a sensitive
message m irrespective of potential secrecy properties of-
fered by a cryptographic function f , e.g., the encryption
of a sensitive message m is still considered sensitive such
that sending this encryption over the Internet is considered
a privacy breach. These approaches consequently provide a
safe approximation of the app’s behavior, but they mistak-
enly classify a large fraction of apps as potentially insecure
and consequently yield overly pessimistic results. While ap-
proaches based on manual declassiﬁcation have successfully
managed to treat cryptographic operations and their protec-
tive properties more accurately, see the section on related
work for more details, no concept for an accurate crypto-
graphic treatment is known for automated analysis of An-
droid apps.

7171.1 Our Contributions

In this paper, we show how cryptographic operations can
be faithfully included into existing approaches for automated
app analysis on Android, in the presence of malicious apps
or network parties aiming to extract sensitive information
from honest parties. Our paper makes two main tangible
contributions to this ﬁeld: (i) we show how cryptographic
operations can be expressed as symbolic abstractions within
Dalvik bytecode, so that existing automated analysis tools
can adopt them with only minor changes in their seman-
tics; and (ii) we show that our abstractions are faithful by
providing the ﬁrst computational soundness result for the
comprehensive Dalvik bytecode language, i.e., the absence of
attacks against our symbolically abstracted program entails
the absence of any attacks against a suitable cryptographic
program realization.

Symbolic abstractions in Dalvik bytecode. We ﬁrst
show how cryptographic operations can be expressed as sym-
bolic abstractions within Dalvik bytecode. These symbolic
abstractions – often also referred to as perfect cryptogra-
phy or Dolev-Yao models – constitute idealizations of cryp-
tographic operations as free algebras that lend themselves
towards automated analysis. Deriving such abstractions
within the comprehensive Dalvik bytecode language con-
stitutes a challenging task, since existing formalizations of
Dalvik do not oﬀer a distinction between honest and adver-
sarially controlled components, which is crucial for deﬁning
the rules that the symbolic adversary has to adhere to. To
this end, we develop a novel semantic characterization of
Dalvik bytecode that we call split-state semantics that pro-
vides a clear separation between honest program parts and
cryptographic API calls with their corresponding augmented
adversarial symbolic capabilities. Moreover, this split-state
form is key to our proof of computational soundness, see
below. Existing tools for automated app analysis can con-
veniently include our abstractions using minor changes in
their underlying semantics, and thereby reason more accu-
rately about cryptographic operations.

Computational soundness for Dalvik bytecode. We
show that our symbolic abstractions can be securely instan-
tiated using suitable cryptographic primitives, and thereby
provide the ﬁrst computational soundness result for Dalvik
bytecode. More speciﬁcally, our result is grounded in the
Abstract Dalvik Language (ADL) [4], which constitutes the
currently most detailed and comprehensive operational se-
mantics for Dalvik in the literature. To this end, we ﬁrst ex-
tended ADL by probabilistic choices, as it otherwise would
be inappropriate to express cryptographic operations.

We cast our computational soundness result in CoSP, a
framework for establishing computational soundness results
that decouples the process of embedding programming lan-
guages into CoSP from the computational soundness proofs
itself.
In particular, by casting our soundness results in
CoSP, a rich body of computational soundness results for in-
dividual cryptographic primitves [6–11] is immediately valid
for Dalvik bytecode without any additional work.

Establishing computational soundness results for Dalvik
bytecode imposed a series of technical challenges that many
prior computational soundness works did not have to cope
with. We highlight one such challenge. Computational
soundness results struggle when confronted with situations
in which binary operations are applied to outputs of crypto-

graphic operations, e.g., if the parity of a ciphertext should
be checked, since such an operation would be undeﬁned in
the symbolic setting. Prior computational soundness results
simply excluded programs with such illegitimate operations;
this exclusion introduced an additional proof obligation for
the automated analysis tool. While excluding such programs
simpliﬁes the soundness result, integrating these additional
proof obligations in existing automated app analysis tools
constitutes a tedious task, since the tools would need to
check upfront whether any symbolically undeﬁned opera-
tions will be performed on symbolic terms, in any execution
branch. As a consequence, we hence decided to establish a
computational soundness result that over-approximates such
scenarios by sending information of such illegitimate opera-
tions to the adversary and letting the adversary decide the
result of such operations.

Finally, our proof reveals an additional result that we con-
sider of independent interest: we show that any small-step
semantics S in split-state form entails a canonical small-step
semantics S∗ for a symbolic model that is computationally
sound with respect to S. Hence, for establishing a computa-
tionally sound symbolic abstraction for any given program-
ming language, it suﬃces to show that the interaction with
the attacker and the cryptographic API can be expressed by
means of our concept of split-state semantics.

1.2 Summary of Our Techniques

This section summarizes the techniques that we use to
achieve these results. We hope that this summary makes
the paper better accessible, given that it was distilled from
a technical report spanning over roughly 50 pages [12]. Fi-
nally, we discuss how our results can be used to extend in-
formation ﬂow tools.

The CoSP framework. A central idea of our work is to
reduce computational soundness of Dalvik bytecode to com-
putational soundness in the CoSP framework [6,10]. All def-
initions in CoSP are cast relative to a symbolic model that
speciﬁes a set of constructors and destructors that symbol-
ically represent the cryptographic operations and are also
used for characterizing the terms that the attacker can derive
(called symbolic attacker knowledge), and a computational
implementation that speciﬁes cryptographic algorithms for
these constructors and destructors. In CoSP, a protocol is
represented by an inﬁnite tree that describes the protocol as
a labeled transition system. Such a CoSP protocol contains
actions for performing abstract computations (applying con-
structors and destructors to messages) and for communicat-
ing with an adversary. A CoSP protocol is equipped with
two diﬀerent semantics: (i) a symbolic CoSP execution, in
which messages are represented by terms; and (ii) a compu-
tational CoSP execution, in which messages are bitstrings,
and the computational implementation is used instead of
applying constructors and destructors. A computational
implementation is said to be computationally sound for a
class of security properties if any CoSP protocol that satis-
ﬁes these properties in the symbolic execution also satisﬁes
these properties in the computational execution. The advan-
tage of expressing computational soundness results in CoSP
is that the protocol model in CoSP is very general so that
the semantics of other languages can be embedded therein,
thereby transferring the various established soundness re-
sults from CoSP into these languages [6–11].

718ADL
Semantics
s Π2(cid:104)s2(cid:105)
Π1(cid:104)s1(cid:105)≈ADL

Lemma 3

Symbolic
Split-State

Π1(cid:104)s1(cid:105)≈SS

s Π2(cid:104)s2(cid:105)

Lemma 4

Symbolic CoSP

Execution
e(Π1(cid:104)s1(cid:105))≈CoSP

s

e(Π2(cid:104)s2(cid:105))

Theorem 1

Computational

Soundness in CoSP

ADL
Semantics
Π1(cid:104)s1(cid:105)≈ADL
c Π2(cid:104)s2(cid:105)

Lemma 2

Computational
Π1(cid:104)s1(cid:105)≈SS
c Π2(cid:104)s2(cid:105)

Split-State

Lemma 5

Computational CoSP

Execution
e(Π1(cid:104)s1(cid:105))≈CoSP

c

e(Π2(cid:104)s2(cid:105))

Figure 1: Overview of the main technical lemmas, where e is the embedding into CoSP

Symbolic ADL and probabilistic choices. ADL as de-
ﬁned in [4] does not support probabilistic choices, and hence
no generation of cryptographic keys and no executions of
cryptographic functions. We thus extended ADL with a rule
that uniformly samples random values (more concretely: a
register value from the set of numerical values).

We consider attackers that are external to the app, e.g.,
malicious parties or network parties with the goal of ex-
tracting secrets from an honest app. We characterize the
interaction points of the attacker with our extended version
of ADL by a set of so-called malicious functions that com-
municate with the attacker. The attacker itself is modeled
as a probabilistic polynomial-time machine. We introduce
an additional semantic rule that is applied whenever a ma-
licious function is called. The rule invokes the attacker with
the arguments of the function call and stores the response
of the attacker as a return value. For deﬁning the indistin-
guishability of two ADL programs, we additionally require
that the adversary can also send a single bit b as a ﬁnal guess,
similar to other indistinguishability deﬁnitions. This entails
the notions of symbolic equivalence (≈ADL
, in the symbolic
setting) and of computational indistinguishability (≈ADL
, in
the computational setting) of two ADL programs.

s

c

Split-state semantics for symbolic ADL. Establishing
a computational soundness proof for ADL requires a clear
separation between honest program parts and cryptographic
API calls with their corresponding augmented adversarial
symbolic capabilities. To achieve this, we characterize this
partitioning by introducing the concept of a split-state form
of an operational semantics. The split-state form partitions
the original semantics into three components, parallelly ex-
ecuted asynchronously: (i) all steps that belong to comput-
ing cryptographic operations (called the crypto-API seman-
tics), (ii) all steps that belong to computing the malicious
functions (called the attacker semantics), and (iii) all steps
that belong to the rest of the program (called the honest-
program semantics). Moreover, we deﬁne explicit transitions
between each of these components, which gives rise to a pre-
cise message-passing interface for cryptographic operations
and for communicating with the attacker.

Our strategy for showing computational soundness is to
use this split-state form for phrasing the symbolic variant as
a small-step semantics by replacing the crypto-API seman-
tics with the symbolic constructors and destructors from
the symbolic model, and by replacing the attacker seman-
tics by the symbolic characterization of the attacker. With

this symbolic semantics at hand, we deﬁne split-state sym-
bolic equivalence (≈SS
s ) as equivalence of (sets of) traces.
However, as explained before, we ﬁrst have to resolve the
problem that computational soundness results struggle to
deal with situations in which binary operations are applied
to outputs of cryptographic operations. We decided not to
exclude programs that exhibit such behaviors, but to per-
form an over-approximation instead by letting the adversary
determine the outcome of such operations. This makes our
abstractions conveniently accessible for existing tools, but it
also complicates the computational soundness proof since we
have to consider the operations of constructors and destruc-
tors on non-symbolic terms as well. To this end, we encode
them as bitstrings and interpret these bitstrings symboli-
cally again. Fortunately, symbolic bitstring interpretations
can be seamlessly combined with all previous CoSP results.
We ﬁnally deﬁne computational indistinguishability of two
honest program semantics in the split-state computational
execution of ADL (≈SS
c ). As usual, the adversary we con-
sider is a probabilistic polynomial-time machine, and all se-
mantics constitute families of semantics that are indexed by
a security parameter.

It might be of independent interest that our symbolic vari-
ant of the semantics and the computational indistinguisha-
bility can be deﬁned on the split-state form independently
of ADL. We show that ADL can be brought into such a
split-state form, then prove later that symbolic equivalence
in ADL implies symbolic equivalence in the split-state form,
and conclude by proving that computational indistinguisha-
bility in the split-state form implies computational indistin-
guishability in ADL. Hence, for every two ADL programs
Π1, Π2 and initial conﬁgurations s1, s2 (Πi(cid:104)si(cid:105) denoting Πi
with initial conﬁguration si) we have

Π1(cid:104)s1(cid:105)≈ADL
Π1(cid:104)s1(cid:105)≈SS

s Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈SS
c Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈ADL

s Π2(cid:104)s2(cid:105), and
c Π2(cid:104)s2(cid:105).

Computational soundness proof. We ﬁrst construct an
injective embedding e that maps every ADL program to a
CoSP protocol. We stress that within CoSP, the same CoSP
protocol is used for the computational and the symbolic ex-
ecution and that CoSP requires a separation of the attacker
and the cryptographic operations from the rest of the pro-
gram. Our split-state form precisely satisﬁes these require-
ments. The embedding e uses the honest-program semantics
to iteratively construct a CoSP protocol: a transition to the
crypto-API semantics corresponds to a computation node; a

719transition to the attacker semantics corresponds to an out-
put node followed by an input node; and whenever several
possibilities exist, a control node is selected to let the adver-
sary decide which possibility (which node) to take.

We prove this embedding sound in the symbolic model,
and we prove it complete with respect to the range of e in
the computational model, i.e., for every two ADL programs
Π1, Π2 and initial conﬁgurations s1, s2 we have

Π1(cid:104)s1(cid:105)≈SS

s Π2(cid:104)s2(cid:105) =⇒ e(Π1(cid:104)s1(cid:105))≈CoSP

s

e(Π2(cid:104)s2(cid:105))

and

e(Π1(cid:104)s1(cid:105))≈CoSP

c

e(Π2(cid:104)s2(cid:105)) =⇒ Π1(cid:104)s1(cid:105)≈SS

c Π2(cid:104)s2(cid:105),

where ≈CoSP
computational indistinguishability in CoSP.

and ≈CoSP

s

c

denote symbolic equivalence and

Figure 1 ﬁnally shows how all pieces are put together:

Theorem 1 (computational soundness of Dalvik –
simpliﬁed).
Let Π1, Π2 be two ADL programs that use
the same crypto-API and s1, s2 be two initial conﬁgurations.
Then we have

Π1(cid:104)s1(cid:105)≈ADL

s Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈ADL

c Π2(cid:104)s2(cid:105).

Extension of information ﬂow tools. To put our work
in perspective, we elaborate on a possible application of our
result. We envision the extension of information ﬂow (IF)
methods with symbolic abstractions. On a high-level, we en-
vision the following approach for extending IF-tools: when-
ever there is a potential information ﬂow from High to Low
and a cryptographic function is called, we extract a model
of the app and query a symbolic prover to ﬁnd our whether
the attacker learns something about the High values. As in
symbolic ADL only a few semantic rules are changed w.r.t.
ADL, modiﬁcations to existing analyses are likely to be con-
ﬁned, thus simple to integrate.

This approach imposes the challenge of extracting a model
of the app. Our embedding of an ADL program into CoSP
already extracts a symbolic model for the program. How-
ever, shrinking this extracted model to a manageable size
and querying the symbolic prover in a way such that it scales
to complex apps is a task far from simple that merits a paper
on its own.
1.3 Overview

Section 3 reviews the CoSP framework for equivalence
properties that we ground our computational soundness re-
sult on. Section 4 reviews the Abstract Dalvik Language
(ADL). Sections 5 and 6 deﬁne the probabilistic execution
of ADL and introduce our symbolic variant of ADL, includ-
ing the symbolic abstractions of cryptographic operations
and the capabilities of the symbolic adversary. Section 7
deﬁnes the connections between ADL, symbolic ADL, and
CoSP, and based on these connections proves the compu-
tational soundness result. Section 8 discusses related work.
We conclude in Section 9 with a summary of our ﬁndings
and outline directions for future research.

2. NOTATION

Let N be the set of natural numbers and assume that they
begin at 0. For indicating that function f from a set A to
a set B is a partial function, we write f : A (cid:42) B. We use
squared brackets in two diﬀerent ways: (i) m[pp] denotes the

instruction with the number pp for a set of instructions m,
and (ii) r[v (cid:55)→ val ] := (r\(v, r(v)))∪(v, val) is short-hand for
the function mapping v to val and otherwise behaving like r.
Throughout the paper, we use η as the security parameter.
We use ε to denote the empty sequence, empty path, empty
bitstring, or empty action depending on the context. We
write t for a sequence t1, . . . , tn if n is clear from the context.
For any sequence l ∈ E∗, we use · to denote concatenation
l1 · l2, as well as the result of appending (l · e) or prepending
(e · l) an element, as long as the diﬀerence is clear from
context. We ﬁlter a sequence l by a set S, denoted l|S, by
removing each element that is not in S. As we represent the
attacker as a transition system, we sometimes write TA and
sometimes A for the attacker.

3. COSP FRAMEWORK (REVIEW)

The computational soundness proof developed in this pa-
per follows CoSP [6,10], a general framework for conducting
computational soundness proofs of symbolic cryptography
and for embedding these proofs into programming languages
with their given semantics. This section reviews the CoSP
framework.

Symbolic Model & Execution.
In CoSP, symbolic ab-
stractions of protocols and the attacker are formulated in a
symbolic model M = (C, N, T, D): a set of free functions
C, a countably inﬁnite set N of nonces, a set T of terms,
and a set D of partial mappings from terms to terms (called
destructors). To unify notation, we introduce eval F (t):
if
F is a constructor, eval F (t) ··= F (t) if F (t) ∈ T and
eval F (t) ··= ⊥ otherwise.
If F is a nonce, eval F () ··= F .
If F is a destructor, eval F (t) ··= F (t) if F (t) (cid:54)= ⊥ and
eval F (t) ··= ⊥ otherwise.
Protocols.
In CoSP, protocols are represented as inﬁnite
trees with the following nodes: computation nodes are used
for drawing fresh nonces and for applying constructors and
destructors; input and output nodes are used for send and
receive operations; control nodes are used for allowing the
attacker to schedule the protocol. A computation node is
annotated with its arguments and has two outgoing edges:
a yes-edge, used for the application of constructors, for draw-
ing a nonce, and for the successful application of a destruc-
tor, and a no-edge, used if an application of a constructor or
destructor F on a term t fails, i.e., if eval F (t) = ⊥. Nodes
have explicit references to other nodes whose terms they use.

Symbolic operations. To model the capabilities of the
symbolic attacker, we explicitly list the tests and operations
that the attacker can perform on protocol messages using
so-called symbolic operations. A symbolic operation is (sim-
ilar to a CoSP tree) a ﬁnite tree whose nodes are labeled
with constructors, destructors, or nonces from the symbolic
model M, or formal parameters xi denoting pointers to the
ith protocol message. There is a natural evaluation func-
tion for a symbolic operation O and a list t of terms that
the attacker received so far (the view ).

Symbolic execution. A symbolic execution is a path
through a protocol tree deﬁned as deﬁned below. It induces
a symbolic view, which contains the communication with the
attacker. We, moreover, deﬁne an attacker strategy as the
sequence of symbolic operations that the attacker performs
in the symbolic execution.

720(V, ν, f ) (cid:32)CoSPs (V, yes(ν), f [ν (cid:55)→ m])
(V, ν, f ) (cid:32)CoSPs (V, no(ν), f )
(V, ν, f ) (cid:32)CoSPs (V · (in, (t, O)), succ(ν), f [ν (cid:55)→ t])
(V, ν, f ) (cid:32)CoSPs (V · (out, ˜t1), succ(ν), f )
(V, ν, f ) (cid:32)CoSPs (V · (control, (l, l
(cid:48)
)), ν

, f )

(cid:48)

ν computation n. with F ∈ C ∪ D ∪ N, m ··= eval F (˜t) (cid:54)= ⊥
ν computation node with F ∈ C ∪ D ∪ N, eval F (˜t) = ⊥
ν input node, t ∈ T, O ∈ SO(M), eval O(Out(V )) = t
ν output node

ν control n., out-metadata l, successor ν

has in-metadata l

(cid:48)

(cid:48)

Figure 2: Rules for deﬁning the smallest relation for the symbolic execution

Definition 1

(Symbolic executions). Let a sym-
bolic model M = (C, N, T, D) and a CoSP protocol Π for
M be given. Let Views = (Event in ∪ Event out ∪ Event ctl )∗,
with Event in := {in} × T × SO(M), Event out := {out} ×
T∗, Event ctl := {control} × {0, 1}∗ × {0, 1}∗. We deﬁne

(cid:32)CoSPs⊆Views
Views

∗ × Nodes × (Nodes → T) →
∗ × Nodes × (Nodes → T)

as the smallest relation s.t. the rules from Figure 2 hold,
where ˜t ··= f (˜ν1), . . . , f (˜ν|˜ν|), for the nodes ˜ν1, . . . , ˜ν|˜ν| ref-
erenced by ν (for computation nodes). The set of symbolic
executions of Π is deﬁned as

SExec(Π) :={((V0, ν0, f0), . . . , (Vn, νn, fn)) | n ∈ N

∧ ∀i.(Vi, νi, fi) (cid:32)CoSPs (Vi+1, νi+1, fi+1)},

where (V0, ν0, f0) = (, root(Π),∅). Vi is called a symbolic
view for step i. The set of symbolic views of Π is deﬁned as
SViews(Π) := {Vn|(V0, ν0, f0),··· , (Vn, νn, fn) ∈ SExec(Π)}
Given a view V , Out(V ) denotes the list of terms t contained
in (out, t) ∈ V . Out-Meta(V ) denotes the list of terms l
contained in elements of the form (control, (l, l(cid:48))) in the view
V . In(V ), called the attacker strategy, denotes the list of
terms that contains only entries of V of the form (in, (t, O))
or (control, (l, l(cid:48))), where for (in, (t, O)) the entry (in, O) is
stored and for (control, (l, l(cid:48))) the entry (control, l(cid:48)) is stored.
[In(V )]SViews(Π) denotes the equivalence class of all views
U ∈ SViews(Π) with In(U ) = In(V ).

Symbolic knowledge. The symbolic knowledge of the at-
tacker comprises the results of all symbolic tests the attacker
can perform on the messages output by the protocol. Given
a view V with |VOut| = n, we deﬁne the symbolic knowl-
edge KV as a function from symbolic operations on M to
{(cid:62),⊥}, where (cid:62) comprises all results of eval O(VOut ) that
are diﬀerent from ⊥.
Symbolic Equivalence. Two views are equivalent, de-
noted as V ∼ V (cid:48), if they (i) have the same structure (i.e.,
the same order of out, in, control entries), (ii) have the same
out-metadata (i.e., VOut-Meta = V (cid:48)
Out-Meta ), and (iii) lead to
the same knowledge (i.e., KV = KV (cid:48) ). Finally, two CoSP
protocols are symbolically equivalent (≈CoSP
) if its two vari-
ants lead to equivalent views when run with the same at-
tacker.
Computational execution.
In the computational set-
ting, symbolic constructors and destructors are realized
with cryptographic algorithms. A computational implemen-
tation is a family Impl = (Ax)x∈C∪D∪NP of determinis-
tic polynomial-time algorithms ImplF for each construc-
tor or destructor F ∈ C ∪ D as well as a probabilistic

s

polynomial-time (ppt) algorithm AN for drawing protocol
nonces N ∈ N.
Computational execution. The computational execution
of a protocol is a randomized interactive machine, called
the computational challenger, that traverses the protocol
tree and interacts with a ppt attacker A: at a computa-
tion node the corresponding algorithm is run and depending
on whether the algorithm succeeds or outputs ⊥, either the
yes-branch or the no-branch is taken; at an output node,
the message is sent to the attacker, and at an input node a
message is received by the attacker; at a control node the at-
tacker sends a command that speciﬁes which branch to take.
The transcript of the execution contains the computational
counterparts of a symbolic view.
Computational indistinguishability. We ﬁnally deﬁne
computational soundness by requiring that symbolic equiv-
alence implies computational indistinguishability.

Definition 2

(Computational Soundness). An im-
plementation Impl of a given symbolic model M is compu-
tationally sound for M and a class P of eﬃcient pairs of
protocols if for every Π ∈ P, we have that Π is computation-
ally indistinguishable whenever Π is symbolically equivalent.

4. DALVIK BYTECODE (REVIEW)

The Abstract Dalvik Language (ADL) [4] constitutes the
currently most detailed and comprehensive operational se-
mantics for Dalvik in the literature, even though it does not
encompass concurrency and exceptions (as e.g. in [3]). We
refer to Section 8 for further discussion on diﬀerent Dalvik
semantics. Due to lack of space, we only provide a very
compact review of ADL and refer to [4] for more details.
Syntax. ADL methods are non-empty sequences of in-
structions and together constitute a set M. A method
name mid ∈ MID and a class name c ∈ CID iden-
tify the method to be called by means of lookup tables,
i.e., partial functions mapping (c, mid ) to normal methods
(lookup-direct Π), inherited methods (lookup-super ), or vir-
tual methods(lookup-virtual Π). In contrast, static methods
(lookup-staticΠ) are identiﬁed by method name alone. Sim-
ilarly, ﬁelds (F) are referenced via lookup-ﬁeld Π.
Semantics. The semantical domains of ADL programs are
deﬁned by a set of locations L, numerical values N and a
special value void, which together form the set of values
V. Objects carry their class name and a partial function
from ﬁelds to values forming the set O; similarly, arrays
carry their length and a partial function from indices in N
to values. Given a set of registers X (including two reserved
registers from a set Xres, see below), the register state is
deﬁned as R = (X ∪ Xres) → V. The space of heaps is

721rConst : s −→ s{pp + 1, r[va (cid:55)→ n]}
rMove : s −→ s{pp + 1, r[va (cid:55)→ r(vb)]}
rBinop : s −→ s{pp + 1, r[va (cid:55)→ u]}
IfTestT : s −→ s{pp + n}
IfFestF : s −→ s{pp + 1}
rMoveR : s −→ s{pp + 1, r[va (cid:55)→ r(res lo)]}
(cid:48) · m · ml, 0 · pp · ppl,

rISt : s −→ s

(cid:26) m
(cid:26) m

rIDR : s −→ s

(cid:10)m · ml, h, pp · pp

defReg([r(va), . . . , r(ve)]) · r · rl

(cid:48) · m · ml, 0 · pp · ppl,

(cid:48) · rl, as(cid:11) −→

(cid:48) · ppl, r · r
(cid:48)(cid:48)

(cid:48)

rReturn :
rReturnF : (cid:104)(m), h, (pp), (r), as(cid:105) −→ (cid:104)r(va), h, as(cid:105)

+ 1) · ppl, r

(cid:104)ml, h, (pp

] · rl, as(cid:105)

[r

(cid:48)

defReg([r(vk), . . . , r(vk+n−1)]) · r · rl

(cid:48)

m

for m[pp] = const va, n
for m[pp] = move va, vb
for m[pp] = binop va, vb, vc, bop and u = r(vb) bop r(vc)

(cid:27)

for m[pp] = if-test va, vb, n, rop and r(va) rop r(vb)
for m[pp] = if-test va, vb, n, rop and ¬(r(va) rop r(vb))
for m[pp] = move-result va
for m[pp] = invoke-static va, . . . , ve, mid

(cid:27) for m[pp] = invoke-direct-range vk, n, mid

= lookup-staticΠ(mid)

m

(cid:48)

= lookup-direct Π(mid , h(r(vk)).class)

for m[pp] = return va and ml

(cid:48) (cid:54)= ()

(cid:48)(cid:48)

r

= res lo (cid:55)→ lo(r(va)), res up (cid:55)→ up(r(va))

for m[pp] = return va

Figure 3: Selection of inference rules that deﬁne −→ with uop ∈ UNOP, bop ∈ BINOP, rop ∈ RELOP, with
some n ∈ N counter for method calls, some ADL program Π, and some method m. We write va, . . . , ve for
va, vb, vc, vd, ve, and if r = defReg(u1, . . . , ul), then r(vi) = ui for i ∈ {0, . . . , l} and void otherwise.

H = (L (cid:42) (O ∪ AR)) where AR = N × (N (cid:42) V). A con-
ﬁguration describes the state of the program without the
attacker: C(cid:48) := M × H × N × R × Q. The full intermediate
states additionally contains the attacker states Q (see Sec-
tion 5): C = M × H × N × R × Q. Final states are deﬁned
as: (Cﬁnal = V × H × Q ∪ ADVR), where ADVR denotes
the set of malicious functions (see Section 5).

Throughout the paper, we explicitly distinguish between
conﬁgurations and states, in particular initial states and ini-
tial conﬁgurations.

The execution relation →. The operational semantics
is deﬁned in terms of an execution relation → (for an ADL
program Π, which we assume ﬁxed in this section). For
the sake of illustration, Figure 3 contains a representative
selection of the rules deﬁning →. For the full set of rules,
we refer to the work of Lortz et al. [4].

We use the following notation to shorten presentation
and highlight the modiﬁcations applied to the state. For a
state s = (cid:104)m · ml, h, pp · ppl, r · rl, as(cid:105) ∈ C, we use s{pp + 1}
to denote
Similarly
s{r[v (cid:55)→ a]} denotes
(cid:104)m · ml, h, pp · ppl, r[v (cid:55)→ a] · rl, as(cid:105),
s{h[l (cid:55)→ a]}
(cid:104)m · ml, h[l (cid:55)→ a], pp · ppl, r · rl, as(cid:105),
denotes
s{m(cid:48)} denotes (cid:104)m(cid:48) · ml, h, pp · ppl, r · rl, as(cid:105), and s{as(cid:48)}
denotes (cid:104)m · ml, h, pp · ppl, r · rl, as(cid:48)(cid:105).

(cid:104)m · ml, h, pp + 1 · ppl, r · rl, as(cid:105).

The relation deﬁnes constant assignment (rConst), copy-
ing of register values (rMove), binary operations (rBinop),
conditional branching (rIfTestTrue and rIfTestFalse).
Moreover, we depict rules for static method evaluation
(rISt) and evaluation of ﬁnal methods (rIStR). Return val-
ues are stored in distinct result register res lo, res up ∈ Xres
(see rReturn).

We slightly diverge from the characterization of method
calls in [4] to capture the total number of computation steps
in a run: each transition corresponds to one computation
step, and each rule in Figure 3 is annotated accordingly (−→
instead of →Π).

5. SECURITY FRAMEWORK

We extend ADL with prbabilistic choices and with a prob-
abilistic polynomial-time attacker that is invoked whenever
speciﬁc functions are invoked. The modiﬁcations to the
ADL-semantics are depicted in Figure 4.

Execution and communication model. ADL as de-
ﬁned in [4] does not support probabilistic choice and hence
no generation of cryptographic keys and no executions of
cryptographic functions. We thus ﬁrst extended ADL with
a rule that uniformly samples a register value from the set
of numerical values N (see the Prob-rule in Figure 4).

To simplify presentation, we then interpret ADL’s seman-
tics as a probabilistic transition system in the following
manner. A probabilistic transition system T = (S, s0, A, δ),
deﬁnes probabilistic and non-deterministic transitions that
i.e.,
are annotated with a number of computation steps,
δ : S → D(S × N) (cid:93) P(A × S × N). We write s
[p]−→n s(cid:48)
if δ(s) = µ and µ(s(cid:48), n) = p, and s a−→n s(cid:48) if (a, s(cid:48), n) ∈ δ(s).
If p = 1 or n = 1, we omit [p] or n, respectively.
If
S is ﬁnite or countably inﬁnite, and T is fully probabilis-
tic, i.e., there is no non-deterministic transition with more
than one follow-up state, we introduce the following ran-
dom variables: Pr[s α−→n s(cid:48)] = p iﬀ. s
[p]−→n s(cid:48) ∧ α =  or
s α−→n s(cid:48) ∧ p = 1. Given any initial state s0 ∈ S0, we de-
ﬁne the outcome probability of an execution Pr[Exec(T ) =
αi+1−−−→ si+1] and
s0
the probability of a trace (α1, . . . , αn) as Pr[Traces(T ) =

α1−−→n1 ··· αn−−→nn sn] = (cid:81)n−1
(α1, . . . , αn)] =(cid:80) Pr[Exec(T ) = s0

α1−−→n1 ··· αn−−→nn sn].

i=0 Pr[si

Threat model. In this work, we consider adversaries that
are network parties or malicious apps that try to retrieve
sensitive information from an honest app. We model the
adversary as an external entity that cannot run any code
within the program and that does not have access to the
program’s heap, but can read input to and control output

722from a given set of malicious functions ADVR. The attacker
is a probabilistic polynomial-time algorithm A.
We represent the attacker A in ADL as an unlabelled
probabilistic transition system. We assume that each state
is a triple, where the ﬁrst element solely contains the in-
puts and the last element contains the outputs. We use the
relation →A to denote transitions in the attacker’s transi-
tion system in Figure 4. Many computation models can be
expressed this way, including, but not restricted to, Turing
machines.
Whenever a malicious function is invoked, A is executed
with its previous state as and the arguments arg of the ma-
licious function. The output of A is the new state as(cid:48) and
a response-message res in V, or in the set ADVR, which is
distinct from V. If res ∈ V, it is interpreted as the function’s
output values, otherwise, i.e., if the response message is in
ADVR, the execution terminates with the adversarial out-
put res ∈ ADVR. Figure 4 precisely deﬁnes this behavior
in the rule rInvoke-Adv.

We can cast the ADL semantics in terms of a probabilis-
tic transition system ADLΠ,A,(cid:104)ml,h,ppl,rl(cid:105) that is parametric
in the program executed, the attacker (see below) and the
initial conﬁguration. We obtain the following deﬁnition for
executing ADL in the presence of an adversary.

Definition 3

(ADL Execution with Adv). Given
an ADL program Π, an adversary A, and an initial conﬁg-
uration (cid:104)ml, h, ppl, rl(cid:105), the probability that the interaction
between Π on (cid:104)ml, h, ppl, rl(cid:105) and A terminates within n
steps and results in x is deﬁned as
Pr[(cid:104)Π(cid:104)ml, h, ppl, rl(cid:105)(cid:107)A(cid:105) ↓n x] ··=

Pr[ADLΠ,A,(cid:104)ml,h,ppl,rl(cid:105) ↓n (cid:104)x(cid:105)].

where we write (given A’s initial state as) Π(cid:104)ml, h, ppl, rl(cid:105)
for the program Π with initial state (cid:104)ml, h, ppl, rl, as(cid:105).

Calls to crypto APIs. Libraries that oﬀer cryptographic
operations leave the generation of randomness either im-
plicit or explicit. Our result encompasses both settings.
Moreover, most classes for cryptographic operations, such
as the commonly used javax.crypto.Cipher, are used with
a method call that lacks some arguments, e.g., the en-
cryption key when using javax.crypto.Cipher.doFinal()
to account for situations in which the missing argument
has been stored earlier in a member variable, e.g., using
javax.crypto.Cipher.init(). We address this by consid-
ering the class instance (from the heap) as an additional
argument to the method call that has been marked, e.g.,
javax.crypto.Cipher.doFinal(). Since the class instance
contains more information than the arguments of the cryp-
tographic operation of the computationally sound symbolic
model, all relevant information such as the encryption key,
plaintext, and randomness has to be extracted from the class
instance. The derived functions that we explicitly added in
our formalization take care of this extraction.

Definition 4

(Library specification). A

library
speciﬁcation is an eﬃciently computable partial function
libSpec : MID × O ∪ UNOP ∪ BINOP ∪ RELOP (cid:42) SO
deﬁned at least on UNOP ∪ BINOP ∪ RELOP.

In order to be able to use an asymptotic security deﬁni-
tion, we deﬁne uniform families of ADL programs as pro-
grams generated from a security parameter.

Definition 5

(Uniform families of programs).

Let Π be an algorithm that, given a security parameter η,
outputs an ADL program. We denote the output of this
program Πη and call the set of outputs of this program a
uniform family of ADL programs.

Next, we deﬁne initial conﬁgurations for families (indexed
by a security parameter) of transition systems as states that
are valid initial conﬁguration for all security parameters.

Definition 6

(Initial configuration). Given

a
family (Tη)η of transition systems. We say that a state s
is an initial conﬁguration for (Tη)η if it is a valid initial
conﬁguration for all Tη in this family. Analogously, we
say that a conﬁguration s is an initial conﬁguration for a
uniform family of ADL programs if for all η this s is a valid
initial conﬁguration for Πη.

Indistinguishability of two ADL programs. Similar to
CoSP, we deﬁne indistinguishability of ADL programs using
tic-indistinguishability [13].

A

c

call

(Indistinguishability (ADL)).

Definition 7
two
uniform families
1}η∈N and Π2 = {Πη

We
of ADL programs
2}η∈N with initial conﬁg-
Π1 = {Πη
uration s1 = (cid:104)ml1, h1, ppl1, rl1(cid:105) and s2 = (cid:104)ml2, h2, ppl2, rl2(cid:105)
computationally indistinguishable for a (not necessarily
uniform) family of attackers A = {Aη}η∈N A (written
Π2(cid:104)s2(cid:105)) if for all polynomials p, there is a
Π1(cid:104)s1(cid:105)≈ADL
negligible function µ such that for all a, b ∈ {0, 1} with
a (cid:54)= b,
Pr[(cid:104)Πη
2(cid:104)s2(cid:105)(cid:107)Aη(cid:105) ↓p(η) b] ≤ 1+µ(η).
We call Π1(cid:104)s1(cid:105) and Π2(cid:104)s2(cid:105) computationally indistinguish-
Π2(cid:104)s2(cid:105)
able (Π1(cid:104)s1(cid:105)≈ADL
for all machines A.

c Π2(cid:104)s2(cid:105)) if we have Π1(cid:104)s1(cid:105)≈ADL

1(cid:104)s1(cid:105)(cid:107)Aη(cid:105) ↓p(η) a]+Pr[(cid:104)Πη

A

c

This notion indistinguishability gives rise to notion of non-

interference, when Π1 = Π2.

6. SYMBOLIC DALVIK BYTECODE

In this section, we deﬁne a symbolic variant of ADL, which
uses symbolic terms instead of cryptographic values. We
sometimes abbreviate this symbolic variant as ADLs. We
will show in the next section that it suﬃces to analyze a
(symbolic) ADLs program in order to prove the correspond-
ing (cryptographic) ADL program secure, provided that the
cryptographic operations used in that program are computa-
tionally sound, i.e., provided that they have a computation-
ally sound symbolic model in CoSP. ADLs’ semantics pre-
cisely corresponds to the semantics of ADL, except for the
treatment of cryptographic operations. As a consequence,
existing automated analysis tools can be conveniently ex-
tended to ADLs and, thus, accurately cope with crypto-
graphic operations, since this extension only requires seman-
tic adaptations precisely for those cases where cryptographic
behavior needs to be captured. ADLs is parametric in the
symbolic model of the considered cryptographic operations
and, hence, beneﬁts from the rich set of cryptographic primi-
tives that are already supported by computational soundness
results in CoSP, such as encryption and signatures [6–8, 10]
or zero-knowledge proofs [9, 11].

723Prob

m[pp] = rand va

n(cid:48) ∈ N
(cid:104) 1|N|
−−−−→ s{r[va (cid:55)→ n(cid:48)]}

(cid:105)

s

AdvInv

AdvRet

AdvFin

m[pp] = invoke-static va, . . . , ve, mid

Pr[Exec(T ) = (cid:104)(mid , r(va), . . . , r(ve)), as, (cid:105) →A q1 →A ··· →A qn−1 →A (cid:104)i, as(cid:48), res(cid:105)] = p

mid ∈ Mal static

res ∈ V

[p]−→n+2 s{pp + 1, r[res lo (cid:55)→ lo(res), res up (cid:55)→ up(res)], as(cid:48)}

s

m[pp] = invoke-static va, . . . , ve, mid

Pr[Exec(T ) = (cid:104)(mid , r(va), . . . , r(ve)), as, (cid:105) →A q1 →A ··· →A qn−1 →A (cid:104)i, as(cid:48), res(cid:105)] = p

mid ∈ Mal static

res ∈ ADVR

[p]−→n+1 (cid:104)res(cid:105)

s

Pr[Exec(T ) = (cid:104)(), as, (cid:105) →A q1 →A ··· →A qn−1 →A (cid:104)i, as(cid:48), res(cid:105)] = p

res ∈ ADVR

(cid:104)u, h, as(cid:105) [p]−→n+2 (cid:104)res(cid:105)

Figure 4: Inference rules extending ADL with probabilistic semantics and adversarial interaction.

6.1 Embeddable symbolic CoSP models

We ﬁrst deﬁne suﬃcient conditions under which a given
CoSP model can be embedded into ADL. To this end, we
require that, e.g., values in V = N ∪L∪{void} can be embed-
ded into CoSP, i.e., there needs to be an injective function
from V into T. Formally, we assume that there exists an
injective function ι such that all v ∈ V can be distinguished
i.e., ∀v, v(cid:48) ∈ V∃D1, . . . , Dm ∈ D,
using deconstructors,
ι(v(cid:48)) = v if v(cid:48) = v and ⊥ otherwise. As in previous embed-
dings [6,14], we require that the symbolic model includes an
equality destructor equals and a pairing constructor pair .

We deﬁne (cid:98)v = ι(v) if n ∈ V and the identity if n ∈ T, and
lift this notion to sets: ∀V ⊆ V.(cid:98)V = {(cid:98)v | v ∈ v}.

6.2 Semantics of symbolic ADL

The semantical domains of the symbolic variant of ADL
coincide with the semantical domains of ADL except for the
set of values V and the set of (intermediate and ﬁnal) states.
The set of values is extended to hold terms in addition to
ADL values: V = N ∪ L ∪ {void} ∪ T.

We add to each state in the inference rules the list of terms
output so far, called the symbolic view. This symbolic view
corresponds to the symbolic view in the symbolic execution
of a CoSP protocol (Deﬁnition 1), and is used to track the
information the adversary can use to deduce messages.

Transition between states are now annotated with the in-
formation sent to or received from the adversary. As ADL is
sequential, every output to the adversary is followed by the
adversary’s input. Calls to malicious functions reveal regis-
ter values to the adversary, which can be terms, locations,
or numerical values. Terms are added to the adversarial
knowledge as they are; locations and values are translated
by means of the embedding. Calls to the crypto-API imme-
diately yield a term by applying a constructor or destructor
to the term arguments, or their symbolic representation. As
elaborated in the introduction, applying binary operations
(e.g., XOR) to symbolic terms usually invalidates computa-
tional soundness results. We over-approximate this by treat-
ing symbolic terms as a blackbox and let the outcome of
any operation involving a symbolic term be decided by the
adversary. As a side eﬀect, we let the adversary learn the
operands. As binary operations and tests on bits are only de-

ﬁned on inputs in N , rules involving these remain unaltered
and are complemented by the rules in Figure 5. For space
reasons, the ﬁgure does not contain the rules for binary op-
erations (Binop), but they are deﬁned analogously to unary
operations. For brevity, we let V (cid:48) denote the attacker’s view,
which is part of the successor state, and write V (cid:48) (cid:96) m, if
the adversary can deduce a term m from a view V , i.e.,
there is a symbolic operation O such that O(Out(V )) = m.
Observe that for IfTest-m, the adversary can decide the
outcome without learning the operands. This highlights the
non-determinism inherent to the symbolic semantics. Let
ADLsΠ,(cid:104)ml,h,ppl,rl(cid:105) denote the probabilistic transition sys-
tem describing these modiﬁed semantical domains and tran-
sitions.

With the symbolic semantics in place, we can ﬁnally deﬁne
the notion of symbolic equivalence between two programs.
We ﬁrst specify what constitutes a symbolic view, as our def-
inition of traces applies only to fully probabilistic transition
systems.

Definition 8

(Symbolic view). Given a probabilistic
(but not necessarily fully probabilistic) transition system T
with initial state s0, the set of symbolic views of T is deﬁned:
α1−−→n1 ··· αm−−→nm sm

(α1, . . . , αm)|Views

SViews(T ) =

(cid:111)

(cid:110)

(cid:12)(cid:12)(cid:12)s0

We use the notion of symbolic equivalence introduced in

Section 3.

Definition 9

(Symbolic equivalence). Let M be a
symbolic model. Two probabilistic transition systems T1 and
s T2) if SViews(T1) ∼
T2 are symbolically equivalent (T1≈SS
SViews(T2) w.r.t. M. Two uniform families of ADL pro-
grams Π1 = {Πη
2}η∈N and initial conﬁgu-
rations s1 = (cid:104)ml1, h1, ppl1, rl1(cid:105) and s2 = (cid:104)ml2, h2, ppl2, rl2(cid:105)
are symbolically equivalent (Π1(cid:104)s1(cid:105)≈ADL
for
each η, the probabilistic transition systems T1 = ADLsΠ1,s1
and T2 = ADLsΠ2,s2 are symbolically equivalent.

1}η∈N and Π2 = {Πη

s Π2(cid:104)s2(cid:105)) iﬀ,

7. COMPUTATIONAL SOUNDNESS

Establishing a computational soundness proof for ADL
requires a clear separation between honest program parts

724rIDR-s: s

s(cid:8)h[h

(LC,mid,r(vk),h|r(vk )),(LR,(ulo ,uup ,h(cid:48)))
−−−−−−−−−−−−−−−−−−−−−−−−→Sym

], pp + 1 · ppl, r[res lo (cid:55)→ ulo, res up (cid:55)→ uup] · rl(cid:9)

(cid:48)

ISt-m: s

(out,uop,r(vb)),(in,(u,u))

(out,mid,r(va),...,r(ve)),(in,(ulo ,uup ))

−−−−−−−−−−−−−−−−−−−−−−−→Sym
s{pp + 1 · ppl, r[res lo (cid:55)→ ulo, res up (cid:55)→ uhi ] · rl}
−−−−−−−−−−−−−−−→Sym
s{pp + 1 · ppl, r[va (cid:55)→ u] · rl}
−−−−−−−−−−−−−−−→Sym
s{pp + 1 · ppl, r[va (cid:55)→ u] · rl}

−−−−−−−−−−−−−→Sym s(cid:8)(pp + n

) · ppl, r · rl(cid:9)

(LC,uop,r(vb)),(LR,(u,u))

(out,rop,r(va),r(vb))

(cid:48)

Unop-m: s

Unop-l: s

IfTest-m: s

for m[pp] = invoke-direct-range vk, n, mid
∧ O = libSpec(mid, h(r(vk)))
∧ pair (t, h

) = eval O(r(vk),(cid:98)h)

(cid:48)

for m[pp] = invoke-static va, . . . , ve, mid
(cid:48) (cid:96) uup
∧ mid ∈ Mal static ∧ V

(cid:48) (cid:96) ulo ∧ V

for m[pp] = unop va, vb, uop
∧ r(vb) (cid:54)∈ TV ∧ V

(cid:48) (cid:96) u

for m[pp] = unop va, vb, uop
∧ r(vb) ∈ TV ∧ u = duop(r(vb))

for m[pp] = if-test va, vb, n, rop
∧ ¬(r(va) ∈ TV ∧ r(vb) ∈ TV ) ∧ n

(cid:48) ∈ {n, 1}

Figure 5: Modiﬁed inference rules of the symbolic execution relation → -Sym, where s = (cid:104)ml, h, pp · ppl, r · rl(cid:105).

and cryptographic API calls with their corresponding aug-
mented adversarial symbolic capabilities. To achieve this,
we characterize this partitioning by introducing the concept
of a split-state form of an operational semantics, and we
subsequently show that it can be naturally used to repre-
sent ADL. This section, presents the essence of our proof.
For the full proofs and detailed deﬁnition, we refer to the
technical report [12].
7.1 Split-state semantics

The split-state form partitions the original semantics into
three components, parallely executed asynchronously: (i)
all steps that belong to computing cryptographic operations
(called the crypto-API semantics), (ii) all steps that belong
to computing the malicious functions (called the attacker
semantics), and (iii) all steps that belong to the rest of the
program (called the honest-program semantics). The over-
all operational semantics is a composition of each of these
sub-semantics, i.e., the state space is the Cartesian product
of the sub-states with additional information on which en-
tity is currently running, deﬁned in terms of asynchronous
parallel composition. We refer to the technical report for
details [12].
In a split-state form, all three entities can
synchronize through the following sets of labels:
libCall,
libResp, out, and in. The ﬁrst two model message passing
between the honest program and the crypto-API; the latter
two model message passing between the honest program and
the attacker. There is no synchronization step between at-
tacker and the crypto-API, as the attacker can only stop the
execution with a transition of the form (final, m) for some
message m.
An operational semantics is a split-state semantics, if it
can be expressed as a transition system (S, S0,→) by split-
state composition of three transition systems.

The beneﬁt of this notion is that it makes the communi-
cation explicit that occurs between the actual program and
the adversary. This communication is often ﬁxed but ar-
bitrary, i.e., in the case of black-box usage. Moreover, it
separates the actual program from the cryptographic API
calls, which is crucial for computational soundness proofs.

Finally, the details of the crypto-API are irrelevant for pro-
gram analyses, provided that the cryptographic operations
are implemented securely.

A split-state semantics is not necessarily a probabilistic
transition systems, as the transition systems it is composed
from might be non-deterministic. However, we deﬁne the
probability of a certain outcome only for probabilistic split-
state semantics, as in most applications for security, non-
determinism in the honest program semantics stems from
the modelling of concurrency and is usually resolved by spec-
ifying a scheduler. This non-determinism is typically con-
servatively resolved by assuming that the adversary controls
the scheduling.
We write Pr[T (s0) ↓n x] for the probability that the in-
teraction between honest program, attacker and crypto-API
with initial state s0 ∈ S0 results in x and terminates within
n steps. Split-state indistinguishability is then deﬁned as
follows.

Definition 10

(Split-state indistinguishability).
Let TH,1, TH,2, TA, and TL be families of transition systems
indexed by a security parameter in N. We call TH,1 and
TH,2 computationally indistinguishable for TL and TA and
initial states s0
H,2, sL of TH,1, TH,2, TL (respectively)
in the sense of Deﬁnition 6 if for all polynomials p, there
is a negligible function µ such that for all a, b ∈ {0, 1} with
a (cid:54)= b,

H,1, s0

Pr[T η
+ Pr[T η

1 (((cid:62), s0

H,1), (⊥, (0, z)), (⊥, sL)) ↓p(η) a]

2 (((cid:62), s0

H,2), (⊥, (0, z)), (⊥, sL)) ↓p(η) b] ≤ 1 + µ(η),

parameter

where T η
1
and T η
2
for
TH,1(s0
call
able
TH,1(s0
initial states s0

security
H,1)≈TL(sL),TA
TH,1

TH,2
(written
as
H,1)≈TL(sL),TA
H,1, s0

and

is the split-state composition of T η
is the split-state composition of T η

H,1, T η
H,2, T η

η.
TH,2(s0
H,2).
computationally
H,1)≈TL(sL)

L, TA,
L, TA
In short, we write
we
indistinguish-
if
H,2) for all TA ∈ ADV(cid:48) and for
H,2, sL for TH,1, TH,2, TL (respectively).

Additionally,

TH,2(s0

TH,1(s0

TH,2(s0

H,2))

c

c

c

7257.2 Split-state representation of ADL

We now deﬁne the condition necessary for splitting an
ADL program into an honest program semantic and a
crypto-API semantics. For a formal deﬁnition, we refer
to the technical report [12]. An ADL program Π is pre-
compliant with a crypto-API speciﬁcation if: (i) the crypto-
API only reads the slice of the heap belonging to its object,
i.e., only objects reachable from locations stored in its own
member variables, (ii) the crypto-API never invokes the ad-
versary, and (iii) only the crypto-API and the adversary
make use of the rand-instruction.

Definition 11

(ADL split-state representation).
Given a uniform family of ADL programs Π = {Πη}η∈N,
every member thereof pre-compliant with a crypto-API
speciﬁcation libSpec, a family of attackers {Aη}η∈N ∈ ADV,
and an initial conﬁguration s0 = (cid:104)ml, h, ppl, rl(cid:105), we deﬁne
the ADL split-state representation (ADLSS
Πη ,Aη ,s0 )η∈N as
the family of split-state compositions of the following three
transition systems for every η ∈ N:

• honest-program semantics: The transition system
(SH , s0
H , AH , δH ) is deﬁned by the ADL semantics, ex-
tended with rules in Figure 6, and the initial state

(cid:11) for an arbitrary initial adversary

(cid:10)ml, h, ppl, rl, as H

dmy

state as H

dmy which will be ignored.

• crypto-API

The

semantics:

transition system
(SL, s0
L, AL, δL) is deﬁned by the ADL semantics
except rReturnVF, rReturnF, extended with rules
in Figure 4 and Prob (see Figure 7). The initial

(cid:11) for some arbitrary initial

state is (cid:10)(),∅, (), (), as L

dmy

adversary state as L

dmy which will be ignored.

semantics:

• attacker
system
(SA, s0
the
adversary A, extended with the transitions in Fig-
ure 8.

A, AA, δA) consists of

the transitions of

transition

The

To
cise,

((cid:62),(cid:10)ml, h, ppl, rl, as H

make
we

our
abbreviate

(cid:11)), (⊥, sA), (⊥,(cid:10)(),∅, (), (), as L

notation
the

more
initial

dmy

some

for
(cid:104)ml, h, ppl, rl(cid:105)ss .

honest

initial

state

con-
state

(cid:11))

as

(cid:104)ml, h, ppl, rl(cid:105)

dmy

Lemma 1. For all ADL programs Π that are pre-
compliant with a crypto-API speciﬁcation libSpec, all initial
conﬁgurations (cid:104)ml, h, ppl, rl(cid:105), all adversaries all n ∈ N, we
have

Pr[(cid:104)Π(cid:104)ml, h, ppl, rl(cid:105)(cid:107)A(cid:105) ↓n x] = Pr[T ↓n x],

where T denotes the ADL split-state representation of Π and
A for initial conﬁguration (cid:104)ml, h, ppl, rl(cid:105).
7.3 Over-approximating ADL

Recall that our plan is to instantiate Dc with symbolic
terms and even with positions in a CoSP tree. However,
some operations are not deﬁned on symbolic terms. As an
example consider the XOR operation.
It has been shown
that each computationally sound symbolic representation of
XOR has to work on symbolic bitstrings. Hence, for a typical
symbolic representation of a ciphertext the XOR operation
is not deﬁned in the symbolic model.
In order to get rid of any undeﬁned operations after in-
stantiating Dc with symbolic terms or CoSP tree positions,

we over-approximate each undeﬁned operation by querying
the attacker for the result. To this end, we deﬁne an over-
approximation of the ADL semantics in terms of its split-
state representation. This over-approximation tracks values
resulting from calls to the crypto-API. Whenever a compu-
tation, e.g., a unary operation, a binary operation or a test,
is performed on these values, the over-approximation gives
the adversary more power: she can decide the values of these
computations. This is necessary, as these operations cannot
be computed in the symbolic model. Already performing
this over-approximation on the ADL split-state semantics
simpliﬁes the embedding. Thanks to the split-state com-
position, we can deﬁne this over-approximation canonically.
Yet for space constraints, we refer the reader to the technical
report [12], and give here only the core of it.
We assume some domain D underlying the transition func-
tion and the set of states of the honest program semantic,
and a distinct new domain Dc (for values resulting from the
crypto API), a subset of which Db ⊂ Dc (representation
of bitstrings) have a bijection to the original domain (see
Figure 9). We assume the honest-program semantics to be
deﬁned via a set of rules, and interpret these rules in the new
domain Dc. If the re-interpreted rule can be instantiated re-
gardless of whether some state carries values in D or Dc,
this rule is transferred to the over-approximated semantics.
Most rules only move values from registers to heaps and are
homomorphic in this sense. Rules for which the above do
not hold, but which can be expressed using a constructor or
destructor, are split into four rules, two of which send these
values to the adversary and use her input for the follow-up
state in case one of the variables is in Dc\Db. Otherwise, i.e.,
if only values from D are used, or values representable in D,
then the crypto-API is used for the computation. This way,
we were able to encode binary operations like XOR as de-
structors, so representations of bitstrings that have passed
the crypto API (e.g., a bitstring was encrypted and then
decrypted again) can be treated without unnecessary im-
precision. If any rule r ∈ RH falls in neither of the above
cases, the canonical over-approximation is undeﬁned.

Using this over-approximation, we can derive ADLoSS , the
over-approximated ADL semantics. We tag messages result-
ing from calls to the crypto-API using a set Nc, such that
Nc ∩N = ∅, and assume a bijection between the two that is
eﬃciently computable. For n ∈ Nc ∪ N , let [n]Nc and [n]N
denote its representation in Nc or N according to the bijec-
tion. We lift this notation to values in V, too. The inference
rules include those previously deﬁned, but modiﬁed such
that register values are converted to N before addressing
the crypto-API, i.e., LC(f, r(va), . . . , r(ve)) is substituted by
LC(f, [r(va)]Nc , . . . , [r(ve)]Nc ), and out(mid , r(va), . . . , r(ve))
is substituted by out(mid , [r(va)]Nc , . . . , [r(ve)]Nc ). Finally,
the rules in Figure 10 are added.

(ADL split-state equivalence ≈SS
Definition 12
c ).
Let Π1 and Π2
be two families of ADL programs
compliant with the same library speciﬁcation libSpec
and s1, s2 initial conﬁgurations for Π1 and Π2, respec-
c Π2(cid:104)s2(cid:105), if, for all adversaries
tively. We write Π1(cid:104)s1(cid:105)≈SS
A ∈ ADV,
for the over-approximated ADL split-state
)η∈N of Π1(cid:104)s1(cid:105) and A,
representations
)η∈N of Π2(cid:104)s2(cid:105) and A, we have
and (ADLoSS
2 ,Aη ,s2
Πη
TH,1(s1)≈TL,TA

(ADLoSS
1 ,Aη ,s1
Πη

TH,2(s2).

c

726LibCall : s

(LC,mid,r(vk),...,r(vk+n−1),h|r(vk ))
−−−−−−−−−−−−−−−−−−−−−−−→H (wait, s)

LibResponse : (wait, s)

(LR,(mlo ,mup ,h(cid:48)))
−−−−−−−−−−−→H s

(cid:48)

], pp + 1 · ppl,

r [res lo (cid:55)→ mlo, res up (cid:55)→ mup] · rl

(cid:26) h[h

(cid:26)

LeakMsg : s

(out,mid,r(va),...,r(ve))

−−−−−−−−−−−−−−−→H (wait, s)

ReceiveMsg : (wait, s)

(in,mlo ,mup )

−−−−−−−−→H s

pp + 1 · ppl, r

(cid:20) res lo (cid:55)→ mlo,

res up (cid:55)→ mup

(cid:21)

(cid:27)

· rl

for (mid, h(r(vk))) ∈ dom(libSpec)
m[pp] = invoke-direct-range vk, n, mid

(cid:27) for (mid, h(r(vk))) ∈ dom(libSpec)

m[pp] = invoke-direct-range vk, n, mid
for mid ∈ Mal static
m[pp] = invoke-static va, . . . , ve, mid
for mid ∈ Mal static
m[pp] = invoke-static va, . . . , ve, mid

FinalCall :(cid:104)u, h(cid:105) (out,finalCall)

−−−−−−−−→H (cid:104)u, h(cid:105)

Figure 6: ADL split-state representation, honest program semantics, s = (cid:104)ml, h, ppl, r · rl(cid:105)

LLibCall :(cid:104)(),∅, (), (), (cid:105) (LC,mid,r(v),h)

−−−−−−−−−→L (cid:104)(m), h, (0), (defReg([r(v)])), (cid:105)

for r(v) := r(vk), . . . , r(vk+n−1),
m ··= lookup-direct Π(mid , h(r(vk)).class)

LLibRetVoid :(cid:104)(m), h, (pp), (r), (cid:105) (LR,(void,void,h))

LLibRet :(cid:104)(m), h, (pp), (r), (cid:105) (LR,(lo(r(va)),up(r(va)),h))

−−−−−−−−−−−→L (cid:104)(),∅, (), (), (cid:105)
−−−−−−−−−−−−−−−−−→L (cid:104)(),∅, (), (), (cid:105)

for m[pp] = return-void

for m[pp] = return va

Figure 7: ADL split-state representation, library program semantics,

is an arbitrary adversarial state.

Next, we state the lemma that connects the ADL seman-

tics to the over-approximated split-state form.

Lemma 2. Let Π1 and Π2 be two families of ADL pro-
grams pre-compliant with the same library speciﬁcation
libSpec and s1, s2 initial conﬁguration for Π1 and Π2, respec-
tively. Then Π1(cid:104)s1(cid:105)≈SS
7.4 Canonical symbolic semantics

c Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈ADL

c Π2(cid:104)s2(cid:105).

The canonical over-approximated split-state semantics di-
rectly deﬁnes a canonical symbolic semantics. We replace
the domain Dc by the set of terms that are deﬁned by the
CoSP-symbolic model M, we replace the attacker seman-
tics by the symbolic attacker from M, and we replace the
crypto-API by the constructors and destructors in M.

Definition 13

(Symbolic equivalence ≈SS

s ). Two
ADL programs Π1 and Π2, and initial conﬁgurations
s1 = (cid:104)ml1, h1, ppl1, rl1(cid:105) and s2 = (cid:104)ml2, h2, ppl2, rl2(cid:105) are
symbolically split-state equivalent (Π1(cid:104)s1(cid:105)≈SS
s Π2(cid:104)s2(cid:105)) if
for all attacker strategies I, their respective ADL symbolic
split-state semantics T1, T2 w.r.t.
to I are symbolically
equivalent, i.e., if SViews(T1) ∼ SViews(T2).

Next, we state the lemma that connects symbolic ADL to

the symbolic split-state composition of ADL.

Lemma 3. Let Π1 and Π2 be two ADL program pre-
compliant to the same library speciﬁcation libSpec and s1, s2
initial conﬁguration for Π1 and Π2, respectively. Then,

Π1(cid:104)s1(cid:105)≈ADL

s Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈SS

s Π2(cid:104)s2(cid:105)

7.5 The CoSP-embedding

We are ﬁnally in the position to construct the embed-
ding e from the part of the program that is encoded in the

honest-program semantics into CoSP. Recall that the sym-
bolic variant of ADL is also solely deﬁned on the honest-
program semantics of a program. Recall that we map the
honest-program semantics TH that belongs to an ADL pro-
gram Π into CoSP. In the context of a pair of ADL programs
Π1, Π2, we write TH,i for the honest program semantics for
Πi.

The main lemmas of this section show that for every pair
of ADL programs Π1, Π2 with initial conﬁgurations s1, s2 the
equivalence of Π1(cid:104)s1(cid:105) and Π2(cid:104)s2(cid:105) in symbolic ADL implies
the symbolic equivalence of e(TH,1(s1)) and e(TH,2(s2)) in
CoSP and computational indistinguishability of e(TH,1) and
e(TH,2) in CoSP implies computational indistinguishability
of Π1(cid:104)s1(cid:105) and Π2(cid:104)s2(cid:105).

First we construct the embedding, and then we give the
main arguments why the embedding preserves symbolic
equivalence and computational indistinguishability.

Constructing the embedding into CoSP. As CoSP
trees are inﬁnite, we deﬁne the embedding in a co-recursive
manner, i.e., as the largest ﬁxpoint of a co-recursive con-
struction. Each step in this recursion is deﬁned by a func-
tion ETH (s) that takes as input a trace from a leaf-node in
the so-far constructed CoSP tree to the root node and out-
puts a ﬁnite subtree. Within the embedding, we re-interpret
the transition system of the honest program introduced in
Section 7.3 by instantiating the set Dc to be the set of po-
sitions in a CoSP tree. With this representation, registers
and heap locations can store values input by the adversary
or the crypto-API by pointing to the position of the respec-
tive input or computation nodes in addition to numerical
values, locations, and void. Whenever this kind of special
register values are supposed to be given to the adversary or
the crypto-API, the position is resolved to a node identiﬁer.

727ALeakMsg :(cid:104)ε, as, ε(cid:105) (out,mid,va,...,ve)

−−−−−−−−−−−→A (cid:104)(mid , va, . . . , ve), as, ε(cid:105)
−−−−−−−−−−−−−→A
AReceiveMsg :(cid:104)i, as, res(cid:105) (in,(lo(res),up(res)))
−−−−−−→A
(cid:48)

AFinal :(cid:104)i, as, res(cid:105) (final,res)

(cid:10), as
, (cid:11)

(cid:10), as

, (cid:11)

(cid:48)

for res ∈ V
for res ∈ ADVR

Figure 8: ADL split-state representation, adversary semantics, ε denotes the empty string.

D

(e.g., V)

inject.

Dc

(e.g., T)

the implementation Impl from the computational soundness
result with a library speciﬁcation libSpec.

b

ij
e

c
t.

⊆

Db

(e.g., ι(V))

Figure 9: Domains of the canonical over-approx.

The recursion step ETH (s) in the construction of the em-
bedding internally runs the honest semantics of this modiﬁed
version of the over-approximated split-state semantics.
It
computes the next state from deterministic (internal) tran-
sitions until it arrives at a non-deterministic (calling) tran-
sition of the honest-program semantics, i.e., either a LC- or a
out-transition. Each call to the library (i.e., an LC-transition)
is transformed into a computation node with two successors
(labelled yes and no), referencing freshly constructed val-
ues or previous nodes depending on the information in the
label of the transition. Each call to the adversary (i.e., an
out-transition) is transformed into an output node, again ref-
erencing values or nodes based on the label of the transition,
and an input node for the in-transition following suit.
Soundness of the embedding. The main idea in the
proof is to consider the sub-sequences of the traces that start
and end with calls to, or responses from the attacker or the
library. Each step between the sub-sequences corresponds
to an edge in the CoSP-tree. If we choose a canonical over-
approximation such that the domain of the variable values is
the set of positions in the CoSP-tree, then we can show the
following relation: for the over-approximated split-state se-
mantics, there is a direct correspondence between the states
at the end of such a sub-sequence and the nodes in the CoSP-
tree, which store the current state in the node-identiﬁer.
In order to match the notation in the overview, we write
e(Πi(cid:104)si(cid:105)) for e(TH,i(si)) in the following lemmas, for two
ADL programs Π1, Π2 and two initial conﬁgurations s1, s2.

Lemma 4. Let Π1 and Π2 two ADL program together with
input conﬁgurations s1, s2 in the canonical symbolic model
with respect to a CoSP-symbolic model M. Let Π1 and Π2
be pre-compliant with the same library speciﬁcation. Then,

Π1(cid:104)s1(cid:105)≈SS

s Π2(cid:104)s2(cid:105) =⇒ e(Π1(cid:104)s1(cid:105))≈CoSP

s

e(Π2(cid:104)s2(cid:105))

Lemma 5. Let Π1 and Π2 two ADL program together with
input conﬁgurations s1, s2 in the canonical symbolic model
with respect to a CoSP-symbolic model M. Let Π1 and Π2 be
compliant with the same library speciﬁcation w.r.t a symbolic
model M and an implementation Impl. Then,
e(Π2(cid:104)s2(cid:105)) =⇒ Π1(cid:104)s1(cid:105)≈SS

e(Π1(cid:104)s1(cid:105))≈CoSP

c Π2(cid:104)s2(cid:105).

c

Our computational soundness result is parametric in a
given symbolic model and given conditions CI to the imple-
mentation and the protocols such that computational sound-
ness in the sense of the CoSP framework holds. Our result
states that for any symbolic model with conditions C in
CoSP, equivalence in symbolic ADL (see Section 6) implies
indistinguishability in ADL (see Section 5). Since all CoSP
results in the literature characterize the protocol class by a
set of protocol conditions CP , we use these protocol condi-
tions in our theorem as well.

Theorem 1. Let a symbolic model M, protocol condi-
tions CP and implementation conditions CI that are com-
putationally sound in the sense of CoSP (Deﬁnition 2) be
given. Let Π1 and Π2 be two uniform families of ADL pro-
grams compliant with initial conﬁgurations s1, s2 and the
same library speciﬁcation libSpec w.r.t. to a symbolic model
M and all implementations Impl that satisfy CI . Then, the
following implication holds

Π1(cid:104)s1(cid:105)≈ADL

s Π2(cid:104)s2(cid:105) =⇒ Π1(cid:104)s1(cid:105)≈ADL

c Π2(cid:104)s2(cid:105).

8. RELATED WORK
Operational semantics for Dalvik Bytecode. We have
opted to ground our work on the Abstract Dalvik Language
(ADL) [4]. ADL currently excels over alternative seman-
tics such as the ones proposed by Wognsen et al. [15], Xia
et al. [16], TaintDroid [3], and Chaudhuri [17] because of
its comprehensive treatment of the Dalvik language, even
though ADL currently only provides sequential executions
and does not support exceptions. TaintDroid is more gen-
eral in this respect in that it contains an ad-hoc modelling
of concurrent execution. However, in the ADL extension
put forward with the adversary that includes probabilistic
choices and adversary interactions, concurrency in ADL can
be modelled via program transformations, as we discuss in
Section 7.

For our the next lemma and our main theorem, we require
that two ADL programs are compliant, i.e., the programs are
pre-compliant with the same library speciﬁcation (see Sec-
tion 7.2), and the library produces the same distribution as

Information-ﬂow control with cryptographic primi-
tives. The standard notion of security in information ﬂow
control – non-interference – is too strong when cryptographic
operations are being considered, as, e.g., an encryption of

728Cmd: m[pp] = unop va, vb, uop
r(vb) (cid:54)∈ N (cid:48)

c

=⇒ (l1, l2) = (LC, LR)

r(vb) ∈ N (cid:48)

c

=⇒ (l1, l2) = (out, in)

Cmd: m[pp] = binop va, vb, vc, bop
¬(r(vb), r(vc) ∈ N (cid:48)
c)

=⇒ (l1, l2) = (LC, LR)

r(vb), r(vc) ∈ N (cid:48)

c

=⇒ (l1, l2) = (out, in)

Unop-l1: s

Unop-l2: s

(l1,uop,r(vb))

−−−−−−−−−→H s
(l2,u)−−−−→H s{r[va (cid:55)→ u]}

Binop-l1: s

Binop-l2: s

(l1,bop,r(vb),r(vc))

−−−−−−−−−−−−→H s
(l2,u)−−−−→H s{r[va (cid:55)→ u]}

Cmd: m[pp] = if-test va, vb, n, rop
¬(r(va), r(vb) ∈ N (cid:48)
c)

=⇒ (l1, l2) = (LC, LR)

r(va), r(vb) ∈ N (cid:48)

c

(l1,rop,r(va),r(vb))

=⇒ (l1, l2) = (out, in)
−−−−−−−−−−−−→H s
(l2,x)−−−→H s{pp + n}, if x = r(va)
(l2,x)−−−→H s{pp + 1}, if x = ⊥

T1-l1: s

T2-l1: s

T3-l1: s

Figure 10: over-approximated honest program semantics for ADL (ADLoSS ). Here Nb := range(ι) and N (cid:48)
Nc \ Nb.

c :=

a secret key and a secret message is intuitively safe to be
stored in a public variable, but it nontheless results in dif-
ferent values depending on the key and the message. While
the declassiﬁcation of values (see [18] for an introduction
and overview of results) can be used to relax this notion, it
is diﬃcult to decide under what circumstances cryptographic
values can be safely declassiﬁed.

Our approach is similar to Askarov et al.’s, permitting so-
called cryptographically masked ﬂows by considering a re-
laxed equivalence notion on public values, masking accept-
able information ﬂow when ciphertexts are made public [19].
Laud has shown the computational soundness of this ap-
proach [20] if the employed encryption scheme satisﬁes key-
dependent message security, provides plaintext integrity,
and keys are only used in the correct key position, etc. As
cryptographically masked ﬂows are captured in a possibilis-
tic setting, leaks through probabilistic behavior are not cap-
tured; hence the program must not be able to branch on
probabilistic values.
In our work, we treat computations
performed on cryptographic values conservatively by relay-
ing them to the adversary. Furthermore, previous work in-
troduced security type-systems, such as [21], and program
analyses, such as [22], that directly operate on the compu-
tational semantics and are thus capable of verifying non-
interference in a probabilistic setting. This approach avoids
the aforementioned problem at the cost of less modularity
and less potential for automation than our approach.

Computational Soundness. On computational sound-
ness, there is a rich body of literature for various crypto-
graphic primitives [11, 23–25], with malicious keys [8, 26],
and even composable computational results [27, 28]. Even
though these works covered the applied π-calculus [6,26,29],
the stateful applied π calculus [30] and RCF [14] and even a
embedding of a fragment of C [31], none of these works pro-
vide a computational soundness result is known for Dalvik
bytecode and hence for Android app analysis.

Another line of work does not provide a complete sym-
bolic characterization of the attacker but concentrates on
single rules that hold for certain symbolic terms [32, 33].
This restriction enables a much more ﬂexible and compos-
able preservation notion but pays with omitting any guar-
antee that the set of rules characterizes all attacker-actions.
Hence, it is not clear how well-suited this approach is to
automation.

Interactive proof assistants for cryptography. Cryp-
tographic proof assistants enable the mechanized veriﬁcation
of cryptographic proofs, without ﬁrst abstracting the cryp-
tographic operations [34–36]. Consequently, these tools only
oﬀer limited automation. Yet complementarily, these tools
could be used to verify that a library satisﬁes the conditions
that a computational soundness result requires.

9. CONCLUSION AND FUTURE WORK

We have shown how cryptographic operations can be
faithfully included into existing approaches for automated
app analysis. Our results overcome the overly pessimistic
results that arise when current automated approaches deal
with apps that contain cryptographic operations, as these re-
sults do not account for secrecy properties oﬀered by crypto-
graphic operations such as encryption. We have shown how
cryptographic operations can be expressed as symbolic ab-
stractions within Dalvik bytecode, so that these abstractions
can be conveniently added to existing app analysis tools us-
ing minor changes in their semantics. Moreover, we have
established the ﬁrst computational soundness result for the
Abstract Dalvik Language (ADL) [4], which currently con-
stitutes the most detailed and comprehensive operational
semantics for Dalvik in the literature.

A result that we only scratched on in this work is that
any small-step semantics expressed in our novel split-state
form entails a canonical small-step semantics for a symbolic
model that is computationally sound. This hence provides a
recipe for establishing computationally sound symbolic ab-
stractions for any given programming language, provided
that one can show that the interaction with the attacker
and the cryptographic operations can be expressed by means
of our concept of split-state semantics. We plan to further
investigate this claim and its applicability to modern pro-
gramming languages in future work.

10. ACKNOWLEDGEMENTS

This work has been partially funded by the German Re-
search Foundation (DFG) via the collaborative research cen-
ter “Methods and Tools for Understanding and Controlling
Privacy” (SFB 1223), project B3. This work has been par-
tially supported by the Zurich Information Security Center
(ZISC).

72911. REFERENCES

[1] Symantec, “Internet security threat report, volume

20,” Accessed: Oct 15, 2015. [Online]. Available:
http://www.symantec.com/security response/
publications/threatreport.jsp

[2] GData, “Mobile malware report: Q2/2015,” Accessed:

Oct 15, 2015. [Online]. Available: https://public.
gdatasoftware.com/Presse/Publikationen/Malware
Reports/G DATA MobileMWR Q2 2015 EN.pdf

[3] W. Enck, P. Gilbert, B.-G. Chun, L. P. Cox, J. Jung,

P. McDaniel, and A. N. Sheth, “Taintdroid: an
information ﬂow tracking system for real-time privacy
monitoring on smartphones,” Communications of the
ACM, vol. 57, no. 3, pp. 99–106, 2014.

[4] S. Lortz, H. Mantel, A. Starostin, T. B¨ahr,

D. Schneider, and A. Weber, “Cassandra: towards a
certifying app store for android,” in Proc. 4th ACM
SPSM, 2014, pp. 93–104.

[5] M. Backes, S. Bugiel, E. Derr, S. Gerling, and

C. Hammer, “R-droid: In-depth application vetting for
android with path-sensitive value analysis,” in Proc.
ACM AsiaCCS, 2016.

[6] M. Backes, D. Hofheinz, and D. Unruh, “CoSP: A
General Framework for Computational Soundness
Proofs,” in Proc. 16th ACM CCS, 2009, pp. 66–78.

[7] S. Meiser, “Computational soundness of passively

secure encryption in presence of active adversaries,”
Master’s thesis at Saarland University, 2010.

[8] M. Backes, A. Malik, and D. Unruh, “Computational

Soundness without Protocol Restrictions,” in Proc.
19th ACM CCS, 2012, pp. 699–711.

[9] M. Backes, F. Bendun, and D. Unruh, “Computational

Soundness of Symbolic Zero-knowledge Proofs:
Weaker Assumptions and Mechanized Veriﬁcation,” in
Proc. 2nd POST, 2013, pp. 206–225.

[10] M. Backes, E. Mohammadi, and T. Ruﬃng,

“Computational Soundness Results for ProVerif,” in
Proc. 3rd POST, 2014, pp. 42–62.

[11] M. Backes, F. Bendun, M. Maﬀei, E. Mohammadi,

and K. Pecina, “A Computationally Sound, Symbolic
Abstraction for Malleable Zero-knowledge Proofs,” in
Proc. 28th IEEE CSF, 2015, pp. 412–480.

[12] M. Backes, R. K¨unnemann, and E. Mohammadi,

“Technical report: Computational soundness for dalvik
bytecode,” arXiv:1608.04362, 2016.

[13] D. Unruh, “Termination-Insensitive Computational

Indistinguishability (and Applications to
Computational Soundness),” in Proc. 24th IEEE CSF,
2011, pp. 251–265.

[14] M. Backes, M. Maﬀei, and D. Unruh,

“Computationally Sound Veriﬁcation of Source Code,”
in Proc. 17th ACM CCS, 2010, pp. 387–398.

[15] E. R. Wognsen, H. S. Karlsen, M. C. Olesen, and

R. R. Hansen, “Formalisation and analysis of dalvik
bytecode,” Science of Computer Programming, vol. 92,
pp. 25–55, 2014.

[16] M. Xia, L. Gong, Y. Lyu, Z. Qi, and X. Liu, “Eﬀective

real-time android application auditing,” in Proc. 36th
IEEE S&, 2015, pp. 899–914.

[17] A. Chaudhuri, “Language-based security on android,”

in Proc. 4th ACM PLAS, 2009, pp. 1–7.

[18] A. Sabelfeld and D. Sands, “Declassiﬁcation:

Dimensions and principles,” J. Computer Security,
vol. 17, no. 5, 2009.

[19] A. Askarov, D. Hedin, and A. Sabelfeld,

“Cryptographically-masked ﬂows,” TCS, vol. 402, no.
2-3, pp. 82–101, 2008.

[20] P. Laud, “On the computational soundness of

cryptographically masked ﬂows,” in Proc. of 35th
POPL, 2008, pp. 337–348.

[21] P. Laud and V. Vene, “A type system for

computationally secure information ﬂow,” in Proc. of
15th FCT, 2005, pp. 365–377.

[22] P. Laud, “Handling encryption in an analysis for

secure information ﬂow,” in Proc. of 12th ESOP, 2003,
pp. 159–173.

[23] M. Backes, B. Pﬁtzmann, and M. Waidner, “A

Composable Cryptographic Library with Nested
Operations,” in Proc. 10th ACM CCS, 2003, pp.
220–230.

[24] V. Cortier and B. Warinschi, “Computationally

Sound, Automated Proofs for Security Protocols,” in
Proc. 14th ESOP, 2005, pp. 157–171.

[25] D. Galindo, F. D. Garcia, and P. van Rossum,

“Computational Soundness of Non-Malleable
Commitments,” in Proc. 4th ISPEC, 2008, pp.
361–376.

[26] H. Comon-Lundh, V. Cortier, and G. Scerri, “Security

Proof with Dishonest Keys,” in Proc. 1nd POST.
Springer, 2012, pp. 149–168.

[27] V. Cortier and B. Warinschi, “A composable

computational soundness notion,” in Proc. 18th ACM
CCS, 2011, pp. 63–74.

[28] F. B¨ohl, V. Cortier, and B. Warinschi, “Deduction
Soundness: Prove One, Get Five for Free,” in Proc.
20th ACM CCS, 2013, pp. 1261–1272.

[29] H. Comon-Lundh and V. Cortier, “Computational
Soundness of Observational Equivalence,” in Proc.
15th ACM CCS. ACM Press, 2008, pp. 109–118.

[30] J. Shao, Y. Qin, and D. Feng, “Computational

Soundness Results for Stateful Applied Pi Calculus,”
in Proc. 5rd POS, 2016, pp. 254–275.

[31] M. Aizatulin, A. D. Gordon, and J. J¨urjens,

“Computational Veriﬁcation of C Protocol
Implementations by Symbolic Execution,” in Proc.
19th ACM CCS, 2012, pp. 712–723.

[32] G. Bana and H. Comon-Lundh, “Towards

Unconditional Soundness: Computationally Complete
Symbolic Attacker,” in Proc. 1nd POST, 2012, pp.
189–208.

[33] ——, “A Computationally Complete Symbolic

Attacker for Equivalence Properties,” in Proc. 21th
ACM CCS, 2014, pp. 609–620.

[34] G. Barthe, B. Gr´egoire, S. Heraud, and S.-Z. B´eguelin,

“Computer-Aided Security Proofs for the Working
Cryptographer,” in Proc. CRYPTO, 2011, pp. 71–90.

[35] A. Petcher and G. Morrisett, “The Foundational

Cryptography Framework,” in Proc. 4th POST, 2015,
pp. 53–72.

[36] A. Lochbihler, “Probabilistic functions and

cryptographic oracles in higher order logic,” in Proc.
25th ESOP, 2016, pp. 503–531.

730