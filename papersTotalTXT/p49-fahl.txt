Rethinking SSL Development in an Appiﬁed World

Sascha Fahl, Marian Harbach, Henning Perl, Markus Koetter, Matthew Smith

Distributed Computing & Security Group
Leibniz University Hannover, Germany

Hannover, Germany

{fahl,harbach,perl,koetter,smith}@dcsec.uni-hannover.de

ABSTRACT
The Secure Sockets Layer (SSL) is widely used to secure data
transfers on the Internet. Previous studies have shown that
the state of non-browser SSL code is catastrophic across a
large variety of desktop applications and libraries as well as
a large selection of Android apps, leaving users vulnerable to
Man-in-the-Middle attacks (MITMAs). To determine possi-
ble causes of SSL problems on all major appiﬁed platforms,
we extended the analysis to the walled-garden ecosystem
of iOS, analyzed software developer forums and conducted
interviews with developers of vulnerable apps. Our results
show that the root causes are not simply careless developers,
but also limitations and issues of the current SSL develop-
ment paradigm. Based on our ﬁndings, we derive a proposal
to rethink the handling of SSL in the appiﬁed world and
present a set of countermeasures to improve the handling of
SSL using Android as a blueprint for other platforms. Our
countermeasures prevent developers from willfully or acci-
dentally breaking SSL certiﬁcate validation, oﬀer support
for extended features such as SSL Pinning and diﬀerent SSL
validation infrastructures, and protect users. We evaluated
our solution against 13,500 popular Android apps and con-
ducted developer interviews to judge the acceptance of our
approach and found that our solution works well for all in-
vestigated apps and developers.

Categories and Subject Descriptors
D.4.4 [Software]: Communications Management—Network
communication; H.3.5 [Information Storage and Re-
trieval]: Online Information Services—Data Sharing

General Terms
Security, Human Factors

Keywords
Android, Apps, iOS, MITMA, Security, SSL

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from Permissions@acm.org.
CCS’13, November 4–8, 2013, Berlin, Germany.
Copyright 2013 ACM 978-1-4503-2477-9/13/11 ...$15.00.
http://dx.doi.org/10.1145/2508859.2516655.

1.

INTRODUCTION

The proliferation of smartphones and tablet devices is
changing the way software is being developed. Both the
Android Play Market and the Apple App Store oﬀer over
half a million apps and more than one billion apps are in-
stalled from these markets every year. The “There is an
app for that” attitude and the possibility to quickly reach a
huge global market has inspired thousands of small software
companies and hobby developers to create software on an
unprecedented scale. These join big businesses in vying for
the lucrative app market. One issue issue many developers
seem to have in common is that they often have problems
when working with SSL. In previous work, we conducted an
in-depth study of 13,500 Android apps which showed that a
large number of apps did not use SSL correctly [5], thus mak-
ing them vulnerable to Man-In-The-Middle attacks. The af-
fected applications ranged from home-brew and open source
apps to those developed by large corporations and security
specialists, suggesting that SSL problems are not just a mat-
ter of untrained developers getting it wrong.

While our previous work and a related study by Georgiev
et al. [8] discuss possible reasons for why so many apps across
such a wide range of developers are aﬀected and make recom-
mendations on how to prevent these problems in the future,
the actual causes of the problems have not yet been identi-
ﬁed nor have the potential countermeasures been evaluated.
In this paper, we continue where this work left oﬀ and evalu-
ate the root causes of SSL coding problems. Based on these
ﬁndings, we argue that the way developers work with SSL
needs to be changed signiﬁcantly. We designed a framework
for SSL development to demonstrate our proposal, imple-
mented it for Android, evaluated it against the set of 13,500
popular apps we analyzed in our previous study and con-
ducted developer interviews to show its functionality and
feasibility.

Our solution makes several changes to the status quo:
First, it removes the need for developers to write actual SSL
code. Instead an app developer can turn on and conﬁgure
SSL using only conﬁguration options in case they intend to
deviate from the standard use case. Second, unlike in the
current system, all use-cases we found in apps and those
described by developers are supported securely, removing
the need for dangerous customization. Third, the frame-
work can make a distinction between developer devices and
end-user devices. This allows developers to rapidly proto-
type applications and tinker without much eﬀort, but it also
automatically and properly protects end-users. Fourth, in
the remaining rare cases that there is a problem with SSL,

49the end-user is reliably informed about the nature of the
problem which means that apps can no longer silently ig-
nore these warnings and invisibly make users vulnerable to
MITM attacks. Finally, our approach allows for new SSL
validation strategies and infrastructures, such as Certiﬁcate
Transparency [11], Convergence [13], and AKI [10], to be
deployed centrally instead of potentially requiring tens of
thousands of app developers to make adjustments to their
code, thus signiﬁcantly easing the deployment of new SSL
validation strategies1.

Our contributions can be summarized as follows:
• We conducted the ﬁrst analysis of iOS SSL security
to ascertain whether the walled garden approach and
stricter code auditing process of Apple could prevent
the kind of problems previously seen on Android. We
manually examined 1,009 iOS apps. The results show
that, similar to Android, 14 % of apps using SSL do
not implement SSL validation correctly and are thus
vulnerable to active MITMAs.

• We conducted the ﬁrst in-depth study of the reasons
behind the widespread problems with SSL on the two
major app platforms Android and iOS, including both
technical aspects as well as an in-depth study with
aﬀected developers.

• Based on the above research, we designed and imple-
mented countermeasures for handling SSL on Android.
This solution can also serve as a blueprint for SSL han-
dling on other appiﬁed platforms.

• We conducted an extensive evaluation of our approach
by auditing 13,500 apps and showing that our solution
covers all use-cases present in these apps. We also
conducted a follow-up developer study to ensure our
approach does not break any development needs and
would ﬁnd acceptance within the target community.

2. RELATED WORK
2.1 SSL Validation

The main body of work on SSL has centered around ﬁnd-
ing a replacement for the current weakest link, the CA-based
validation of certiﬁcates. Many new proposals have been
made that promise to strengthen the security of certiﬁcate
validation, including Perspectives [18], Convergence [13], Cer-
tiﬁcate Transparency [11], Sovereign Keys [3], TACK [12],
and DANE [9]. However, none of these systems has achieved
widespread adoption yet. While this is certainly at least in
part due to the fact that some have only recently been pro-
posed, a major issue faced by all systems is that they require
modiﬁcation of client code handling SSL connections. While
on desktop systems updating the handful of browsers would
already cover a large amount of SSL real estate, the situa-
tion on appiﬁed platforms is bleak. Here thousands of apps
contain their own SSL validation implementation and thus
must potentially update their code to support a new certiﬁ-
cate validation strategy.

1We believe this last feature could be useful in the light of
the many new solutions suggested in this domain that are
currently facing adoption/deployment problems.

2.2 SSL on Appiﬁed Platforms

Research has shown that the appiﬁcation and app market
trend has caused new security and privacy challenges for
users, developers and researchers [15, 2, 4, 19, 5, 1, 17, 7,
6]. This research focused mainly on the threats posed by
malicious entities and their apps. The problems with SSL
we [5] and Georgiev et al. [8] discovered are diﬀerent in that
they are not caused by malicious intent, but nonetheless pose
a serious threat.

While the bulk of SSL connections on desktop systems
occurs in browsers which validate SSL certiﬁcates correctly,
there are also applications that use SSL to protect their com-
munication. Georgiev et al. [8] analyzed the security of SSL
certiﬁcate validation in a wide range of SSL libraries and
programming frameworks. They conclude that many popu-
lar libraries fail when it comes to SSL certiﬁcate validation
and thus endanger the applications which are based on these
libraries.

In [5] we examined the state of SSL on Android. We an-
alyzed the SSL security of 13,500 popular free apps from
Google’s Play Market. The results showed that 1,074 apps
contained SSL code that either accepted all certiﬁcates or all
hostnames for a certiﬁcate and thus leaves the users poten-
tially vulnerable to MITMAs. The cumulative install base
of the apps with conﬁrmed vulnerabilities against MITMAs
ranged between 40 and 185 million users.

Georgiev et al. [8] make recommendations for what could
be done to alleviate these widespread problems. They rec-
ommend that app developers should use fuzzing and ad-
versarial testing. Developers should not modify applica-
tion code and disable certiﬁcate validation for testing with
self-signed and/or untrusted certiﬁcates, but create a tem-
porary keystore with the untrusted CA’s public key in it.
They also recommend that app developers should not rely
on SSL libraries to do things correctly for them.
Instead
they should set all necessary security parameters themselves
explicitly. For library developers, they recommend that SSL
libraries be made more explicit about the semantics of their
APIs. They also recommend that libraries use safe defaults
as much as possible. Furthermore, they should not silently
skip important functionalities such as hostname veriﬁcation
and should remain consistent in using return values or ﬂags
for reporting purposes.

Our central suggestion was to drastically limit custom SSL
handling in apps. In an alternative approach we suggested
that a static code analysis be performed by the app store
or the app installer to then inform developers/users about
potentially unsafe code.

Both papers only brieﬂy describe their potential counter-
measures as part of their recommendations for future work.
No implementations or evaluations were presented.
Inter-
estingly, the countermeasures suggested by the two parties
diverge somewhat in their direction. Georgiev et al. call for
better APIs for developers, emphasize that developers need
to check their apps themselves instead of relying on libraries
to do things correctly and to work around API restrictions
using custom keystores instead of modifying validation for
development purposes, while we suggest almost the opposite
approach by recommending to limit the developers’ capabil-
ities for customizing SSL and adding checks to prevent bro-
ken apps from entering the market or the device. In the next
two sections of this paper, we will examine the root causes
of the problems facing developers when using SSL to better

50judge which countermeasures are likely to achieve the best
results.
2.3 SSL Development Paradigm

There are countless SSL libraries and TrustManagers that
aim to make the integration of SSL into apps easier. How-
ever, as the studies by Georgiev et al. [8] and us [5] have
shown, many of these are either broken or so error-prone
that developers break their apps using them. To the best
of the authors’ knowledge there is no related work evaluat-
ing the root causes of these SSL coding problems nor any
work suggesting changes to the development paradigm. Our
paper makes important contributions to both these areas.

3. SSL ON IOS

To examine whether or not the widespread SSL problems
of apps and libraries introduced above are endemic to the
Android and open source ecosystems, we conducted the ﬁrst
in-depth analysis of iOS apps to see if the more restrictive
and curated Apple App Store would prevent apps with bro-
ken SSL code from entering the iOS ecosystem. While iOS
does not oﬀer developers as many options as Android, it still
oﬀers similar freedom concerning the implementation and
use of SSL. Developers can decide if they want to use SSL
or not and just like on Android they can use SSL but can
turn SSL certiﬁcate validation oﬀ. They are also left alone
with the challenge to ﬁnd an appropriate way to handle cer-
tiﬁcation validation errors and inform the user: In terms of
SSL APIs, Android and iOS are fairly similar. However, Ap-
ple performs a code analysis on all apps, in order to prevent
apps that do not conform to their policies from entering the
store.

We did not have the means to automatically crawl Apple’s
app store and use static code analysis on tens of thousands
of apps as we did with Android, so we opted for a manual
approach. Initially, we downloaded 150 cherry-picked apps
for analysis. Based on the ﬁndings in these apps we con-
ducted developer interviews as described in section 4.2. We
then extended our study to include 1,009 apps for a more
robust evaluation. We downloaded the 1,009 apps by select-
ing the most popular free apps. Since iOS does not work
with permissions the way Android does, it was not possible
to see which apps have access to sensitive information and
can connect to the Internet before installation. We therefore
installed all of the apps on an iPhone 4S running iOS 5 to
study them in action. We then mounted active Man-In-The-
Middle attacks against SSL connections using a transparent
proxy to see how the apps react and what kind of sensitive
information we could gather.

We captured network traﬃc from 884 apps and SSL-protected

network traﬃc from 697 of these 884 apps. Of these 697
apps, 98 (14 %, 9.7 % of all 1,009 apps) were vulnerable to
our MITMA and leaked sensitive information. Of the re-
maining 599 apps that were not vulnerable to our active
MITMA, 312 apps presented the user with a warning mes-
sage; 58 apps presented a warning message indicating that
there were problems with the SSL certiﬁcate. 254 presented
warning messages that did not give an appropriate descrip-
tion of what was going on, for instance stating that the login
credentials were wrong or that there was no Internet connec-
tion available. Finally, 287 apps simply did not connect to
the attacked host either doing nothing, hanging indeﬁnitely
or crashing. Additionally, 82 (9.27 %) of the 884 apps used

plain HTTP connections to transfer sensitive information.
Two apps were vulnerable to SSL stripping attacks. One of
these was an online banking app that loaded the bank’s web-
site via plain HTTP, while the other app connected to the
HTTP version of Facebook. Thus we were able to gather
sensitive information from 182 apps, i.e. 20.5 % of apps
from which we captured network traﬃc. The information
included the usual suspects of login credentials, banking ac-
counts, data stored on cloud storage services, emails, or chat
messages.

This shows that the SSL problems on iOS are similar to
those on Android and that Apple’s more restrictive and cu-
rated app development model and App Store do not prevent
SSL-related security issues. Just like on Android, app devel-
opers turn oﬀ SSL certiﬁcate validation, write apps that are
vulnerable to SSL stripping and even in cases where apps
apply SSL certiﬁcate validation correctly, they often do not
present sensible feedback when validation fails.

While there are many more details worth discussing in
the context of iOS, for the purpose of this work, the fact
that iOS apps suﬀer from a similar number of SSL prob-
lems shows that these problems must have underlying causes
which are not speciﬁc to a platform or app store model. For
more details on the iOS analysis the reader is referred to
AppendixA.

4. CAUSE ANALYSIS

The iOS study shows that the trouble developers have us-
ing SSL correctly is common to the major platforms and
across all applications and platform paradigms. To develop
an eﬀective countermeasure, we wanted to identify the root
causes of these problems. Therefore, we studied entries
about SSL development for both Android and iOS in on-
line forums and conducted interviews with developers who
had produced broken SSL code.
4.1 Online Forums

We used stackoverflow.com, a popular online forum for
software developers, to search for results that contained text
such as “android/ios allow all certiﬁcates” and “android/ios
trust all certiﬁcates” ﬁrst. These kinds of results were found
in threads where developers asked how they could “work with
self-signed certiﬁcates” or “make ’javax.net.ssl.SSLException’
go away”. Answers to these and similar questions mainly
contained explanations on how to turn oﬀ SSL certiﬁcate
validation or hostname veriﬁcation without mentioning that
this would create serious security issues. Studying these
discussions conﬁrmed our impression that many developers
on both platforms – iOS as well as Android – lack an ade-
quate understanding of how SSL works and were frustrated
with the complexity of customizing SSL code and thus will-
ing to use the quick ﬁxes oﬀered by the forums – potentially
without understanding the consequences. These threads had
more than 30,000 views. To put this number into perspec-
tive, searching for “android ssl pinning” or “ios ssl pinning”
returns only one result for Android and two results for iOS
with less than 600 views in total.
4.2 Interviews

While online forums give a good indication of potential
issues, a more reliable way to conﬁrm whether or not these
issues are the actual reasons causing the problems in the
thousands of real world apps is to talk to developers. We

51contacted 78 developers of the 82 vulnerable apps2 from the
100 Android and 150 iOS apps we studied in detail. We
informed the developers of the discovered vulnerabilities via
email and kindly asked them to contact us for further infor-
mation and assistance in ﬁxing their problems. We received
responses from 39 of the 78 developers. We disclosed the
respective vulnerability, oﬀered further assistance and asked
whether the developers were willing to discuss the details of
the security bug either via telephone or email. We promised
the developers to anonymize all information they provided
and to make neither their names nor the apps’ names pub-
licly available. 14 developers agreed to an interview while
the rest was not willing to discuss the topic in further detail
– often with regard to “constraints” dictated by their legal
departments. The interviews were conducted in German or
English, depending on the developer’s origin. However, not
all developers were native speakers. Statements were trans-
lated by the authors, grammatical errors were not corrected.
4.2.1 Results
One of the main causes for the problems we found, was
that developers wanted to use self-signed certiﬁcates dur-
ing development. 5 of the 14 developers reported that they
needed to turn oﬀ SSL certiﬁcate validation during develop-
ment because they were working with test servers that used
self-signed SSL certiﬁcates. To avoid certiﬁcate validation
exceptions, they implemented their own SSL certiﬁcate val-
idation strategies that accept all certiﬁcates, or copied code
from the online forums mentioned above that promised to
help with getting out of the “self-signed certiﬁcate dilemma”.
While it is understandable that developers turn oﬀ SSL cer-
tiﬁcate validation in the development phase, these develop-
ers basically forgot to remove their accept-all code when they
released their apps. Three of these ﬁve developers realized
that this was a serious security threat and stated that they
should ﬁx this security issue as soon as possible. The other
two did not see the problem and even after our explanations
stated the following:

“You said that an attacker with access to the network
traﬃc can see the data in cleartext. I tried that and I
connected my phone to a Wi-Fi hotspot on my laptop.
When I used Wireshark to look at the traﬃc, Wireshark
said that this is a proper SSL protected data stream and
I could not see any cleartext information when I man-
ually inspected the packets. So I really cannot see what
the problem is here.”

This supports the hypothesis stated by Georgiev et al. [8]
that too little adversarial testing is conducted by app devel-
opers. However, it also raises the issue that there are de-
velopers, who, while being technically adept enough to use
Wireshark to check if their app’s traﬃc is really encrypted,
do not understand the nature of the threat and thus take no
precautions to counter it.

Apart from developers wanting to use self-signed certiﬁ-
cates during development, we also talked to developers who
actually wanted to use them in their production environment
but were unaware of the security implications of accepting
any certiﬁcate:

“I was using a self-signed certiﬁcate for my app because
it is free and CA-signed certiﬁcates cost a lot. But, ac-
2Some developers were responsible for both an Android and
an iOS app; thus there were only 78 developers for 82 apps.

tually, I had no idea that working with self-signed cer-
tiﬁcates could have resulted in such a security issue. I
think the online forum where I found the code snippet
only said that it makes self-signed certiﬁcates work.”

“We added this piece of code because our client uses an
SSL certiﬁcate for his web-service which was signed by a
certiﬁcate authority that is not pre-installed on Android
and actually we did not realize that this would cause
such trouble.”

Sometimes, the broken SSL code was added because de-
velopers had diﬃculties understanding the problem and just
went for the ﬁrst solution that seemingly made the problem
disappear:

“This app was one of our ﬁrst mobile apps and when
we noticed that there were problems with the SSL cer-
tiﬁcate, we just implemented the ﬁrst working solution
we found on the Internet. [. . .] We usually build Java
backend software for large-scale web services.”

However, there were also developers who even after being
informed about the problems and the threat scenario did not
properly understand the problem and their countermeasures
did not address the threat arising from a MITMA:

“We hadn’t realized that it would cause such an issue
by using self-signed certiﬁcates in the past time, and
we just veriﬁed if the certiﬁcate was expired. But after
noticing this issue, we strengthened the security check
like verifying host name. We believe this improvement
can ensure users’ security. So we still stick to trust
self-signed certiﬁcates right now for its smaller size and
lower bandwidth cost.”

So while they added hostname veriﬁcation after we informed
them about the issue, they still accept all self-signed certiﬁ-
cates thus defeating hostname veriﬁcation entirely. In an-
other case, a development company of a vulnerable online
banking app needed two iterations to ﬁx their app correctly,
even though we had sent them the necessary code snippets.
There were also cases where developers thought using broken
SSL was adequate to protect information that they deemed
to be not that valuable:

“We checked into this. Only the [. . .] feature is using
a weak SSL certiﬁcate and that connection only sends
the device models and IMEI, but that’s not a security
concern.”

Some developers knew that their code could cause security
problems but saw no other option but to work with self-
signed certiﬁcates by turning oﬀ certiﬁcate validation en-
tirely, since their customers wanted to use self-signed certiﬁ-
cates.

“This issue exists because many of our customers use
self-signed certiﬁcates for SSO (single sign on). Some
time back, a ﬁx was implemented to allow this to work.”

One of those developers raised the interesting point that An-
droid does not oﬀer any default warning, forcing developers
to provide one for themselves if they wish to inform users
about failed certiﬁcate validations:

“The app accepts all SSL certiﬁcates because some users
wanted to connect to their blogs with self-signed certs

52and [. . . ] because Android does not provide an easy-to-
use SSL certiﬁcate warning message, it was a lot easier
to simply accept all self-signed certiﬁcates.”

The consequence of this design decision was that all users of
this app were at risk because some wanted to use self-signed
certiﬁcates.

The iOS developers in our study tended to rely on frame-
works and libraries during development and were under-
standably startled and upset when told that their apps were
endangered because of faulty code generated by the frame-
work (cf. Appendix A):

“I am using the MKNetworkToolkit as a network wrap-
ping library and its SSL features for HTTPS. After you
informed me of the issue I checked the library’s code
and found that by default SSL certiﬁcate validation is
oﬀ. But, when I used the library in my app, I trusted
it and did not check for the SSL MITMA vulnerability
because it is a widely used library.”

“When I was starting to build apps for iOS, I had a
strong background in coding web applications. When I
came up with the Titanium framework that allows de-
velopers to build native mobile apps by writing HTML
and Javascript, I decided to use this framework just be-
cause it was easier for me. [. . .] I never thought that the
framework would produce broken code for SSL encryp-
tion and [. . .], although we conduct security audits for
our apps, we did not include SSL certiﬁcate validation
checks into the audit process.”

The feedback from app developers conﬁrms that develop-
ers struggle to implement SSL correctly when they have a
need to deviate from the standard use-case. They also rely
on the implementations of frameworks and libraries to pro-
tect their apps without thoroughly testing either the frame-
works’ or their app’s security. However, our investigation
also provides some new insights: developers modiﬁed certiﬁ-
cate validation code for internal testing purposes, e. g. work-
ing with arbitrary self-signed certiﬁcates on test servers, but
forgot about that and thus did not remove the code for the
production environment. So even those developers who un-
derstood the current need for signed and trusted certiﬁcates
put their customers at risk. Also, the developers’ problems
did not only lie in the complexity of the code, but were based
on a lack of understanding of how SSL works. There were
also some cases where developers turned SSL validation oﬀ
because of a customer’s request, either accepting or not real-
izing the implications. Even when we explained what could
go wrong and how to correct it, developers struggled when
trying to ﬁx their app (cf. Section 4.4). Altogether, our
results imply that code-level customization of SSL-handling
is an overwhelming problem for many developers and that
there is a fairly high level of frustration with the complexity
of adapting code to their use-cases.
4.3 Summary

After studying code snippets and advice in developer fo-
rums, as well as talking to app developers that use broken
SSL certiﬁcate validation, we believe that in most cases when
Android and iOS developers deviate from default SSL cer-
tiﬁcate validation strategies – that are secure on both plat-
forms by default – they apply customization features in a
way that weakens security signiﬁcantly (c.f. Section 6.2 for

a quantitative conﬁrmation). Many developers of aﬀected
apps seem to have only a partial understanding of what SSL
does and how it works. Yet, there are also developers who
complain about the bad support for self-signed certiﬁcates
and the lack of easy-to-use SSL warning messages.

One interesting aspect we found in the interviews was that
developers in general seem to be interested in providing a
high level of security for their users. We oﬀered all develop-
ers to help them with their SSL problems and most of them
took the oﬀer. After giving background information on the
security model of SSL and certiﬁcate validation, 10 of the
14 interviewed developers accepted our assitance. 7 of these
10 developers decided to strengthen their app’s security by
implementing SSL pinning. They did this because it gave
them full control over the SSL certiﬁcates trusted by their
app and they found that this was the most secure, ﬂexible
and cheapest way to provide a high level of security. We
provided the developers with code to integrate SSL pinning
based on Moxie Marlinspike’s github page3. All developers
agreed that being able to control exactly which certiﬁcates
their apps trust is a great way to increase security, but that
they would not have known how to do this without our help.
Our results imply that allowing app developers to cus-
tomize SSL handling on source-code level overburdens many
developers and leads to insecure apps. While it is easy to
weaken app security by removing the default SSL certiﬁcate
validation code, it is hard to strengthen it by implementing
pinning or other security-strengthening strategies. Only one
developer stated that using insecure SSL should not be taken
too seriously, which makes us believe that in most cases inse-
cure SSL connections are unintentional and that users must
be protected against careless developers and developers who
usually are no security experts.
4.4 Follow-up Analysis

Our developer study showed that many developers were
unaware of the dangers facing their SSL connections and in-
terested in ﬁxing the issues. Some of the developers who
accepted our help were capable of ﬁxing the SSL problems
in their apps. To analyze how developers cope with this sit-
uation without direct help, we ran a follow-up analysis. All
aﬀected developers (iOS & Android) were informed about
the vulnerabilities and the possible security consequences
for their users at the time of discovery of the vulnerability.
They were given the recommendation that they should ﬁx
the identiﬁed issues as soon as possible. Three months after
the respective notiﬁcations, we downloaded the apps again
to check if they had ﬁxed the SSL vulnerabilities. We found
that 51 of the 78 developers did not ﬁx the SSL issues. Six
apps were not available any more which means we could not
test them a second time. Only 21 (26.9 %) apps were ﬁxed
and implemented correct SSL certiﬁcate validation in their
current versions. Of these 21 apps, 9 belonged to developers
we had helped directly during the interview process. How-
ever, 5 of the 14 developers we interviewed did not ﬁx the
SSL issues in their apps. Furthermore, developers of an app
that included vulnerable SSL certiﬁcate validation on both
Android and iOS only ﬁxed it for Android while the iOS app
was still vulnerable in the second test.

The results of this follow-up analysis indicate that even af-
ter informing and educating developers about vulnerabilities
in their SSL code, problems in correcting these mistakes and
3https://github.com/moxie0/AndroidPinning

53deploying a safe solution still remain. Finding that 73.1 % of
all informed developers did not ﬁx the reported SSL issues
demonstrates even more that the current SSL mechanisms
on appiﬁed platforms need rethinking.

While there are well known usability problems with SSL
warning messages in browsers [16], we believe that allowing
developers to for instance silently ignore SSL errors and put
the user at risk is worse. We thus deﬁne an additional goal:

5. A NEW APPROACH TO SSL SECURITY

ON APPIFIED PLATFORMS

In the previous sections, we showed that incorrect SSL val-
idation is a widespread problem on appiﬁed platforms and
analyzed the causes of these issues. In a follow-up study, we
found that only a small part of previously vulnerable apps
had ﬁxed their app’s SSL vulnerabilities, even after we in-
formed the developers about the problems. In the following,
we propose a major change in how app developers use SSL
to address these issues. While we implemented our ideas
for the Android platform, they can serve as a blueprint for
increasing SSL security on other platforms such as iOS, but
also OS X and Windows 8 which are moving towards the
app paradigm as well.

Based on our analysis described above, we believe that
simplifying SSL libraries or trying to educate developers in
the context of SSL security will not solve the problem. For
most developers, network security is not a primary concern
and they just want to “make it work”. An ideal solution
would enable developers to use SSL correctly without cod-
ing eﬀort and prevent them from breaking SSL validation
through customization. However, it is also important not
to restrict their capabilities to produce functional (and se-
cure) applications: If our solution does not oﬀer the needed
functionality, developers will be tempted to break it just like
they are breaking the built-in SSL code at the moment.

Before going into detail, we summarize the desired fea-

tures for SSL validation identiﬁed during analysis:

Self-Signed Certiﬁcates – Development. Developers

commonly wish to use self-signed certiﬁcates for test-
ing purposes and hence want to turn oﬀ certiﬁcate val-
idation during testing.

Self-Signed Certiﬁcates – Production. A few develop-
ers wanted to use self-signed certiﬁcates in their pro-
duction app for cost and eﬀort reasons.

Certiﬁcate Pinning / Trusted Roots. Developers liked
the idea of having an easy way to limit the number of
trusted certiﬁcates and/or certiﬁcate authorities.

Global Warning Message. Developers requested global
SSL warning messages since they described building
their own warning messages as too challenging.

Code Complexity. Developers described the code-level

customization features of SSL as too complex and re-
quiring too much eﬀort.

In addition to these developer requirements, we add a user
requirement to our list of desired changes on how SSL is
handled in apps. We base this goal on the related area of SSL
handling in browsers. While a website can choose not to oﬀer
SSL at all, it cannot prevent the browser from warning the
user about an unsafe connection. The website also cannot
turn oﬀ SSL validation for the user. In the world of apps,
developers currently have the power to deﬁne SSL policies
for an app without those being transparent for the user.

User Protection. The capabilities of a developer should
be limited in a way that prevents them from invisibly
putting user information at risk.

To achieve all these features, several changes to the way
SSL is used on appiﬁed platforms are necessary. First and
foremost, we propose the following paradigm-shift: instead
of letting all developers implement their own SSL code (and
potentially break SSL in the process, with no chance for
the user to notice), the main SSL usage patterns should be
provided by the OS as a service that can be added to apps
via conﬁguration instead of implementation. This is a fairly
radical shift in responsibility, however, we believe there now
is enough evidence to warrant this move. Furthermore, the
evaluation of our system presented in Section 6 shows that
it is both technically possible and acceptable from the devel-
oper’s standpoint. Conﬁguration instead of implementation
also lends itself well to oﬀer other requested features, such
as allowing developers to turn oﬀ SSL certiﬁcate validation
for their app on their device in the settings during devel-
opment. This would allow the use of self-signed certiﬁcates
during development, but would not aﬀect the installation of
an app on a user’s device. Surprisingly, none of the major
mobile or desktop operating systems provide this feature,
although we believe it would oﬀer signiﬁcant beneﬁts to all
parties.

The platform should oﬀer conﬁgurable options for the new
SSL service so that developers cannot and need not circum-
vent security features on the code level. The simple removal
of the need to tinker with SSL security aspects for testing
purposes will already reduce the amount of vulnerable apps
signiﬁcantly. It will also protect users from developers who
do not understand how SSL works and who therefore make
honest mistakes during implementation.

Table 1 gives an overview of our proposed modiﬁcations

compared to the traditional code-level approach.
5.1 Implementation on Android

Figure 1 gives a high-level overview of the modiﬁcations
we implemented to create the proposed SSL service on An-
droid. The white boxes contain classes we modiﬁed or cre-
ated for our solution. The dashed lines show Android com-
ponents that are now circumvented since they proved to be
insecure. The grey boxes are comments on what the diﬀer-
ent components do. The start arrow shows the entry point
where app code passes control over to the central SSL sys-
tem. The features oﬀered by our solution are presented in
the following sections.
5.2 Features

5.2.1 Mandatory SSL Validation
As stated above, we propose that the capability and need
to customize SSL certiﬁcate validation and hostname veriﬁ-
cation on source code-level is removed. Instead, SSL certiﬁ-
cate validation should be enforced for every SSL handshake
automatically, while taking into account the diﬀerent usage
scenarios such as development vs. production.

54s
e
i
g
e
t
a
r
t
S
n
o
i
t
a
d
i
l
a
V
Standard (cid:88) — — — — —
(cid:88) P

g
n
i
n
n
i
P
e
t
a
c
ﬁ
i
t
r
e
C

n
o
i
t
a
d
i
l
a
V
A
C

g
n
i
n
n
i
P
A
C

t
n
e
m
p
o
l
e
v
e
D

(cid:88)

Our approach (cid:88)

(cid:88)

(cid:88)

e
d
o
M

g
n
i
g
g
o
L

Table 1: A comparison between the status quo and
our approach concerning validation features.
(cid:88) = supported out of the box;
− = custom code required;
P = pluggable.

Our modiﬁcations

Existing architecture

Force hostname
veriﬁcation

org.apache.http.conn.ssl

SSLSocketFactory

start

Force certiﬁcate validation;
Conﬁgurable by the users

android.net.ssl

TrustManagerClient

(in app)

uses

removed

uses

replaced by

javax.net.ssl

TrustManager

android.net.ssl

TrustManagerService

(in system)

Pluggable Certiﬁcate
Validation:
(CA-based validation, CT,
AKI, TACK, etc.)

Turn on/oﬀ SSLPinning,
Accept all certiﬁcates
on developer devices

conﬁgures

User options

Developer options

decisions

w
a
r
n

i
f

S
S
L

v
a
l
i

d
a
t
i
o
n

f
a
i
l
s

Warn the user if con-
nection is insecure

Human Com-
puter Interface

Figure 1: This ﬁgure illustrates the process of creat-
ing an SSL protected network connection. The grey
boxes comment on our contributions.

To this end, we provide the TrustManagerClient and Trust-

ManagerService that replace the capabilities of Android’s
default TrustManager (cf. Figure 1). We only modify meth-

ods which are private and ﬁnal, thus binary compatibility is
given and we do not break modularity. More information on
the compatibility of our approach can be found in Section 6.2
and Appendix B. Both the client and service part of our SSL
validation implementation prevent Android apps from us-
ing broken certiﬁcate validation. Upon creation of a socket,
the newly developed TrustManagerClient automatically re-
quests SSL certiﬁcate validation from the service counter-
part. App developers cannot circumvent secure validation
anymore, since customized TrustManager implementations
are prevented by our modiﬁcation. The TrustManagerSer-
vice enforces SSL certiﬁcate validation against the trusted
root CAs and can drop the connection or present the user
with a warning message in case validation fails (more on this
in Section 5.2.4).

To mandate secure hostname veriﬁcation, we patched all
stock hostname veriﬁers to enforce browser compatible host-
name veriﬁcation. We also added hostname veriﬁcation to
the central SSLSocketFactory (cf. Figure 1). Hostname ver-
iﬁcation is conventionally delegated to the application layer:
With HTTPS for example, the hostname for veriﬁcation is
extracted from the requested URL. In contrast, Android’s
SSLSocketConnection implementation does not check the
hostname, even though it may have been provided in the
method call. Our patch improves this behavior by verifying
hostnames with the parameters provided during connection
establishment for any SSL connection.

This strict enforcement could cause developer issues in
some usage scenarios described by our study participants,
so several conﬁguration options are described in the follow-
ing in order to adapt our solution to diﬀerent situations.
Additionally, we discuss potential pathological cases in the
appendix (see App. B.1).

Self-Signed Certiﬁcates

5.2.2
To allow developers to use self-signed certiﬁcates for test-
ing purposes, we add a new option (cf. Figure 2) to the
Developer settings, allowing app developers to turn oﬀ SSL
certiﬁcate validation for speciﬁc apps installed on their de-
vice without needing to modify the code of their app. This
option is monitored by the TrustManagerService and skips
certiﬁcate validation for this app only. These settings only
aﬀect the speciﬁc app on the developer device, not the apps
deployed onto users’ devices or other apps on the developer’s
device. Thus, even if developers forget to turn on certiﬁcate
validation again, this has no eﬀect on apps on user devices.
This feature eﬀectively protects users from forgetful devel-
opers and solves many of the problems we discovered during
code analysis and interviews.

We only allow this option on devices that have developer
settings enabled. Thus, app developers have a simple way to
work with self-signed certiﬁcates during development while
preventing careless users from turning oﬀ SSL certiﬁcate val-
idation for their apps.4 Nonetheless, we show a warning
message using strong wording that advises against abuse
(cf. Fig. 2(b)) when this option is toggled.

4While it is conceivable that users annoyed by warning mes-
sages could ﬁnd information online on how to activate de-
veloper options and then turn oﬀ certiﬁcate validation for a
speciﬁc app, we believe this risk is fairly low compared to
the huge beneﬁt this option brings. Additionally, we recom-
mend limiting this option to devices that are registered with
Google developer accounts to prevent normal users from

55(a) Developer settings to turn
oﬀ certiﬁcate validation for an
app. This option is not dis-
played for normal users.

(b) On disabling validation, a
message warns against security
threats.

Figure 2: Instead of writing code, SSL parameters
can be changed with via Developer settings options.

5.2.3 SSL Pinning
SSL public key pinning can be conﬁgured by app develop-
ers to limit the number of certiﬁcates an app trusts. It can
either be used to specify exactly which CA certiﬁcates are
trusted to sign SSL certiﬁcates for this app or directly specify
which individual SSL certiﬁcates are to be used. The stan-
dard Android approach to use certiﬁcate pinning requires
developers to implement it individually in their source code,
resulting in only very few apps implementing pinning at all.5
The standard approach for limiting the number of trusted
issuers is using a custom keystore, which is also complex
and requires custom code to load the keystore. Using our
extension, it is possible to conﬁgure SSL certiﬁcate pinning
in an Android app’s Manifest.xml ﬁle. This allows devel-
opers who know which endpoints their app connects to (this
should be most apps) to easily and securely add SSL pin-
ning without having to write any code. Figure 3 shows the
Manifest.xml for an Android app with SSL pinning.

Pinning individual leaf certiﬁcates also allows developers
to use self-signed certiﬁcates in a production environment
in a secure way, which is a requirement several app devel-
opers articulated (cf. Section 4). In case developers wish
to restrict the number of trusted issuers instead of pinning
individual leaf certiﬁcates, pins for certiﬁcate issuers can be
added to the Manifest.xml ﬁle in the same way. The app
then accepts only certiﬁcates issued by the pinned certiﬁ-
cate issuers. To simplify the process of creating certiﬁcate
pins and adding them to the Manifest.xml ﬁle, we extended
Eclipse’s Android Development Tools. This way pins for
given certiﬁcates can be generated and added to an app’s
Manifest.xml ﬁle automatically.

Since SSL public key pinning can be problematic in some
rare cases, for instance if a company mandates the use of
an SSL proxy6, we allow for SSL pinning to be disabled
globally using the (enterprise) Device Administration API
policies. While careless users cannot unintentionally turn
oﬀ SSL pinning since they do not have access to the De-

carelessly breaking their apps’ SSL security.
5One of these apps is the Twitter app by Twitter Inc., for
whom Moxie Marlinspike developed the SSL pinning code.
6Some companies use SSL proxy servers to monitor the net-
work traﬃc of their employees.

Figure 3: The new SSL conﬁguration options for an
Android app’s Manifest.xml ﬁle allow developers to
easily conﬁgure diﬀerent options for handling SSL.
Developers can pin either leaf or issuer certiﬁcates,
determine if their app should log SSL-relevant infor-
mation and observe how their apps react to failed
SSL certiﬁcate validations. By default no pin is set,
logging is turned oﬀ and apps refuse to connect to
hosts for which certiﬁcate validation failed.

vice Administration API, enterprises can conﬁgure devices
to respect company policies.

5.2.4 User Protection
Currently it is entirely up to the developers to implement
the UI to interact with the user when something goes wrong
with SSL. This has led to a large number of apps silently
accepting invalid certiﬁcates, crashing or displaying unin-
telligible warning messages such as: ”Reset your local time
to the current time” when faced with a certiﬁcate valida-
tion error. The lack of a ready-to-use warning message was
also an issue criticized by developers in our study. It should
also be impossible for app developers to invisibly accept un-
trusted certiﬁcates without the users’ consent. We oﬀer a
system-triggered, standardized warning that gives app users
the chance to recognize security threats originating from
insecure SSL connections, thus preventing app developers
from silently accepting invalid certiﬁcates. This capability
is needed for apps that connect to endpoints outside of the
control of developers and thus might not have trusted cer-
tiﬁcates, such as mobile browsers, news readers, blog aggre-
gators, etc.7. In these cases, the users are allowed to decide
if they want to connect anyway after being shown a warning
message.

Usability studies on SSL warning messages for browsers [16]
show that designing meaningful and eﬀective SSL warning
messages is a challenging task. Designing such a system is
outside the scope of this paper which is why we use An-
droid’s stock browser warning message for now. Still, we
think that having a standardized warning message that app
developers can use to let the user decide what to do with
untrusted certiﬁcates is a good starting point for such fu-
ture work. Issues such as habituation need to be taken into
account at that point, but showing any warning message is
better than allowing apps to silently accept all invalid cer-
tiﬁcates due to developers’ negligence.

7One of the developers we interviewed explicitly stated he
turned oﬀ certiﬁcate validation for his app entirely because
his customers wanted to connect to blogs with self-signed
certiﬁcates.

AndroidManifest.xml169    170    171    172    173    174    175    176    177    178<!-- SSLConfiguration for my App -->    179<ssl>180 <pinning>181  <!-- Only trust my self-signed certificate. -->182  <pin type="leaf" val="18:DA:D1:9E:26:7D..."/>183  <!-- And certificates signed by Verisign. -->184  <pin type="issuer" val="8F:57:5A:C8:5B..."/>185 </pinning>186 <logging level="INFO"/>187 <handle-validation-fails action="Do-Not-Connect"/>188</ssl>189190191</manifest>192Page 756While we no longer allow developers to silently accept con-
nections for which validation fails, we do allow developers to
be more restrictive and drop connections for which valida-
tion fails without allowing the user to override. This is the
correct (and default) behavior for most apps where the de-
veloper knows which endpoints the app communicates with
and these endpoints have valid certiﬁcates, such as online
banking, social networking and most other single purpose
apps. As long as developers exercise due diligence with their
server certiﬁcates, the only validation errors would be in the
presence of a real MITMA.8 In these cases, users would be
eﬀectively protected from themselves.

The decision of whether a warning message should be dis-
played or connections should be dropped was added as a
conﬁguration parameter to an app’s manifest (cf. Fig. 3).

Thus, our framework can protect users of multi-purpose
apps from developers who would hide warnings and accept
untrusted certiﬁcates as well as enabling developers to pro-
tect their users from accidentally accepting connections from
MITMAs for apps where the endpoints are known in ad-
vance.

5.2.5 Alternate SSL Validation Strategies
One feature which oﬀers promising future potential is the
capability of our system to plug new validation strategies
into the system and thus protect both new and existing
apps without requiring a large number of app developers
to update their code. This could signiﬁcantly speed up
the adoption of alternatives to the current weakest-link CA
based system. We have created a plugin infrastructure for
this purpose and are in the process of evaluating Certiﬁcate
Transparency (CT) [11] and AKI [10] as new approaches to
validate certiﬁcates. This feature is still in the experimental
phase and is currently conﬁgured into an app’s manifest. It
is a matter for future work to research how and by whom this
feature should be conﬁgured and of course to create plugins
to improve certiﬁcate validation.

6. EVALUATION

As Section 4 showed, all broken SSL implementations on
Android and iOS came about because developers wanted
to customize the way their app uses SSL and failed to do
so safely. While our new approach to SSL-development in
apps closes all the security holes we found, it will only be
adopted by developers if all their needs are met and they
feel comfortable with conﬁguration instead of coding. To
evaluate our approach, we conducted two evaluation studies.
We ran interviews with the 14 developers of our previous
developer study to discuss how they perceived our proposed
solution and if they would be comfortable using it. Since the
number of developers available for interview was fairly small,
we also did an extensive code analysis of all custom SSL-
handling code in the set of 13,500 Android apps to ensure
that all use-cases could be covered by our solutions and thus
remove the need for dangerous code-level customization.
6.1 Developer Evaluation

8We realize not all developers practice due diligence with
their certiﬁcates, however we still believe this to be the
right default setting. With this setting developers would
quickly realize that there is a problem with their certiﬁcate
and would be forced to update it.

We conducted a pre-test study in which novice developers
added SSL to their apps and used pinning and self-signed
certiﬁcates. Since our framework made all these tasks triv-
ial, we decided not to deploy this study on a large scale, since
it would not have led to any valuable insights. Instead, we
focused on whether the proposed paradigm shift would ﬁnd
the developers’ approval and make them feel comfortable
with conﬁguring SSL instead of implementing it. We pre-
sented our approach to the 14 developers from Section 4.2
and queried them if these features would fulﬁll their require-
ments and remove the need to customize the way their app
uses SSL. We also asked if they would feel comfortable us-
ing conﬁguration instead of coding to add advanced features
such as SSL pinning to their apps.

All use-cases of these developers were met with our new
design and the reaction of the developers was very positive.
They conﬁrmed their previous statements – that SSL devel-
opment is too complex – and that they very much appre-
ciated anything which would ease the burden. They were
particularly positive about the option to use self-signed cer-
tiﬁcates during development and to use pinning in such an
easy way for their production apps. None of the interviewed
developers were concerned that they could not fulﬁll their
certiﬁcate validation tasks with the provided conﬁguration
options. Due to the small number of developers willing to
discuss the problems they have with SSL development, we
decided to follow up this qualitative study with a quantita-
tive study.
6.2 Compatibility Evaluation

To evaluate whether our proposed solution really covers
all relevant use-cases, we ran another static code analysis on
the set of 13,500 Android apps [5]. We extracted all cus-
tomized TrustManager implementations and manually an-
alyzed the semantics of the checkServerTrusted methods.
Unlike in the previous study, we also analyzed the 2.04 %
of implementations that customized SSL handling without
breaking SSL. While there are not many apps in this cate-
gory, it is still imperative that these good apps also continue
to work as expected with our new approach. In total, we
found 3,464 classes that implement customized TrustMan-
agers. We categorized them based on their handling of SSL
validation compared to the default procedure. Table 2 gives
an overview of the customizations we found. We denote a
customization that weakens certiﬁcate validation with a “−”,
a customization that strengthens validation with a “+” and
customizations that do not aﬀect validation security with a
“=”.

Customized Implementations

Accept All Certiﬁcates
Expiry-Only Check
Leaf-Cert Pinning
Add Logging to Default Validation
Add Hostname Pinning to Default Validation
Limit Trusted Issuers

I

y
t
t
i
c
r
a
u
p
c
m
e
3,464 S
−
−
+
=
+
+

3,098
263
47
32
16
8

Table 2: Distribution of Customized TrustManager
Implementations in Android Apps

57In the 97.02 % of cases where TrustManagers accept all
certiﬁcates or only check certiﬁcates’ expiry dates, our ap-
proach protects app users from careless developers by enforc-
ing secure certiﬁcate validation. As we previously showed [5],
97.1 % of the endpoints in the 1,074 vulnerable apps had
valid certiﬁcates. In these cases, our modiﬁcation ﬁxes the
apps without any development eﬀort or negative side-eﬀects
for the developer or the user.
In the remaining 2.9 % of
cases, the endpoints used by the apps do not have valid
certiﬁcates.
In these cases, our system would prevent the
connection, unless the developer installs a valid certiﬁcate,
updates their application to pin the current certiﬁcate or
sets the handle-validation-fails option in the manifest
(cf. Fig. 3) to show warning messages. Since all three mod-
iﬁcations a developer would have to perform are very easy
in our framework, we believe this to be a good trade-oﬀ for
the broken apps.

While the majority of all implementations turns eﬀective
SSL certiﬁcate validation oﬀ entirely, a small number of de-
velopers created beneﬁcial customizations. 0.9 % of Trust-
Managers add logging to the default certiﬁcate validation
process. While this does not strengthen certiﬁcate valida-
tion itself, it still is a potentially positive feature that should
not be made impossible. We therefore added a conﬁguration
option (cf. Fig. 3) that allows developers to get log output
from the framework’s validation process.

0.5 % of implementations add hostname veriﬁcation di-
rectly to the certiﬁcate validation process. This strengthens
an app’s security since default SSL certiﬁcate validation does
not cover checking the hostname during the SSL handshake
outside of an HTTPSUrlConnection. This feature is covered
in our framework (cf. Section 5.2.1 above).

In the 1.6 % of cases where TrustManagers were used to
improve SSL validation (i. e. through pinning a leaf certiﬁ-
cate or a CA), the functionality added by the custom code is
available as a conﬁgurable option in our solution. Thus, we
found no custom SSL code which implements a use-case that
is not covered by our solution with signiﬁcantly less eﬀort.
We conducted ﬁeld trials that conﬁrmed this analysis.

6.3 Deployability

All our modiﬁcations are implemented as part of An-
droid’s Java Framework. A system update would thus be
the most convenient way to make the new features of our
system available to developers and users. All apps built
from then on would use this update by default and would
beneﬁt from our framework’s features. Existing apps’ bina-
ries do not need to be modiﬁed to beneﬁt. However, it is
possible for power users with root access to their device to
install our modiﬁcations on their devices without having to
wait for an oﬃcial update or having to make major changes
to their device, such as ﬂashing the device.

A noteworthy feature of our solution is that it does not
break binary compatibility and could in theory be used to
protect existing apps as well. Our modiﬁcations only aﬀect
private ﬁnal methods of the Java Framework and thus do
not break modularity or collide with developer code. This
would instantly ﬁx all the vulnerable apps we discovered in
our studies. However there are some rare pathological cases
which would need to be considered if our system were to be
applied to all apps blindly. We discuss these issues and the
possible trade-oﬀs in Appendix B.1.

7. LIMITATIONS

We contacted 78 developers and asked them to participate
in interviews about the identiﬁed SSL issues in their apps.
Only 14 developers agreed to participate in an interview
while all others either did not respond at all or turned down
our request with reference to company guidelines forbidding
them to talk about conﬁdential information. Despite the
relatively small number of participants, we were still able to
identify a wide range of causes which lead to serious security
issues in the context of app development and SSL. After the
developer study, we conducted a large scale code analysis
and did not ﬁnd any indication that there were further issues
that would warrant more interviews.

8. CONCLUSION

In this paper, we argue for a new way of handling SSL
connections on appiﬁed platforms, since previous work dis-
covered severe problems in this area. To discover the root
causes of these problems, we conducted a study of 1,009
iOS apps to ascertain whether iOS suﬀers from the same
problems as Android. We also surveyed developer forums
and conducted a developer study. Based on our ﬁndings, we
proposed to rethink how developers interact with SSL: in-
stead of requiring developers to work with SSL on the code
level, we designed and implemented a framework that allows
them to protect their network connections via conﬁguration.
Our solution prevents developers from willfully or acciden-
tally breaking SSL, while at the same time giving them easy
access to additional features, such as pinning and the secure
use of self-signed certiﬁcates. We evaluated our proposal
with existing Android apps and showed that all use-cases
we found can be implemented more easily and securely with
our approach. The feedback we gathered from developers
was also very positive.

There are several important areas of future work: Our
framework oﬀers all necessary features to include alternative
certiﬁcate validation strategies such as Certiﬁcate Trans-
parency and AKI just to name two. We are currently work-
ing on plugins for these proposals to implement these promis-
ing solutions. Since currently there is a great amount of
research being conducted on these alternative validation ap-
proaches, we believe our framework can make a valuable
contribution by enabling this research to be deployed with
greater ease and thus not only to be studied better but also
hopefully to help with real world adoption.

Furthermore, while we currently recommend our solution
to be adopted by new or updated apps, it is in theory pos-
sible to apply our changes to all existing apps, thus ﬁxing
all broken apps with one update. In future work, we will
investigate how to discover and avoid possible side-eﬀects
in apps that applied benign code modiﬁcations to the SSL
validation process. For more on this avenue of research, the
reader is referred to Appendix B.

Acknowledgments
We would like to thank all the developers that agreed to sup-
port our research, openly discussed security issues in their
apps and provided us with the background needed to design
our solution.

58References
[1] P. P. F. Chan, L. C. K. Hui, and S. M. Yiu. Droid-
Checker: Analyzing Android Applications for Capabil-
ity Leaks. In WISEC ’12: Proceedings of the Fifth ACM
Conference on Security and Privacy in Wireless and
Mobile Networks. ACM Press, Apr. 2012.

[2] L. Davi, A. Dmitrienko, A. Sadeghi, and M. Winandy.
Privilege Escalation Attacks on Android. In Proceed-
ings of the 13th International Conference on Informa-
tion Security, pages 346–360, 2011.

[3] P. Eckersley. Sovereign Key Cryptography for Internet
Domains. https://git.eff.org/?p=sovereign-keys.
git;a=blob;f=sovereign-key-design.txt;hb=
master.

[4] A. Egners, B. Marschollek, and U. Meyer. Messing
In Proceedings of

with Android’s Permission Model.
the IEEE TrustCom, pages 1–22, Apr. 2012.

[5] S. Fahl, M. Harbach, T. Muders, L. Baumg¨artner,
B. Freisleben, and M. Smith. Why Eve and Mal-
lory Love Android: An Analysis of Android SSL
(In)Security. In Proceedings of the 19th ACM Confer-
ence on Computer and Communications Security. ACM
Press, Oct. 2012.

[6] A. Felt, E. Ha, S. Egelman, A. Haney, E. Chin, and
D. Wagner. Android Permissions: User Attention,
Comprehension, and Behavior.
In Proceedings of the
Eighth Symposium on Usable Privacy and Security.
ACM Press, 2012.

[7] A. P. Felt, E. Chin, S. Hanna, D. Song, and D. Wagner.
Android permissions Demystiﬁed. In Proceedings of the
18th ACM Conference on Computer and Communica-
tions Security. ACM Press, Oct. 2011.

[8] M. Georgiev, S.

Iyengar, S. Jana, R. Anubhai,
D. Boneh, and V. Shmatikov. The Most Dangerous
Code in the World: Validating SSL Certiﬁcates in Non-
Browser Software.
In Proceedings of the 2012 ACM
Conference on Computer and Communications secu-
rity. ACM Press, Oct. 2012.

[9] P. Hoﬀman and J. Schlyter. The DNS-Based Authenti-
cation of Named Entities (DANE) Protocol for Trans-
port Layer Security (TLS): TLSA . https://tools.
ietf.org/html/rfc6698, Aug. 2012.

[10] T. Hyun-Jin Kim, L.-S. Huang, A. Perrig, C. Jackson,
and V. Gligor. Accountable Key Infrastructure (AKI):
A Proposal for a Public-Key Validation Infrastructure.
In Proceedings of the 2013 Conference on World Wide
Web, to appear, 2013.

[11] B. Laurie, A. Langley, and E. Kasper. Certiﬁcate
Transparency. Network Working Group Internet-Draft,
v12, work in progress. http://tools.ietf.org/html/
draft-laurie-pki-sunlight-12, Apr. 2013.

[12] M. Marlinspike. TACK: Trust Assertions for Certiﬁcate

Keys. http://tack.io/draft.html.

[13] M. Marlinspike. SSL And The Future Of Authenticity.

In BlackHat USA 2011, 2011.

[14] P. Saint-Andre and J. Hodges. RFC 6125, Mar. 2011.

[15] R. Schlegel, K. Zhang, X. Zhou, M. Intwala, and e. al.
Soundcomber: A Stealthy and Context-aware Sound
Trojan for Smartphones. Proceedings of the Network
and Distributed System Security Symposium, 2011.

[16] J. Sunshine, S. Egelman, H. Almuhimedi, N. Atri,
and L. Cranor. Crying Wolf: An Empirical Study of
SSL Warning Eﬀectiveness. In Proceedings of the 18th
USENIX Security Symposium, pages 399–416, 2009.

[17] T. Vidas, D. Votipka, and N. Christin. All Your Droid
Are Belong To Us: A Survey Of Current Android At-
tacks. In Proceedings of the 5th USENIX Workshop on
Oﬀensive Technologies, pages 10–10, 2011.

[18] D. Wendlandt, D. G. Andersen, and A. Perrig. Per-
spectives: improving ssh-style host authentication with
multi-path probing. In USENIX 2008 Annual Technical
Conference on Annual Technical Conference, ATC’08,
pages 321–334, Berkeley, CA, USA, 2008. USENIX As-
sociation.

[19] Y. Zhou and X. Jiang. Dissecting android malware:
Characterization and evolution.
In Security and Pri-
vacy (SP), 2012 IEEE Symposium on, pages 95–109,
2012.

APPENDIX
A.

IOS SURVEY DETAILS

Several of the vulnerable apps we found were created us-
ing popular programming frameworks. Since any bug intro-
duced by such a framework could potentially aﬀect a large
number of apps, we decided to take a closer look at these
frameworks. During our analysis, we identiﬁed two cross-
platform mobile application SDKs and an iOS networking
wrapper library that all create code that contains vulnera-
ble SSL certiﬁcate validation.

MKNetworkKit.

The MKNetworkKit9 is a networking wrapper library for
iOS with the aim to be easy to use and to simplify the
iOS default networking stack.
In online forums, such as
stackoverflow.com, developers often complain about prob-
lems with iOS’s built-in networking APIs, accounting for
the popularity of libraries such as MKNetworkKit, which
provides lightweight methods for standard networking tasks.
The library can also handle HTTPS requests, but fails when
it comes to SSL server certiﬁcate validation.

Titanium Framework.

The Titanium cross platform mobile application SDK10
is a JavaScript-based platform which enables developers to
write mobile apps in JavaScript and automatically trans-
lates them into native mobile apps. Titanium targets iOS,
Android and HTML5, making it particularly attractive for
web developers who want to create mobile apps. While the

9http://blog.mugunthkumar.com/products/
ios-framework-introducing-mknetworkkit/
10http://www.appcelerator.com/platform/
titanium-sdk/

59Titanium framework generates secure SSL code for Android,
SSL certiﬁcate validation for iOS apps is turned oﬀ. Based
on app creation statistics posted on their website, this could
aﬀect more than 30,000 apps built with the framework.

PhoneGap.

PhoneGap11 is a free open source framework for develop-
ing mobile apps for seven platforms including Android and
iOS, using HTML, CSS and JavaScript.
It contains dedi-
cated classes for data transfer that include customized SSL
veriﬁcation code. For Android and iOS, the framework pro-
duces code that eﬀectively turns SSL certiﬁcate validation
oﬀ. If developers do not manually check the generated code,
they will not see the comment and thus not be aware of the
problem. According to PhoneGap12, more than 23,000 apps
could be aﬀected.

B. TRANSITION PERIOD/COLD-TURKEY

UPDATE

With such a high number of users at risk and such a
slow/non-existent response time by developers when ﬁxing
the vulnerabilities, it might be worth considering activating
our framework not only for new apps but for all existing apps
as well. This would instantly ﬁx all instances of apps with
broken SSL we could ﬁnd. There are two ways in which our
framework could be deployed in such a case. The ﬁrst ap-
proach would simply override custom SSL code. This would
work ﬁne for 98 % of the 13,500 apps we analyzed and ﬁx
all the broken ones. However, the remaining 2 % would lose
important functionality (such as custom pinning) until the
developers update their apps. They would still have stan-
dard certiﬁcate validation but their custom improvements
would be disabled. So while applying our framework for all
apps in this way is simple and helps most apps, it would
be good to avoide this undesirable side-eﬀect. A second ap-
proach could combine our framework’s validation code with
the app’s custom SSL validation code. In this case, the sim-
ple rule would be only if both validation methods accept a
certiﬁcate, then the connection is established. If one of the
two validation processes rejects a certiﬁcate, a warning mes-
sage is shown to the user by our framework.13 The main
issue with this is that users could potentially see two warn-
ing messages for the same connection: In those cases where
validation legitimately fails and the developers of the app
followed best practices and warns the user and the users ac-
cepts the invalid certiﬁcate, our framework would also warn
the user and the user would have to accept again. While
this is not a security threat per se, it is a highly undesirable
characteristic to have in a system. However, our code anal-
ysis has shown that these cases should be very rare when
no MITM attacker is present. Thus this could be consid-
ered an acceptable trade-oﬀ to ﬁx the many vulnerabilities
which otherwise will remain unﬁxed for an unknown amount
of time. It might also be possible to get the developers of
the ”good“ apps to update their apps for the greater good by

11http://phonegap.com/
12http://www.slideshare.net/AndreCharland/
phone-gap-stats-growth
13For the cold-turkey approach, the default warning mecha-
nism would be switched from “drop connection” to “warning”
since we cannot automatically tell in advance if the app has
a legitimate reason to connect to untrusted hosts.

contacting them before the cold-turkey roll-out. Ironically
getting the few ”good“ developers to react is probably eas-
ier than getting all the developers with vulnerable apps to
react. However, evaluating and discussing the ramiﬁcations
of this kind of roll-out is beyond the scope of this paper and
would need to be discussed in the community.
B.1 Pathological Cases

There are some pathological cases that need to be consid-

IP Addresses Instead of Hostnames

ered when activating our framework for existing apps:
B.1.1
The current Android API allows URLs and socket con-
nections to be established with IP addresses instead of host-
names. Using an IP address has the drawback that host-
name veriﬁcation might not work properly. The concept of
virtual hosts for HTTP(S) servers hinders eﬀective hostname
veriﬁcation when an IP address is used to establish a con-
nection instead of a hostname, since common names for SSL
certiﬁcates typically are fully qualiﬁed domain names [14].
Yet, there are certiﬁcate authorities14 that issue certiﬁcates
with IP addresses as the common name. So, while creating
a secure connection using an IP address can cause problems
because hostname veriﬁcation fails, there is also a valid use-
case for this practice. Our SSL API treats IP addresses as
normal hostnames during hostname veriﬁcation.

We analyzed the set of Android 13,500 apps to ﬁnd those
that include URLs using IP addresses instead of hostnames
to estimate the scope of this practice in Android apps. In
all 13,500 apps, we found 163 apps (1.21 %) that include IP
address-based URLs, pointing to 118 diﬀerent hosts. 88 of
these IP addresses did not support SSL. Of the 30 which
supported SSL, only one of the remaining used a certiﬁcate
for which hostname veriﬁcation did not fail. However, this
certiﬁcate was self-signed, so none of the IP address-based
apps used SSL correctly.
B.1.2 Custom Sockets
If an app implements a custom application layer socket
that resolves hostnames by itself, it may rely on the SSLSock-
etFactory to create an SSL-secured socket based on only
an IP, but cater for hostname veriﬁcation itself at a later
stage. Given the modiﬁcations of our framework, this imple-
mentation would break, as our modiﬁed SSLSocketFactory
would attempt to verify the hostname (in this case the IP ad-
dress) during the handshake and fail because the hostname
in the certiﬁcate presented by the server is unknown to the
SSLSocketFactory. While it is uncommon to not delegate
hostname resolution to the operating system, we acknowl-
edge that such implementations would need to be updated
to work with our modiﬁcations.

14e. g. https://www.globalsign.com/

60