Automating Reverse Engineering with Machine Learning

Techniques

Blake Anderson
Los Alamos National

Laboratory

banderson@lanl.gov

Curtis Storlie

Los Alamos National

Laboratory

storlie@lanl.gov

Micah Yates

Los Alamos National

Laboratory

micah@lanl.gov

Aaron McPhall

Los Alamos National Laboratory

mcphall@lanl.gov

ABSTRACT
Malware continues to be an ongoing threat, with millions of
unique variants created every year. Unlike the majority of
this malware, Advanced Persistent Threat (APT) malware
is created to target a speciﬁc network or set of networks
and has a precise objective, e.g. exﬁltrating sensitive data.
While 0-day malware detectors are a good start, they do not
help the reverse engineers better understand the threats at-
tacking their networks. Understanding the behavior of mal-
ware is often a time sensitive task, and can take anywhere
between several hours to several weeks. Our goal is to au-
tomate the task of identifying the general function of the
subroutines in the function call graph of the program to aid
the reverse engineers. Two approaches to model the sub-
routine labels are investigated, a multiclass Gaussian pro-
cess and a multiclass support vector machine. The output
of these methods is the probability that the subroutine be-
longs to a certain class of functionality (e.g., ﬁle I/O, exploit,
etc.). Promising initial results, illustrating the eﬃcacy of
this method, are presented on a sample of 201 subroutines
taken from two malicious families.

Categories and Subject Descriptors
I.5.2 [Design Methodology]: Classiﬁer design and evalu-
ation; K.6.5 [Security and Protection]: Invasive software
(e.g., viruses, worms, Trojan horses

General Terms
Security, Algorithms, Experimentation

Keywords
Computer Security; Malware; Machine Learning; Multiple
Kernel Learning; Gaussian Processes; Support Vector Ma-
chines

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full cita-
tion on the ﬁrst page. Copyrights for components of this work owned by others than
ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or re-
publish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
AISec’14, November 7, 2014, Scottsdale, Arizona, USA.
Copyright 2014 ACM 978-1-4503-3153-1/14/11 ...$15.00.
http://dx.doi.org/10.1145/2666652.2666665.

1.

INTRODUCTION

Millions of unique variants of malware are created every
year, with McAfee labs cataloging more than 30 million new
samples in the ﬁrst quarter of 2014 [14]. The majority of this
malware is created through simple modiﬁcations of known
malware and is not intended to subvert sophisticated secu-
rity procedures. On the other hand, Advanced Persistent
Threat (APT) malware is created with the intention to at-
tack a speciﬁc network or set of networks and has a precise
objective, e.g. setting up a persistent beaconing mechanism
or exﬁltrating sensitive data. Because APT malware is much
more alarming, most incident response teams of large net-
works have several reverse engineers on hand to deal with
these threats.

A reverse engineer has the task of classifying the hundreds-
to-thousands of individual subroutines of a program into the
appropriate classes of functionality. With this information,
they can then begin to decipher the intent of the program.
But this is a very time consuming process, and can take
anywhere from several hours to several weeks depending on
the complexity of the program. At the same time, reversing
APT is a time critical process, and understanding the extent
of an attack is of paramount importance. And while 0-day
malware detectors are a good start, they do not help the
reverse engineers better understand the threats attacking
their networks.

In this paper, we have developed methods to aid the re-
verse engineer, speciﬁcally in the process of classifying indi-
vidual subroutines. Figure 1 illustrates a function call graph
visualized by the popular reverse engineering program, IDA
Pro [10]. The program in Figure 1 is a relatively small and
straightforward one.

The novel contribution this line of research makes is to au-
tomatically label each subroutine in the function call graph.
The subroutine label is modeled using a multiclass Gaus-
sian process or multiclass support vector machine giving the
probability that the subroutine belongs to a certain class
of functionality (e.g., ﬁle I/O, exploit, etc.). A multiview
approach is used to construct the subroutine kernel (or sim-
ilarity) matrix for use in the classiﬁcation method. The dif-
ferent views include the instructions contained within each
subroutine, the API calls contained within each subroutine,
and the subroutine’s neighbor information.

The process begins with a skilled reverse engineer labeling
subroutines into general, predeﬁned categories. The cate-

103104mov
lea
push
or
or
jmp
mov
mov
sub
adc
jc
push
or
...

esi, 0x0040C000
edi, [esi-0xB000]

edi

ebp, 0xFF
ebp, 0xFF
0x00419532

ebx, [esi]
ebx, [esi]
esi, 0xFC
ebx, ebx

0x00419528

edi

ebp, 0xFF

...

(cid:18)(cid:19)(cid:20)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:20)

(cid:18)(cid:19)(cid:23)

(cid:1)(cid:2)(cid:3)(cid:4)

(cid:18)(cid:19)(cid:23)

(cid:5)(cid:6)(cid:7)(cid:8)(cid:9)

(cid:18)(cid:19)(cid:20)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:22)

(cid:18)(cid:19)(cid:22)

(cid:18)(cid:19)(cid:21)

(cid:13)(cid:11)(cid:2)(cid:14)(cid:9)(cid:4)

(cid:18)(cid:19)(cid:20)

(cid:16)(cid:3)(cid:2)(cid:9)(cid:17)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:24)

(cid:18)(cid:19)(cid:22)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:21)

(cid:14)(cid:6)(cid:10)

(cid:18)(cid:19)(cid:20)

(cid:18)(cid:19)(cid:20)

(cid:10)(cid:11)(cid:8)(cid:12)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:21)

(cid:18)(cid:19)(cid:21)

(cid:18)(cid:19)(cid:25)

(cid:18)(cid:19)(cid:25)

(cid:6)(cid:3)(cid:4)(cid:15)(cid:11)

(cid:1)(cid:15)(cid:1)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:23)

(cid:18)(cid:19)(cid:25)

(cid:18)(cid:19)(cid:22)

Figure 2: The left table shows an example of the assembly instructions contained within a subroutine. A hypothetical resulting
Markov chain is shown on the right.

Type
File I/O
Process/Thread
Network
GUI
Registry
Exploit

# examples

44
42
70
21
18
6

Table 1: The number of each class of subroutines. The
dataset contained 201 subroutines in total.

registry, or exploit. These subroutines came from 2 APT
malware families and some random benign programs. The
benign programs were mainly used to get more examples of
the GUI category. There were 32 programs in total. The
number of each class of subroutines is given in Table 1.
2.1

Instructions

Assembly instructions have had a lot of exposure in the
literature [1, 4, 19, 23]. This is a fundamental view of sub-
routines, and we make use of it in this work. The assembly
instructions are ﬁrst categorized, i.e., there is a set number
of classes of instructions and all instructions seen fall into
one of the categories. In this work, 86 classes of instructions
are used, which are based on the pydasm instruction types.
Categorizations are used because there are a large number
of semantically similar instructions (e.g. add and fadd), and
this helps to limit the feature space to a manageable size.

There are several methods that can be used to repre-
sent the assembly instructions. The ﬁrst method we ex-
perimented with was simply as sequences and then use a
sequence alignment algorithm to compare the subroutines.
This seems to be the most intuitive method, but yielded
poor results and was orders of magnitude slower than the
chosen method.

Because the sequence alignment method did not work as
well as hoped, the instructions were modeled as a Markov
chain. The instruction categories are the nodes of the Markov
chain graph. In the Markov chain representation, the edge
weight, eij, between vertices i and j corresponds to the tran-
sition probability from state i to state j, therefore, the edge
weights for edges originating at vi are required to sum to 1,

(cid:2)

i;j eij = 1. An n × n (n = |V |) adjacency matrix is used
to represent the graph, where each entry in the matrix, aij
= eij. An example is shown in Figure 2 on a simple eight
category representation for ease of illustration.

2.2 API Calls

When a reverse engineer begins the process of understand-
ing the functionality of a program, the API calls performed
within the subroutine are highly informative. For instance,
“wininet.dll” contains API calls that are exclusively used for
network activity, and is a good indicator that the subrou-
tine containing those calls is related to network functional-
ity. The eﬃcacy of API calls for the program classiﬁcation
problem has been shown in other work [8, 19]. Our dataset
contains 791 unique API calls from 22 unique DLLs.

We tried several methods to encode the information from
the API calls, notably using a feature vector of length 791
for each unique API call and a feature vector of length 22
for each unique DLL. Based on early results, we settled on
using the feature vector of length 22, where each entry in
the vector corresponds to the count of calls to that speciﬁc
DLL within the subroutine.

2.3 Neighbor Information

Although API calls are clearly very informative, there ex-
ists a large number of subroutines that do not contain any
API calls. This prompted the use of neighborhood informa-
tion, with the assumption that the neighboring subroutines
of subroutine x will be likely to perform a similar function
to the neighboring subroutines of subroutine y, given that x
and y have the same label.

Two views are constructed with the neighbor informa-
tion, the incoming and outgoing neighbor views. Similar
to the API calls, a feature vector of length 22 (for the 22
unique DLLs) is used for each view. The incoming view is
constructed by counting all unique DLLs in every incoming
subroutine and setting the appropriate entry in the feature
vector. For example, in Figure 3, the counts of the blue
subroutines’ DLLs would be used to construct the feature
vector. The outgoing neighbor view is constructed analo-
gously.

1053.2 Classiﬁcation

Support Vector Machine.

A support vector machine searches for a hyperplane in the
feature space that separates the points of the two classes
with a maximal margin [6]. The hyperplane that is found
by the SVM is a linear combination of the data instances,
xi, with weights, αi. It is important to note that only points
close to the hyperplane will have non-zero α’s. These points
are called support vectors. Therefore, the goal in learning
SVMs is to ﬁnd the weight vector, α, describing each data
instance’s contribution to the hyperplane. Using quadratic
programming, the following optimization problem can be
eﬃciently solved:

(cid:5)

(cid:3)

n(cid:4)

max

α

i=1

αi − 1
2

n(cid:4)

n(cid:4)

i=1

j=1

αiαjyiyjK(xi, xj)

(3)

subject to the constraints:

n(cid:4)

i=1

αiyi = 0

(4)

(5)
Given α found in Equation 3, the decision function is de-

0 ≤ αi ≤ C
(cid:3)
n(cid:4)

(cid:5)

ﬁned as:

i

f (x) = sgn

αiyiK(x, xi)

(6)
which returns class +1 if the summation is ≥ 0, and class -1
if the summation is < 0. The number of kernel computations
in Equation 6 is decreased because many of the α’s are zero.
To perform multiclass classiﬁcation with the support vec-
tor machine, a one-versus-all strategy is used [9]. A classiﬁer
is trained for each class resulting in l scores, where l is the
number of classes (in our case, 6). This list of scores can
then be transformed into a multiclass probabilty estimate
by standard methods [25].

Gaussian Process.

Gaussian processes are a popular probabilistic alternative
to support vector machines for kernel learning. A Gaus-
sian process can be completely speciﬁed by a mean function,
m, and covariance (kernel) function, K, although the mean
function is often taken to be zero without loss of generality
[16]. They can be thought of as an inﬁnite For multiclass
classiﬁcation, we use multinomial logistic Gaussian process
regression [11]. For each class label, l, deﬁne

fl ∼ GP(0, K)

(7)

to be an independent Gaussian process with covariance ma-
trix K and positive training examples belonging to class l.
Let pl(x) be the probability of x belonging to thel th class,
and be deﬁned as:

pl(x) =

exp fl(x)

(cid:2)L−1
exp fl(x)
l=1
1
(cid:2)L−1
exp fl(x)
l=1

1+

1+

for l = 1, . . . , L − 1
for l = L

(8)

⎧⎨
⎩

p(x) is now a probability vector containing the probabilities
of belonging to each of theL classes.

The fl(x) are then conditioned on the training lables,
y, and a posterior distribution is obtained for fl(x), and

Figure 3: Illustration of the neighbor information used. For
a given red node, the incoming blue nodes and the outgoing
purple nodes are used.

3. METHODS

Kernel-based classiﬁers have been shown to perform well
on a wide variety of tasks [16, 18]. For this work, support
vector machines and Gaussian processes are used to classify
the subroutines. These methods are related [16], and both
rely on kernel matrices to perform their respective optimiza-
tions.
3.1 Kernels

(cid:2)
A kernel, K(x, x

(cid:2)

)(cid:4)

(cid:2)
K(x, x

) = (cid:3)φ(x), φ(x

), is a generalized inner product and can
be thought of as a measure of similarity between two objects
[18]. The power of kernels lies in their ability to compute the
inner product between two objects in a possibly much higher
dimensional feature space, without explicitly constructing
the feature space. A kernel, K : X × X → R, is deﬁned as:
(1)
where (cid:3)·,·(cid:4) is the dot product and φ(·) is the projection of the
input object into feature space. A well-deﬁned kernel must
(cid:2)n
satisfy two properties: it must be symmetric (for all x and
(cid:2) ∈ X: K(x, x
(cid:2), x)) and positive-semideﬁnite (for
x
j=1 cicjK(xi, xj) ≥
any x1, . . . , xn ∈ X and c ∈ R
0). Kernels are appealing in a classiﬁcation setting due to
the kernel trick [18], which replaces inner products with ker-
nel evaluations. The kernel trick uses the kernel function to
perform a non-linear projection of the data into a higher
dimensional space, where linear classiﬁcation in this higher
dimensional space is equivalent to non-linear classiﬁcation
in the original input space.

(cid:2)n

) = K(x

i=1

n

:

(cid:2)

If each view from Section 2 is treated as a feature vector,

a Gaussian kernel can be deﬁned:

K(x, x

(cid:2)

) = σ2e−λd(x,x(cid:2))2

(2)
(cid:2)
are the feature vectors for a speciﬁc view, σ
where x and x
and λ are the hyperparameters of the kernel function (de-
termined through cross-validation or MCMC), and d(·,·) is
the distance between two examples. The Euclidean distance
is used for d(·,·).

106107108109110synergy we are seeking between our methods/tools and the
reverse engineers who use them.

The ﬁrst attempt at constructing the similarity matrices
for use in the kernel classiﬁers was based on sequence align-
ment [19, 24]. While sequence alignment between two pro-
grams may be easily confused by simple reordering of basic
blocks and subroutines, we believed that the subroutines
would be homogeneous enough to avoid these problems. In
our initial tests, we found that the Markov chain represen-
tation performed slightly better with respect to accuracy,
much better in terms of the predicted probabilities of the
true class, and was orders of magnitude faster. Along these
lines, it would be foolish not to continue investigating the
subroutine metric space to ﬁnd better, more reliable ker-
nels. The most fruitful direction is most likely going to be
ﬁnding new ways of incorporating the graph structure and
neighborhood information, a direction we are pursuing.

As mentioned in Section 4, subroutines are not always
functionally “pure”, i.e., a subroutine can perform multiple
functions. We have shown that we can classify pure subrou-
tines with high accuracy. It would be interesting to design
methods that can robustly classify subroutines into more
than one class.

Along these lines, classifying subroutines into general cat-
egories can be seen as a ﬁrst step to classifying groups of
subroutines, or a sub-graph of the function call graph, into
more speciﬁc tasks. These tasks could include things such
as data exﬁltration or keylogging. These complex tasks are
often comprised of more than one subroutine. We are look-
ing at ways to cluster the function call graph using graph
structure and the general labels found in this paper to ﬁnd
the more speciﬁc task labels.

Assuming that we can accurately identify the speciﬁc tasks
of a program, such as data exﬁltration, keylogging, etc.,
building classiﬁers based on this information for the mal-
ware/benign problem for an overall program would seem like
a natural next step. One would expect malware to perform
several malicious tasks, but benign programs should, for the
most part, be free of these tasks.

To get the methods of this paper adopted for mainstream
use, a new user interface will need to be developed that can
be easily integrated into the workﬂow of a reverse engineer.
The reverse engineers of this project have been very willing
to test our prototype system, but it is highly unlikely that
all reverse engineers will be so willing to learn new tools.
A future plan is to integrate this line of research with the
highly used program, IDA Pro [10]. Creating a plugin for
IDA Pro that can automatically label the subroutines would
be far less disruptive and much more likely to be adopted
than a new web-based application.

7. CONCLUSIONS

Classifying programs as either benign or malicious is an
important ﬁrst step to stopping advanced APT malware,
but a simple binary decision does not give the analysts the
information they need to properly assess the threat. In this
paper, we presented a ﬁrst step in helping reverse engineers
understand a malicious program more quickly by classifying
the subroutines of the function call graph into six general
categories: ﬁle I/O, process/thread, network, GUI, registry,
and exploit. Support vector machines and Gaussian pro-
cesses were used for the classiﬁcation process. We showed

that we can achieve high accuracy (98.51%) on a set of 201
labeled subroutines.

8. REFERENCES
[1] Blake Anderson, Daniel Quist, Joshua Neil, Curtis

Storlie, and Terran Lane. Graph-Based Malware
Detection using Dynamic Analysis. Journal of
Computer Virology, pages 1–12, 2011.

[2] Blake Anderson, Curtis Storlie, and Terran Lane.

Improving Malware Classiﬁcation: Bridging the
Static/Dynamic Gap. In Proceedings of the Fifth ACM
Workshop on Security and Artiﬁcial Intelligence,
pages 3–14. ACM, 2012.

[3] Ulrich Bayer, Paolo Milani Comparetti, Clemens

Hlauschek, Christopher Kruegel, and Engin Kirda.
Scalable, Behavior-Based Malware Clustering. In
ISOC Network and Distributed System Security
Symposium. 2009.

[4] Daniel Bilar. Opcodes as Predictor for Malware.
International Journal of Electronic Security and
Digital Forensics, 1:156–168, 2007.

[5] Danilo Bruschi, Lorenzo Martignoni, and Mattia

Monga. Detecting Self-Mutating Malware using
Control-Flow Graph Matching. In Detection of
Intrusions and Malware and Vulnerability Assessment,
Lecture Notes in Computer Science, pages 129–143.
Springer Berlin / Heidelberg, 2006.

[6] Christopher J. C. Burges. A Tutorial on Support

Vector Machines for Pattern Recognition. Data
Mining and Knowledge Discovery, 2:121–167, 1998.

[7] Jianyong Dai, Ratan Guha, and Joohan Lee. Eﬃcient

Virus Detection Using Dynamic Instruction
Sequences. Journal of Computers, 4(5), 2009.

[8] Steven A. Hofmeyr, Stephanie Forrest, and Anil

Somayaji. Intrusion Detection Using Sequences of
System Calls. Journal of Computer Security,
6(3):151–180, January 1998.

[9] Chih-Wei Hsu and Chih-Jen Lin. A Comparison of
Methods for Multiclass Support Vector Machines.
IEEE Transactions on Neural Networks,
13(2):415–425, 2002.

[10] IDA Pro, Accessed 17 September 2013. http:

//www.hex-rays.com/products/ida/index.shtml.

[11] Balaji Krishnapuram, Lawrence Carin, Mario AT

Figueiredo, and Alexander J Hartemink. Sparse
Multinomial Logistic Regression: Fast Algorithms and
Generalization Bounds. IEEE Transactions on
Pattern Analysis and Machine Intelligence,
27(6):957–968, 2005.

[12] Christopher Kruegel, Engin Kirda, Darren Mutz,

William Robertson, and Giovanni Vigna. Polymorphic
Worm Detection Using Structural Information of
Executables. In Recent Advances in Intrusion
Detection, pages 207–226. Springer Berlin /
Heidelberg, 2006.

[13] Corrado Leita, Ulrich Bayer, and Engin Kirda.

Exploiting Diverse Observation Perspectives to Get
Insights on the Malware Landscape. In IEEE/IFIP
International Conference on Dependable Systems and
Networks, pages 393–402, 2010.

[14] McAfee. McAfee Threat Report, First Quarter, June

Accessed 15 July 2014.

111http://www.mcafee.com/sg/resources/reports/
rp-quarterly-threat-q1-2014.pdf.

[15] Eitan Menahem, Asaf Shabtai, Lior Rokach, and

Yuval Elovici. Improving Malware Detection by
Applying Multi-Inducer Ensemble. Computational
Statistics and Data Analysis, 53(4):1483–1494, 2009.

[16] Carl Edward Rasmussen and Christopher K.I.

Williams. Gaussian Processes for Machine Learning.
MIT Press, 2006.

[17] Konrad Rieck, Thorsten Holz, Carsten Willems,

Patrick D ˜Aijssel, and Pavel Laskov. Learning and
Classiﬁcation of Malware Behavior. In Detection of
Intrusions and Malware, and Vulnerability
Assessment, volume 5137 of Lecture Notes in
Computer Science, pages 108–125. Springer Berlin /
Heidelberg, 2008.

[18] Bernhard Sch¨olkopf and Alexander Johannes Smola.

Learning with Kernels. MIT Press, 2002.

[19] Madhu Shankarapani, Subbu Ramamoorthy, Ram

Movva, and Srinivas Mukkamala. Malware Detection
Using Assembly and API Call Sequences. Journal of
Computer Virology, 7(2):1–13, 2010.

[20] Qi-Man Shao and Joseph G Ibrahim. Monte Carlo

Methods in Bayesian Computation. Springer Series in
Statistics, New York, 2000.

[21] S¨oren Sonnenburg, Gunnar Raetsch, and Christin
Schaefer. A General and Eﬃcient Multiple Kernel
Learning Algorithm. Nineteenth Annual Conference
on Neural Information Processing Systems, 2005.

[22] S¨oren Sonnenburg, Gunnar R¨atsch, Sebastian

Henschel, Christian Widmer, Jonas Behr, Alexander
Zien, Fabio de Bona, Alexander Binder, Christian
Gehl, and Vojtech Franc. The SHOGUN Machine
Learning Toolbox. Journal of Machine Learning
Research, 11:1799–1802, 2010.

[23] Curtis Storlie, Blake Anderson, Scott Vander Wiel,

Daniel Quist, Curtis Hash, and Nathan Brown.
Stochastic Identiﬁcation of Malware with Dynamic
Traces. The Annals of Applied Statistics, 8(1):1–18,
2014.

[24] J-Y Xu, Andrew H Sung, Patrick Chavez, and Srinivas

Mukkamala. Polymorphic Malicious Executable
Scanner by API Sequence Analysis. In Fourth
International Conference on Hybrid Intelligent
Systems (HIS), pages 378–383. IEEE, 2004.

[25] Bianca Zadrozny and Charles Elkan. Transforming

Classiﬁer Scores into Accurate Multiclass Probability
Estimates. Proceedings of the Eighth ACM SIGKDD
International Conference on Knowledge Discovery and
Data Mining, pages 694–699, 2002.

112