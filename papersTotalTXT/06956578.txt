2014 IEEE Symposium on Security and Privacy

The Peril of Fragmentation: Security Hazards in

Android Device Driver Customizations

Xiaoyong Zhou∗, Yeonjoon Lee∗, Nan Zhang∗, Muhammad Naveed† and XiaoFeng Wang∗

∗School of Informatics and Computing

Email: {zhou, yl52, nz3, xw7}@indiana.edu

Indiana University, Bloomington
†Department of Computer Science

University of Illinois at Urbana-Champaign

Email: naveed2@illinois.edu

Abstract—Android phone manufacturers are under the per-
petual pressure to move quickly on their new models, continu-
ously customizing Android to ﬁt their hardware. However, the
security implications of this practice are less known, particularly
when it comes to the changes made to Android’s Linux device
drivers, e.g., those for camera, GPS, NFC etc. In this paper, we
report the ﬁrst study aimed at a better understanding of the
security risks in this customization process. Our study is based
on ADDICTED, a new tool we built for automatically detecting
some types of ﬂaws in customized driver protection. Speciﬁcally,
on a customized phone, ADDICTED performs dynamic analysis
to correlate the operations on a security-sensitive device to its
related Linux ﬁles, and then determines whether those ﬁles are
under-protected on the Linux layer by comparing them with
their counterparts on an ofﬁcial Android OS. In this way, we
can detect a set of likely security ﬂaws on the phone. Using the
tool, we analyzed three popular phones from Samsung, identiﬁed
their likely ﬂaws and built end-to-end attacks that allow an
unprivileged app to take pictures and screenshots, and even log
the keys the user enters through touchscreen. Some of those
ﬂaws are found to exist on over a hundred phone models and
affect millions of users. We reported the ﬂaws and helped the
manufacturers ﬁx those problems. We further studied the security
settings of device ﬁles on 2423 factory images from major phone
manufacturers, discovered over 1,000 vulnerable images and also
gained insights about how they are distributed across different
Android versions, carriers and countries.

I.

INTRODUCTION

The Linux-based open source Android platform has grown
into the mainstay of mobile computing, attracting most phone
manufacturers, carriers as well as millions of developers to
build their services and applications (app for short) upon it.
Up to August 2013, Android has dominated global smartphone
shipments with nearly 80% market share [8]. Such success,
however, does not come without any cost. The openness of the
system allows the manufacturers and carriers to alter it at will,
making arbitrary customizations to ﬁt the OS to their hardware
and distinguish their services from what their competitors offer.
Further complicating this situation is the fast pace with which
the Android Open Source Project (AOSP) upgrades its OS
versions. Since 2009, 19 ofﬁcial Android versions have been
released. Most of them have been heavily customized, which
results in tens of thousands of customized Android branches
coexisting on billions of mobile phones around the world. This
fragmented ecosystem not only makes development and testing
of new apps across different phones a challenge, but it also

brings in a plethora of security risks when vendors and carriers
enrich the system’s functionalities without fully understanding
the security implications of the changes they make.

Security risks in customizations. For each new Android ver-
sion, Google ﬁrst releases it to mobile phone vendors, allowing
them to add their apps, device drivers and other new features
to their corresponding Android branches. Such customizations,
if not carefully done, could bring in implementation errors,
including those with serious security consequences. Indeed,
recent studies show that many pre-loaded apps on those images
are vulnerable, leaking system capabilities or sensitive user
information to unauthorized parties [43]. The security risks
here, however, go much deeper than those on the app layer,
as what have been customized by vendors are way beyond
apps. Particularly, they almost always need to modify a few
device drivers (e.g., for camera, audio, etc.) and related system
settings to support their hardware. In our research, we found
that most customizations on the Android kernel
layer are
actually related to those devices (Section II-B), and they
are extremely error-prone, due to the complexity of Android
architecture and the security mechanism built upon it.

Android is a layered system, with its app layer and
framework layer built with Java sitting on top of a set of C
libraries and the Linux kernel. Device drivers work on the
Linux layer and communicate with Android users through
framework services such as Location Service and Media Ser-
vice. Therefore, any customization on an Android device needs
to make sure that it remains well protected at both the Linux
and framework layers, a task that can be hard to accomplish
within the small time window the vendors have to develop their
own OS version. Any lapses in safeguarding these devices can
have devastating consequences, giving a malicious app access
to sensitive user information (e.g., photos, audio, location,
etc.) and critical services they provide (e.g., GPS navigation).
However, with the complexity of Android’s layered system
architecture and limited device-related documentations avail-
able in the wild, so far, little has been done to understand the
security risks in such device customizations, not to mention
any effort that helps detect the threats they may pose.

Flaw detection. In this paper, we report the ﬁrst systematic
study on the security hazards in Android device customiza-
tions. Before we go to the details of this research, a few
terms used throughout the paper are explained in Table I. Our

© 2014, Xiaoyong Zhou. Under license to IEEE.
DOI 10.1109/SP.2014.33

409

TABLE I.

TERMINOLOGIES IN THIS PAPER

Term
Phone

Device
Device node or device ﬁle

Device-related ﬁle

Semantic
Mobile phone, e.g., Nexus 4, Samsung Galaxy SII.
Here we avoid using “device” to refer to phone.
Hardware on the phone, e.g., camera, GPS.
An
interface
driver,
/dev/null.
Files related to device operations, including device
nodes and other ﬁles such as logs.

device

e.g.,

for

a

study is based upon an automatic tool, ADDICTED, which
we designed to detect such customization hazards. The high-
level idea is to automatically identify the Linux ﬁles related to
the operations on the devices (e.g., phone’s camera) Android
intends to protect, and compare the levels of protection (in
terms of Linux ﬁle permissions) for the individual ﬁles on
a vendor’s version with those on the corresponding AOSP
version (called a reference in our research1). The rationale here
is that a Linux ﬁle related to a security-critical device operation
on the customized Android should not be less protected than
its counterpart on the reference. Otherwise, it can lead to a
security hazard. For example, we do not expect that the device
node (see Table I) for camera on the Samsung Galaxy SII is set
publicly readable and writable (a Linux permission of 666),
while its counterpart on Android 4.0.4 is accessible only by
system:camera user group (660). Actually, even if we do
not know the semantic of the ﬁle (i.e., the camera node), the
presence of the discrepancy in its Linux permission settings
across the two OSes, together with its relation with a dangerous
Android permission on devices (camera access), is sufﬁciently
alarming to justify a close attention.

To implement

this idea, we built

into ADDICTED a
component called Device Miner
that dynamically maps
permission-protected device operations (through APIs such
as Camera.startPreview()) on the Android framework
layer to their related ﬁles on the Linux layer. This requires
monitoring the way Android processes device-related service
requests across multiple layers (framework, libraries, Linux
and even hardware) over different phones, in the presence of
complicated event and call-back mechanisms, which cannot be
handled by existing techniques [26, 44]. Our design addresses
these technical challenges with a simple differential analysis
over the system call traces (recorded by strace [16]) with
and without a speciﬁc device-related operation. Device Miner
can further ﬁngerprint a device node with a set of system
calls involving the ﬁle and their parameters. The ﬁngerprint
serves to correlate device-related ﬁles on a customized phone
to those on its reference (the Nexus reference), even when they
have different names and are under different Linux groups.
Over such correlation information identiﬁed by Device Miner,
another component, Risk Identiﬁer, detects likely customization
ﬂaws (LCFs, i.e., a downgrade of the Linux protection level of
a customized device-related ﬁle) through the aforementioned
comparison (between the customized phone and its Nexus
reference).

We evaluated ADDICTED on a Google Nexus 4 with 4.2
and 4.3 and Samsung customized Android on Galaxy SII,
ACE 3 and GRAND. Our analysis discovered 4 LCFs across
those phones: oftentimes, device nodes that are supposed to

1In our research, we actually used Google’s customization of AOSP (for
Nexus phones) as the reference, as Google’s version closely follows the
original AOSP OS with minimum changes being made.

410

be protected to the system level have been exposed to the
public on the Linux layer; examples include input, camera
and frame buffer. We further conducted a case study
on three discovered LCFs and constructed end-to-end attacks
in which we take pictures and screenshots, and read touch-
screen coordinates on the phones without requesting relevant
Android permissions. As a prominent example, our analysis
found that on Samsung Galaxy SII, camera device node has
been made publicly accessible. To demonstrate the devastating
consequences once this vulnerability is exploited, we built a
carefully drafted attack app that directly commands the camera
driver to take pictures without being noticed by the phone
user, even when it does not have the permission to do so. This
problem affects over 40 million Galaxy SII users alone [12].
We reported our ﬁndings to Samsung, who acknowledged the
importance of this research and our ﬁndings. We are now
working with them to ﬁx those problems. Video demos of our
attacks can be found online [1].

Large-scale measurement. To understand the scope and mag-
nitude of such security hazards in device customizations, we
further scanned over 2423 factory images from Samsung, LG
and HTC for LCFs, through searching for the device-related
ﬁles on those images using the ﬁle names from AOSP images,
and inspecting the levels of their Linux-layer permission
protection. This large-scale measurement study led to the
discovery of 1290 problematic images and hundreds of under-
protected devices. It also yields several new interesting ﬁndings
not known before. For example, we found that most device-
related LCFs on Samsung Galaxy SII have never been ﬁxed,
even though its operating system was upgraded from 4.0, to
4.1 and later to 4.2. As another example, our research shows
that the customizations to the smartphones distributed in China
and Brazil have more potential security ﬂaws than those sold
in North America. We also measured the LCFs discovered on
different carriers’ customized phones and identiﬁed the most
vulnerable ones.

Contributions. We summarize the contributions of the paper
as follows:

•

•

New techniques. We developed a new technique that
made the ﬁrst step towards automated discovery of
security-critical vulnerabilities introduced during An-
droid device customization. The technique leverages
system-call level information to link the device opera-
tions protected by Android permissions to their related
Linux ﬁles, and a simple differential analysis to detect
the potential customization ﬂaws in those ﬁles’ pro-
tection. Our approach helps discovery of previously-
unknown critical security ﬂaws in real-world mobile
systems, which affect millions of smartphone users.

New ﬁndings. We performed the ﬁrst large-scale mea-
surement study on the security implications of An-
droid device customizations. Our research reveals a
large number of potential security ﬂaws within hun-
dreds of customized images, and sheds light on a
few important issues such as how such security risks
are distributed across different countries, carriers and
Android versions.

Roadmap. The rest of the paper is organized as follows:
Section II introduces the background of Android vendor cus-
tomization and a study we performed to understand the layers
of Android most heavily customized; Section III presents the
design and implementation of ADDICTED; Section IV de-
scribes a case study in which we analyzed customized devices
using ADDICTED and discovered high-impact security ﬂaws;
Section V reports our large-scale measurement study on the
security ﬂaws in device customizations; Section VI discusses
the limitation of the work and potential future research;
Section VII reviews the related research and Section VIII
concludes the paper.

II. VENDOR CUSTOMIZATIONS ON ANDROID

In this section, we provide some backgrounds for our
research and elaborate a study that helps to understand the
way Android is customized by different vendors.

A. Background
Android architecture and security model. As discussed
before, Android has a hierarchical architecture. On top of
the stack are various Android apps, including those from the
system (e.g., contacts, phone, browser, etc.) and those provided
by third parties. Supporting these apps are the services running
on the framework layer, such as Activity Manager, Content
Providers, Package Manager, Telephone Manager and others.
Those services mediate individual apps’ interactions with the
system and enforce security policies when necessary. The nuts
and bolts for them come from Android C libraries, e.g., SSL,
Bionic, Webkit, etc. Underneath this layer is the Linux kernel,
which is ultimately responsible for security protection.

The Android security model is built upon Linux user and
process protection. Each app is given a unique user ID (UID)
and by default, only allowed to touch the resources within its
own sandbox. Access to system resources requires permissions,
which an app can ask for at the time of installation. Decisions
on granting those permissions are made either by the system
through checking the app’s signatures or by the user. When
some permissions are given to an app, it is assigned to a
Linux group corresponding to the permission such as gps.
Resources on Android typically need to be protected on both
the framework layer and the Linux layer: the former checks
an app’s permissions and the latter is expected to enforce
security policies consistent with those on the framework layer
to mediate the access to the resources.

Vendor customization. Android is an open system. Google
releases the AOSP versions as baselines and different manu-
facturers (e.g, Samsung, HTC etc.) and carriers (e.g., AT&T,
Verizon etc.) are free to tailor it to their hardware and add new
apps and functionalities. Most of these Android versions from
the vendors have been heavily customized. For example, prior
research [43] shows that among all the apps pre-installed by
the major smartphone vendors (Samsung, HTC, LG, Sony)
on their phones, only about 18% come from AOSP, and
the rest are either provided by the vendors (about 65%) or
grabbed from third parties (17%). Under the current business
model, those vendors have a small time-window of about 6
months to customize the ofﬁcial version. This brings in a
lot of security issues: it has been reported that over 60% of

the app vulnerabilities found in a study come from vendor
customizations [43].

The primary reason for vendors to customize Android
is to make it work on their hardware. Therefore, the most
heavy-lifting part of their customization venture is always
ﬁtting new device drivers to the AOSP baseline. This is a
delicate operation from the security viewpoint: not only should
those new drivers be well connected to their corresponding
framework layer services, so that they can serve apps and
are still protected by permissions, but they also need to be
properly guarded on the Linux layer. Further complicating the
situation is the observation that a new device may require its
driver to talk to other existing drivers. The problem here is
that the latter’s permission settings on AOSP could block such
communication. When this happens, the vendor has to change
the driver’s security settings on Linux to accommodate the
new driver. An example is the camera device on Galaxy SII
that needs to use the UMP driver to allocate memory; for this
purpose, Samsung made UMP publicly accessible. So far, the
security implications of this customization are unclear.

Android Linux devices. Android inherits the way Linux man-
ages its device drivers and related ﬁles, in which both block
devices (e.g., ﬂash drives) and stream devices (e.g., virtual
terminals) are placed under /dev. Other devices like network
devices are placed under other directories (e.g., /sys). In
addition to those standard devices, Android further introduces
a plethora of new devices, such as camera, accelerometer,
GPS, etc., whose proper levels of security protection on
the Linux layer have never been made public. These new
devices have been heavily customized by vendors, who also
bring in an array of perplexing device-related ﬁles for their
new hardware pieces like CPU, graphic device, etc. Some of
such devices are security-critical, which are protected under
Android permissions or not even made available to apps such
as /dev/graphic/fb0.

Those devices,

if inadequately protected, can allow an
unauthorized app to get access to sensitive user data (e.g.,
locations, conversations, etc.) or critical system capabilities
(e.g., taking pictures). However, it is challenging to ﬁnd out
whether they are guarded to the level expected, as simply
correlating devices to their device nodes under /dev (or
/sys) can be hard. Except a few standard Linux devices,
Android never provides any documentation to explain the
device-related ﬁles under those directories. Different vendors
further add their customized device nodes, arbitrarily change
their names, group afﬁliations, etc. As a result, even ﬁnding the
counterpart for a given AOSP device node on a customized OS
can be difﬁcult. As an example, the near ﬁeld communication
(NFC) device node is /dev/bcm2097x-12c on the Nexus 4
Android 4.2, while on Samsung SII, it becomes /dev/pn544
as detected by ADDICTED. Without knowing the relations
between Android Linux devices and their drivers, little can be
done to ﬁnd out whether they are properly protected.

In our research, we made the ﬁrst, though preliminary,
step toward a better understanding of the security risk in
customizing Android Linux devices. Our idea is to use a
dynamic analysis to map a set of security-critical devices (in
Table IV) to their related Linux ﬁles, and then compare the
protection they receive with that provided on an AOSP Android

411

(again, Google-customized OSes in our research). This helps
us assess whether certain important devices become under-
protected during a customization (Section III).

Adversary model. The purpose of our research is to un-
derstand the security risks in customizing Android Linux
devices. To evaluate such risks, we assume the presence of
malicious apps on the phone running a customized Android
OS. These apps do not have root privileges, nor do they have
the permissions to use the devices under investigation, such as
camera, audio, GPS, etc. On the other hand, they are actively
seeking access to those protected devices through exploiting
the vulnerabilities introduced by the customization. We want
to understand whether such attempts can be successful.

B. Understanding Customizations

During a customization,

the vendor could change any
Android layer. In our research, we performed a study to
understand which layer has been heavily modiﬁed. The study
shows that changes mainly happen on the app layer and Linux
layer and rarely does the vendor touch the Android framework
interface such as services. On the Linux layer, most effort has
been made on device drivers to support new hardware. Here
we elaborate this study.

Methodology. To ﬁnd out where modiﬁcations happen,
we compared the source code of
two popular vendor-
customized phones – Samsung Galaxy SII (AT&T version
i.e. SGH-I777) and Samsung Galaxy Ace 3 (GT-S7270L)
– with their corresponding AOSP versions. Speciﬁcally,
we paired the source code GT-S7270_JB_Opensource
for Samsung Galaxy Ace 3 with its AOSP reference An-
droid 4.2 and kernel android-msm-mako-3.4-jb-mr2,
and SGH-I777_NA_JB_ATT_Opensource for Samsung
Galaxy SII with its AOSP reference Android 4.0.4 and kernel
android-samsung-3.0-jb-mr0. For each pair, we used
a diff-tool (DeltaWalker [3]) to measure how many ﬁles have
been added/modiﬁed/deleted under different directories during
Samsung’s customization of the AOSP code. DeltaWalker is
a ﬁle and folder comparison and synchronization tool. In our
study, it was conﬁgured to compare ﬁles based upon text (line
by line), as opposed to individual bytes. Before our analysis,
we also ﬁltered out ﬁles related to version control (e.g., .git
or .gitignore), and tuned the tool for accuracy, instead of
speed. The outputs of the analysis were sanitized to remove
the differences caused by whitespace and delimiters.

Findings. The results of the study are presented in Table II
and Table III. As is clear from the tables, changes made
on the Linux layer mainly happen to the driver source-code
directory, which involve hundreds or even thousands of ﬁles
being added, modiﬁed or deleted. The other directory with the
similar dynamic is arch, which contains different hardware-
related source code for processors. Actually, other directories
also contain code related to device drivers. However, even just
looking at the driver directory, we found that its modiﬁ-
cations are extensive compared with other directories. On the
framework layer, most of the customizations are either related
to device (/device/samsung/bcm_common) or new apps
(/vendor/samsung/common/packages), as presented
in Table III, while the service ﬁles under /framework have
not been touched at all.

TABLE II.

CUSTOMIZATIONS IN LINUX KERNEL

Path

/arch
/block
/crypto
/drivers
/ﬁrmware
/fs
/include
/init
/kernel
/lib
/mm
/net
/scripts
/security
/sound
/tools
/virt

Galaxy Ace 3
added/modiﬁed/deleted
1202/341/1029
0/10/1
0/0/0
958/661/1390
1/1/0
0/74/ 0
210/183/213
0/2/0
0/44/3
0/12/1
0/22/0
0/84/20
3/5/2
0/5/0
339/29/99
0/12/1
0/1/0

Galaxy SII
added/modiﬁed/deleted
695/244/407
0/7/0
1/12/0
2830/687/322
45/1/1
0/34/0
135/306/14
0/2/0
0/25/1
0/6/0
10/23/0
108/26/0
3/1/0
0/6/0
68/31/15
0/0/0
0/0/0

TABLE III.

CUSTOMIZATIONS IN ANDROID FRAMEWORK LAYER

Galaxy Ace 3
added/modiﬁed/deleted added/modiﬁed/deleted
2395/0/0

Galaxy SII

Path

/device/samsung/bcm common
/external/bluetooth
/external/chromium
/external/dnsmasq
/external/e2fsprogs
/external/iproute2
/external/iptables
/external/KeyUtils
/external/libexifa
/external/libjpega
/external/webkit
/libcore
/packages/apps/BluetoothTest
/packages/apps/.../mozilla
/packages/apps/Email/lib Src
/vendor/broadcom/common
/vendor/samsung/.../external
/vendor/samsung/.../frameworks
/vendor/samsung/.../packages
/framework

2/38/1
35/44/0
160/436/24
0/0/0
3/0/3

69/525/0
0/3/0

3/0/0
4/0/0
102/0/0
35936/0/0
0/0/0

3/26/0
0/0/19
0/4/0
1/2/2
1/0/0
0/0/28
3/0/0
60/0/0
40/0/0
31/238/0

2/0/0
58/0/0
807/0/0

0/0/0

III. AUTOMATED DETECTION OF SECURITY FLAWS IN

DEVICE CUSTOMIZATIONS

Our study shows that besides pre-installed apps, Linux
device drivers are the focus of vendor customizations (Sec-
tion II-B). To better understand the security risks that come
with such customizations, we designed and implemented AD-
DICTED (Android Device Customization Error Detector), a
suite of new techniques for automatic detection of the problems
in customized device protection. In this section, we ﬁrst
describe our high-level idea and then present the details of
our techniques.

A. Overview
The design. Given a set of security-critical Android devices,
it is nontrivial to ﬁnd out whether they are well-protected
on the Linux layer. Although, we may ﬁgure out the rough
locations of their related Linux ﬁles (most likely under /dev),
ﬁnding them in hundreds of ﬁles is difﬁcult. Even more
complicated is the evaluation of their protection levels under
Linux, which needs semantic information about what those
ﬁles indeed are (device nodes, log ﬁles, etc.). To address these
issues, towards automatic detection of customization ﬂaws, we
propose running a dynamic analysis to identify all the ﬁles

412

related to a customized device and then comparing the Linux
permission settings of those ﬁles with their counterparts on
the AOSP reference (the Android version installed on Google
Nexus phones). The rationale here is that there is no reason
for the vendor to lower the protection levels of such ﬁles,
particularly when they are related to a security-critical device.
The risks discovered in this way (i.e., LCFs) then need to be
further investigated to understand their security implications.

Based upon this idea, our design receives from the user
a list of devices to be analyzed. The Linux ﬁles for some
of
those devices could be well-known, such as the in-
put device (/dev/input/event*) and the frame buffer
(/dev/graphics/fb*) [7, 11], but most of them are
Android additions and therefore, less known (e.g., drivers for
camera, NFC, etc.). To identify these ﬁles, ADDICTED runs
a suite of test cases that serve as an input to the dynamic
analyzer. The analyzer traces the execution of the Android
system when it is processing these cases and operating on their
related devices, in an attempt to catch all the ﬁles necessary
for such operations. Each of these ﬁles is further ﬁngerprinted
by the way they are handled (e.g., system call types and
parameter values). The outcomes of this analysis on an AOSP
version (including ﬁles related to different devices and their
ﬁngerprints) serve as a reference. Such reference ﬁles are
correlated to those discovered from a customized Android
based on their ﬁngerprints, and further compared with them
in terms of individual ﬁles’ Linux permission settings. Once
any discrepancy is found, particularly when the customized
ﬁle has a lower protection level (e.g., system-only for the ﬁle
on AOSP and publicly readable on the customized version), a
security risk is reported.

Architecture. Figure 1 illustrates the design discussed above.
ADDICTED includes Device Miner, that performs the afore-
mentioned dynamic analysis on the test cases running on a
customized Android phone, and further analyzes its outputs
(including the system-call traces from multiple executions of
individual cases) to identify a set of ﬁles related to each device.
Those ﬁles and their ﬁngerprints are then handed over to Risk
Identiﬁer, which correlates them to those on the reference
AOSP version and reports an LCF once any of them is found
to be under-protected.

B. Device Miner
The approach. Device Miner is designed to trace operations
on an Android device to identify its related Linux device ﬁles.
Given the complexity of the Android architecture, this is by
no means trivial. Speciﬁcally, static analysis of Android is
complicated, given its layered structure with the framework
written in Java and the Linux kernel in C. When it comes
to dynamic analysis, existing tools like TaintDroid [26] can
support a variable and message level taint analysis. However,
to handle the complicated inter-process communication (IPC)
and message passing model within Android, it requires in-
tensive instrumentations of the OS. As a result, it becomes
less portable and unsuitable for analyzing a large number of
customized phones. Alternatively, DroidScope [44] performs
the analysis within a virtual machine, however, it cannot con-
veniently simulate different types of hardware on customized
phones or tablets.

7HVW
7HVW
&DVH
&DVH

5HI7HVW
&DVH

'HYLFH0LQHU

7HVW
5XQQHU

/RJV/RJV
ORJV

'\QDPLF
$QDO\]HU

7UDFHV
7UDFHV
WUDFHV

5LVN,GHQWLILHU

'LII

$QDO\VLV

'DWDEDVH

$2635HIHUHQFH

'HYLFH
&RUUHODWLRQ

/&)$QDO\VLV

/&)V
5HSRUW

Fig. 1. Design of ADDICTED. Test cases are ﬁrst executed by Test Runner
and analyzed by the Dynamic Analyzer. The logs and traces are analyzed by
the Diff Analysis tool to ﬁlter out irrelevant device operations and later sent
to Risk Identiﬁer to check for LCFs.

In our research, we built into Device Miner a dynamic
level. This makes
analyzer that works on the system-call
it coarse-grained in tracking device operations, but much
more lightweight and portable than prior approaches. More
speciﬁcally, Device Miner utilizes a suite of test cases to
trigger device operations such as taking pictures, requesting
geolocations, etc., and attaches strace [16] to the app that
runs those cases. The app does not directly access device
ﬁles sitting on the Linux layer, and hence it needs to send
an IPC to acquire relevant OS services to access them as
shown in Figure 2. To ﬁnd out the service that operates on
a given device, our approach leverages an instrumented binder
to follow the IPC call and identify the system process that
serves the app’s request, and then attaches strace to that process
and its children. On a customized device, this step can be
replaced by directly attaching straces to the processes and
services involved in execution of a test case, based upon a
model identiﬁed from running the same case on a reference
phone, so as to avoid modifying any OS code on the device.
In this way, Device Miner is able to observe all system level
activities when Android is operating on a target device, and
ﬁnd out all the ﬁles it touches. We further perform a differential
analysis to remove those unrelated to the device operations. In
Figure 2, we elaborate individual components of Device Miner.

Test cases. As an input to ADDICTED, we need to prepare
a list of security-critical devices. The devices we tested are
shown in Table IV. This list covers most (if not all) of the
common Android hardware protected by Android permissions2
(at the dangerous level). Also on it are some standard Linux
devices, whose device nodes are well known. Those devices

2Note that we did not include nonsensitive Android devices such as gyro,

accelerometer.

413

7HVW5XQQHU

$FWLYLW\

'DOYLN90

6HUYLFH
0DQDJHU
3UR[\

OLE%LQGHU

6HUYLFH3URFHVVHV

6HUYLFH
-1,

1DWLYH
OLE[[[
OLE%LQGHU

SDWWDFK

7UDFHU

7UDQVDFWLRQ

?@Q=DI?@M
%LQGHU'ULYHU

9HQGRU+$/
$/

?@QSSS

GULYHU

.HUQHO

Fig. 2. Dynamic Analyzer. In the ﬁgure, the dashed green (---) line describes
a conceptual RPC call and the solid green line (—) is the real call chain for
accessing hardware devices. The dash-dash-dot red (− · − · − ) lines show
how the tracer is attached to all the processes related to a device operation
and the dash-dot blue (-.-.-) line illustrates how this attachment operation is
performed by the binder.

TABLE IV.

SENSITIVE DEVICES: ANDROID-SPECIFIC OR

LINUX-INHERITED

Device

Camera

NFC
Audio
Radio

External
Storage
GPS

Bluetooth

Wiﬁ
Frame Buffer
Input
Subsystem
Block
Devices
VPN, PPP

Related Permissions

CAMERA

NFC
RECORD AUDIO
CALL PRIVILEGED
CALL PHONE
READ EXTERNAL STORAGE
WRITE EXTERNAL STORAGE
ACCESS COARSE LOCATION
ACCESS FINE LOCATION
BLUETOOTH
BLUETOOTH ADMIN
ACCESS WIFI STATE

Test Operations
or Device Node
Take pictures, change cam-
era settings
Send NFC tags
Play audio, record audio
Make phone calls

Write and read from exter-
nal storages
Read GPS data

Pair to a device, send a ﬁle

Enable wiﬁ, connect to wiﬁ
/dev/graphics/fb*
/dev/input/event*
/dev/uevent
/dev/block/*

BIND VPN SERVICE

/dev/vpn, /dev/ppp

are not analyzed by Device Miner and instead, directly sent
to Risk Identiﬁer for security checks. Note that even though
this list is not complete, the same methodology can be used
to evaluate other devices, once their test cases are added, to
improve the coverage of the analysis.

For each device on the list (except those standard Linux
devices), we built a test case, which is executed by Test Runner.
The app calls related APIs to operate on the device, such as
taking a picture, transferring a tag for an NFC device, etc. Such
a test case can be generated automatically using the testing
tools such as Randoop [13]. However, given the relatively
small number of devices and the complexity in automatic
construction of a correct call sequence and parameters, we
just manually developed those cases for our implementations.
Once this test suite is constructed, it can be executed upon
different customized Android phones automatically.

Dynamic analysis. As soon as Device Miner starts the Test
Runner, it attaches a tracer (a wrapper of strace) to the app’s

process. The app needs to make API calls to access its target
devices. In Android, such an API call goes through the binder
driver in the kernel, which passes the request to a system
service. This interaction is called a transaction as shown in
Figure 2. Device Miner includes an instrumented binder that
monitors the processes communicating with the test app and
attaches tracers to them.

Speciﬁcally, our approach instruments binder.c with
the code for inspecting individual transactions. This can be
done automatically, given the binder’s source code has not
been changed signiﬁcantly across different Android versions.
Later we will discuss an alternative to avoid even this mostly
automated instrumentation.

During its runtime, this modiﬁed binder checks the trans-
action parameters of an IPC call to extract the source Process
Identiﬁer (PID) of the transaction and its target PID, together
with the transaction data. The source PID is directly retrieved
from binder_proc.pid and the target one is obtained from
target_node, which is referred by target_handler
embedded in the transaction data. Those PIDs are further
mapped to package names retrieved from process memory
using access_process_vm. If either party in the IPC
(source or target) is found to be the test app, based upon
its package name, Device Miner attaches a tracer to the one
that has not been monitored yet. Those tracers log all their
processes’ ﬁle operations, such as ioctl, read and write.
They are also capable of parsing some parameters for the
ﬁle operations, which are important to ﬁngerprinting a ﬁle
(Section III-C).

A problem for our dynamic analysis is instrumentation
of the binder. Although this can be done automatically on
Android source code, we still need to compile the instrumented
code and install it on every customized device, which makes
the approach less portable. To address this issue, we further
leverage the way the AOSP OS handles a service to simplify
the analysis. Speciﬁcally, as discovered in our research (Sec-
tion II-B), mobile phone vendors rarely modify the framework
layer services during their customizations. Particularly, they
tend to leave the package names of the services intact, because
otherwise, a large number of program locations referring those
packages need to be adjusted as well. Therefore, we can
assume that the names of the services working on a device-
related request stay unchanged across different Android OSes
(though the names of device drivers could be different). In
this case, Device Miner can build a model for running each
test case, based upon what it observes on the AOSP OS (the
reference), to record all the packages involved in handling its
device-related requests. On a customized system, our approach
automatically attaches tracers to all the processes of those
packages during the operations of the test case to monitor
ﬁles they drop. Since we do not need to change the OS to run
strace, the whole Device Miner becomes completely portable
across different Android phones. There could be a problem
when some vendors indeed touch the framework layer. In this
case, we need to install the instrumented binder on the device
and run the test again.

Differential analysis. To achieve portability, Device Miner
tracks device operations at the system-call level, which is
coarse-grained. For the Linux ﬁles discovered this way, we

414

do not know whether they are indeed related to the device
or just the noise introduced by other processes running in
the background. To remove such random noise, our approach
further performs a differential analysis on the outcomes of
an analysis, comparing them with those produced by other
independent
tests. Speciﬁcally, we run the same test case
multiple times, independently, until the set of the ﬁles touched
by all those executions no longer change (which indicates that
those ﬁles are related to the test case, not other processes).
This ﬁlters out ﬁles that are touched by other concurrently
running processes. Then, we invoke the test case again, and
this time, the app attempts to access the target device without
a proper permission and naturally will not get what it asks for.
The outputs we observe from this execution are used to remove
the ﬁles from the intersection produced by the prior runs, since
those ﬁles do not contribute to the normal operations on the
target device. In this way, we get a “sanitized” list of ﬁles that
are very likely to be directly related to the device.

C. Risk Identiﬁer

Given a list of Linux ﬁles related to a device, as identiﬁed
by Device Miner, we need to ﬁnd out whether their security
protection levels are properly set. The problem is that even
though we know the device protected by a dangerous or
signature permission on the framework layer, we still have
no idea whether the Linux permissions assigned to the ﬁles
are appropriate, given that there is little semantic information
about what those ﬁles indeed are. For example, it would be
natural to have null device node less protected than other
device nodes. Even given such semantic information, AOSP
has never made it clear how to set the Linux permissions for
a device-related ﬁle properly based on its protection at the
framework layer. To work around such complexities, in our
research, we simply take the way those device-related ﬁles
are conﬁgured on AOSP OSes as references and compare
the security settings of a ﬁle on a customized OS with its
counterpart in the reference. Note that we do not assume
here that AOSP always makes device protection right on the
Linux layer, though the references are typically less error-
prone than their customized counterparts. Our point here is
that if a customization makes a highly-protected ﬁle related
to a security-critical device on the original AOSP version
less protected, there could be a security issue (i.e., a LCF).
Also, nor do we consider that our approach can ﬁnd us most
customization errors: after all, it cannot handle new devices
and their ﬁles that never show up on the reference OS.
Nevertheless, our study demonstrates that even this simple,
ﬁrst-step approach can already detect security-critical and also
high-impact vulnerabilities in customizations (Section IV).

To implement this idea, we need to correlate device ﬁles
on different phones and detect LCFs through the aforemen-
tioned differential analysis. Risk Identiﬁer is designed for this
purpose. Here we elaborate how it works.

Device ﬁle correlations. To customize an AOSP version
to ﬁt their hardware, vendors typically need to add to the
system their own device drivers and other supporting ﬁles.
Compared with their AOSP counterparts, these ﬁles could have
different names and be assigned to different Linux groups,
as observed in our study (Section IV). For example,
the
camera device node on Nexus 4 (with an Android 4.2) is

video0 or video1 under the group camera, while on
GRAND, it becomes vc-cam and afﬁliated with the Linux
group system. Correlating such a ﬁle to their counterpart
on a reference OS can become nontrivial when Device Miner
outputs multiple device-related ﬁles on both sides. Here we
describe how Risk Identiﬁer establishes such a connection.

Our approach ﬁrst ﬁngerprints those ﬁles based upon how
they are operated by system calls. Speciﬁcally, for each ﬁle,
we look at the set of system calls that touch the ﬁle, and the
content and other features of those calls’ arguments. For the
arguments that pass values to a system function, strace can
often parse them to ﬁnd their content. Since the designs of
customized devices (camera, video, Bluetooth, etc.) tend to
follow their industry standards, oftentimes, the content of the
arguments for their related system calls can be informative
enough for establishing the relation between two device nodes
built according to the standards. For example, different camera
devices designed according to the V4L2 driver framework [17]
all share some arguments for the ioctl call that operates
on them, such as 0x560f (parsed into VIDIOC_QBUF).
Therefore, whenever two device-related ﬁles are found to have
some of such standard arguments (automatically identiﬁed by
strace) in common, they are considered to be related. In the
case that Risk Identiﬁer cannot ﬁnd such common arguments,
it further checks the set of system calls that happen to each ﬁle
to connect customized ﬁle to the reference one. This approach
works particularly well on the device whose operations need to
go through a standard procedure. An example is NFC, whose
call sequence is always (select, read, write) with the
2nd arguments of read and write being well-formatted NFC
streams, even when the drivers are heavily customized, with
different ﬁle names and group memberships. Note that given
a device node on the reference side, all we need to do here is
just to determine which customized ﬁle (out of several ones
reported by Device Miner) is more likely to be its counterpart.
This can often be done, since Android processes device nodes
differently from other ﬁles, such as logs.

LCF detection. After pairing individual device ﬁles on a
customized phone with those in a reference, an analysis tool
starts checking their Linux ﬁle permissions. For a pair of
device ﬁles, what we are looking for there is any discrepancy
in their permission settings. For example, if the one within the
reference is made readable and writable only to group members
while the other is open to the public, then our approach imme-
diately reports discovery of an LCF. More complicated is when
these two ﬁles end up in different Linux groups: for example,
one in camera and the other in system. We consider this
practice risky, though it may not lead to any exploitable ﬂaw.
The rationale is that Android maps permissions to different
Linux groups and as a result, change of a resource’s group
afﬁliation could open an unexpected avenue for unauthorized
access. Of course, in most cases, such afﬁliation changes may
not result in security-critical vulnerabilities. A device ﬁle found
to have this problem is thus just marked as risky, and will not
be alarmed as an LCF.

IV. FINDINGS AND ATTACKS

In our study, we ran our implementation of ADDICTED
on four smartphones to analyze the security protection of their
Linux devices. These phones include a Google Nexus 4 with

415

an Android 4.2, a Samsung Galaxy SII with a customized
4.0.3, a Galaxy ACE 3 with a 4.2.2 and a Galaxy GRAND
with a 4.1.2. ADDICTED instrumented the binder on the
Nexus 4 to identify the device ﬁles for our test suites. It also
built up a model for each test case, recording the packages
involved in handling its device access request. All the device
ﬁles discovered from the rest three phones were compared
with their counterparts on the Nexus 4, which served as
the reference, to identify their LCFs based on their Linux
permission settings.

This study discovered 4 LCFs and all of them were
conﬁrmed to be indeed problematic. Particularly, we performed
an in-depth study on 3 such ﬂaws3 and came up with end-to-
end attacks on them. These attacks enable a malicious app,
without relevant permissions, to log the keys the phone user
enters on her touchscreen, and to take pictures or screenshots
stealthily. Some of these ﬂaws were found to be extremely per-
vasive, affecting millions of smartphone users, as discovered
by our measurement study reported in Section V. Following
we elaborate this research.

A. Findings
Device ﬁles identiﬁed. On the Nexus 4 (the reference),
ADDICTED automatically identiﬁed the ﬁles associated with
individual devices. Table V illustrates our ﬁndings. For NFC
devices, only a single ﬁle was found for each of them, which
turned out to be their device nodes. Other devices are more
complicated. For example, on Nexus 4, the front video device
is video1 while on Galaxy SII, it becomes video0 for
both front and rear (more details in IV-B). In the case of
Galaxy GRAND, vchiq is its camera controller and vc-cam
is its device node. Device ﬁles’ group memberships may
vary as well. For example, on Nexus 4, the camera device
node is with system:camera, on Galaxy SII the group
becomes system:root and on GRAND it
to
be system:system. Vendors did not follow any guideline
when conﬁguring the Linux settings of their customized device
ﬁles. With such a diversity, those device ﬁles were all identiﬁed
by Device Miner.

turns out

LCFs detected. Those ﬁles were further correlated by Ref-
erence Identiﬁer through their system call set and call argu-
ments. As an example, Table VI shows the argument-level
connections between camera device nodes on Nexus 4 and SII.
By comparing the device-related ﬁles on the three customized
phones with those on the reference, ADDICTED reported 4
LCFs, which are presented in Table V. Most problems come
from obvious erroneous settings of sensitive device ﬁles to
publicly accessible. We manually inspected those cases, which
all look indeed problematic: the camera device nodes on SII
and GRAND, the input device on SII, and the frame buffer on
Galaxy ACE 3 are set to be publicly readable and writable.
We further built end-to-end attacks to exploit one of these two
camera ﬂaws and the LCFs with the input device and the frame
buffer to demonstrate the seriousness of the problem.

B. Attacks

To understand the seriousness of the LCFs we discovered,
we thoroughly analyzed the 3 vulnerabilities and built end-

to-end exploits on them. These vulnerabilities include the
exposure of the input device node and camera device node
on Galaxy SII, and the unprotected frame buffer on Galaxy
ACE. We found that those ﬂaws can be exploited by an app
either without any permission or with unrelated ones such
as WRITE_EXTERNAl_STORAGE (for the purpose of storing
collected data). Some of such attacks can be quite complicated,
due to the lack of documentations about those customized
devices. We reported all our ﬁndings to Samsung and Google
and are currently working with them to ﬁx those ﬂaws.

Touchscreen Keylogger. On Galaxy SII, ADDICTED discov-
ered that part of the standard Linux input driver ﬁles (e.g.,
/dev/input/event2)4 are made public. This problem
was also found on a series of other phones, as reported by
our measurement study (Section V). On Android, the input
system is used for dispatching events to different services and
delivering to them the data received by sensors like gyro and
compass and other input hardware such as touchscreen and
keyboard. Once the device ﬁles are exposed, any party can
get from them sensitive sensor data and user inputs. In our
research, we show that a touchscreen keylogger can be built
by exploiting this vulnerability.

The Android input system includes three components,
EventHub, EventReader and EventDispatcher.
EventReader reads from different driver ﬁles (through
EventHub) the data collected by sensors or input hardware
and converts them into different events such as KeyEvent,
MotionEvent etc. These events are dispatched to proper
windows through EventDispatcher.

Now that all the device ﬁles are up for grabs, we im-
plemented our own input reader to directly collect data from
them, in the absence of proper permissions. Speciﬁcally, our
reader is designed to work on touch events and capable of
extracting the coordinates (ABS_X, ABS_Y) of any touch on
the screen, together with its status (ABS_PRESSURE with 0
for up and 1 for down). The input reader can be embedded into
a malicious app running in the background and silently logging
all the touch events from the screen. Since a phone’s keyboard
layout is ﬁxed, the app can easily identify all the keys the
user enters from those events. The consequence of this attack
is serious, which allows an unprivileged adversary to steal the
phone user’s password and any sensitive information she types
through the touchscreen. Given the popularity of Galaxy SII
and other phones with the same vulnerabilities, this problem
affects millions of Samsung customers. A video demo of the
attack [1], which shows the input reader recording coordinates
of touch events, is posted online.

Camera attack. Our automatic analysis detected the exposure
of the camera device node on Galaxy SII, a problem that
also exists on other popular phones (Section V). Speciﬁcally,
the ﬁle (/dev/video0) of Galaxy SII was correlated to the
device node on the reference from their argument ﬁngerprints,
and it was also found to be public. With this device node’s
complete disclosure, one can take pictures without any camera-
access permission in theory. However, exploiting this ﬂaw
in practice is highly nontrivial, as the driver is customized
and Samsung never provides any documentation about how

3The two camera LCFs are similar. We just exploited one of them.

4The number may change depending on the systems and conﬁgurations.

416

TABLE V.

LCFS DETECTED BY RISK IDENTIFIER

Device

camera

input
framebuffer

Nexus 4
/dev
video0(rear)
video1(front)
input/event*
graphics/fb*

Galaxy SII
/dev

mod owner
660
660
660
660

system:camera video0(front)
system:camera video1(rear)
input/event*
root:input
root:graphics
graphics/fb*

Galaxy ACE 3
/dev
owner
system:root
video0
system:camera video1
root:input
root:graphics

mod
660
660
input/event* 660
graphics/fb* 666

mod
666
666
666
660

owner
system:camera
system:camera
root:input
system:graphics

Galaxy GRAND
mod
/dev
666
vchiq
vc-cam
666
input/event* 660
graphics/fb* 660

owner
system:system
system:system
root:input
root:graphics

to directly work on it. Following we describe our end-to-end
attack on this vulnerability.

rear channel

To communicate with the camera device, we ﬁrst tried the
operation sequence speciﬁed by the V4L2 standard [17] as
shown on the left column of Table VI. This approach turned
out to be ineffective and keep crashing and rebooting the
phone when we invoked the command VIDIOC_ENUM_FMT
through ioctl, which itself is a denial-of-service attack. To
ﬁnd out the correct way to take a picture, we ﬁrst analyzed
traces collected from normal operations
the system-call
of the camera on SII and found that
the sequence here
is different from that on Nexus 4. Speciﬁcally, we found
that
in Samsung SII, video0 is for both its front and
rear camera and a camera client needs to select the front
or
through VIDEO_S_INPUT before using
the camera. Even after we made the sequence right, our
app still caused the system to crash at VIDIOC_S_FMT, a
command for specifying the format parameters for pictures.
By digging the speciﬁcations for the camera chips used in
the phone (S5K5BAFX and M5M0), we ﬁnally realized
that Samsung customized the V4L2 protocol deﬁned in
videodev2.h with new settings. For example, the V4L2
standard buffer type v4l2_buf_type has been extended by
V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE,
adding
and
V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE
V4L2_BUF_TYPE_PRIVATE. We ended up implementing
the whole Hardware Abstract Layer (HAL) within our app,
based upon an open-source driver for the same chips [15].

Using our own HAL, we successfully commanded our at-
tack app (without any camera permission) to open the camera,
take pictures, retrieve camera raw data from the exposed device
and covert them from the YUV color space [18] to the RGB
color space [14] for constructing images.

TABLE VI.

DIFFERENCE OF CAMERA OPERATIONS ON NEXUS 4 AND

SAMSUNG SII

Nexus 4
open
VIDIOC QUERYCAP

Samsung SII
open
VIDIOC QUERYCAP
VIDIOC ENUMINPUT
VIDIOC S INPUT
VIDIOC S CTRL*

VIDIOC ENUM FMT

VIDIOC ENUM FMT

VIDIOC S FMT
VIDIOC REQBUFS
VIDIOC QUERYBUF

VIDIOC S FMT
VIDIOC REQBUFS
VIDIOC QUERYBUF

VIDIOC QBUF

VIDIOC QBUF

VIDIOC STREAMON

VIDIOC STREAMON

VIDIOC DQBUF

VIDIOC DQBUF

VIDIOC S CTRL
VIDIOC STREAMOFF

Operations
open camera device
query capabilities
enumerate video input
set the input
set white balance, mode,
focus
enumerate supported for-
mat
set format
allocate shared memory
query the status of the
buffer
exchange a buffer with
the driver
start or stop streaming
I/O
exchange a buffer with
the driver
pause in our case
close the stream

Again, our attack does not need any camera-access permis-
sions, and nor does it demonstrate any visual effects during
picture taking (such as showing preview in a normal use of
the camera). Therefore, it is completely stealthy to the phone
user. A video demo of the attack is here [1]. This problem
affects millions of phone users (Section V).

Screenshot capture. Screenshot taking is considered to be a
highly sensitive capability, which Google guards with a system
permission READ_FRAME_BUFFER and never grants to any
third-party app. Actually, apps that provide programmatic ap-
proaches to capturing screenshots need to either run on a rooted
phone or get the capability through Android Development
Bridge [10]. However, we found in our study that some
vendors expose this capability to the public. Speciﬁcally, on
Galaxy ACE 3 GT-7270L (running 4.2.2), the Linux standard
frame buffer device /dev/graphics/fb0 is set
to be
publicly readable and writable. The fb0 ﬁle is a hardware
independent graphic abstraction layer and contains the current
image on screen. We suspect that this oversight (exposure of
the frame buffer) could be caused by the attempt to provide a
customized screenshot capability for vendor pre-installed apps
such as screenshot for Samsung Note app. In our study, we
implemented an attack on this ﬂaw over Samsung Galaxy ACE
3, a phone model distributed in Latin America.

In the attack, again we implemented a malicious app that
runs as a background service and periodically reads from the
frame buffer. Each time, the app converts the content it gets
from the buffer into an image ﬁle (JPG) and saves it on
the phone’s SD card. Whenever the user is running sensitive
apps such as those providing ﬁnancial services (which can be
found out from the package names of the running processes),
the malicious app continuously takes screenshots to collect
sensitive user data. The demo of this attack is also online [1].
All those malicious apps can be made highly context-
aware: that is, they can continuously monitor what the phone
user is running and only start collecting information at the
right moment. This can be done through inspecting the list of
running processes and CPU, memory usages of those apps, as
proposed in prior research [46].

V. A LARGE-SCALE MEASUREMENT STUDY

Our study on 4 Android devices, as described in Section IV,
reveals the great impact of customization errors to Android
device security, which allow an unauthorized app to get access
to critical system capabilities on popular phones. What is less
clear is how pervasive those security-critical ﬂaws are across a
large number of phones, tablets and all kinds of Linux devices,
beyond those on our short list (Table V). Since it is hard to
get the answer to this question by running ADDICTED over
thousands of physical devices, we have to statically check
factory images. The problem is that without hardware, we
cannot perform the dynamic analysis to identify all customized

417

TABLE VII.

ANDROID FACTORY IMAGES COLLECTED BY OUR

CRAWLER

Version
4.0.3
4.0.4
4.1.1
4.1.2
4.2.1
4.2.2
4.3
TOTAL

# of Phone Models of each Version
16
113
48
159
1
59
21
417 (288 distinct models)

# of Images
109
564
238
1054
1
397
60
2423

device ﬁles even for those on our short list. All we can do is
to use the names of the device related ﬁles on the reference
to search for those on customized images to ﬁnd out whether
they are as well protected there as on the reference.

Also we want to go beyond the devices on the list. Device
nodes are typically located under /dev with some of them
placed under /sys. Finding what hardware pieces those
individual ﬁles serve is challenging. In our research, we just
blindly compared them with their counterparts on the reference
according to their names, to get some clues about whether
they are well conﬁgured based on their Linux permission
settings. Another trouble here is that /sys and /dev are
actually dynamically generated by the Linux init process.
To ﬁnd out those virtual ﬁles’ security settings, we resorted
to the conﬁguration ﬁles that init utilizes to determine
their protection levels. Speciﬁcally, when Linux initializes,
init runs the ueventd process to read from ueventd.rc
and ueventd.$HARDWARE.rc settings of different device
nodes. In our research, we just extracted these two ﬁles from
factory images and used them to analyze device-related ﬁles’
Linux protection. Following we ﬁrst explain the methodology
used in our study and then present the ﬁndings we made.

A. Methodology and Data

As discussed above, the methodology of our measurement
study is to analyze the conﬁguration ﬁles of different factory
images, comparing the device settings on these images (as
recorded in the ﬁles) with those on the reference to identify
LCFs. Most important to this study is to ﬁnd out as many
images as possible to collect their conﬁguration ﬁles. Here we
discuss how this was done in our research.

Factory image collection. Although vendors release the
source code of their Android updates, they typically do not
make public the conﬁguration ﬁles we are looking for. Those
ﬁles can only be extracted from factory images. In our study,
we developed a crawler that automatically checks top image
storing websites,
including Samsung update [5] and full-
ﬁrmwarec [4], to download those images. From all the images
there, we selected one image for each phone model each
version (at
least 4.0). In total, our crawler gathered 2423
images covering 417 phone models ranging from android 4.0
to 4.3 and total of 2.5TB disk size. Table VII summarizes
the scale of our study. (Note that one phone model even at
one speciﬁc version may have multiple images for different
countries or regions.)

Conﬁguration ﬁle extraction. The factory image we down-
loaded is usually in zip or tar format. To extract from
it
the conﬁguration ﬁles, our approach ﬁrst unzipped the

Fig. 3. Number of phone models with the 3 conﬁrmed vulnerabilities. No
data is available for gray areas.

image to search for zImage or boot.img. Then it ran
zImageTool and Boot-Image-tools [9] to split the image into
kernel and ramdisk. From the ramdisk part, we retrieved the
.rc conﬁguration ﬁles. Those ﬁles were parsed and their
relevant content was stored into a database. During this pro-
cess, ueventd.$HARDWARE.rc was always processed after
ueventd.rc, as the conﬁgurations in the former overrule
those in the latter during Linux initialization.

All the ﬁle settings from one image were then compared
with those on the reference with the image’s Android version.
For example,
the two conﬁguration ﬁles from a Samsung
customized 4.0.4 were analyzed against those on AOSP 4.0.4.

B. Results
Pervasiveness of LCFs. Our study shows that security hazards
of device customizations are indeed pervasive. Table VIII
summarizes the total number of LCFs we found. From the
table, we can see that 1290 (53.24%) images we studied
contain LCFs. More speciﬁcally, they include at least one
device ﬁle whose protection level is set to be publicly readable
and writable, way below that of the same ﬁle on the reference.
We found that such LCFs affect 75.65% of the distinct phone
models and 86.65% of the carriers we studied.

We also measured the magnitude of the conﬁrmed vulner-
abilities we exploited (Section IV). Table VIII shows the per-
vasiveness of these ﬂaws across different customized devices.
Just for an example, the problem with the camera driver was
found within 952 images for 72 phone models.

Distribution of the ﬂaws. We further studied the distribution
of the LCFs across different geo-locations. For this purpose, we
identiﬁed the countries of different factory images and mapped
to them the number of the phone models in those individual
countries affected by the 3 conﬁrmed ﬂaws (Section IV-B).
Figure 3 illustrates the results, which are presented on the
Google maps. Interestingly, we found that developing countries
(e.g., China, Brazil) host more vulnerable phone models. The
security quality of customizations there may be lower than that
in other countries.

418

TABLE VIII.

IDENTIFIED LCFS AND CONFIRMED VULNERABILITIES

LCFs
INPUT
VIDEO
FRAME BUFFER

# of distinct device nodes
(Total on references: 222)
28(12.61%)
1
5
1

# of distinct images (Total: 2423)

# of distinct models (Total: 288)

# of carriers (Total: 275)

1290(53.24%)
329(13.58%)
952(39.23%)
90(3.71%)

215(75.65%)
35(12.15%)
72(22.00%)
14(4.86%)

238(86.55%)
136(49.45%)
217(78.91%)
47(17.09%)

TABLE IX.

TOP 10 REGIONS WITH MOST LCFS AND CONFIRMED

VULNERABILITIES

RANK

Region

CHINA
BRAZIL
FRANCE
US
INDIA
GERMANY
TAIWAN
SPAIN
HONG KONG
AUSTRALIA

# of models
with LCFs
80
65
51
46
42
41
40
40
38
37

# of models with the
3 vulnerabilities
28
27
22
12
17
20
17
16
14
21

Model w/ LCFs Model w/ Comfirmed LCFs

1
2
3
4
5
6
7
8
9
10

16
14
12
10
8
6
4
2
0

s
F
C
L
 
/
w
 
s
l
e
d
o
m
e
n
o
h
p
 
f
o
#

 

 

TABLE X.

DISTRIBUTION OF LCFS OVER OS VERSIONS

OS Version
4.0.3
4.0.4
4.1.1
4.1.2
4.2.2
4.3

Phone Models with LCFs
11
78
9
48
14
6

Total Phone Models %
16
113
48
159
59
21

68.75%
69.03%
18.75%
30.19%
23.73%
28.57%

stop making much progress on suppressing such customization
ﬂaws.

We further selected all 103 phone models with at least 2
images (of course, with different Android versions) to study
the evolution of LCFs across different versions on individual
models. Out of them, 92 phone models have at least one of the
LCFs, including the 3 conﬁrmed vulnerabilities, on at least one
of their images. On these 92 models, we checked whether their
LCFs are removed after the phones are upgraded. Table XI
shows the number of phone models whose updates ﬁx their
existing LCFs or introduce new ones. As we can see here, only
on 6 phone models, the vendors have completely addressed all
their LCFs through updates, while the others either continue to
suffer from at least one of the existing LCFs, or even get new
ones. The most interesting case is GT-N7000 Galaxy Note: its
camera vulnerability (Section IV-B) is present on both 4.0.3
and 4.0.4; the problem disappears on 4.1.1 but shows up again
on the 4.1.2. Therefore, we are not sure whether the vendor has
discovered the problem, intentionally addressed it and made
the same lapse again later. Also for the frame buffer ﬂaw, we
only have images for the affected phones at 4.1 and 4.2 and
therefore do not know whether they have been addressed in
their most recent versions.

TABLE XI.

LCFS FIXED OR INTRODUCED BY UPDATES ON PHONE

MODELS

Fixed at least 1 LCF when upgrading
Fixed all LCFs on the phone when upgrading
Fixed LCF shows up again after upgrades
Introduce new LCFs when upgrading

# of Phone Models
53
6
2
36

Popular public device ﬁles. Finally, we took a look at all
public device ﬁles under /dev. Table XII lists top device
ﬁles based upon their individual number of occurrences across
various customized phones. On the list, only the ﬁrst one
/dev/kgsl-2d1 was reported to have an LCF, which is
a driver for a 2D graphic acceleration card. Its disclosure
to the public could allow an unauthorized party to access
the information about the images displayed on the phone’s
screen, though whether this exploit can work out needs a
further investigation. Other device ﬁles on the list do not
even show up on the references, so we did not have any
indications that they need to be protected. To ﬁnd out what
those ﬁles are, we manually analyzed their source code and
searched for their information on Google. It turns out that

Fig. 4. Top 10 Carriers that has most LCFs and Conﬁrmed Vulnerabilities.

We also analyzed the distributions of all LCFs discovered
through the comparison between factory images and refer-
ences. Table IX presents the top 10 countries in terms of the
number of phone models involving LCFs and the number of
the models with the 3 conﬁrmed vulnerabilities. As we can
see here, these two ranking lists are largely aligned.

Besides vendors, carriers may also customize phones to
add new features. Figure 4 shows the top 10 carriers with
the highest number of phone models affected by the LCFs
and conﬁrmed vulnerabilities. Among them, the SK Telecom
(Korea) and China Mobile have the largest number of vulner-
able phone models. T-Mobile and AT&T are also on the list.
Particularly, they have few popular models (Galaxy Note 2
and Galaxy Tab for T-Mobile, and Galaxy SII for AT&T) that
contain the conﬁrmed customization vulnerabilities described
in Section IV.

To ﬁnd out how the security quality of customizations
evolves across different Android versions, we inspected the
factory images across multiple Android versions for the pres-
ence of LCFs. Table X shows the number of LCF-affected
phone models on different versions. When those phones are
upgraded from 4.0.3 to 4.1,
the percentage of vulnerable
models drops from nearly 70% to 18%. However, it goes up to
round 30% for 4.1.2 and 4.3. This shows that vendors seem to

419

TABLE XII.

MOST POPULAR PUBLICLY ACCESSIBLE DEVICE NODES

AND THEIR POTENTIAL IMPACTS

Functionality and Impact
GPU device for 2D acceleration
Uniﬁed Memory Provider that provides a way
to share both existing and new memory areas
across processes and hardware units.
2D graphic driver that provides image trans-
formation for stretching, rotation and alpha
blending. Data will be delivered to frame-
buffer.
An interface to allocate contiguous memory
buffers for hardware and handle sharing of
allocated buffers between processes
Camera driver. Exposure of this device could
lead to camera attacks.

/dev/exynos-mem Memory used by graphics, surfaceﬂinger. Ex-
posure of this device could enable an app to
tamper kernel memory.
Low memory kill. Exposure of this device may
allow an ordinary app to kill any process.
Driver for RFID smart card system.

/dev/vc-lmk

Device Node
/dev/kgsl-2d1
/dev/ump

/dev/ﬁmg2d

/dev/hwmem

/dev/s5p-mfc

/dev/felica

all of them are indeed security-critical. For example,
the
ﬁle /dev/vc-lmk was found to be a “low-memory kill”
device, which terminates an app when the phone’s memory
is running low. With its complete exposure, any app, without
any permission, can invoke the device to stop another app.
Another example is /dev/hwmem, a memory device through
which one can touch physical memory. This device has been
made public on Galaxy S 3 Mini and other models. As a
result, an unprivileged app may be able to make ioctl calls
to this device to read or write part of the phone’s physical
memory. All such ﬁndings, again, show that what we detected
through ADDICTED are nothing more than a tip of the iceberg.
The security problems in Android device customizations are
so serious that immediate efforts need to be made to better
understand them and effectively address them.

More attacks. We further analyzed two potential vulnerabil-
ities in Table XII and developed end-to-end attacks on them.
This conﬁrmed that those ﬂaws are real and their exploits
can have serious consequences. Speciﬁcally, we studied the
vc-lmk device, which, as discussed before, is a low memory
kill driver. Android is designed to accommodate as many
processes as possible in the memory to help them promptly
respond to the user’s requests. However, when the memory
is about to run out, the OS picks up processes, based upon
their oom_adj values, to terminate. For this purpose, Android
includes this process-killing device, which should never be
made public. In our research, we implemented an app, without
any permission, to exploit this exposure to terminate other
processes. Since the exposed driver runs in the kernel land,
it can stop any processes, including system apps like Phone,
SurfaceFlinger and even the init process. To command
the driver, the app was built to make ioctl calls to vc-lmk
with the command VC_LMK_IOC_KILL_PID and pid as
the argument. Executing the command, the driver then sends
an SIGKILL to the target and asks it to stop running. Note
that there is no access-control protection whatsoever within
ioctl to prevent our app from unleashing vc-lmk. In our
experiment, we successfully stopped several system processes.
Interestingly, once the Phone app is terminated, ongoing
calls hang up; SurfaceFlinger’s termination immediately
freezes the phone’s user interface; When the init process is
stopped, the whole phone reboots.

420

We also came up with an attack on the exposed UMP
device, which is a uniﬁed memory resource allocator. Our
analysis of its source code reveals two IO control commands:
UMP_IOC_ALLOCATE for allocating memory and copying
user data to kernel, and UMP_IOC_MSYNC for cache main-
tenance. Our attack leveraged the ﬁrst command to contin-
uously require resources until disabling the phone by using
up all it memory. For the second command, we ran it to
access a random memory location, which caused the phone
to reboot immediately. Clearly, the device provides security-
critical capability and therefore should not be made available
to unauthorized apps.

VI. DISCUSSION

The openness of Android has brought in a fragmented
ecosystem with signiﬁcant security implications. In our re-
search, we made the ﬁrst step toward understanding the se-
curity challenges there, particularly the security-critical ﬂaws
introduced during customization of Android Linux devices. We
found the presence of customization errors in the security con-
ﬁgurations of device-related ﬁles on a large number of Android
phones, across multiple OS versions, different vendors, carriers
and regions, leading to complete exposure of critical system
resources and capabilities. On the other hand, we believe that
what we found just scratches the surface of the new security
challenges in device customizations. Further research effort is
urgently needed on the following directions.

Other devices. Our techniques cannot connect most device-
related ﬁles to their Linux devices. Under /dev, still dozens
of ﬁles are there which we cannot interpret, though some of
them may not be sensitive. To increase the coverage, more
test cases need to be added to ADDICTED’s test suite. More
challenging here is identiﬁcation of the drivers for the devices
not supported by the ofﬁcial Android OSes. A comparison with
the reference in this case will not help detect the security-
critical ﬂaws in their device ﬁles. New techniques therefore
need to be developed to address this problem.

Flaw detection. The design of ADDICTED is to detect LCFs
by looking at the way device ﬁles are protected on the refer-
ence. For those with downgraded protection levels, all we can
say here is that they might cause some security concerns. Con-
ﬁrmation of security ﬂaws still need a manual analysis. New
techniques for automating this process are deﬁnitely valuable.
Also, ADDICTED is not designed to identify the device ﬁle
conﬁguration problems on the ofﬁcial Android OSes. Further
research on this direction could leverage observed relations
between Android permission levels and their corresponding
devices’ Linux-level protection settings to build a model for
detecting security conﬁguration ﬂaws on AOSP versions.

VII. RELATED WORK

In this section, we review related prior studies and compare

them with our work.

Android app analysis. Android apps have often been analyzed
statistically for malware detection [47] and vulnerability iden-
tiﬁcation. Examples include CHEX [38] and ComDroid [23]
that utilize this technique to ﬁnd out security-critical ﬂaws
within apps. Also, Woodpecker [30] scans a large number of

apps for their privilege-leak weaknesses. Different from those
prior approach, ADDICTED is meant to work on the Android
system, instead of individual apps. Given the complexity of
the system, which includes both C code and Java programs,
tracking operations on device ﬁles is hard to be done statically.

Most relevant to our work is the recent research on vendor
customization of pre-installed apps [43]. This research stati-
cally analyzes 10 representative stock Android images from 5
top vendors to identify the provenances of their pre-installed
apps. It further discovers that a large portion of those apps are
overly privileged or have re-delegation vulnerabilities, and also
most of the problematic apps come from the vendors. Unlike
this prior work, whose focus is the impact of customizations
on apps, our work looks at device drivers, which are the
predominant cause for phone vendors to customize Android.
What we found, including the pervasiveness of exposed Linux
device nodes and the serous consequences once they are
exploited, have never been reported before.

When a security analysis on Android needs to touch its
system code, oftentimes, this needs to be done through a
dynamic analysis [2, 26, 32, 44]. A prominent example of
this line of work is TaintDroid [26], a tool designed for
dynamic taint analysis on Android. This approach can achieve
a ﬁne-grained tracking of data ﬂows across apps and the OS.
However, it is less suitable for analyzing multiple customized
systems because it requires an intensive instrumentation of the
OS to get a good performance, which limits its portability.
Another ﬁne-grained dynamic tool is Droidscope [44], which
runs the whole Android platform on an emulator to reconstruct
both the OS and Dalvik level views of the system. The
problem is that it is difﬁcult for the emulator to mimic different
customized hardware, which is required for our study on
Android Linux devices.

System-call analysis. Given the challenges of using existing
tools for our study, we built our own dynamic analysis tool that
works on the system-call level to achieve a high performance
and portability. System calls have long been used for security-
related program analysis [21, 36, 37, 40]. ADDICTED is built
on strace that is ported and extended to work on ARM-based
systems.

Android permissions. Also related to our research is a large
amount of the literature on Android permissions. Those per-
missions are meant to protect critical Android resources on
the framework layer [24, 27–29]. Prior work leverages dy-
namic analysis to “demystify” Android permissions, mapping
Android APIs to their related permissions [28]. The outcomes
of the study can help us ﬁnd the right APIs to trigger device-
related permissions, for the purpose of locating the Linux
ﬁles related to the device. Another example is the technique
for tracking an IPC call’s provenance to prevent permission
re-delegation attacks. Our approach also monitors the IPC
but for ﬁnding the ﬁle-system activities in response to the
request. There is also a line of research on enhancement of
the permission system [19, 22, 25, 33, 35, 39]. Fundamentally,
all those prior studies focus on the security protection on the
framework layer, while our research investigated the Linux-
layer security hazards introduced by device customizations.

Android Linux-layer security. Only limited effort has been
made on Android’s Linux-layer security. Prominent exam-
ples include Momento [34], which investigates the informa-
tion leaks from the shared memory usage data exposed by
Android’s Linux, and the recent work on Android public
information leaks [46]. Those studies follow the foot step
of the work on the privacy implications of the Linux Proc
ﬁle system [45]. Different from the prior work, our research
investigates the Linux-layer protection of Android device ﬁles,
whose exposures have direct and often more serious conse-
quences, as shown in the paper. Also, effort has been made
recently to enhance access control on Android [42], based upon
SELinux [6].

Sensor data inference. There is a line of research on inferring
sensitive user information from the public data exposed by
Android devices, particularly the outputs of different sen-
sors [20, 31, 41]. Different from such work, our approach
reveals the customization errors that cause explicit disclosure
of Android device nodes, allowing an unauthorized party to
directly get information from them.

VIII. CONCLUSION

The fragmentation of the Android ecosystem has brought
in new security challenges: vendors and carriers aggressively
customize ofﬁcial OS versions to accommodate their new
hardware pieces and services, which can potentially undermine
Android security protection. This important issue, however,
has not been adequately studied. Particularly, little is known
about the security implications of customizing a variety of
Android Linux devices such as camera, audio, GPS, etc. In our
research, we made the ﬁrst step toward better understanding of
this issue, leveraging a new technique, ADDICTED, designed
for automatic detection of some types of security-critical
customization ﬂaws. ADDICTED dynamically analyzes the
operations on a sensitive Android device to connect it to a set
of Linux device ﬁles. The security protection of these ﬁles is
then evaluated against that received by their counterparts on the
AOSP OS. In this way, our approach automatically identiﬁes
those under-protected device nodes. Running ADDICTED on
popular phone models, we discovered critical ﬂaws that allow
an unauthorized app to take pictures and screenshots, and
even record the user’s input keys from touchscreen. Those
vulnerabilities were found to exist on hundreds of other phone
models. Our measurement study further reveals the LCFs
present in over 1,000 phone models distributed across different
Android versions, carriers and countries.

With the important discoveries we made, our research just
scratches the surface of the grand security challenges that
come with Android customizations. Even on the Linux layer,
still there are many device ﬁles we cannot interpret, not to
mention detection of their security ﬂaws. More importantly,
further effort is expected to understand how to protect security-
critical resources on different Android layers, and develop
effective means to ensure that customized resources are still
well guarded.

ACKNOWLEDGEMENTS

The project was supported in part by the NSF CNS-

1017782, 1117106, 1223477 and 1223495.

421

REFERENCES

[1] Demo of

the paper.

https://sites.google.com/site/

linuxdroid0/.

[2] Droidbox: Android application sandbox.

https://code.

google.com/p/droidbox/. Accessed:Nov, 2013.

[3] File,
os x.
macosx/. Accessed: 05/20/2013.

folder comparison & synchronization for mac
http://www.deltopia.com/compare-merge-sync/

[4] Full ﬁrmware.

http://www.full-ﬁrmware.com/.

Ac-

[5] Samsung updates: Latest news and ﬁrmware for your
http://samsung-updates.com/. Ac-

cessed:05/02/2013.

samsung devices!
cessed: 05/02/2013.

[6] Se linux.

http://www.nsa.gov/research/ ﬁles/selinux/

papers/slinux.pdf. Accessed: 11/09/2013.

[7] Using the input subsystem. http://www.linuxjournal.com/

article/6429, year = 2013,.

[8] Android tops 81 percent of

share in q3.
strategy-analytics-q3-2013-phone-share/, 2013.
cessed: 10/31/2013.

smartphone market
http://www.engadget.com/2013/10/31/
Ac-

[9] Boot image tools. https://github.com/sakindia123/Boot-

Image-tools, 2013.

[10] How to take screenshots on your unrooted android
http://www.lindylabs.com/

phone – windows version.
screenshot it/instructions win.html, 2013.

[11] Linux-fbdev.org. http://www.linux-fbdev.org/, 2013.
[12] List of best-selling mobile phones. http://en.wikipedia.

org/wiki/List of best-selling mobile phones, 2013.

[13] randoop, random test generation.

https://code.google.

com/p/randoop/, 2013. Accessed: 11/08/2013.

http://en.wikipedia.org/wiki/RGB

[14] Rgb color model.
color model, 2013.

[15] Samsung s5p/exynos4 ﬁmc driver. https://www.kernel.

org/doc/Documentation/video4linux/ﬁmc.txt, 2013.

[16] strace. http://sourceforge.net/projects/strace/, 2013. Ac-

cessed: 11/08/2013.
framework.

[17] V4l2

https://www.kernel.org/doc/

Documentation/video4linux/v4l2-framework.txt, 2013.

[18] Yuv. http://en.wikipedia.org/wiki/YUV, 2013.
[19] Alastair R. Beresford, Andrew Rice, Nicholas Skehin,
and Ripduman Sohan. Mockdroid: trading privacy for
application functionality on smartphones. In Proceedings
of the 12th Workshop on Mobile Computing Systems and
Applications, HotMobile ’11, pages 49–54, New York,
NY, USA, 2011. ACM.

[20] Liang Cai and Hao Chen.

inferring
keystrokes on touch screen from smartphone motion. In
Proceedings of the 6th USENIX conference on Hot topics
in security, HotSec’11, pages 9–9, Berkeley, CA, USA,
2011. USENIX Association.

Touchlogger:

[21] Davide Canali, Andrea Lanzi, Davide Balzarotti, Christo-
pher Kruegel, Mihai Christodorescu, and Engin Kirda.
A quantitative study of accuracy in system call-based
malware detection.
In Proceedings of the 2012 Inter-
national Symposium on Software Testing and Analysis,
ISSTA 2012, pages 122–132, New York, NY, USA, 2012.
ACM.

[22] Kevin Zhijie Chen, Noah M. Johnson, Vijay D’Silva,
Shuaifu Dai, Kyle MacNamara, Tom Magrino, Ed-
ward XueJun Wu, Martin Rinard, and Dawn Xiaodong

Song. Contextual policy enforcement in android appli-
cations with permission event graphs.
In NDSS. The
Internet Society, 2013.

[23] Erika Chin, Adrienne Porter Felt, Kate Greenwood, and
David Wagner. Analyzing inter-application communica-
tion in android. In Proceedings of the 9th international
conference on Mobile systems, applications, and services,
MobiSys ’11, pages 239–252, New York, NY, USA,
2011. ACM.

[24] Michael Dietz, Shashi Shekhar, Yuliy Pisetsky, Anhei
Shu, and Dan S. Wallach. Quire: Lightweight provenance
for smart phone operating systems.
In 20th USENIX
Security Symposium, San Francisco, CA, August 2011.
[25] Manuel Egele, Christopher Kruegel, Engin Kirda, and
Giovanni Vigna. PiOS: Detecting privacy leaks in iOS
applications.
In Proceedings of the 18th Annual Net-
work & Distributed System Security Symposium (NDSS),
February 2011.

[26] William Enck, Peter Gilbert, Byung-Gon Chun, Lan-
don P. Cox, Jaeyeon Jung, Patrick McDaniel, and An-
mol N. Sheth. Taintdroid: an information-ﬂow tracking
system for realtime privacy monitoring on smartphones.
In Proceedings of the 9th USENIX conference on Operat-
ing systems design and implementation, OSDI’10, pages
1–6, Berkeley, CA, USA, 2010. USENIX Association.

[27] William Enck, Machigar Ongtang, and Patrick McDaniel.
On lightweight mobile phone application certiﬁcation. In
Proceedings of the 16th ACM CCS, CCS ’09, pages 235–
245, New York, NY, USA, 2009. ACM.

[28] Adrienne Porter Felt, Erika Chin, Steve Hanna, Dawn
Song, and David Wagner. Android permissions demys-
tiﬁed.
In Proceedings of the 18th ACM conference on
Computer and communications security, CCS ’11, pages
627–638, New York, NY, USA, 2011. ACM.

[29] Adrienne Porter Felt, Helen J Wang, Alexander
Moshchuk, Steven Hanna, and Erika Chin. Permission re-
delegation: Attacks and defenses. In Proceedings of the
20th USENIX Security Symposium, pages 22–37, 2011.
[30] Michael Grace, Yajin Zhou, Zhi Wang, and Xuxian Jiang.
Systematic detection of capability leaks in stock Android
smartphones.
In Proceedings of the 19th Network and
Distributed System Security Symposium (NDSS), Febru-
ary 2012.

[31] Jun Han, Emmanuel Owusu, Thanh-Le Nguyen, Adrian
Perrig, and Joy Zhang. Accomplice: Location inference
using accelerometers on smartphones.
In Proceedings
of the 4th International Conference on Communication
Systems and Networks, Bangalore, India, 2012.

[32] Kim Hazelwood and Artur Klauser. A dynamic binary
instrumentation engine for the arm architecture. In Pro-
ceedings of the 2006 international conference on Com-
pilers, architecture and synthesis for embedded systems,
CASES ’06, pages 261–270, New York, NY, USA, 2006.
ACM.

[33] Peter Hornyack, Seungyeop Han, Jaeyeon Jung, Stuart
Schechter, and David Wetherall. These aren’t the droids
you’re looking for: retroﬁtting android to protect data
from imperious applications. In Proceedings of the 18th
ACM CCS, CCS ’11, pages 639–652, New York, NY,
USA, 2011. ACM.

[34] Suman Jana and Vitaly Shmatikov. Memento: Learning
In Proceedings of the

secrets from process footprints.

422

2012 IEEE Symposium on Security and Privacy, SP
’12, pages 143–157, Washington, DC, USA, 2012. IEEE
Computer Society.

[35] Limin Jia, Jassim Aljuraidan, Elli Fragkaki, Lujo Bauer,
Michael Stroucken, Kazuhide Fukushima, Shinsaku Kiy-
omoto, and Yutaka Miyake. Run-time enforcement of
information-ﬂow properties on Android (extended ab-
stract).
In Computer Security—ESORICS 2013: 18th
European Symposium on Research in Computer Security,
pages 775–792. Springer, September 2013.

[36] Clemens Kolbitsch, Paolo Milani Comparetti, Christo-
pher Kruegel, Engin Kirda, Xiaoyong Zhou, and Xi-
aoFeng Wang. Effective and efﬁcient malware detection
at the end host. In Proceedings of the 18th conference on
USENIX security symposium, SSYM’09, pages 351–366,
Berkeley, CA, USA, 2009. USENIX Association.

[37] Andrea Lanzi, Davide Balzarotti, Christopher Kruegel,
Mihai Christodorescu, and Engin Kirda. Accessminer:
using system-centric models for malware protection. In
Proceedings of the 17th ACM conference on Computer
and communications security, CCS ’10, pages 399–412,
New York, NY, USA, 2010. ACM.

[38] Long Lu, Zhichun Li, Zhenyu Wu, Wenke Lee, and
Guofei Jiang. Chex: statically vetting android apps for
component hijacking vulnerabilities.
In Proceedings of
the 2012 ACM conference on Computer and communica-
tions security, CCS ’12, pages 229–240, New York, NY,
USA, 2012. ACM.

[39] Mohammad Nauman, Sohail Khan, and Xinwen Zhang.
Apex: extending android permission model and enforce-
ment with user-deﬁned runtime constraints.
In Pro-
ceedings of the 5th ACM Symposium on Information,
Computer and Communications Security, ASIACCS ’10,
pages 328–332, New York, NY, USA, 2010. ACM.

[40] Alessandro Reina, Aristide Fattori, and Lorenzo Cav-
allaro. A system call-centric analysis and stimulation
technique to automatically reconstruct android malware
behaviors. In Proceedings of the 6th European Workshop

on System Security (EUROSEC), Prague, Czech Repub-
lic, April 2013.

[41] Roman Schlegel, Kehuan Zhang, Xiao yong Zhou,
Mehool Intwala, Apu Kapadia, and XiaoFeng Wang.
Soundcomber: A stealthy and context-aware sound trojan
for smartphones. In NDSS. The Internet Society, 2011.
[42] Stephen Smalley and Robert Craig. Security enhanced
(se) android: Bringing ﬂexible mac to android. In NDSS.
The Internet Society, 2013.

[43] Lei Wu, Michael Grace, Yajin Zhou, Chiachih Wu, and
Xuxian Jiang. The impact of vendor customizations
on android security.
In Proceedings of the 2013 ACM
SIGSAC conference on Computer communications secu-
rity, CCS ’13, pages 623–634, New York, NY, USA,
2013. ACM.

[44] Lok Kwong Yan and Heng Yin. Droidscope: seamlessly
reconstructing the os and dalvik semantic views for
dynamic android malware analysis.
In Proceedings of
the 21st USENIX conference on Security symposium,
Security’12, pages 29–29, Berkeley, CA, USA, 2012.
USENIX Association.

[45] Kehuan Zhang and XiaoFeng Wang. Peeping tom in
the neighborhood: keystroke eavesdropping on multi-user
systems.
the 18th conference on
USENIX security symposium, SSYM’09, pages 17–32,
Berkeley, CA, USA, 2009. USENIX Association.

In Proceedings of

[46] Xiaoyong Zhou, Soteris Demetriou, Dongjing He,
Muhammad Naveed, Xiaorui Pan, XiaoFeng Wang,
Carl A. Gunter, and Klara Nahrstedt. Identity, location,
disease and more: Inferring your secrets from android
public resources. In Proceedings of 20th ACM Confer-
ence on Computer and Communications Security (CCS),
November 2013.

[47] Yajin Zhou, Zhi Wang, Wu Zhou, and Xuxian Jiang.
Hey, you, get off of my market: Detecting malicious
apps in ofﬁcial and alternative Android markets.
In
Proceedings of the 19th Annual Network & Distributed
System Security Symposium, February 2012.

423

