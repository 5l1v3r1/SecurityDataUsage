Strong Non-Interference and Type-Directed

Higher-Order Masking∗

Gilles Barthe

IMDEA Software Institute

Madrid, Spain

François Dupressoir
IMDEA Software Institute

Madrid, Spain

Sonia Belaïd

Thales Communications & Security

Gennevilliers, France
Pierre-Alain Fouque
Université de Rennes 1

Rennes, France

Benjamin Grégoire

Inria Sophia-Antipolis – Méditerranée

Sophia-Antipolis, France

Pierre-Yves Strub

IMDEA Software Institute

Madrid, Spain

Rébecca Zucchini

Inria Sophia-Antipolis – Méditerranée
École Normale Supérieure de Cachan

France

ABSTRACT
Differential power analysis (DPA) is a side-channel attack in which
an adversary retrieves cryptographic material by measuring and
analyzing the power consumption of the device on which the crypto-
graphic algorithm under attack executes. An effective countermea-
sure against DPA is to mask secrets by probabilistically encoding
them over a set of shares, and to run masked algorithms that com-
pute on these encodings. Masked algorithms are often expected to
provide, at least, a certain level of probing security.

Leveraging the deep connections between probabilistic infor-
mation ﬂow and probing security, we develop a precise, scalable,
and fully automated methodology to verify the probing security of
masked algorithms, and generate them from unprotected descrip-
tions of the algorithm. Our methodology relies on several contribu-
tions of independent interest, including a stronger notion of probing
security that supports compositional reasoning, and a type system
for enforcing an expressive class of probing policies. Finally, we
validate our methodology on examples that go signiﬁcantly beyond
the state-of-the-art.

1.

INTRODUCTION

Differential power analysis, or DPA [26], is a class of side-channel
attacks in which an adversary extracts secret data from the power
consumption of the device on which a program manipulating the
data executes. One practical countermeasure against DPA, called
∗Preliminary and long versions of this work appear as revisions of
IACR ePrint report 2015/506 [5].

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’16, October 24 - 28, 2016, Vienna, Austria
c(cid:13) 2016 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ISBN 978-1-4503-4139-4/16/10. . . $15.00
DOI: http://dx.doi.org/10.1145/2976749.2978427

masking [12, 23], transforms an algorithm that performs computa-
tions over a ﬁnite ring K into a randomized algorithm that manip-
ulates probabilistic encodings.1At an abstract level, any masking
transformation performs two tasks. First, it replaces every algebraic
operation performed by the original algorithm by a call to a gadget,
i.e. a probabilistic algorithm that simulates the behavior of algebraic
operations on probabilistic encodings. Second, it inserts refreshing
gadgets, i.e. gadgets that take a probabilistic encoding of v and
rerandomizes its shares in order to produce another probabilistic
encoding w of v. Inserting refreshing gadgets does not change the
functional behavior of the masked algorithm, and increases the ran-
domness complexity and execution time of the masked program.
However, it is also compulsory for achieving security. Therefore, an
important line of research is to ﬁnd suitable trade-offs that ensure
security while minimizing the performance overhead of masking;
see [9] for recent developments in this direction.

The baseline notion of security for masked algorithms is t-probing
security. Informally, an algorithm P is t-probing secure if the values
taken by at most t intermediate variables of P during execution do
not leak any information about secrets (held by its inputs). More
formally, an algorithm P achieves t-probing security iff for every
set of at most t intermediate variables, the joint distributions of
the values taken by these intermediate variables coincide for any
two executions initiated from initial inputs that agree on t shares
of each input encoding. Stated in this form, probing security is an
instance of probabilistic information ﬂow, universally quantiﬁed
over all position sets that meet a cardinality constraint, and is there-
fore potentially amenable to formal analysis using a well-developed
body of work on language-based security and program veriﬁcation.
Indeed, the connection between probing security and information
ﬂow has been instrumental in a promising line of research, initiated
in [28] and further developed in [8, 21, 20, 4], which uses type sys-
tems, program logics, SMT solvers and other methods for verifying
1A t-encoding of an element v ∈ K is a (t + 1)-tuple v =
= v0 ⊕ . . . ⊕ vt = v. Each of the
vı ∈ K in an encoding v of v is called a share. Moreover, t is called
the masking order. A probabilistic encoding of v is a distribution
over encodings of v.

(cid:104)v0, . . . , vt(cid:105) such that(cid:74)v(cid:75) (cid:52)

116or synthesizing masked algorithms at small (≤ 5) orders. However,
none of these works addresses the problem of composition, and all
fail to scale either to higher orders or to larger algorithms.

Contributions. We develop precise and scalable techniques for
synthesizing masked algorithms that achieve probing security. Our
techniques apply to a wide range of probing policies, including
existing policies and new policies deﬁned in this paper, and deliver
masked algorithms that outperform (in terms of randomness com-
plexity and computational efﬁciency) prior approaches. In more
detail, we make the following broad contributions:

1. Strong non-interference. We introduce a stronger notion of
probing security, which we call strong non-interference, and prove
that it is in fact satisﬁed by many (but not all) gadgets from the
literature. Furthermore, we justify that strong non-interference
is the desired property for refreshing gadgets, by reconsidering
known negative and positive results [16] for a simpliﬁed example
extracted from Rivain and Prouff’s inversion algorithm [32]. We
ﬁrst observe that the refreshing gadget used in the original, ﬂawed,
algorithm does not enjoy strong non-interference. Second, we note
that the refreshing gadget used in the ﬁxed, secure, algorithm is
indeed strongly non-interfering, and we show that one can prove
the probing security of the ﬁxed algorithm, based simply on the
assumption that the refreshing gadget is strongly non-interfering.
Generalizing these observations, we prove that every non-interfering
algorithm can be turned into a strongly non-interfering algorithm,
by processing its inputs or its output with a strongly non-interfering
refreshing gadget. We also provide more general results about the
composition of strongly non-interfering gadgets.

2. Formal proofs. We develop and implement an automated
method, inspired from [4], for checking strong non-interference. We
apply our automated veriﬁer for strong non-interference to several
gadgets from the literature and some other interesting compositions,
for orders t ≤ 6. For several more widely-used gadgets, we further
use EasyCrypt [6] to provide machine-checked proofs of t-probing
security for all t.

3. Type-based enforcement of probing security. We deﬁne an
expressive language for specifying a large class of non-interference
properties with cardinality constraints. Our language can be seen
as a variant of the ﬁrst-order theory of ﬁnite sets with cardinality
constraints [33, 3], and can be used to specify baseline probing
security and strong non-interference, among others. Then, we deﬁne
a type system that enforces probing policies and prove its soundness.
Furthermore, we show how to model in our language of probing
policies the notion of afﬁne gadget, and we show how it helps
improve the precision of type-checking.

4. Certifying Masking Transformation. As a proof of concept, we
implement a type inference algorithm and a certifying masking trans-
formation that takes as input an arithmetic expression and returns
a masked algorithm typable by our type system.2 Our transforma-
tion improves over prior works by selectively inserting refreshing
gadgets only at points where type-checking would otherwise fail.
This strategy leads to improved efﬁciency while retaining provable
soundness.

5. Practical evaluation. We evaluate our type system and mask-
ing transformation on complete algorithms at various orders, often
achieving provable t-probing security levels far beyond the state-of-
the-art for algorithms of those sizes, and with better performance

2The cryptography literature often refers to such transformations as
masking compilers. We purposely avoid this terminology, since the
terms is used in programming languages for transformations that
output executable code

than most known (provably secure) algorithms in terms of time,
memory and randomness complexity.

Related work. Section 9 discusses related work in more detail.
Here we focus on recent work on automated tools for the veriﬁ-
cation of synthesis of masked algorithms, starting with Moss et
al. [28], who point out and leverage connections between probing
security and probabilistic information-ﬂow for ﬁrst-order boolean
masking schemes. Subsequent works in this direction accommodate
higher-order and arithmetic masking, using type systems and SMT
solvers [8], or model counting and SMT solvers [21, 20]. Although
approaches based on model counting are more precise than early ap-
proaches based on type systems and can be extended to higher-order
masking schemes, their algorithmic complexity constrains their ap-
plicability. In particular, existing tools based on model counting can
only analyze ﬁrst or second order masked implementations, and can
only deal with round-reduced versions of the algorithms they con-
sider (for instance, only analyzing a single round of Keccak at order
1, and algorithms for ﬁeld operations at orders 2 and higher). Break-
ing away from model counting, Barthe et al. [4] develop efﬁcient
algorithms for analyzing the security of masked algorithms in the
probing model. Their approach outperforms previous work and can
analyze a full block of AES at ﬁrst-order, reduced-round (4 rounds)
AES at the second-order, and several S-box computation algorithms
masked at the third and fourth orders. However, their work does not
readily scale either to higher orders or to larger algorithms, mainly
due to the lack of composition results.

Our work also bears some connections with language-based secu-
rity, and in particular with work on the speciﬁcation and the enforce-
ment of conﬁdentiality policies using techniques from programming
languages. For instance, our work has similarities with the work of
Pettai and Laud [30], who develop techniques for proving security
of multi-party computations in the presence of strong adversaries,
and work by Zdancewic et al. [34], who propose a compiler that
partitions programs for secure distributed execution.
Mathematical preliminaries. A function µ : B → R≥0 is a
(discrete) distribution over B if the subset supp(µ) of B with non-
b∈supp(µ) µ(b) = 1.
We let D(B) denote the set of discrete distributions over B. Equality
of distributions is deﬁned as pointwise equality of functions. Dis-
tributions can be given a monadic structure with the two operators
munit(·) and mlet · = ·. For every b ∈ B, munit(b) is the unique
distribution µ such that µ(b) = 1. Moreover, given µ : D(B) and
M : B → D(C), mlet x = µ inM x is the unique distribution µ(cid:48)

zero weight under µ is discrete and moreover(cid:80)

over C such that µ(cid:48)(c) =(cid:80)

b µ(b) M (b)(c).

We often use the notion of marginals. The ﬁrst and second
marginals of a distribution µ ∈ D(B1 × B2) are the distributions
π1(µ) ∈ D(B1) and π2(µ) ∈ D(B2) given by

π1(µ)(b1) =

µ(b1, b2)

π2(µ)(b2) =

µ(b1, b2).

The notion of marginal readily extends to distributions over ﬁnite
maps (rather than pairs).

2. A BIRD’S EYE VIEW OF STRONG NON-

INTERFERENCE

Before formalizing our deﬁnitions, we give an intuitive descrip-
tion of our language for gadgets and of our security notions, based
on simple examples.

(cid:88)

b2∈B2

(cid:88)

b1∈B1

117(cid:74)a(cid:75) =(cid:74)c(cid:75). The gadget ﬁrst makes local copies of individual input

Gadgets and Positions. Gadget RefreshM2 (Gadget 1) shows
the description in our language of a mask refreshing gadget for t = 2.
The gadget takes as input an encoding variable a ∈ K3, where K
is some ﬁnite ring and returns a new encoding c ∈ K3 such that
shares aı (for 0 ≤ ı ≤ 2) of a into local variables cı (for 0 ≤ ı ≤ 2).
After this ﬁrst step, we sample uniform random elements from K
into a local variable r and perform some ring operations. Finally, the
algorithm returns a vector in K3, constructed from the ﬁnal value of
local variables c0, c1 and c2.

Gadget 1 SNI Mask Refreshing with t = 2

function RefreshM2(a)
c0,0 ← a0; c1,0 ← a1; c2,0 ← a2;
r0
r1
r2
return (cid:104)c0,2, c1,2, c2,2(cid:105)

$← K; c0,1 ← c0,0 ⊕ r0; c1,1 ← c1,0 (cid:9) r0;
$← K; c0,2 ← c0,1 ⊕ r1; c2,1 ← c2,0 (cid:9) r1;
$← K; c1,2 ← c1,1 ⊕ r2; c2,2 ← c2,1 (cid:9) r2;

Note that the gadget is written in single static assignment (SSA)
form, an intermediate representation in which each variable is de-
ﬁned exactly once. Having gadgets written in SSA form allows
us to easily refer to the value of a particular variable at a partic-
ular point in the program–simply by referring to its name, which
corresponds to a unique deﬁnition. In this paper, we refer to po-
sitions in gadgets and algorithms, which correspond exactly to in-
termediate variables. We distinguish between three different kinds
of positions: input positions, which correspond to shares of the
gadget’s input (here, IRefreshM2 = {a0, a1, a2}), output positions,
which correspond to the variables that appear in the gadget’s re-
RefreshM2 = {c0,2, c1,2, c2,2}), and internal
turn vector (here, Oint
positions, which refer to all other positions (here, Oext
RefreshM2 =
{c0,0, c1,0, c2,0, c0,1, c1,1, c2,1, r0, r1, r2}). Intuitively, this separa-
tion allows us to distinguish between direct observations made by
the adversary into a gadget (as internal positions), output shares
about which the adversary may have learned some information by
probing gadgets that use them as input (as output positions), and
shares of the gadget’s inputs (as input positions) about which the
adversary is now learning information. In the following, we often
write “the joint distribution of a set of positions” to discuss the
joint distribution of the variables deﬁned at these positions in the
gadget (in order). For example, referring to RefreshM2, the joint
distribution of the ordered set O = (cid:104)c0,1, c2,2(cid:105) of positions can be
described as the following function of a, where we use $ to denote a
fresh uniform random sample in K (using indices to denote distinct

(cid:52)
= (cid:104)a0 ⊕ $0, (a2 (cid:9) $1) (cid:9) $2(cid:105).

samples):(cid:74)RefreshM2(cid:75)O(a)

Probing Security and Non-Interference. The RefreshM2
gadget is known to be 2-probing secure, or 2-non-interfering (2-NI)
in our terminology, in the sense that the joint distribution of any
set of at most 2 of its positions, corresponding to adversary probes,
depends on at most 2 shares of the gadget’s inputs. This guarantees,
if the input encoding is uniform, that no information about it leaks
through any 2 probes in the circuit.
Considering again the set O = (cid:104)c0,1, c2,2(cid:105) of positions and its

distribution(cid:74)RefreshM2(cid:75)O, it is easy to see–purely syntactically–

that it depends, at most, on shares a0 and a2 of the gadget’s input
encoding. Similarly considering all possible pairs of positions, we
can prove that each of them has a joint distribution that depends on
at most two shares of a.

Strong Non-Interference. Probing security is generally not
composable: combining t-probing secure gadgets does not necessar-
ily yield a t-probing secure algorithm [16]. Our main contribution
is a new and stronger notion of security for gadgets, which we dub
strong non-interference (or SNI), which does support some com-
positional reasoning. SNI reinforces probing security by requiring
that the number of input shares on which the distribution of a given
position set may depend be determined only by the number of in-
ternal positions present in that set. For example, consider again
position set O = (cid:104)c0,1, c2,2(cid:105) in RefreshM2, and note that it contains
only one internal position (c0,1). We have seen that the joint dis-

tribution(cid:74)RefreshM2(cid:75)O of that position set syntactically depends
(cid:74)RefreshM2(cid:75)O(a) = (cid:104)$0, (a2 (cid:9) $1) (cid:9) $2(cid:105) (since the ring addition

on two shares of a. However, it can be equivalently expressed as
⊕ is a bijection of each of its arguments and $0 is a fresh and uni-
form ring element). This shows that the distribution in fact depends
on at most one share of a (here a2). In fact, it can be shown that
RefreshM2 is 2-SNI. More generally, surprisingly many gadgets
from the literature achieve SNI.

However, and not unexpectedly, some gadgets from the literature
do not satisfy SNI. Consider for instance RefreshA2 (Gadget 2). It is
easy to see that the gadget is 2-NI (each position cı, depends only on
input share aı, and each position ri is completely independent from
the input encoding). Still, looking at position set O(cid:48) = (cid:104)c0,1, c1,1(cid:105),
which is composed of one internal position and one external one,
(cid:52)
= (cid:104)a0 ⊕ $0, a1 ⊕ $0(cid:105)
does depend on more than one share of a. RefreshA2 is therefore
not 2-SNI.

we see that the distribution(cid:74)RefreshA2(cid:75)O(cid:48)

Gadget 2 NI Mask Refreshing with t = 2

function RefreshA2(a)
c0,0 ← a0; c1,0 ← a1; c2,0 ← a2;
r0
r1
return (cid:104)c0,2, c1,1, c2,1(cid:105)

$← K; c0,1 ← c0,0 ⊕ r0; c1,1 ← c1,0 (cid:9) r0;
$← K; c0,2 ← c0,1 ⊕ r1; c2,1 ← c2,0 (cid:9) r1;

Compositional Probing Security. This small difference be-
tween NI and SNI has a signiﬁcant effect on security when used
in larger circuits. Indeed, the output positions of a strongly non-
interfering gadgets do not depend on any of its input positions: when
considered independently from internal positions (in the absence of
internal probes), their distribution is uniform; and in the presence
of internal probes, their joint distribution is entirely determined by
that of the probed internal positions. This is essential in supporting
compositional reasoning about the probing security of larger algo-
rithms. In particular, this makes algorithms of the form shown in
Algorithm 3 (for some gadgets R and G of the appropriate types
that work on 2-encodings) easy to prove t-NI if R is RefreshM2,
and illustrates why composition might fail if R is instantiated with
RefreshA2.

Alg. 3 An abstract algorithm

function Alg2(a)
b := R(a);
c := G(a, b);
return c

A key observation to make is that an adversary that observes 2
positions internal to G may learn 2 shares of both a and b. If R is
instantiated with RefreshA2 (and is thus only 2-probing secure), the

1182 shares of b can be used to infer information about 2 further shares
of a, which may give the adversary full knowledge of all 3 shares
of a. On the other hand, if R is instantiated with RefreshM2 (and is
thus 2-SNI), the adversary’s knowledge of 2 shares of b does not
propagate any further back to a, and the algorithm remains secure.

Broader uses of SNI. The notion of strong non-interference,
and the masking transformation we deﬁne here have already found
applications in follow-up work. Belaïd et al. [9] prove using our
compositional techniques that their new non-interfering multiplica-
tion can be securely combined with the strongly non-interfering one
of Rivain and Prouff [32] to build a strongly non-interfering AES
S-box with reduced randomness complexity. Similarly, Goudarzi
and Rivain [24] use our method to ensure the compositional secu-
rity of their bitsliced software implementation of AES. Battistelo et
al. [7] use and prove t-SNI for their O(n · log n) mask refreshing
gadget, allowing further randomness complexity reductions without
loss of probing security. Coron et al. [17] use and prove t-SNI for
their efﬁcient parallel algorithms for the evaluation of SBoxes.

Outline. The rest of the paper is organized as follows. Section 3
formalizes our two-tier language for masked gadgets and algorithms,
the notion of position, and their semantics, as well as the joint dis-
tribution of a set of positions. Sections 4, and 5 formalize probing
security as t-non-interference, and formally deﬁne our new notion of
t-strong-non-interference before illustrating it more generally with
simple examples. In Section 6, we deﬁne a language to describe
probing policies, and deﬁne a simple type system for enforcing
probing policies of algorithms, formalizing and generalizing the
simple compositional arguments outlined here. In Section 7, we
present an automated method to verify the strong non-interference
of arbitrary gadgets at small ﬁxed orders, that follows the approach
used above in arguing that RefreshM2 is 2-SNI, and adapts algo-
rithms by Barthe et al. [4] to reduce the number of position sets to
consider. In Section 8, we extend our type system into a masking
transformation which automatically builds a masked algorithm from
an unprotected program, carefully choosing the proper locations
for strongly non-interfering refreshing gadgets. We evaluate on full
cryptographic algorithms the performance of the type system, of the
resulting transformation, and of the transformed algorithms. Sec-
tion 9 discusses related work on leakage models, composition for
probing security, and other masking transformations. We interleave
discussions of interesting leads for future work.

3. MASKED ALGORITHMS

The formal development of this paper is based on a minimalist
2-tier language.3 The lower tier models gagdets as sequences of
probabilistic and (three-address code) deterministic assignments,
whereas the upper tier models algorithms as sequences of gadget
calls (we assume that each gadget call is tagged with its instruction
number (cid:96) ∈ N). The formal deﬁnition of the language is given in
Figure 1, where we use vector notations ((cid:126)x, . . . ) to denote (t + 1)-
tuples of scalar variables, ı to denote indices (such that 0 ≤ ı ≤ t)
in such a tuple or in encoding variables, and exponents ·ı to denote
the projection of a component out of a (t + 1)-tuple (for example
aı, or (cid:126)xı). We require gadgets and algorithms to be well-formed,
3However, the veriﬁcation tool supports richer settings to which
the theory extends smoothly and our examples are written in a
more general language, closer to our implementation, that supports
static for loops, direct assignments to shares (aı ← e), arbitrary
expressions on the right-hand side of assignments, and a broader
return syntax. For example, Gadget 4 shows generic descriptions of
the mask refreshing algorithms from Section 2.

algorithm
alg. body

gadget
gadget body

P (a1, . . . , an) ::= s; return a
s

::= b :=(cid:96) G(a1, . . . , an)

| s; s

G(a1, . . . , an) ::= c; return (cid:126)x
c

::= x $← K
| x ← e
| c; c

expressions

e

::= x, y, . . .

| aı
| x (cid:63) y

gadget call.
call seq.

prob. assign.
det. assign.
assign. seq.

variable
ıth-share of a
ring operation

Figure 1: Syntax of masked algorithms

in the following sense. A gadget G is well-formed if its body is
in SSA form, i.e.
its scalar variables appear at most once on the
left-hand side of an assignment. An algorithm P is well-formed if
all its gadgets are deﬁned and well-formed, and if, in all gadget calls
b := G(a1, . . . , an), variables b, a1, . . . , ak are pairwise disjoint.
We now turn to the semantics of gadgets and algorithms. Cru-
cially, the semantics of gadgets and algorithms is instrumented
to keep track of the joint distribution of all intermediate values
computed during execution. Formally, we assume that scalar and
encoding variables take values in K and Kt+1, where K is the carrier
set of a ﬁnite ring (K, 0, 1,⊕,(cid:9),(cid:12)). We let Val = Kt+1 denote
the set of encoded values. Furthermore, we let A denote the set
of encoding variables and deﬁne the set of global memories as
Mem = A → Kt+1. Likewise, we let V denote the set of scalar
variables and deﬁne the set of local memories as LMem = V (cid:42) K
and extended local memories as ELMem = (N × V) (cid:42) K. Then,

the semantics of a gagdet G is a function(cid:74)G(cid:75) that takes as input a
function(cid:74)P(cid:75) that takes as input a global memory and returns a dis-

global memory and returns a distribution over pairs of local mem-
ories and values. Likewise, the semantics of an algorithm P is a

tribution over extended local memories and values. The semantics
is outlined in Figure 2.

In order to deﬁne probing security, we ﬁrst deﬁne a notion of
position that corresponds to the intuition illustrated in Section 2.
First, we deﬁne the set I (cid:52)
= {aı | a ∈ A, 0 ≤ ı ≤ t} of input
positions (these correspond to shares of encodings used in the gadget
or algorithm), the set O (cid:52)
= I ∪ V of positions (composed of input
positions and scalara variables) and the set O+ (cid:52)
= I ∪ (N × V)
of extended positions (where scalar variables are tagged with a
label in N to differentiate between uses of a variable in different
gadgets). The input positions of a gadget G and of an algorithm
P are denoted by IG and IP respectively and contain exactly those
elements of I that correspond to encoding variables that occur in
G or P . Likewise, the set of positions of a gadget G and of an
algorithm P are denoted by OG ⊆ O and OP ⊆ O+ respectively
and consist of all positions that occur in a gadget G, and all extended
positions that occur in an algorithm P .
To capture the joint distribution of a set of positions O in a gadget
G or an algorithm P (with O ⊆ OG, resp. O ⊆ OP ), we take
the marginal of the gadget or algorithm’s semantics with respect

to O. These are denoted by(cid:74)G(cid:75)O : Mem → D(O → K) and
(cid:74)P(cid:75)O : Mem → D(O → K) respectively.4
that one can reﬁne the type of(cid:74)G(cid:75) given in Figure 2 to Mem →

4In order to justify that the marginals have the required type, observe

119with m ∈ Mem and lm ∈ LMem

: K

: D(Mem × LMem)

with m ∈ Mem and lm ∈ LMem

(cid:74)e(cid:75)(m, lm)
(cid:74)x(cid:75)(m, lm) = lm(x)
(cid:74)aı(cid:75)(m, lm) = m(a)ı
(cid:74)x (cid:63) y(cid:75)(m, lm) = lm(x) (cid:63) lm(y)
(cid:74)c(cid:75)(m, lm)
(cid:74)x ← e(cid:75)(m, lm) = munit(m, lm{x ←(cid:74)e(cid:75)(m, lm)})
(cid:74)x $← K(cid:75)(m, lm) = mlet v = UK in munit(m, lm{x ← v})
(cid:74)c1; c2(cid:75)(m, lm) = mlet (m1, lm1) =(cid:74)c1(cid:75)(m, lm) in(cid:74)c2(cid:75)(m1, lm1)
(cid:74)G(cid:75)(m)
(cid:74)G(cid:75)(m) = mlet (m1, lm1) =(cid:74)c(cid:75)(m,∅) in munit(lm1, lm1((cid:126)x))
(cid:74)s(cid:75)(m, elm)
(cid:74)s1; s2(cid:75)(m, elm) = mlet (m1, elm1) =(cid:74)s1(cid:75)(m, elm) in(cid:74)s2(cid:75)(m1, elm1)
(cid:74)P(cid:75)(m)
(cid:74)P(cid:75)(m) = mlet (m1, elm1) =(cid:74)s(cid:75)(m,∅) in munit(elm1, m1(b))

: D(ELMem × Val)

: D(LMem × Val)

with m ∈ Mem and G(a1, . . . , an) ::= c; return (cid:126)x

with m ∈ Mem and P (a1, . . . , an ::= s; return b

(cid:74)b :=(cid:96) G(c1, . . . , cn)(cid:75)(m, elm) = mlet (lm1, v) =(cid:74)G(cid:75)(m{a0, . . . , at ← m(c0), . . . , m(ct)}) in munit(m{b ← v}, elm (cid:93) elm1)

with m ∈ Mem, elm ∈ ELMem and G(a1, . . . , an) ::= c; return (cid:126)x
where elm1 is the map deﬁned by setting only elm1((cid:96), v) = lm(v) for all v ∈ dom(lm)

: D(Mem × ELMem)

where m{x1, . . . , xn ← v1, . . . , vn} denotes the map m where xi is updated with vi for each i in increasing order, and (cid:93) denotes the disjoint
union of partial maps.

Figure 2: Semantics of gadgets and algorithms

4. BASELINE PROBING SECURITY

We ﬁrst review the basic notion of probabilistic non-interference
and state some of its key properties. As usual, we start by introduc-
ing a notion of equivalence on memories.

DEFINITION 1. Let G be a gadget, and let I ⊆ IG. Two memo-
ries m, m(cid:48) ∈ Mem are I-equivalent, written m ∼I m(cid:48), whenever
m(a)ı = m(cid:48)(a)ı for every aı ∈ I.
Next, we deﬁne probabilistic non-interference.

DEFINITION 2. Let I ⊆ IG and O ⊆ OG. A gadget G is

(I,O)-non-interfering (or (I,O)-NI), iff(cid:74)G(cid:75)O(m) =(cid:74)G(cid:75)O(m(cid:48))
dency set of O as depsetG(O) =(cid:84){ I | G is (I,O)-NI }; thus,

for every m, m(cid:48) ∈ Mem s.t. m ∼I m(cid:48).
For every gadget G and every position set O, we deﬁne the depen-
depsetG(O) is the smallest set I ⊆ IG such that G is (I,O)-NI.
LEMMA 1. Let G be a gadget and O ⊆ OG be a set of positions

in G. G is (depsetG(O),O)-NI.
We conclude this section by providing an alternative deﬁnition of
non-interference, in the style of simulation-based security.

LEMMA 2. A gadget G is (I,O)-NI iff there exists a simulator
Sim ∈ (I → K) → D(O → K) such that for every m ∈ Mem,

(cid:74)G(cid:75)O(m) = Sim(m|I)

where m|I is the restriction of m to elements in I.
This observation is useful to connect the information-ﬂow based for-
mulation of probing security introduced below with the simulation-
based formulations of probing security often used by cryptographers.
Indeed, the dependency set depsetG(O) can be interpreted as a set
of G’s input shares that is sufﬁcient to perfectly simulate the joint
distribution of positions in O to an adversary.

Next we deﬁne our baseline notion of probing security, which
we call t-non-interference, and state some of its basic properties.

D(Val × (OG → K)). Similarly, one can reﬁne the type of(cid:74)P(cid:75) to

Mem → D(Val × (OP → K)) .

The notion of t-non-interference is based on the notion of degree
of an input set, which we deﬁne ﬁrst. Given an input set I and an
(cid:52)
encoding variable a, we deﬁne the set I|a
= I ∩ a of positions in
I that correspond to shares of a. Further, we deﬁne the degree of an
input set I as (cid:107)I(cid:107) (cid:52)
= maxa |I|a| (where | · | is the standard notion
of cardinality on ﬁnite sets). This notion captures the intuition that
the adversary should not learn all shares of any single encoding
variable, by bounding the information an adversary may learn about
any of a gadget’s shared inputs through positions probed internally
to that gadget.

(PROBING SECURITY). A gadget G is t-non-
DEFINITION 3
interfering (or t-NI) if (cid:107)depsetG(O)(cid:107) ≤ |O| for every O ⊆ OG
such that |O| ≤ t.

The next lemma establishes that t-NI is already achieved under a
weaker cardinality constraint on the dependency set. Variants of
Lemma 3 in simulation-based settings appear in [11, 9].

LEMMA 3. A gadget G is t-NI iff (cid:107)depsetG(O)(cid:107) ≤ t for every

O ⊆ OG s.t. |O| ≤ t.

The notion of t-non-interference extends readily to algorithms.
In addition, one can prove that an algorithm is secure iff the gadget
obtained by fully inlining the algorithm is secure.

LEMMA 4. A program P is t-NI iff the gadget inline(P ) ob-

tained by full inlining is t-NI.

The lemma sheds some intuition on the deﬁnition of t-NI for algo-
rithms. However, we emphasize that verifying fully inlined algo-
rithms is a bad strategy; in fact, previous work indicates that this
approach does not scale, and that composition results are needed.

5. STRONG NON-INTERFERENCE

We introduce strong non-interference, a reinforcement of prob-
ing security based on a ﬁner analysis of cardinality constraints for
dependency sets. Informally, strong non-interference distinguishes
between internal and output positions, and requires that the depen-
dency set of a position set O has degree ≤ k, i.e. contains at most

120k shares of each encoding input, where k is the number of internal
positions in O. Formally, a local variable is an output position for
G if it appears in the return tuple of G, and an internal position
otherwise. Let Oint (resp. Oext) denote the subset of internal (resp.
output) positions of a set O. Strong t-non-interference requires
that the degree of depset(O) is smaller than |Oint|, rather than
|O|. Intuitively, a t-SNI gadget information-theoretically hides de-
pendencies between each of its inputs and its outputs, even in the
presence of internal probes. This essential property is what supports
compositional reasoning.

DEFINITION 4

(STRONG PROBING SECURITY). A gadget G
is t-strongly non-interfering (or t-SNI) if (cid:107)depsetG(O)(cid:107) ≤ |Oint|
for every position set O such that |O| ≤ t.

Gadget 4 Mask Refreshing Gadgets
0: function RefreshA(a)
1: c0 ← a0
for i = 1 to t do
2:
r $← K
3:
c0 ← c0 ⊕ r
4:
ci ← ai (cid:9) r
5:
return c
6:
(4a) Addition-Based Mask

Refreshing

for i = 0 to t do
ci ← ai
for i = 0 to t do
for j = i + 1 to t do
r $← K
ci ← ci ⊕ r
cj ← cj (cid:9) r

0: function RefreshM(a)
1:
2:
3:
4:
5:
6:
7:
8:
(4b) Multiplication-Based Mask

return c

Refreshing

Fortunately, many gadgets from the literature achieve strong non-
interference (see Table 1 and Section 7). First, we note that gad-
get RefreshM (Gadget 4b) generalized from Ishai, Sahai and Wag-
ner [25] is t-SNI for all t. (A proof sketch for this proposition is
given in Appendix A.)

PROPOSITION 1. RefreshM (Gadget 4b) is t-SNI.

On the contrary, the additive refreshing gadget RefreshA (Gad-
get 4a) achieves NI but fails to achieve SNI. Interestingly, Coron’s
linear-space variant of Ishai, Sahai and Wagner’s multiplication [13,
Alg. 6] (Gadget 5a) and the MultLin gadget for securely multiplying
linearly dependent inputs [16, Alg. 5] (Gadget 5b) are both strongly
non-interfering. The proof of SNI for Gadget 5a is easy to adapt to
the more standard quadratic-space multiplication gadget, since they
compute the same intermediate values in different orders.

PROPOSITION 2. The SecMult gadget (Gadget 5a) is t-SNI.

PROPOSITION 3. The MultLin gadget (Gadget 5b) is t-SNI.

The proofs of Propositions 1, 2 and 3 have been machine-checked
using EasyCrypt [6]. We also provide more detailed game-based
proof sketches in the full version of this paper.

Strong Non-Interference for Mask Refreshing. We now
show how choosing a t-SNI refreshing gadget over a t-NI refreshing
gadget critically inﬂuences the security of algorithms. Concretely,
we provide a separating example, which captures the essence of
the ﬂaw in the inversion algorithm of Rivain and Prouff [32]. The
example considers two algorithms (Algorithm 6) which compute a
cube in GF(28) by squaring and multiplying (using, for illustration
purposes, some t-NI gadgets Square and Mult for squaring and
multiplication). Both algorithms use a refreshing gadget between the
two operations, but they differ in which gadget they use: BadCube

Gadget 5 Some arithmetic gadgets
0: function SecMult(a, b)
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
(5a) Masked multiplication [13]

for i = 0 to t do
ci ← ai (cid:12) bi
for i = 0 to t do
for j = i + 1 to t do
r $← K
ci ← ci (cid:9) r
t ← ai (cid:12) bj
r ← r ⊕ t
t ← aj (cid:12) bi
r ← r ⊕ t
cj ← cj ⊕ r

return c

0: function MultLin(a)
for i = 0 to t do
1:
ci ← ai (cid:12) g(ai)
2:
for i = 0 to t do
3:
for j = i + 1 to t do
4:
r $← K
5:
r(cid:48) $← K
6:
ci ← ci (cid:9) r
7:
t ← ai ⊗ g(r(cid:48)) ⊕ r
8:
t ← t ⊕ (r(cid:48) ⊗ g(ai))
9:
t ← t ⊕ (ai ⊗ g(aj (cid:9) r(cid:48))
10:
t ← t⊕((aj(cid:9)r(cid:48))⊗g(ai))
11:
cj ← cj ⊕ t
12:
13:
(5b) x⊗ g(x) with linear g [16, Alg. 5]

return c

(Gadget 6a) uses the additive refreshing gagdet RefreshA, which
is t-NI but not t-SNI, and Cube (Gadget 6b) uses the RefreshM
gadget, which is t-SNI. This simple difference is fundamental for
the security of the two algorithms.

Alg. 6 Cubing procedures (with K = GF(28))

function BadCube(x)
y1 := Square(x)
y2 := RefreshA(y1)
z := Mult(x, y2)
return z

(6a) Insecure Cubing

function Cube(x)
y1 := Square(x)
y2 := RefreshM(y1)
z := Mult(x, y2)
return z

(6b) Secure Cubing

LEMMA 5

is t-NI for all t.

([16]). BadCube is not t-NI for any t ≥ 2. Cube

Coron et al. [16] exhibit proofs for both statements. In Appendix A,
we give a compact proof of t-NI for Cube that does not exhaustively
consider all (t + 1)-tuples of positions in Cube. The key argu-
ment is that RefreshM being t-SNI essentially renders useless any
information on y2 the adversary may have learned from observing
positions in Mult: those do not add any shares of y1 to the depen-
dency set we compute for RefreshM, and therefore do not inﬂuence
the shares of x that appear in the ﬁnal dependency set for Cube. On
the other hand, using a simple t-NI mask refreshing gadget (such
as RefreshA) in its place breaks the proof by allowing us to deduce
only that each position in the multiplication may depend on 2 shares
of x.

In Section 6, we show how the proof of Lemma 5 can be improved
and extended into a compositional proof for the (repaired) inversion
algorithm of Rivain and Prouff [32], and, in fact, outlines a general
mehodology for proving algorithms t-NI or t-SNI.

A Generic Composition Result. Before formalizing and au-
tomating this proof process to obtain precise probing security proofs
for large circuits, we now give a coarse but simple composition
result that illustrates the generality of SNI. Informally, an algorithm
is t-NI if all its gadgets verify t-NI and every non-linear usage of
an encoding variable is guarded by t-SNI refreshing gadgets. In
addition, it shows that processing all inputs, or the output of a t-NI
algorithm with a t-SNI gadget (here RefreshM) sufﬁces to make the
algorithm t-SNI.

121PROPOSITION 4. An algorithm P is t-NI provided all its gad-
gets are t-NI, and all encoding variables are used at most once as
argument of a gadget call other than RefreshM. Moreover P is
t-SNI if it is t-NI and one of the following holds:

• its return expression is b and its last instruction is of the form

b := RefreshM(a);

• its sequence of encoding parameters is (a1, . . . , an), its ith
instruction is b :=i RefreshM(ai) for 1 ≤ i ≤ n, and ai is
not used anywhere else in the algorithm.

6. ENFORCING PROBING POLICIES

We ﬁrst deﬁne an expressive assertion language for specifying
sets of position sets, and then introduce probing policies, which yield
a convenient formalism for deﬁning a large class of information ﬂow
policies with cardinality constraints.

(PROBING POLICY).

DEFINITION 5
1. A probing assertion is a pair (Γ, φ), where Γ is a map from
encoding variables to expressions in the theory of ﬁnite sets,
and φ is a cardinality constraint. Each probing assertion
(Γ, φ) deﬁnes a set of subsets of positions for a ﬁxed algorithm

P , denoted by(cid:74)(Γ, φ)(cid:75). (The syntax and semantics of set

expressions and cardinality constraints is explained below.)

2. A probing policy is a pair of assertions

(Γin, φin) ⇐= (Γout, φout)

where (Γout, φout) is the post-assertion and (Γin, φin) is the
pre-assertion.
3. Algorithm P satisﬁes the policy (Γin, φin) ⇐= (Γout, φout),
written P |= (Γin, φin) ⇐= (Γout, φout), if for every posi-

tion set O ∈ (cid:74)(Γout, φout)(cid:75), P is (I,O)-NI for some input
position set I ∈(cid:74)(Γin, φin)(cid:75).

The syntax of set expressions and cardinality constraints is given by
the following grammar:

S := X | ∅ | S ∪ S
(set expr.)
(arith. expr.)
l
(cardinality constr.) φ := l ≤ l | φ ∧ φ

:= |S| | |O(cid:96)| | t | l + l

The syntax distinguishes between variables X that are drawn from
a set X of names–that we will use to represent sets of shares of an
encoding variable, and variables O, annotated with a label (cid:96), that are
drawn from a disjoint set Ω of names–that we will use to represent
sets of internal positions probed in the gadget used at instruction (cid:96).

REMARK 1. Our syntax for set expressions and constraints is
a fragment of the (decidable) theory of ﬁnite sets with cardinality
constraints. It would be possible to include other set-theoretical
operations, as in [33, 3]. However, we have found our core fragment
sufﬁcient for our purposes.

The semantics of assertions is deﬁned using the notion of valuation.
A valuation µ is a mapping from names in X and Ω to ﬁnite sets,
such that ∀ X ∈ X . µ(X) ⊆ {0, . . . , t} and ∀ O(cid:96) ∈ Ω. µ(O(cid:96)) ⊆
OG(cid:96), where G(cid:96) is the gadget called at instruction (cid:96). Every valuation
µ deﬁnes, for every set expression S, a set of share indices µ(S) ⊆
{0, . . . , t} and for every arithmetic expression l an interpretation
µ(l) ∈ N, using the intended interpetation of symbols (i.e. ∪ is
interpreted as set union, + is interpreted as addition, . . . ).

DEFINITION 6
1. µ satisﬁes a cardinality constraint φ, written µ |= φ, if

(INTERPRETATION OF ASSERTIONS).

µ(l1) ≤ µ(l2) for every conjunct l1 ≤ l2 of φ.

(cid:91)

{aı | ı ∈ µ(Γ(a))} ∪(cid:91)
(cid:74)(Γ, φ)(cid:75) = {µ(Γ) | µ |= φ}

O

a

3. The interpretation of (Γ, φ) is the set

2. The interpretation of Γ under µ is the set

µ(Γ) =

µ(O)

We now turn to the deﬁnition of the type system.

DEFINITION 7. Algorithm P (a1, . . . , an) ::= s; return r has
type (Γin, φin) ⇐= (Γout, φout) if the judgment (cid:96) s : (Γin, φin) ⇐=
(Γout, φout) is derivable using the typing rules from Figure 3. We
denote this fact (cid:96) P : (Γin, φin) ⇐= (Γout, φout).
We brieﬂy comment on the rules. Rule (SEQ) is used for typing
the sequential composition of gadget calls and is as expected. The
remaining rules are used for interpreting the non-interference prop-
erties of gadgets. We now detail them.

Rule (SNI-GADGET) is used for typing calls to a SNI-gadget
with an arbitrary post-assertion and a pre-assertion in which the
mapping Γout is updated to reﬂect the dependencies created by the
call, and the constraint is strenghtened with the cardinality constraint
imposed by strong non-interference. The rule has a side condition
|O(cid:96)| + |Γout(b)| ≤ t ensuring that the total number of positions
whose dependency set by G we are considering is bounded by t,
where O(cid:96) is the name of the subset of positions that are observed in
the current gadget (called at line (cid:96)), and Γout(b) is the set of shares
of b the adversary has information about from positions probed in
gadgets that use b later on in the algorithm. This side condition
is veriﬁed under the condition φout. Note that the variables X (cid:96)
k
are fresh, and annotated with the label (cid:96) that identiﬁes the current
instruction, and an indice k that identiﬁes the argument. Rule (NI-
GADGET) is similar but deals with NI-gadgets, and therefore extends
k.
Γin with correspondingly weaker constraints on the X (cid:96)

We now turn to the rule for afﬁne gadgets. Informally, we say
that a gadget is afﬁne if it manipulates its input encodings share by
share; this includes standard implementations of ring addition, for
example, but also of many other functions that are linear in K (for
example, multiplication by a constant–or public–scalar, or shifts in
the representation when addition is bitwise). Formally, we say that
a gadget G with parameters (a1, . . . , an) is afﬁne iff there exists a
family of procedures f0, . . . , ft such that G is an inlining of

x0 ← f0(a0
1, . . . , a0
return (cid:104)x0, . . . , xt(cid:105);

n); . . . ; xt ← ft(at

1, . . . , at

n);

1, . . . , aı

Thus, one can deﬁne a mapping η : OG → {0, . . . , t} such that for
every position π ∈ OG, η(π) = ı if π occurs in the computation
of the ıth share (i.e. in the computation of fı(aı
n)). The
ﬁne-grained information about dependencies given by this notion of
afﬁnity is often critical to proving the probing security of algorithms.
Therefore, it is important to capture afﬁnity in our type system.
Let O = Oint (cid:93) Oext be a position set, split between internal
and output positions. The afﬁne property ensures that the joint
distribution of O depends only on input positions in η(Oint∪Oext),
and furthermore that |η(Oint ∪ Oext)| = |η(Oint)| + |η(Oext)| =
|η(Oint)| + |Oext|. Rule (AFFINE) interprets this afﬁne property
into our type system, using Γout(b) and a fresh O(cid:96) for Oext and
Oint, respectively, and encoding η(O(cid:96)) into an abstract existential
set X (cid:96). The condition |X (cid:96)| ≤ |O(cid:96)| precisely captures the fact that
|η(O)| ≤ |O| for all O.

DEFINITION 8

(TYPING OF AN ALGORITHM). Let P be an

algorithm deﬁned by P (a1, . . . , an) ::= s; return r.

122(cid:96) b := G(a1, . . . , an) : (Γin, φin) ⇐= (Γ, φ)

(cid:96) c : (Γ, φ) ⇐= (Γout, φout)

(cid:96) b := G(a1, . . . , an); c : (Γin, φin) ⇐= (Γout, φout)

(SEQ)

G is t-NI

φout ⇒ |Γout(b)| + |O(cid:96)| ≤ t
(cid:96) b :=(cid:96) G(a1, . . . , an) : (Γin, φout ∧ (
φout ⇒ |Γout(b)| + |O(cid:96)| ≤ t

G is t-SNI

Γin := Γout{b,∀ k. ak ← ∅,∀ k. Γout(ak) ∪ X (cid:96)
k}

|X (cid:96)

k| ≤ |Γout(b)| + |O(cid:96)|)) ⇐= (Γout, φout)

Γin := Γout{b,∀ k. ak ← ∅,∀ k. Γout(ak) ∪ X (cid:96)
k}

(cid:96) b :=(cid:96) G(a1, . . . , an) : (Γin, φout ∧ (

k| ≤ |O(cid:96)|)) ⇐= (Γout, φout)
Γin := Γout{b, ak ← ∅, Γout(ak) ∪ Γout(b) ∪ X (cid:96)}
G is afﬁne
(cid:96) b :=(cid:96) G(a1, . . . , an) : (Γin, φout ∧ |X (cid:96)| ≤ |O(cid:96)|) ⇐= (Γout, φout)

1≤k≤n

|X (cid:96)

(AFFINE)

(cid:94)

1≤k≤n

(cid:94)

(NI-GADGET)

(SNI-GADGET)

where Γ{∀ k. vk ← ∀ k. ek} stands for the map Γ where each vk is updated to map to ek and all other indices are left untouched.

Figure 3: Typing rules

φin such that (cid:96) P : (Γin, φin) ⇐= (∅,(cid:80)
(cid:80)
φin ⇒ |Γin(ai)| ≤ (cid:80)

P is well-typed for NI, written (cid:96)NI P , whenever there exist Γin,
1≤(cid:96)≤|P| |O(cid:96)| ≤ t) and,
for each i ∈ {1, . . . , n}, φin ⇒ |Γin(ai)| ≤ t.
P is well-typed for SNI, written (cid:96)SNI P , whenever there ex-
ist Γin, φin such that (cid:96) P : (Γin, φin) ⇐= ([r ← O],|O| +
1≤(cid:96)≤|P| |O(cid:96)| ≤ t) and, for each i ∈ {1, . . . , n}, we have
1≤(cid:96)≤|P| |O(cid:96)| (where [v ← x] is the map

that associates x to v and is everywhere else undeﬁned).

When typing for NI, we start from the empty map for Γout and
simply consider any output position observed as if they were internal.
However, the same cannot be done when typing for SNI since we
need to distinguish clearly between internal positions in one of the
O(cid:96), used to type the gadget at instruction (cid:96), and output positions
in O, initially used as the set of position of the algorithm’s return
encoding.

PROPOSITION 5
If (cid:96) s : (Γin, φin) ⇐= (Γout, φout) then also

(SOUNDNESS OF THE TYPE SYSTEM).

|= P : (Γin, φin) ⇐= (Γout, φout)

If (cid:96)NI P then P is t-NI
If (cid:96)SNI P then P is t-SNI

An Example: Rivain and Prouff’s inversion algorithm.
We now illustrate the type system by describing a typing deriva-
tion on Rivain and Prouff’s algorithm for computing inversion in
GF(28) [32, 16]. An algorithm implementing this operation securely
is shown in Figure 4, with some information relevant to its typing
derivation. We recall that the function x (cid:55)→ x2n is linear (for any n)
in binary ﬁelds and rely on afﬁne gadgets pow2, pow4, and pow16
to compute the corresponding functionalities.

We present the typing derivation in the slightly unusual form of a
table, in Figure 4, which shows the code of the inversion algorithm
along with the values of Γin and φin (φin shows only the part of
the constraint that is added at that program point, not the entire
constraint) at each program point. By the sequence rule, these serve
as Γout and φout for the immediately preceding program point. The
table also shows the side conditions checked during the application
of gadget rules where relevant. It is easier to understand the type-
checking process by reading the table from the bottom up.

As per the deﬁnition of well-typedness for SNI, we start from a
state where the output position set O is associated to the algorithm’s
return encoding r5, and where the constraint contains only the global

constraint that the whole position set O ∪(cid:83)

(cid:96) O(cid:96) is of cardinality
bounded by t. When treating line 9, we know that SecMult is t-SNI
and try to apply rule (SNI-GADGET). We check that the number
of positions observed in this instance of SecMult is bounded by t
(which trivially follows from the global constraint), and construct
the new value of (Γin, φin) following the rule: since neither of the
call’s input encodings are used below, new sets X 9
2 are
associated to the call’s inputs and the SNI constraints are added
to φin. Applying the rules further until the top of the program
is reached, and performing the appropriate set unions in Γ when
an encoding variable is used more than once, we observe that the
resulting pre-assertion is such that |Γin(a)| ≤ |O1| +|O2| +|O3| +
(cid:96) O(cid:96), and therefore proves that this inversion algorithm

|O9| ≤(cid:80)

1 and X 9

is t-SNI.

Finally, one can remark that the instances of SecMult at line 6
and 8 do not in fact need to be t-SNI. As pointed out by Belaïd et
al. [9], using a t-NI multiplication gadget at these program points is
sufﬁcient to construct a type derivation for SNI.

7. SNI CHECKER FOR GADGETS

We present an automated method for proving that gadgets (or
small algorithms, by inlining) are t-SNI at small ﬁxed orders (up
to t = 6 for ring multiplication). We then give some experimental
results.

Veriﬁcation algorithm. We adapt to t-SNI the algorithmic con-
tributions of Barthe et al. [4] that support the automated veriﬁcation,
on small to medium gadgets and for small orders, of Ishai, Sahai and
Wagner’s circuit privacy property [25], which is similar to our t-NI.
Their work builds on two observations: ﬁrst, every probabilistic
program P taking input x and performing a (statically) bounded
number (say q) of uniform samplings over K is equivalent, in the
sense below, to composing a deterministic program P † taking inputs
x and r with random sampling over Kq. Formally, for every x,

Second, P satisﬁes (I,O)-NI iff there exists a function f such that
for every x1, x2 and r, such that x1 ∼I x2

(cid:74)P(cid:75)(x) = mlet r = UKq in(cid:74)P
†(cid:75)O(x1, r) =(cid:74)P
(cid:74)P

†(cid:75)O(x, r)
†(cid:75)O(x2, f (x2, r))

and moreover f (x,·) is a bijection for every x. The latter equality
can be easily veriﬁed for all x and r using standard tools, therefore
the key to proving non-interference is to exhibit a suitable func-
tion f. Their algorithm proceeds by incrementally deﬁning bijec-

123Γin
1 ∪ X 1
2 ∪ X 9
2 ∪ X 2
a : X 3
2 ∪ X 2
2 ; z1 : X 9
a : X 3
1
z2 : X 3
2 ; z1 : X 9
a : X 3
2 ;
1
1 ∪ X 8
2 ∪ X 5
r1 : X 6
z1 : X 9
2 ;
1 ; w1 : X 8
z1 : X 9
r1 : X 6
2 ;
1 ; w1 : X 8
z1 : X 9
r1 : X 6
2 ;
r2 : X 8
2 ; w1 : X 8
z1 : X 9
2 ;
2 ; w1 : X 8
z1 : X 9
r3 : X 8
2 ;
1
z1 : X 9
r4 : X 9
2 ;
1
r5 : O

1 ∪ X 4
2 ∪ X 5
2 ; w2 : X 6
2
1 ∪ X 7

1

φin
|X 1| ≤ |O1|
|X 2
1| ≤ |O2|
|X 3
k| ≤ |O3|
|X 4| ≤ |O4|
|X 5
1| ≤ |O5|
|X 6
k| ≤ |O6|
|X 7| ≤ |O7|
|X 8
k| ≤ |O8|
|X 9
k| ≤ |O9|

|O| +(cid:80)

1≤(cid:96)≤9 |O(cid:96)| ≤ t

Instructions
function invert(a)
z1 :=1 pow2(a)
z2 :=2 Refresh(z1)
r1 :=3 SecMult(z2, a)
w1:=4 pow4(r1)
w2:=5 Refresh(w1)
r2 :=6 SecMult(r1, w2)
r3 :=7 pow16(r2)
r4 :=8 SecMult(r3, w1)
r5 :=9 SecMult(r4, z1)
return r5

Side conditions

|X 6

1 ∪ X 8

2 ∪ X 5

|X 6

|X 3

1| + |O2| ≤ t
1 ∪ X 4| + |O3| ≤ t
2| + |O5| ≤ t
1 ∪ X 7| + |O6| ≤ t
|X 9
1| + |O8| ≤ t
|O| + |O9| ≤ t

|X 8

Figure 4: a−1 in GF(28)

tions f1, . . . , fn satisfying the two conditions above until evenutally

(cid:74)P †(cid:75)O(x, fn(x, r)) can be rewritten into an expression that does

not depend syntactically on secrets.
However, even with efﬁcient algorithms to prove that a program
P is (I,O)-NI for some position set O, proving that P is t-NI
remains a complex task: indeed this involves proving (I,O)-NI for
all O with |O| ≤ t. Simply enumerating all possible position sets
quickly becomes untractable as P and t grow. Therefore, [4] uses
the following fact: if P is (I,O(cid:48))-NI then it is also (I,O)-NI for
all O ⊆ O(cid:48). Hence, checking that P is (I,O(cid:48))-NI for some large
set O(cid:48) is sufﬁcient to prove that P is (I,O)-NI for every O ⊆ O(cid:48),
and this using only one proof of non-interference. In particular, they
exhibit algorithms that rely on the explicit construction of the bijec-
tion fn to efﬁciently extend the set O from which it was constructed
into a potentially much larger set O(cid:48) for which that bijection still
proves (I,O(cid:48))-NI. Further, they also exhibit algorithms that rely on
such extensions to prove the existence of I such that (I,O)-NI for
all position sets O much more efﬁciently than by considering all
position sets individually.

We adapt their algorithms by changing the core bijection-ﬁnding
algorithm in two ways: i. rather than being applied to a modiﬁed
program that includes the initial uniform sampling of secret encod-
ings, our core algorithm works directly on the gadget description
(this is necessary to ensure that we prove t-SNI instead of alterna-
tive security notions); and ii. our search for a bijection stops when

(cid:74)P †(cid:75)O(x, fn(x, r)) can be simpliﬁed into an expression that syn-

tactically depends on at most d shares of the secret (for the desired
bound d on (cid:107)I(cid:107), that is d = |Oint| for SNI), rather than stopping
when all syntactic dependencies on the secret input have been re-
moved. We note that replacing the bound d from the second point
with d = t yields a veriﬁcation algorithm for t-NI (by Lemma 3).
Our full algorithm is given in the long version [5].

Evaluation. We evaluate the performance of our SNI veriﬁer on
some medium and small gadgets: SecMult, Coron’s linear-memory
ring multiplication algorithm [13, Alg. 6]; MultLin, Coron et al.’s
algorithm for the computation of functionalities of the form x(cid:12)g(x)
for some linear g [16, Alg. 5]; Add, the standard afﬁne gadget for
the addition of two encodings; RefreshA, the weakly secure mask
refreshing algorithm from Rivain and Prouff [32]; RefreshIterk, the
iterated additive refresh proposed by Coron [13, Alg. 4] for sup-
porting more efﬁcient composition in his full model (we make ex-
plicit the number of iterations k); WeakMult, the generic reduced-
randomness multiplication algorithm proposed by Belaïd et al. [9].
Table 1 sums up our ﬁndings and some veriﬁcation statistics.

8. MASKING TRANSFORMATION

As a proof of concept, we implement our type system for a com-
fortable subset of C that includes basic operators, static for loops,
table lookups at public indices, and mutable secret state, and ex-
tended with libraries that implement core gadgets for some choices
of K. Moreover, we deﬁne a source-to-source certifying masking
transformation, which takes an unprotected program and returns a
masked algorithm accepted by our type system, selectively inserting
refreshing gadgets as required for typing to succeed. We note that
the transformation itself need not be trusted, since its result is the
ﬁnal program on which typing is performed.

Furthermore, the choice of C as a supporting language is for con-
venience, since many of the algorithms we consider have reference
implementations written in C. In particular, we do not claim that
compiling and executing the C programs produced by our masking
transformation will automatically yield secure executables: our veri-
ﬁcation results are on algorithms described in the C language rather
than on C programs in general. Making use of these veriﬁcation
results in practice still requires to take into account details not taken
into account in the probing model. Although an important problem,
this is out of the scope of this paper and a research area on its own:
for example Balasch et al. [2] consider some of the issues involved
in securely implementing probing secure algorithms.

8.1 Implementation

We now give an overview of the different passes performed by
our masking transformation. The input programs use explicit typing
annotations to distinguish public variables (for example, public
inputs, or public loop indices) from sensitive or secret variables that
must be encoded. We call public type any type outside of those used
for denoting variables that must be encoded.

Parsing and Pre-Typing. This pass parses C code into our in-
ternal representation, checks that the program is within the supported
subset of C, performs C type-checking and checks that variables
marked as sensitive (variables given type K) are never implicitly cast
to public types. Implicit casts from public types to K (when compat-
ible, for example, when casting a public uint8_t to a protected
variable in GF(28)) are replaced with public encoding gadgets (that
set one share to the public value and all other shares to 0).

Gadget Selection and Generic Optimizations. This pass
heuristically selects optimal gadgets depending on their usage. For
example, multiplication of a secret by a public value can be com-
puted by an afﬁne gadget that multiplies each share of the secret,

124Order 1

1-SNI

Order 2

2-SNI

Order 3

3-SNI

Order 4

4-SNI

Order 5

5-SNI

Order 6

6-SNI

Gadget

SecMult
MultLin
RefreshA
RefreshIter2
RefreshIter3
WeakMult

Time
0.07s
0.07s
0.07s
0.08s

–

0.07s





–


Time
0.08s
0.08s
0.08s
0.08s
0.09s
0.07s








Time
0.09s
0.15s
0.08s
0.08s
0.08s
0.09s








Time
0.86s
1.19s

–

0.08s
0.09s

–



–


–

Time
36.40s
54.13s

–

0.13s
0.14s

–



–


–

Time
37min
48min

–
.20s
.54s
–



–


–

Table 1: Experimental Results for the SNI Veriﬁer

whereas the multiplication of two secrets must be performed using
the SecMult gadget. Further efforts in formally proving precise
types for specialized core gadgets may also improve this optimiza-
tion step. Since the encoding replaces scalar-typed variables (passed
by value) with array-typed variables (passed by reference), it is also
necessary to slightly transform the program to ensure the correctness
of the resulting program. In addition, we also transform the input
program into a form that more closely follows the abstract language
from Figure 1, which makes it easier to type-check.

Type Inference and Refresh Insertion. This is the core of
our transformation. We implement a type inference algorithm for
the type system of Section 6. The algorithm simpliﬁes policies
on the ﬂy, supports inferred types on sub-algorithms as gadget-
invocation types, and fails when the simpliﬁed policy is inconsistent.
Failure arises exactly when a refreshing operation is needed. At
the cost of tracking some more information and reinforcing the
typing constraint on sub-algorithms, we use this observation to
automatically insert Refresh gadgets where required. When type
inference fails, the variable whose masks need to be refreshed is
duplicated and one of its uses is replaced with the refreshed duplicate.
To avoid having to re-type the entire program after insertion of a
refresh gadget, our transformation keeps track of typing information
for each program point already traversed and simply rewinds the
typing to the program point immediately after the modiﬁcation.

Code Generation. Finally, once all necessary mask refresh-
ing operations have been inserted and the program has been type-
checked, we produce a masked C program. This transformation
is almost a one-to-one mapping from the instructions in the type-
checked programs to calls to a library of veriﬁed core gadgets or
to newly deﬁned gadgets. Some cleanup is performed on loops to
clarify the ﬁnal code whenever possible, and to remove initialization
code on normalized gadgets. Interestingly, our transformation pro-
duces a (set of) C ﬁles that is parameterized by the masking order
t. Producing executable versions of that algorithm at a particular
order, for example to evaluate its performance, is as easy as deﬁning
a pre-processor macro at compile-time.

8.2 Practical Evaluation

To test the effectiveness of our transformation, we apply it to
different algorithms, generating equivalent masked algorithms at
various orders. We apply our transformation to the following pro-
grams: AES ((cid:12)), a full computation (10 rounds including key sched-
ule) of AES-128 masked using the multiplication gadget, and im-
plemented in GF(28); AES (x (cid:12) g(x)), a full computation (10
rounds including key schedule) of AES-128 masked using Coron et
al.’s gadget for computing x (cid:12) g(x), and implemented in GF(28);
Keccak, a full computation (24 rounds) of Keccak-f[1600], im-
plemented in GF(264); Simon, a block of Simon(128,128), im-

plemented in GF(264); Speck, a block of Speck(128,128), im-
plemented in GF(2)64, and using one of the following modular
addition algorithms; AddLin, Coron, Großschädl and Vadnala’s
algorithm [15] for the computation of modular addition on boolean-
masked variables (in GF(2)64); AddLog, Coron et al.’s improved
algorithm [14] for the computation of modular addition on boolean-
masked variables (in GF(2)64). We ﬁrst discuss the performance of
our veriﬁer and the veriﬁcation results before discussing the practical
signiﬁcance, in terms of time, memory and randomness complexity
of our masking transformation. Finally, we discuss examples on
which our tool implementation could be improved.

Veriﬁcation Performance and Results. Table 2 shows re-
source usage statistics for generating the masked algorithms (at any
order) from unprotected implementations of each algorithm. The
table shows the number of mask refreshing operations inserted in
the program5, the compilation time, and the memory consumption.
For Keccak, we show two separate sets of ﬁgures: the ﬁrst, marked
“no refresh”, is produced by running our algorithm transformer on a
bare implementation of the algorithm; the second, marked “refresh
in χ”, is produced by running our tool on an annotated implemen-
tation, where a mask refreshing operation is manually inserted in
the χ function and the tool used for veriﬁcation only. We discuss
discrepancies between the numbers on these two lines in Section 9,
and consider the “refresh in χ” set of statistics in all discussions
until then. We ﬁrst note the signiﬁcant improvements these results
represent over the state of the art in formal veriﬁcation for probing
security. Indeed, our closest competitor [4] report the veriﬁcation
of all 10 rounds of AES (including key schedule) at order 1 in 10
minutes, and could not verify all 10 rounds for higher orders. In
contrast, our tool veriﬁes the probing security of Rivain and Prouff’s
algorithm [32] as ﬁxed by Coron et al. [16] at all orders in less than
a second.6 Further, we note that the masked algorithms our transfor-
mation produce for modular addition are the ﬁrst such algorithms
known to be t-probing secure using only t + 1 shares. Indeed, the
original proofs [15, 14] rely on the ISW framework and make use
of 2t + 1 shares to obtain t-probing security. We further note that
Coron, Großschädl and Vadnala’s algorithm [15] does not require
the insertion of mask refreshing operations, and is thus t-probing
secure with t + 1 shares as it was originally described. Finally,
we note that, to the best of our knowledge, the results obtained on
Keccak, Simon and Speck constitute the ﬁrst generic higher-order
masking schemes for these algorithms.

5Note that the number of mask refreshing operations executed dur-
ing an execution of the algorithm may be much greater, since the
sub-procedure in which the insertion occurs may be called multiple
times.
6This excludes the once-and-forall cost of proving the security of
core gadgets.

125Algorithm
AES ((cid:12))
AES (x (cid:12) g(x))
AddLin
AddLog
Keccak (no refresh)
Keccak (refresh in χ)
Simon
Speck (AddLin)
Speck (AddLog)

0
0

0

# Refresh
2 per round

Time
0.09s
0.05s
0.01s
log2(k) − 1
0.01s
1 per round ∼20min
18.20s
0.38s
0.35s
0.21s

67 per round
61 per round
66 per round

Mem.
4MB
4MB
4MB
4MB
23GB
456MB
15MB
38MB
8MB

Table 2: Resource usage during masking and veriﬁcation

Performance of Masked Algorithms. Table 3 reports the
time taken to execute the resulting programs 10,000 times at various
orders on an Intel(R) Xeon(R) CPU E5-2667 0 @ 2.90GHz with
64GB of memory running Linux (Fedora). As an additional test
to assess the performance of the generated algorithms at very high
orders, we masked an AES computation at order 100: computation
took ∼0.11 seconds per block. For AES and Speck, the ﬁgures
shown in the “unmasked” column are execution times for the input
to our transformation: a table-based implementation of AES or an
implementation of Speck that uses machine arithmetic, rather than
Coron, Großschädl and Vadnala’s algorithm would be much faster,
but cannot be masked directly using our transformation. Although
these observations do highlight the cost of security, we note that
using RefreshA when masking the AES SBox does not incur a
signiﬁcant timing gain for any of the masking orders we tested (t ≤
20). However, the randomness cost is greatly reduced, which may
be signiﬁcant in hardware or embedded software settings. Further
research in reducing the randomness cost of SNI mask refreshing,
or of other gadgets, serves to make security less costly [9, 1, 7]. We
also conﬁrm the 15% timing improvements reported by Coron et
al. [16] when implementing the AES SBox using their gadget for
computing x (cid:12) g(x).

We now look more closely at statistics for the modular addition
algorithms AddLin and AddLog and their effects on the perfor-
mance of masked algorithms for Speck. We ﬁrst note that proving
AddLog t-NI requires the addition of a mask refreshing gadget,
whereas AddLin does not. Despite this additional cost, however,
AddLog is better than AddLin when word size k grows, since it
saves k − log(k) multiplications and replaces them with a single
mask refreshing operation. These performance gains on modular ad-
dition become overwhelming when seen in the context of a masked
algorithm for Speck, which computes one 64-bit modular addition
per round. It would be interesting to consider using our transformer
to produce masked algorithms for other efﬁcient circuits for modu-
lar addition [27] and measure their performance impact in terms of
randomness, time and memory when masked.

9. DISCUSSIONS AND RELATED WORK

Here, we further discuss the relation between the deﬁnitions and
results reported here and existing and future work in theoretical and
practical cryptography. Our discussions focus mainly on: i. adver-
sary and leakage models; ii. compositional security notions; iii. the-
oretical and practical masking transformations; and iv. limitations
of our deﬁnitions and tools.

Adversary and Leakage Models for Masking. We have
considered security in the probing model of Ishai, Sahai and Wag-
ner [25], which is particularly well-suited to automated analysis due

to its tight relation to probabilistic non-interference. In particular,
our notion of t-NI is equivalent to the notions of t-probing secu-
rity and perfect t-probing security used by Carlet et al. [11] and
others [32, 16].

Despite its broad usage in the literature, the practical relevance
of the probing model is not immediately obvious: in practice, side-
channel adversaries observe leakage traces, which contain noisy
information about all intermediate computations, rather than precise
information about some. This threat model is much more closely
captured by the noisy leakage model, ﬁrst introduced by Chari et
al. [12] and extended by Prouff and Rivain [31]. The noisy leakage
model is much more complex and makes security proofs on masked
algorithms signiﬁcantly more involved, and much harder to verify.
Duc, Dziembowski and Faust [18] show that proving probing
security allows one to estimate the practical (noisy leakage) secu-
rity of a masked algorithm. While Duc, Faust and Standaert [19]
empirically show that some of the factors of Duc et al.’s bound [18]
are likely proof artefacts, the remainder of the bound, and in par-
ticular a factor that includes the size of the circuit, seems to be
tight. Intuitively, Duc et al. [19] essentially show that the probing
security order gives an indication of the smallest order moment of
the distribution over leakage traces that contains information about
the secret, whereas the size of the circuit the adversary can probe is
an indicator of how easy it is to evaluate higher-order moments.

Composition, and Region and Stateful Probing. This ob-
servation makes clear the importance of also considering more
powerful probing adversaries that may place t probes in each of
some (pre-determined) regions of an algorithm (the t-region probing
model). For example, each core gadget (ﬁeld operations and mask
refreshing operation) could be marked off as a separate region (as
in [18]). More recently, and in work contemporary with that pre-
sented here, Andrychowicz, Dziembowski and Faust [1] consider
a more general notion of region whose size must be linear in the
security parameter (and masking order), and exhibit a mask refresh-
ing gadget that is linear in size and fulﬁlls, in the probing model,
the reconstructibility and re-randomization properties from Faust et
al. [22]. We now discuss the implications of reconstructibility and re-
randomization, and their relation to our notion of SNI, based on the
similarity of Prop. 4 with Ishai et al.’s remark on “Re-randomized
outputs” [25], before discussing the applicability of SNI to security
in the region and stateful probing models [25].

Intuitively, a gadget is t-reconstructible whenever any t of its
positions can be simulated using only its (shared) inputs and out-
puts, and a gadget is re-randomizing whenever its output encoding
is uniform and t-wise independent even if its input encoding is
completely known. Our SNI notions combines both considerations.
Formulating it in similar terms, a gadget is t-SNI whenever any
t of its positions can be simulated using only its (shared) inputs,
and if its output encoding is uniform and (t − d)-wise independent
even if d shares of each of its inputs are known (for all d such that
0 ≤ d < t). Expressed in this way, it is clear that SNI is slightly
weaker than “reconstructible and re-randomizable” in the probing
model. This allows us to automatically verify that a gadget is SNI
for some ﬁxed t, whereas reconstructibility and re-randomization
are more complex. In addition, the ability to combine the use of
SNI and weaker (NI or afﬁne) gadgets in a ﬁne-grained way allows
us to more precisely verify the security of large algorithms in mod-
els where the adversary can place t probes in the entire algorithm.
We leave a formal investigation of the relation between SNI and
“reconstructibility and re-randomization” as future work.

Based on reconstructibility and re-randomization, Faust et al. [22,
1] prove elegant and powerful composition results that in fact apply

126Algorithm
AES ((cid:12))

AES (x (cid:12) g(x))

Keccak
Simon

Speck (AddLin)
Speck (AddLog)

unmasked Order 1 Order 2 Order 3 Order 5 Order 10 Order 15 Order 20
59.567s
50.588s
156.050s
20.140s
603.261s
72.358s

21.318s
17.875s
42.764s
6.136s
231.423s
19.991s

38.007s
32.552s
92.476s
11.551s
357.153s
42.032

3.326s
3.209s
3.057s
0.526s
10.281s
1.231s

4.516s
4.368s
5.801s
0.873s
20.053s
2.258s

8.161s
7.707s
13.505s
1.782s
47.389s
5.621

0.078s
0.078s
0.238s
0.053s
0.022s
0.022s

2.697s
2.278s
1.572s
0.279s
4.361s
0.529s

Table 3: Time taken by 10,000 executions of each program at various masking orders

in the more powerful region probing and stateful probing mod-
els [25], where the adversary may (adaptively) place t probes in
each region (or in each subsequent iteration) of the algorithm. It
is worth noting that our SNI notion also enables composition in
these two models: indeed, it is easy to see that any two 2t-SNI
algorithms (our regions) can be composed securely when the adver-
sary can place t probes in each of them. Further, our composition
techniques also support elegant constructions that support compo-
sitional security proofs in the region and stateful probing models
without doubling the number of shares computations are carried out
on (instead, simply doubling the number of shares at region bound-
aries). We give details of these robust composition results in the full
version. Depending on the size of regions that are considered, these
robust composition results may bring signiﬁcant performance gains
in terms of randomness and time complexity.

Finally, our notion of SNI and the automated veriﬁcation tech-
niques presented allow the efﬁcient, precise and automated veriﬁca-
tion of t-SNI inside each region, an issue which is not addressed by
the works of Faust et al. [22, 1].

Existing Masking Transformations. Ishai, Sahai and Wag-
ner [25] and others [18, 1] also propose simple masking transfor-
mations that turn unprotected algorithms (or boolean or arithmetic
circuits) into protected masked algorithms. Ishai, Sahai and Wag-
ner [25] forgo the use of mask refreshing gadgets by doubling the
number of shares on which masked computations occur–with a
quadratic impact on performance and randomness complexity. Faust
et al. [18, 1] rely on making sure that all gadgets used in the masked
algorithm are reconstructible and re-randomizing. This guarantees
security in a stronger probing model, but incurs an even greater loss
of performance. By contrast, our transformation attempts to decide
whether a mask refreshing operation is required to ensure security
in the probing model, and our core contributions (the notion of SNI
and the type-checker) do support composition in stronger probing
models, whilst still allowing the proofs of security within regions to
be handled precisely.

Coron [13] proposes schemes for masking lookups at secret or
sensitive indices in public tables. We have not investigated whether
or not the proposed algorithms are SNI or simply NI, and whether
or not establishing these properties can be done by adapting our
type-system or if it should be done in a different way (either as
a direct proof or using the checker from Section 7). We note in
passing that part of the result by Coron [13], namely that using
between each query to the masked S-box supports
RefreshIter2t+1
security in the stateful probing model is subsumed and improved by
the robust composition results described in the full version.

2t

The security analysis of masking schemes in the t-probing model
is connected to techniques from multi-party computation, exploited
in parallel lines of research by threshold implementations [29, 10].
In particular, higher-order threshold implementations are exposed
to similar security issues due to composition, although they offer
additional protection against practical considerations not captured

in standard probing models, namely glitches. We believe that the
results discussed here are in fact applicable to the compositional
security analysis of threshold implementations but leave a formal
investigation of these links as future work.

Reﬁning SNI. We now discuss some limitations of our current
implementation, and leads for future theoretical work that may yield
signiﬁcant practical improvements.

Alg. 7 Semi Public Modular Addition in GF(2)k
function AddPub(x, y)
w := x (cid:12) y
a := x ⊕ y
w := RefreshM(w)
u := w (cid:28) 1
for i = 2 to k − 1 do
ua := u (cid:12) a
u := ua ⊕ w
u := u (cid:28) 1
z := a ⊕ u
return z

function AddPub(x, y)
w := x (cid:12) y
a := x ⊕ y
u := w (cid:28) 1
for i = 2 to k − 1 do
a(cid:48) := RefreshM(a)
ua := u (cid:12) a(cid:48)
u := ua ⊕ w
u := u (cid:28) 1
z := a ⊕ u
return z

(7a) Masked algorithm produced by

(7b) Masked algorithm produced by

our tool

hand

The ﬁrst point we wish to discuss is the case of Keccak, for which
algorithm transformation is prohibitively expensive. This issue is
due to our handling of static for loops: indeed, our tool unrolls
them to perform type-checking and rolls them back up afterwards
if possible (otherwise leaving them unrolled in the ﬁnal algorithm).
For smaller algorithms, this is not a problem, but unrolling all
24 rounds of Keccak-f, along with all the loops internal to each
iteration, yields a very large program that is then backtracked over
each time a mask refreshing operation is inserted. Reﬁning our
non-interference notions to multi-output gadgets and algorithms
would allow us to signiﬁcantly improve our tool’s handling of loops
and high-level composition, whilst gaining a better understanding
of probing security in such scenarios. This improved understanding
may in turn help inform the design of primitives that are easier to
protect against higher-order probing.

Second, we discuss our greedy policy for the insertion of mask re-
freshing algorithms. In our experiments, we consider a version of the
linear-time modular addition algorithm [15] whose second argument
is a public (non-shared) value (for example, a round counter, as in
Speck). We show its code, as produced by our masking transformer,
in Gadget 7a, and display a hand-masked variant in Gadget 7b,
slightly abusing notations by denoting simple gadgets with the sym-
bol typically used for their unprotected versions. Notice that the
variable w is used once per loop iteration, and that our tool refreshes
each of them, while it is sufﬁcient to mask only the ﬁrst one. Im-
proving our gadget selection algorithm to detect and implement
this optimization—and others—would be an interesting avenue for

127future work, that could help improve our understanding of the effect
on security of compiler optimizations.

Acknowledgements. The work presented here was supported
by projects S2013/ICE-2731 N-GREENS Software-CM, ANR-10-
SEGI-015 PRINCE and ANR-14-CE28-0015 BRUTUS, and ONR
Grants N000141210914 and N000141512750, as well as FP7 Marie
Curie Actions-COFUND 291803.

10. REFERENCES
[1] Marcin Andrychowicz, Stefan Dziembowski, and Sebastian
Faust. Circuit compilers with O(1/ log(n)) leakage rate. In
EUROCRYPT 2016, LNCS, pages 586–615. Springer,
Heidelberg, 2016.

[2] Josep Balasch, Benedikt Gierlichs, Vincent Grosso, Oscar

Reparaz, and François-Xavier Standaert. On the cost of lazy
engineering for masked software implementations. In
Proceedings of the Smart Card Research and Advanced
Application Conference (CARDIS), volume 8968 of LNCS,
pages 64–81. Springer, Heidelberg, November 2014.

[3] Kshitij Bansal, Andrew Reynolds, Clark Barrett, and Cesare

Tinelli. A new decision procedure for ﬁnite sets and
cardinality constraints in SMT. In Proceedings of the 8th
International Joint Conference on Automated Reasoning
(IJCAR), volume 9706 of LNCS, pages 82–98, June 2016.

[4] Gilles Barthe, Sonia Belaïd, François Dupressoir, Pierre-Alain
Fouque, Benjamin Grégoire, and Pierre-Yves Strub. Veriﬁed
proofs of higher-order masking. In Elisabeth Oswald and
Marc Fischlin, editors, EUROCRYPT 2015, Part I, volume
9056 of LNCS, pages 457–485. Springer, Heidelberg, April
2015.

[5] Gilles Barthe, Sonia Belaïd, François Dupressoir, Pierre-Alain
Fouque, Benjamin Grégoire, Pierre-Yves Strub, and Rébecca
Zucchini. Strong non-interference and type-directed
higher-order masking. Cryptology ePrint Archive, Report
2015/506, 2015. http://eprint.iacr.org/2015/506.

[6] Gilles Barthe, François Dupressoir, Benjamin Grégoire, César
Kunz, Benedikt Schmidt, and Pierre-Yves Strub. EasyCrypt:
A tutorial. In Foundations of Security Analysis and Design VII
- FOSAD 2012/2013 Tutorial Lectures, pages 146–166, 2013.
[7] Alberto Battistello, Jean-Sébastien Coron, Emmanuel Prouff,

and Rina Zeitoun. Horizontal side-channel attacks and
countermeasures on the ISW masking scheme. In CHES 2016,
LNCS, pages 23–29. Springer, Heidelberg, 2016.

[8] Ali Galip Bayrak, Francesco Regazzoni, David Novo, and

Paolo Ienne. Sleuth: Automated veriﬁcation of software
power analysis countermeasures. In Guido Bertoni and
Jean-Sébastien Coron, editors, CHES 2013, volume 8086 of
LNCS, pages 293–310. Springer, Heidelberg, August 2013.

[9] Sonia Belaïd, Fabrice Benhamouda, Alain Passelègue,

Emmanuel Prouff, Adrian Thillard, and Damien Vergnaud.
Randomness complexity of private circuits for multiplication.
In EUROCRYPT 2016, LNCS, pages 616–648. Springer,
Heidelberg, 2016.

[10] Begül Bilgin, Benedikt Gierlichs, Svetla Nikova, Ventzislav

Nikov, and Vincent Rijmen. Higher-order threshold
implementations. In Palash Sarkar and Tetsu Iwata, editors,
ASIACRYPT 2014, Part II, volume 8874 of LNCS, pages
326–343. Springer, Heidelberg, December 2014.

[11] Claude Carlet, Emmanuel Prouff, Matthieu Rivain, and

Thomas Roche. Algebraic decomposition for probing security.
In Rosario Gennaro and Matthew J. B. Robshaw, editors,

CRYPTO 2015, Part I, volume 9215 of LNCS, pages 742–763.
Springer, Heidelberg, August 2015.

[12] Suresh Chari, Charanjit S. Jutla, Josyula R. Rao, and Pankaj

Rohatgi. Towards sound approaches to counteract
power-analysis attacks. In Michael J. Wiener, editor,
CRYPTO’99, volume 1666 of LNCS, pages 398–412. Springer,
Heidelberg, August 1999.

[13] Jean-Sébastien Coron. Higher order masking of look-up

tables. In Phong Q. Nguyen and Elisabeth Oswald, editors,
EUROCRYPT 2014, volume 8441 of LNCS, pages 441–458.
Springer, Heidelberg, May 2014.

[14] Jean-Sébastien Coron, Johann Großschädl, Mehdi Tibouchi,
and Praveen Kumar Vadnala. Conversion from arithmetic to
boolean masking with logarithmic complexity. In Gregor
Leander, editor, FSE 2015, volume 9054 of LNCS, pages
130–149. Springer, Heidelberg, March 2015.

[15] Jean-Sébastien Coron, Johann Großschädl, and

Praveen Kumar Vadnala. Secure conversion between boolean
and arithmetic masking of any order. In Lejla Batina and
Matthew Robshaw, editors, CHES 2014, volume 8731 of
LNCS, pages 188–205. Springer, Heidelberg, September 2014.

[16] Jean-Sébastien Coron, Emmanuel Prouff, Matthieu Rivain,
and Thomas Roche. Higher-order side channel security and
mask refreshing. In Shiho Moriai, editor, FSE 2013, volume
8424 of LNCS, pages 410–424. Springer, Heidelberg, March
2014.

[17] Jean-Sébastien Coron, Aurélien Greuet, Emmanuel Prouff,
and Rina Zeitoun. Faster evaluation of sboxes via common
shares. In CHES 2016, LNCS, pages 498–514. Springer,
Heidelberg, 2016.

[18] Alexandre Duc, Stefan Dziembowski, and Sebastian Faust.

Unifying leakage models: From probing attacks to noisy
leakage. In Phong Q. Nguyen and Elisabeth Oswald, editors,
EUROCRYPT 2014, volume 8441 of LNCS, pages 423–440.
Springer, Heidelberg, May 2014.

[19] Alexandre Duc, Sebastian Faust, and François-Xavier

Standaert. Making masking security proofs concrete - or how
to evaluate the security of any leaking device. In Elisabeth
Oswald and Marc Fischlin, editors, EUROCRYPT 2015, Part
I, volume 9056 of LNCS, pages 401–429. Springer,
Heidelberg, April 2015.

[20] Hassan Eldib and Chao Wang. Synthesis of masking

countermeasures against side channel attacks. In Proceedings
of the 26th International Conference on Computer Aided
Veriﬁcation., pages 114–130, 2014.

[21] Hassan Eldib, Chao Wang, and Patrick Schaumont.

SMT-based veriﬁcation of software countermeasures against
side-channel attacks. In Proceedings of the 20th International
Conference on Tools and Algorithms for the Construction and
Analysis of Systems, pages 62–77, 2014.

[22] Sebastian Faust, Tal Rabin, Leonid Reyzin, Eran Tromer, and
Vinod Vaikuntanathan. Protecting circuits from leakage: the
computationally-bounded and noisy cases. In Henri Gilbert,
editor, EUROCRYPT 2010, volume 6110 of LNCS, pages
135–156. Springer, Heidelberg, May 2010.

[23] Louis Goubin and Jacques Patarin. DES and differential

power analysis (the “duplication” method). In Çetin Kaya Koç
and Christof Paar, editors, CHES’99, volume 1717 of LNCS,
pages 158–172. Springer, Heidelberg, August 1999.

[24] Dahmun Goudarzi and Matthieu Rivain. How fast can

higher-order masking be in software? Cryptology ePrint
Archive, Report 2016/264, 2016. http://eprint.iacr.org/.

128[25] Yuval Ishai, Amit Sahai, and David Wagner. Private circuits:

Securing hardware against probing attacks. In Dan Boneh,
editor, CRYPTO 2003, volume 2729 of LNCS, pages 463–481.
Springer, Heidelberg, August 2003.

[26] Paul C. Kocher, Joshua Jaffe, and Benjamin Jun. Differential

power analysis. In Michael J. Wiener, editor, CRYPTO’99,
volume 1666 of LNCS, pages 388–397. Springer, Heidelberg,
August 1999.

[27] Thomas Walker Lynch. Binary adders, 1996.
[28] Andrew Moss, Elisabeth Oswald, Dan Page, and Michael

Tunstall. Compiler assisted masking. In Emmanuel Prouff and
Patrick Schaumont, editors, CHES 2012, volume 7428 of
LNCS, pages 58–75. Springer, Heidelberg, September 2012.
[29] Svetla Nikova, Vincent Rijmen, and Martin Schläffer. Secure

hardware implementation of nonlinear functions in the
presence of glitches. Journal of Cryptology, 24(2):292–321,
April 2011.

[30] Martin Pettai and Peeter Laud. Automatic proofs of privacy of

secure multi-party computation protocols against active
adversaries. In Cédric Fournet, Michael W. Hicks, and Luca
Viganò, editors, IEEE 28th Computer Security Foundations
Symposium, pages 75–89. IEEE Computer Society, 2015.
[31] Emmanuel Prouff and Matthieu Rivain. Masking against
side-channel attacks: A formal security proof. In Thomas
Johansson and Phong Q. Nguyen, editors, EUROCRYPT 2013,
volume 7881 of LNCS, pages 142–159. Springer, Heidelberg,
May 2013.

[32] Matthieu Rivain and Emmanuel Prouff. Provably secure

higher-order masking of AES. In Stefan Mangard and
François-Xavier Standaert, editors, CHES 2010, volume 6225
of LNCS, pages 413–427. Springer, Heidelberg, August 2010.
[33] Calogero G. Zarba. Combining sets with cardinals. Journal of

Automated Reasoning, 34(1):1–29, 2005.

[34] Steve Zdancewic, Lantian Zheng, Nathaniel Nystrom, and

Andrew C. Myers. Untrusted hosts and conﬁdentiality: Secure
program partitioning. In Keith Marzullo and
M. Satyanarayanan, editors, Proceedings of the 18th ACM
Symposium on Operating System Principles, pages 1–14.
ACM, 2001.

Appendices
A. PROOFS

This appendix lists proofs omitted from the main body of the

paper, and whose text may add to the reader’s comprehension.

PROOF SKETCH FOR PROPOSITION 1. Leveraging the equiva-
lence between simulation and non-interference (Lemma 2), we prove
t-SNI by constructing a simulator that uses at most |Oint| shares of
the gadget’s input to perfectly simulate the joint distribution of any
position set O such that |O| ≤ t. The constructed simulator is very
similar to those previously used in proofs of t-NI.
Let O be a set of positions such that |O| ≤ t, and let d1 = |Oint|
and d2 = |Oext|. Note that d1 + d2 ≤ t. Our goals are: i. to ﬁnd an
input set I such that (cid:107)I(cid:107) ≤ d1, ii. to construct a perfect simulator
that uses only input shares ai ∈ I.
First, we identify which variables are internal (and therefore will
be considered in Oint) and which are outputs (in Oext). Internals
are the ai, the ri,j (the value of r sampled at iteration i, j), and
the ci,j (resp. cj,i) which correspond to the value of the variable

ci (resp. cj) at iteration i, j of the second loop. Outputs are the
ﬁnal values of ci (i.e. ci,t). Then, we deﬁne I as follows: for
each position among ai, ri,j and ci,j (with j < t) we add share
ai to I. It is clear that I contains at most d1 positions, since each
internal position adds at most one position to I. We now construct
the simulator. For clarity, observe that the RefreshM algorithm can
be represented using the following matrix, observing that ci,j is the
partial sum of the ﬁrst j + 2 elements of line i.
···
···
···
...
···

r0,1
0
(cid:9)r1,2
...
...
(cid:9) r1,t (cid:9)r2,t

0
(cid:9) r0,1
(cid:9)r0,2
...
(cid:9) r0,t

 .



a0
a1
a2

...
ad

r0,2
r1,2
0

r0,t
r1,t
r2,t

...

0

For each ı0 such that aı0 ∈ I (that is, for each line ı0 of the matrix
that contains at least one observed internal value), aı0 is provided to
the simulator (by deﬁnition of I). Thus, the simulator can sample all
th output normally.
rı0,j and compute all partial sums cı0,j and the ı0
At this point, all values (all internals and all outputs) on lines indexed
by an ı with aı ∈ I follow the same distribution as they would in
the real computation and are therefore perfectly simulated.
It remains to simulate output shares c when a /∈ I. Remark
that simulating the ıth line as above also necessarily ﬁxes the value
of all random variables appearing in the ıth column. After internal
positions are simulated, at most d1 lines of the matrix are fully ﬁlled.
Therefore, each line  with a /∈ I contains at least t − d1 ≥ d2
holes corresponding to random values that have not yet been ﬁxed.
For each of the output position made on one such line , we can
therefore pick a different r,k that we choose so c can be simulated
by a freshly sampled uniform value.

PROOF SKETCH FOR LEMMA 5. [16] exhibit proofs for both
statements. We now sketch a proof of t-NI for Cube that does not
exhaustively consider all (t + 1)-tuples of positions in Cube, empha-
sizing the critical use of strong non-interference for the refreshing
gadget. Recall that our goal is to upper-bound (cid:107)depsetCube(O)(cid:107)
for all O ⊆ OCube such that |O| ≤ t. Given such a set, we ﬁrst
partition it as O (cid:52)
= OM (cid:93) OR (cid:93) OS following gadget boundaries
(recall that positions in algorithms include the label of the gadget
invocation they occur in). First, we consider the dependency set
(cid:52)
IM
= depsetMult(OM) of OM by Mult. We know |OM| ≤ |O| ≤ t,
and by t-NI of Mult, we deduce that (cid:107)IM(cid:107) ≤ |OM|. Consider-
ing now the invocation of RefreshM, we must establish cardinality
(cid:52)
properties of the dependency set IR
= depsetRefreshM(OR ∪ IM|y2 )
of those direct internal positions observed by the adversary in
RefreshM, jointly with those output positions she may have learned
information about through positions probed in later parts of the
circuit (here, in Mult). From previous inequalities, we know that
|IM|y2| ≤ (cid:107)IM(cid:107) ≤ |OM|, and thus we have |OR ∪ IM|y2| ≤ t. By
t-SNI of RefreshM, we thus have (cid:107)IR(cid:107) ≤ |OR| (since positions in
IM|y2 are external to RefreshM). Finally, we consider the depen-
(cid:52)
dency set IS
= depsetSquare(OS∪IR|y1 ) of direct internal positions
observed by the adversary in Square, jointly with those output po-
sitions she may have learned information about through positions
probed in later parts of the circuit (here in RefreshM and Mult, prop-
agated through the single use of y1 in the invocation of RefreshM).
Since we have |OS ∪ IR|y1| ≤ |OS| + (cid:107)IR(cid:107) ≤ |OS| + |OR| ≤ t,
and since Square is t-NI, we conclude that (cid:107)IS(cid:107) ≤ |OS| + |OR|.
Overall, we have depsetCube(O) ⊆ IS|x ∪ IM|x, and we can con-
clude (using some of the intermediate inequalities from above), that
(cid:107)depsetCube(O)(cid:107) ≤ |OS| + |OR| + |OM| ≤ t.

129