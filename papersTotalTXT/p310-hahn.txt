Searchable Encryption with Secure and Efﬁcient Updates

Florian Hahn
SAP, Karlsruhe

Germany

Florian Kerschbaum

SAP, Karlsruhe

Germany

ﬂorian.hahn@sap.com

ﬂorian.kerschbaum@sap.com

ABSTRACT
Searchable (symmetric) encryption allows encryption while
still enabling search for keywords.
Its immediate applica-
tion is cloud storage where a client outsources its ﬁles while
the (cloud) service provider should search and selectively
retrieve those. Searchable encryption is an active area of
research and a number of schemes with diﬀerent eﬃciency
and security characteristics have been proposed in the liter-
ature. Any scheme for practical adoption should be eﬃcient
– i.e. have sub-linear search time –, dynamic – i.e. allow
updates – and semantically secure to the most possible ex-
tent. Unfortunately, eﬃcient, dynamic searchable encryp-
tion schemes suﬀer from various drawbacks. Either they
deteriorate from semantic security to the security of deter-
ministic encryption under updates, they require to store in-
formation on the client and for deleted ﬁles and keywords
or they have very large index sizes. All of this is a problem,
since we can expect the majority of data to be later added
or changed. Since these schemes are also less eﬃcient than
deterministic encryption, they are currently an unfavorable
choice for encryption in the cloud. In this paper we present
the ﬁrst searchable encryption scheme whose updates leak
no more information than the access pattern, that still has
asymptotically optimal search time, linear, very small and
asymptotically optimal index size and can be implemented
without storage on the client (except the key). Our con-
struction is based on the novel idea of learning the index for
eﬃcient access from the access pattern itself. Furthermore,
we implement our system and show that it is highly eﬃcient
for cloud storage.

Categories and Subject Descriptors
D.4.6 [Operating Systems]: Security and Protection—
Cryptographic controls; H.3.1 [Information Storage and
Retrieval]: Content Analysis and Indexing—Indexing meth-
ods

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for proﬁt or commercial advantage and that copies bear this notice and the full citation
on the ﬁrst page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior speciﬁc permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’14, November 3–7, 2014, Scottsdale, Arizona, USA.
Copyright is held by the owner/author(s). Publication rights licensed to ACM.
ACM 978-1-4503-2957-6/14/11 ...$15.00.
http://dx.doi.org/10.1145/2660267.2660297.

Keywords
Searchable Encryption; Dynamic Searchable Encryption; Se-
cure Index; Update

1.

INTRODUCTION

Searchable (symmetric) encryption [8, 9, 11, 13, 19, 20,
24, 29] consists of three operations. Encryption transforms a
keyword/ﬁle pair using a secret key into a ciphertext. Using
the secret key one can generate a search token for a speciﬁc
keyword. Using this token, one can then search in a set of
ciphertexts for those that match the keyword. Hence, one
can encrypt, but still search without decryption.

The immediate application for searchable encryption is
cloud storage where the client outsources its storage, but
encrypts its ﬁles for conﬁdentiality beforehand and retains
the key. The advantage compared to standard encryption is
that the cloud can perform the search operation without the
key and only return a matching subset for a query. Hence,
the client does not have to download the entire data set and
search himself. In many cases this is an enormous eﬃciency
gain.

Any practical searchable encryption scheme should be eﬃ-
cient, dynamic and secure. By eﬃciency we mean sub-linear
search time and this is achieved using an (inverted) index.
Indices can be diﬃcult to update, particularly if they are
encrypted, but eﬃcient dynamic searchable encryption [8,
19, 20, 24] achieves just this. Nevertheless, current eﬃcient,
dynamic schemes [20, 24] leak a deterministic function of
the keyword during an update, require client storage and
additional storage linear in the number of deletes [8] or have
an index of the size of the number of documents times the
number of keywords [19]. This is a problem, since in long-
running systems the majority of data will be later added,
changed or deleted. Hence, a long-running system using
such a method is either no more secure or very ineﬃcient
in storage. Furthermore, since deterministic encryption is
very eﬃcient, searchable encryption becomes an unfavorable
choice for such cloud storage systems.

In this paper we present the ﬁrst dynamic searchable en-
cryption scheme with secure and eﬃcient updates. Even
under updates, our schemes leaks no more than what can
be inferred from the search tokens. Our index is only linear
in the number of keywords, hence asymptotically optimal,
and client storage (except the key) is optional in our con-
struction1. While our time for the ﬁrst, initial search of a
keyword is linear in the number of keywords, we show that

1Client storage can be used to speed up additions

310it amortizes over multiple searches and is hence practical.
We show a theoretic upper bound for amortization in O(n2)
searches in Section 6.3. In our experiments amortization is
approached much faster, namely after 0.73n searches, which
is a much more practical assumption. Furthermore, 84% of
all keywords where never searched for and remained seman-
tically secure encrypted.

Hence, our scheme oﬀers a new viable alternative for se-
cure storage in the cloud. It is nearly as eﬃcient as determin-
istic encryption having the same overall search complexity,
but it is clearly more secure leaking only the access pattern
of ﬁles. We implement our scheme and show that is highly
eﬃcient also in absolute performance metrics.

In summary, we contribute a searchable encryption scheme

that is

• dynamic. Data can be added, deleted and hence changed

after the initial outsourcing. In fact, we do not oﬀer
a speciﬁc operation for initial outsourcing and assume
all data is added incrementally.

• eﬃcient. Our scheme has asymptotically optimal, sub-
linear search time. Furthermore, our Java-based im-
plementation shows that a search in a collection with
300.000 keywords and documents can be performed in
70 ms on average. We only require to store 2 crypto-
graphic hash values per keyword and document.

• secure. We formalize security using a simulation-based
deﬁnition. Particularly, we deﬁne our own leakage
functions which are signiﬁcantly more restrictive than
those of related work. Loosely speaking, our scheme
is semantically secure unless a search token has been
revealed.

The remainder of the paper is structured as follows.

In
the next section, we explain the problem of securely up-
dating searchable encryption in more detail and outline our
solution approach. In Section 3 we describe the algorithms
of our scheme and formally deﬁne its security. We present
our construction in Section 4, before we prove its security
according to our deﬁnition in Section 5. We discuss open as-
pects in Section 6. In Section 7 we present the results of the
evaluation of our implementation. Finally, in Section 8 we
overview related work, before we summarize our conclusions
in Section 9.

2. PROBLEM DESCRIPTION

Searchable encryption consists of three operations: en-
cryption, token generation and search. Encryption takes a
plaintext, e.g. a ﬁle identiﬁer, a (set of) keyword(s) and a
key as input. In this paper we investigate symmetric search-
able encryption, but there also exists public key searchable
encryption [6]. Encryption produces a ciphertext which can
be outsourced to a server, e.g. in the cloud. The key holder
can generate a search token for a keyword using the token
generation operation. The storage service provider can iden-
tify all ciphertexts for a keyword using this search token and
the ciphertext(s) in the search operation. He learns which
ciphertexts match the query (the access pattern) and mul-
tiple ciphertexts can match.

Searchable encryption can secure outsourcing of data by
retaining the key at the client. Still due to the search ca-
pability eﬃcient retrieval can be implemented. The leakage

of the access pattern is key to this eﬃciency, since it allows
to retrieve all ciphertexts in one round. Methods that hide
the access pattern come with additional restrictions. Private
information retrieval (PIR) [10, 22] can only retrieve one ci-
phertext. Furthermore computational PIR [22] requires a
linear scan of the data [28] and information-theoretic PIR
requires multiple servers to store the data [10]. Oblivious
RAM [14, 31, 33] accesses also one entry at a time and
that even with at least logarithmic overhead. An interesting
scheme is proposed by Stefanov et al. that combines ORAM
and searchable encryption [30]. This scheme leaks the access
pattern, but hides all keywords of updated ﬁles. Hence, it
has less leakage than our scheme, but it still has logarithmic
search time.

Song et al. introduced searchable encryption as a standard
semantically secure encryption scheme that only leaks the
access pattern of searches [29]. Their scheme still requires a
linear scan of all data for searching. Meanwhile, Hacig¨um¨us
et al. use deterministic encryption to search eﬃciently – in
sublinear time – in databases [16]. Clearly, deterministic en-
cryption leaks signiﬁcantly more information than the access
pattern and hence is less secure, but more eﬃcient.

Curtmola et al. introduced semantically secure searchable
encryption with sublinear search time [11]. Loosely speak-
ing, the basic idea is to construct an index as also used
in deterministic encryption. The index is encrypted and
contains deterministically encrypted index keywords. Then
there is a list of entries where the pointer to the next entry
is encrypted with a key speciﬁc for the keyword. The search
token is a deterministic function of the keyword plus the
key for the decryption of the pointers. The storage service
provider can look up the deterministic keyword in sublinear
time and then decrypt and traverse the list. Still, this is
semantically secure unless a search token has been revealed,
since each keyword is encrypted deterministically at most
once.

Curtmola et al.’s construction builds this index on the
client before he uploads the data to the service provider.
They introduce an additional operation called BuildIndex
that takes all plaintexts and keywords as input. Afterwards
they allow no more updates until the client builds the next
entire index. Kamara et al. propose dynamic searchable en-
cryption where this index can be incrementally updated [20].
They describe an update operation that, loosely speaking,
takes the deterministically encrypted keyword, a ciphertext
and a token key as input. The service provider can then
insert the new ciphertext at the beginning of the list and
encrypt the pointer using the token key.

Another contribution starting with Curtmola et al. is the
simulation-based security deﬁnition. Diﬀerently from a game-
based security deﬁnition as in standard semantic security
the simulation-based security uses all leaked information to
construct a simulator that produces indistinguishable out-
put. This has the clear advantage that the expected leakage
of the encryption is explicitly spelled out. In order to acco-
modate updates Kamara et al. introduced additional leakage
functions: L3 and L4 in their paper. Particularly, for addi-
tions L3 leaks a deterministic function of each keyword in a
ciphertext. Now, consider a case where the client uploads an
empty index and incrementally adds all ciphertexts. In this
case, the deterministic keyword function result(s) is (are)
revealed for each ciphertext. Hence, in this case dynamic
searchable encryption is no more secure than any determin-

311Scheme
[20]
[24]
[19]
[8]
This paper 1
This paper 2

Search Time

O(m/n)
O(m/n)

Index Size Client Storage Revocation Storage Update Leakage Update Cost
O(m + n)
O(m + n)
O(log |f | · m/n) O(|f | · n)
O(m + n)
O(m + n)
O(m + n)

O(1)
O(1)
O(1)
O(n)
O(n)
O(1)

O(m/n)
O(m/n)
O(m/n)

O(m/n)
O(m/n)

O(m/n)
O(m/n)

O(m)

ID(w)
ID(w)

-
-
-
-

-
-
-

-
-

O(m)

O(log |f | · n)

Table 1: Overview over average complexities for eﬃcient dynamic searchable encryption schemes. n is the number of unique
keywords, m is the total number of keywords, ID(w) is a deterministic identiﬁer of the keyword, |f | is the number of ﬁles

istic encryption, yet has a constant overhead in space and
time.

Naveed et al. propose a scheme which trades storage for
performance by scattering the stored blocks using hashing
instead of encrypting the index [24]. They still leak a deter-
ministic function of the added keywords, i.e. the block where
the keyword index is stored. Kamara and Papamanthou ﬁx
this problem by using a tree-based construction, but this
has index size linear in the number of documents times the
number of keywords [19]. Furthermore, constants are quite
high, since each index entry (one bit) requires a semantically
secure ciphertext. Cash et al. ﬁx this problem by giving each
update a counter, but the client has to keep track of these
counters [8]. Furthermore, in order to accomodate deletes,
they organize those by keeping a revocation list, such that
the data may actually never be deleted. Nevertheless, they
oﬀer an edit operation that is also indistinguishable from
an add operation in case of never before searched keywords.
Table 1 gives a comparison of these and our schemes.

The problem we consider in this paper is whether we can
update an outsourced storage without leaking anything ex-
cept the access pattern and with minimal storage overhead.
It is important to maintain an index for sublinear search
time, since for large data sets linear scans are prohibitive,
particularly if they involve a linear number of cryptographic
operations. Moreover, it is important to provide storage-
eﬃcient updates, since in the long run the majority of the
data will have been added after the initial outsourcing. Over
the history of computing we have observed an exponential
growth in data, such that the initial data set is quickly
marginalized.

On a high level our approach works by learning the index
from the access pattern. We start with a non-index based
searchable encryption scheme that requires linear scans. When
we search, we learn the search token which is deterministic
and the access pattern. We then start to construct an in-
dex using the token and the accessed ciphertexts. When
we search the same keyword again we can use the index
and search in constant time. Over the long run, the initial
linear search time amortizes and we achieve asymptotically
optimal search time while leaking nothing except the access
pattern.

We show a theoretic analysis with an upper bound for
amortization of O(n2) searches. Yet, in our experiments
amortization is approached much faster, namely after 0.73n
searches.This is an assumption which can be easily met in
practice.

Clearly, the access pattern of past searches extends to the
future. A search token stays valid and can be used to match
against future ciphertexts until the entire system is rekeyed.

We have to account for this in our security deﬁnition and
include the respective leakage. We emphasize that this leak-
age is notably less than the leakage of the add operation
by Kamara et al. [20] or Naveed et al. [24] and diﬀerently
to their scheme ciphertexts for not previously searched key-
words remain semantically secure. Furthermore, this leakage
is already part of the most simple construction based on the
searchable encryption scheme by Song et al. [29] and it is also
not excluded in any of the other eﬃcient, dynamic searchable
encryption schemes [8, 19]. In our experiments using real-
world search terms, 84% of all keywords were never searched
for and hence remained semantically secure encrypted.

We also optionally maintain a history of previous search
tokens at the client, such that ciphertexts for previously
searched keywords are encrypted diﬀerently. We emphasize
that this choice is a pure performance optimization and the
history could just as well be kept at the service provider at a
higher update cost. Furthermore, should the client lose the
saved history, he can restore it from the index information
of the service provider. We further explain this choice in
Section 6.1.

Still, our construction is highly eﬃcient and provides prac-
tical performance. We implement our system and a search
in collection with 300.000 keywords and documents can be
performed in 70 ms on average. We require very little stor-
age overhead and only need to store 2 cryptographic hash
values per keyword and document. We provide the detailed
performance results in Section 7.

3. DEFINITIONS

The set of binary strings of length n is denoted as {0, 1}n,
the set of all ﬁnite binary strings is denoted as {0, 1}∗.
Given a binary string u, we denote len (u) as its bit length.
Given two binary strings u, v, the concatenation is written
as u||v. The notation [1, n] with n ∈ N denotes the integer
set {1, . . . , n}. We denote the output z of a (possibly proba-
bilistic) algorithm A as z ← A. Sampling uniformly random
from a set X is denoted as x ← X.

Throughout, λ will denote the security parameter. A
function f : N → R is negligible in x if for every positive
polynomial p(·) there exists a x0 such that for all x > x0,
f (x) < 1/p(·).

We assume each ﬁle f having a unique ﬁle identiﬁer ID(f ),
each ﬁle consists of words that is f = (w1, . . . , wlen(f )) with
wi ∈ {0, 1}∗. For a ﬁleset f we denote len (f) as the number
of ﬁles in f. Given a keyword w we write fw as the subset
of all ﬁles f that contain w. In addition, the set of all ﬁle
identiﬁers that contain this keyword w is denoted by Iw more
formally it is deﬁned as Iw = {ID(fi) : fi ∈ fw}.

312As mentioned in Section 1, our scheme does not oﬀer an
operation for initial outsourcing a set of ﬁles but starts with
an empty search index γ. The service provider’s search in-
dex γ and collection of encrypted ﬁles c are updated by ﬁle
speciﬁc add tokens αf for ﬁle f and its encryption.

To perform a search query for keyword w, the client gen-
erates an deterministic search token τw that is handed to
the service provider. For simplicity of the exposition we as-
sume that all generated search tokens are given to the service
provider, i.e. if a search token has been created by the client
the service provider gains knowledge of it.

Finally, to delete a ﬁle f the client simply passes its ﬁle

identiﬁer ID(f ) to the service provider.

Definition 1

(SUISE). A securely updating index-based

searchable encryption scheme is a tuple of eight (possibly
probabilistic) polynomial-time algorithms SUISE = (Gen,
Enc, SearchToken, Search, AddToken, Add, Delete, Dec)
such that:

(K, γ, σ) ← Gen(1λ): is a probabilistic algorithm that
takes as input a security parameter λ and outputs a
secret key K, a (still empty) search index γ and a (still
empty) search history σ.

c ← Enc(K, f ): is a probabilistic algorithm that takes
as input a secret key K and a ﬁle f .
It outputs an
encrypted ﬁle c.

(σ′, τw) ← SearchToken(K, w, σ): is a (possibly proba-
bilistic) algorithm that takes as input a secret key K,
a keyword w and search history σ. It outputs a new
search history σ′ and a search token τw.

(Iw, γ ′) ← Search(τw, γ): is a deterministic algorithm
that takes as input a search token τw, a sequence of
encrypted ﬁles c and a search index γ. It outputs a
sequence of identiﬁers Iw and an updated search index
γ ′.

αf ← AddToken(K, f, σ): is a (possibly probabilistic)
algorithm that takes as input a secret key K, a ﬁle f
and a search history σ. It outputs an add token αf .

(c′, γ ′) ← Add(αf , c, c, γ):
is a deterministic algo-
rithm that takes as input an add token αf , an en-
crypted ﬁle c, a sequence of encrypted ﬁles c and a
search index γ . It outputs an updated search index γ ′
and an updated sequence of encrypted ﬁles c′.

(c′, γ ′) ← Delete(ID(f ), c, γ): is a deterministic algo-
rithm that takes as input an identiﬁer ID(f ) of the ﬁle
that shall be removed, a sequence of encrypted ﬁles c
and a search index γ. It outputs an updated sequence
of encrypted ﬁles c′ and an updated search index γ ′.

f ← Dec(K, c): is a deterministic algorithm that takes
as input an encrypted ﬁle c and a key K. It outputs
the decrypted ﬁle f .

In an ideal scenario, searchable encryption is implemented
in a way where the service provider learns absolutely nothing
about either the ﬁles or the search queries. As mentioned
in Section 2, there are methods to achieve this strict secu-
rity goals, but these come along with huge overhead. By
allowing the sever to learn particular information (e.g. the
access pattern) we can construct more eﬃcient searchable
encryption schemes. To address this small knowledge the
service provider gains, we follow the approach of [8, 11, 19,
20, 24] and use leakage functions. The additional knowledge
the provider gains by getting ciphertexts and (add or search)
tokens is deﬁned by these functions.

As noticed in [11], there is a diﬀerence between security
against adaptive chosen keyword attacks (CKA2) and non-
adaptive chosen keyword attacks (CKA 1), that must be
taken into account for security analyses. Security against
CKA2 guarantees security even when the client’s generated
query depend on results of previous queries and the search
index.
In contrast, security against CKA1 guarantees se-
curity only when all queries generated by the client are in-
dependent of previous queries and the search index. Our
construction achieves the stronger notion of CKA2 security,
that is modiﬁed in a way suggested by Kamara et al. in [20]
to ﬁt into the scenario of dynamic SSE.

Definition 2. Let SUISE = (Gen, Enc, SearchToken,
Search, AddToken, Add, Delete, Dec) be a securely updat-
ing index-based searchable encryption scheme. Consider the
following experiments with stateful attacker A, stateful sim-
ulator S and stateful leakage functions Lsearch, Ladd, Lencrypt.

A (λ) : the challenger runs Gen(1λ) to get the
RealSSE
tuple (K, γ, σ). The adversary A makes a polynomial
number of adaptive queries q ∈ {w, f1, f2} and for
each query q the challenger generates either a search
token τw ← SearchToken(K, w, σ), an add token αf ←
AddToken(K, f1, σ), or a ﬁle encryption c ← Enc(K, f2).
Finally, A returns a bit b that is output by the experi-
ment.

IdealSSE
A,S (λ) : the simulator sets up its internal envi-
ronment. The adversary A makes a polynomial num-
ber of adaptive queries q ∈ {w, f1, f2} and for each
query q the simulator is given the appropriate leakage
i.e. either given Lsearch(f, w), Ladd(f, f1) or Lencrypt(f2).
S returns the appropriate token fτw, fαf or a ciphertext
ec. Finally, A returns a bit b that is output by the ex-
periment.

We say SUISE is (Lsearch, Ladd, Lencrypt)-secure against adap-
tive dynamic chosen-keyword attacks if for all probabilis-
tic polynomial-time algorithms A there exists a probabilistic
polynomial-time simulator S so that advantage of A deﬁned
as

A (λ) = 1(cid:3) − Pr(cid:2)IdealSSE

A,S (λ) = 1(cid:3)(cid:12)(cid:12)

(cid:12)(cid:12)Pr(cid:2)RealSSE

is negligible in λ.

In Figure 1 we show the protocols between client and
server combining these algorithms into interaction patterns.
A dynamic searchable encryption scheme is called correct
if for all λ ∈ N, all keys K generated by Gen(1λ), and all
sequences of add, delete and search operations on search
index γ, every search operation returns the correct set of
ﬁles (except with negligible probability).

4.

IMPLEMENTATION

On a high level our construction works by learning the
index from the access pattern. Initially we maintain a reg-
ular index, i.e. for each document we store its (encrypted)
keywords. We denote this index γf . Once a keyword is
searched, we move all ﬁle identiﬁers to an inverted index for

313Initial Setup

Client

Server

Search Files

Client

Server

Gen(1λ)

(K, γ, σ)

Add File
Delete File
Search Files

γ

. . .

. . .

SearchToken(K, w, σ)

(σ′, τw)

Dec(K, ci)i∈Iw

{fi}i∈Iw

τw

{ci}i∈Iw

Search(τw, γ)

(Iw, γ ′)

Add File

Client

Server

Delete File

Enc(K, f )

c

AddToken(K, f, σ)

αf

c, αf

Add(αf , c, c, γ)

(c′, γ ′)

Client

Server

ID(f )

Delete(ID(f ), c, γ)

(c′, γ ′)

Figure 1: Use of algorithms from Deﬁnition 1 for realizing the complete protocol.

the keyword, i.e. the keyword is now the key to the index.
The keyword is also encrypted; it is the search token. We
denote this index γw.

Clearly, we have to accomodate future updates for key-
words that have already been searched. These keywords –
and their corresponding ﬁle identiﬁers – have been moved to
the inverted index. Hence, an update needs to update the
inverted index, or we need to always search both indices,
completely ruining search time. In this section we present
the option to maintain the search history at the client. The
client checks whether a keyword has been searched and tells
the server to include it in the inverted index. This is a pure
performance optimization. We present the alternative op-
tion to maintain the search history on the server at a higher
update cost in Section 6.1.

For our implementation we use several data structures in-
cluding lists and (chained) hash tables. For list l we denote
len (l) for the number of elements in l and x ∈ l iﬀ value x is
stored in list l. Accessing the element at position i is written
as l[i]. A hash table T stores values v associated with keys
k, written as T [k] = v. We write v ∈ T if there is a key k so
that T [k] = v. For our implementation it is crucial that it is
feasible to access a value v with corresponding key k stored
in a hash table in constant time. If the values stored in the
hash table are lists, we call it a chained hash table.

Given an IND-CPA secure secret-key encryption scheme
SKE = (GIND-CPA, E IND-CPA, DIND-CPA), a pseudorandom
number generator G that outputs random numbers with
bit length λ and a pseudorandom functions F : {0, 1}λ ×
{0, 1}∗ → {0, 1}λ, and a random oracle H : {0, 1}λ×{0, 1}∗ →
{0, 1}λ we construct dynamic SSE scheme SUISE = (Gen,

Enc, SearchToken, Search, AddToken, Add, Delete, Dec) as
follows:

• (K, γ, σ) ← Gen(1λ): sample two λ-bit strings k1 ←
{0, 1}λ and k2 ← GIND-CPA(1λ).
In addition, create
two empty chained hash tables γf , γw and an empty
set σ. Output (K, γ, σ), with K = (k1, k2) and γ =
(γf , γw).

• c ← Enc(K, f ): parse key K = (k1, k2) and output

c = E IND-CPA

k2

(f ).

• (τw, σ′) ← SearchToken(K, w, σ): parse key K = (k1, k2)

calculate Fk1 (w) = τw set σ′ = σ ∪ {τw} and output
(τw, σ′).

• (Iw, γ ′) ← Search(τw, γ): parse search index γ = (γw, γf )

and check if there is an entry for τw in γw.

– If yes, then set Iw = γw[τw] and γ ′
– Otherwise create an empty list Iw and do for every

w = γw.

c ∈ γf :

1. for every ci ∈ c that is i ∈ [1, len (c)], set
ci = li||ri and check if Hτw (ri) = li. If yes
then insert ID(f ) that corresponds to c into
Iw.

Update γ ′

w by creating an entry γw[τw] = Iw

Output Iw and (an updated version of) γ ′ = (γ ′

w, γf ).

• αf ← AddToken(K, f, σ): parse K = (k1, k2). For ﬁle
f that consists of a sequence of words create a list f
of unique words f ⊇ f = (w1, . . . , wlen(f)). Generate

314a sequence of pseudorandom values s1, . . . slen(f) with
PRNG G and create an empty list x. For every word
wi ∈ f do the following:

1. compute the corresponding search token τwi =

Fk1 (wi)

2. if this search token was used for a previous search:

if τwi ∈ σ, add τwi to x.

3. set ci = Hτwi (si)||si

Now sort c = (c1, . . . , clen(f)) in lexicographic order
and set αf = (ID(f ), c, x). Output αf .

• (c′, γ ′) ← Add(αf , c, c, γ): parse αf = (ID(f ), c, x),
γ = (γw, γf ) and set γf [ID(f )] = c. In addition, for
every xi ∈ x add ID(f ) to γw[xi]. Update the cipher-
texts c to c′ by adding c. Output c′ and the updated
version γ ′ = (γw, γf ).

• (c′, γ ′) ← Delete(ID(f ), c, γ): parse γ = (γw, γf ),
check for every list e saved in γw if ID(f ) ∈ e and
remove ID(f ) in this case from e. Remove ciphertext
c corresponding to ID(f ) from c and remove γf [ID(f )]
from γf . Output an updated set of encrypted ﬁles c
and an updated search index γ ′ = (γw, γf ).

• f ← Dec(K, c): parse K = (k1, k2) and output f =

DIND-CPA

k2

(c).

Our scheme provides correctness with all but negligible
probability. When we have a collision of H, Search out-
puts a false index Iw that is for two diﬀerent search to-
kens τ, τ ′ and two diﬀerent random numbers s, s′ we have
H(τ, s) = H(τ ′, s′). Since H is a random oracle with image
size {0, 1}λ, a collision occurs for N queries with probabil-
ity proportional to N 22−λ and therefore is negligible for N
polynomial in λ. Furthermore, these collisions result in false
positive answers for Iw and can be ﬁltered out by the client
repeating the search on all decrypted ﬁles with IDs contained
in Iw. Exactly the same argument holds for a collision of the
pseudorandom function F , that is generating two equivalent
search tokens for diﬀerent words.

5. SECURITY

As mentioned before, some operations leak particular in-
In detail, we use three

formation to the service provider.
leakage functions Lsearch, Ladd, Lencrypt deﬁned as follows:

Lsearch(f, w) = (ACCPt(w), ID(w))

Ladd(f, f ) = (ID(f ), len(cid:0)f(cid:1) , SRCH HISt(f ))
Lencrypt(f ) = len (f )

where ACCPt(w) is the access pattern at time t deﬁned
as set {ID(fi) : w ∈ fi and fi ∈ f}, f is the set of unique
words in ﬁle f , and SRCH HISt(f ) is the set of IDs of all
searched words until time t that also appear in f .

Since search tokens τ are deterministic, an attacker is able
to link generated search tokens with words, although she
does not know what the plain word is. This is denoted by
ID(w) in our leakage functions.

Now we are ready to proof the following theorem:

Theorem 1. If the used secret key encryption scheme
SKE is IND-CPA secure, F is a pseudorandom function and

G is a pseudorandom generator, then SUISE as described
in Section 4 is (Lsearch, Ladd, Lencrypt)-secure against adap-
tive dynamic chosen-keyword attacks in the random oracle
model.

Proof. We describe a polynomial time simulator S for
which the advantage of any PPT attacker A to distinguish
between the output of RealSSE
A,S (λ) is negli-
gible. Our simulator adaptively simulates a search index eγ
with the additional information given by the leakage func-
tions.

A (λ) and IdealSSE

1. Setting up the environment:

S creates an empty list eσ as simulated search history,
an empty simulated search index eγ = (fγw, fγf ) consist-
ing of two empty hash tables, and an empty dictionary
ρ to keep track of queries to the random oracle. A key
k3 ← GIND-CPA(1λ) is sampled for simulating encryp-
tion of ﬁles. A chained hash table C is used to keep
track of tuples (j, eτ ) consisting of previously simulated
search indexes and simulated search tokens for each
individual ﬁle. In detail, an entry of C consists of a
linked list, we denote Cfi as the linked list for ﬁle fi,
that is stored at hash table entry C[ID(fi)]. Further-
more, other empty hash tables T and A are created,
where T is needed to keep track of the assignment of
simulated search tokens fτw for word w with ID(w) and
A is needed to keep track of simulated add tokens fαf
for already added ﬁles with ID(f ).

2. Simulating search tokens eτ with given leakage
Lsearch(f, w) = (ACCPt(w), ID(w)),

the simulator checks if ID(w) is in T i.e.
token for this word was queried before.

if a search

• If this is the case, S outputs T [ID(w)].

• Otherwise, a random bit string eτ ← {0, 1}λ is
chosen and stored at T [ID(w)] and added to eσ.
For every ID(fi) ∈ ACCPt(w) the simulator sets
Jfi as the set of all ﬁrst components of Cfi more
formally set Jfi = {jl : (jl, τl) ∈ Cfi with 0 ≤ l ≤
|Cfi |}. Then the simulator chooses a random in-
dex ji ← [1, |fγf [ID(fi)]|] \ Jfi and adds the tuple
(ji, eτ ) to the list Cfi . Finally, S outputs eτ .

3. Simulating add eα tokens with given leakage

Ladd(f, f ) = (ID(f ), len(cid:0)f(cid:1) , SRCH HISt(f )),

S checks if there is an entry at A[ID(f )] i.e. if an add
token for ﬁle f with ID(f ) was simulated before.

• If an add token fαf for ﬁle f with ID(f ) was re-
quested before, the simulator outputs A[ID(f )].
• If, on the other hand, this ﬁle was not added be-
fore, the simulator chooses for every i ∈ [1, len(cid:0)f(cid:1)]
a random bit string esi ← {0, 1}2λ, and sorts this
generated set ( es1, . . . ,eslen(f)) in lexicographic or-
der to get es and stores this at fγf [ID(f )]. In ad-
dition, an empty list ex is created and for every
ID(w) ∈ SRCH HISt(f ) the token fτw = T [ID(w)]
is looked up, added to ex and ID(f ) is added to
fγw[fτw]. S creates a temporary set J and for
all l ∈ [1, len (ex)] a random fake index jl ←

315[1, |fγf [ID(fi)]|] \ J is sampled and added to J.
This index jl is marked as full in the list of used
search indexes by adding the tuple (jl, eτl) to Cf
in the chained hash table C, where eτl = ex[l]. Fi-
nally, S outputs fαw = (ID(f ),es, ex) and stores
this simulated token at A[ID(f )].

4. Simulating encryption with given leakage

Lencrypt(f ) = len (f ) ,

the simulator outputs ec ← E IND-CPA

K3

(0len(f )).

5. Answering random oracle queries: given query (k, r),
the simulator checks if this query was submitted before
i.e. if there is an entry l = ρ[k||r].

• If this is the case, set l = ρ[k||r].

• Otherweise, S checks if key k is linked with some
if there is an entry k = T [ID(w)]
ID(w) i.e.
for some ID(w).
If there is no used search to-
ken, a random bit string l ← {0, 1}λ is sampled
and ρ[k||r] = l is set to stay consistent for future
queries.
If, on the other hand, k is linked with some ID(w),
for every ID(fi) ∈ fγw[k] the simulator looks up
the tuple (j, k′) ∈ Cfi where k′ = k. Then the
value esj ∈ {0, 1}2λ is set as the j-th entry of
es = fγf [ID(fi)] and divided in two λ-bit strings
l′||r′ = esj .
– S checks if r′ = r, sets l = l′ in this case and

stores l at ρ[k||r].

– If there was no ﬁtting r′ for any ID(fi) ∈
fγw[k], a random l ← {0, 1}λ is sampled and

stored at ρ[k||r] to stay consistent for future
queries.

Finally, l is returned.

The indistinguishability of a simulated search token eτ and
a real search token τ follows from the pseudorandomness of
F . Also, the indistinguishability of a simulated search his-
tory eσ and a real search history σ follows from the pseu-
dorandomness of F . The indistinguishability of a simulated
add token eα, especially of es, ex, and a real add token α fol-
lows from the pseudorandomness of G and F . The indistin-
guishability of a simulated ciphertext ec and real ciphertext
c follows from the IND-CPA security of our used secret key
encryption. Since we choose the output of our simulated
random oracle H either totally random or out of a prede-
ﬁned domain, that itself is generated in a random way, our
random oracle is indistinguishable from a pseudo-random
function.

6. DISCUSSION

6.1 Why maintain a search history at the client?

We maintain a history of previously used search tokens at
the client and use it during the add operation. The client
creates the corresponding search tokens immediately as the
deterministic identiﬁer of the keyword. Hence, the service
provider can include it in the index. Note that the search
token is not necessarily part of the add token, rather it could
be randomized. In order to check whether a randomized add

token corresponds to a search token, the service provider
would need to check all previous search tokens. Only then, it
could convert the randomized add token to the deterministic
search token. To the contrary, the client can compute both
– search and add token of the inserted keyword – and simply
look up the search token in the history. Hence, the cost of
one insertion is O(len(f )) using a history at the client and
O(len(f )|SRCH HISt(f )|) using a history at the service
provider. Our solution using no client storage (except the
key) modiﬁes the Add and AddToken operations as follows:

• αf ← AddToken(K, f, σ): parse K = (k1, k2). For ﬁle
f that consists of a sequence of words create a list f
of unique words f ⊇ f = (w1, . . . , wlen(f)). Generate
a sequence of pseudorandom values s1, . . . slen(f) with
PRNG G. For every word wi ∈ f set ci = Hτwi (si)||si
with τwi = Fk1 (wi). Now sort c = (c1, . . . , clen(f)) in
lexicographic order and set αf = (ID(f ), c). Output
αf .

• (c′, γ ′) ← Add(αf , c, c, γ): parse αf = (ID(f ), c), γ =
(γw, γf ) and set γf [ID(f )] = c. In addition, for each
τwi ∈ γw and each cj ∈ c set cj = lj||rj and check if
Hτwi (rj) = lj. If yes, add ID(f ) to γw[wi]. Update
the ciphertexts c to c′ by adding c. Output c′ and the
updated version γ ′ = (γw, γf ).

The history at the client is the same as the index words
ID(w) in inverted index γw at the service provider. Hence
the client can always restore its history by downloading these
from the server. Moreover, let the number of unique key-
words be n, then the size of the history will never exceed
O(n) independent of the number of searches performed.

6.2 How to hide the number of unique key-

words per ﬁle?

Our leakage deﬁnition for the add operation still includes
the identiﬁer of the ﬁle (ID(f )) and the number of unique
keywords in that ﬁle (len(f )). One can hide both by adding
a level of indirection. First encrypt each ﬁle f , resulting
in the identiﬁer ID(f ). Then for each wi ∈ f encrypt ﬁle
f ′ = {ID(f )} resulting in unique identiﬁer ID(f ′). One can
now create the add token for ID(f ′) and wi. A simulator
for the add token operation is simple to derive from our
simulator: ID(f ′) – which is unique in the system – replaces
ID(f ) and is leaked instead, but len(f ′) = 1 and can hence
be omitted.

6.3 Search Time Analysis

In our algorithm the ﬁrst search for a keyword requires a
linear scan, but subsequent searches are (almost) constant.
Hence, the initial overhead amortizes and we reach asymp-
totically optimal search time for long-running systems. In
this section we analyse the required number of searches until
we reach this optimum.

Let n be the number of unique keywords stored in the ci-
phertexts; let m be the total number of stored keywords in
the ciphertext. Once we have created an index entry for a
keyword, our search complexity is m/n: We have a constant
lookup in the hash table and return m/n ciphertexts on av-
erage. An initial search can take up to m search (lookup)
operations and there can be at most n of those. Hence, the
initial eﬀort is (upper) bounded by mn. We are interested in

316the number N of searches such that the amortized cost be-
comes optimal. Since we need to return at least m/n entries,
this is the lower bound optimum. The cost is asymptotically
optimal, if there exists a constant c, such that the cost is at
most the optimum times c. The amortized cost is the cost
for inital searches (mn) divided by the number of searches
plus the cost for one subsequent search:

mn
N

+

m
n

≤ c

m
n

We conclude from this formula that we need at least N ≥
n2 searches until our cost is asymptotically optimal. The
constant c = 2 is low and we need at most 0.5 cryptographic
hash operation on the server on average. Read (search) re-
quests dominate many systems like databases, such that this
number can be quickly reached in practice.

7. PERFORMANCE RESULTS

The following experiments were implemented in Java 7.
Either operations performed by the server, or operations
performed by the client, were executed on an Intel Xeon
1230v3 CPU 3.30GHz with 8GB RAM running Windows 8.
To minimize I/O access time all ﬁles used in our simulations
are loaded into main memory before starting measurements.
For the implementation of our keyed random function
F and our random oracle H we use the implementation
of HMAC-SHA-1 that is contained in the default Java li-
brary. Also contained in the default Java library, we use
SHA1PRNG as random number generator G that outputs a
PRN with length of 160 bits.

7.1 On the client’s side

One main argument for outsourcing data is the use of
slow and weak hardware on client’s side. To show our SUISE
scheme feasible for this scenario, we simulated the creation of
add tokens and search tokens for 250, 000 random words per
run. We repeated each creation run 100 times and present
the mean value of these 100 runs for creating one token. We
simulated both versions for storing the search history that
is storing it on the client or storing it on the server.

The cost for creating search tokens depends on the cost
of generating one HMAC-SHA-1 mainly. Creating an add
token without checking the search history (so let the server
check for indexed words used in previous search queries)
needs two HMAC operations and one random number. If the
client has to check the search history, the cost for add token
generation also depends on the size of search history. For our
simulation we ﬁlled the search history with 0, 100, 000 and
1, 000, 000 unique words. By using Java’s HashSet as search
history, the lookup time can be minimized. Remember that
the search history contains unique search words used before
and stays quite small (see Figure 3) in relation to the number
of search queries.

We omitted time measurements for encryption and de-
cryption operations, since encrypting and decrypting ﬁles
with secret key encryption in an IND-CPA secure way is a
well studied problem. Furthermore, special clients may have
highly specialized hardware for performing a special kind of
secret key encryption scheme.

7.2 On the server’s side

All our simulations ran single threaded, but can easily
be executed in parallel. By dividing the search index γf

operation
SearchToken
AddToken
AddToken
AddToken

|σ|
-
0
105
106

time [µs]
1.14
4.77
5.06
5.47

Figure 2: Average duration for creating one token for one
word.

into subsets and search these subsets on diﬀerent cores it
is possible to speed up searches for search tokens that were
not searched before. In our test scenario all operations ran
on one machine so we were able to ignore latency through
network transfers that may occur in practice application.

We omit benchmarks for Add and Delete since the run-
time of these tasks depend on the chosen methods for cre-
ating indexes and updating these indexes. In addition, one
can interpret these operations as storing, accessing, adding
and deleting plaintext in an eﬃcient way, because no cryp-
tographic primitives are used there. Either cryptographic
primitives are used on the client before and benchmarked
there (e.g. creating add tokens) or are not needed at all.

So, the runtime of Search is discussed in the following.
For our experiments we added 50 ebooks downloaded from
project Gutenberg [1]. Before adding these ﬁles, all words
were transformed to lower case and punctuation was re-
moved. Our complete ﬁleset f consisted of 3, 654, 417 words
separated by whitespaces after this transformation. Remov-
ing words that appear multiple times in one ﬁle resulted in
a ﬁlest containing 337, 724 words so our index γf had size
337, 724. Altogether 95, 465 words were indexed i.e. 95, 465
diﬀerent search tokens would result in at least one posi-
tive match. To simulate realistic search queries we use a
list of word frequencies from [2] which represent real world
search queries but omitted the ﬁrst 100 entries that mainly
contained pronouns and prepositions. This word frequency
list contains about 400, 000 words and our search words are
chosen in a random fashion weighted according to their fre-
quency.

In order to benchmark search operations Search at the
service provider we generate 5000 random search tokens
using the probability distribution explained above. The
mean search time for these 5000 search tokens results in one
measurement point. A complete benchmark run consists of
75, 000 search queries, i.e. 15 values are measured per run.
In total, we repeated these benchmark runs 10 times and
plotted the average and the error bars provide the standard
derivation of these 10 runs. The average time for an initial,
linear search was 414.38 ms. The average time for a second,
constant time search was 0.01 ms.

Figure 3 shows the size of the search history over the time
of the experiment.
It also depicts the decreasing number
of newly generated search tokens that were not contained
in the search history before. Denoted by the white part,
every bar represents the size of search history σ before the
5000 search queries. The grey part represents the amount
of queried search tokens that were not known before these
5000 search queries. So, combining the white and the grey
part shows the size of search history σ after executing these
5000 queries. Figure 3 demonstrates the decreasing amount
of newly generated search tokens with increasing amount of

3179 5 4 6 5

...

1 5 0 0 0

1 0 0 0 0

5 0 0 0

]
s
d
r
o
w

[
 

y
r
o
t
s
i
h

 

h
c
r
a
e
s
 

n
i
 
s
d
r
o
w

 
e
u
q
i
n
u

 
f
o

 
e
z
i

S

Nu m b e r o f a ll u n iq u e  in d e xe d  w o rd s

Ne w  a d d e d  w o rd s  in  5 0 0 0  ru n s

Size  o f s e a rc h  h is t o ry  b e fo re

2 0 0

1 5 0

1 0 0

5 0

]
s

m

[
 
e
g
a
r
e
v
a
 

n
i
 

h
c
r
a
e
s
 
e
n
o

 
r
o
f
 
e
m
T

i

0

0

1 0 0 0 0 2 0 0 0 0 3 0 0 0 0 4 0 0 0 0 5 0 0 0 0 6 0 0 0 0 7 0 0 0 0 8 0 0 0 0

Am o u n t  o f a ll p e rfo rm e d  s e a rc h e s

0

0

1 0 0 0 0

2 0 0 0 0
5 0 0 0 0
Am o u n t  o f a ll p e rfo rm e d  s e a rc h e s

3 0 0 0 0

4 0 0 0 0

6 0 0 0 0

7 0 0 0 0

Figure 3: Unique search tokens queried; grey represents new
search tokens not asked before.

Figure 4: Mean query time for one random generated search
token of 5000.

total search queries. On the one hand, due to this eﬀect
the majority of our randomized add tokens remain random-
ized. At the end of the experiment less than 16% of the
unique keywords are in the inverted index γw and hence en-
crypted deterministically. On the other hand, this results in
decreasing search time, because already searched tokens can
be looked up in this inverted index.

This eﬀect is presented in Figure 4 in more detail. It shows
the mean search time in ms for blocks of 5000 searches over
the time of the experiment. One bar at position i in Figure 3
can be linked with the point in Figure 4 at position i on x-
axes. At the beginning the service provider did not know any
search tokens so that the search history σ is empty. Given
a search token in this situation, the service provider needed
to check the index of every ﬁle i.e. every list representing
one ﬁle in γf had to be checked value by value. With an
increasing size of the search history an increasing number
of search tokens were indexed in our reverse index γw and
hence the service provider was able to answer these queries
much faster. Our results also show that the optimal search
time is reached much faster than in n2 searches, since we
only perform 70.000 searches for more than 95.000 unique
keywords.

8. RELATED WORK

Song et al. introduced searchable encryption [29]. It pro-
vides a more secure alternative for searching compared to
deterministic encryption. Deterministic encryption is use-
ful for searching in outsourced databases, since it does not
require to modify the database engine for queries or up-
dates [16, 17]. Recent results, such as CryptDB [25], show
that its performance overhead is negligible and only a mi-
nority of database columns need to be encrypted in deter-
ministic encryption. Motivated by these use cases Bellare et
al. investigated deterministic encryption in a public key set-
ting [5]. Still, they conclude that searchable encryption, as

also proposed in this paper, could help securing the searched
data.

A number of works investigated eﬃciency increases for
searchable encryption. Goh ﬁrst proposed the use of in-
dexes [13]. Deterministic encryption allows the construction
of (most) indexes on the ciphertext – without modiﬁcation
of the algorithm –, but searchable encryption requires an
adjustment of the indexing method. Curtmola et al. were
the ﬁrst to use inverted indexes [11]. While constructing
the index can be performed on the plaintext, modifying it
without leakage is diﬃcult. We discussed in detail in Sec-
tion 2 the diﬀerent drawbacks of the dynamic searchable
encryption schemes [8, 19, 20, 24]. We did not consider the
scheme in [32], since it does not contain a formal security
proof. The scheme proposed in this paper is the ﬁrst with
asymptotically optimal search time, asymptotically optimal
storage cost and no leakage on updates.

Searchable encryption has also been extended in a num-
ber of ways. Boneh et al. introduced public key searchable
encryption based on identity-based encryption [6]. Another
direction is complex queries for conjunctive [15] and dis-
junctive [7] keyword combinations. Recent results achieved
signiﬁcant eﬃciency gains for these complex queries [9, 21].
Extending our method to complex queries is subject of fu-
ture work.

Searchable encryption has also been combined with proxy
re-encryption [12, 26]. Popa et al. also demonstrate another
interesting application of re-encryptable, searchable encryp-
tion for securing web applications [26]. Commercial oﬀerings
in this space currently focus on deterministic encryption [3,
4], since they do not require to rewrite the web application.
Clearly, searchable encryption has the potential to provide
enhanced security should the necessary operations, such as
updates, be eﬃciently and securely supported.

Disjunctive queries also allow to perform range queries.
Shi et al. ﬁrst demonstrate this in [27]. Lu shows that one
can also construct an index for range queries [23].

318Although searchable encryption is a clear security advan-

[7] D. Boneh and B. Waters. Conjunctive, subset, and

tage compared to deterministic encryption, Islam et al. demon-
strate an attack based on the leaked access patterns [18].
Their attack relies on the knowledge of the distribution of
keywords and works for many ciphertexts with a correspond-
ing search token. Hence, it is even more important to not
leak additional information during updates.

9. CONCLUSIONS

We have demonstrated a new technique for eﬃcient, dy-
namic searchable encryption. Our idea is to learn the index
from the search token. We have theoretically shown that
this must lead to the optimal search time over a suﬃciently
long period. We have experimentally shown that this search
time is low in absolute numbers and hence highly practical.
Furthermore, it is reached much faster in practice than the
theoretical upper bound.

Our scheme can be implemented without client storage
and only requires to store 2 cryptographic hash values per in-
dex entry. Additions and deletes can be performed securely.
We maintain semantic security even during updates, i.e. we
leak no additional information. We give detailed leakage
functions in our simulation-based security proof that com-
pare favourably with related work. In our experiments us-
ing real-world search terms, 84% of all keywords were never
searched for. These keywords remain semantically secure en-
crypted and hence proﬁt from the additional security under
updates provided by our scheme.

We believe our construction to be valuable from two per-
spectives. First, it provides a novel design alternative for
constructing dynamic searchable encryption scheme. Our
idea may be also applied to other research directions of
searchable encryption, such as complex queries. Second, it
provides a favorable trade-oﬀ compared to deterministic en-
cryption, since it is almost as eﬃcient – the time for the
second search of a keyword is the same –, but signiﬁcantly
more secure. Hence, it may provide a viable alternative for
practical adoption.

Acknowledgements
We would like to thank our reviewers for their insightful
comments that helped improve the paper and our shepherd
Frederik Armknecht who provided many helpful hints for
ﬁnishing the paper in the best possible mode. The work in
this paper was supported by the European Union Seventh
Framework Program (FP7/2007–2013) under grant agree-
ment no. 609611 (PRACTICE).

10. REFERENCES
[1] http://www.gutenberg.org/.
[2] http:

//invokeit.wordpress.com/frequency-word-lists/.

[3] http://www.ciphercloud.com/.
[4] http://www.vaultive.com/.
[5] M. Bellare, A. Boldyreva, and A. O’Neill.

Deterministic and eﬃciently searchable encryption. In
Advances in Cryptology, CRYPTO, 2007.

[6] D. Boneh, G. Di Crescenzo, R. Ostrovsky, and

G. Persiano. Public key encryption with keyword
search. In Advances in Cryptology, EUROCRYPT,
2004.

range queries on encrypted data. In Proceedings of the
4th Theory of Cryptography Conference, TCC, 2007.

[8] D. Cash, J. Jaeger, S. Jarecki, C. Jutla, H. Krawczyk,

M. Rosu, and M. Steiner. Dynamic searchable
encryption in very-large databases: Data structures
and implementation. In Proceedings of the 21st
Network and Distributed System Security Symposium,
NDSS, 2014.

[9] D. Cash, S. Jarecki, C. Jutla, H. Krawczyk, M.-C.

Rosu, and M. Steiner. Highly-scalable searchable
symmetric encryption with support for boolean
queries. In Proceedings of the 33rd Cryptology
Conference, CRYPTO, 2013.

[10] B. Chor, E. Kushilevitz, O. Goldreich, and M. Sudan.

Private information retrieval. Journal of the ACM,
45(6), 1998.

[11] R. Curtmola, J. Garay, S. Kamara, and R. Ostrovsky.

Searchable symmetric encryption: improved
deﬁnitions and eﬃcient constructions. Journal of
Computer Security, 19(5), 2011.

[12] C. Dong, G. Russello, and N. Dulay. Shared and
searchable encrypted data for untrusted servers.
Journal of Computer Security, 19(3), 2011.

[13] E.-J. Goh. Secure indexes. Technical Report 216,

IACR Cryptology ePrint Archive, 2003.

[14] O. Goldreich and R. Ostrovsky. Software protection

and simulation on oblivious rams. Journal of the
ACM, 43(3), 1996.

[15] P. Golle, J. Staddon, and B. Waters. Secure

conjunctive keyword search over encrypted data. In
Proccedings of the International Conference on Applied
Cryptography and Network Security, ACNS, 2004.
[16] H. Hacig¨um¨us, B. R. Iyer, C. Li, and S. Mehrotra.

Executing sql over encrypted data in the
database-service-provider model. In Proceedings of the
2002 ACM International Conference on Management
of Data, SIGMOD, 2002.

[17] H. Hacig¨um¨us, S. Mehrotra, and B. R. Iyer. Providing

database as a service. In Proceedings of the 18th
International Conference on Data Engineering, ICDE,
2002.

[18] M. Islam, M. Kuzu, and M. Kantarcioglu. Access

pattern disclosure on searchable encryption:
ramiﬁcation, attack and mitigation. In Proceedings of
the 19th Network and Distributed System Security
Symposium, NDSS, 2012.

[19] S. Kamara and C. Papamanthou. Parallel and
dynamic searchable symmetric encryption. In
Proceedings of the 17th International Conference on
Financial Cryptography and Data Security, FC, 2013.

[20] S. Kamara, C. Papamanthou, and T. Roeder.
Dynamic searchable symmetric encryption. In
Proceedings of the 19th ACM Conference on Computer
and Communications Security, CCS, 2012.

[21] J. Katz, A. Sahai, and B. Waters. Predicate

encryption supporting disjunctions, polynomial
equations, and inner products. In Advances in
Cryptology, EUROCRYPT, 2008.

[22] E. Kushilevitz and R. Ostrovsky. Replication is not

needed: Single database, computationally-private
information retrieval. In Proceedings of the 38th IEEE

319Symposium on Foundations of Computer Science,
FOCS, 1997.

[23] Y. Lu. Privacy-preserving logarithmic-time search on

encrypted data in cloud. In Proceedings of the 19th
Network and Distributed System Security Symposium,
NDSS, 2012.

[24] M. Naveed, M. Prabhakaran, and C. Gunter. Dynamic
searchable encryption via blind storage. In Proceedings
of the 35th IEEE Symposium on Security and Privacy,
S&P, 2014.

[25] R. A. Popa, C. M. S. Redﬁeld, N. Zeldovich, and

H. Balakrishnan. Cryptdb: protecting conﬁdentiality
with encrypted query processing. In Proceedings of the
23rd ACM Symposium on Operating Systems
Principles, SOSP, 2011.

[26] R. A. Popa, E. Stark, J. Helfer, S. Valdez,

N. Zeldovich, F. Kaashoek, and H. Balakrishnan.
Building web applications on top of encrypted data
using mylar. In Proceedings of the 11th USENIX
Symposium of Networked Systems Design and
Implementation, NSDI, 2014.

[27] E. Shi, J. Bethencourt, H. T.-H. Chan, D. X. Song,
and A. Perrig. Multi-dimensional range query over
encrypted data. In Proceedings of the 2007 Symposium
on Security and Privacy, S&P, 2007.

[28] R. Sion and B. Carbunar. On the practicality of

private information retrieval. In Proceedings of the
Network and Distributed System Security Symposium,
NDSS, 2007.

[29] D. X. Song, D. Wagner, and A. Perrig. Practical

techniques for searches on encrypted data. In
Proceedings of the 21st IEEE Symposium on Security
and Privacy, S&P, 2000.

[30] E. Stefanov, C. Papamanthou, and E. Shi. Practical
dynamic searchable symmetric encryption with small
leakage. In Proceedings of the 21st Network and
Distributed System Security Symposium, NDSS, 2014.
[31] E. Stefanov, M. van Dijk, E. Shi, C. Fletcher, L. Ren,

X. Yu, and S. Devadas. Path oram: an extremely
simple oblivious ram protocol. In Proceedings of the
20th ACM Conference on Computer and
Communications Security, CCS, 2013.

[32] P. van Liesdonk, S. Sedghi, J. Doumen, P. H. Hartel,
and W. Jonker. Computationally eﬃcient searchable
symmetric encryption. In Proceedings of the 7th VLDB
Workshop on Secure Data Management, SDM, 2010.
[33] P. Williams and R. Sion. Single round access privacy
on outsourced storage. In Proceedigs of the 19th ACM
Conference on Computer and Communications
Security, CCS, 2012.

320